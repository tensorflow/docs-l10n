{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4EFY9e5wRn7v"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "pkTRazeVRwDe"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VyOckJu6Rs-i"
      },
      "source": [
        "# Ampliação de dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HEsULqDR7AH"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>     <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/images/data_augmentation\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver em TensorFlow.org</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/pt-br/tutorials/images/data_augmentation.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Executar no Google Colab</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/pt-br/tutorials/images/data_augmentation.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver fonte no GitHub</a>\n",
        "</td>\n",
        "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/pt-br/tutorials/images/data_augmentation.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Baixar notebook</a>\n",
        "</td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxIOE5RnSQtj"
      },
      "source": [
        "## Visão geral\n",
        "\n",
        "Este tutorial demonstra a ampliação de dados, uma técnica para aumentar a diversidade do conjunto de treinamento por meio da aplicação de transformações aleatórias (mas realistas), como rotação de imagem.\n",
        "\n",
        "Você aprenderá a aplicar a ampliação de dados de duas maneiras:\n",
        "\n",
        "- Usando as camadas de pré-processamento do Keras, como `tf.keras.layers.Resizing`, `tf.keras.layers.Rescaling`, `tf.keras.layers.RandomFlip` e `tf.keras.layers.RandomRotation`.\n",
        "- Usando os métodos do `tf.image`, como `tf.image.flip_left_right`, `tf.image.rgb_to_grayscale`, `tf.image.adjust_brightness`, `tf.image.central_crop` e `tf.image.stateless_random*`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-UxHAqXmSXN5"
      },
      "source": [
        "## Configuração"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C2Q5rPenTAJP"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ydx3SSoF4wpG"
      },
      "source": [
        "## Baixar um dataset\n",
        "\n",
        "Este tutorial usa o dataset [tf_flowers](https://www.tensorflow.org/datasets/catalog/tf_flowers). Para sua conveniência, baixe o dataset usando os [TensorFlow Datasets](https://www.tensorflow.org/datasets). Se você quiser saber mais sobre outras formar de importar dados, confira o tutorial [Carregar imagens](https://www.tensorflow.org/tutorials/load_data/images).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ytHhsYmO52zy"
      },
      "outputs": [],
      "source": [
        "(train_ds, val_ds, test_ds), metadata = tfds.load(\n",
        "    'tf_flowers',\n",
        "    split=['train[:80%]', 'train[80%:90%]', 'train[90%:]'],\n",
        "    with_info=True,\n",
        "    as_supervised=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjxEJtCwsnmm"
      },
      "source": [
        "O dataset Flowers tem cinco classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wKwx7vQuspxz"
      },
      "outputs": [],
      "source": [
        "num_classes = metadata.features['label'].num_classes\n",
        "print(num_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZAQW44949uw"
      },
      "source": [
        "Vamos recuperar uma imagem do dataset e usá-la para demonstrar a ampliação de dados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kXlx1lCr5Bip"
      },
      "outputs": [],
      "source": [
        "get_label_name = metadata.features['label'].int2str\n",
        "\n",
        "image, label = next(iter(train_ds))\n",
        "_ = plt.imshow(image)\n",
        "_ = plt.title(get_label_name(label))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdJ6XA4q2nqK"
      },
      "source": [
        "## Usar as camadas de pré-processamento do Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRMPnfzBB2hw"
      },
      "source": [
        "### Redimensionamento e reescalonamento\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhG7gSWmUMJx"
      },
      "source": [
        "Você pode usar as camadas de pré-processamento do Keras para redimensionar suas imagens para um formato consistente (com `tf.keras.layers.Resizing`) e para reescalonar valores de pixels (com `tf.keras.layers.Rescaling`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jMM3b85e3yhd"
      },
      "outputs": [],
      "source": [
        "IMG_SIZE = 180\n",
        "\n",
        "resize_and_rescale = tf.keras.Sequential([\n",
        "  layers.Resizing(IMG_SIZE, IMG_SIZE),\n",
        "  layers.Rescaling(1./255)\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4z8AV1WgnYNW"
      },
      "source": [
        "Observação: a camada de reescalonamento acima padroniza os valores de pixel no intervalo `[0, 1]`. Se, em vez disso, você quiser que seja `[-1, 1]`, pode escrever `tf.keras.layers.Rescaling(1./127.5, offset=-1)`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQiTwsHJDHAD"
      },
      "source": [
        "Você pode visualizar o resultado da aplicação dessas camadas em uma imagem. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X9OLuR1bC1Pd"
      },
      "outputs": [],
      "source": [
        "result = resize_and_rescale(image)\n",
        "_ = plt.imshow(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxAMg8Zql5lw"
      },
      "source": [
        "Verifique se os pixels estão no intervalo `[0, 1]`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DPTB8IQmSeKM"
      },
      "outputs": [],
      "source": [
        "print(\"Min and max pixel values:\", result.numpy().min(), result.numpy().max())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fL6M7fuivAw4"
      },
      "source": [
        "### Ampliação de dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SL4Suj46ScfU"
      },
      "source": [
        "Você também pode usar as camadas de pré-processamento do Keras para fazer ampliação de dados, como `tf.keras.layers.RandomFlip` e `tf.keras.layers.RandomRotation`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-4PugTE-4sl"
      },
      "source": [
        "Vamos criar algumas camadas de pré-processamento e aplicá-las repetidamente à mesma imagem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Svu_5yfa_Jb7"
      },
      "outputs": [],
      "source": [
        "data_augmentation = tf.keras.Sequential([\n",
        "  layers.RandomFlip(\"horizontal_and_vertical\"),\n",
        "  layers.RandomRotation(0.2),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kfzEuaNg69iU"
      },
      "outputs": [],
      "source": [
        "# Add the image to a batch.\n",
        "image = tf.cast(tf.expand_dims(image, 0), tf.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eR4wwi5Q_UZK"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(9):\n",
        "  augmented_image = data_augmentation(image)\n",
        "  ax = plt.subplot(3, 3, i + 1)\n",
        "  plt.imshow(augmented_image[0])\n",
        "  plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jA17pEeS_2_-"
      },
      "source": [
        "Há diversas camadas de pré-processamento que você pode usar para fazer ampliação de dados, incluindo `tf.keras.layers.RandomContrast`, `tf.keras.layers.RandomCrop`, `tf.keras.layers.RandomZoom`, entre outras."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GG5RhIJtE0ng"
      },
      "source": [
        "### Duas opções de uso das camadas de pré-processamento do Keras\n",
        "\n",
        "Existem duas formas de usar essas camadas de pré-processamento, com contrapartidas importantes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MxGvUT727Po6"
      },
      "source": [
        "#### Opção 1: tornar as camadas de pré-processamento parte do seu modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ULGJQjP6hHvu"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential([\n",
        "  # Add the preprocessing layers you created earlier.\n",
        "  resize_and_rescale,\n",
        "  data_augmentation,\n",
        "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  # Rest of your model.\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pc6ELneyhJN9"
      },
      "source": [
        "É importante ficar ciente destes dois pontos importantes nesse caso:\n",
        "\n",
        "- A ampliação de dados será executada no dispositivo de forma síncrona com o restante das suas camadas e se beneficiará da aceleração de GPU.\n",
        "\n",
        "- Ao exportar o modelo usando `model.save`, as camadas de pré-processamento serão salvas junto com o restante do modelo. Se você implantar esse modelo posteriormente, ele vai padronizar as imagens de forma automática (de acordo com a configuração das suas camadas). Assim, você não precisará reimplementar essa lógica no servidor, poupando esforços."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syZwDSpiRXZP"
      },
      "source": [
        "Observação: a ampliação de dados fica inativa no momento do teste, então as imagens de entrada serão ampliadas somente durante chamadas a `Model.fit` (e não a `Model.evaluate` ou a `Model.predict`)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2X3JTeY_vfv"
      },
      "source": [
        "#### Opção 2: aplicar as camadas de pré-processamento ao seu dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r1Bt7w5VhVDY"
      },
      "outputs": [],
      "source": [
        "aug_ds = train_ds.map(\n",
        "  lambda x, y: (resize_and_rescale(x, training=True), y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKqeahG2hVdV"
      },
      "source": [
        "Com esta estratégia, você usa `Dataset.map` para criar um dataset que gera lotes de imagens ampliadas. Neste caso:\n",
        "\n",
        "- A ampliação de dados acontecerá de forma assíncrona na CPU e não causa bloqueios. Você pode sobrepor o treinamento do modelo na GPU com pré-processamento de dados usando `Dataset.prefetch`, conforme exibido abaixo.\n",
        "- Neste caso, as camadas de pré-processamento não serão exportadas com o modelo ao chamar `Model.save`. Você precisará anexá-las ao modelo antes de salvá-lo e reimplementá-las no servidor. Após o treinamento, você pode anexar as camadas de pré-processamento antes da exportação.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cgj51k9J7jfc"
      },
      "source": [
        "Confira um exemplo da primeira opção no tutorial [Classificação de imagens](classification.ipynb). Demonstraremos a segunda opção aqui."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31YwMQdrXKBP"
      },
      "source": [
        "### Aplicar as camadas de pré-processamento aos datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUgW-2LOGiOT"
      },
      "source": [
        "Configure os datasets de treinamento, validação e teste com as camadas de pré-processamento do Keras criadas anteriormente. Você também vai configurar os datasets para melhor desempenho usando leituras paralelas e pré-busca em buffers para gerar lotes pelo disco sem bloqueio de I/O (saiba mais sobre o desempenho do dataset no guia [Desempenho melhor com a API tf.data](https://www.tensorflow.org/guide/data_performance))."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eI7VdyqK767y"
      },
      "source": [
        "Observação: a ampliação de dados deve ser aplicada somente ao conjunto de treinamento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R5fGVMqlFxF7"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "def prepare(ds, shuffle=False, augment=False):\n",
        "  # Resize and rescale all datasets.\n",
        "  ds = ds.map(lambda x, y: (resize_and_rescale(x), y), \n",
        "              num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "  if shuffle:\n",
        "    ds = ds.shuffle(1000)\n",
        "\n",
        "  # Batch all datasets.\n",
        "  ds = ds.batch(batch_size)\n",
        "\n",
        "  # Use data augmentation only on the training set.\n",
        "  if augment:\n",
        "    ds = ds.map(lambda x, y: (data_augmentation(x, training=True), y), \n",
        "                num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "  # Use buffered prefetching on all datasets.\n",
        "  return ds.prefetch(buffer_size=AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N86SFGMBHcx-"
      },
      "outputs": [],
      "source": [
        "train_ds = prepare(train_ds, shuffle=True, augment=True)\n",
        "val_ds = prepare(val_ds)\n",
        "test_ds = prepare(test_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gplDz4ZV6kk"
      },
      "source": [
        "### Treinar um modelo\n",
        "\n",
        "Para completar, agora você treinará um modelo simples usando os datasets que acabou de preparar.\n",
        "\n",
        "O modelo [Sequential](https://www.tensorflow.org/guide/keras/sequential_model) consiste em três blocos de convolução (`tf.keras.layers.Conv2D`) com uma camada de pooling máximo (`tf.keras.layers.MaxPooling2D`) em cada um. Há uma camada totalmente conectada (`tf.keras.layers.Dense`) com 128 unidades sobre ela, que é ativada por uma função de ativação ReLU (`'relu'`). Esse modelo não foi ajustado para exatidão (o objetivo é mostrar as mecânicas)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IODSymGhq9N6"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential([\n",
        "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  layers.Dense(num_classes)\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86454855f7d9"
      },
      "source": [
        "Escolha o otimizador `tf.keras.optimizers.Adam` e a função de perda `tf.keras.losses.SparseCategoricalCrossentropy`. Para ver a exatidão do treinamento e da validação para cada época de treinamento, passe o argumento `metrics` para `Model.compile`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZnRJr95WY68k"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "976f718cabc8"
      },
      "source": [
        "Treine com algumas épocas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i_sDl9uZY9Mh"
      },
      "outputs": [],
      "source": [
        "epochs=5\n",
        "history = model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=epochs\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V9PSf4qgiQJG"
      },
      "outputs": [],
      "source": [
        "loss, acc = model.evaluate(test_ds)\n",
        "print(\"Accuracy\", acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BkRvvsXb6SI"
      },
      "source": [
        "### Ampliação de dados personalizada\n",
        "\n",
        "Você também pode criar camadas personalizadas de ampliação de dados.\n",
        "\n",
        "Esta seção do tutorial mostra duas maneiras de fazer isso:\n",
        "\n",
        "- Primeiro, você criará uma camada `tf.keras.layers.Lambda`. Essa é uma boa maneira de escrever códigos concisos.\n",
        "- Em seguida, você escreverá uma nova camada fazendo uma [subclasse](https://www.tensorflow.org/guide/keras/custom_layers_and_models), o que oferece um controle maior.\n",
        "\n",
        "As duas camadas inverterão aleatoriamente as cores de uma imagem de acordo com uma determinada probabilidade."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nMxEhIVXmAH0"
      },
      "outputs": [],
      "source": [
        "def random_invert_img(x, p=0.5):\n",
        "  if  tf.random.uniform([]) < p:\n",
        "    x = (255-x)\n",
        "  else:\n",
        "    x\n",
        "  return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C0huNpxdmDKu"
      },
      "outputs": [],
      "source": [
        "def random_invert(factor=0.5):\n",
        "  return layers.Lambda(lambda x: random_invert_img(x, factor))\n",
        "\n",
        "random_invert = random_invert()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wAcOluP0TNG6"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(9):\n",
        "  augmented_image = random_invert(image)\n",
        "  ax = plt.subplot(3, 3, i + 1)\n",
        "  plt.imshow(augmented_image[0].numpy().astype(\"uint8\"))\n",
        "  plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xd9XG2PLM5ZJ"
      },
      "source": [
        "Agora, implemente uma camada personalizada fazendo uma [subclasse](https://www.tensorflow.org/guide/keras/custom_layers_and_models):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d11eExc-Ke-7"
      },
      "outputs": [],
      "source": [
        "class RandomInvert(layers.Layer):\n",
        "  def __init__(self, factor=0.5, **kwargs):\n",
        "    super().__init__(**kwargs)\n",
        "    self.factor = factor\n",
        "\n",
        "  def call(self, x):\n",
        "    return random_invert_img(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qX-VQgkRL6fc"
      },
      "outputs": [],
      "source": [
        "_ = plt.imshow(RandomInvert()(image)[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0nmllnXZO6T"
      },
      "source": [
        "As duas camadas podem ser usadas conforme descrito nas opções 1 e 2 acima."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7-k__2dAfX6"
      },
      "source": [
        "## Uso de tf.image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJco2x35EAMs"
      },
      "source": [
        "Os utilitários de pré-processamento do Keras acima são convenientes, mas, para ter um controle mais granular, você pode escrever seus próprios pipelines ou camadas de ampliação de dados usando `tf.data` e `tf.image` (talvez você queira verificar também [Imagem dos complementos do TensorFlow: operações](https://www.tensorflow.org/addons/tutorials/image_ops) e [I/O do TensorFlow: conversões do espaço de cores](https://www.tensorflow.org/io/tutorials/colorspace))."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xR1RvjYkdd_i"
      },
      "source": [
        "Como o dataset Flowers foi configurado anteriormente com ampliação de dados, vamos reimportá-lo para que tenha a configuração original:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JB-lAS0z9ZJY"
      },
      "outputs": [],
      "source": [
        "(train_ds, val_ds, test_ds), metadata = tfds.load(\n",
        "    'tf_flowers',\n",
        "    split=['train[:80%]', 'train[80%:90%]', 'train[90%:]'],\n",
        "    with_info=True,\n",
        "    as_supervised=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQ3pqBTS9hNj"
      },
      "source": [
        "Recupere uma imagem para trabalhar com ela:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dDsPaAi8de_j"
      },
      "outputs": [],
      "source": [
        "image, label = next(iter(train_ds))\n",
        "_ = plt.imshow(image)\n",
        "_ = plt.title(get_label_name(label))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chelxcPtFiTF"
      },
      "source": [
        "Vamos usar a seguinte função para visualizar e comparar lado a lado as imagens original e ampliada:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sN1ykjJCHikc"
      },
      "outputs": [],
      "source": [
        "def visualize(original, augmented):\n",
        "  fig = plt.figure()\n",
        "  plt.subplot(1,2,1)\n",
        "  plt.title('Original image')\n",
        "  plt.imshow(original)\n",
        "\n",
        "  plt.subplot(1,2,2)\n",
        "  plt.title('Augmented image')\n",
        "  plt.imshow(augmented)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5X4ijQYHmlt"
      },
      "source": [
        "### Ampliação de dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRD9oujLHo6c"
      },
      "source": [
        "#### Inverter uma imagem\n",
        "\n",
        "Inverta uma imagem vertical ou horizontalmente com `tf.image.flip_left_right`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ZjVI24nIH0S"
      },
      "outputs": [],
      "source": [
        "flipped = tf.image.flip_left_right(image)\n",
        "visualize(image, flipped)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6iD_lLibIL9q"
      },
      "source": [
        "#### Mudar uma imagem para escala de cinza\n",
        "\n",
        "Você pode mudar uma imagem para escala de cinza com `tf.image.rgb_to_grayscale`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ikaMj0guIRtL"
      },
      "outputs": [],
      "source": [
        "grayscaled = tf.image.rgb_to_grayscale(image)\n",
        "visualize(image, tf.squeeze(grayscaled))\n",
        "_ = plt.colorbar()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-5yjIs4IZ7v"
      },
      "source": [
        "#### Saturar uma imagem\n",
        "\n",
        "Sature uma imagem com `tf.image.adjust_saturation`, fornecendo um fator de saturação:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PHz-NosiInmz"
      },
      "outputs": [],
      "source": [
        "saturated = tf.image.adjust_saturation(image, 3)\n",
        "visualize(image, saturated)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWXiy8qfIqdC"
      },
      "source": [
        "#### Alterar o brilho da imagem\n",
        "\n",
        "Altere o brilho da imagem com `tf.image.adjust_brightness`, fornecendo um fator de brilho:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1hdG-j46I0nJ"
      },
      "outputs": [],
      "source": [
        "bright = tf.image.adjust_brightness(image, 0.4)\n",
        "visualize(image, bright)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjEOFEITJOr2"
      },
      "source": [
        "#### Recorte uma imagem a partir do centro\n",
        "\n",
        "Recorte a imagem a partir do centro até a parte desejada usando `tf.image.central_crop`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RWkK5GFHJUKT"
      },
      "outputs": [],
      "source": [
        "cropped = tf.image.central_crop(image, central_fraction=0.5)\n",
        "visualize(image, cropped)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unt76GebI3Gc"
      },
      "source": [
        "#### Girar uma imagem\n",
        "\n",
        "Gire um imagem em 90 graus com `tf.image.rot90`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b19KuAhkJKR-"
      },
      "outputs": [],
      "source": [
        "rotated = tf.image.rot90(image)\n",
        "visualize(image, rotated)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CPP0vEKB56X"
      },
      "source": [
        "### Transformações aleatórias\n",
        "\n",
        "Atenção: há dois conjuntos de operações aleatórias de imagens: `tf.image.random*` e `tf.image.stateless_random*`. É altamente desaconselhável usar as operações de `tf.image.random*`, pois elas usam os RNGs antigos do TF 1.x. Em vez disso, use as operações aleatórias de imagens apresentadas neste tutorial. Confira mais informações em [Geração de números aleatórios](../../guide/random_numbers.ipynb).\n",
        "\n",
        "A aplicação de transformações aleatórias às imagens pode generalizar e expandir o dataset ainda mais. A API `tf.image` atual fornece oito operações aleatórias de imagens (também chamadas de ops):\n",
        "\n",
        "- [`tf.image.stateless_random_brightness`](https://www.tensorflow.org/api_docs/python/tf/image/stateless_random_brightness)\n",
        "- [`tf.image.stateless_random_contrast`](https://www.tensorflow.org/api_docs/python/tf/image/stateless_random_contrast)\n",
        "- [`tf.image.stateless_random_crop`](https://www.tensorflow.org/api_docs/python/tf/image/stateless_random_crop)\n",
        "- [`tf.image.stateless_random_flip_left_right`](https://www.tensorflow.org/api_docs/python/tf/image/stateless_random_flip_left_right)\n",
        "- [`tf.image.stateless_random_flip_up_down`](https://www.tensorflow.org/api_docs/python/tf/image/stateless_random_flip_up_down)\n",
        "- [`tf.image.stateless_random_hue`](https://www.tensorflow.org/api_docs/python/tf/image/stateless_random_hue)\n",
        "- [`tf.image.stateless_random_jpeg_quality`](https://www.tensorflow.org/api_docs/python/tf/image/stateless_random_jpeg_quality)\n",
        "- [`tf.image.stateless_random_saturation`](https://www.tensorflow.org/api_docs/python/tf/image/stateless_random_saturation)\n",
        "\n",
        "Essas operações aleatórias de imagens são puramente funcionais: a saída depende somente da entrada, o que simplifica seu uso em pipelines de entrada determinísticos de alto desempenho. Elas requerem que um valor de `seed` (semente) seja a entrada em cada passo. Dada a mesma `seed`, elas retornam os mesmos resultados, não importa quantas vezes sejam chamadas.\n",
        "\n",
        "Observação: `seed` é um `Tensor` de tamanho `(2,)` cujos valores são números inteiros.\n",
        "\n",
        "Nas próximas seções, você:\n",
        "\n",
        "1. Verá exemplos de como usar operações aleatórias de imagens para transformar uma imagem.\n",
        "2. Demonstrará como aplicar transformações aleatórias a um dataset de treinamento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "251Wy-MqE4La"
      },
      "source": [
        "#### Alterar o brilho da imagem aleatoriamente\n",
        "\n",
        "Altere o brilho da `image` aleatoriamente usando `tf.image.stateless_random_brightness` ao fornecer um fator de brilho e uma `seed`. O fator de brilho é escolhido aleatoriamente no intervalo `[-max_delta, max_delta)` e está associado à `seed` fornecida."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-fFd1kh7Fr-_"
      },
      "outputs": [],
      "source": [
        "for i in range(3):\n",
        "  seed = (i, 0)  # tuple of size (2,)\n",
        "  stateless_random_brightness = tf.image.stateless_random_brightness(\n",
        "      image, max_delta=0.95, seed=seed)\n",
        "  visualize(image, stateless_random_brightness)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLaDEmooUfYJ"
      },
      "source": [
        "#### Alterar o contraste da imagem aleatoriamente\n",
        "\n",
        "Altere o contraste da `image` aleatoriamente usando `tf.image.stateless_random_contrast` ao fornecer um fator de contraste e uma `seed`. O fator de contraste é escolhido aleatoriamente no intervalo `[lower, upper]` e está associado à `seed` fornecida."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GmcYoQHaUoke"
      },
      "outputs": [],
      "source": [
        "for i in range(3):\n",
        "  seed = (i, 0)  # tuple of size (2,)\n",
        "  stateless_random_contrast = tf.image.stateless_random_contrast(\n",
        "      image, lower=0.1, upper=0.9, seed=seed)\n",
        "  visualize(image, stateless_random_contrast)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxb-MP-KVPNz"
      },
      "source": [
        "#### Recortar uma imagem aleatoriamente\n",
        "\n",
        "Recorte uma `image` aleatoriamente usando `tf.image.stateless_random_crop` ao fornecer o `size` (tamanho) e a `seed` (semente) alvos. A parte da `image` recortada tem um deslocamento escolhido aleatoriamente e está associada à `seed` fornecida."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vtZQbUw0VOm5"
      },
      "outputs": [],
      "source": [
        "for i in range(3):\n",
        "  seed = (i, 0)  # tuple of size (2,)\n",
        "  stateless_random_crop = tf.image.stateless_random_crop(\n",
        "      image, size=[210, 300, 3], seed=seed)\n",
        "  visualize(image, stateless_random_crop)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "isrM-MZtpxTq"
      },
      "source": [
        "### Aplicar ampliação a um dataset\n",
        "\n",
        "Primeiro, vamos baixar o dataset de imagens novamente caso tenha sido modificado nas seções anteriores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xC80NQP809Uo"
      },
      "outputs": [],
      "source": [
        "(train_datasets, val_ds, test_ds), metadata = tfds.load(\n",
        "    'tf_flowers',\n",
        "    split=['train[:80%]', 'train[80%:90%]', 'train[90%:]'],\n",
        "    with_info=True,\n",
        "    as_supervised=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMo9HTDV0Gaz"
      },
      "source": [
        "Agora, defina uma função utilitária para redimensionar e reescalonar as imagens. Essa função será usada para unificar o tamanho e a escala das imagens no dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1JKmx06lfcFr"
      },
      "outputs": [],
      "source": [
        "def resize_and_rescale(image, label):\n",
        "  image = tf.cast(image, tf.float32)\n",
        "  image = tf.image.resize(image, [IMG_SIZE, IMG_SIZE])\n",
        "  image = (image / 255.0)\n",
        "  return image, label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7OpE_-jWq-I"
      },
      "source": [
        "Também vamos definir a função `augment`, que pode aplicar as transformações aleatórias às imagens. Esta função será usada no dataset no próximo passo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KitLdvlpVxPa"
      },
      "outputs": [],
      "source": [
        "def augment(image_label, seed):\n",
        "  image, label = image_label\n",
        "  image, label = resize_and_rescale(image, label)\n",
        "  image = tf.image.resize_with_crop_or_pad(image, IMG_SIZE + 6, IMG_SIZE + 6)\n",
        "  # Make a new seed.\n",
        "  new_seed = tf.random.split(seed, num=1)[0, :]\n",
        "  # Random crop back to the original size.\n",
        "  image = tf.image.stateless_random_crop(\n",
        "      image, size=[IMG_SIZE, IMG_SIZE, 3], seed=seed)\n",
        "  # Random brightness.\n",
        "  image = tf.image.stateless_random_brightness(\n",
        "      image, max_delta=0.5, seed=new_seed)\n",
        "  image = tf.clip_by_value(image, 0, 1)\n",
        "  return image, label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SlXRsVp70hg8"
      },
      "source": [
        "#### Opção 1: usando tf.data.experimental.Counter\n",
        "\n",
        "Crie um objeto `tf.data.experimental.Counter` (vamos chamá-lo de `counter`) (contador) e compacte (`Dataset.zip`) o conjunto com `(counter, counter)`. Isso garantirá que cada imagem do dataset seja associada a um valor único (de formato `(2,)`) com base no `counter`, que depois poderá ser passado para a função `augment` como o valor de `seed` para transformações aleatórias."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SZ6Qq0IWznfi"
      },
      "outputs": [],
      "source": [
        "# Create a `Counter` object and `Dataset.zip` it together with the training set.\n",
        "counter = tf.data.experimental.Counter()\n",
        "train_ds = tf.data.Dataset.zip((train_datasets, (counter, counter)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eF9ybVQ94X9f"
      },
      "source": [
        "Mapeie a função `augment` para o dataset de treinamento:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wQK9BDKk1_3N"
      },
      "outputs": [],
      "source": [
        "train_ds = (\n",
        "    train_ds\n",
        "    .shuffle(1000)\n",
        "    .map(augment, num_parallel_calls=AUTOTUNE)\n",
        "    .batch(batch_size)\n",
        "    .prefetch(AUTOTUNE)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3AQoyA-k3ELk"
      },
      "outputs": [],
      "source": [
        "val_ds = (\n",
        "    val_ds\n",
        "    .map(resize_and_rescale, num_parallel_calls=AUTOTUNE)\n",
        "    .batch(batch_size)\n",
        "    .prefetch(AUTOTUNE)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p2IQN3NN3G_M"
      },
      "outputs": [],
      "source": [
        "test_ds = (\n",
        "    test_ds\n",
        "    .map(resize_and_rescale, num_parallel_calls=AUTOTUNE)\n",
        "    .batch(batch_size)\n",
        "    .prefetch(AUTOTUNE)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pvTVY8BY2LpD"
      },
      "source": [
        "#### Opção 2: usando tf.random.Generator\n",
        "\n",
        "- Crie um objeto `tf.random.Generator` com um valor inicial de `seed`. Ao chamar a função `make_seeds` no mesmo objeto gerador, sempre será retornado um novo valor de `seed` único.\n",
        "- Defina uma função de encapsulamento que: 1) chame a função `make_seeds`; e 2) passe o valor de `seed` recém-gerado para a função `augment` para que sejam feitas transformações aleatórias.\n",
        "\n",
        "Observação: objetos `tf.random.Generator` armazenam o estado RNG em um `tf.Variable` e, portanto, ele pode ser salvo como um [checkpoint](../../guide/checkpoint.ipynb) ou em um [SavedModel](../../guide/saved_model.ipynb). Confira mais detalhes em [Geração de números aleatórios](../../guide/random_numbers.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BQDvedZ33eAy"
      },
      "outputs": [],
      "source": [
        "# Create a generator.\n",
        "rng = tf.random.Generator.from_seed(123, alg='philox')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eDEkO1nt2ta0"
      },
      "outputs": [],
      "source": [
        "# Create a wrapper function for updating seeds.\n",
        "def f(x, y):\n",
        "  seed = rng.make_seeds(2)[0]\n",
        "  image, label = augment((x, y), seed)\n",
        "  return image, label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PyPC4vUM4MT0"
      },
      "source": [
        "Mapeie a função de encapsulamento `f` para o dataset de treinamento, e a função `resize_and_rescale` para os conjuntos de validação e teste."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pu2uB7k12xKw"
      },
      "outputs": [],
      "source": [
        "train_ds = (\n",
        "    train_datasets\n",
        "    .shuffle(1000)\n",
        "    .map(f, num_parallel_calls=AUTOTUNE)\n",
        "    .batch(batch_size)\n",
        "    .prefetch(AUTOTUNE)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e6caldPi2HAP"
      },
      "outputs": [],
      "source": [
        "val_ds = (\n",
        "    val_ds\n",
        "    .map(resize_and_rescale, num_parallel_calls=AUTOTUNE)\n",
        "    .batch(batch_size)\n",
        "    .prefetch(AUTOTUNE)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ceaCdJnh2I-r"
      },
      "outputs": [],
      "source": [
        "test_ds = (\n",
        "    test_ds\n",
        "    .map(resize_and_rescale, num_parallel_calls=AUTOTUNE)\n",
        "    .batch(batch_size)\n",
        "    .prefetch(AUTOTUNE)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKwCA6AOjTrc"
      },
      "source": [
        "Agora, esses datasets podem ser usados para treinar um modelo conforme mostrado anteriormente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YypDihDlj0no"
      },
      "source": [
        "## Próximos passos\n",
        "\n",
        "Este tutorial demonstrou a ampliação de dados usando as camadas de pré-processamento do Keras e `tf.image`.\n",
        "\n",
        "- Para ver como incluir camadas de pré-processamento dentro do seu modelo, confira o tutorial [Classificação de imagens](classification.ipynb).\n",
        "- Se tiver interesse em aprender como as camadas de pré-processamento podem ajudar a classificar o texto, confira o tutorial [Classificação básica de texto](../keras/text_classification.ipynb).\n",
        "- Saiba mais sobre o `tf.data` neste [guia](../../guide/data.ipynb) e veja como configurar seus pipelines de entrada para melhor desempenho [aqui](../../guide/data_performance.ipynb)."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "data_augmentation.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
