{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rA5Mubike7OJ"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "fY0a3LRYfHUl"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNz7xXMSsAQa"
      },
      "source": [
        "# Treinamento de servidor de parâmetros com ParameterServerStrategy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHyqRIqxsJuc"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>     <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/distribute/parameter_server_training\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver em TensorFlow.org</a> </td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/pt-br/tutorials/distribute/parameter_server_training.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Executar no Google Colab</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/pt-br/tutorials/distribute/parameter_server_training.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver fonte no GitHub</a>\n",
        "</td>\n",
        "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/pt-br/tutorials/distribute/parameter_server_training.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Baixar notebook</a>\n",
        "</td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6v4D6QfcfTrm"
      },
      "source": [
        "## Visão geral\n",
        "\n",
        "O [treinamento de servidor de parâmetros](https://www.usenix.org/system/files/conference/osdi14/osdi14-paper-li_mu.pdf) é um método de Paralelo de Dados comum para fazer o treinamento de modelos em diversas máquinas.\n",
        "\n",
        "Um cluster de treinamento de servidor de parâmetros é composto por *workers* e *servidores de parâmetros*. As variáveis são criadas nos servidores de parâmetros e são lidas e atualizadas pelos workers em cada passo. Por padrão, os workers leem e atualizam essas variáveis de forma independente, sem sincronizá-las entre si. É por isso que o treinamento de servidor de parâmetros às vezes é chamado de <em>treinamento assíncrono</em>.\n",
        "\n",
        "No TensorFlow 2, o treinamento de servidor de parâmetros é possibilitado pela classe `tf.distribute.ParameterServerStrategy`, que distribui os passos de treinamento em um cluster que pode ter até milhares de workers (acompanhados por servidores de parâmetros)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1LGfTdgOF-J"
      },
      "source": [
        "### Métodos de treinamento disponíveis\n",
        "\n",
        "Há dois métodos de treinamento principais disponíveis:\n",
        "\n",
        "- API `Model.fit` do Keras: se você preferir uma abstração e tratamento do treinamento de alto nível. Geralmente, esse é o método recomendado se você estiver treinando um `tf.keras.Model`.\n",
        "- Loop de treinamento personalizado: se você preferir definir os detalhes do loop de treinamento (confira mais detalhes nos guias [Treinamento personalizado](../customization/custom_training_walkthrough.ipynb), [Como escrever um loop de treinamento do zero](https://www.tensorflow.org/guide/keras/writing_a_training_loop_from_scratch) e [Loop de treinamento personalizado com o Keras e MultiWorkerMirroredStrategy](multi_worker_with_ctl.ipynb))."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FjbULGvV7NRz"
      },
      "source": [
        "### Cluster com trabalhos e tarefas\n",
        "\n",
        "Não importa a API escolhida (`Model.fit` ou loop de treinamento personalizado), o treinamento distribuído no TensorFlow 2 envolve um `'cluster'` com diversos `'jobs'` (trabalhos), e cada trabalho pode ter uma ou mais `'task'`s (tarefas).\n",
        "\n",
        "Ao usar o treinamento de servidor de parâmetros, recomenda-se ter:\n",
        "\n",
        "- Um trabalho *coordenador* (que tem o nome `chief`)\n",
        "- Diversos trabalhos *worker* (com nome `worker`)\n",
        "- Diversos trabalhos *servidor de parâmetros* (com nome <code>ps</code>)\n",
        "\n",
        "O *coordenador* cria recursos, envia tarefas de treinamento, escreve checkpoints e lida com as falhas das tarefas. Os *workers* e *servidores de parâmetros* executam instâncias de `tf.distribute.Server`, que escutam solicitações do coordenador."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLV1FbpLtqtB"
      },
      "source": [
        "### Treinamento de servidor de parâmetros com a API `Model.fit`\n",
        "\n",
        "O treinamento de servidor de parâmetros com a API `Model.fit` requer que o coordenador use um objeto `tf.distribute.ParameterServerStrategy`. Similar ao uso de `Model.fit` sem estratégia ou com outras estratégias, o fluxo de trabalho inclui criar e compilar o modelo, preparar os callbacks e fazer uma chamada a `Model.fit`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJ5AosxFyfzk"
      },
      "source": [
        "### Treinamento de servidor de parâmetros com um loop de treinamento personalizado\n",
        "\n",
        "Com loops de treinamento personalizado, a classe `tf.distribute.coordinator.ClusterCoordinator` é o componente essencial usado para o coordenador.\n",
        "\n",
        "- A classe `ClusterCoordinator` precisa funcionar em conjunto com um objeto `tf.distribute.ParameterServerStrategy`.\n",
        "- O objeto `tf.distribute.Strategy` é necessário para fornecer as informações do cluster e é usado para definir um passo de treinamento, conforme demonstrado em [Treinamento personalizado com tf.distribute.Strategy](custom_training.ipynb).\n",
        "- Então, o objeto `ClusterCoordinator` envia a execução desses passos de treinamento para os workers remotos.\n",
        "\n",
        "A API mais importante fornecida pelo objeto `ClusterCoordinator` é `schedule`:\n",
        "\n",
        "- A API `schedule` enfileira uma `tf.function` e retorna um `RemoteValue` com previsão futura imediatamente.\n",
        "- As funções enfileiradas serão enviadas para workers remotos em threads em segundo plano, e seus `RemoteValue`s serão preenchidos de forma assíncrona.\n",
        "- Como `schedule` não requer atribuição de workers, a `tf.function` passada pode ser executada em qualquer worker.\n",
        "- Se o worker no qual ele é executado ficar indisponível antes da conclusão, a função será refeita em outro worker disponível.\n",
        "- Devido a isso e ao fato de a execução de função não ser atômica, uma mesma chamada à função pode ser executada mais de uma vez.\n",
        "\n",
        "Além de enviar mais funções remotas, o `ClusterCoordinator` também ajuda a criar datasets em todos os workers e a reconstruir esses datasets quando um worker se recupera após uma falha."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MyDnWjmOje5-"
      },
      "source": [
        "## Organização do tutorial\n",
        "\n",
        "Este tutorial será dividido em dois caminhos, `Model.fit` e loop de treinamento personalizado, e você pode escolher o mais adequado para suas particularidades. Seções que não comecem com \"Treinamento com X\" são aplicáveis aos dois caminhos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0-V3LUcIs4a-"
      },
      "outputs": [],
      "source": [
        "!pip install portpicker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GlI_NAVFae3J"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "import multiprocessing\n",
        "import os\n",
        "import random\n",
        "import portpicker\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvwgM2rzgzIC"
      },
      "source": [
        "## Configuração do cluster\n",
        "\n",
        "Conforme mencionado acima, um cluster de treinamento de servidor de parâmetros requer uma tarefa coordenadora que execute seu programa de treinamento, um ou vários workers e tarefas de servidor de parâmetros que executem servidores do TensorFlow, `tf.distribute.Server`, e possivelmente uma tarefa de avaliação adicional que execute uma avaliação secundária (confira a seção [Avaliação secundária](#sidecar_evaluation) abaixo). Os requisitos para configurá-los são:\n",
        "\n",
        "- A tarefa coordenadora precisa saber os endereços e portas de todos os outros servidores do TensorFlow, exceto do avaliador.\n",
        "- Os workers e servidores de parâmetros precisam saber qual porta devem escutar. Por questões de simplicidade, geralmente você pode passar as informações completas do cluster ao criar servidores do TensorFlow nessas tarefas.\n",
        "- A tarefa de avaliação não precisa saber a configuração do cluster de treinamento. Caso saiba, ela não deve tentar estabelecer conexão com o cluster do treinamento.\n",
        "- Os workers e servidores de parâmetros devem ter os tipos de tarefa `\"worker\"` e `\"ps\"`, respectivamente. O coordenador deve usar `\"chief\"` como o tipo de tarefa por questões de compatibilidade legada.\n",
        "\n",
        "Neste tutorial, você criará um cluster dentro do processo para que o todo o treinamento de servidor de parâmetros possa ser executado no Colab. Você aprenderá a configurar [clusters reais](#real_clusters) em uma seção posterior."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7UNs7Lm2g19n"
      },
      "source": [
        "### Cluster dentro do processo\n",
        "\n",
        "Você começará criando vários servidores do TensorFlow antecipadamente e estabelecerá conexão com eles posteriormente. Isso é feito apenas para fins de demonstração neste tutorial. Em treinamentos reais, os servidores serão iniciados nas máquinas `\"worker\"` e `\"ps\"`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FbrP5pXuaoVH"
      },
      "outputs": [],
      "source": [
        "def create_in_process_cluster(num_workers, num_ps):\n",
        "  \"\"\"Creates and starts local servers and returns the cluster_resolver.\"\"\"\n",
        "  worker_ports = [portpicker.pick_unused_port() for _ in range(num_workers)]\n",
        "  ps_ports = [portpicker.pick_unused_port() for _ in range(num_ps)]\n",
        "\n",
        "  cluster_dict = {}\n",
        "  cluster_dict[\"worker\"] = [\"localhost:%s\" % port for port in worker_ports]\n",
        "  if num_ps > 0:\n",
        "    cluster_dict[\"ps\"] = [\"localhost:%s\" % port for port in ps_ports]\n",
        "\n",
        "  cluster_spec = tf.train.ClusterSpec(cluster_dict)\n",
        "\n",
        "  # Workers need some inter_ops threads to work properly.\n",
        "  worker_config = tf.compat.v1.ConfigProto()\n",
        "  if multiprocessing.cpu_count() < num_workers + 1:\n",
        "    worker_config.inter_op_parallelism_threads = num_workers + 1\n",
        "\n",
        "  for i in range(num_workers):\n",
        "    tf.distribute.Server(\n",
        "        cluster_spec,\n",
        "        job_name=\"worker\",\n",
        "        task_index=i,\n",
        "        config=worker_config,\n",
        "        protocol=\"grpc\")\n",
        "\n",
        "  for i in range(num_ps):\n",
        "    tf.distribute.Server(\n",
        "        cluster_spec,\n",
        "        job_name=\"ps\",\n",
        "        task_index=i,\n",
        "        protocol=\"grpc\")\n",
        "\n",
        "  cluster_resolver = tf.distribute.cluster_resolver.SimpleClusterResolver(\n",
        "      cluster_spec, rpc_layer=\"grpc\")\n",
        "  return cluster_resolver\n",
        "\n",
        "# Set the environment variable to allow reporting worker and ps failure to the\n",
        "# coordinator. This is a workaround and won't be necessary in the future.\n",
        "os.environ[\"GRPC_FAIL_FAST\"] = \"use_caller\"\n",
        "\n",
        "NUM_WORKERS = 3\n",
        "NUM_PS = 2\n",
        "cluster_resolver = create_in_process_cluster(NUM_WORKERS, NUM_PS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pX_91OByt0J2"
      },
      "source": [
        "A configuração do cluster dentro do processo é usada com frequência no teste de unidade, como [aqui](https://github.com/tensorflow/tensorflow/blob/eb4c40fc91da260199fa2aed6fe67d36ad49fafd/tensorflow/python/distribute/coordinator/cluster_coordinator_test.py#L447).\n",
        "\n",
        "Outra opção para testes locais é iniciar processos na máquina local. Confira um exemplo dessa estratégia no guia [Treinamento multiworker com o Keras](multi_worker_with_keras.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyby6M2Jqg6J"
      },
      "source": [
        "## Criação de instância de ParameterServerStrategy\n",
        "\n",
        "Antes de você conferir todo o código de treinamento, vamos instanciar um objeto de `tf.distribute.ParameterServerStrategy`. Isso é necessário tanto para o caso do `Model.fit` quanto do loop de treinamento personalizado. O argumento `variable_partitioner` será explicado na seção [Fragmentação de variável](#variable_sharding)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_YyEPgisrC35"
      },
      "outputs": [],
      "source": [
        "variable_partitioner = (\n",
        "    tf.distribute.experimental.partitioners.MinSizePartitioner(\n",
        "        min_shard_bytes=(256 << 10),\n",
        "        max_shards=NUM_PS))\n",
        "\n",
        "strategy = tf.distribute.ParameterServerStrategy(\n",
        "    cluster_resolver,\n",
        "    variable_partitioner=variable_partitioner)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlAQxuMDJ3k9"
      },
      "source": [
        "Para usar as GPUs para treinamento, aloque GPUs visíveis a cada worker. `ParameterServerStrategy` usará todas as GPUs disponíveis em cada worker, com a restrição de que todos os workers devem ter o mesmo número de GPUs disponíveis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMmBLsf6sEXh"
      },
      "source": [
        "### Fragmentação de variável\n",
        "\n",
        "Fragmentação variável refere-se a dividir uma variável em diversas variáveis menores, chamadas de *fragmentos*. A fragmentação de variável pode ser útil para distribuir a carga da rede ao acessar esses fragmentos. Também é útil para distribuir computação e armazenamento de uma variável normal em diversos servidores de parâmetros ao, por exemplo, usar embeddings muito grandes que possam não caber na memória de uma única máquina.\n",
        "\n",
        "Para ativar a fragmentação de variável, você pode passar `variable_partitioner` ao construir um objeto `ParameterServerStrategy`. `variable_partitioner` será chamado toda vez em que uma variável for criada e deve retornar o número de fragmentos em cada dimensão da variável. Alguns `variable_partitioner`s prontos para uso são fornecidos, como `tf.distribute.experimental.partitioners.MinSizePartitioner`. Recomenda-se usar particionadores baseados em tamanho, como `tf.distribute.experimental.partitioners.MinSizePartitioner`, para evitar particionar variáveis pequenas, o que poderia causar um impacto negativo na velocidade de treinamento do modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1--SxlxtsOb7"
      },
      "source": [
        "Quando um `variable_partitioner` é passado e você criar uma variável diretamente dentro de `Strategy.scope`, a variável se tornará um tipo container com uma propriedade `variables`, que fornece acesso à lista de fragmentos. Na maioria dos casos, esse container será convertido automaticamente em um Tensor concatenando-se todos os fragmentos. Como consequência, ele pode ser usado como uma variável normal. Por outro lado, alguns métodos do TensorFlow, como `tf.nn.embedding_lookup`, oferecem uma implementação eficiente para esse tipo container e, nesses métodos, a concatenação automática será evitada.\n",
        "\n",
        "Confira mais detalhes nos documentos da API de `tf.distribute.ParameterServerStrategy`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlOq-O-26O1d"
      },
      "source": [
        "## Treinamento com `Model.fit`\n",
        "\n",
        "<a id=\"training_with_modelfit\"></a>\n",
        "\n",
        "O Keras oferece uma API de treinamento fácil de usar por meio do `Model.fit` que trata o loop de treinamento em segundo plano, com a flexibilidade de um `train_step` que pode ser sobrescrito e callbacks, que oferecem funcionalidades como salvamento de checkpoints ou salvamento de resumos para o TensorBoard. Com o `Model.fit`, o mesmo código de treinamento pode ser usado com outras estratégias com uma troca simples do objeto de estratégia."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMZ9Cu5J6ZGi"
      },
      "source": [
        "### Dados de entrada\n",
        "\n",
        "O `Model.fit` do Keras com `tf.distribute.ParameterServerStrategy` aceita dados de entrada na forma de um `tf.data.Dataset`, `tf.distribute.DistributedDataset` ou `tf.keras.utils.experimental.DatasetCreator`, sendo que `Dataset` é a opção recomendada pela facilidade de uso. Porém, se você tiver problemas de memória ao usar `Dataset`, talvez precise usar `DatasetCreator` com um argumento `dataset_fn` que pode ser chamado (confira mais detalhes na documentação da API de `tf.keras.utils.experimental.DatasetCreator`).\n",
        "\n",
        "Se você transformar seu dataset em um `tf.data.Dataset`, deve usar `Dataset.shuffle` e `Dataset.repeat`, conforme demonstrado no exemplo de código abaixo.\n",
        "\n",
        "- O `Model.fit` do Keras com o treinamento de servidor de parâmetros pressupõe que cada worker recebe o mesmo dataset, exceto quando ele é misturado de forma diferente. Portanto, ao fazer uma chamada a `Dataset.shuffle`, você garante ainda mais iterações dos dados.\n",
        "- Como os workers não sincronizam, eles podem terminar o processamento dos datasets em momentos diferentes. Dessa forma, a maneira mais fácil de definir épocas para o treinamento de servidor de parâmetros é usando `Dataset.repeat` – que repete um dataset indefinidamente quando a chamada é feita sem um argumento – e especificando o argumento `steps_per_epoch` na chamada a `Model.fit`.\n",
        "\n",
        "Consulte a seção \"Treinamento dos fluxos de trabalho\" do [guia do tf.data](../../guide/data.ipynb) para ver mais detalhes de `shuffle` e `repeat`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "shAo1CCS7wU1"
      },
      "outputs": [],
      "source": [
        "global_batch_size = 64\n",
        "\n",
        "x = tf.random.uniform((10, 10))\n",
        "y = tf.random.uniform((10,))\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((x, y)).shuffle(10).repeat()\n",
        "dataset = dataset.batch(global_batch_size)\n",
        "dataset = dataset.prefetch(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_jhF70K7zON"
      },
      "source": [
        "Se você criar o dataset com `tf.keras.utils.experimental.DatasetCreator`, o código em `dataset_fn` será chamado no dispositivo de entrada, que geralmente é a CPU, em cada uma das máquinas de worker.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w60PuWrWwBD4"
      },
      "source": [
        "### Construção e compilação do modelo\n",
        "\n",
        "Agora, você criará um `tf.keras.Model` – um modelo `tf.keras.models.Sequential` trivial para fins de demonstração – seguido por uma chamada `Model.compile` para incorporar componentes, como um otimizador, métricas e outros parâmetros, como `steps_per_execution`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PhTHUYaD74vT"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "  model = tf.keras.models.Sequential([tf.keras.layers.Dense(10)])\n",
        "\n",
        "  model.compile(tf.keras.optimizers.legacy.SGD(), loss=\"mse\", steps_per_execution=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWb_Ekm377YX"
      },
      "source": [
        "### Callbacks e treinamento\n",
        "\n",
        "<a id=\"callbacks-and-training\"> </a>\n",
        "\n",
        "Antes de fazer uma chamada a `Model.fit` do Keras para o treinamento real, prepare todos os [callbacks](https://www.tensorflow.org/guide/keras/train_and_evaluate) necessários para tarefas comuns, como:\n",
        "\n",
        "- `tf.keras.callbacks.ModelCheckpoint`: salva o modelo com uma determinada frequência, como após cada época.\n",
        "- `tf.keras.callbacks.BackupAndRestore`: faz backup do modelo e do número da época atual para proporcionar tolerância a falhas, se o cluster passar por uma indisponibilidade (como anulamento e interrupção). Então, você pode restaurar o estado de treinamento ao reiniciar após a falha de um trabalho e continuar o treinamento pelo começo da época interrompida.\n",
        "- `tf.keras.callbacks.TensorBoard`: escreve periodicamente logs do modelo em arquivos de resumo que podem ser visualizados na ferramenta TensorBoard.\n",
        "\n",
        "Observação: por questões de desempenho, callbacks personalizados não podem ter os callbacks no nível de lote sobrescritos quando usados com `ParameterServerStrategy`. Modifique seus callbacks personalizados para que sejam chamados no nível de época e ajuste `steps_per_epoch` para um valor adequado. Além disso, `steps_per_epoch` é um argumento necessário para `Model.fit` quando usado com `ParameterServerStrategy`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ddUvUZk7_wm"
      },
      "outputs": [],
      "source": [
        "working_dir = \"/tmp/my_working_dir\"\n",
        "log_dir = os.path.join(working_dir, \"log\")\n",
        "ckpt_filepath = os.path.join(working_dir, \"ckpt\")\n",
        "backup_dir = os.path.join(working_dir, \"backup\")\n",
        "\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.TensorBoard(log_dir=log_dir),\n",
        "    tf.keras.callbacks.ModelCheckpoint(filepath=ckpt_filepath),\n",
        "    tf.keras.callbacks.BackupAndRestore(backup_dir=backup_dir),\n",
        "]\n",
        "\n",
        "model.fit(dataset, epochs=5, steps_per_epoch=20, callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWgP1h2z8B3j"
      },
      "source": [
        "### Uso direto com `ClusterCoordinator` (opcional)\n",
        "\n",
        "Mesmo se você optar pelo caminho de treinamento com `Model.fit`, pode, opcionalmente, instanciar um objeto `tf.distribute.coordinator.ClusterCoordinator` para agendar outras funções que você deseja executar nos workers. Confira a seção [Treinamento com um loop de treinamento personalizado](#training_with_custom_training_loop) para ver mais detalhes e exemplos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxypEyIthR0z"
      },
      "source": [
        "## Treinamento com um loop de treinamento personalizado\n",
        "\n",
        "<a id=\"training_with_custom_training_loop\"> </a>\n",
        "\n",
        "O uso de loops de treinamento personalizado com `tf.distribute.Strategy` proporciona excelente flexibilidade para definir os loops de treinamento. Com o `ParameterServerStrategy` definido acima (como `strategy`), você usará um `tf.distribute.coordinator.ClusterCoordinator` para enviar a execução dos passos de treinamento para os workers remotos.\n",
        "\n",
        "Em seguida, você criará um modelo, definirá um dataset e definirá uma função de passos da mesma forma que no loop de treinamento com outros `tf.distribute.Strategy`s. Confira mais detalhes no tutorial [Treinamento personalizado com tf.distribute.Strategy](custom_training.ipynb).\n",
        "\n",
        "Para garantir uma pré-busca eficiente do dataset, use as APIs de criação de dataset distribuído recomendadas na seção [Envio dos passos de treinamento para os workers remotos](#dispatch_training_steps_to_remote_workers) abaixo. Além disso, faça uma chamada a `Strategy.run` dentro de `worker_fn` para usar ao máximo as GPUs alocadas aos workers. As outras etapas são as mesmas para treinamento com ou sem GPUs.\n",
        "\n",
        "Vamos criar esses componentes nos seguintes passos:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QNkCtV8VivM"
      },
      "source": [
        "### Configuração dos dados\n",
        "\n",
        "Primeiro, escreva uma função que crie um dataset.\n",
        "\n",
        "Se você quiser pré-processar os dados com as [camadas de pré-processamento do Keras](https://www.tensorflow.org/guide/keras/preprocessing_layers) ou com as [ camadas do TensorFlow Transform](https://www.tensorflow.org/tfx/tutorials/transform/simple), crie essas camadas **fora de `dataset_fn`** e **dentro de `Strategy.scope`**, como faria para qualquer outra camada do Keras. Isso é necessário porque `dataset_fn` será encapsulado em uma função `tf.function` e depois executado em cada worker para gerar o pipeline de dados.\n",
        "\n",
        "Se você não seguir o procedimento acima, a criação das camadas poderá criar estados do TensorFlow que serão levados da `tf.function` para o coordenador. Dessa forma, acessá-las nos workers poderia ocasionar chamadas RPC repetitivas entre o coordenador e os workers, causando uma lentidão considerável.\n",
        "\n",
        "Ao colocar as camadas dentro de `Strategy.scope`, elas serão criadas em todos os workers. Então, você aplicará a transformação dentro de `dataset_fn` por meio de `tf.data.Dataset.map`. Confira *Pré-processamento de dados* no tutorial [Entrada distribuída](input.ipynb) para ver mais informações sobre pré-processamento de dados com entrada distribuída."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2GUwATssauus"
      },
      "outputs": [],
      "source": [
        "feature_vocab = [\n",
        "    \"avenger\", \"ironman\", \"batman\", \"hulk\", \"spiderman\", \"kingkong\", \"wonder_woman\"\n",
        "]\n",
        "label_vocab = [\"yes\", \"no\"]\n",
        "\n",
        "with strategy.scope():\n",
        "  feature_lookup_layer = tf.keras.layers.StringLookup(\n",
        "      vocabulary=feature_vocab,\n",
        "      mask_token=None)\n",
        "  label_lookup_layer = tf.keras.layers.StringLookup(\n",
        "      vocabulary=label_vocab,\n",
        "      num_oov_indices=0,\n",
        "      mask_token=None)\n",
        "\n",
        "  raw_feature_input = tf.keras.layers.Input(\n",
        "      shape=(3,),\n",
        "      dtype=tf.string,\n",
        "      name=\"feature\")\n",
        "  feature_id_input = feature_lookup_layer(raw_feature_input)\n",
        "  feature_preprocess_stage = tf.keras.Model(\n",
        "      {\"features\": raw_feature_input},\n",
        "      feature_id_input)\n",
        "\n",
        "  raw_label_input = tf.keras.layers.Input(\n",
        "      shape=(1,),\n",
        "      dtype=tf.string,\n",
        "      name=\"label\")\n",
        "  label_id_input = label_lookup_layer(raw_label_input)\n",
        "\n",
        "  label_preprocess_stage = tf.keras.Model(\n",
        "      {\"label\": raw_label_input},\n",
        "      label_id_input)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jgp8MX_7OR_A"
      },
      "source": [
        "Gere exemplos em um dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "chIY4fFANaFH"
      },
      "outputs": [],
      "source": [
        "def feature_and_label_gen(num_examples=200):\n",
        "  examples = {\"features\": [], \"label\": []}\n",
        "  for _ in range(num_examples):\n",
        "    features = random.sample(feature_vocab, 3)\n",
        "    label = [\"yes\"] if \"avenger\" in features else [\"no\"]\n",
        "    examples[\"features\"].append(features)\n",
        "    examples[\"label\"].append(label)\n",
        "  return examples\n",
        "\n",
        "examples = feature_and_label_gen()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AtZBya7OeyZ"
      },
      "source": [
        "Depois, crie o dataset de treinamento encapsulado em um `dataset_fn`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gs0QYRZoNbvw"
      },
      "outputs": [],
      "source": [
        "def dataset_fn(_):\n",
        "  raw_dataset = tf.data.Dataset.from_tensor_slices(examples)\n",
        "\n",
        "  train_dataset = raw_dataset.map(\n",
        "      lambda x: (\n",
        "          {\"features\": feature_preprocess_stage(x[\"features\"])},\n",
        "          label_preprocess_stage(x[\"label\"])\n",
        "      )).shuffle(200).batch(32).repeat()\n",
        "  return train_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IT9PQexJiFtB"
      },
      "source": [
        "### Criação do modelo\n",
        "\n",
        "Agora, crie o modelo e outros objetos. Lembre-se de criar todas as variáveis dentro de `Strategy.scope`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Quxud1uEazeo"
      },
      "outputs": [],
      "source": [
        "# These variables created under the `Strategy.scope` will be placed on parameter\n",
        "# servers in a round-robin fashion.\n",
        "with strategy.scope():\n",
        "  # Create the model. The input needs to be compatible with Keras processing layers.\n",
        "  model_input = tf.keras.layers.Input(\n",
        "      shape=(3,), dtype=tf.int64, name=\"model_input\")\n",
        "\n",
        "  emb_layer = tf.keras.layers.Embedding(\n",
        "      input_dim=len(feature_lookup_layer.get_vocabulary()), output_dim=16384)\n",
        "  emb_output = tf.reduce_mean(emb_layer(model_input), axis=1)\n",
        "  dense_output = tf.keras.layers.Dense(\n",
        "      units=1, activation=\"sigmoid\",\n",
        "      kernel_regularizer=tf.keras.regularizers.L2(1e-4),\n",
        "  )(emb_output)\n",
        "  model = tf.keras.Model({\"features\": model_input}, dense_output)\n",
        "\n",
        "  optimizer = tf.keras.optimizers.legacy.RMSprop(learning_rate=0.1)\n",
        "  accuracy = tf.keras.metrics.Accuracy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iyuxiqCQU50m"
      },
      "source": [
        "Vamos confirmar que o uso de `FixedShardsPartitioner` divida todas as variáveis em dois fragmentos e que cada fragmento seja atribuído a um servidor de parâmetros diferente:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "04r1nO4WVDO1"
      },
      "outputs": [],
      "source": [
        "assert len(emb_layer.weights) == 2\n",
        "assert emb_layer.weights[0].shape == (4, 16384)\n",
        "assert emb_layer.weights[1].shape == (4, 16384)\n",
        "\n",
        "print(emb_layer.weights[0].device)\n",
        "print(emb_layer.weights[1].device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWhfXZLRiHyM"
      },
      "source": [
        "### Definição do passo de treinamento\n",
        "\n",
        "A terceira etapa é criar o passo de treinamento encapsulado em uma função `tf.function`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aNNVo0bFa1K9"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def step_fn(iterator):\n",
        "\n",
        "  def replica_fn(batch_data, labels):\n",
        "    with tf.GradientTape() as tape:\n",
        "      pred = model(batch_data, training=True)\n",
        "      per_example_loss = tf.keras.losses.BinaryCrossentropy(\n",
        "          reduction=tf.keras.losses.Reduction.NONE)(labels, pred)\n",
        "      loss = tf.nn.compute_average_loss(per_example_loss)\n",
        "      model_losses = model.losses\n",
        "      if model_losses:\n",
        "        loss += tf.nn.scale_regularization_loss(tf.add_n(model_losses))\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "    actual_pred = tf.cast(tf.greater(pred, 0.5), tf.int64)\n",
        "    accuracy.update_state(labels, actual_pred)\n",
        "    return loss\n",
        "\n",
        "  batch_data, labels = next(iterator)\n",
        "  losses = strategy.run(replica_fn, args=(batch_data, labels))\n",
        "  return strategy.reduce(tf.distribute.ReduceOp.SUM, losses, axis=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvrYQUeYiLNy"
      },
      "source": [
        "Na função de passo de treinamento acima, chamar `Strategy.run` e `Strategy.reduce` em `step_fn` pode oferecer suporte a múltiplas GPUs por worker. Se os workers tiverem GPUs alocadas, `Strategy.run` distribuirá os datasets em múltiplas réplicas (GPUs). Suas chamadas paralelas para `tf.nn.compute_average_loss()` computam a média da perda nas réplicas (GPUs) de um worker, independente do número total de workers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPJ3PV_L2zAY"
      },
      "source": [
        "### Envio dos passos de treinamento para os workers remotos\n",
        "\n",
        "<a id=\"dispatch_training_steps_to_remote_workers\"> </a>\n",
        "\n",
        "Após todas as computações serem definidas por `ParameterServerStrategy`, você usará a classe `tf.distribute.coordinator.ClusterCoordinator` para criar recursos e distribuir os passos de treinamento para os workers remotos.\n",
        "\n",
        "Primeiro, crie um objeto `ClusterCoordinator` e passe o objeto \"strategy\":"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DpcMlH7Pa3DB"
      },
      "outputs": [],
      "source": [
        "coordinator = tf.distribute.coordinator.ClusterCoordinator(strategy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xRIgKxciOSe"
      },
      "source": [
        "Depois, crie um dataset e um iterador por worker usando a API `ClusterCoordinator.create_per_worker_dataset`, que replica o dataset em todos os workers. Em `per_worker_dataset_fn` abaixo, recomenda-se encapsular `dataset_fn` em `strategy.distribute_datasets_from_function` para permitir uma pré-busca eficiente nas GPUs de forma transparente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h9DCvTJTa4Q2"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def per_worker_dataset_fn():\n",
        "  return strategy.distribute_datasets_from_function(dataset_fn)\n",
        "\n",
        "per_worker_dataset = coordinator.create_per_worker_dataset(per_worker_dataset_fn)\n",
        "per_worker_iterator = iter(per_worker_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2pnOx78iRwW"
      },
      "source": [
        "A etapa final é distribuir a computação para os workers remotos usando `ClusterCoordinator.schedule`:\n",
        "\n",
        "- O método `schedule` enfileira uma `tf.function` e retorna um `RemoteValue` com previsão futura imediatamente. As funções enfileiradas serão enviadas para workers remotos em threads em segundo plano, e `RemoteValue` será preenchido de forma assíncrona.\n",
        "- O método `join` (`ClusterCoordinator.join`) pode ser usado para aguardar até que todas as funções agendadas sejam executadas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gmPvactfa6Eh"
      },
      "outputs": [],
      "source": [
        "num_epochs = 4\n",
        "steps_per_epoch = 5\n",
        "for i in range(num_epochs):\n",
        "  accuracy.reset_states()\n",
        "  for _ in range(steps_per_epoch):\n",
        "    coordinator.schedule(step_fn, args=(per_worker_iterator,))\n",
        "  # Wait at epoch boundaries.\n",
        "  coordinator.join()\n",
        "  print(\"Finished epoch %d, accuracy is %f.\" % (i, accuracy.result().numpy()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBn-gn-OP3DR"
      },
      "source": [
        "Veja como você pode buscar o resultado de um `RemoteValue`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-15a2I_lQDO1"
      },
      "outputs": [],
      "source": [
        "loss = coordinator.schedule(step_fn, args=(per_worker_iterator,))\n",
        "print(\"Final loss is %f\" % loss.fetch())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htY4QKc9iXg9"
      },
      "source": [
        "Outra opção é iniciar todos os passos e fazer alguma outra coisa enquanto aguarda a conclusão:\n",
        "\n",
        "```python\n",
        "for _ in range(total_steps):\n",
        "  coordinator.schedule(step_fn, args=(per_worker_iterator,))\n",
        "while not coordinator.done():\n",
        "  time.sleep(10)\n",
        "  # Do something like logging metrics or writing checkpoints.\n",
        "```\n",
        "\n",
        "Confira o fluxo de trabalho de treinamento e serviço completo para esse exemplo específico neste [teste](https://github.com/keras-team/keras/blob/master/keras/integration_test/parameter_server_keras_preprocessing_test.py).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzNsj2GR3BGs"
      },
      "source": [
        "### Mais detalhes sobre a criação do dataset\n",
        "\n",
        "O dataset no código acima é criado usando a API `ClusterCoordinator.create_per_worker_dataset`. Ela cria um dataset por worker e retorna um objeto container. Você pode fazer uma chamada ao método `iter` para criar um iterador por worker. Você terá um iterador por worker, e a fatia correspondente de um worker será substituída no argumento de entrada da função passado ao método `ClusterCoordinator.schedule` antes que a função seja executada em um worker específico.\n",
        "\n",
        "O método `ClusterCoordinator.schedule` pressupõe que todos os workers sejam equivalentes e, portanto, também pressupõe que os datasets em diferentes workers sejam os mesmos (exceto pelo fato de poderem ter sido misturados de forma diferente). Dessa forma, também recomenda-se repetir os datasets e agendar um número finito de passos em vez de contar com o recebimento do erro `OutOfRangeError` de um dataset.\n",
        "\n",
        "Outra observação importante: os datasets de `tf.data` não têm suporte à serialização e desserialização implícitas após cada tarefa. Portanto, é importante criar o dataset inteiro dentro da função passada a `ClusterCoordinator.create_per_worker_dataset`. A API `create_per_worker_dataset` também pode receber diretamente um `tf.data.Dataset` ou `tf.distribute.DistributedDataset` como entrada."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LcfdI_M83lAM"
      },
      "source": [
        "## Avaliação\n",
        "\n",
        "As duas principais estratégias para fazer a avaliação com o treinamento `tf.distribute.ParameterServerStrategy` são a avaliação embutida e a avaliação secundária. Cada uma tem suas vantagens e desvantagens, conforme descrito abaixo. O método de avaliação embutida é recomendado se você não tiver uma preferência específica. Para usuários que usam `Model.fit`, `Model.evaluate` usa avaliação embutida (distribuída) em segundo plano."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oiG8EhcY3gA1"
      },
      "source": [
        "### Avaliação embutida\n",
        "\n",
        "Neste método, o coordenador alterna entre treinamento e avaliação e, portanto, é chamado de *avaliação embutida*.\n",
        "\n",
        "Existem vários benefícios da avaliação embutida. Por exemplo:\n",
        "\n",
        "- É compatível com modelos de avaliação e datasets de avaliação grandes que uma única tarefa não consegue realizar.\n",
        "- Os resultados da avaliação podem ser usados para tomar decisões para treinar a próxima época (por exemplo, se o treinamento deve ser interrompido antecipadamente).\n",
        "\n",
        "Existem duas formas de implementar a avaliação embutida: avaliação direta e avaliação distribuída.\n",
        "\n",
        "- **Avaliação direta**: para modelos e datasets de avaliação pequenos, o coordenador pode executar a avaliação diretamente no modelo distribuído, com o dataset de avaliação no coordenador:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WakiAakoaHVn"
      },
      "outputs": [],
      "source": [
        "eval_dataset = tf.data.Dataset.from_tensor_slices(\n",
        "    feature_and_label_gen(num_examples=16)).map(\n",
        "          lambda x: (\n",
        "              {\"features\": feature_preprocess_stage(x[\"features\"])},\n",
        "              label_preprocess_stage(x[\"label\"])\n",
        "          )).batch(8)\n",
        "\n",
        "eval_accuracy = tf.keras.metrics.Accuracy()\n",
        "\n",
        "for batch_data, labels in eval_dataset:\n",
        "  pred = model(batch_data, training=False)\n",
        "  actual_pred = tf.cast(tf.greater(pred, 0.5), tf.int64)\n",
        "  eval_accuracy.update_state(labels, actual_pred)\n",
        "\n",
        "print(\"Evaluation accuracy: %f\" % eval_accuracy.result())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKGHbdI7aGoJ"
      },
      "source": [
        "- **Avaliação distribuída**: para modelos ou datasets grandes em que não seria viável executar diretamente no coordenador, a tarefa do coordenador pode distribuir tarefas de avaliação para os workers pelos métodos `ClusterCoordinator.schedule`/`ClusterCoordinator.join`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XcHNHJpDgEvK"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "  # Define the eval metric on parameter servers.\n",
        "  eval_accuracy = tf.keras.metrics.Accuracy()\n",
        "\n",
        "@tf.function\n",
        "def eval_step(iterator):\n",
        "  def replica_fn(batch_data, labels):\n",
        "    pred = model(batch_data, training=False)\n",
        "    actual_pred = tf.cast(tf.greater(pred, 0.5), tf.int64)\n",
        "    eval_accuracy.update_state(labels, actual_pred)\n",
        "  batch_data, labels = next(iterator)\n",
        "  strategy.run(replica_fn, args=(batch_data, labels))\n",
        "\n",
        "def eval_dataset_fn():\n",
        "  return tf.data.Dataset.from_tensor_slices(\n",
        "      feature_and_label_gen(num_examples=16)).map(\n",
        "          lambda x: (\n",
        "              {\"features\": feature_preprocess_stage(x[\"features\"])},\n",
        "              label_preprocess_stage(x[\"label\"])\n",
        "          )).shuffle(16).repeat().batch(8)\n",
        "\n",
        "per_worker_eval_dataset = coordinator.create_per_worker_dataset(eval_dataset_fn)\n",
        "per_worker_eval_iterator = iter(per_worker_eval_dataset)\n",
        "\n",
        "eval_steps_per_epoch = 2\n",
        "for _ in range(eval_steps_per_epoch):\n",
        "  coordinator.schedule(eval_step, args=(per_worker_eval_iterator,))\n",
        "coordinator.join()\n",
        "print(\"Evaluation accuracy: %f\" % eval_accuracy.result())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKrQktZX5z7a"
      },
      "source": [
        "#### Ativação da avaliação \"exatamente uma vez\"\n",
        "\n",
        "<a id=\"exactly_once_evaluation\"></a>\n",
        "\n",
        "Os métodos `schedule` e `join` de `tf.distribute.coordinator.ClusterCoordinator` não oferecem suporte às semânticas de \"garantias de análise\" e \"exatamente uma vez\" por padrão. Em outras palavras, no exemplo acima, não há garantia de que todos os exemplos de avaliação em um dataset serão avaliados exatamente uma vez; alguns poderão não ser analisados, e alguns poderão ser avaliados diversas vezes.\n",
        "\n",
        "A avaliação \"exatamente uma vez\" poderá ser preferível para reduzir a variância da avaliação entre as épocas e para melhorar a seleção de modelo por interrupção antecipada, ajuste de hiperparâmetros ou outros métodos. Existem diferentes formas de ativar a avaliação \"exatamente uma vez\":\n",
        "\n",
        "- Com um fluxo de trabalho `Model.fit/.evaluate`, é possível ativá-la adicionando um argumento a `Model.compile`. Confira a documentação do argumento `pss_evaluation_shards`.\n",
        "- A API de serviço `tf.data` pode ser usada para permitir a análise \"exatamente uma vez\" para a avaliação usando `ParameterServerStrategy` (confira a seção *Fragmentação dinâmica* da documentação da API de `tf.data.experimental.service`).\n",
        "- A [avaliação secundária](#sidecar_evaluation) fornece a avaliação \"exatamente uma vez\" por padrão, já que a avaliação é feita em somente uma máquina. Entretanto, isso poderá ser muito mais lento do que fazer a avaliação distribuída em vários workers.\n",
        "\n",
        "A primeira opção, com o uso de `Model.compile`, é a solução sugerida para a maioria dos usuários.\n",
        "\n",
        "A avaliação \"exatamente uma vez\" tem algumas limitações:\n",
        "\n",
        "- Não há suporte à escrita de um loop de avaliação distribuído personalizado com uma garantia de análise \"exatamente uma vez\". Registre um problema no GitHub caso precise de suporte.\n",
        "- Não pode lidar automaticamente com a computação de métricas que usem a API `Layer.add_metric`. Elas devem ser excluídas da avaliação ou convertidas em objetos `Metric`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H40X-9Gs3i7_"
      },
      "source": [
        "### Avaliação secundária\n",
        "\n",
        "<a id=\"sidecar_evaluation\"></a>\n",
        "\n",
        "Outro método para definir e executar um loop de avaliação no treinamento `tf.distribute.ParameterServerStrategy` é chamado de *avaliação secundária*, em que você cria uma tarefa de avaliação dedicada que lê checkpoints repetidamente e executa a avaliação no último checkpoint (confira mais detalhes sobre criação de checkpoints [neste guia](../../guide/checkpoint.ipynb)). As tarefas do coordenador e dos workers não gastam tempo com avaliação, então, para um número fixo de iterações, o tempo de treinamento geral deverá ser menor do que ao usar outros métodos de avaliação. Entretanto, requer uma tarefa de avaliação adicional e criação periódica de checkpoints para acionar a avaliação."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HonyjnXK9-ys"
      },
      "source": [
        "Para escrever um loop de avaliação para a avaliação secundária, você tem duas opções:\n",
        "\n",
        "1. Usar a API `tf.keras.utils.SidecarEvaluator`.\n",
        "2. Criar um loop de avaliação personalizado.\n",
        "\n",
        "Consulte a documentação da API `tf.keras.utils.SidecarEvaluator` para ver mais detalhes sobre primeira opção."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_c0EiwB88OG"
      },
      "source": [
        "A avaliação secundária é compatível somente com uma única tarefa. Portanto:\n",
        "\n",
        "- Há uma garantia de que cada exemplo será avaliado uma vez. Caso o avaliador seja interrompido ou reiniciado, ele reinicia o loop de avaliação pelo último checkpoint, e o progresso parcial de avaliação feito antes da reinicialização é descartado.\n",
        "\n",
        "- Entretanto, ao executar a avaliação em uma única tarefa, uma avaliação completa pode levar um longo tempo.\n",
        "\n",
        "- Se o tamanho do modelo for grande demais e não couber na memória do avaliador, a avaliação secundária única não será aplicável."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNJoWVc797B1"
      },
      "source": [
        "Outra ressalva é que a implementação `tf.keras.utils.SidecarEvaluator` e o loop de avaliação personalizado abaixo podem pular alguns checkpoints, pois eles sempre escolhem o último checkpoint disponível e, durante uma época de avaliação, diversos checkpoints podem ser gerados pelo cluster de treinamento. Você pode escrever um loop de avaliação personalizado que avalie cada checkpoint, mas isso não é discutido neste tutorial. Por outro lado, ele pode ficar ocioso se os checkpoints forem produzidos com uma frequência inferior ao tempo necessário para executar a avaliação."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5jopxBd85Ji"
      },
      "source": [
        "Um loop de avaliação personalizado oferece mais controle dos detalhes, como escolher qual checkpoint será avaliado ou incluir lógica adicional para ser executada junto com a avaliação. Veja abaixo um possível loop de avaliação secundária personalizado:\n",
        "\n",
        "```python\n",
        "checkpoint_dir = ...\n",
        "eval_model = ...\n",
        "eval_data = ...\n",
        "checkpoint = tf.train.Checkpoint(model=eval_model)\n",
        "\n",
        "for latest_checkpoint in tf.train.checkpoints_iterator(\n",
        "    checkpoint_dir):\n",
        "  try:\n",
        "    checkpoint.restore(latest_checkpoint).expect_partial()\n",
        "  except (tf.errors.OpError,) as e:\n",
        "    # checkpoint may be deleted by training when it is about to read it.\n",
        "    continue\n",
        "\n",
        "  # Optionally add callbacks to write summaries.\n",
        "  eval_model.evaluate(eval_data)\n",
        "\n",
        "  # Evaluation finishes when it has evaluated the last epoch.\n",
        "  if latest_checkpoint.endswith('-{}'.format(train_epochs)):\n",
        "    break\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9TkNbtpPhFRQ"
      },
      "source": [
        "## Clusters no mundo real\n",
        "\n",
        "<a id=\"real_clusters\"></a>\n",
        "\n",
        "Observação: esta seção não é necessária para executar o código do tutorial nesta página.\n",
        "\n",
        "Em um ambiente de produção real, você executará todas as tarefas em processos diferentes, em máquinas diferentes. A maneira mais simples de configurar as informações do cluster em cada tarefa é definindo variáveis de ambiente `\"TF_CONFIG\"` e usando `tf.distribute.cluster_resolver.TFConfigClusterResolver` para processar `\"TF_CONFIG\"`.\n",
        "\n",
        "Confira a descrição geral de variáveis de ambiente `\"TF_CONFIG\"` em \"Configuração da variável de ambiente`TF_CONFIG`\" no guia [Treinamento distribuído](../../guide/distributed_training.ipynb).\n",
        "\n",
        "Se você iniciar suas tarefas de treinamento usando Kubernetes ou outros modelos de configuração, provavelmente a variável de ambiente `\"TF_CONFIG\"` já foi configurada para você."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7AK9SJGt3tQ"
      },
      "source": [
        "### Configuração da variável de ambiente `\"TF_CONFIG\"`\n",
        "\n",
        "Vamos supor que você tenha três workers e dois servidores de parâmetros. Portanto, `\"TF_CONFIG\"` do worker 1 pode ser:\n",
        "\n",
        "```python\n",
        "os.environ[\"TF_CONFIG\"] = json.dumps({\n",
        "    \"cluster\": {\n",
        "        \"worker\": [\"host1:port\", \"host2:port\", \"host3:port\"],\n",
        "        \"ps\": [\"host4:port\", \"host5:port\"],\n",
        "        \"chief\": [\"host6:port\"]\n",
        "    },\n",
        "    \"task\": {\"type\": \"worker\", \"index\": 1}\n",
        "})\n",
        "```\n",
        "\n",
        "`\"TF_CONFIG\"` do avaliador pode ser:\n",
        "\n",
        "```python\n",
        "os.environ[\"TF_CONFIG\"] = json.dumps({\n",
        "    \"cluster\": {\n",
        "        \"evaluator\": [\"host7:port\"]\n",
        "    },\n",
        "    \"task\": {\"type\": \"evaluator\", \"index\": 0}\n",
        "})\n",
        "```\n",
        "\n",
        "A parte `\"cluster\"` na string `\"TF_CONFIG\"` acima para o avaliador é opcional."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZRjMS0pt1LM"
      },
      "source": [
        "### Se você usar o mesmo binário para todas as tarefas\n",
        "\n",
        "Se você preferir executar todas essas tarefas usando um único binário, precisará deixar seu programa se dividir em diferentes funções no começo:\n",
        "\n",
        "```python\n",
        "cluster_resolver = tf.distribute.cluster_resolver.TFConfigClusterResolver()\n",
        "if cluster_resolver.task_type in (\"worker\", \"ps\"):\n",
        "  # Start a TensorFlow server and wait.\n",
        "elif cluster_resolver.task_type == \"evaluator\":\n",
        "  # Run sidecar evaluation\n",
        "else:\n",
        "  # Run the coordinator.\n",
        "```\n",
        "\n",
        "O código abaixo inicia um servidor do TensorFlow e aguarda, o que é útil para as funções `\"worker\"` e `\"ps\"`:\n",
        "\n",
        "```python\n",
        "# Set the environment variable to allow reporting worker and ps failure to the\n",
        "# coordinator. This is a workaround and won't be necessary in the future.\n",
        "os.environ[\"GRPC_FAIL_FAST\"] = \"use_caller\"\n",
        "\n",
        "server = tf.distribute.Server(\n",
        "    cluster_resolver.cluster_spec(),\n",
        "    job_name=cluster_resolver.task_type,\n",
        "    task_index=cluster_resolver.task_id,\n",
        "    protocol=cluster_resolver.rpc_layer or \"grpc\",\n",
        "    start=True)\n",
        "server.join()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWdYfK593eOL"
      },
      "source": [
        "## Tratamento de falhas das tarefas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bl9eK5r13cOv"
      },
      "source": [
        "### Falha dos workers\n",
        "\n",
        "Tanto a estratégia de loop de treinamento personalizado `tf.distribute.coordinator.ClusterCoordinator` quanto `Model.fit` têm uma tolerância a falhas integrada em caso de falha dos workers. Quando o worker se recupera, `ClusterCoordinator` chama a recriação do dataset nos workers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aP0OHZ1-Ne-B"
      },
      "source": [
        "### Falha do servidor de parâmetros ou do coordenador\n",
        "\n",
        "Entretanto, quando o coordenador observar um erro no servidor de parâmetros, gerará um erro `UnavailableError` ou `AbortedError` imediatamente. Nesse caso, você pode reiniciar o coordenador. O coordenador em si também pode ficar indisponível. Portanto, recomenda-se usar certas ferramentas para não perder o progresso do treinamento:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7m7Itoz8lsI"
      },
      "source": [
        "- Para `Model.fit`, você deve usar um callback `BackupAndRestore`, que trata o salvamento e a restauração do progresso automaticamente. Confira um exemplo na seção [Callbacks e treinamento](#callbacks-and-training) acima."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XlLyJp53Z8A"
      },
      "source": [
        "- Para um loop de treinamento personalizado, você deve fazer o checkpoint das variáveis do modelo periodicamente e carregar as variáveis do modelo a partir de um checkpoint, se algum existir, antes de o treinamento começar. O progresso do treinamento pode ser inferido aproximadamente de `optimizer.iterations`, se for feito checkpoint de um otimizador:\n",
        "\n",
        "```python\n",
        "checkpoint_manager = tf.train.CheckpointManager(\n",
        "    tf.train.Checkpoint(model=model, optimizer=optimizer),\n",
        "    checkpoint_dir,\n",
        "    max_to_keep=3)\n",
        "if checkpoint_manager.latest_checkpoint:\n",
        "  checkpoint = checkpoint_manager.checkpoint\n",
        "  checkpoint.restore(\n",
        "      checkpoint_manager.latest_checkpoint).assert_existing_objects_matched()\n",
        "\n",
        "global_steps = int(optimizer.iterations.numpy())\n",
        "starting_epoch = global_steps // steps_per_epoch\n",
        "\n",
        "for _ in range(starting_epoch, num_epochs):\n",
        "  for _ in range(steps_per_epoch):\n",
        "    coordinator.schedule(step_fn, args=(per_worker_iterator,))\n",
        "  coordinator.join()\n",
        "  checkpoint_manager.save()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PlN1P7C53XK9"
      },
      "source": [
        "### Busca de `RemoteValue`\n",
        "\n",
        "A busca de `RemoteValue` sempre será bem-sucedida se uma função for executada com êxito. Isso ocorre porque, atualmente, o valor de retorno é copiado imediatamente para o coordenador após a execução de uma função. Se qualquer worker falhar durante a cópia, a função será refeita em outro worker disponível. Portanto, se você quiser otimizar o desempenho, pode agendar funções sem um valor de retorno."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZcR_xNZ3UdU"
      },
      "source": [
        "## Relatório de erros\n",
        "\n",
        "Quando o coordenador observa um erro, como `UnavailableError`, nos servidores de parâmetros ou outros erros de aplicação, como `InvalidArgument` em `tf.debugging.check_numerics`, ele cancelará todas as funções pendentes e enfileiradas antes de gerar o erro. A busca dos `RemoteValue`s correspondentes gerará um erro `CancelledError`.\n",
        "\n",
        "Após um erro ser gerado, o coordenador não gerará o mesmo erro ou qualquer outro erro a partir das funções canceladas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfhbXH-j3NVw"
      },
      "source": [
        "## Melhoria do desempenho\n",
        "\n",
        "Há vários possíveis motivos para você se deparar com problemas de desempenho ao fazer o treinamento com `tf.distribute.ParameterServerStrategy` e `tf.distribute.coordinator.ClusterCoordinator`.\n",
        "\n",
        "Um motivo comum é servidores de parâmetros com carga desbalanceada, em que alguns servidores de parâmetros com carga em excesso chegam à capacidade máxima. Também há diversas causas raiz. Veja alguns métodos simples para mitigar esse problema:\n",
        "\n",
        "1. Fragmente as variáveis grandes do modelo especificando `variable_partitioner` ao construir `ParameterServerStrategy`.\n",
        "2. Evite criar uma variável de hotspot exigida por todos os servidores de parâmetros em um único passo:\n",
        "\n",
        "1. Use uma taxa de aprendizado constante ou a subclasse `tf.keras.optimizers.schedules.LearningRateSchedule` nos otimizadores. Isso é feito porque o comportamento padrão é a taxa de aprendizado se tornar uma variável colocada em um servidor de parâmetros específico e solicitada por todos os outros servidores de parâmetros em cada passo.\n",
        "\n",
        "2. Use um `tf.keras.optimizers.legacy.Optimizer` (os `tf.keras.optimizers.Optimizer`s padrão ainda podem acarretar variáveis de hotspot).\n",
        "\n",
        "1. Misture seus vocabulários grandes antes de passá-los às camadas de pré-processamento do Keras.\n",
        "\n",
        "Outro possível motivo para problemas de desempenho é o coordenador. A implementação de `schedule`/`join` é baseada no Python e, portanto, pode haver sobrecarga de threads. Além disso, a latência entre o coordenador e os workers pode ser alta. Se esse for o caso:\n",
        "\n",
        "- Para `Model.fit`, você pode definir o argumento `steps_per_execution` fornecido em `Model.compile` como um valor maior do que 1.\n",
        "\n",
        "- Para um loop de treinamento personalizado, você pode agrupar diversos passos em uma única função `tf.function`:\n",
        "\n",
        "```python\n",
        "steps_per_invocation = 10\n",
        "\n",
        "@tf.function\n",
        "def step_fn(iterator):\n",
        "  for _ in range(steps_per_invocation):\n",
        "    features, labels = next(iterator)\n",
        "    def replica_fn(features, labels):\n",
        "      ...\n",
        "\n",
        "    strategy.run(replica_fn, args=(features, labels))\n",
        "```\n",
        "\n",
        "À medida que a biblioteca for otimizada, espera-se que a maioria dos usuários não precise agrupar passos manualmente no futuro.\n",
        "\n",
        "Além disso, uma dica para melhorar o desempenho é agendar funções sem um valor de retorno, conforme explicado na seção [Tratamento de falhas das tarefas](#handling_task_failure) acima."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chu5F7M_JmVk"
      },
      "source": [
        "## Limitações conhecidas\n",
        "\n",
        "<a id=\"known_limitations\"> </a>\n",
        "\n",
        "A maioria das limitações conhecidas já foram discutidas nas seções acima. Esta seção apresenta um resumo.\n",
        "\n",
        "### `ParameterServerStrategy` geral\n",
        "\n",
        "- `os.environment[\"grpc_fail_fast\"]=\"use_caller\"` é necessário em cada tarefa, incluindo o coordenador, para que a tolerância a falhas funcione corretamente.\n",
        "- Não há suporte a treinamento de servidor de parâmetros síncrono.\n",
        "- Geralmente, é necessário agrupar vários passos em uma única função para atingir o desempenho ideal.\n",
        "- Não há suporte ao carregamento de um saved_model por meio de `tf.saved_model.load` contendo variáveis fragmentadas. Espera-se que carregar um saved_model usando o TensorFlow Serving funcione (consulte mais detalhes no [tutorial de serviço](https://www.tensorflow.org/tfx/tutorials/serving/rest_simple)).\n",
        "- Não há suporte à recuperação de uma falha do servidor de parâmetros sem reiniciar tarefa do coordenador.\n",
        "- A criação de `tf.lookup.StaticHashTable`, usada com frequência por algumas camadas de pré-processamento do Keras, como `tf.keras.layers.IntegerLookup`, `tf.keras.layers.StringLookup` e `tf.keras.layers.TextVectorization`, deve ser feita dentro de `Strategy.scope`. Caso contrário, os recursos serão colocados no coordenador, e os RPCs de pesquisa dos workers para o coordenador terão consequências para o desempenho.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MKBF0RPSvzB"
      },
      "source": [
        "### Especificidades de `Model.fit`\n",
        "\n",
        "- O argumento `steps_per_epoch` é exigido no `Model.fit`. Você pode selecionar um valor que forneça intervalos adequados em uma época.\n",
        "- `ParameterServerStrategy` não tem suporte a callbacks personalizados que tenham chamadas no nível de lote por questões de desempenho. Você deve converter essas chamadas em chamadas no nível de época e escolher um `steps_per_epoch` adequado para que as chamadas sejam feitas a cada `steps_per_epoch` passos. Os callbacks integrados não são afetados: suas chamadas no nível de lote foram modificadas de forma a terem bom desempenho. Há planos para incluir suporte a chamadas no nível de lote em `ParameterServerStrategy`.\n",
        "- Pelo mesmo motivo, diferentemente de outras estratégias, as barras e métricas de progresso são registradas somente após cada época.\n",
        "- Não há suporte a `run_eagerly`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvY-mg35Sx5L"
      },
      "source": [
        "### Especificidades do loop de treinamento personalizado\n",
        "\n",
        "- De forma geral, `ClusterCoordinator.schedule` não tem suporte a garantia de análise para um dataset, embora seja possível ter garantia de análise da avaliação com `Model.fit/.evaluate`. Confira [Ativação da avaliação \"exatamente uma vez\"](#exactly_once_evaluation).\n",
        "- Quando `ClusterCoordinator.create_per_worker_dataset` é usado com um callable como entrada, todo o dataset deve ser criado dentro da função passada a ele.\n",
        "- `tf.data.Options` é ignorado em um dataset criado por `ClusterCoordinator.create_per_worker_dataset`."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "parameter_server_training.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
