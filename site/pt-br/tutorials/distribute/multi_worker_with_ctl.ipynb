{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tce3stUlHN0L"
      },
      "source": [
        "##### Copyright 2019 The TensorFlow Authors.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tuOe1ymfHZPu"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfBg1C5NB3X0"
      },
      "source": [
        "# Loop de treinamento personalizado com o Keras e MultiWorkerMirroredStrategy\n",
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>     <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/distribute/multi_worker_with_ctl\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver em TensorFlow.org</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/pt-br/tutorials/distribute/multi_worker_with_ctl.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Executar no Google Colab</a> </td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/pt-br/tutorials/distribute/multi_worker_with_ctl.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver fonte no GitHub</a> </td>\n",
        "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/pt-br/tutorials/distribute/multi_worker_with_ctl.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Baixar notebook</a> </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHxb-dlhMIzW"
      },
      "source": [
        "## Visão geral\n",
        "\n",
        "Este tutorial demonstra como fazer um treinamento distribuído multiworker com um modelo do Keras e com [loops de treinamento personalizado](https://www.tensorflow.org/guide/keras/writing_a_training_loop_from_scratch) usando a API `tf.distribute.Strategy`. O loop de treinamento é distribuído pelo `tf.distribute.MultiWorkerMirroredStrategy` de tal modo que um modelo `tf.keras` — desenvolvido para executar em um [único worker](custom_training.ipynb) — possa funcionar de forma transparente em diversos workers, com alterações de código mínimas. Os loops de treinamento personalizado proporcionam flexibilidade e um maior controle do treinamento, além de facilitar a depuração do modelo. Saiba mais sobre [como escrever um loop de treinamento básico](../../guide/basic_training_loops.ipynb), [como escrever um loop de treinamento do zero](https://www.tensorflow.org/guide/keras/writing_a_training_loop_from_scratch) e [treinamento personalizado](../customization/custom_training_walkthrough.ipynb).\n",
        "\n",
        "Se você deseja saber como usar `MultiWorkerMirroredStrategy` com `tf.keras.Model.fit`, confira este [tutorial](multi_worker_with_keras.ipynb).\n",
        "\n",
        "O guia [Treinamento distribuído no TensorFlow](../../guide/distributed_training.ipynb) apresenta uma visão geral das estratégias de distribuição oferecidas pelo TensorFlow para quem tiver interesse em compreender de forma mais aprofundada as APIs de `tf.distribute.Strategy`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUXex9ctTuDB"
      },
      "source": [
        "## Configuração\n",
        "\n",
        "Primeiro, faça as importações necessárias."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bnYxvfLD-LW-"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "import sys"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zz0EY91y3mxy"
      },
      "source": [
        "Antes de importar o TensorFlow, faça algumas alterações no ambiente:\n",
        "\n",
        "- Desative todas as GPUs. Isso evita erros causados quando todos os workers tentam usar a mesma GPU. Em uma aplicação real, cada worker estaria em uma máquina diferente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "685pbYEY3jGC"
      },
      "outputs": [],
      "source": [
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7X1MS6385BWi"
      },
      "source": [
        "- Redefina a variável de ambiente `'TF_CONFIG'` (você verá mais detalhes sobre isso posteriormente)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WEJLYa2_7OZF"
      },
      "outputs": [],
      "source": [
        "os.environ.pop('TF_CONFIG', None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rd4L9Ii77SS8"
      },
      "source": [
        "- O diretório atual deve estar no caminho do Python. Dessa forma, o notebook pode importar os arquivos escritos por `%%writefile` posteriormente.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hPBuZUNSZmrQ"
      },
      "outputs": [],
      "source": [
        "if '.' not in sys.path:\n",
        "  sys.path.insert(0, '.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDhHuMjb7bfU"
      },
      "source": [
        "Agora, importe o TensorFlow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vHNvttzV43sA"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0S2jpf6Sx50i"
      },
      "source": [
        "### Definição do dataset e do modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLW6D2TzvC-4"
      },
      "source": [
        "Agora, crie um arquivo `mnist.py` com uma configuração simples de modelo e dataset. Este arquivo do Python será usado pelos processos dos workers neste tutorial:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dma_wUAxZqo2"
      },
      "outputs": [],
      "source": [
        "%%writefile mnist.py\n",
        "\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "def mnist_dataset(batch_size):\n",
        "  (x_train, y_train), _ = tf.keras.datasets.mnist.load_data()\n",
        "  # The `x` arrays are in uint8 and have values in the range [0, 255].\n",
        "  # You need to convert them to float32 with values in the range [0, 1]\n",
        "  x_train = x_train / np.float32(255)\n",
        "  y_train = y_train.astype(np.int64)\n",
        "  train_dataset = tf.data.Dataset.from_tensor_slices(\n",
        "      (x_train, y_train)).shuffle(60000)\n",
        "  return train_dataset\n",
        "\n",
        "def dataset_fn(global_batch_size, input_context):\n",
        "  batch_size = input_context.get_per_replica_batch_size(global_batch_size)\n",
        "  dataset = mnist_dataset(batch_size)\n",
        "  dataset = dataset.shard(input_context.num_input_pipelines,\n",
        "                          input_context.input_pipeline_id)\n",
        "  dataset = dataset.batch(batch_size)\n",
        "  return dataset\n",
        "\n",
        "def build_cnn_model():\n",
        "  regularizer = tf.keras.regularizers.L2(1e-5)\n",
        "  return tf.keras.Sequential([\n",
        "      tf.keras.Input(shape=(28, 28)),\n",
        "      tf.keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
        "      tf.keras.layers.Conv2D(32, 3,\n",
        "                             activation='relu',\n",
        "                             kernel_regularizer=regularizer),\n",
        "      tf.keras.layers.Flatten(),\n",
        "      tf.keras.layers.Dense(128,\n",
        "                            activation='relu',\n",
        "                            kernel_regularizer=regularizer),\n",
        "      tf.keras.layers.Dense(10, kernel_regularizer=regularizer)\n",
        "  ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmgZwwymxqt5"
      },
      "source": [
        "## Configuração multiworker\n",
        "\n",
        "Agora, vamos entrar na seara do treinamento multiworker. No TensorFlow, a variável de ambiente `'TF_CONFIG'` é necessária para treinamento em diversas máquinas. Cada máquina pode ter uma função diferente. A variável `'TF_CONFIG'` usada abaixo é uma string JSON que especifica a configuração de cluster em cada worker que faz parte do cluster. Esse é o método padrão de especificação de um cluster, usando `cluster_resolver.TFConfigClusterResolver`, mas existem outras opções disponíveis no módulo `distribute.cluster_resolver`. Saiba mais sobre como configurar a variável `'TF_CONFIG'` no guia [Treinamento distribuído](../../guide/distributed_training.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SS8WhvRhe_Ya"
      },
      "source": [
        "### Descrição do cluster\n",
        "\n",
        "Veja um exemplo de configuração:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XK1eTYvSZiX7"
      },
      "outputs": [],
      "source": [
        "tf_config = {\n",
        "    'cluster': {\n",
        "        'worker': ['localhost:12345', 'localhost:23456']\n",
        "    },\n",
        "    'task': {'type': 'worker', 'index': 0}\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjgwJbPKZkJL"
      },
      "source": [
        "Observe que `tf_config` é apenas uma variável local no Python. Para usá-la na configuração do treinamento, serialize-a como JSON e coloque-a em uma variável de ambiente `'TF_CONFIG'`. Veja a mesma variável `'TF_CONFIG'` serializada como string JSON:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yY-T0YDQZjbu"
      },
      "outputs": [],
      "source": [
        "json.dumps(tf_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUBmYRZqxthH"
      },
      "source": [
        "Existem dois componentes de `'TF_CONFIG'`: `'cluster'` e `'task'` (tarefa).\n",
        "\n",
        "- `'cluster'` é igual para todos os workers e fornece informações sobre o cluster de treinamento, que é um dicionário consistindo de diferentes tipos de trabalhos, como `'worker'`. No treinamento multiworker com `MultiWorkerMirroredStrategy`, geralmente existe um `'worker'` que tem mais responsabilidades, como salvar checkpoints e escrever arquivos de resumo para o TensorBoard, além das tarefas de um `'worker'` comum. Esse tipo de worker é chamado de worker `'chief'` (principal), e geralmente o `'worker'` com `'index'` (índice) 0 é designado como o `worker` principal.\n",
        "\n",
        "- `'task'` fornece informações da tarefa atual e é diferente em cada worker. Ela especifica o `'type'` (tipo) e o `'index'` (índice) desse worker."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YFpxrcsZ2xG"
      },
      "source": [
        "Neste exemplo, você define o `'type'` da tarefa como `'worker'` e o `'index'` da tarefa como `0`. Esta máquina é o primeiro worker e será designada como o worker principal, realizando mais trabalho do que os outros. Também será preciso definir a variável de ambiente `'TF_CONFIG'` nas outras máquinas, e ela deve ter o mesmo dicionário `'cluster'`, mas um `'type'` de tarefa ou um `'index'` de tarefa diferente, dependendo das funções das máquinas.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aogb74kHxynz"
      },
      "source": [
        "Para fins de ilustração, este tutorial mostra como definir uma variável `'TF_CONFIG'` com dois workers no `'localhost'`.  Na prática, os usuários criariam diversos workers em endereços IP/portas externos e definiriam `'TF_CONFIG'` em cada worker da forma adequada.\n",
        "\n",
        "Este exemplo usa dois workers. A variável `'TF_CONFIG'` do primeiro worker é exibida acima. Para o segundo worker, defina `tf_config['task']['index']=1`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cIlkfWmjz1PG"
      },
      "source": [
        "### Variáveis de ambiente e subprocessos nos notebooks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcjAbuGY1ACJ"
      },
      "source": [
        "Os subprocessos herdam as variáveis de ambiente do pai. Portanto, se você definir uma variável de ambiente neste processo do Jupyter Notebook:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PH2gHn2_0_U8"
      },
      "outputs": [],
      "source": [
        "os.environ['GREETINGS'] = 'Hello TensorFlow!'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQkIX-cg18md"
      },
      "source": [
        "...você poderá acessar a variável de ambiente em um subprocesso:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pquKO6IA18G5"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "echo ${GREETINGS}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "af6BCA-Y2fpz"
      },
      "source": [
        "Na próxima seção, você usará esse método para passar a variável `'TF_CONFIG'` aos subprocessos do worker. Você jamais iniciaria seus trabalhos dessa forma, mas é suficiente para as finalidades deste tutorial, para demonstrar um exemplo mínimo de multiworker."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhNtHfuxCGVy"
      },
      "source": [
        "## MultiWorkerMirroredStrategy\n",
        "\n",
        "Antes de treinar o modelo, primeiro crie uma instância de `tf.distribute.MultiWorkerMirroredStrategy`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1uFSHCJXMrQ-"
      },
      "outputs": [],
      "source": [
        "strategy = tf.distribute.MultiWorkerMirroredStrategy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0iv7SyyAohc"
      },
      "source": [
        "Observação: `'TF_CONFIG'` é processada e os servidores gRPC do TensorFlow são iniciados no momento em que você faz a chamada a `tf.distribute.MultiWorkerMirroredStrategy`. Portanto, você precisa definir a variável de ambiente `'TF_CONFIG'` antes de instanciar um `tf.distribute.Strategy`. Para economizar tempo neste exemplo ilustrativo, isso não é demonstrado neste tutorial para que não seja preciso iniciar os servidores. Um exemplo completo está disponível na última seção deste tutorial."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TS4S-faBHHam"
      },
      "source": [
        "Use `tf.distribute.Strategy.scope` para especificar que uma estratégia deve ser usada ao criar o modelo. Dessa forma, a estratégia poderá controlar várias coisas, como o posicionamento de variáveis: ela criará cópias de todas as variáveis nas camadas do modelo em cada dispositivo, em todos os workers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nXV49tG1_opc"
      },
      "outputs": [],
      "source": [
        "import mnist\n",
        "with strategy.scope():\n",
        "  # Model building needs to be within `strategy.scope()`.\n",
        "  multi_worker_model = mnist.build_cnn_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSYkM-on6r3Y"
      },
      "source": [
        "## Fragmentação automática dos dados nos workers\n",
        "\n",
        "No treinamento multiworker, a *fragmentação do dataset* é necessária para convergência e capacidade de reprodutibilidade. Com a fragmentação, cada worker recebe um subconjunto do dataset, o que ajuda a criar uma experiência similar ao treinamento em um único worker. No exemplo abaixo, é utilizada a política padrão de fragmentação automática de `tf.distribute`. Você também pode personalizá-la definindo a `tf.data.experimental.AutoShardPolicy` de `tf.data.experimental.DistributeOptions`. Para saber mais, confira a seção *Fragmentação* do [tutorial Entrada distribuída](input.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "65-p36pt6rUF"
      },
      "outputs": [],
      "source": [
        "per_worker_batch_size = 64\n",
        "num_workers = len(tf_config['cluster']['worker'])\n",
        "global_batch_size = per_worker_batch_size * num_workers\n",
        "\n",
        "with strategy.scope():\n",
        "  multi_worker_dataset = strategy.distribute_datasets_from_function(\n",
        "      lambda input_context: mnist.dataset_fn(global_batch_size, input_context))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkNzSR3g60iP"
      },
      "source": [
        "## Definição de um loop de treinamento personalizado e treinamento do modelo\n",
        "\n",
        "Especifique um otimizador:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NoMr4_zTeKSn"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "  # The creation of optimizer and train_accuracy needs to be in\n",
        "  # `strategy.scope()` as well, since they create variables.\n",
        "  optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.001)\n",
        "  train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
        "      name='train_accuracy')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmrDcAii4B5O"
      },
      "source": [
        "Defina um passo de treinamento com `tf.function`:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "znXWN5S3eUDB"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def train_step(iterator):\n",
        "  \"\"\"Training step function.\"\"\"\n",
        "\n",
        "  def step_fn(inputs):\n",
        "    \"\"\"Per-Replica step function.\"\"\"\n",
        "    x, y = inputs\n",
        "    with tf.GradientTape() as tape:\n",
        "      predictions = multi_worker_model(x, training=True)\n",
        "      per_example_loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "          from_logits=True,\n",
        "          reduction=tf.keras.losses.Reduction.NONE)(y, predictions)\n",
        "      loss = tf.nn.compute_average_loss(per_example_loss)\n",
        "      model_losses = multi_worker_model.losses\n",
        "      if model_losses:\n",
        "        loss += tf.nn.scale_regularization_loss(tf.add_n(model_losses))\n",
        "\n",
        "    grads = tape.gradient(loss, multi_worker_model.trainable_variables)\n",
        "    optimizer.apply_gradients(\n",
        "        zip(grads, multi_worker_model.trainable_variables))\n",
        "    train_accuracy.update_state(y, predictions)\n",
        "    return loss\n",
        "\n",
        "  per_replica_losses = strategy.run(step_fn, args=(next(iterator),))\n",
        "  return strategy.reduce(\n",
        "      tf.distribute.ReduceOp.SUM, per_replica_losses, axis=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFXHsUVBy0Rx"
      },
      "source": [
        "### Como salvar e restaurar checkpoints\n",
        "\n",
        "Ao escrever um loop de treinamento personalizado, você precisa [salvar checkpoints](../../guide/checkpoint.ipynb) manualmente em vez de fazer um callback ao Keras. Para o `MultiWorkerMirroredStrategy`, salvar um checkpoint ou um modelo completo requer a participação de todos os workers, pois tentar salvar somente no worker principal poderia levar a um deadlock. Os workers também precisam escrever em caminhos diferentes para evitar sobrescrever os arquivos. Veja um exemplo de como configurar os diretórios:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LcFO6x1KyjhI"
      },
      "outputs": [],
      "source": [
        "from multiprocessing import util\n",
        "checkpoint_dir = os.path.join(util.get_temp_dir(), 'ckpt')\n",
        "\n",
        "def _is_chief(task_type, task_id, cluster_spec):\n",
        "  return (task_type is None\n",
        "          or task_type == 'chief'\n",
        "          or (task_type == 'worker'\n",
        "              and task_id == 0\n",
        "              and \"chief\" not in cluster_spec.as_dict()))\n",
        "\n",
        "def _get_temp_dir(dirpath, task_id):\n",
        "  base_dirpath = 'workertemp_' + str(task_id)\n",
        "  temp_dir = os.path.join(dirpath, base_dirpath)\n",
        "  tf.io.gfile.makedirs(temp_dir)\n",
        "  return temp_dir\n",
        "\n",
        "def write_filepath(filepath, task_type, task_id, cluster_spec):\n",
        "  dirpath = os.path.dirname(filepath)\n",
        "  base = os.path.basename(filepath)\n",
        "  if not _is_chief(task_type, task_id, cluster_spec):\n",
        "    dirpath = _get_temp_dir(dirpath, task_id)\n",
        "  return os.path.join(dirpath, base)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nrcdPHtG4ObO"
      },
      "source": [
        "Crie um `tf.train.Checkpoint` que monitore o modelo, que é gerenciado por um `tf.train.CheckpointManager` de forma que apenas os últimos checkpoints sejam preservados:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4rURT2pI4aqV"
      },
      "outputs": [],
      "source": [
        "epoch = tf.Variable(\n",
        "    initial_value=tf.constant(0, dtype=tf.dtypes.int64), name='epoch')\n",
        "step_in_epoch = tf.Variable(\n",
        "    initial_value=tf.constant(0, dtype=tf.dtypes.int64),\n",
        "    name='step_in_epoch')\n",
        "task_type, task_id = (strategy.cluster_resolver.task_type,\n",
        "                      strategy.cluster_resolver.task_id)\n",
        "# Normally, you don't need to manually instantiate a `ClusterSpec`, but in this\n",
        "# illustrative example you did not set `'TF_CONFIG'` before initializing the\n",
        "# strategy. Check out the next section for \"real-world\" usage.\n",
        "cluster_spec = tf.train.ClusterSpec(tf_config['cluster'])\n",
        "\n",
        "checkpoint = tf.train.Checkpoint(\n",
        "    model=multi_worker_model, epoch=epoch, step_in_epoch=step_in_epoch)\n",
        "\n",
        "write_checkpoint_dir = write_filepath(checkpoint_dir, task_type, task_id,\n",
        "                                      cluster_spec)\n",
        "checkpoint_manager = tf.train.CheckpointManager(\n",
        "    checkpoint, directory=write_checkpoint_dir, max_to_keep=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RO7cbN40XD5v"
      },
      "source": [
        "Agora, quando você precisar restaurar um checkpoint, encontrará o último checkpoint salvo usando a função conveniente `tf.train.latest_checkpoint` (ou fazendo uma chamada a `tf.train.CheckpointManager.restore_or_initialize`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gniynaQj6HMV"
      },
      "outputs": [],
      "source": [
        "latest_checkpoint = tf.train.latest_checkpoint(checkpoint_dir)\n",
        "if latest_checkpoint:\n",
        "  checkpoint.restore(latest_checkpoint)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1j9JuI-h6ObW"
      },
      "source": [
        "Após restaurar o checkpoint, você pode continuar treinando o seu loop de treinamento personalizado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kZzXZCh45FY6"
      },
      "outputs": [],
      "source": [
        "num_epochs = 3\n",
        "num_steps_per_epoch = 70\n",
        "\n",
        "while epoch.numpy() < num_epochs:\n",
        "  iterator = iter(multi_worker_dataset)\n",
        "  total_loss = 0.0\n",
        "  num_batches = 0\n",
        "\n",
        "  while step_in_epoch.numpy() < num_steps_per_epoch:\n",
        "    total_loss += train_step(iterator)\n",
        "    num_batches += 1\n",
        "    step_in_epoch.assign_add(1)\n",
        "\n",
        "  train_loss = total_loss / num_batches\n",
        "  print('Epoch: %d, accuracy: %f, train_loss: %f.'\n",
        "                %(epoch.numpy(), train_accuracy.result(), train_loss))\n",
        "\n",
        "  train_accuracy.reset_states()\n",
        "\n",
        "  # Once the `CheckpointManager` is set up, you're now ready to save, and remove\n",
        "  # the checkpoints non-chief workers saved.\n",
        "  checkpoint_manager.save()\n",
        "  if not _is_chief(task_type, task_id, cluster_spec):\n",
        "    tf.io.gfile.rmtree(write_checkpoint_dir)\n",
        "\n",
        "  epoch.assign_add(1)\n",
        "  step_in_epoch.assign(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0W1Osks466DE"
      },
      "source": [
        "## Confira o código completo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfYpmIxO6Jck"
      },
      "source": [
        "Resumindo todos os procedimentos abordados até agora:\n",
        "\n",
        "1. Crie processos nos workers.\n",
        "2. Passe variáveis `'TF_CONFIG'` aos processos dos workers.\n",
        "3. Deixe cada processo dos workers executar o script abaixo, que contém o código de treinamento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MIDCESkVzN6M"
      },
      "outputs": [],
      "source": [
        "%%writefile main.py\n",
        "#@title File: `main.py`\n",
        "import os\n",
        "import json\n",
        "import tensorflow as tf\n",
        "import mnist\n",
        "from multiprocessing import util\n",
        "\n",
        "per_worker_batch_size = 64\n",
        "tf_config = json.loads(os.environ['TF_CONFIG'])\n",
        "num_workers = len(tf_config['cluster']['worker'])\n",
        "global_batch_size = per_worker_batch_size * num_workers\n",
        "\n",
        "num_epochs = 3\n",
        "num_steps_per_epoch=70\n",
        "\n",
        "# Checkpoint saving and restoring\n",
        "def _is_chief(task_type, task_id, cluster_spec):\n",
        "  return (task_type is None\n",
        "          or task_type == 'chief'\n",
        "          or (task_type == 'worker'\n",
        "              and task_id == 0\n",
        "              and 'chief' not in cluster_spec.as_dict()))\n",
        "\n",
        "def _get_temp_dir(dirpath, task_id):\n",
        "  base_dirpath = 'workertemp_' + str(task_id)\n",
        "  temp_dir = os.path.join(dirpath, base_dirpath)\n",
        "  tf.io.gfile.makedirs(temp_dir)\n",
        "  return temp_dir\n",
        "\n",
        "def write_filepath(filepath, task_type, task_id, cluster_spec):\n",
        "  dirpath = os.path.dirname(filepath)\n",
        "  base = os.path.basename(filepath)\n",
        "  if not _is_chief(task_type, task_id, cluster_spec):\n",
        "    dirpath = _get_temp_dir(dirpath, task_id)\n",
        "  return os.path.join(dirpath, base)\n",
        "\n",
        "checkpoint_dir = os.path.join(util.get_temp_dir(), 'ckpt')\n",
        "\n",
        "# Define Strategy\n",
        "strategy = tf.distribute.MultiWorkerMirroredStrategy()\n",
        "\n",
        "with strategy.scope():\n",
        "  # Model building/compiling need to be within `tf.distribute.Strategy.scope`.\n",
        "  multi_worker_model = mnist.build_cnn_model()\n",
        "\n",
        "  multi_worker_dataset = strategy.distribute_datasets_from_function(\n",
        "      lambda input_context: mnist.dataset_fn(global_batch_size, input_context))\n",
        "  optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.001)\n",
        "  train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
        "      name='train_accuracy')\n",
        "\n",
        "@tf.function\n",
        "def train_step(iterator):\n",
        "  \"\"\"Training step function.\"\"\"\n",
        "\n",
        "  def step_fn(inputs):\n",
        "    \"\"\"Per-Replica step function.\"\"\"\n",
        "    x, y = inputs\n",
        "    with tf.GradientTape() as tape:\n",
        "      predictions = multi_worker_model(x, training=True)\n",
        "      per_example_loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "          from_logits=True,\n",
        "          reduction=tf.keras.losses.Reduction.NONE)(y, predictions)\n",
        "      loss = tf.nn.compute_average_loss(per_example_loss)\n",
        "      model_losses = multi_worker_model.losses\n",
        "      if model_losses:\n",
        "        loss += tf.nn.scale_regularization_loss(tf.add_n(model_losses))\n",
        "\n",
        "    grads = tape.gradient(loss, multi_worker_model.trainable_variables)\n",
        "    optimizer.apply_gradients(\n",
        "        zip(grads, multi_worker_model.trainable_variables))\n",
        "    train_accuracy.update_state(y, predictions)\n",
        "\n",
        "    return loss\n",
        "\n",
        "  per_replica_losses = strategy.run(step_fn, args=(next(iterator),))\n",
        "  return strategy.reduce(\n",
        "      tf.distribute.ReduceOp.SUM, per_replica_losses, axis=None)\n",
        "\n",
        "epoch = tf.Variable(\n",
        "    initial_value=tf.constant(0, dtype=tf.dtypes.int64), name='epoch')\n",
        "step_in_epoch = tf.Variable(\n",
        "    initial_value=tf.constant(0, dtype=tf.dtypes.int64),\n",
        "    name='step_in_epoch')\n",
        "\n",
        "task_type, task_id, cluster_spec = (strategy.cluster_resolver.task_type,\n",
        "                                    strategy.cluster_resolver.task_id,\n",
        "                                    strategy.cluster_resolver.cluster_spec())\n",
        "\n",
        "checkpoint = tf.train.Checkpoint(\n",
        "    model=multi_worker_model, epoch=epoch, step_in_epoch=step_in_epoch)\n",
        "\n",
        "write_checkpoint_dir = write_filepath(checkpoint_dir, task_type, task_id,\n",
        "                                      cluster_spec)\n",
        "checkpoint_manager = tf.train.CheckpointManager(\n",
        "    checkpoint, directory=write_checkpoint_dir, max_to_keep=1)\n",
        "\n",
        "# Restoring the checkpoint\n",
        "latest_checkpoint = tf.train.latest_checkpoint(checkpoint_dir)\n",
        "if latest_checkpoint:\n",
        "  checkpoint.restore(latest_checkpoint)\n",
        "\n",
        "# Resume our CTL training\n",
        "while epoch.numpy() < num_epochs:\n",
        "  iterator = iter(multi_worker_dataset)\n",
        "  total_loss = 0.0\n",
        "  num_batches = 0\n",
        "\n",
        "  while step_in_epoch.numpy() < num_steps_per_epoch:\n",
        "    total_loss += train_step(iterator)\n",
        "    num_batches += 1\n",
        "    step_in_epoch.assign_add(1)\n",
        "\n",
        "  train_loss = total_loss / num_batches\n",
        "  print('Epoch: %d, accuracy: %f, train_loss: %f.'\n",
        "                %(epoch.numpy(), train_accuracy.result(), train_loss))\n",
        "\n",
        "  train_accuracy.reset_states()\n",
        "\n",
        "  checkpoint_manager.save()\n",
        "  if not _is_chief(task_type, task_id, cluster_spec):\n",
        "    tf.io.gfile.rmtree(write_checkpoint_dir)\n",
        "\n",
        "  epoch.assign_add(1)\n",
        "  step_in_epoch.assign(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ItVOvPN1qnZ6"
      },
      "source": [
        "Agora, o diretório atual contém os dois arquivos do Python:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bi6x05Sr60O9"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "ls *.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmEEStPS6vR_"
      },
      "source": [
        "Então, serialize a variável `'TF_CONFIG'` como JSON e adicione-a às variáveis de ambiente:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9uu3g7vV7Bbt"
      },
      "outputs": [],
      "source": [
        "os.environ['TF_CONFIG'] = json.dumps(tf_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MsY3dQLK7jdf"
      },
      "source": [
        "Agora, você pode iniciar um processo de worker, que executará `main.py` e usará a variável `'TF_CONFIG'`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "txMXaq8d8N_S"
      },
      "outputs": [],
      "source": [
        "# first kill any previous runs\n",
        "%killbgscripts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qnSma_Ck7r-r"
      },
      "outputs": [],
      "source": [
        "%%bash --bg\n",
        "python main.py &> job_0.log"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZChyazqS7v0P"
      },
      "source": [
        "Veja algumas observações sobre o comando acima:\n",
        "\n",
        "1. Ele usa `%%bash`, que é um [“magic” dos notebooks](https://ipython.readthedocs.io/en/stable/interactive/magics.html) que executa alguns comandos bash.\n",
        "2. Ele usa o sinalizador `--bg` para executar o processo `bash` em segundo plano, pois esse worker não será encerrado. Ele aguarda todos os workers antes de iniciar.\n",
        "\n",
        "O processo do worker em segundo plano não exibe a saída nesse notebook. `&>` redireciona a saída para um arquivo para que você possa analisar o que aconteceu.\n",
        "\n",
        "Aguarde alguns segundos para o processo iniciar:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hm2yrULE9281"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "time.sleep(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFPoNxg_9_Mx"
      },
      "source": [
        "Agora, verifique a saída no arquivo de log do worker:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vZEOuVgQ9-hn"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "cat job_0.log"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqZhVF7L_KOy"
      },
      "source": [
        "A última linha do arquivo de log deve dizer: `Started server with target: grpc://localhost:12345` (Serviço iniciado com destino: grpc://localhost:12345). Agora, o primeiro worker está pronto e aguarda que todos os outros workers estejam prontos para prosseguir."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pi8vPNNA_l4a"
      },
      "source": [
        "Atualize `tf_config` para o processo do segundo worker prosseguir:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lAiYkkPu_Jqd"
      },
      "outputs": [],
      "source": [
        "tf_config['task']['index'] = 1\n",
        "os.environ['TF_CONFIG'] = json.dumps(tf_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0AshGVO0_x0w"
      },
      "source": [
        "Agora, inicie o segundo worker. O treinamento será iniciado, já que todos os workers estão ativos (então não há necessidade de colocar esse processo em segundo plano):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ESVtyQ9_xjx"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "python main.py > /dev/null 2>&1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hX4FA2O2AuAn"
      },
      "source": [
        "Se você verificar novamente os logs escritos pelo primeiro worker, notará que ele participou do treinamento do modelo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rc6hw3yTBKXX"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "cat job_0.log"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sG5_1UgrgniF"
      },
      "outputs": [],
      "source": [
        "# Delete the `'TF_CONFIG'`, and kill any background tasks so they don't affect the next section.\n",
        "os.environ.pop('TF_CONFIG', None)\n",
        "%killbgscripts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhxMXa0AaZkK"
      },
      "source": [
        "## Treinamento multiworker aprofundado\n",
        "\n",
        "Este tutorial demonstrou um fluxo de trabalho de loop de treinamento personalizado para a configuração multiworker. Estão disponíveis descrições detalhadas de outros tópicos no tutorial [Treinamento multiworker com o Keras (`tf.keras.Model.fit`)](multi_worker_with_keras.ipynb), aplicável a loops de treinamento personalizado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ega2hdOQEmy_"
      },
      "source": [
        "## Saiba mais\n",
        "\n",
        "1. O guia [Treinamento distribuído no TensorFlow](../../guide/distributed_training.ipynb) apresenta uma visão geral das estratégias de distribuição disponíveis.\n",
        "2. [Modelos oficiais](https://github.com/tensorflow/models/tree/master/official), muitos dos quais podem ser configurados para executarem diversas estratégias de distribuição.\n",
        "3. A [seção Desempenho](../../guide/function.ipynb) do guia do `tf.function` apresenta informações sobre outras estratégias e [ferramentas](../../guide/profiler.md) que você pode usar para otimizar o desempenho dos seus modelos do TensorFlow.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "multi_worker_with_ctl.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
