{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pL--_KGdYoBz"
      },
      "source": [
        "##### Copyright 2019 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "uBDvXpYzYnGj"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQzaEQuJiW_d"
      },
      "source": [
        "# TFRecord e tf.train.Example\n",
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>     <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/load_data/tfrecord\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver em TensorFlow.org</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/pt-br/tutorials/load_data/tfrecord.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Executar no Google Colab</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/pt-br/tutorials/load_data/tfrecord.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver fonte no GitHub</a>\n",
        "</td>\n",
        "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/pt-br/tutorials/load_data/tfrecord.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Baixar notebook</a>\n",
        "</td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3pkUd_9IZCFO"
      },
      "source": [
        "O TFRecord é um formato simples para armazenar uma sequência de registros binários.\n",
        "\n",
        "Os [buffers de protocolo](https://developers.google.com/protocol-buffers/) são uma biblioteca de várias plataformas e linguagens para a serialização eficiente de dados estruturados.\n",
        "\n",
        "As mensagens de protocolo são definidas por arquivos `.proto` e geralmente são a maneira mais fácil de entender um tipo de mensagem.\n",
        "\n",
        "`tf.train.Example` (ou protobuf) é um tipo de mensagem flexível que representa um mapeamento `{\"string\": value}`. Foi criado para o TensorFlow e é usado em APIs de alto nível, como o [TFX](https://www.tensorflow.org/tfx/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ac83J0QxjhFt"
      },
      "source": [
        "Este notebook mostra como criar, processar e usar a mensagem `tf.train.Example` e depois serializar, escrever e ler mensagens `tf.train.Example` de e para arquivos `.tfrecord`.\n",
        "\n",
        "Observação: embora sejam úteis, essas estruturas são opcionais. Não há necessidade de converter código existente para usar TFRecords, a menos que você esteja [usando o tf.data](https://www.tensorflow.org/guide/data) e a leitura dos dados ainda seja o gargalo do treinamento. Consulte dicas de desempenho do dataset no guia [Melhor desempenho com a API tf.data](https://www.tensorflow.org/guide/data_performance).\n",
        "\n",
        "Observação: em geral, você deve fragmentar seus dados em vários arquivos para paralelizar a I/O (em um ou mais hosts). A regra geral é ter pelo menos 10 vezes mais arquivos que o número de hosts lendo dados. Ao mesmo tempo, cada arquivo deve ser grande o suficiente (no mínimo 10 MB e de preferência maior que 100 MB) para você aproveitar a pré-busca de I/O. Por exemplo, digamos que você tenha `X` GB de dados e planeje treinar em até `N` hosts. O ideal é compartilhar os dados em ~`10*N` arquivos, desde que ~`X/(10*N)` seja maior que 10 MB (preferencialmente, maior que 100 MB). Se for menor que isso, talvez seja necessário criar menos fragmentos para equilibrar os benefícios do paralelismo e os benefícios da pré-busca de I/O."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WkRreBf1eDVc"
      },
      "source": [
        "## Configuração"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ja7sezsmnXph"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "import IPython.display as display"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5Kq88ccUWQV"
      },
      "source": [
        "## `tf.train.Example`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VrdQHgvNijTi"
      },
      "source": [
        "### Tipos de dados para `tf.train.Example`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZw57Qrn4CTE"
      },
      "source": [
        "Essencialmente, o `tf.train.Example` é um mapeamento de `{\"string\": tf.train.Feature}`.\n",
        "\n",
        "O tipo de mensagem `tf.train.Feature` aceita um dos três tipos a seguir (Consulte o [arquivo `.proto`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/example/feature.proto) para referência). A maioria dos outros tipos genéricos pode ser coagida em um destes:\n",
        "\n",
        "1. `tf.train.BytesList` (os seguintes tipos podem ser coagidos)\n",
        "\n",
        "- `string`\n",
        "- `byte`\n",
        "\n",
        "1. `tf.train.FloatList` (os seguintes tipos podem ser coagidos)\n",
        "\n",
        "- `float` (`float32`)\n",
        "- `double` (`float64`)\n",
        "\n",
        "1. `tf.train.Int64List` (os seguintes tipos podem ser coagidos)\n",
        "\n",
        "- `bool`\n",
        "- `enum`\n",
        "- `int32`\n",
        "- `uint32`\n",
        "- `int64`\n",
        "- `uint64`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_e3g9ExathXP"
      },
      "source": [
        "Para converter um tipo padrão do TensorFlow em um `tf.train.Feature` compatível com `tf.train.Example`, use as funções de atalho abaixo. Observe que cada função aceita um valor de entrada escalar e retorna um `tf.train.Feature` com um dos três tipos `list` acima:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mbsPOUpVtYxA"
      },
      "outputs": [],
      "source": [
        "# The following functions can be used to convert a value to a type compatible\n",
        "# with tf.train.Example.\n",
        "\n",
        "def _bytes_feature(value):\n",
        "  \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
        "  if isinstance(value, type(tf.constant(0))):\n",
        "    value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
        "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
        "\n",
        "def _float_feature(value):\n",
        "  \"\"\"Returns a float_list from a float / double.\"\"\"\n",
        "  return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
        "\n",
        "def _int64_feature(value):\n",
        "  \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
        "  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wst0v9O8hgzy"
      },
      "source": [
        "Observação: para simplicidade, este exemplo só usa entradas escalares. A maneira mais simples de lidar com características não escalares é usar `tf.io.serialize_tensor` para converter tensores em strings binárias. As strings são escalares no TensorFlow. Use `tf.io.parse_tensor` para converter a string binária de volta para um tensor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsMbkkC8xxtB"
      },
      "source": [
        "Confira abaixo alguns exemplos de como essas funções funcionam. Observe os tipos de entrada variáveis e os tipos de saída padronizados. Se o tipo de entrada para uma função não corresponder a um dos tipos que podem ser coagidos indicados acima, a função lançará uma exceção (por exemplo, `_int64_feature(1.0)` gerará um erro porque `1.0` é um float — portanto, deve ser usado com a função `_float_feature`):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hZzyLGr0u73y"
      },
      "outputs": [],
      "source": [
        "print(_bytes_feature(b'test_string'))\n",
        "print(_bytes_feature(u'test_bytes'.encode('utf-8')))\n",
        "\n",
        "print(_float_feature(np.exp(1)))\n",
        "\n",
        "print(_int64_feature(True))\n",
        "print(_int64_feature(1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nj1qpfQU5qmi"
      },
      "source": [
        "Todas as mensagens proto podem ser serializadas para uma string binária usando o método `.SerializeToString`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5afZkORT5pjm"
      },
      "outputs": [],
      "source": [
        "feature = _float_feature(np.exp(1))\n",
        "\n",
        "feature.SerializeToString()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "laKnw9F3hL-W"
      },
      "source": [
        "### Criando uma mensagem `tf.train.Example`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_MEnhxchQPC"
      },
      "source": [
        "Digamos que você queira criar uma mensagem `tf.train.Example` a partir de dados existentes. Na prática, o dataset pode vir de qualquer lugar, mas o procedimento de criar a mensagem `tf.train.Example` a partir de uma única observação será o mesmo:\n",
        "\n",
        "1. Em cada observação, cada valor precisa ser convertido em `tf.train.Feature` com um dos 3 tipos compatíveis, usando uma das funções acima.\n",
        "\n",
        "2. Você cria um mapa (dicionário) a partir da string de nome da característica para o valor da característica codificado produzido no nº 1.\n",
        "\n",
        "3. O mapa produzido na etapa 2 é convertido em uma [mensagem `Features`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/example/feature.proto#L85)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4EgFQ2uHtchc"
      },
      "source": [
        "Neste notebook, você criará um dataset usando o NumPy.\n",
        "\n",
        "Esse dataset terá 4 características:\n",
        "\n",
        "- uma característica booleana, `False` ou `True` com a mesma probabilidade\n",
        "- uma característica de número inteiro escolhida de maneira uniforme e aleatória de `[0, 5]`\n",
        "- uma característica de string gerada a partir de uma tabela de string ao usar a característica de número inteiro como um índice\n",
        "- uma característica float de uma distribuição normal padrão\n",
        "\n",
        "Considere um exemplo que consiste em 10 mil observações distribuídas de maneira independente e idêntica de cada uma das distribuições acima:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CnrguFAy3YQv"
      },
      "outputs": [],
      "source": [
        "# The number of observations in the dataset.\n",
        "n_observations = int(1e4)\n",
        "\n",
        "# Boolean feature, encoded as False or True.\n",
        "feature0 = np.random.choice([False, True], n_observations)\n",
        "\n",
        "# Integer feature, random from 0 to 4.\n",
        "feature1 = np.random.randint(0, 5, n_observations)\n",
        "\n",
        "# String feature.\n",
        "strings = np.array([b'cat', b'dog', b'chicken', b'horse', b'goat'])\n",
        "feature2 = strings[feature1]\n",
        "\n",
        "# Float feature, from a standard normal distribution.\n",
        "feature3 = np.random.randn(n_observations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGrscehJr7Jd"
      },
      "source": [
        "Cada um desses atributos pode ser coagido em um tipo compatível com `tf.train.Example` usando um `_bytes_feature`, `_float_feature` ou `_int64_feature`. Depois, é possível criar uma mensagem `tf.train.Example` a partir dessas características codificadas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RTCS49Ij_kUw"
      },
      "outputs": [],
      "source": [
        "def serialize_example(feature0, feature1, feature2, feature3):\n",
        "  \"\"\"\n",
        "  Creates a tf.train.Example message ready to be written to a file.\n",
        "  \"\"\"\n",
        "  # Create a dictionary mapping the feature name to the tf.train.Example-compatible\n",
        "  # data type.\n",
        "  feature = {\n",
        "      'feature0': _int64_feature(feature0),\n",
        "      'feature1': _int64_feature(feature1),\n",
        "      'feature2': _bytes_feature(feature2),\n",
        "      'feature3': _float_feature(feature3),\n",
        "  }\n",
        "\n",
        "  # Create a Features message using tf.train.Example.\n",
        "\n",
        "  example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
        "  return example_proto.SerializeToString()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XftzX9CN_uGT"
      },
      "source": [
        "Por exemplo, suponha que você tenha uma única observação do dataset, `[False, 4, bytes('goat'), 0.9876]`. Você pode criar e imprimir a mensagem `tf.train.Example` para essa observação usando `create_message()`. Cada observação será escrita como uma mensagem `Features` conforme acima. Observe que a [mensagem](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/example/example.proto#L88) `tf.train.Example` é apenas um wrapper da mensagem `Features`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N8BtSx2RjYcb"
      },
      "outputs": [],
      "source": [
        "# This is an example observation from the dataset.\n",
        "\n",
        "example_observation = []\n",
        "\n",
        "serialized_example = serialize_example(False, 4, b'goat', 0.9876)\n",
        "serialized_example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pbGATlG6u-4"
      },
      "source": [
        "Para decodificar a mensagem, use o método `tf.train.Example.FromString`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dGim-mEm6vit"
      },
      "outputs": [],
      "source": [
        "example_proto = tf.train.Example.FromString(serialized_example)\n",
        "example_proto"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6qxofy89obI"
      },
      "source": [
        "## Detalhes do formato TFRecords\n",
        "\n",
        "Um arquivo TFRecord contém uma sequência de registros. O arquivo só pode ser lido sequencialmente.\n",
        "\n",
        "Cada registro contém uma string de bytes, para a carga útil de dados, além do comprimento de dados, e hashes CRC-32C ([CRC de 32 bits](https://en.wikipedia.org/wiki/Cyclic_redundancy_check#CRC-32_algorithm) usando os hashes [polinomiais Castagnoli](https://en.wikipedia.org/wiki/Cyclic_redundancy_check#Standards_and_common_use)) para a verificação da integridade.\n",
        "\n",
        "Cada registro é armazenado nos seguintes formatos:\n",
        "\n",
        "```\n",
        "uint64 length\n",
        "uint32 masked_crc32_of_length\n",
        "byte   data[length]\n",
        "uint32 masked_crc32_of_data\n",
        "```\n",
        "\n",
        "Os registros são concatenados para produzir um arquivo. Os CRCs estão [descritos aqui](https://en.wikipedia.org/wiki/Cyclic_redundancy_check), e a máscara de um CRC é:\n",
        "\n",
        "```\n",
        "masked_crc = ((crc &gt;&gt; 15) | (crc &lt;&lt; 17)) + 0xa282ead8ul\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0iHagLQCJv6"
      },
      "source": [
        "Observação: não há nenhum requisito para usar o `tf.train.Example` nos arquivos TFRecord. `tf.train.Example` é apenas um método de serialização de dicionários para strings de bytes. Qualquer string de bytes que possa ser decodificada no TensorFlow pode ser armazenada em um arquivo TFRecord. Exemplos incluem: linhas de texto, JSON (usando `tf.io.decode_json_example`), dados de imagens codificados ou `tf.Tensors` serializados (usando `tf.io.serialize_tensor`/`tf.io.parse_tensor`). Veja mais opções no módulo `tf.io`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-Hjmee-fbLH"
      },
      "source": [
        "## Arquivos TFRecord usando `tf.data`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmehkCCT81Ez"
      },
      "source": [
        "O módulo `tf.data` também fornece ferramentas para ler e escrever dados no TensorFlow."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FISEuz8ubu3"
      },
      "source": [
        "### Escrevendo um arquivo TFRecord\n",
        "\n",
        "A maneira mais fácil de colocar os dados em um dataset é usando o método `from_tensor_slices`.\n",
        "\n",
        "Aplicado a um array, ele retorna um dataset de escalares:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mXeaukvwu5_-"
      },
      "outputs": [],
      "source": [
        "tf.data.Dataset.from_tensor_slices(feature1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-q0VKyZvcad"
      },
      "source": [
        "Aplicado a uma tupla de arrays, ele retorna um dataset de tuplas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H5sWyu1kxnvg"
      },
      "outputs": [],
      "source": [
        "features_dataset = tf.data.Dataset.from_tensor_slices((feature0, feature1, feature2, feature3))\n",
        "features_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m1C-t71Nywze"
      },
      "outputs": [],
      "source": [
        "# Use `take(1)` to only pull one example from the dataset.\n",
        "for f0,f1,f2,f3 in features_dataset.take(1):\n",
        "  print(f0)\n",
        "  print(f1)\n",
        "  print(f2)\n",
        "  print(f3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhIe63awyZYd"
      },
      "source": [
        "Use o método `tf.data.Dataset.map` para aplicar uma função a cada elemento de um `Dataset`.\n",
        "\n",
        "A função mapeada precisa operar no modo grafo do TensorFlow — ela precisa operar com e retornar `tf.Tensors`. Uma função que não seja de tensores, como `serialize_example`, pode ser empacotada com `tf.py_function` para torná-la compatível.\n",
        "\n",
        "Ao usar `tf.py_function`, é necessário especificar as informações de formato e tipo indisponíveis de outra maneira:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "apB5KYrJzjPI"
      },
      "outputs": [],
      "source": [
        "def tf_serialize_example(f0,f1,f2,f3):\n",
        "  tf_string = tf.py_function(\n",
        "    serialize_example,\n",
        "    (f0, f1, f2, f3),  # Pass these args to the above function.\n",
        "    tf.string)      # The return type is `tf.string`.\n",
        "  return tf.reshape(tf_string, ()) # The result is a scalar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lHFjW4u4Npz9"
      },
      "outputs": [],
      "source": [
        "tf_serialize_example(f0, f1, f2, f3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrFZ9avE3HUF"
      },
      "source": [
        "Aplique essa função a cada elemento do dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VDeqYVbW3ww9"
      },
      "outputs": [],
      "source": [
        "serialized_features_dataset = features_dataset.map(tf_serialize_example)\n",
        "serialized_features_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DlDfuh46bRf6"
      },
      "outputs": [],
      "source": [
        "def generator():\n",
        "  for features in features_dataset:\n",
        "    yield serialize_example(*features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iv9oXKrcbhvX"
      },
      "outputs": [],
      "source": [
        "serialized_features_dataset = tf.data.Dataset.from_generator(\n",
        "    generator, output_types=tf.string, output_shapes=())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dqz8C4D5cIj9"
      },
      "outputs": [],
      "source": [
        "serialized_features_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6lw5VYpjZZC"
      },
      "source": [
        "E os escreva em um arquivo TFRecord:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vP1VgTO44UIE"
      },
      "outputs": [],
      "source": [
        "filename = 'test.tfrecord'\n",
        "writer = tf.data.experimental.TFRecordWriter(filename)\n",
        "writer.write(serialized_features_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aV0GQhV8tmp"
      },
      "source": [
        "### Lendo um arquivo TFRecord"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3J5D4gcSy8N"
      },
      "source": [
        "Você também pode ler o arquivo TFRecord usando a classe `tf.data.TFRecordDataset`.\n",
        "\n",
        "Encontre mais informações sobre como consumir arquivos TFRecord usando o `tf.data` no guia [tf.data: crie pipelines de entrada do TensorFlow](https://www.tensorflow.org/guide/data#consuming_tfrecord_data).\n",
        "\n",
        "Usar `TFRecordDataset`s pode ser útil para padronizar os dados de entrada e otimizar o desempenho."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6OjX6UZl-bHC"
      },
      "outputs": [],
      "source": [
        "filenames = [filename]\n",
        "raw_dataset = tf.data.TFRecordDataset(filenames)\n",
        "raw_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_EQ9i2E_-Fz"
      },
      "source": [
        "Neste ponto, o dataset contém mensagens `tf.train.Example` serializadas. Quando elas são iteradas, retornam tensores de strings escalares.\n",
        "\n",
        "Use o método `.take` para mostrar apenas os 10 primeiros registros.\n",
        "\n",
        "Observação: a iteração de `tf.data.Dataset` só funciona com a eager execution ativada."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hxVXpLz_AJlm"
      },
      "outputs": [],
      "source": [
        "for raw_record in raw_dataset.take(10):\n",
        "  print(repr(raw_record))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-6oNzM4luFQ"
      },
      "source": [
        "Esses tensores podem ser processados usando a função abaixo. Observe que `feature_description` é necessário porque `tf.data.Dataset`s usam a execução de grafo e precisam dessa descrição para criar a assinatura de formato e tipo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zQjbIR1nleiy"
      },
      "outputs": [],
      "source": [
        "# Create a description of the features.\n",
        "feature_description = {\n",
        "    'feature0': tf.io.FixedLenFeature([], tf.int64, default_value=0),\n",
        "    'feature1': tf.io.FixedLenFeature([], tf.int64, default_value=0),\n",
        "    'feature2': tf.io.FixedLenFeature([], tf.string, default_value=''),\n",
        "    'feature3': tf.io.FixedLenFeature([], tf.float32, default_value=0.0),\n",
        "}\n",
        "\n",
        "def _parse_function(example_proto):\n",
        "  # Parse the input `tf.train.Example` proto using the dictionary above.\n",
        "  return tf.io.parse_single_example(example_proto, feature_description)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWETjUqhEQZf"
      },
      "source": [
        "Como alternativa, use `tf.parse_example` para processar o lote inteiro de uma vez. Aplique essa função a cada item no dataset usando o método `tf.data.Dataset.map`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Ob7D-zmBm1w"
      },
      "outputs": [],
      "source": [
        "parsed_dataset = raw_dataset.map(_parse_function)\n",
        "parsed_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNV-XclGnOvn"
      },
      "source": [
        "Use a eager execution para mostrar as observações no dataset. Há 10.000 observações nesse dataset, mas você só mostrará as 10 primeiras. Os dados são exibidos como um dicionário de características. Cada item é um `tf.Tensor`, e o elemento `numpy` desse tensor mostra o valor da característica:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x2LT2JCqhoD_"
      },
      "outputs": [],
      "source": [
        "for parsed_record in parsed_dataset.take(10):\n",
        "  print(repr(parsed_record))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cig9EodTlDmg"
      },
      "source": [
        "Aqui, a função `tf.parse_example` descompacta os campos `tf.train.Example` em tensores padrão."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyg1g3gU7DNn"
      },
      "source": [
        "## Arquivos TFRecord em Python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FXG3miA7Kf1"
      },
      "source": [
        "O módulo `tf.io` também contém funções puras do Python para ler e escrever arquivos TFRecord."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKn5uql2lAaN"
      },
      "source": [
        "### Escrevendo um arquivo TFRecord"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNW_FA-GQWXs"
      },
      "source": [
        "Em seguida, escreva as 10.000 observações no arquivo `test.tfrecord`. Cada observação é convertida em uma mensagem `tf.train.Example` e depois escrita no arquivo. Em seguida, você pode verificar se o arquivo `test.tfrecord` foi criado:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MKPHzoGv7q44"
      },
      "outputs": [],
      "source": [
        "# Write the `tf.train.Example` observations to the file.\n",
        "with tf.io.TFRecordWriter(filename) as writer:\n",
        "  for i in range(n_observations):\n",
        "    example = serialize_example(feature0[i], feature1[i], feature2[i], feature3[i])\n",
        "    writer.write(example)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EjdFHHJMpUUo"
      },
      "outputs": [],
      "source": [
        "!du -sh {filename}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2osVRnYNni-E"
      },
      "source": [
        "### Lendo um arquivo TFRecord\n",
        "\n",
        "Esses tensores serializados podem ser processados facilmente usando `tf.train.Example.ParseFromString`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U3tnd3LerOtV"
      },
      "outputs": [],
      "source": [
        "filenames = [filename]\n",
        "raw_dataset = tf.data.TFRecordDataset(filenames)\n",
        "raw_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nsEAACHcnm3f"
      },
      "outputs": [],
      "source": [
        "for raw_record in raw_dataset.take(1):\n",
        "  example = tf.train.Example()\n",
        "  example.ParseFromString(raw_record.numpy())\n",
        "  print(example)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhnZZmhm1miG"
      },
      "source": [
        "Isso retorna um proto `tf.train.Example` que é difícil de ser usado no seu estado, mas é basicamente uma representação de:\n",
        "\n",
        "```\n",
        "Dict[str,\n",
        "     Union[List[float],\n",
        "           List[int],\n",
        "           List[str]]]\n",
        "```\n",
        "\n",
        "O código a seguir converte manualmente o `Example` em um dicionário de arrays do NumPy, sem usar o TensorFlow Ops. Confira mais detalhes [no arquivo PROTO](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/example/feature.proto)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ziv9tiNE1l6J"
      },
      "outputs": [],
      "source": [
        "result = {}\n",
        "# example.features.feature is the dictionary\n",
        "for key, feature in example.features.feature.items():\n",
        "  # The values are the Feature objects which contain a `kind` which contains:\n",
        "  # one of three fields: bytes_list, float_list, int64_list\n",
        "\n",
        "  kind = feature.WhichOneof('kind')\n",
        "  result[key] = np.array(getattr(feature, kind).value)\n",
        "\n",
        "result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0tFDrwdoj3q"
      },
      "source": [
        "## Tutorial: como ler e escrever os dados de imagem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjN2LFxFpcR9"
      },
      "source": [
        "Este é um exemplo de como ler e escrever dados de imagem usando TFRecords do começo ao fim. Usando uma imagem como dados de entrada, você escreverá os dados como um arquivo TFRecord, lerá o arquivo novamente e exibirá a imagem.\n",
        "\n",
        "Isso pode ser útil se, por exemplo, você quiser usar vários modelos no mesmo dataset de entrada. Em vez de armazenar os dados brutos da imagem, eles podem ser processados no formato TFRecords, que pode ser usado em processamento e modelagem adicionais.\n",
        "\n",
        "Primeiro, vamos baixar [esta imagem](https://commons.wikimedia.org/wiki/File:Felis_catus-cat_on_snow.jpg) de um gato na neve e [esta foto](https://upload.wikimedia.org/wikipedia/commons/f/fe/New_East_River_Bridge_from_Brooklyn_det.4a09796u.jpg) da Ponte Williamsburg, em Nova York, sendo construída."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Lk2qrKvN0yu"
      },
      "source": [
        "### Busque as imagens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3a0fmwg8lHdF"
      },
      "outputs": [],
      "source": [
        "cat_in_snow  = tf.keras.utils.get_file(\n",
        "    '320px-Felis_catus-cat_on_snow.jpg',\n",
        "    'https://storage.googleapis.com/download.tensorflow.org/example_images/320px-Felis_catus-cat_on_snow.jpg')\n",
        "\n",
        "williamsburg_bridge = tf.keras.utils.get_file(\n",
        "    '194px-New_East_River_Bridge_from_Brooklyn_det.4a09796u.jpg',\n",
        "    'https://storage.googleapis.com/download.tensorflow.org/example_images/194px-New_East_River_Bridge_from_Brooklyn_det.4a09796u.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7aJJh7vENeE4"
      },
      "outputs": [],
      "source": [
        "display.display(display.Image(filename=cat_in_snow))\n",
        "display.display(display.HTML('Image cc-by: <a \"href=https://commons.wikimedia.org/wiki/File:Felis_catus-cat_on_snow.jpg\">Von.grzanka</a>'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KkW0uuhcXZqA"
      },
      "outputs": [],
      "source": [
        "display.display(display.Image(filename=williamsburg_bridge))\n",
        "display.display(display.HTML('<a \"href=https://commons.wikimedia.org/wiki/File:New_East_River_Bridge_from_Brooklyn_det.4a09796u.jpg\">From Wikimedia</a>'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VSOgJSwoN5TQ"
      },
      "source": [
        "### Escreva o arquivo TFRecord"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Azx83ryQEU6T"
      },
      "source": [
        "Como antes, codifique as características como tipos compatíveis com `tf.train.Example`. Isso armazena a característica da string de imagem bruta, além da altura, largura, profundidade e da característica `label` arbitrária. A última é usada quando você escreve o arquivo para distinguir entre a imagem de um gato e a imagem de uma ponte. Use `0` para a imagem do gato e `1` para a imagem da ponte:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kC4TS1ZEONHr"
      },
      "outputs": [],
      "source": [
        "image_labels = {\n",
        "    cat_in_snow : 0,\n",
        "    williamsburg_bridge : 1,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c5njMSYNEhNZ"
      },
      "outputs": [],
      "source": [
        "# This is an example, just using the cat image.\n",
        "image_string = open(cat_in_snow, 'rb').read()\n",
        "\n",
        "label = image_labels[cat_in_snow]\n",
        "\n",
        "# Create a dictionary with features that may be relevant.\n",
        "def image_example(image_string, label):\n",
        "  image_shape = tf.io.decode_jpeg(image_string).shape\n",
        "\n",
        "  feature = {\n",
        "      'height': _int64_feature(image_shape[0]),\n",
        "      'width': _int64_feature(image_shape[1]),\n",
        "      'depth': _int64_feature(image_shape[2]),\n",
        "      'label': _int64_feature(label),\n",
        "      'image_raw': _bytes_feature(image_string),\n",
        "  }\n",
        "\n",
        "  return tf.train.Example(features=tf.train.Features(feature=feature))\n",
        "\n",
        "for line in str(image_example(image_string, label)).split('\\n')[:15]:\n",
        "  print(line)\n",
        "print('...')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2G_o3O9MN0Qx"
      },
      "source": [
        "Observe que todas as características estão agora armazenadas na mensagem `tf.train.Example`. Em seguida, funcionalize o código acima e escreva as mensagens de exemplo para um arquivo chamado `images.tfrecords`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qcw06lQCOCZU"
      },
      "outputs": [],
      "source": [
        "# Write the raw image files to `images.tfrecords`.\n",
        "# First, process the two images into `tf.train.Example` messages.\n",
        "# Then, write to a `.tfrecords` file.\n",
        "record_file = 'images.tfrecords'\n",
        "with tf.io.TFRecordWriter(record_file) as writer:\n",
        "  for filename, label in image_labels.items():\n",
        "    image_string = open(filename, 'rb').read()\n",
        "    tf_example = image_example(image_string, label)\n",
        "    writer.write(tf_example.SerializeToString())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yJrTe6tHPCfs"
      },
      "outputs": [],
      "source": [
        "!du -sh {record_file}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJSsCkZLPH6K"
      },
      "source": [
        "### Leia o arquivo TFRecord\n",
        "\n",
        "Agora você tem o arquivo — `images.tfrecords` — e pode iterar os registros nele para ler o que você escreveu. Considerando que, nesse exemplo, você só reproduzirá a imagem, a única característica de que você precisará é a string de imagem bruta. Faça a extração dela usando os getters descritos acima, especificamente `example.features.feature['image_raw'].bytes_list.value[0]`. Você também pode usar os rótulos para determinar qual registro é o gato e qual é a ponte:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M6Cnfd3cTKHN"
      },
      "outputs": [],
      "source": [
        "raw_image_dataset = tf.data.TFRecordDataset('images.tfrecords')\n",
        "\n",
        "# Create a dictionary describing the features.\n",
        "image_feature_description = {\n",
        "    'height': tf.io.FixedLenFeature([], tf.int64),\n",
        "    'width': tf.io.FixedLenFeature([], tf.int64),\n",
        "    'depth': tf.io.FixedLenFeature([], tf.int64),\n",
        "    'label': tf.io.FixedLenFeature([], tf.int64),\n",
        "    'image_raw': tf.io.FixedLenFeature([], tf.string),\n",
        "}\n",
        "\n",
        "def _parse_image_function(example_proto):\n",
        "  # Parse the input tf.train.Example proto using the dictionary above.\n",
        "  return tf.io.parse_single_example(example_proto, image_feature_description)\n",
        "\n",
        "parsed_image_dataset = raw_image_dataset.map(_parse_image_function)\n",
        "parsed_image_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0PEEFPk4NEg1"
      },
      "source": [
        "Recupere as imagens do arquivo TFRecord:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yZf8jOyEIjSF"
      },
      "outputs": [],
      "source": [
        "for image_features in parsed_image_dataset:\n",
        "  image_raw = image_features['image_raw'].numpy()\n",
        "  display.display(display.Image(data=image_raw))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "pL--_KGdYoBz"
      ],
      "name": "tfrecord.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
