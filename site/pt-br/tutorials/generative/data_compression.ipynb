{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tce3stUlHN0L"
      },
      "source": [
        "##### Copyright 2022 The TensorFlow Compression Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tuOe1ymfHZPu"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFdPvlXBOdUN"
      },
      "source": [
        "# Compactação de dados aprendidos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfBg1C5NB3X0"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>     <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/generative/data_compression\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver em TensorFlow.org</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/pt-br/tutorials/generative/data_compression.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Executar no Google Colab</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/pt-br/tutorials/generative/data_compression.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver fonte no GitHub</a>\n",
        "</td>\n",
        "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/pt-br/tutorials/generative/data_compression.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Baixar notebook</a>\n",
        "</td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHxb-dlhMIzW"
      },
      "source": [
        "## Visão geral\n",
        "\n",
        "Este notebook mostra como fazer uma compactação de dados com perda usando redes neurais e o [TensorFlow Compression](https://github.com/tensorflow/compression).\n",
        "\n",
        "A compactação com perda envolve equilibrar a **taxa** – o número esperado de bits necessários para codificar uma amostra – e a **distorção** – o erro esperado na reconstrução da amostra.\n",
        "\n",
        "Os exemplos abaixo usam um modelo tipo autoencoder para compactar imagens do dataset MNIST. O método baseia-se no artigo [Compactação de imagens de ponta a ponta](https://arxiv.org/abs/1611.01704).\n",
        "\n",
        "Confira mais detalhes sobre a compactação de dados aprendidos [neste artigo](https://arxiv.org/abs/2007.03034), criado para quem já conhece a compactação de dados clássica, ou [nesta pesquisa](https://arxiv.org/abs/2202.06533), para um público de aprendizado de máquina.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUXex9ctTuDB"
      },
      "source": [
        "## Configuração\n",
        "\n",
        "Instale o TensorFlow Compression pelo `pip`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K489KsEgxuLI"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "# Installs the latest version of TFC compatible with the installed TF version.\n",
        "\n",
        "read MAJOR MINOR <<< \"$(pip show tensorflow | perl -p -0777 -e 's/.*Version: (\\d+)\\.(\\d+).*/\\1 \\2/sg')\"\n",
        "pip install \"tensorflow-compression<$MAJOR.$(($MINOR+1))\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfVAmHCVxpTS"
      },
      "source": [
        "Importe as dependências de biblioteca."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IqR2PQG4ZaZ0"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import tensorflow_compression as tfc\n",
        "import tensorflow_datasets as tfds\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsncKT2iymgQ"
      },
      "source": [
        "## Definir o modelo do treinador\n",
        "\n",
        "Como o modelo parece um autoencoder e precisamos realizar um conjunto diferente de funções durante o treinamento e a inferência, a configuração é um pouco diferente de um classificador, por exemplo.\n",
        "\n",
        "O modelo do treinamento é composto por três partes:\n",
        "\n",
        "- A transformação de **análise** (ou encoder), convertendo a imagem em um espaço latente.\n",
        "- A transformação de **síntese** (ou decoder), convertendo o espaço latente de volta no espaço de imagem.\n",
        "- Um modelo de **prior** e entropia, que modela as probabilidades marginais dos latentes.\n",
        "\n",
        "Primeiro, defina as transformações:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8yZESLgW-vp1"
      },
      "outputs": [],
      "source": [
        "def make_analysis_transform(latent_dims):\n",
        "  \"\"\"Creates the analysis (encoder) transform.\"\"\"\n",
        "  return tf.keras.Sequential([\n",
        "      tf.keras.layers.Conv2D(\n",
        "          20, 5, use_bias=True, strides=2, padding=\"same\",\n",
        "          activation=\"leaky_relu\", name=\"conv_1\"),\n",
        "      tf.keras.layers.Conv2D(\n",
        "          50, 5, use_bias=True, strides=2, padding=\"same\",\n",
        "          activation=\"leaky_relu\", name=\"conv_2\"),\n",
        "      tf.keras.layers.Flatten(),\n",
        "      tf.keras.layers.Dense(\n",
        "          500, use_bias=True, activation=\"leaky_relu\", name=\"fc_1\"),\n",
        "      tf.keras.layers.Dense(\n",
        "          latent_dims, use_bias=True, activation=None, name=\"fc_2\"),\n",
        "  ], name=\"analysis_transform\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2sHdYBzF2xcu"
      },
      "outputs": [],
      "source": [
        "def make_synthesis_transform():\n",
        "  \"\"\"Creates the synthesis (decoder) transform.\"\"\"\n",
        "  return tf.keras.Sequential([\n",
        "      tf.keras.layers.Dense(\n",
        "          500, use_bias=True, activation=\"leaky_relu\", name=\"fc_1\"),\n",
        "      tf.keras.layers.Dense(\n",
        "          2450, use_bias=True, activation=\"leaky_relu\", name=\"fc_2\"),\n",
        "      tf.keras.layers.Reshape((7, 7, 50)),\n",
        "      tf.keras.layers.Conv2DTranspose(\n",
        "          20, 5, use_bias=True, strides=2, padding=\"same\",\n",
        "          activation=\"leaky_relu\", name=\"conv_1\"),\n",
        "      tf.keras.layers.Conv2DTranspose(\n",
        "          1, 5, use_bias=True, strides=2, padding=\"same\",\n",
        "          activation=\"leaky_relu\", name=\"conv_2\"),\n",
        "  ], name=\"synthesis_transform\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYC8tHhkxTlK"
      },
      "source": [
        "O treinador armazena uma instância das duas transformações, bem como os parâmetros do prior.\n",
        "\n",
        "Seu método `call` é configurado para computar:\n",
        "\n",
        "- A **taxa**, uma estimativa do número de bits necessários para representar o lote de dígitos.\n",
        "- A **distorção**, a diferença absoluta média entre os pixels dos dígitos originais e suas reconstruções.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ROn2DbzsBirI"
      },
      "outputs": [],
      "source": [
        "class MNISTCompressionTrainer(tf.keras.Model):\n",
        "  \"\"\"Model that trains a compressor/decompressor for MNIST.\"\"\"\n",
        "\n",
        "  def __init__(self, latent_dims):\n",
        "    super().__init__()\n",
        "    self.analysis_transform = make_analysis_transform(latent_dims)\n",
        "    self.synthesis_transform = make_synthesis_transform()\n",
        "    self.prior_log_scales = tf.Variable(tf.zeros((latent_dims,)))\n",
        "\n",
        "  @property\n",
        "  def prior(self):\n",
        "    return tfc.NoisyLogistic(loc=0., scale=tf.exp(self.prior_log_scales))\n",
        "\n",
        "  def call(self, x, training):\n",
        "    \"\"\"Computes rate and distortion losses.\"\"\"\n",
        "    # Ensure inputs are floats in the range (0, 1).\n",
        "    x = tf.cast(x, self.compute_dtype) / 255.\n",
        "    x = tf.reshape(x, (-1, 28, 28, 1))\n",
        "\n",
        "    # Compute latent space representation y, perturb it and model its entropy,\n",
        "    # then compute the reconstructed pixel-level representation x_hat.\n",
        "    y = self.analysis_transform(x)\n",
        "    entropy_model = tfc.ContinuousBatchedEntropyModel(\n",
        "        self.prior, coding_rank=1, compression=False)\n",
        "    y_tilde, rate = entropy_model(y, training=training)\n",
        "    x_tilde = self.synthesis_transform(y_tilde)\n",
        "\n",
        "    # Average number of bits per MNIST digit.\n",
        "    rate = tf.reduce_mean(rate)\n",
        "\n",
        "    # Mean absolute difference across pixels.\n",
        "    distortion = tf.reduce_mean(abs(x - x_tilde))\n",
        "\n",
        "    return dict(rate=rate, distortion=distortion)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEXbp9RV3kRX"
      },
      "source": [
        "### Computar a taxa e a distorção\n",
        "\n",
        "Mostraremos o passo a passo, usando uma imagem do conjunto de treinamento. Carregue o dataset MNIST para treinamento e validação:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7FV99WTrIBen"
      },
      "outputs": [],
      "source": [
        "training_dataset, validation_dataset = tfds.load(\n",
        "    \"mnist\",\n",
        "    split=[\"train\", \"test\"],\n",
        "    shuffle_files=True,\n",
        "    as_supervised=True,\n",
        "    with_info=False,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwKgNTg_QfjH"
      },
      "source": [
        "Extraia uma imagem $x$:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O-BSdeHcPBBf"
      },
      "outputs": [],
      "source": [
        "(x, _), = validation_dataset.take(1)\n",
        "\n",
        "plt.imshow(tf.squeeze(x))\n",
        "print(f\"Data type: {x.dtype}\")\n",
        "print(f\"Shape: {x.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8IvuFkrRJIa"
      },
      "source": [
        "Para obter a representação latente $y$, precisamos convertê-la em `float32`, adicionar uma dimensão de lote e passá-la pela transformação de análise."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jA0DOWq23lEq"
      },
      "outputs": [],
      "source": [
        "x = tf.cast(x, tf.float32) / 255.\n",
        "x = tf.reshape(x, (-1, 28, 28, 1))\n",
        "y = make_analysis_transform(10)(x)\n",
        "\n",
        "print(\"y:\", y)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTojJQvZT8SX"
      },
      "source": [
        "Os latentes serão quantizados no momento do teste. Para modelar de uma maneira diferenciável durante o treinamento, adicionamos ruído uniforme no intervalo $(-.5, .5)$ e chamamos o resultado de $\\tilde y$. Essa é a mesma terminologia usada no artigo [Compactação de imagens de ponta a ponta](https://arxiv.org/abs/1611.01704)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Spr3503OUOFQ"
      },
      "outputs": [],
      "source": [
        "y_tilde = y + tf.random.uniform(y.shape, -.5, .5)\n",
        "\n",
        "print(\"y_tilde:\", y_tilde)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hRN89R7SA3U"
      },
      "source": [
        "O “prior” é uma densidade de probabilidade que treinamos para modelar a distribuição marginal dos latentes com ruído. Por exemplo, poderia ser um conjunto de [distribuições logísticas](https://en.wikipedia.org/wiki/Logistic_distribution) independentes com escalas diferentes para cada dimensão de latente. `tfc.NoisyLogistic` leva em consideração que os latentes têm ruído aditivo. À medida que a escala se aproxima de zero, uma distribuição logística se aproxima de um delta de Dirac (pico), mas o ruído adicionado faz a distribuição “com ruído” se aproximar de uma distribuição uniforme."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2tmA1Bw7ReMY"
      },
      "outputs": [],
      "source": [
        "prior = tfc.NoisyLogistic(loc=0., scale=tf.linspace(.01, 2., 10))\n",
        "\n",
        "_ = tf.linspace(-6., 6., 501)[:, None]\n",
        "plt.plot(_, prior.prob(_));\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NSWtBZmUvVY"
      },
      "source": [
        "Durante o treinamento, `tfc.ContinuousBatchedEntropyModel` adiciona ruído uniforme e usa o ruído e o prior para computar um limite superior (diferenciável) da taxa (o número médio de bits necessários para codificar a representação latente). Esse limite pode ser minimizado como uma perda."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hFuGlyJuThBC"
      },
      "outputs": [],
      "source": [
        "entropy_model = tfc.ContinuousBatchedEntropyModel(\n",
        "    prior, coding_rank=1, compression=False)\n",
        "y_tilde, rate = entropy_model(y, training=True)\n",
        "\n",
        "print(\"rate:\", rate)\n",
        "print(\"y_tilde:\", y_tilde)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cyr8DGgmWd32"
      },
      "source": [
        "Por fim, os latentes com ruído são passados de volta pela transformação de síntese para produzir uma reconstrução da imagem $\\tilde x$. A distorção é o erro entre a imagem original e a reconstrução. Obviamente, com as transformações não treinadas, a reconstrução não é muito útil."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gtmI0xGEVym0"
      },
      "outputs": [],
      "source": [
        "x_tilde = make_synthesis_transform()(y_tilde)\n",
        "\n",
        "# Mean absolute difference across pixels.\n",
        "distortion = tf.reduce_mean(abs(x - x_tilde))\n",
        "print(\"distortion:\", distortion)\n",
        "\n",
        "x_tilde = tf.saturate_cast(x_tilde[0] * 255, tf.uint8)\n",
        "plt.imshow(tf.squeeze(x_tilde))\n",
        "print(f\"Data type: {x_tilde.dtype}\")\n",
        "print(f\"Shape: {x_tilde.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVz3I7E8ecij"
      },
      "source": [
        "Para cada lote de dígitos, uma chamada a `MNISTCompressionTrainer` produz a taxa e a distorção como uma média para esse lote:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ICJnjj1LeB8L"
      },
      "outputs": [],
      "source": [
        "(example_batch, _), = validation_dataset.batch(32).take(1)\n",
        "trainer = MNISTCompressionTrainer(10)\n",
        "example_output = trainer(example_batch)\n",
        "\n",
        "print(\"rate: \", example_output[\"rate\"])\n",
        "print(\"distortion: \", example_output[\"distortion\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgdfRtmee5Mn"
      },
      "source": [
        "Na próxima seção, vamos configurar o modelo para fazer o método do gradiente descendente nessas duas perdas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKGVwv5MAq6w"
      },
      "source": [
        "## Treinar o modelo\n",
        "\n",
        "Compilamos o treinador de uma forma que ele otimiza a taxa-distorção de Lagrange, ou seja, uma soma da taxa e da distorção, em que um dos termos é ponderado pelo parâmetro de Lagrange $\\lambda$.\n",
        "\n",
        "Essa função de perda afeta partes diferentes do modelo de forma diferente:\n",
        "\n",
        "- A transformação de análise é treinada para produzir uma representação latente que atinge o equilíbrio desejado entre taxa e distorção.\n",
        "- A transformação de síntese é treinada para minimizar a distorção, dada a representação latente.\n",
        "- Os parâmetros do prior são treinados para minimizar a taxa, dada a representação latente. Isso é idêntico a colocar o prior na distribuição marginal de latentes quanto à verossimilhança máxima."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k5mm1aDkcgAf"
      },
      "outputs": [],
      "source": [
        "def pass_through_loss(_, x):\n",
        "  # Since rate and distortion are unsupervised, the loss doesn't need a target.\n",
        "  return x\n",
        "\n",
        "def make_mnist_compression_trainer(lmbda, latent_dims=50):\n",
        "  trainer = MNISTCompressionTrainer(latent_dims)\n",
        "  trainer.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "    # Just pass through rate and distortion as losses/metrics.\n",
        "    loss=dict(rate=pass_through_loss, distortion=pass_through_loss),\n",
        "    metrics=dict(rate=pass_through_loss, distortion=pass_through_loss),\n",
        "    loss_weights=dict(rate=1., distortion=lmbda),\n",
        "  )\n",
        "  return trainer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPwd4DTs3Mfr"
      },
      "source": [
        "Agora, treine o modelo. Anotações humanas não são necessárias aqui, já que queremos compactar as imagens, então as colocamos em um `map` e adicionamos alvos “simulados” para a taxa e a distorção."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QNBpCTgzAV7M"
      },
      "outputs": [],
      "source": [
        "def add_rd_targets(image, label):\n",
        "  # Training is unsupervised, so labels aren't necessary here. However, we\n",
        "  # need to add \"dummy\" targets for rate and distortion.\n",
        "  return image, dict(rate=0., distortion=0.)\n",
        "\n",
        "def train_mnist_model(lmbda):\n",
        "  trainer = make_mnist_compression_trainer(lmbda)\n",
        "  trainer.fit(\n",
        "      training_dataset.map(add_rd_targets).batch(128).prefetch(8),\n",
        "      epochs=15,\n",
        "      validation_data=validation_dataset.map(add_rd_targets).batch(128).cache(),\n",
        "      validation_freq=1,\n",
        "      verbose=1,\n",
        "  )\n",
        "  return trainer\n",
        "\n",
        "trainer = train_mnist_model(lmbda=2000)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Td4xuttmCd7T"
      },
      "source": [
        "## Compactar algumas imagens do MNIST\n",
        "\n",
        "Para a compactação e descompactação no momento do teste, dividimos o modelo treinado em duas partes:\n",
        "\n",
        "- O lado do encoder é composto pela transformação de análise e pelo modelo de entropia.\n",
        "- O lado do decoder é composto pela transformação de síntese e pelo mesmo modelo de entropia.\n",
        "\n",
        "No momento do teste, os latentes não terão ruído aditivo, mas serão quantizados e depois compactados sem perda, então damos novos nomes a eles. Fazemos uma chamada a eles e à reconstrução da imagem $\\hat x$ e $\\hat y$, respectivamente (conforme o artigo [Compactação de imagens de ponta a ponta](https://arxiv.org/abs/1611.01704))."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sBRAPa5jksss"
      },
      "outputs": [],
      "source": [
        "class MNISTCompressor(tf.keras.Model):\n",
        "  \"\"\"Compresses MNIST images to strings.\"\"\"\n",
        "\n",
        "  def __init__(self, analysis_transform, entropy_model):\n",
        "    super().__init__()\n",
        "    self.analysis_transform = analysis_transform\n",
        "    self.entropy_model = entropy_model\n",
        "\n",
        "  def call(self, x):\n",
        "    # Ensure inputs are floats in the range (0, 1).\n",
        "    x = tf.cast(x, self.compute_dtype) / 255.\n",
        "    y = self.analysis_transform(x)\n",
        "    # Also return the exact information content of each digit.\n",
        "    _, bits = self.entropy_model(y, training=False)\n",
        "    return self.entropy_model.compress(y), bits\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sSZ0X2xPnkN-"
      },
      "outputs": [],
      "source": [
        "class MNISTDecompressor(tf.keras.Model):\n",
        "  \"\"\"Decompresses MNIST images from strings.\"\"\"\n",
        "\n",
        "  def __init__(self, entropy_model, synthesis_transform):\n",
        "    super().__init__()\n",
        "    self.entropy_model = entropy_model\n",
        "    self.synthesis_transform = synthesis_transform\n",
        "\n",
        "  def call(self, string):\n",
        "    y_hat = self.entropy_model.decompress(string, ())\n",
        "    x_hat = self.synthesis_transform(y_hat)\n",
        "    # Scale and cast back to 8-bit integer.\n",
        "    return tf.saturate_cast(tf.round(x_hat * 255.), tf.uint8)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GI7rxeOUDnaC"
      },
      "source": [
        "Quando instanciado com `compression=True`, o modelo de entropia converte o prior aprendido em tabelas, para um algoritmo de codificação de intervalo. Quando fazemos uma chamada a `compress()`, esse algoritmo é chamado para converter o vetor de espaço latente em sequências de bits. O tamanho de cada string binária aproxima o conteúdo de informação do latente (a verossimilhança logarítmica negativa do latente para o prior).\n",
        "\n",
        "O modelo de entropia para compactação e descompactação deve ser a mesma instância, pois as tabelas de codificação de intervalo precisam ser idênticas nos dois lados. Caso contrário, poderão ocorrer erros de decodificação."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dnm_p7mbnigo"
      },
      "outputs": [],
      "source": [
        "def make_mnist_codec(trainer, **kwargs):\n",
        "  # The entropy model must be created with `compression=True` and the same\n",
        "  # instance must be shared between compressor and decompressor.\n",
        "  entropy_model = tfc.ContinuousBatchedEntropyModel(\n",
        "      trainer.prior, coding_rank=1, compression=True, **kwargs)\n",
        "  compressor = MNISTCompressor(trainer.analysis_transform, entropy_model)\n",
        "  decompressor = MNISTDecompressor(entropy_model, trainer.synthesis_transform)\n",
        "  return compressor, decompressor\n",
        "\n",
        "compressor, decompressor = make_mnist_codec(trainer)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYu5sVVH3YMv"
      },
      "source": [
        "Pegue 16 imagens do dataset de validação. Você pode selecionar um subconjunto diferente alterando o argumento para `skip`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qAxArlU728K5"
      },
      "outputs": [],
      "source": [
        "(originals, _), = validation_dataset.batch(16).skip(3).take(1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHeN_ny929YS"
      },
      "source": [
        "Compacte-as em strings e controle o conteúdo de informação de cada uma delas em bits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "smOk42gQ3IXv"
      },
      "outputs": [],
      "source": [
        "strings, entropies = compressor(originals)\n",
        "\n",
        "print(f\"String representation of first digit in hexadecimal: 0x{strings[0].numpy().hex()}\")\n",
        "print(f\"Number of bits actually needed to represent it: {entropies[0]:0.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5j9R4bTT3Qhl"
      },
      "source": [
        "Descompacte as imagens das strings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yOP6pEqU3P0w"
      },
      "outputs": [],
      "source": [
        "reconstructions = decompressor(strings)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWo0Q-vy23tt"
      },
      "source": [
        "Exiba cada um dos 16 dígitos originais junto com sua representação binária compactada e o dígito reconstruído."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "jU5IqzZzeEpf"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "\n",
        "def display_digits(originals, strings, entropies, reconstructions):\n",
        "  \"\"\"Visualizes 16 digits together with their reconstructions.\"\"\"\n",
        "  fig, axes = plt.subplots(4, 4, sharex=True, sharey=True, figsize=(12.5, 5))\n",
        "  axes = axes.ravel()\n",
        "  for i in range(len(axes)):\n",
        "    image = tf.concat([\n",
        "        tf.squeeze(originals[i]),\n",
        "        tf.zeros((28, 14), tf.uint8),\n",
        "        tf.squeeze(reconstructions[i]),\n",
        "    ], 1)\n",
        "    axes[i].imshow(image)\n",
        "    axes[i].text(\n",
        "        .5, .5, f\"→ 0x{strings[i].numpy().hex()} →\\n{entropies[i]:0.2f} bits\",\n",
        "        ha=\"center\", va=\"top\", color=\"white\", fontsize=\"small\",\n",
        "        transform=axes[i].transAxes)\n",
        "    axes[i].axis(\"off\")\n",
        "  plt.subplots_adjust(wspace=0, hspace=0, left=0, right=1, bottom=0, top=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "km9PqVEtPJPc"
      },
      "outputs": [],
      "source": [
        "display_digits(originals, strings, entropies, reconstructions)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzlrIOiYOzJc"
      },
      "source": [
        "O tamanho da string codificada difere do conteúdo de informação de cada dígito.\n",
        "\n",
        "Isso ocorre porque o processo de codificação de intervalo funciona com probabilidades discretas e uma pequena quantidade de sobrecarga. Portanto, especificamente para strings pequenas, a correspondência é apenas aproximada. Entretanto, a codificação de intervalo é **ideal de forma assintótica**: no limite, a quantidade esperada de bits se aproximará da entropia cruzada (o conteúdo de informação esperado), em que a taxa no modelo de treinamento é um limite superior."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78qIG8t8FvJW"
      },
      "source": [
        "## Equilíbrio entre taxa e distorção\n",
        "\n",
        "Acima, o modelo foi treinado para um equilíbrio específico (dado `lmbda=2000`) entre o número médio de bits usados para representar cada dígito e o erro decorrente na reconstrução.\n",
        "\n",
        "O que acontece quando repetimos o experimento com valores diferentes?\n",
        "\n",
        "Vamos começar reduzindo $\\lambda$ para 500."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1iFcAD0WF78p"
      },
      "outputs": [],
      "source": [
        "def train_and_visualize_model(lmbda):\n",
        "  trainer = train_mnist_model(lmbda=lmbda)\n",
        "  compressor, decompressor = make_mnist_codec(trainer)\n",
        "  strings, entropies = compressor(originals)\n",
        "  reconstructions = decompressor(strings)\n",
        "  display_digits(originals, strings, entropies, reconstructions)\n",
        "\n",
        "train_and_visualize_model(lmbda=500)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uy5OkgJMObMc"
      },
      "source": [
        "A taxa de bits do nosso código cai, assim como a fidelidade dos dígitos. Entretanto, a maioria dos dígitos permanece reconhecível.\n",
        "\n",
        "Vamos reduzir $\\lambda$ ainda mais."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NQp9_9_5GcxH"
      },
      "outputs": [],
      "source": [
        "train_and_visualize_model(lmbda=300)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ELLMAN1OwMQ"
      },
      "source": [
        "As strings começam a ficar muito menores agora, da ordem de um byte por dígito. Entretanto, isso acarreta um custo. Mais dígitos estão ficando irreconhecíveis.\n",
        "\n",
        "Isso demonstra que esse modelo é agnóstico quanto às percepções humanas de erro; ele apenas mensura o desvio absoluto quando aos valores de pixels. Para conseguir uma qualidade de imagem melhor, teríamos que substituir a perda de pixel por uma perda perceptiva."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9cWHtH0LP_r"
      },
      "source": [
        "## Usar o decoder como modelo generativo\n",
        "\n",
        "Se alimentarmos bits aleatórios no decoder, será feita uma amostragem da distribuição que o modelo aprendeu para representar dígitos.\n",
        "\n",
        "Primeiro, instancie novamente o compactador/descompactador sem uma verificação que detectaria se a string de entrada não está totalmente decodificada."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qnic8YsM0_ke"
      },
      "outputs": [],
      "source": [
        "compressor, decompressor = make_mnist_codec(trainer, decode_sanity_check=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86uc9_Is1eeo"
      },
      "source": [
        "Agora, alimente strings aleatórias grandes o suficiente no descompactador para que ele possa decodificar/amostrar dígitos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o4fP7BkqKCHY"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "strings = tf.constant([os.urandom(8) for _ in range(16)])\n",
        "samples = decompressor(strings)\n",
        "\n",
        "fig, axes = plt.subplots(4, 4, sharex=True, sharey=True, figsize=(5, 5))\n",
        "axes = axes.ravel()\n",
        "for i in range(len(axes)):\n",
        "  axes[i].imshow(tf.squeeze(samples[i]))\n",
        "  axes[i].axis(\"off\")\n",
        "plt.subplots_adjust(wspace=0, hspace=0, left=0, right=1, bottom=0, top=1)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "data_compression.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
