{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwZNOAMZcxl3"
      },
      "source": [
        "##### Copyright 2019 The TensorFlow Neural Structured Learning Authors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "nxbcnXODdE06"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BszoQj0dSZO"
      },
      "source": [
        "# Regularização adversária para classificação de imagens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfqlePz0g6o5"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>     <a target=\"_blank\" href=\"https://www.tensorflow.org/neural_structured_learning/tutorials/adversarial_keras_cnn_mnist\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver em TensorFlow.org</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/pt-br/neural_structured_learning/tutorials/adversarial_keras_cnn_mnist.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Executar no Google Colab</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/pt-br/neural_structured_learning/tutorials/adversarial_keras_cnn_mnist.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver fonte no GitHub</a>\n",
        "</td>\n",
        "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/pt-br/neural_structured_learning/tutorials/adversarial_keras_cnn_mnist.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Baixar notebook</a>\n",
        "</td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHEGl8h_m6tS"
      },
      "source": [
        "## Visão geral\n",
        "\n",
        "Neste tutorial, exploraremos o uso do aprendizado adversário ([Goodfellow et al., 2014](https://arxiv.org/abs/1412.6572)) para classificação de imagens usando o framework Neural Structured Learning (NSL).\n",
        "\n",
        "A ideia central do aprendizado adversário é treinar um modelo com dados adversariamente perturbados (chamados de exemplos adversários), além dos dados de treinamento orgânico. Para o olho humano, esses exemplos adversários parecem iguais aos originais, mas a perturbação fará com que o modelo fique confuso e faça previsões ou classificações incorretas. Os exemplos adversários são construídos para enganar intencionalmente o modelo, fazendo-o com que ele faça previsões ou classificações incorretas. Ao treinar com esses exemplos, o modelo aprende a ser robusto contra perturbações adversárias ao fazer previsões.\n",
        "\n",
        "Neste tutorial, ilustraremos o seguinte procedimento de aplicação de aprendizado adversário para obter modelos robustos usando o framework Neural Structured Learning:\n",
        "\n",
        "1. Crie uma rede neural como modelo de referência. Neste tutorial, o modelo de referência é criado com a API funcional `tf.keras`; este procedimento também é compatível com modelos criados por APIs sequenciais e de subclasse `tf.keras`. Para mais informações sobre os modelos Keras no TensorFlow, consulte esta [documentação](https://www.tensorflow.org/api_docs/python/tf/keras/Model) .\n",
        "2. Envolva o modelo de referência com a classe wrapper **`AdversarialRegularization`**, que é fornecida pelo framework NSL, para criar uma nova instância de `tf.keras.Model`. Este novo modelo incluirá a perda adversária como termo de regularização em seu objetivo de treinamento.\n",
        "3. Converta exemplos nos dados de treinamento em dicionários de características.\n",
        "4. Treine e avalie o novo modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZEDFUhqn42r"
      },
      "source": [
        "## Recapitulação para iniciantes\n",
        "\n",
        "Há uma [explicação em vídeo](https://youtu.be/Js2WJkhdU7k) relacionada sobre aprendizado adversário para classificação de imagens, parte da série TensorFlow Neural Structured Learning do YouTube. Abaixo, resumimos os principais conceitos explicados neste vídeo, expandindo a explicação fornecida na seção Visão Geral acima.\n",
        "\n",
        "O framework NSL otimiza em conjunto as características de imagem e os sinais estruturados para fazer com que as redes neurais aprendam melhor. Mas e se não houver uma estrutura explícita disponível para treinar a rede neural? Este tutorial explica uma abordagem que envolve a criação de vizinhos adversários (modificados a partir da amostra original) para construir uma estrutura dinamicamente.\n",
        "\n",
        "Primeiro, vizinhos adversários são definidos como versões modificadas da imagem da amostra aplicada com pequenas perturbações que induzem uma rede neural a gerar classificações imprecisas. Essas perturbações cuidadosamente projetadas são normalmente baseadas na direção reversa do gradiente e têm como objetivo confundir a rede neural durante o treinamento. Os humanos podem não ser capazes de distinguir entre uma imagem de amostra e seu vizinho adversário gerado. No entanto, para a rede neural, as perturbações aplicadas são eficazes em levar a uma conclusão imprecisa.\n",
        "\n",
        "Os vizinhos adversários gerados são então conectados à amostra, construindo assim dinamicamente uma estrutura borda por borda. Usando essa conexão, as redes neurais aprendem a manter as semelhanças entre a amostra e os vizinhos adversários, evitando confusões resultantes de classificações incorretas, melhorando assim a qualidade e a precisão geral da rede neural.\n",
        "\n",
        "O segmento de código abaixo é uma explicação em alto nível das etapas envolvidas, enquanto o restante deste tutorial vai mais longe e se aprofunda nos detalhes técnicos.\n",
        "\n",
        "1. Leia e prepare os dados. Carregue o dataset MNIST e normalize os valores do características para que permaneçam no intervalo [0,1]\n",
        "\n",
        "```\n",
        "import neural_structured_learning as nsl\n",
        "\n",
        "(x_train, y_train), (x_train, y_train) = tf.keras.datasets.mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSlSGafKn42s"
      },
      "source": [
        "1. Construa a rede neural. Um modelo de referência Keras Sequencial é usado para este exemplo.\n",
        "\n",
        "```\n",
        "model = tf.keras.Sequential(...)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFJ6cixdn42s"
      },
      "source": [
        "1. Configure o modelo adversário. Incluindo os hiperparâmetros: multiplicador aplicado na regularização adversária, valores diferentes escolhidos empiricamente para tamanho do passo/taxa de aprendizagem. Invoque a regularização adversária com uma classe wrapper em torno da rede neural construída.\n",
        "\n",
        "```\n",
        "adv_config = nsl.configs.make_adv_reg_config(multiplier=0.2, adv_step_size=0.05)\n",
        "adv_model = nsl.keras.AdversarialRegularization(model, adv_config)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ohmfLgLn42s"
      },
      "source": [
        "1. Conclua com o workflow padrão do Keras: compilar, ajustar, avaliar.\n",
        "\n",
        "```\n",
        "adv_model.compile(optimizer='adam', loss='sparse_categorizal_crossentropy', metrics=['accuracy'])\n",
        "adv_model.fit({'feature': x_train, 'label': y_train}, epochs=5)\n",
        "adv_model.evaluate({'feature': x_test, 'label': y_test})\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgSOF-49Q7kS"
      },
      "source": [
        "O que você viu aqui foi o aprendizado adversário habilitado em 2 etapas e com 3 linhas simples de código. Esta é a simplicidade do framework Neural Structured Learning. Nas seções a seguir, expandiremos esse procedimento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qODwGDl-n42t"
      },
      "source": [
        "## Configuração"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4RhmgQ7-mlrl"
      },
      "source": [
        "Instale o pacote Neural Structured Learning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ByJ7133BQULR"
      },
      "outputs": [],
      "source": [
        "!pip install --quiet neural-structured-learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZvsEQrhSqKx"
      },
      "source": [
        "Importe as bibliotecas. Abreviamos `neural_structured_learning` para `nsl`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EuqEuAYzTMo0"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import neural_structured_learning as nsl\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LwBtQGaTvbe"
      },
      "source": [
        "## Hiperparâmetros\n",
        "\n",
        "Coletamos e explicamos os hiperparâmetros (num objeto `HParams`) para treinamento e avaliação do modelo.\n",
        "\n",
        "Entrada/Saída:\n",
        "\n",
        "- **`input_shape`**: o formato do tensor de entrada. Cada imagem tem 28 por 28 pixels com 1 canal.\n",
        "- **`num_classes`**: há um total de 10 classes, correspondendo a 10 dígitos [0-9].\n",
        "\n",
        "Arquitetura do modelo:\n",
        "\n",
        "- **`conv_filters`**: uma lista de números, cada um especificando o número de filtros em uma camada convolucional.\n",
        "- **`kernel_size`**: o tamanho da janela de convolução 2D, compartilhada por todas as camadas convolucionais.\n",
        "- **`pool_size`**: fatores para reduzir a escala da imagem em cada camada de pooling máximo.\n",
        "- **`num_fc_units`**: o número de unidades (ou seja, largura) de cada camada totalmente conectada.\n",
        "\n",
        "Treinamento e avaliação:\n",
        "\n",
        "- **`batch_size`**: tamanho do lote usado para treinamento e avaliação.\n",
        "- **`epochs`**: o número de épocas de treinamento.\n",
        "\n",
        "Aprendizagem adversária:\n",
        "\n",
        "- **`adv_multiplier`**: o peso da perda adversária no objetivo de treinamento, em relação à perda rotulada.\n",
        "- **`adv_step_size`**: a magnitude da perturbação adversária.\n",
        "- **`adv_grad_norm`**: a norma para medir a magnitude da perturbação adversária.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iOc8YdmIRSHo"
      },
      "outputs": [],
      "source": [
        "class HParams(object):\n",
        "  def __init__(self):\n",
        "    self.input_shape = [28, 28, 1]\n",
        "    self.num_classes = 10\n",
        "    self.conv_filters = [32, 64, 64]\n",
        "    self.kernel_size = (3, 3)\n",
        "    self.pool_size = (2, 2)\n",
        "    self.num_fc_units = [64]\n",
        "    self.batch_size = 32\n",
        "    self.epochs = 5\n",
        "    self.adv_multiplier = 0.2\n",
        "    self.adv_step_size = 0.2\n",
        "    self.adv_grad_norm = 'infinity'\n",
        "\n",
        "HPARAMS = HParams()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72zL1AMcYYGG"
      },
      "source": [
        "## O dataset MNIST\n",
        "\n",
        "O [dataset MNIST](http://yann.lecun.com/exdb/mnist/) contém imagens em escala de cinza de dígitos manuscritos (de '0' a '9'). Cada imagem mostra um dígito em baixa resolução (28 por 28 pixels). A tarefa é classificar as imagens em 10 categorias, uma por dígito.\n",
        "\n",
        "Aqui carregamos o dataset MNIST de [TensorFlow Datasets](https://www.tensorflow.org/datasets). Ele cuida do download dos dados e da construção de um `tf.data.Dataset`. O dataset carregado possui dois subconjuntos:\n",
        "\n",
        "- `train` com 60.000 exemplos e\n",
        "- `test` com 10.000 exemplos.\n",
        "\n",
        "Os exemplos em ambos os subconjuntos são armazenados em dicionários de características com as duas chaves a seguir:\n",
        "\n",
        "- `image`: array de valores de pixels, variando de 0 a 255.\n",
        "- `label`: rótulo de verdade absoluta (ground truth), variando de 0 a 9."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R1dK6E4axNHB"
      },
      "outputs": [],
      "source": [
        "datasets = tfds.load('mnist')\n",
        "\n",
        "train_dataset = datasets['train']\n",
        "test_dataset = datasets['test']\n",
        "\n",
        "IMAGE_INPUT_NAME = 'image'\n",
        "LABEL_INPUT_NAME = 'label'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBkh4mbsxLR_"
      },
      "source": [
        "Para deixar o modelo numericamente estável, normalizamos os valores dos pixels para [0, 1] mapeando o dataset sobre a função `normalize`. Depois de embaralhar o dataset de treinamento e o lote, convertemos os exemplos em tuplas de características `(image, label)` para treinar o modelo de referência. Também fornecemos uma função para converter tuplas em dicionários para uso posterior."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VhMEJqKs0_7z"
      },
      "outputs": [],
      "source": [
        "def normalize(features):\n",
        "  features[IMAGE_INPUT_NAME] = tf.cast(\n",
        "      features[IMAGE_INPUT_NAME], dtype=tf.float32) / 255.0\n",
        "  return features\n",
        "\n",
        "def convert_to_tuples(features):\n",
        "  return features[IMAGE_INPUT_NAME], features[LABEL_INPUT_NAME]\n",
        "\n",
        "def convert_to_dictionaries(image, label):\n",
        "  return {IMAGE_INPUT_NAME: image, LABEL_INPUT_NAME: label}\n",
        "\n",
        "train_dataset = train_dataset.map(normalize).shuffle(10000).batch(HPARAMS.batch_size).map(convert_to_tuples)\n",
        "test_dataset = test_dataset.map(normalize).batch(HPARAMS.batch_size).map(convert_to_tuples)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrrMpPNmpCKK"
      },
      "source": [
        "## Modelo de referência\n",
        "\n",
        "Nosso modelo de referência será uma rede neural composta por 3 camadas convolucionais seguidas por 2 camadas totalmente conectadas (conforme definido em `HPARAMS`). Aqui nós o definimos usando a API funcional Keras. Sinta-se à vontade para experimentar outras APIs ou arquiteturas de modelo (por exemplo, subclasses). Observe que o framework NSL oferece suporte a todos os três tipos de APIs Keras."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4UjrtuIsYWo3"
      },
      "outputs": [],
      "source": [
        "def build_base_model(hparams):\n",
        "  \"\"\"Builds a model according to the architecture defined in `hparams`.\"\"\"\n",
        "  inputs = tf.keras.Input(\n",
        "      shape=hparams.input_shape, dtype=tf.float32, name=IMAGE_INPUT_NAME)\n",
        "\n",
        "  x = inputs\n",
        "  for i, num_filters in enumerate(hparams.conv_filters):\n",
        "    x = tf.keras.layers.Conv2D(\n",
        "        num_filters, hparams.kernel_size, activation='relu')(\n",
        "            x)\n",
        "    if i < len(hparams.conv_filters) - 1:\n",
        "      # max pooling between convolutional layers\n",
        "      x = tf.keras.layers.MaxPooling2D(hparams.pool_size)(x)\n",
        "  x = tf.keras.layers.Flatten()(x)\n",
        "  for num_units in hparams.num_fc_units:\n",
        "    x = tf.keras.layers.Dense(num_units, activation='relu')(x)\n",
        "  pred = tf.keras.layers.Dense(hparams.num_classes)(x)\n",
        "  model = tf.keras.Model(inputs=inputs, outputs=pred)\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "288nsmN5pLoo"
      },
      "outputs": [],
      "source": [
        "base_model = build_base_model(HPARAMS)\n",
        "base_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlTUGn1t_HAr"
      },
      "source": [
        "Em seguida, treinamos e avaliamos o modelo de referência."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K2cFDbmRpRMp"
      },
      "outputs": [],
      "source": [
        "base_model.compile(\n",
        "    optimizer='adam',\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=['acc'])\n",
        "base_model.fit(train_dataset, epochs=HPARAMS.epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J94Y_WTaqAsi"
      },
      "outputs": [],
      "source": [
        "results = base_model.evaluate(test_dataset)\n",
        "named_results = dict(zip(base_model.metrics_names, results))\n",
        "print('\\naccuracy:', named_results['acc'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8OClWqGALIm"
      },
      "source": [
        "Podemos ver que o modelo de referência atinge 99% de exatidão no dataset de teste. Veremos quão robusto ele é em [Robustez sob perturbações adversárias](#scrollTo=HXK9MGG8lBX3) abaixo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CemXA8N9q336"
      },
      "source": [
        "## Modelo regularizado adversário\n",
        "\n",
        "Aqui mostramos como incorporar o treinamento adversário num modelo Keras com algumas linhas de código, usando o framework NSL. O modelo de referência é empacotado para criar um novo `tf.Keras.Model`, cujo objetivo de treinamento inclui regularização adversária."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUOpl-rkzRrY"
      },
      "source": [
        "Primeiro, criamos um objeto de configuração com todos os hiperparâmetros relevantes usando a função auxiliar `nsl.configs.make_adv_reg_config`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-WWVwJB2qstE"
      },
      "outputs": [],
      "source": [
        "adv_config = nsl.configs.make_adv_reg_config(\n",
        "    multiplier=HPARAMS.adv_multiplier,\n",
        "    adv_step_size=HPARAMS.adv_step_size,\n",
        "    adv_grad_norm=HPARAMS.adv_grad_norm\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmeIUyxE4s68"
      },
      "source": [
        "Agora podemos encapsular um modelo de referência com `AdversarialRegularization`. Aqui criamos um novo modelo de referência (`base_adv_model`), para que o existente (`base_model`) possa ser usado em comparações posteriores.\n",
        "\n",
        "O `adv_model` retornado é um objeto `tf.keras.Model`, cujo objetivo de treinamento inclui um termo de regularização para a perda adversária. Para calcular essa perda, o modelo precisa ter acesso às informações do rótulo (feature `label`), além da entrada regular (feature `image`). Por esse motivo, convertemos os exemplos de tuplas nos datasets de volta para dicionários. E informamos ao modelo qual característica contém as informações do rótulo por meio do parâmetro `label_keys`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TObqJLEX4sQq"
      },
      "outputs": [],
      "source": [
        "base_adv_model = build_base_model(HPARAMS)\n",
        "adv_model = nsl.keras.AdversarialRegularization(\n",
        "    base_adv_model,\n",
        "    label_keys=[LABEL_INPUT_NAME],\n",
        "    adv_config=adv_config\n",
        ")\n",
        "\n",
        "train_set_for_adv_model = train_dataset.map(convert_to_dictionaries)\n",
        "test_set_for_adv_model = test_dataset.map(convert_to_dictionaries)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKTQWzfj7JvL"
      },
      "source": [
        "Em seguida, compilamos, treinamos e avaliamos o modelo regularizado adversário. Pode haver avisos como \"Output missing from loss dictionary\", o que não tem problema pois o `adv_model` não depende da implementação de referência para calcular a perda total."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aTSK-cHbuWDw"
      },
      "outputs": [],
      "source": [
        "adv_model.compile(\n",
        "    optimizer='adam',\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=['acc'])\n",
        "adv_model.fit(train_set_for_adv_model, epochs=HPARAMS.epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3v_Jn7wuviZx"
      },
      "outputs": [],
      "source": [
        "results = adv_model.evaluate(test_set_for_adv_model)\n",
        "named_results = dict(zip(adv_model.metrics_names, results))\n",
        "print('\\naccuracy:', named_results['sparse_categorical_accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgnslZYk9Acg"
      },
      "source": [
        "Podemos ver que o modelo regularizado adversário também tem um desempenho muito bom (99% de exatidão) no dataset de testes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXK9MGG8lBX3"
      },
      "source": [
        "## Robustez sob perturbações adversárias\n",
        "\n",
        "Agora comparamos o modelo de referência com o modelo regulamentado pelo adversário quanto à robustez sob perturbação adversária.\n",
        "\n",
        "Usaremos a função `AdversarialRegularization.perturb_on_batch` para gerar exemplos adversariamente perturbados. E gostaríamos que a geração fosse baseada no modelo de referência. Para fazer isso, encapsulamos o modelo de referência com `AdversarialRegularization`. Observe que, desde que o treinamento (`Model.fit`) não seja invocado, as variáveis ​​aprendidas no modelo não mudarão e o modelo ainda será o mesmo da seção [Modelo de referência](#scrollTo=JrrMpPNmpCKK)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FLkYw54pvxJO"
      },
      "outputs": [],
      "source": [
        "reference_model = nsl.keras.AdversarialRegularization(\n",
        "    base_model, label_keys=[LABEL_INPUT_NAME], adv_config=adv_config)\n",
        "reference_model.compile(\n",
        "    optimizer='adam',\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=['acc'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DR0Rn5rxBeDh"
      },
      "source": [
        "Juntamos num dicionário os modelos a serem avaliados, e também criamos um objeto de métricas para cada um dos modelos.\n",
        "\n",
        "Observe que consideramos que `adv_model.base_model` tem o mesmo formato de entrada (sem exigir informações de rótulo) do modelo de referência. As variáveis ​​aprendidas em `adv_model.base_model` são as mesmas que em `adv_model`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "igRBxPlPm_JE"
      },
      "outputs": [],
      "source": [
        "models_to_eval = {\n",
        "    'base': base_model,\n",
        "    'adv-regularized': adv_model.base_model\n",
        "}\n",
        "metrics = {\n",
        "    name: tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "    for name in models_to_eval.keys()\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BAPYegAbC8mZ"
      },
      "source": [
        "Aqui está o loop para gerar exemplos perturbados e avaliar modelos com eles. Salvamos as imagens, rótulos e previsões perturbadas para visualização na próxima seção."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IGnLXhswmUN8"
      },
      "outputs": [],
      "source": [
        "perturbed_images, labels, predictions = [], [], []\n",
        "\n",
        "for batch in test_set_for_adv_model:\n",
        "  perturbed_batch = reference_model.perturb_on_batch(batch)\n",
        "  # Clipping makes perturbed examples have the same range as regular ones.\n",
        "  perturbed_batch[IMAGE_INPUT_NAME] = tf.clip_by_value(\n",
        "      perturbed_batch[IMAGE_INPUT_NAME], 0.0, 1.0)\n",
        "  y_true = perturbed_batch.pop(LABEL_INPUT_NAME)\n",
        "  perturbed_images.append(perturbed_batch[IMAGE_INPUT_NAME].numpy())\n",
        "  labels.append(y_true.numpy())\n",
        "  predictions.append({})\n",
        "  for name, model in models_to_eval.items():\n",
        "    y_pred = model(perturbed_batch)\n",
        "    metrics[name](y_true, y_pred)\n",
        "    predictions[-1][name] = tf.argmax(y_pred, axis=-1).numpy()\n",
        "\n",
        "for name, metric in metrics.items():\n",
        "  print('%s model accuracy: %f' % (name, metric.result().numpy()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5cC3XbRGFJQ"
      },
      "source": [
        "Podemos ver que a exatidão do modelo de referência cai drasticamente (de 99% para cerca de 50%) quando a entrada é perturbada de forma adversária. Por outro lado, a precisão do modelo regularizado adversário apenas degrada um pouco (de 99% para 95%). Isto mostrs a eficácia do aprendizado adversário na melhoria da robustez do modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YfB5oBBfWLRK"
      },
      "source": [
        "## Exemplos de imagens perturbadas adversariamente\n",
        "\n",
        "Aqui damos uma olhada nas imagens perturbadas adversariamente. Podemos ver que as imagens perturbadas ainda mostram dígitos reconhecíveis por humanos, mas podem enganar com sucesso o modelo de referência."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3iK9vO_xKJfg"
      },
      "outputs": [],
      "source": [
        "batch_index = 0\n",
        "\n",
        "batch_image = perturbed_images[batch_index]\n",
        "batch_label = labels[batch_index]\n",
        "batch_pred = predictions[batch_index]\n",
        "\n",
        "batch_size = HPARAMS.batch_size\n",
        "n_col = 4\n",
        "n_row = (batch_size + n_col - 1) // n_col\n",
        "\n",
        "print('accuracy in batch %d:' % batch_index)\n",
        "for name, pred in batch_pred.items():\n",
        "  print('%s model: %d / %d' % (name, np.sum(batch_label == pred), batch_size))\n",
        "\n",
        "plt.figure(figsize=(15, 15))\n",
        "for i, (image, y) in enumerate(zip(batch_image, batch_label)):\n",
        "  y_base = batch_pred['base'][i]\n",
        "  y_adv = batch_pred['adv-regularized'][i]\n",
        "  plt.subplot(n_row, n_col, i+1)\n",
        "  plt.title('true: %d, base: %d, adv: %d' % (y, y_base, y_adv))\n",
        "  plt.imshow(tf.keras.utils.array_to_img(image), cmap='gray')\n",
        "  plt.axis('off')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_vo1pWYJlHP"
      },
      "source": [
        "## Conclusão\n",
        "\n",
        "Demonstramos o uso do aprendizado adversário para classificação de imagens usando o framework Neural Structured Learning (NSL). Incentivamos os usuários a experimentar diferentes configurações adversárias (em hiperparâmetros) e ver como elas afetam a robustez do modelo."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "adversarial_keras_cnn_mnist.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
