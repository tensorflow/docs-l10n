{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qN8P0AnTnAhh"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnUwFbCAKB2r"
      },
      "source": [
        "## Antes de começarmos\n",
        "\n",
        "Para acessar o notebook no Colab, vá até \"File (Arquivo)\" -&gt; \"Save a copy in Drive (Salvar uma cópia no Drive)\" e faça as alterações no notebook copiado.\n",
        "\n",
        "Antes de começarmos, execute o código abaixo para que o ambiente seja configurado corretamente. Se não for exibida uma saudação, consulte as instruções de [instalação](../install.md). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "both",
        "id": "ZrGitA_KnRO0"
      },
      "outputs": [],
      "source": [
        "#@title Upgrade tensorflow_federated and load TensorBoard\n",
        "#@test {\"skip\": true}\n",
        "!pip install --quiet --upgrade tensorflow-federated\n",
        "!pip install --quiet --upgrade nest-asyncio\n",
        "\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "%load_ext tensorboard\n",
        "\n",
        "import sys\n",
        "\n",
        "if not sys.warnoptions:\n",
        "    import warnings\n",
        "    warnings.simplefilter(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "both",
        "id": "8BKyHkMxKHfV"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "import collections\n",
        "from matplotlib import pyplot as plt\n",
        "from IPython.display import display, HTML, IFrame\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_federated as tff\n",
        "\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "def greetings():\n",
        "  display(HTML('<b><font size=\"6\" color=\"#ff00f4\">Greetings, virtual tutorial participants!</font></b>'))\n",
        "  return True\n",
        "l = tff.federated_computation(greetings)()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AftvNA5VMemJ"
      },
      "source": [
        "# TensorFlow Federated para classificação de imagens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coAumH42q9nz"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>     <a target=\"_blank\" href=\"https://www.tensorflow.org/federated/tutorials/federated_learning_for_image_classification\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver em TensorFlow.org</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/pt-br/federated/openmined2020/openmined_conference_2020.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Executar no Google Colab</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/pt-br/federated/openmined2020/openmined_conference_2020.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver fonte no GitHub</a>\n",
        "</td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zs2LgZBOMt4M"
      },
      "source": [
        "Vamos simular um aprendizado federado. Neste tutorial, usaremos o exemplo de treinamento MNIST clássico para apresentar a camada de API Federated Learning (FL, na sigla em inglês para aprendizado federado) do TFF, `tff.learning` – um conjunto de interfaces de alto nível que podem ser usadas para fazer tarefas comuns de aprendizado federado, como treinamento federado, usando modelos fornecidos por usuários e implementados no TensorFlow.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dN7n8RS7-rLR"
      },
      "source": [
        "# Organização do tutorial\n",
        "\n",
        "Treinaremos um modelo para fazer classificação de imagens usando o dataset MNIST clássico, com o aprendizado de rede neutral para classificar dígitos em imagens. Neste caso, simularemos o aprendizado federado com os dados de treinamento distribuídos em diferentes dispositivos.\n",
        "\n",
        "<p><b>Seções</b></p>\n",
        "\n",
        "1. Carregue as bibliotecas do TFF.\n",
        "2. Explore/pré-processe o dataset federado EMNIST.\n",
        "3. Crie um modelo.\n",
        "4. Configure o processo de agregação federada para o treinamento.\n",
        "5. Analise as métricas de treinamento.\n",
        "6. Configure a computação de avaliação federada.\n",
        "7. Analise as métricas de avaliação.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Cyy2AWbLMKj"
      },
      "source": [
        "## Prepare os dados de entrada\n",
        "\n",
        "Vamos começar pelos dados. O aprendizado federado requer um conjunto federado de dados, ou seja, uma coleção de dados vindos de diversos usuários. Geralmente, os dados federados não são [i.i.d.](https://en.wikipedia.org/wiki/Independent_and_identically_distributed_random_variables) (independentes e identicamente distribuídos), o que traz desafios únicos. Tipicamente, os usuários têm distribuições diferentes de dados dependendo dos padrões de uso.\n",
        "\n",
        "Para que possamos fazer experimentos, alimentamos o repositório do TFF com alguns datasets.\n",
        "\n",
        "Veja como carregar nosso dataset de amostra:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bP6WDENHSSZ9"
      },
      "outputs": [],
      "source": [
        "# Code for loading federated data from TFF repository\n",
        "emnist_train, emnist_test = tff.simulation.datasets.emnist.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yeX8BKgPfeFw"
      },
      "source": [
        "Os datasets retornados por `load_data()` são instâncias de `tff.simulation.datasets.ClientData`, uma interface que permite enumerar o conjunto de usuários para construir um `tf.data.Dataset` que represente os dados de um usuário específico e para consultar a estrutura de elementos individuais.\n",
        "\n",
        "Vamos explorar o dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kN4-U5nJgKig"
      },
      "outputs": [],
      "source": [
        "len(emnist_train.client_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZyCzIrSegT62"
      },
      "outputs": [],
      "source": [
        "# Let's look at the shape of our data\n",
        "example_dataset = emnist_train.create_tf_dataset_for_client(\n",
        "    emnist_train.client_ids[0])\n",
        "\n",
        "example_dataset.element_spec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EsvSXGEMgd9G"
      },
      "outputs": [],
      "source": [
        "# Let's select an example dataset from one of our simulated clients\n",
        "example_dataset = emnist_train.create_tf_dataset_for_client(\n",
        "    emnist_train.client_ids[0])\n",
        "\n",
        "# Your code to get an example element from one client:\n",
        "example_element = next(iter(example_dataset))\n",
        "\n",
        "example_element['label'].numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OmLV0nfMg98V"
      },
      "outputs": [],
      "source": [
        "plt.imshow(example_element['pixels'].numpy(), cmap='gray', aspect='equal')\n",
        "plt.grid(False)\n",
        "_ = plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-3KUf0kC8TN"
      },
      "source": [
        "**Explorando dados não independentes e identicamente distribuídos**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "veWNAxdQfrgZ"
      },
      "outputs": [],
      "source": [
        "## Example MNIST digits for one client\n",
        "f = plt.figure(figsize=(20,4))\n",
        "j = 0\n",
        "\n",
        "for e in example_dataset.take(40):\n",
        "  plt.subplot(4, 10, j+1)\n",
        "  plt.imshow(e['pixels'].numpy(), cmap='gray', aspect='equal')\n",
        "  plt.axis('off')\n",
        "  j += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_XJRWDFWniik"
      },
      "outputs": [],
      "source": [
        "# Number of examples per layer for a sample of clients\n",
        "f = plt.figure(figsize=(12,7))\n",
        "f.suptitle(\"Label Counts for a Sample of Clients\")\n",
        "for i in range(6):\n",
        "  ds = emnist_train.create_tf_dataset_for_client(emnist_train.client_ids[i])\n",
        "  k = collections.defaultdict(list)\n",
        "  for e in ds:\n",
        "    k[e['label'].numpy()].append(e['label'].numpy())\n",
        "  plt.subplot(2, 3, i+1)\n",
        "  plt.title(\"Client {}\".format(i))\n",
        "  for j in range(10):\n",
        "    plt.hist(k[j], density=False, bins=[0,1,2,3,4,5,6,7,8,9,10])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JOUI4zW9LQNH"
      },
      "outputs": [],
      "source": [
        "# Let's play around with the emnist_train dataset.\n",
        "# Let's explore the non-iid charateristic of the example data.\n",
        "\n",
        "for i in range(5):\n",
        "  ds = emnist_train.create_tf_dataset_for_client(emnist_train.client_ids[i])\n",
        "  k = collections.defaultdict(list)\n",
        "  for e in ds:\n",
        "    k[e['label'].numpy()].append(e['pixels'].numpy())\n",
        "  f = plt.figure(i, figsize=(12,5))\n",
        "  f.suptitle(\"Client #{}'s Mean Image Per Label\".format(i))\n",
        "  for j in range(10):\n",
        "    mn_img = np.mean(k[j],0)\n",
        "    plt.subplot(2, 5, j+1)\n",
        "    plt.imshow(mn_img.reshape((28,28)))#,cmap='gray') \n",
        "    plt.axis('off')\n",
        "\n",
        "# Each client has different mean images -- each client will be nudging the model\n",
        "# in their own directions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMd01egqy9we"
      },
      "source": [
        "### Pré-processamento de dados\n",
        "\n",
        "Como os dados já são um `tf.data.Dataset`, o pré-processamento pode ser feito usando-se transformações de datasets. Confira mais detalhes sobre essas transformações [aqui](https://www.tensorflow.org/guide/data)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cyG_BMraSuu_"
      },
      "outputs": [],
      "source": [
        "NUM_CLIENTS = 10\n",
        "NUM_EPOCHS = 5\n",
        "BATCH_SIZE = 20\n",
        "SHUFFLE_BUFFER = 100\n",
        "PREFETCH_BUFFER=10\n",
        "\n",
        "def preprocess(dataset):\n",
        "\n",
        "  def batch_format_fn(element):\n",
        "    \"\"\"Flatten a batch `pixels` and return the features as an `OrderedDict`.\"\"\"\n",
        "    return collections.OrderedDict(\n",
        "        x=tf.reshape(element['pixels'], [-1, 784]),\n",
        "        y=tf.reshape(element['label'], [-1, 1]))\n",
        "\n",
        "  return dataset.repeat(NUM_EPOCHS).shuffle(SHUFFLE_BUFFER).batch(\n",
        "      BATCH_SIZE).map(batch_format_fn).prefetch(PREFETCH_BUFFER)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9LXykN_jlJw"
      },
      "source": [
        "Vamos verificar se funcionou."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VChB7LMQjkYz"
      },
      "outputs": [],
      "source": [
        "preprocessed_example_dataset = preprocess(example_dataset)\n",
        "\n",
        "sample_batch = tf.nest.map_structure(lambda x: x.numpy(),\n",
        "                                     next(iter(preprocessed_example_dataset)))\n",
        "\n",
        "sample_batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGsMvRQt9Agl"
      },
      "source": [
        "Veja abaixo uma função helper simples que construirá uma lista de datasets a partir do conjunto fornecido de usuários como uma entrada para uma rodada de treinamento ou avaliação."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_PHMvHAI9xVc"
      },
      "outputs": [],
      "source": [
        "def make_federated_data(client_data, client_ids):\n",
        "  return [\n",
        "      preprocess(client_data.create_tf_dataset_for_client(x))\n",
        "      for x in client_ids\n",
        "  ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0M9PfjOtAVqw"
      },
      "source": [
        "Agora, como escolhemos os clientes?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GZ6NYHxB8xer"
      },
      "outputs": [],
      "source": [
        "sample_clients = emnist_train.client_ids[0:NUM_CLIENTS]\n",
        "\n",
        "# Your code to get the federated dataset here for the sampled clients:\n",
        "federated_train_data = make_federated_data(emnist_train, sample_clients)\n",
        "\n",
        "print('Number of client datasets: {l}'.format(l=len(federated_train_data)))\n",
        "print('First dataset: {d}'.format(d=federated_train_data[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOxq4tbi9m8-"
      },
      "source": [
        "## Criando um modelo com o Keras\n",
        "\n",
        "Se você estiver usando o Keras, provavelmente já tem algum código que construa um modelo do Keras. Veja abaixo um exemplo de um modelo simples que será suficiente para nosso tutorial."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LYCsJGJFWbqt"
      },
      "outputs": [],
      "source": [
        "def create_keras_model():\n",
        "  return tf.keras.models.Sequential([\n",
        "      tf.keras.layers.InputLayer(input_shape=(784,)),\n",
        "      tf.keras.layers.Dense(10, kernel_initializer='zeros'),\n",
        "      tf.keras.layers.Softmax(),\n",
        "  ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0214iKjCTyX"
      },
      "source": [
        "**Treinamento centralizado com o Keras**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g5XW_p4iLlJ2"
      },
      "outputs": [],
      "source": [
        "## Centralized training with keras ---------------------------------------------\n",
        "\n",
        "# This is separate from the TFF tutorial, and demonstrates how to train a\n",
        "# Keras model in a centralized fashion (contrasting training in a federated env)\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# Preprocess the data (these are NumPy arrays)\n",
        "x_train = x_train.reshape(60000, 784).astype(\"float32\") / 255\n",
        "\n",
        "y_train = y_train.astype(\"float32\")\n",
        "\n",
        "mod = create_keras_model()\n",
        "mod.compile(\n",
        "    optimizer=tf.keras.optimizers.RMSprop(),\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]\n",
        ")\n",
        "h = mod.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    batch_size=64,\n",
        "    epochs=2\n",
        ")\n",
        "\n",
        "# ------------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6pzsjoJQ2_D"
      },
      "source": [
        "**Treinamento federado usando um modelo do Keras**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHdraKFH4OU2"
      },
      "source": [
        "Para usar qualquer modelo com o TFF, ele precisa ser encapsulado em uma instância da interface `tff.learning.Model`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mA8cJoGE3Rh_"
      },
      "source": [
        "Confira mais métricas do Keras [aqui](https://www.tensorflow.org/api_docs/python/tf/keras/metrics)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q3ynrxd53HzY"
      },
      "outputs": [],
      "source": [
        "def model_fn():\n",
        "  # We _must_ create a new model here, and _not_ capture it from an external\n",
        "  # scope. TFF will call this within different graph contexts.\n",
        "  keras_model = create_keras_model()\n",
        "  return tff.learning.from_keras_model(\n",
        "      keras_model,\n",
        "      input_spec=preprocessed_example_dataset.element_spec,\n",
        "      loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJ5E3O18_JZ6"
      },
      "source": [
        "## Treinando o modelo com dados federados\n",
        "\n",
        "Agora que temos um modelo encapsulado como `tff.learning.Model` para uso com o TFF, podemos deixar que o TFF construa um algoritmo de agregação federada por meio da invocação da função helper `tff.learning.build_federated_averaging_process` conforme mostrado abaixo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sk6mjOfycX5N"
      },
      "outputs": [],
      "source": [
        "iterative_process = tff.learning.build_federated_averaging_process(\n",
        "    model_fn,\n",
        "    client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.02),\n",
        "    # Add server optimizer here!\n",
        "    server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1.0))\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8FpvN2n67sm"
      },
      "source": [
        "O que aconteceu? O TFF construiu um par de *computações federadas* e as encapsulou em um `tff.templates.IterativeProcess` (processo iterativo), em que essas computações ficam disponíveis como um par de propriedades `initialize` (inicializar) e `next` (próximo).\n",
        "\n",
        "Geralmente, um processo iterativo é feito por um loop de controle, como:\n",
        "\n",
        "```\n",
        "def initialize():\n",
        "  ...\n",
        "\n",
        "def next(state):\n",
        "  ...\n",
        "\n",
        "iterative_process = IterativeProcess(initialize, next)\n",
        "state = iterative_process.initialize()\n",
        "for round in range(num_rounds):\n",
        "  state = iterative_process.next(state)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1gbHQ_7BiyT"
      },
      "source": [
        "Vamos invocar a computação `initialize` para construir o estado do servidor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6cagCWlZmcch"
      },
      "outputs": [],
      "source": [
        "state = iterative_process.initialize()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjjxTx9e_rMd"
      },
      "source": [
        "O segundo item do par de computações federadas, `next`, representa uma única rodada da agregação federada, que consiste em enviar o estado do servidor (incluindo os parâmetros do modelo) para os clientes, treinamento no dispositivo usando os dados locals, coleta e agregação das atualizações do modelo e geração de um modelo atualizado no servidor.\n",
        "\n",
        "Vamos executar uma única rodada de treinamento e ver os resultados. Podemos usar os dados federados já gerados acima para uma amostra de usuários."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F3M_W9dDE6Tm"
      },
      "outputs": [],
      "source": [
        "# Run one single round of training.\n",
        "state, metrics = iterative_process.next(state, federated_train_data)\n",
        "print('round  1, metrics={}'.format(metrics['train']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmhReXt9G4A5"
      },
      "source": [
        "Vamos executar mais algumas rodadas. Conforme dito antes, geralmente, a esta altura, você deve escolher um subconjunto dos seus dados de simulação usando uma nova amostra de usuários selecionada aleatoriamente para cada rodada para simular uma implantação realista, em que os usuários chegam e saem o tempo todo. Porém, neste notebook interativo, para fins de demonstração, reutilizaremos os mesmos usuários para que a convergência do sistema seja rápida."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qrJkQuCRJP9C"
      },
      "outputs": [],
      "source": [
        "NUM_ROUNDS = 11\n",
        "for round_num in range(2, NUM_ROUNDS):\n",
        "  state, metrics = iterative_process.next(state, federated_train_data)\n",
        "  print('round {:2d}, metrics={}'.format(round_num, metrics['train']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "joHYzn9jcs0Y"
      },
      "source": [
        "A perda de treinamento está diminuindo a cada rodada de treinamento federado, indicando que o modelo está convergindo. Há algumas ressalvas importantes sobre essas métricas de treinamento, que são explicadas mais adiante, na seção *Avaliação* do tutorial."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruSHJl1IjhNf"
      },
      "source": [
        "##Exibindo métricas do modelo no TensorBoard Agora, vamos visualizar as métricas dessas computações federadas usando o Tensorboard.\n",
        "\n",
        "Vamos começar criando o diretório e o gravador de resumo correspondente que gravará as mensagens.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E3QUBK41lWDW"
      },
      "outputs": [],
      "source": [
        "#@test {\"skip\": true}\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "logdir = \"/tmp/logs/scalars/training/\"\n",
        "if os.path.exists(logdir):\n",
        "  shutil.rmtree(logdir)\n",
        "\n",
        "# Your code to create a summary writer:\n",
        "summary_writer = tf.summary.create_file_writer(logdir)\n",
        "\n",
        "state = iterative_process.initialize()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-2aGxUlzS_J"
      },
      "source": [
        "Plote as métricas de escalares relevantes com o mesmo gravador de resumo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JZtr4_8lzN-V"
      },
      "outputs": [],
      "source": [
        "#@test {\"skip\": true}\n",
        "with summary_writer.as_default():\n",
        "  for round_num in range(1, NUM_ROUNDS):\n",
        "    state, metrics = iterative_process.next(state, federated_train_data)\n",
        "    for name, value in metrics['train'].items():\n",
        "      tf.summary.scalar(name, value, step=round_num)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUouyAHG0Mk8"
      },
      "source": [
        "Inicialize o TensorBoard com o diretório de log raiz especificado acima. O carregamento dos dados pode demorar alguns segundos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "urYYcmA9089p"
      },
      "outputs": [],
      "source": [
        "#@test {\"skip\": true}\n",
        "%tensorboard --logdir /tmp/logs/scalars/ --port=0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jejrFEVP1EDs"
      },
      "source": [
        "Para ver as métricas de avaliação da mesma forma, você pode criar uma pasta eval separada, como \"logs/scalars/eval\", para gravar no TensorBoard."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7lz59lMJ0kj"
      },
      "source": [
        "## Avaliação\n",
        "\n",
        "Para fazer a avaliação de dados federados, você pode construir outra *computação federada* criada para esse fim por meio da função `tff.learning.build_federated_evaluation` e passando seu construtor do modelo como argumento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nRiXyqnXM2VO"
      },
      "outputs": [],
      "source": [
        "# Construct federated evaluation computation here:\n",
        "evaluation = tff.learning.build_federated_evaluation(model_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SpfgdNDoRjPy"
      },
      "source": [
        "Agora, vamos compilar uma amostra de teste dos dados federados e executar a avaliação novamente para os dados de teste, que virão de uma amostra diferente de usuários, mas de um conjunto de dados externo distinto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "in8vProVNc04"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "shuffled_ids = emnist_test.client_ids.copy()\n",
        "random.shuffle(shuffled_ids)\n",
        "sample_clients = shuffled_ids[0:NUM_CLIENTS]\n",
        "\n",
        "federated_test_data = make_federated_data(emnist_test, sample_clients)\n",
        "\n",
        "len(federated_test_data), federated_test_data[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ty-ZwfE0NJfV"
      },
      "outputs": [],
      "source": [
        "# Run evaluation on the test data here, using the federated model produced from \n",
        "# training:\n",
        "test_metrics = evaluation(state.model, federated_test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e5fGtIJYNqYH"
      },
      "outputs": [],
      "source": [
        "str(test_metrics)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67vYxrDWzRcj"
      },
      "source": [
        "Isso concluí este tutorial. Sugerimos que você faça experimentos com os parâmetros (por exemplo, tamanho de lote, número de usuários, épocas, taxas de aprendizado, etc.) para modificar o código acima a fim de simular o treinamento com amostras de usuários aleatórias em cada rodada e para explorar os outros tutoriais criados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Zv28F7QLo8O"
      },
      "source": [
        "# Crie seus próprios algoritmos de aprendizado federado\n",
        "\n",
        "Nos tutoriais anteriores, aprendemos a configurar o modelo e os pipelines de dados, que serão usados para fazer o treinamento federado utilizando a API `tff.learning`.\n",
        "\n",
        "Na pesquisa de aprendizado federado, essa é só a ponta do iceberg. Neste tutorial, vamos discutir como implementar algoritmos de aprendizado federado *sem* usar a API `tff.learning`. Nossos objetivos são os seguintes:\n",
        "\n",
        "**Objetivos:**\n",
        "\n",
        "- Entender a estrutura geral dos algoritmos de aprendizado federado.\n",
        "- Explorar o *Federated Core* do TFF.\n",
        "- Usar o Federated Core para implementar a agregação federada diretamente.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQ_N9XbULo8P"
      },
      "source": [
        "## Prepare os dados de entrada\n",
        "\n",
        "Primeiro, carregamos e pré-processamos o dataset EMNIST incluído no TFF. Basicamente, usamos o mesmo código do primeiro tutorial."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-WdnFluLLo8P"
      },
      "outputs": [],
      "source": [
        "emnist_train, emnist_test = tff.simulation.datasets.emnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Blrh8zJgLo8R"
      },
      "outputs": [],
      "source": [
        "NUM_CLIENTS = 10\n",
        "BATCH_SIZE = 20\n",
        "\n",
        "def preprocess(dataset):\n",
        "\n",
        "  def batch_format_fn(element):\n",
        "    \"\"\"Flatten a batch of EMNIST data and return a (features, label) tuple.\"\"\"\n",
        "    return (tf.reshape(element['pixels'], [-1, 784]), \n",
        "            tf.reshape(element['label'], [-1, 1]))\n",
        "\n",
        "  return dataset.batch(BATCH_SIZE).map(batch_format_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-vYM_IT7Lo8W"
      },
      "outputs": [],
      "source": [
        "client_ids = np.random.choice(emnist_train.client_ids, size=NUM_CLIENTS, replace=False)\n",
        "\n",
        "federated_train_data = [preprocess(emnist_train.create_tf_dataset_for_client(x))\n",
        "  for x in client_ids\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNO_Y9j_Lo8X"
      },
      "source": [
        "## Prepare o modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJ0I89ixz8yV"
      },
      "source": [
        "Usamos o mesmo modelo do primeiro tutorial, que tem uma única camada oculta seguida por uma camada softmax."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yfld4oFNLo8Y"
      },
      "outputs": [],
      "source": [
        "def create_keras_model():\n",
        "  return tf.keras.models.Sequential([\n",
        "      tf.keras.layers.InputLayer(input_shape=(784,)),\n",
        "      tf.keras.layers.Dense(10, kernel_initializer='zeros'),\n",
        "      tf.keras.layers.Softmax(),\n",
        "  ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLln0Q8G0Bky"
      },
      "source": [
        "Encapsulamos esse modelo do Keras como `tff.learning.Model`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SPwbipTNLo8a"
      },
      "outputs": [],
      "source": [
        "def model_fn():\n",
        "  keras_model = create_keras_model()\n",
        "  return tff.learning.from_keras_model(\n",
        "      keras_model,\n",
        "      input_spec=federated_train_data[0].element_spec,\n",
        "      loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPOWP2JjsfTk"
      },
      "source": [
        "# Personalize o algoritmo de aprendizado federado\n",
        "\n",
        "Embora a API `tff.learning` abarque diversas variantes da agregação federada, há diversos outros algoritmos que não são perfeitamente adequados para este framework. Por exemplo, talvez você queira acrescentar regularização, recorte ou algoritmos mais complicados, como [treinamento federado de GAN](https://github.com/google-research/federated/blob/master/gans). Talvez você também tenha interesse em [análise federada](https://ai.googleblog.com/2020/05/federated-analytics-collaborative-data.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50N36Zz8qyY-"
      },
      "source": [
        "Para esses algoritmos mais avançados, teremos que escrever nosso próprio algoritmo personalizado de aprendizado federado.\n",
        "\n",
        "De forma geral, os algoritmos de aprendizado federado têm quatro componentes principais:\n",
        "\n",
        "1. Um passo de difusão servidor para cliente.\n",
        "2. Um passo de atualização do cliente local.\n",
        "3. Um passo de upload cliente para servidor.\n",
        "4. Um passo de atualização do servidor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jH8s0GRdQt3b"
      },
      "source": [
        "No TFF, geralmente representamos algoritmos federados como um `IterativeProcess` (processo iterativo), que é uma classe que contém `initialize_fn` e `next_fn`. A função `initialize_fn` é usada para inicializar o servidor, enquanto a função `next_fn` faz uma rodada de comunicação de agregação federada. Vamos escrever um esqueleto do nosso processo de iteração para FedAvg.\n",
        "\n",
        "Primeiro, temos uma função de inicialização que simplesmente cria um `tff.learning.Model` e retorna seus pesos treináveis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ylLpRa7T5DDh"
      },
      "outputs": [],
      "source": [
        "def initialize_fn():\n",
        "  model = model_fn()\n",
        "  return model.weights.trainable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nb1-XAK8fB2A"
      },
      "source": [
        "Essa função parece boa, mas, como veremos posteriormente, precisaremos fazer uma pequena modificação para transformá-la em uma computação do TFF.\n",
        "\n",
        "Também queremos esboçar a função `next_fn`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IeHN-XLZfMso"
      },
      "outputs": [],
      "source": [
        "def next_fn(server_weights, federated_dataset):\n",
        "  # Broadcast the server weights to the clients.\n",
        "  server_weights_at_client = broadcast(server_weights)\n",
        "\n",
        "  # Each client computes their updated weights.\n",
        "  client_weights = client_update(federated_dataset, server_weights_at_client)\n",
        "\n",
        "  # The server averages these updates.\n",
        "  mean_client_weights = mean(client_weights)\n",
        "\n",
        "  # The server updates its model.\n",
        "  server_weights = server_update(mean_client_weights)\n",
        "\n",
        "  return server_weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWXvjXPWeujU"
      },
      "source": [
        "Vamos nos concentrar na implementação desses quatro componentes separadamente. Primeiro, vamos nos concentrar nas partes que podem ser implementadas totalmente no TensorFlow, ou seja, os passos de atualização do cliente e do servidor.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yKS4VkALo8g"
      },
      "source": [
        "## Blocos do TensorFlow "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxpNYucgLo8g"
      },
      "source": [
        "### Atualização do cliente\n",
        "\n",
        "Usaremos nosso `tff.learning.Model` para o treinamento do cliente basicamente da mesma maneira que treinaríamos um modelo do TF. Especificamente, usaremos `tf.GradientTape` para computar o gradiente dos lotes de dados e depois aplicaremos esse gradiente usando um `client_optimizer`.\n",
        "\n",
        "Observe que cada instância de `tff.learning.Model` tem um atributo `weights` (pesos) com dois subatributos:\n",
        "\n",
        "- `trainable`: lista dos tensores que correspondem a camadas treináveis.\n",
        "- `non_trainable`: lista dos tensores que correspondem a camadas não treináveis.\n",
        "\n",
        "Para nossos objetivos, usaremos somente os pesos treináveis (pois nosso modelo tem somente esse tipo de peso).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c5rHPKreLo8g"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def client_update(model, dataset, server_weights, client_optimizer):\n",
        "  \"\"\"Performs training (using the server model weights) on the client's dataset.\"\"\"\n",
        "  # Initialize the client model with the current server weights.\n",
        "  client_weights = model.weights.trainable\n",
        "  # Assign the server weights to the client model.\n",
        "  tf.nest.map_structure(lambda x, y: x.assign(y),\n",
        "                        client_weights, server_weights)\n",
        "\n",
        "  # Use the client_optimizer to update the local model.\n",
        "  for batch in dataset:\n",
        "    with tf.GradientTape() as tape:\n",
        "      # Compute a forward pass on the batch of data\n",
        "      outputs = model.forward_pass(batch)\n",
        "\n",
        "    # Compute the corresponding gradient\n",
        "    grads = tape.gradient(outputs.loss, client_weights)\n",
        "    grads_and_vars = zip(grads, client_weights)\n",
        "\n",
        "    # Apply the gradient using a client optimizer.\n",
        "    client_optimizer.apply_gradients(grads_and_vars)\n",
        "\n",
        "  return client_weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pP0D9XtoLo8i"
      },
      "source": [
        "### Atualização do servidor\n",
        "\n",
        "A atualização do servidor requer ainda menos esforços. Implementamos a agregação federada comum, em que apenas substituímos os pesos do modelo do servidor pela média dos pesos do modelo do cliente. Novamente, nos concentraremos somente nos pesos treináveis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rYxErLvHLo8i"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def server_update(model, mean_client_weights):\n",
        "  \"\"\"Updates the server model weights as the average of the client model weights.\"\"\"\n",
        "  model_weights = model.weights.trainable\n",
        "  # Assign the mean client weights to the server model.\n",
        "  tf.nest.map_structure(lambda x, y: x.assign(y),\n",
        "                        model_weights, mean_client_weights)\n",
        "  return model_weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddCklfWlVr1U"
      },
      "source": [
        "Observe que o trecho de código acima é um exagero, pois poderíamos simplesmente retornar `mean_client_weights`. Entretanto, para implementações mais avançadas de agregação federada, poderíamos usar `mean_client_weights` com técnicas mais sofisticadas, como momento e adaptatividade."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KuP9g6RFLo8k"
      },
      "source": [
        "Até agora, escrevemos somente código puro TensorFlow. Isso foi de propósito, pois o TFF permite o uso de muito código TensorFlow que já conhecemos. Porém, agora temos que especificar a *lógica de orquestração*, ou seja, a lógica que dita a difusão feita do servidor para o cliente e o upload do cliente para o servidor.\n",
        "\n",
        "Isso requer o \"Federated Core\" do TFF."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CgFLVPgLo8l"
      },
      "source": [
        "# Introdução ao Federated Core\n",
        "\n",
        "O Federated Core (FC) é um conjunto de interfaces de baixo nível que serve como a base da API `tff.learning`. Porém, essas interfaces não estão limitadas ao aprendizado. De fato, podem ser usadas para análises e muitas outras computações de dados distribuídos.\n",
        "\n",
        "De forma gera, o Federated Core é um ambiente de desenvolvimento que permite uma lógica de programa expressada compactamente para combinar código TensorFlow com operadores de comunicação distribuída (como somas e difusões distribuídas). O objetivo é fornecer aos pesquisadores e usuários controle explícito da comunicação distribuída em seus sistemas sem exigir os detalhes de implementação do sistema (como especificar trocas de mensagem da rede ponto a ponto).\n",
        "\n",
        "Um ponto fundamental é que o TFF foi criado para preservar a privacidade. Portanto, ele permite o controle de onde os dados ficam para evitar o acúmulo indesejado de dados no servidor centralizado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYinjNqZLo8l"
      },
      "source": [
        "## Dados federados\n",
        "\n",
        "Similar ao conceito de \"Tensor\" no TensorFlow, um dos conceitos fundamentais, um conceito importante no TFF são os \"dados federados\", uma coleção de itens de dados hospedados em um grupo de dispositivos em um sistema distribuído (por exemplo, os datasets do cliente ou os pesos do modelo do servidor). Modelamos toda a coleção de itens de dados em todos os dispositivos como um único *valor federado*.\n",
        "\n",
        "Por exemplo, vamos supor que tenhamos dispositivos clientes, cada um com um float representando a temperatura de um sensor. Poderíamos representá-lo como um *float federado* assim:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7EJY0MHpLo8l"
      },
      "outputs": [],
      "source": [
        "federated_float_on_clients = tff.type_at_clients(tf.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSQAXD0FLo8n"
      },
      "source": [
        "Os tipos federados são especificados por um tipo `T` de seus membros constituintes (por exemplo, `tf.float32`) e um grupo `G` de dispositivos. Vamos nos concentrar nos casos em que `G` é `tff.CLIENTS` ou `tff.SERVER`. Um tipo federado como este é representado como `{T}@G`, conforme exibido abaixo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6mlPgubJLo8n"
      },
      "outputs": [],
      "source": [
        "str(federated_float_on_clients)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjAQytkeLo8o"
      },
      "source": [
        "Por que essas colocações são tão importantes? Um objetivo essencial do TFF é permitir a escrita de código que possa ser implantado em um sistema distribuído real. Portanto, isso é essencial para decidir quais subconjuntos de dispositivos executam qual código e onde diferentes conjuntos de dados ficam.\n",
        "\n",
        "O TFF se concentra em três aspectos: *dados*, onde os dados são *colocados* e como os dados estão sendo *transformados*. Os dois primeiros são encapsulados em tipos federados, enquanto o último é encapsulado em *computações federadas*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLT2FmVMLo8p"
      },
      "source": [
        "## Computações federadas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XwDC1vTLo8p"
      },
      "source": [
        "O TFF é um ambiente de programação funcional fortemente tipado, cujas unidades básicas são *computações federadas*, que são partes de lógica que recebem valores federados como entrada e retornam valores federados como saída.\n",
        "\n",
        "Por exemplo, vamos supor que queiramos fazer a média da temperaturas dos nossos sensores do cliente. Podemos definir o seguinte (usando nosso float federado):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IfwXDNR1Lo8p"
      },
      "outputs": [],
      "source": [
        "@tff.federated_computation(tff.type_at_clients(tf.float32))\n",
        "def get_average_temperature(client_temperatures):\n",
        "  return tff.federated_mean(client_temperatures)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSgs6Te5Lo8r"
      },
      "source": [
        "Talvez você pergunte: como isso é diferente do decorador `tf.function` no TensorFlow? A resposta fundamental é que o código gerado por `tff.federated_computation` não é nem codigo TensorFlow nem código Python, é uma especificação de um sistema distribuído em uma *linguagem glue* interna independente de plataforma.\n",
        "\n",
        "Embora isso possa parecer complicado, pense nas computações do TFF como funções com assinaturas de tipo bem definidas. Essas assinaturas de tipo podem ser consultadas diretamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wAG1eDlULo8r"
      },
      "outputs": [],
      "source": [
        "str(get_average_temperature.type_signature)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TveOYFfuLo8s"
      },
      "source": [
        "`tff.federated_computation` recebe argumentos do tipo federado `<float>@CLIENTS` e retorna valores do tipo federado `<float>@SERVER`. As computações federadas também podem ir de servidor a cliente, de cliente a cliente e de servidor a servidor. As computações federadas também podem ser compostas como funções normais, desde que as assinaturas de tipo coincidam.\n",
        "\n",
        "Para dar suporte ao desenvolvimento, o TFF permite invocar uma `tff.federated_computation` como uma função do Python. Por exemplo, podemos chamar:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eFoqtuOTLo8t"
      },
      "outputs": [],
      "source": [
        "get_average_temperature([68.5, 70.3, 69.8])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXn-yje9RJ6H"
      },
      "source": [
        "## Computações não eager (não adiantadas) e o TensorFlow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwyj8f3HLo8w"
      },
      "source": [
        "É preciso ter em mente duas restrições importantes. Primeiro, quando o interpretador do Python encontra um decorador `tff.federated_computation`, é feito o tracing e a serialização da função uma vez para uso futuro. Portanto, as computações do TFF são fundamentalmente *não eager*. Esse comportamento é de certa forma análogo ao do decorador [`tf.function`](https://www.tensorflow.org/api_docs/python/tf/function) no TensorFlow.\n",
        "\n",
        "Segundo, uma computação federada pode consistir somente de operadores federados (como `tff.federated_mean`), que não podem conter operações do TensorFlow. O código TensorFlow precisa estar confinado aos blocos decorados com `tff.tf_computation`. A maior parte do código comum do TensorFlow pode ser decorado diretamente, como a seguinte função que recebe um número e adiciona `0.5` a ele."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "huz3mNmMLo8w"
      },
      "outputs": [],
      "source": [
        "@tff.tf_computation(tf.float32)\n",
        "def add_half(x):\n",
        "  return tf.add(x, 0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ptjWALDLo8y"
      },
      "source": [
        "Também há assinaturas de tipo, mas *sem colocações*. Por exemplo, podemos chamar:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xfAb0vG2Lo8y"
      },
      "outputs": [],
      "source": [
        "str(add_half.type_signature)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNjwrNMjLo8z"
      },
      "source": [
        "Aqui vemos uma diferença importante entre `tff.federated_computation` e `tff.tf_computation`. O primeiro tem colocações explícitas, enquanto o segundo, não.\n",
        "\n",
        "Podemos usar blocos `tff.tf_computation` em computações federadas por meio da especificação de colocações. Vamos criar uma função que adicione 0,5, mas somente a floats federados nos clientes. Podemos fazer isso usando `tff.federated_map`, que aplica uma determinada `tff.tf_computation`, preservando a colocação."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pG6nw3wiLo80"
      },
      "outputs": [],
      "source": [
        "@tff.federated_computation(tff.type_at_clients(tf.float32))\n",
        "def add_half_on_clients(x):\n",
        "  return tff.federated_map(add_half, x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4msKRKJLo81"
      },
      "source": [
        "Essa função é quase idêntica a `add_half`, exceto que recebe somente valores com colocação em `tff.CLIENTS` e retorna valores com a mesma colocação. Podemos ver isso em sua assinatura de tipo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_C2hDiz0Lo82"
      },
      "outputs": [],
      "source": [
        "str(add_half_on_clients.type_signature)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JxQ0DeiLo83"
      },
      "source": [
        "Resumindo:\n",
        "\n",
        "- O TFF faz operações em valores federados.\n",
        "- Cada valor federado tem um *tipo federado*, com um *tipo* (por exemplo, `tf.float32`) e uma *colocação* (por exemplo, `tff.CLIENTS`).\n",
        "- Os valores federados podem ser transformados usando-se *computações federadas*, que devem ser decoradas com `tff.federated_computation`, e uma assinatura de tipo federado.\n",
        "- O código TensorFlow deve ficar contido em blocos com decoradores `tff.tf_computation`.\n",
        "- Esses blocos podem ser incorporados às computações federadas.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvyFWox3Lo83"
      },
      "source": [
        "# Crie seu próprio algoritmo de aprendizado federado (parte 2)\n",
        "\n",
        "Agora que demos uma olhada no Federated Core, podemos criar nosso próprio algoritmo de aprendizado federado. Lembre-se de que definimos acima funções `initialize_fn` e `next_fn` para o algoritmo. `next_fn` usa `client_update` e `server_update` que definimos usando código puro TensorFlow.\n",
        "\n",
        "Porém, para fazer do nosso algoritmo uma computação federada, precisamos que `next_fn` e `initialize_fn` sejam `tff.federated_computations`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvY8fh1cLo84"
      },
      "source": [
        "## Blocos do TensorFlow Federated "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0zNTO7LLo84"
      },
      "source": [
        "### Crie a computação de inicialização\n",
        "\n",
        "A função de inicialização será bem simples: vamos criar um modelo usando `model_fn`. Porém, lembre-se de que precisamos separar o código TensorFlow usando `tff.tf_computation`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jJY9xUBZLo84"
      },
      "outputs": [],
      "source": [
        "@tff.tf_computation\n",
        "def server_init():\n",
        "  model = model_fn()\n",
        "  return model.weights.trainable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGlv8LLgLo85"
      },
      "source": [
        "Em seguida, podemos passá-la diretamente para uma computação federada usando `tff.federated_value`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m2hinzuRLo86"
      },
      "outputs": [],
      "source": [
        "@tff.federated_computation\n",
        "def initialize_fn():\n",
        "  return tff.federated_value(server_init(), tff.SERVER)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFBghOgxLo88"
      },
      "source": [
        "### Crie `next_fn`\n",
        "\n",
        "Agora usaremos nosso código de atualização do cliente e do servidor para escrever o algoritmo em si. Primeiro, transformamos `client_update` em uma `tff.tf_computation` que receba datasets do cliente e pesos do servidor e gere como saída um tensor de pesos do cliente atualizados.\n",
        "\n",
        "Precisamos dos tipos correspondentes para decorar corretamente a função. Felizmente, o tipo dos pesos do servidor pode ser extraído diretamente do modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ph_noHN2Lo88"
      },
      "outputs": [],
      "source": [
        "whimsy_model = model_fn()\n",
        "tf_dataset_type = tff.SequenceType(whimsy_model.input_spec)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMPgpTaW66qx"
      },
      "source": [
        "Vamos conferir a assinatura de tipo do dataset. Lembre-se de que pegamos imagens 28x28 (com rótulos inteiros) e as nivelamos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ju91izuz64wD"
      },
      "outputs": [],
      "source": [
        "str(tf_dataset_type)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuS8d0BHLo8-"
      },
      "source": [
        "Também podemos extrair o tipo de pesos do modelo usando a função `server_init` acima."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4yx6CExMLo8-"
      },
      "outputs": [],
      "source": [
        "model_weights_type = server_init.type_signature.result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mS-Eh6Xj7J15"
      },
      "source": [
        "Ao avaliar a assinatura de tipos, poderemos ver a arquitetura do modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nPdhhM1O7IIL"
      },
      "outputs": [],
      "source": [
        "str(model_weights_type)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1U1wTGRLo8_"
      },
      "source": [
        "Agora, vamos criar `tff.tf_computation` para a atualização do cliente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q0W05pMWLo9A"
      },
      "outputs": [],
      "source": [
        "@tff.tf_computation(tf_dataset_type, model_weights_type)\n",
        "def client_update_fn(tf_dataset, server_weights):\n",
        "  model = model_fn()\n",
        "  client_optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
        "  return client_update(model, tf_dataset, server_weights, client_optimizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uP5quaAuLo9B"
      },
      "source": [
        "A versão de `tff.tf_computation` da atualização do servidor pode ser definida de forma similar, usando os tipos que já extraímos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F4WvQtVzLo9B"
      },
      "outputs": [],
      "source": [
        "@tff.tf_computation(model_weights_type)\n",
        "def server_update_fn(mean_client_weights):\n",
        "  model = model_fn()\n",
        "  return server_update(model, mean_client_weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SImhLbu4Lo9D"
      },
      "source": [
        "Por último, precisamos criar a `tff.federated_computation` que junta tudo isso. Essa função receberá dois *valores federados*, um correspondente aos pesos do servidor (com a colocação `tff.SERVER`) e outro correspondente aos datasets do cliente (com colocação `tff.CLIENTS`).\n",
        "\n",
        "Esses dois tipos foram definidos acima. Só precisamos definir a colocação correta para eles usando `tff.type_at_{server/clients}``."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ekPsA8AsLo9D"
      },
      "outputs": [],
      "source": [
        "federated_server_type = tff.type_at_server(model_weights_type)\n",
        "federated_dataset_type = tff.type_at_clients(tf_dataset_type)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FXAX7vGLo9G"
      },
      "source": [
        "Lembra-se dos quatro elementos de um algoritmo de aprendizado federado?\n",
        "\n",
        "1. Um passo de difusão servidor para cliente.\n",
        "2. Um passo de atualização do cliente local.\n",
        "3. Um passo de upload cliente para servidor.\n",
        "4. Um passo de atualização do servidor.\n",
        "\n",
        "Agora que construímos tudo isso, cada parte pode ser representada compactamente como uma única linha de código do TFF. É por essa simplicidade que tomamos cuidado redobrado ao especificar os tipos federados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Epc7MwfELo9G"
      },
      "outputs": [],
      "source": [
        "@tff.federated_computation(federated_server_type, federated_dataset_type)\n",
        "def next_fn(server_weights, federated_dataset):\n",
        "  # Broadcast the server weights to the clients.\n",
        "  server_weights_at_client = tff.federated_broadcast(server_weights)\n",
        "\n",
        "  # Each client computes their updated weights.\n",
        "  client_weights = tff.federated_map(\n",
        "      client_update_fn, (federated_dataset, server_weights_at_client))\n",
        "  \n",
        "  # The server averages these updates.\n",
        "  mean_client_weights = tff.federated_mean(client_weights)\n",
        "\n",
        "  # The server updates its model.\n",
        "  server_weights = tff.federated_map(server_update_fn, mean_client_weights)\n",
        "\n",
        "  return server_weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWomG3TtLo9I"
      },
      "source": [
        "Agora temos uma `tff.federated_computation` para o algoritmo de inicialização e para executar um passo do algoritmo. Para finalizar o algoritmo, nós os passamos para `tff.templates.IterativeProcess`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GxdWgEddLo9I"
      },
      "outputs": [],
      "source": [
        "federated_algorithm = tff.templates.IterativeProcess(\n",
        "    initialize_fn=initialize_fn,\n",
        "    next_fn=next_fn\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Z__9k-Dc1I3"
      },
      "source": [
        "Vamos conferir a *assinatura de tipo* das funções `initialize` e `next` do processo iterativo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kyRLXDj-Lo9J"
      },
      "outputs": [],
      "source": [
        "str(federated_algorithm.initialize.type_signature)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UyyEi5Kec90_"
      },
      "source": [
        "Isso reflete o fato de `federated_algorithm.initialize` ser uma função sem argumentos que retorna um modelo de uma única camada (com uma matriz de pesos 784 por 10 e 10 unidades de bias)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mx6yuIKtLo9M"
      },
      "outputs": [],
      "source": [
        "str(federated_algorithm.next.type_signature)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efpdHodmdU_6"
      },
      "source": [
        "Aqui, vemos que `federated_algorithm.next` recebe um modelo do servidor e dados do cliente, e retorna um modelo do servidor atualizado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4UYZ3qeMLo9N"
      },
      "source": [
        "## Avalie o algoritmo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwd9Gs0ULo9O"
      },
      "source": [
        "Vamos executar algumas rodadas e ver como a perda muda. Primeiro, vamos definir uma função de avaliação usando a estratégia *centralizada* discutida no segundo tutorial.\n",
        "\n",
        "Primeiro, criamos um dataset de avaliação centralizado e depois aplicamos o mesmo pré-processamento usado para os dados de treinamento.\n",
        "\n",
        "Observe que apenas recebemos (`take`) os primeiros 1.000 elementos por motivos de eficiência computacional, mas, geralmente, usaríamos todo o dataset de teste."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EdNgYoIwLo9P"
      },
      "outputs": [],
      "source": [
        "central_emnist_test = emnist_test.create_tf_dataset_from_all_clients().take(1000)\n",
        "central_emnist_test = preprocess(central_emnist_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7R50NZ35dphE"
      },
      "source": [
        "Em seguida, escrevemos uma função que receba um estado do servidor e use o Keras para fazer a avaliação para o dataset de teste. Se você já conhece `tf.Keras`, reconhecerá esse código, exceto pelo uso de `set_weights`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I5UEX4EWLo9Q"
      },
      "outputs": [],
      "source": [
        "def evaluate(server_state):\n",
        "  keras_model = create_keras_model()\n",
        "  keras_model.compile(\n",
        "      loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]  \n",
        "  )\n",
        "  keras_model.set_weights(server_state)\n",
        "  keras_model.evaluate(central_emnist_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hygoBACkLo9S"
      },
      "source": [
        "Agora, vamos inicializar o algoritmo e fazer a avaliação para o dataset de teste."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JC6zMDTTLo9S"
      },
      "outputs": [],
      "source": [
        "server_state = federated_algorithm.initialize()\n",
        "evaluate(server_state)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2knqix2cLo9U"
      },
      "source": [
        "Vamos treinar por algumas rodadas e ver se algo muda."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v1zBlzFILo9U"
      },
      "outputs": [],
      "source": [
        "for round in range(15):\n",
        "  server_state = federated_algorithm.next(server_state, federated_train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q91Vjyc_jumU"
      },
      "outputs": [],
      "source": [
        "evaluate(server_state)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XM34ammUW-T3"
      },
      "source": [
        "Vemos uma pequena diminuição na função de perda. Embora a mudança seja pequena, observe que só fizemos 10 rodadas de treinamento com um subconjunto de clientes pequeno. Para obter resultados melhores, talvez precisemos de centenas ou milhares de rodadas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o13H5dDFXRFn"
      },
      "source": [
        "## Modificação do algoritmo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qt4jVD21XTL-"
      },
      "source": [
        "Agora, vamos parar e pensar no que fizemos. Implementamos agregação federada diretamente pela combinação de código puro TensorFlow (para as atualizações do servidor e do cliente) com computações federadas usando o Federated Core do TFF.\n",
        "\n",
        "Para fazer um aprendizado mais sofisticado, basta alterar o que temos acima. Especificamente, ao editar o código puro TF acima, podemos mudar como o cliente faz o treinamento ou como o servidor atualiza seu modelo.\n",
        "\n",
        "**Desafio:** acrescente [recorte de gradiente](https://towardsdatascience.com/what-is-gradient-clipping-b8e815cdfb48) à função `client_update`.\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "openmined_conference_2020.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
