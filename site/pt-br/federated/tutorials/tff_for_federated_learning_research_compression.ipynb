{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exFeYM4KWlz9"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Oj6X6JHoWtVs"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPFgLeZIsZ3Q"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>     <a target=\"_blank\" href=\"https://www.tensorflow.org/federated/tutorials/tff_for_federated_learning_research_compression\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver em TensorFlow.org</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/pt-br/federated/tutorials/tff_for_federated_learning_research_compression.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Executar no Google Colab</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/pt-br/federated/tutorials/tff_for_federated_learning_research_compression.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver fonte no GitHub</a>\n",
        "</td>\n",
        "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/pt-br/federated/tutorials/tff_for_federated_learning_research_compression.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Baixar notebook</a>\n",
        "</td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5DZ2c-xfa9m"
      },
      "source": [
        "# TFF para pesquisa de aprendizado federado – Compressão de modelo e atualização\n",
        "\n",
        "**OBSERVAÇÃO**: foi verificado que este Colab funciona com a [versão mais recente lançada](https://github.com/tensorflow/federated#compatibility) do pacote pip `tensorflow_federated`. Talvez não seja possível atualizar este Colab para funcionar no `master`.\n",
        "\n",
        "Neste tutorial, usamos o dataset [EMNIST](https://www.tensorflow.org/federated/api_docs/python/tff/simulation/datasets/emnist) para demonstrar como permitir algoritmos de compressão com perda para reduzir o custo de comunicação no algoritmo de cálculo federado de médias usando a API `tff.learning`. Para mais detalhes sobre o algoritmo de cálculo federado de médias, confira o artigo [Communication-Efficient Learning of Deep Networks from Decentralized Data](https://arxiv.org/abs/1602.05629) (Aprendizado de redes profundas com comunicação eficiente usando dados descentralizados)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrPTFv7ngz-P"
      },
      "source": [
        "## Antes de começarmos\n",
        "\n",
        "Antes de começarmos, execute o código abaixo para que o ambiente seja configurado corretamente. Se não for exibida uma saudação, consulte as instruções de [instalação](../install.md)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X_JnSqDxlw5T"
      },
      "outputs": [],
      "source": [
        "#@test {\"skip\": true}\n",
        "!pip install --quiet --upgrade tensorflow-federated\n",
        "!pip install --quiet --upgrade tensorflow-model-optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ctxIBpYIl846"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "\n",
        "import functools\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_federated as tff"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wj-O1cnxKHMw"
      },
      "source": [
        "Verifique se o TFF está funcionando."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8VPepVmfdhHv"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "b'Hello, World!'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "@tff.federated_computation\n",
        "def hello_world():\n",
        "  return 'Hello, World!'\n",
        "\n",
        "hello_world()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30Pln72ihL-z"
      },
      "source": [
        "## Prepare os dados de entrada\n",
        "\n",
        "Nesta seção, carregamos e pré-processamos o dataset EMNIST incluído no TFF. Confira mais detalhes sobre esse dataset no tutorial [Aprendizado federado para classificação de imagens](https://www.tensorflow.org/federated/tutorials/federated_learning_for_image_classification#preparing_the_input_data).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oTP2Dndbl2Oe"
      },
      "outputs": [],
      "source": [
        "# This value only applies to EMNIST dataset, consider choosing appropriate\n",
        "# values if switching to other datasets.\n",
        "MAX_CLIENT_DATASET_SIZE = 418\n",
        "\n",
        "CLIENT_EPOCHS_PER_ROUND = 1\n",
        "CLIENT_BATCH_SIZE = 20\n",
        "TEST_BATCH_SIZE = 500\n",
        "\n",
        "emnist_train, emnist_test = tff.simulation.datasets.emnist.load_data(\n",
        "    only_digits=True)\n",
        "\n",
        "def reshape_emnist_element(element):\n",
        "  return (tf.expand_dims(element['pixels'], axis=-1), element['label'])\n",
        "\n",
        "def preprocess_train_dataset(dataset):\n",
        "  \"\"\"Preprocessing function for the EMNIST training dataset.\"\"\"\n",
        "  return (dataset\n",
        "          # Shuffle according to the largest client dataset\n",
        "          .shuffle(buffer_size=MAX_CLIENT_DATASET_SIZE)\n",
        "          # Repeat to do multiple local epochs\n",
        "          .repeat(CLIENT_EPOCHS_PER_ROUND)\n",
        "          # Batch to a fixed client batch size\n",
        "          .batch(CLIENT_BATCH_SIZE, drop_remainder=False)\n",
        "          # Preprocessing step\n",
        "          .map(reshape_emnist_element))\n",
        "\n",
        "emnist_train = emnist_train.preprocess(preprocess_train_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUQA55yjhTGh"
      },
      "source": [
        "## Definição do modelo\n",
        "\n",
        "Definimos um modelo do Keras baseado na CNN FedAvg original e então encapsulamos o modelo do Keras em uma instância de [tff.learning.models.VariableModel](https://www.tensorflow.org/federated/api_docs/python/tff/learning/Model) para que ele possa ser consumido pelo TFF.\n",
        "\n",
        "Precisaremos de uma **função** que gere um modelo em vez de simplesmente um modelo direto. Além disso, a função **não pode** simplesmente capturar um modelo pré-construído, ela precisa criar o modelo no contexto em que é chamada. O motivo para isso é que o TFF foi projetado para uso em dispositivos e precisa controlar quando os recursos são construídos para que eles possam ser capturados e empacotados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f2dLONjFnE2E"
      },
      "outputs": [],
      "source": [
        "def create_original_fedavg_cnn_model(only_digits=True):\n",
        "  \"\"\"The CNN model used in https://arxiv.org/abs/1602.05629.\"\"\"\n",
        "  data_format = 'channels_last'\n",
        "\n",
        "  max_pool = functools.partial(\n",
        "      tf.keras.layers.MaxPooling2D,\n",
        "      pool_size=(2, 2),\n",
        "      padding='same',\n",
        "      data_format=data_format)\n",
        "  conv2d = functools.partial(\n",
        "      tf.keras.layers.Conv2D,\n",
        "      kernel_size=5,\n",
        "      padding='same',\n",
        "      data_format=data_format,\n",
        "      activation=tf.nn.relu)\n",
        "\n",
        "  model = tf.keras.models.Sequential([\n",
        "      tf.keras.layers.InputLayer(input_shape=(28, 28, 1)),\n",
        "      conv2d(filters=32),\n",
        "      max_pool(),\n",
        "      conv2d(filters=64),\n",
        "      max_pool(),\n",
        "      tf.keras.layers.Flatten(),\n",
        "      tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "      tf.keras.layers.Dense(10 if only_digits else 62),\n",
        "      tf.keras.layers.Softmax(),\n",
        "  ])\n",
        "\n",
        "  return model\n",
        "\n",
        "# Gets the type information of the input data. TFF is a strongly typed\n",
        "# functional programming framework, and needs type information about inputs to \n",
        "# the model.\n",
        "input_spec = emnist_train.create_tf_dataset_for_client(\n",
        "    emnist_train.client_ids[0]).element_spec\n",
        "\n",
        "def tff_model_fn():\n",
        "  keras_model = create_original_fedavg_cnn_model()\n",
        "  return tff.learning.models.from_keras_model(\n",
        "      keras_model=keras_model,\n",
        "      input_spec=input_spec,\n",
        "      loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipfUaPLEhYYj"
      },
      "source": [
        "## Treinamento do modelo e geração das métricas de treinamento como saída\n",
        "\n",
        "Agora está tudo pronto para construirmos o algoritmo de cálculo federado de médias e treinarmos o modelo definido com o dataset EMNIST.\n",
        "\n",
        "Primeiro, precisamos construir um algoritmo de cálculo federado de médias usando a API [tff.learning.algorithms.build_weighted_fed_avg](https://www.tensorflow.org/federated/api_docs/python/tff/learning/algorithms/build_weighted_fed_avg)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SAsGGkL9nHEl"
      },
      "outputs": [],
      "source": [
        "federated_averaging = tff.learning.algorithms.build_weighted_fed_avg(\n",
        "    model_fn=tff_model_fn,\n",
        "    client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.02),\n",
        "    server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1.0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mn1FAPQ32FcV"
      },
      "source": [
        "Agora, vamos executar o algoritmo de cálculo federado de médias. Sua execução pela perspectiva do TFF é da seguinte forma:\n",
        "\n",
        "1. Inicialize o algoritmo e obtenha o estado inicial do servidor, que contém as informações necessárias para executar o algoritmo. Lembre-se de que, como o TFF é funcional, esse estado inclui tanto o estado do otimizador usado pelo algoritmo (ou seja, termos do momento) quanto os parâmetros do modelo em si (que serão passados como argumentos e retornados como resultados a partir das computações do TFF).\n",
        "2. Execute o algoritmo rodada por rodada. Em cada rodada, um novo estado do servidor será retornado como resultado do treinamento do modelo feito por cada cliente com seus dados. Tipicamente, em uma rodada:\n",
        "    1. O servidor faz broadcast do modelo para todos os clientes participantes.\n",
        "    2. Cada cliente realiza o trabalho com base no modelo e seus próprios dados.\n",
        "    3. O servidor agrega todo o modelo para gerar um estado do servidor que contenha um novo modelo.\n",
        "\n",
        "Confira mais detalhes no tutorial [Algoritmos federados personalizados, parte 2: Implementando o cálculo federado de médias](https://www.tensorflow.org/federated/tutorials/custom_federated_algorithms_2).\n",
        "\n",
        "As métricas de treinamento são escritas no diretório do TensorBoard para exibição após o treinamento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jvH6qIgynI8S"
      },
      "outputs": [],
      "source": [
        "def train(federated_averaging_process, num_rounds, num_clients_per_round, summary_writer):\n",
        "  \"\"\"Trains the federated averaging process and output metrics.\"\"\"\n",
        "\n",
        "  # Initialize the Federated Averaging algorithm to get the initial server state.\n",
        "  state = federated_averaging_process.initialize()\n",
        "\n",
        "  with summary_writer.as_default():\n",
        "    for round_num in range(num_rounds):\n",
        "      # Sample the clients parcitipated in this round.\n",
        "      sampled_clients = np.random.choice(\n",
        "          emnist_train.client_ids,\n",
        "          size=num_clients_per_round,\n",
        "          replace=False)\n",
        "      # Create a list of `tf.Dataset` instances from the data of sampled clients.\n",
        "      sampled_train_data = [\n",
        "          emnist_train.create_tf_dataset_for_client(client)\n",
        "          for client in sampled_clients\n",
        "      ]\n",
        "      # Round one round of the algorithm based on the server state and client data\n",
        "      # and output the new state and metrics.\n",
        "      result = federated_averaging_process.next(state, sampled_train_data)\n",
        "      state = result.state\n",
        "      train_metrics = result.metrics['client_work']['train']\n",
        "\n",
        "      # Add metrics to Tensorboard.\n",
        "      for name, value in train_metrics.items():\n",
        "          tf.summary.scalar(name, value, step=round_num)\n",
        "      summary_writer.flush()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xp3o3QcBlqY_"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "round  0, train_metrics=OrderedDict([('sparse_categorical_accuracy', 0.092454836), ('loss', 2.310193), ('num_examples', 941), ('num_batches', 51)]), broadcasted_bits=507.62Mibit, aggregated_bits=507.62Mibit\n",
            "round  1, train_metrics=OrderedDict([('sparse_categorical_accuracy', 0.10029791), ('loss', 2.3102622), ('num_examples', 1007), ('num_batches', 55)]), broadcasted_bits=1015.24Mibit, aggregated_bits=1015.25Mibit\n",
            "round  2, train_metrics=OrderedDict([('sparse_categorical_accuracy', 0.10710711), ('loss', 2.3048222), ('num_examples', 999), ('num_batches', 54)]), broadcasted_bits=1.49Gibit, aggregated_bits=1.49Gibit\n",
            "round  3, train_metrics=OrderedDict([('sparse_categorical_accuracy', 0.1061061), ('loss', 2.3066027), ('num_examples', 999), ('num_batches', 55)]), broadcasted_bits=1.98Gibit, aggregated_bits=1.98Gibit\n",
            "round  4, train_metrics=OrderedDict([('sparse_categorical_accuracy', 0.1287594), ('loss', 2.2999024), ('num_examples', 1064), ('num_batches', 58)]), broadcasted_bits=2.48Gibit, aggregated_bits=2.48Gibit\n",
            "round  5, train_metrics=OrderedDict([('sparse_categorical_accuracy', 0.13529412), ('loss', 2.2994456), ('num_examples', 1020), ('num_batches', 55)]), broadcasted_bits=2.97Gibit, aggregated_bits=2.97Gibit\n",
            "round  6, train_metrics=OrderedDict([('sparse_categorical_accuracy', 0.124045804), ('loss', 2.2947247), ('num_examples', 1048), ('num_batches', 57)]), broadcasted_bits=3.47Gibit, aggregated_bits=3.47Gibit\n",
            "round  7, train_metrics=OrderedDict([('sparse_categorical_accuracy', 0.14217557), ('loss', 2.290349), ('num_examples', 1048), ('num_batches', 57)]), broadcasted_bits=3.97Gibit, aggregated_bits=3.97Gibit\n",
            "round  8, train_metrics=OrderedDict([('sparse_categorical_accuracy', 0.14641434), ('loss', 2.290953), ('num_examples', 1004), ('num_batches', 56)]), broadcasted_bits=4.46Gibit, aggregated_bits=4.46Gibit\n",
            "round  9, train_metrics=OrderedDict([('sparse_categorical_accuracy', 0.1695238), ('loss', 2.2859888), ('num_examples', 1050), ('num_batches', 57)]), broadcasted_bits=4.96Gibit, aggregated_bits=4.96Gibit\n"
          ]
        }
      ],
      "source": [
        "# Clean the log directory to avoid conflicts.\n",
        "try:\n",
        "  tf.io.gfile.rmtree('/tmp/logs/scalars')\n",
        "except tf.errors.OpError as e:\n",
        "  pass  # Path doesn't exist\n",
        "\n",
        "# Set up the log directory and writer for Tensorboard.\n",
        "logdir = \"/tmp/logs/scalars/original/\"\n",
        "summary_writer = tf.summary.create_file_writer(logdir)\n",
        "\n",
        "train(federated_averaging_process=federated_averaging, num_rounds=10,\n",
        "      num_clients_per_round=10, summary_writer=summary_writer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwdpTySt7pGQ"
      },
      "source": [
        "Inicialize o TensorBoard com o diretório de logs raiz especificado acima para exibir as métricas de treinamento. Pode demorar alguns segundos para os dados serem carregados. Exceto pela perda e exatidão, geramos como saída a quantidade de dados transmitidos via broadcast e agregados. Os dados transmitidos via broadcast referem-se aos tensores que o servidor envia para cada cliente, enquanto os dados agregados referem-se aos tensores que cada cliente envia de volta ao servidor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EJ9XQiL-7e1i"
      },
      "outputs": [],
      "source": [
        "#@test {\"skip\": true}\n",
        "%tensorboard --logdir /tmp/logs/scalars/ --port=0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rY5tWN_5ht6-"
      },
      "source": [
        "## Crie uma função de agregação personalizada\n",
        "\n",
        "Agora, vamos implementar uma função para usar algoritmos de compressão com perda nos dados agregados. Para isso, usaremos a API do TFF para criar uma `tff.aggregators.AggregationFactory`. Embora os pesquisadores costumem querer implementar seu próprio agregador (o que pode ser feito usando a API `tff.aggregators`), usaremos um método integrado para isso, especificamente `tff.learning.compression_aggregator`.\n",
        "\n",
        "É importante observar que esse agregador não aplica compressão a todo o modelo de uma só vez. Em vez disso, aplica compressão somente às variáveis no modelo que são suficientemente grandes. De forma geral, variáveis pequenas, como bias, têm maior sensibilidade à inexatidão e, por serem relativamente pequenas, a possível economia de comunicação também é relativamente pequena."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lkRHkZTTnKn2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "compression_aggregator = tff.learning.compression_aggregator()\n",
        "isinstance(compression_aggregator, tff.aggregators.WeightedAggregationFactory)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82iYUklQKP2e"
      },
      "source": [
        "Acima, podemos ver que o agregador de compressão é uma fábrica de agregação *com pesos*, ou seja, envolve agregação com pesos (ao contrário de agregadores para privacidade diferencial, que costumam não ter pesos).\n",
        "\n",
        "A fábrica de agregação pode ser alimentada diretamente no FedAvg via seu argumento `model_aggregator`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aqD61hqAGZiW"
      },
      "outputs": [],
      "source": [
        "federated_averaging_with_compression = tff.learning.algorithms.build_weighted_fed_avg(\n",
        "    tff_model_fn,\n",
        "    client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.02),\n",
        "    server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1.0),\n",
        "    model_aggregator=compression_aggregator)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3-ADI0hjTqH"
      },
      "source": [
        "## Treine o modelo novamente\n",
        "\n",
        "Agora, vamos executar o novo algoritmo de cálculo federado de médias."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0KM_THYdn1yH"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "round  0, train_metrics=OrderedDict([('sparse_categorical_accuracy', 0.087804876), ('loss', 2.3126457), ('num_examples', 1025), ('num_batches', 55)]), broadcasted_bits=507.62Mibit, aggregated_bits=146.47Mibit\n",
            "round  1, train_metrics=OrderedDict([('sparse_categorical_accuracy', 0.073267326), ('loss', 2.3111901), ('num_examples', 1010), ('num_batches', 56)]), broadcasted_bits=1015.24Mibit, aggregated_bits=292.93Mibit\n",
            "round  2, train_metrics=OrderedDict([('sparse_categorical_accuracy', 0.08925144), ('loss', 2.3071017), ('num_examples', 1042), ('num_batches', 57)]), broadcasted_bits=1.49Gibit, aggregated_bits=439.40Mibit\n",
            "round  3, train_metrics=OrderedDict([('sparse_categorical_accuracy', 0.07985144), ('loss', 2.3061485), ('num_examples', 1077), ('num_batches', 59)]), broadcasted_bits=1.98Gibit, aggregated_bits=585.86Mibit\n",
            "round  4, train_metrics=OrderedDict([('sparse_categorical_accuracy', 0.11947791), ('loss', 2.302166), ('num_examples', 996), ('num_batches', 55)]), broadcasted_bits=2.48Gibit, aggregated_bits=732.33Mibit\n",
            "round  5, train_metrics=OrderedDict([('sparse_categorical_accuracy', 0.12195122), ('loss', 2.2997446), ('num_examples', 984), ('num_batches', 54)]), broadcasted_bits=2.97Gibit, aggregated_bits=878.79Mibit\n",
            "round  6, train_metrics=OrderedDict([('sparse_categorical_accuracy', 0.10429448), ('loss', 2.2997215), ('num_examples', 978), ('num_batches', 55)]), broadcasted_bits=3.47Gibit, aggregated_bits=1.00Gibit\n",
            "round  7, train_metrics=OrderedDict([('sparse_categorical_accuracy', 0.16857143), ('loss', 2.2961135), ('num_examples', 1050), ('num_batches', 56)]), broadcasted_bits=3.97Gibit, aggregated_bits=1.14Gibit\n",
            "round  8, train_metrics=OrderedDict([('sparse_categorical_accuracy', 0.1399177), ('loss', 2.2942808), ('num_examples', 972), ('num_batches', 54)]), broadcasted_bits=4.46Gibit, aggregated_bits=1.29Gibit\n",
            "round  9, train_metrics=OrderedDict([('sparse_categorical_accuracy', 0.14202899), ('loss', 2.2972558), ('num_examples', 1035), ('num_batches', 57)]), broadcasted_bits=4.96Gibit, aggregated_bits=1.43Gibit\n"
          ]
        }
      ],
      "source": [
        "logdir_for_compression = \"/tmp/logs/scalars/compression/\"\n",
        "summary_writer_for_compression = tf.summary.create_file_writer(\n",
        "    logdir_for_compression)\n",
        "\n",
        "train(federated_averaging_process=federated_averaging_with_compression, \n",
        "      num_rounds=10,\n",
        "      num_clients_per_round=10,\n",
        "      summary_writer=summary_writer_for_compression)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sE8Bnjel8TIA"
      },
      "source": [
        "Inicialize o TensorBoard novamente para comparar as métricas de treinamento entre as duas execuções.\n",
        "\n",
        "Como podemos ver no TensorBoard, há uma redução considerável entre a curva `original` e `compression` nos gráficos `aggregated_bits`, enquanto nos gráficos de `loss` e `sparse_categorical_accuracy`, as duas curvas são muito similares.\n",
        "\n",
        "Concluindo, implementamos um algoritmo de compressão que tem desempenho similar ao do algoritmo original de cálculo federado de médias, mas com custo de comunicação consideravelmente menor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K9M2_1re28ff"
      },
      "outputs": [],
      "source": [
        "#@test {\"skip\": true}\n",
        "%tensorboard --logdir /tmp/logs/scalars/ --port=0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jaz9_9H7NUMW"
      },
      "source": [
        "## Exercícios\n",
        "\n",
        "Para implementar um algoritmo de compressão personalizado e aplicá-lo ao loop de treinamento, você pode:\n",
        "\n",
        "1. Implementar um novo algoritmo de compressão como subclasse de [tff.aggregators.MeanFactory](https://www.tensorflow.org/federated/api_docs/python/tff/aggregators/MeanFactory).\n",
        "2. Fazer o treinamento com o algoritmo de compressão para ver se ele tem desempenho melhor do que o algoritmo acima.\n",
        "\n",
        "Confira alguns possíveis campos para pesquisa: quantização não uniforme, compressão sem perda, como Codificação de Huffman, e mecanismos para adaptar a compressão com base nas informações de rodadas de treinamento anteriores.\n",
        "\n",
        "Leituras recomendadas:\n",
        "\n",
        "- [Expanding the Reach of Federated Learning by Reducing Client Resource Requirements](https://research.google/pubs/pub47774/) (Expansão do alcance do aprendizado federado por meio da redução dos requisitos de recursos dos clientes).\n",
        "- [Federated Learning: Strategies for Improving Communication Efficiency](https://research.google/pubs/pub45648/) (Aprendizado federado: Estratégias para melhorar a eficiência da comunicação).\n",
        "- *Seção 3.5 – Communication and Compression* (Comunicação e compressão) em [Advanced and Open Problems in Federated Learning](https://arxiv.org/abs/1912.04977) (Problemas avançados e em aberto no aprendizado federado)."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "tff_for_federated_learning_research_compression.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
