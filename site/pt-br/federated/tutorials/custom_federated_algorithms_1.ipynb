{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lNeCgAVkdhM"
      },
      "source": [
        "##### Copyright 2019 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "uDcWxmG9kh1Q"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32xflLc4NTx-"
      },
      "source": [
        "# Algoritmos federados personalizados, parte 1: introdução ao Federated Core"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyXVak0dknQw"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>     <a target=\"_blank\" href=\"https://www.tensorflow.org/federated/tutorials/custom_federated_algorithms_1\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver em TensorFlow.org</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/pt-br/federated/tutorials/custom_federated_algorithms_1.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Executar no Google Colab</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/pt-br/federated/tutorials/custom_federated_algorithms_1.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver fonte no GitHub</a>\n",
        "</td>\n",
        "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/pt-br/federated/tutorials/custom_federated_algorithms_1.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Baixar notebook</a>\n",
        "</td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_igJ2sfaNWS8"
      },
      "source": [
        "Este tutorial é a primeira parte de uma série de duas partes que demonstra como implementar tipos personalizados de algoritmos federados no TensorFlow Federated (TFF) usando o [Federated Core (FC)](../federated_core.md) - um conjunto de interfaces de nível inferior que servem como base para nossa implementação da camada de [aprendizado federado (FL)](../federated_learning.md).\n",
        "\n",
        "Essa primeira parte é mais conceitual. Apresentamos alguns dos principais conceitos e abstrações de programação usados no TFF, e demonstramos o uso deles em um exemplo bastante simples com um array distribuído de sensores de temperatura. Na [segunda parte dessa série](custom_federated_algorithms_2.ipynb), usamos os mecanismos apresentados aqui para implementar uma versão simples de algoritmos de treinamento federado e avaliação. Em sequência, recomendamos que estude a [implementação](https://github.com/tensorflow/federated/blob/main/tensorflow_federated/python/learning/algorithms/fed_avg.py) do cálculo federado de médias no `tff.learning`.\n",
        "\n",
        "No final da série, você deve conseguir reconhecer que os aplicativos do Federated Core não se limitam necessariamente ao aprendizado. As abstrações de programação que oferecemos são bastante genéricas e podem ser usadas, por exemplo, para implementar a análise de dados e outros tipos personalizados de computações sobre dados distribuídos.\n",
        "\n",
        "Este tutorial foi criado para ser independente, mas recomendamos que você leia primeiro os tutoriais sobre [classificação de imagens](federated_learning_for_image_classification.ipynb) e [geração de texto](federated_learning_for_text_generation.ipynb) para uma introdução mais geral e leve ao framework do TensorFlow Federated e às APIS do [aprendizado federado](../federated_learning.md) (`tff.learning`), ajudando você a contextualizar os conceitos descritos aqui."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09FT9ertw8KP"
      },
      "source": [
        "## Usos pretendidos\n",
        "\n",
        "Resumindo, o Federated Core (FC) é um ambiente de desenvolvimento que possibilita expressar de maneira compacta a lógica de programa que combina o código do TensorFlow com operadores de comunicação distribuída, como aqueles usados no [cálculo federado de médias](https://arxiv.org/abs/1602.05629) - computando somas distribuídas, médias e outros tipos de agregações distribuídas em um conjunto de dispositivos do cliente no sistema, transmitindo modelos e parâmetros a esses dispositivos etc.\n",
        "\n",
        "Talvez você esteja ciente do [`tf.contrib.distribute`](https://www.tensorflow.org/api_docs/python/tf/contrib/distribute) e, neste ponto, é natural se perguntar: qual é a diferença desse framework? Afinal, ambos os frameworks tentam tornar as computações do TensorFlow distribuídas.\n",
        "\n",
        "Uma forma de pensar sobre isso é: enquanto o objetivo declarado de `tf.contrib.distribute` é *permitir que os usuários usem modelos e código de treinamento existentes com mudanças mínimas para o treinamento distribuído*, e grande parte do foco está em como aproveitar a infraestrutura distribuída para deixar o código de treinamento mais eficiente, o objetivo do Federated Core do TFF é dar aos pesquisadores e profissionais o controle explícito sobre os padrões específicos de comunicação distribuída que eles usarão nos seus sistemas. O foco do FC está em fornecer uma linguagem flexível e extensível para expressar os algoritmos de fluxo de dados distribuídos, em vez de um conjunto concreto de capacidades de treinamento distribuídas.\n",
        "\n",
        "Um dos principais públicos-alvo para a API FC do TFF são os pesquisadores e profissionais que desejam testar novos algoritmos de aprendizado federado e avaliar as consequências de decisões sutis de design que afetam a maneira como o fluxo de dados é orquestrado no sistema distribuído, sem que fiquem presos em detalhes de implementação do sistema. O nível de abstração que a API FC visa corresponde praticamente ao pseudocódigo que se usaria para descrever a mecânica de um algoritmo de aprendizado federado em uma pesquisa - quais dados existem no sistema e como ele é transformado, mas sem diminuir o nível das trocas de mensagens entre redes ponto a ponto individuais.\n",
        "\n",
        "O TFF como um todo almeja cenários em que os dados são distribuídos e precisam permanecer assim, por exemplo, por motivos de privacidade e quando coletar todos os dados em uma localização centralizada não é uma opção viável. Isso afeta a implementação de algoritmos de aprendizado de máquina que exigem um maior nível de controle explícito, em comparação com cenários em que todos os dados podem ser acumulados em uma localização centralizada em um data center."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuJuLEh2TfZG"
      },
      "source": [
        "## Antes de começarmos\n",
        "\n",
        "Antes de mergulhar no código, tente executar o seguinte exemplo \"Olá, mundo\" para garantir que o ambiente esteja configurado corretamente. Se não funcionar, consulte as instruções no guia de [instalação](../install.md)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ary-OZz5jMJI"
      },
      "outputs": [],
      "source": [
        "#@test {\"skip\": true}\n",
        "!pip install --quiet --upgrade tensorflow-federated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-skNC6aovM46"
      },
      "outputs": [],
      "source": [
        "import collections\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_federated as tff"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "okHp5z7ekFoc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "b'Hello, World!'"
            ]
          },
          "execution_count": 4,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "@tff.federated_computation\n",
        "def hello_world():\n",
        "  return 'Hello, World!'\n",
        "\n",
        "hello_world()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xX97PJwaBLf"
      },
      "source": [
        "## Dados federados\n",
        "\n",
        "Uma das características diferenciais do TFF é que ele permite que você expresse de maneira compacta computações baseadas no TensorFlow com *dados federados*. Vamos usar o termo *dados federados* neste tutorial para fazer referência a uma coleção de itens de dados hospedados em um grupo de dispositivos de um sistema distribuído. Por exemplo, aplicativos executados em dispositivos móveis podem coletar dados e armazená-los localmente, sem fazer upload para uma localização centralizada. Ou um array de sensores distribuídos pode coletar e armazenar leituras de temperaturas nas suas localizações.\n",
        "\n",
        "Os dados federados como esses nos exemplos acima são tratados no TTF como [cidadãos de primeira classe](https://en.wikipedia.org/wiki/First-class_citizen), ou seja, eles aparecem como parâmetros e resultados de funções, além de possuírem tipos. Para reforçar essa noção, vamos chamar os conjuntos de dados federados de *valores federados* ou *valores de tipos federados*.\n",
        "\n",
        "O ponto importante a entender é que estamos modelando toda a coleção de itens de dados em todos os dispositivos (por exemplo, toda a coleção de leituras de temperaturas de todos os sensores em um array distribuído) como um único valor federado.\n",
        "\n",
        "Por exemplo, veja como seria definido no TFF o tipo de um *float federado* hospedado por um grupo de dispositivos do cliente. Uma coleção de leituras de temperatura que se materializam em um array de sensores pode ser modelada como um valor desse tipo federado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "COe0tLPPtTbe"
      },
      "outputs": [],
      "source": [
        "federated_float_on_clients = tff.type_at_clients(tf.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCAMsF_T8p63"
      },
      "source": [
        "De forma mais geral, um tipo federado no TFF é definido ao especificar o tipo `T` dos *membros constituintes* - os itens de dados que residem nos dispositivos individuais, e o grupo `G` de dispositivos em que os valores federados desse tipo são hospedados (além de uma terceira informação opcional que vamos mencionar a seguir). O grupo `G` de dispositivos que hospeda um valor federado é considerado a *colocação* do valor. Portanto, `tff.CLIENTS` é um exemplo de colocação."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zFVZQwUZ_nbt"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'float32'"
            ]
          },
          "execution_count": 6,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "str(federated_float_on_clients.member)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eTK00mVb_qi7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'CLIENTS'"
            ]
          },
          "execution_count": 7,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "str(federated_float_on_clients.placement)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6dp3OHVW_2Q"
      },
      "source": [
        "Um tipo federado com membros constituintes `T` e uma colocação `G` pode ser representado de maneira compacta como `{T}@G`, conforme mostrado abaixo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eR-9cP219brl"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'{float32}@CLIENTS'"
            ]
          },
          "execution_count": 8,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "str(federated_float_on_clients)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kn1logOGtBI"
      },
      "source": [
        "As chaves `{}` nessa notação concisa servem como um lembrete de que os membros constituintes (itens de dados em diferentes dispositivos) podem variar, conforme você esperaria, por exemplo, em leituras de sensores de temperatura. Então, os clientes como um grupo estão hospedando um [conjunto múltiplo](https://en.wikipedia.org/wiki/Multiset) de itens do tipo `T` que juntos constituem o valor federado.\n",
        "\n",
        "É importante observar que os membros constituintes de um valor federado são geralmente opacos ao programador, ou seja, um valor federado não deve ser considerado como um simples `dict` com a chave por um identificador de um dispositivo no sistema - esses valores pretendem ser transformados coletivamente somente por *operadores federados* que representam abstratamente vários tipos de protocolos de comunicação distribuída (como agregação). Se parece muito abstrato, não se preocupe - vamos retomar isso em breve e ilustrar com exemplos concretos.\n",
        "\n",
        "Os tipos federados no TFF tem duas variações: aqueles em que os membros constituintes de um valor federado podem diferir (como acabamos de ver acima) e aqueles em que são todos iguais. Isso é controlado pelo terceiro parâmetro opcional `all_equal` no construtor `tff.FederatedType` (padronizado como `False`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wenF_FnGivCZ"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 9,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "federated_float_on_clients.all_equal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wxL6UAkittF"
      },
      "source": [
        "Um tipo federado com uma colocação `G` em que todos os membros constituintes do tipo `T` são iguais pode ser representado de maneira compacta como `T@G` (em vez de `{T}@G`, ou seja, sem as chaves para refletir o fato de que o conjunto múltiplo de membros constituintes consiste em um único item)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ei1pmBEuLWf-"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'float32@CLIENTS'"
            ]
          },
          "execution_count": 10,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "str(tff.type_at_clients(tf.float32, all_equal=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZ2JlbX6H0h5"
      },
      "source": [
        "Um exemplo de um valor federado desse tipo que pode surgir em cenários práticos é um hiperparâmetro (como taxa de aprendizado, norma de recorte etc.) que foi transmitido por um servidor a um grupo de dispositivos que participa do treinamento federado.\n",
        "\n",
        "Outro exemplo é um conjunto de parâmetros para um modelo de aprendizado de máquina pré-treinado no servidor que foram depois transmitidos a um grupo de dispositivos do cliente, onde podem ser personalizados para cada usuário.\n",
        "\n",
        "Por exemplo, suponha que temos um par de parâmetros `float32` `a` e `b` para um modelo de regressão linear unidimensional. Podemos construir o tipo (não federado) desses modelos para uso no TFF da seguinte maneira. Os colchetes angulares `<>` na string de tipo impressa são uma notação compacta do TFF para tuplas nomeadas ou não."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "noN9mFSN10e6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'<a=float32,b=float32>'"
            ]
          },
          "execution_count": 11,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "simple_regression_model_type = (\n",
        "    tff.StructType([('a', tf.float32), ('b', tf.float32)]))\n",
        "\n",
        "str(simple_regression_model_type)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytngzr6r10yn"
      },
      "source": [
        "Observe que só estamos especificando `dtype`s acima. Os tipos não escalares também são compatíveis. No código acima, `tf.float32` é uma notação de atalho para o `tff.TensorType(dtype=tf.float32, shape=[])` mais geral.\n",
        "\n",
        "Quando esse modelo é transmitido aos clientes, o tipo do valor federado resultante pode ser representado conforme exibido abaixo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jZxvM1m9OJZc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'<a=float32,b=float32>@CLIENTS'"
            ]
          },
          "execution_count": 12,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "str(tff.type_at_clients(\n",
        "    simple_regression_model_type, all_equal=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfnRcX7rNspF"
      },
      "source": [
        "Em simetria com o *float federado* acima, vamos chamar esse tipo de *tupla federada*. Em termos mais gerais, vamos usar com frequência o termo *XYZ federado* para um valor federado em que os membros constituintes são como *XYZ*. Portanto, vamos falar sobre coisas como *tuplas federadas*, *sequências federadas*, *modelos federados*, e assim por diante.\n",
        "\n",
        "Agora, voltando a `float32@CLIENTS` - embora apareça replicado em vários dispositivos, é um único `float32`, já que todos os membros são iguais. Em geral, você pode pensar em qualquer tipo federado *todo igual*, ou seja, um de formato `T@G`, como isomórfico a um tipo não federado `T`, já que, em ambos os casos, só há um único (apesar de possivelmente replicado) item de tipo `T`.\n",
        "\n",
        "Considerando o isomorfismo entre `T` e `T@G`, você pode se perguntar qual é a finalidade, se houver, dos últimos tipos. Continue lendo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pUXF8WEQLV26"
      },
      "source": [
        "## Colocações\n",
        "\n",
        "### Visão geral do design\n",
        "\n",
        "Na seção anterior, apresentamos o conceito de *colocações* - grupos de participantes do sistema que podem hospedar em conjunto um valor federado, e demonstramos o uso de `tff.CLIENTS` como uma especificação de exemplo para uma colocação.\n",
        "\n",
        "Para explicar o motivo pelo qual a *colocação* é tão fundamental que precisamos incorporá-la ao sistema de tipos do TTF, lembre-se do que mencionamos no início deste tutorial sobre alguns dos usos pretendidos do TFF.\n",
        "\n",
        "Embora neste tutorial você só verá o código do TFF ser executado localmente em um ambiente simulado, nosso objetivo é que o TFF permite a escrita de código que você pode implantar para a execução em grupos de dispositivos físicos em um sistema distribuído, possivelmente incluindo dispositivos móveis ou embarcados que executam o Android. Cada um desses dispositivos receberia um conjunto separado de instruções para executar localmente, dependendo da função que tem no sistema (um dispositivo de usuário final, um coordenador centralizado, uma camada intermediária em uma arquitetura de vários níveis etc.). É importante conseguir raciocinar sobre quais subconjuntos de dispositivos executam qual código e onde diferentes partes de dados podem se materializar fisicamente.\n",
        "\n",
        "Isso é especialmente importante ao lidar, por exemplo, com dados de aplicativos em dispositivos móveis. Como os dados são privados e podem ser sensíveis, precisamos da capacidade de verificar estaticamente que esses dados nunca deixarão o dispositivo (e comprovar fatos sobre como os dados estão sendo processados). As especificações de colocação são um dos mecanismos criados para possibilitar isso.\n",
        "\n",
        "O TFF foi criado como um ambiente de programação focado em dados e, por isso, ao contrário de alguns frameworks existentes que focam em *operações* e onde essas operações podem ser *executadas*, o TFF foca nos *dados*, onde os dados se *materializam* e como eles estão sendo *transformados*. Consequentemente, a colocação é modelada como uma propriedade dos dados no TFF, em vez de uma propriedade das operações nos dados. Você verá na próxima seção que algumas das operações no TFF abrangem várias localizações e são executadas \"na rede\", por assim dizer, em vez de serem executadas por uma única máquina ou um grupo de máquinas.\n",
        "\n",
        "A representação do tipo de um determinado valor como `T@G` ou `{T}@G` (em vez de apenas `T`) torna as decisões de colocação de dados explícitas e, junto com a análise estática de programas escritos no TFF, ela pode servir como uma base para fornecer garantias de privacidade formais para dados sensíveis no dispositivo.\n",
        "\n",
        "No entanto, uma observação importante neste momento é que, embora incentivemos os usuários do TFF a serem explícitos sobre os *grupos* de dispositivos participantes que hospedam os dados (as colocações), o programador nunca lidará com os dados brutos ou as identidades de participantes *individual* individuais.\n",
        "\n",
        "No corpo do código do TFF, por padrão, não há como enumerar os dispositivos que constituem o grupo representado por `tff.CLIENTS` ou verificar a existência de um dispositivo específico no grupo. Não há conceito de um dispositivo ou identidade de cliente em qualquer lugar da API Federated Core, o conjunto subjacente de abstrações arquitetônicas ou a infraestrutura de runtime principal que fornecemos para apoiar as simulações. Toda a lógica computacional que você escreve será expressa como operações em todo o grupo de clientes.\n",
        "\n",
        "Lembre-se aqui do que mencionamos antes sobre os valores dos tipos federados não serem como o `dict` do Python, porque não é possível simplesmente enumerar os membros constituintes. Pense em valores que a lógica do seu programa do TFF manipula como sendo associados às colocações (grupos), e não a participantes individuais.\n",
        "\n",
        "As colocações *são* criadas para serem um cidadão de primeira classe no TFF também e podem aparecer como parâmetros e resultados de um tipo de `colocação` (que será representado por `tff.PlacementType` na API). No futuro, planejamos oferecer uma variedade de operadores para transformar ou combinar colocações, mas está fora do escopo deste tutorial. Por enquanto, basta pensar na `colocação` como um tipo integrado primitivo e opaco no TFF, semelhante a como `int` e `bool` são tipos integrados e opacos no Python, sendo `tff.CLIENTS` uma literal constante desse tipo, como `1` é uma literal constante do tipo `int`.\n",
        "\n",
        "### Especificação das colocações\n",
        "\n",
        "O TFF fornece duas literais de colocação básicas, `tff.CLIENTS` e `tff.SERVER`, para facilitar a expressão da rica variedade de cenários práticos que são modelados naturalmente como arquiteturas do servidor do cliente, com vários dispositivos do *cliente* (dispositivos móveis, dispositivos embarcados, bancos de dados distribuídos, sensores etc.) orquestrados por um único coordenador de *servidor* centralizado. O TFF também foi projetado para oferecer suporte a colocações personalizadas, vários grupos de clientes, arquiteturas distribuídas de várias níveis e outras mais gerais, mas discuti-los está fora do escopo deste tutorial.\n",
        "\n",
        "O TFF não estabelece o que `tff.CLIENTS` ou `tff.SERVER` realmente representa.\n",
        "\n",
        "Em especial, `tff.SERVER` pode ser um único dispositivo físico (um membro de um grupo único), mas pode ser também um grupo de réplicas em uma replicação máquina de estados que executa clusters tolerante a falhas - não fazemos presunções arquitetônicas especiais. Em vez disso, usamos o bit `all_equal` mencionado na seção anterior para expressar o fato de que geralmente lidamos com apenas um único item de dados no servidor.\n",
        "\n",
        "Da mesma forma, `tff.CLIENTS` em alguns aplicativos pode representar todos os clientes no sistema - o que no contexto do aprendizado federado às vezes chamados de *população*, mas, por exemplo, nas [implementações de produção do cálculo federado de médias](https://arxiv.org/abs/1602.05629), pode representar uma *coorte* - um subconjunto de clientes selecionados para a participação em uma rodada específica de treinamento. As colocações definidas de maneira abstrata recebem um significado concreto quando uma computação em que elas aparecem é implantada para execução (ou simplesmente invocada como uma função Python em um ambiente simulado, conforme demonstrado neste tutorial). Em nossas simulações locais, o grupo de clientes é determinado pelos dados federados fornecidos como entrada."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Lmpr7vpA-3A"
      },
      "source": [
        "## Computações federadas\n",
        "\n",
        "### Declaração de computações federadas\n",
        "\n",
        "O TFF foi criado como um ambiente de programação funcional fortemente tipado que é compatível com o desenvolvimento modular.\n",
        "\n",
        "A unidade básica de composição no TFF é uma *computação federada* - uma seção de lógica que aceita valores federados como entrada e retorna valores federados como saída. Veja como você pode definir uma computação que calcula a média das temperaturas relatadas pelo array de sensores do exemplo anterior."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g38EkHwGGEUo"
      },
      "outputs": [],
      "source": [
        "@tff.federated_computation(tff.type_at_clients(tf.float32))\n",
        "def get_average_temperature(sensor_readings):\n",
        "  return tff.federated_mean(sensor_readings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjRTFxGxY-AL"
      },
      "source": [
        "Observando o código acima, você talvez esteja se perguntando: já não há construtos de decorador para definir unidades que podem ser compostas, como [`tf.function`](https://www.tensorflow.org/api_docs/python/tf/function) no TensorFlow? E, se sim, por que introduzir mais um e qual é a diferença?\n",
        "\n",
        "A resposta curta é que o código gerado pelo wrapper `tff.federated_computation` não é *nem* TensorFlow, *nem* Python - é uma especificação de um sistema distribuído em um linguagem *glue* independente de plataforma interna. Neste momento, isso definitivamente soará incompreensível, mas considere essa interpretação intuitiva de uma computação federada como uma especificação abstrata de um sistema distribuído. Vamos explicar isso em um instante.\n",
        "\n",
        "Primeiro, vamos brincar um pouco com a definição. As computações do TFF são geralmente modeladas como funções - com ou sem parâmetros, mas com assinaturas de tipo bem definidas. Você pode imprimir a assinatura de tipo de uma computação ao consultar sua propriedade `type_signature`, conforme exibido abaixo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o7FmRyQACtZU"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'({float32}@CLIENTS -> float32@SERVER)'"
            ]
          },
          "execution_count": 14,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "str(get_average_temperature.type_signature)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCJGl2SFAs7S"
      },
      "source": [
        "A assinatura de tipo nos diz que a computação aceita uma coleção de diferentes leituras de sensores em dispositivos de clientes e retorna uma única média no servidor.\n",
        "\n",
        "Antes de continuar, vamos refletir sobre isso por um minuto - a entrada e a saída dessa computação estão *em locais diferentes* (em `CLIENTS` x no `SERVER`). Lembre-se do que falamos na seção anterior de colocações sobre como as *operações TFF podem abranger vários locais e serem executadas na rede*, e o que acabamos de falar sobre as computações federadas que representam especificações abstratas de sistemas distribuídos. Acabamos de definir uma computação assim - um sistema distribuído simples em que os dados são consumidos nos dispositivos dos cliente e os resultados agregados surgem no servidor.\n",
        "\n",
        "Em vários cenários práticos, as computações que representam tarefas de nível superior tendem a aceitar as entradas e relatar as saídas no servidor - isso reflete a ideia de que as computações podem ser acionadas por *consultas* que são originadas e encerradas no servidor.\n",
        "\n",
        "No entanto, a API FC não impõe esse pressuposto, e vários dos blocos básicos que usamos internamente (incluindo vários operadores `tff.federated_...` que você talvez encontre na API) têm entradas e saídas com colocações distintas. Então, em geral, você não deve pensar em uma computação federada como algo que é *executado no servidor* ou *executado por um servidor*. O servidor é apenas um tipo de participante em uma computação federada. Ao pensar sobre a mecânica dessas computações, é sempre melhor usar a perspectiva de toda a rede global, e não a perspectiva de um único coordenador centralizado.\n",
        "\n",
        "Em geral, as assinaturas de tipo funcional são representadas de maneira compacta como `(T -> U)` para tipos `T` e `U` de entradas e saídas, respectivamente. O tipo do parâmetro formal (como `sensor_readings` nesse caso) é especificado como o argumento do decorador. Você não precisa especificar o tipo do resultado - ele é determinado automaticamente.\n",
        "\n",
        "Embora o TFF realmente ofereça formas limitadas de polimorfismo, é recomendável que os programadores sejam explícitos sobre os tipos de dados com que trabalham, já que isso facilita a compreensão, depuração e a verificação formal das propriedades do seu código. Em alguns casos, especificar os tipos explicitamente é um requisito (por exemplo, as computações polimórficas não são executáveis diretamente no momento).\n",
        "\n",
        "### Execução de computações federadas\n",
        "\n",
        "Para oferecer suporte ao desenvolvimento e à depuração, o TFF permite que você invoque diretamente as computações definidas dessa forma como funções Python, conforme mostrado abaixo. Quando a computação espera um valor de um tipo federado com o conjunto de bitset `all_equal` como `False`, você pode alimentá-lo como uma simples `list` no Python e, para tipos federados com o bitset `all_equal` como `True`, você pode alimentar diretamente o (único) membro constituinte. Isso também é como os resultados são relatados de novo para você."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HMDW-7U1aREW"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "69.53334"
            ]
          },
          "execution_count": 15,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_average_temperature([68.5, 70.3, 69.8])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XsTKl4OIBUSH"
      },
      "source": [
        "Ao realizar computações como essa no modo simulação, você age como um observador externo com uma visão de todo o sistema, que tem a capacidade de fornecer entradas e consumir saídas em qualquer localização na rede, como realmente é o caso aqui - você forneceu valores de clientes como entrada e consumiu o resultado do servidor.\n",
        "\n",
        "Agora, vamos retomar uma observação que fizemos antes sobre o decorador `tff.federated_computation` emitir código em uma linguagem *glue*. A lógica das computações do TFF pode ser expressa como funções comuns em Python (você só precisa decorá-las com `tff.federated_computation`, conforme acabamos de fazer acima), e você pode invocá-las diretamente com argumentos Python, como qualquer outra função Python neste notebook, porém, nos bastidores, as computações do TFF *não* são Python.\n",
        "\n",
        "Queremos dizer com isso que, quando o interpretador Python se depara com uma função decorada com `tff.federated_computation`, ele faz o tracing das declarações no corpo dessa função uma vez (no tempo de definição) e constrói uma [representação serializada](https://github.com/tensorflow/federated/blob/main/tensorflow_federated/proto/v0/computation.proto) da lógica computacional para uso futuro - seja para execução ou para incorporação como subcomponente em outra computação.\n",
        "\n",
        "Você pode verificar isso ao adicionar uma declaração print da seguinte maneira:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6gvzd1vwp8sG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Getting traced, the argument is \"Value\".\n"
          ]
        }
      ],
      "source": [
        "@tff.federated_computation(tff.type_at_clients(tf.float32))\n",
        "def get_average_temperature(sensor_readings):\n",
        "\n",
        "  print ('Getting traced, the argument is \"{}\".'.format(\n",
        "      type(sensor_readings).__name__))\n",
        "\n",
        "  return tff.federated_mean(sensor_readings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMJdv8Fip7Rv"
      },
      "source": [
        "Você pode pensar no código Python que define uma computação federada semelhante à maneira como você pensaria no código Python que cria um grafo do TensorFlow em um contexto não eager (se você não estiver familiarizado com os usos não eager do TensorFlow, pense no seu código Python definindo um grafo de operações que serão executadas depois, mas sem executá-las dinamicamente). O código de criação de grafo não eager no TensorFlow é Python, mas o grafo do TensorFlow construído por esse código é independente de plataforma e serializável.\n",
        "\n",
        "De forma semelhante, as computações do TFF são definidas em Python, mas as declarações Python nos seus corpos, como `tff.federated_mean` no exemplo que acabamos de mostrar, são compiladas em uma representação portátil e serializável independente de plataforma em segundo plano.\n",
        "\n",
        "Como um desenvolvedor, você não precisa se preocupar com os detalhes dessa representação, já que você nunca precisará trabalhar diretamente com ela, mas você deve estar ciente da sua existência, do fato de que as computações do TFF são fundamentalmente não eager e não podem capturar o estado Python arbitrário. O código Python contido no corpo de uma computação do TFF é executado no tempo de definição, quando o corpo da função Python decorada com `tff.federated_computation` passa pelo tracing antes da serialização. O tracing não é realizado novamente no tempo de invocação (exceto quando a função é polimórfica; consulte mais detalhes nas páginas de documentação).\n",
        "\n",
        "Você pode se perguntar sobre por que escolhemos apresentar uma representação não Python interna dedicada. Um motivo é que, no final, as computação do TFF devem ser implantáveis em ambientes físicos reais e hospedadas em dispositivos móveis ou embarcados, onde Python talvez não esteja disponível.\n",
        "\n",
        "Outro motivo é que as computações do TFF expressam o comportamento global dos sistemas distribuídos, em vez dos programas Python que expressam o comportamento local de participantes individuais. Você pode ver isso no exemplo simples acima, com o operador especial `tff.federated_mean` que aceita dados em dispositivos de clientes, mas deposita os resultados no servidor.\n",
        "\n",
        "O operador `tff.federated_mean` não pode ser facilmente modelado como um operador ordinário no Python, já que não é executado localmente - conforme observado antes, ele representa um sistema distribuído que coordena o comportamento de vários participantes do sistema. Vamos chamar esses operadores de *operadores federados* para diferenciá-los dos operadores (locais) normais no Python.\n",
        "\n",
        "Portanto, o sistema de tipos do TFF e o conjunto fundamental de operações compatíveis com a linguagem do TFF divergem consideravelmente daquelas no Python, exigindo o uso de uma representação dedicada.\n",
        "\n",
        "### Composição de computações federadas\n",
        "\n",
        "Conforme observado acima, as computações federadas e os constituintes delas são melhor compreendidos como modelos de sistemas distribuídos, e você pode pensar em compor computações federadas como compor sistemas distribuídos mais complexos a partir de outros mais simples. Você pode considerar o operador `tff.federated_mean` como um tipo de computação federada de modelo integrada com uma assinatura de tipo `({T}@CLIENTS -> T@SERVER)` (realmente, exatamente como as computações que você escreve, esse operador também tem uma estrutura complexa - em segundo plano, dividimos em operadores mais simples).\n",
        "\n",
        "O mesmo se aplica à composição de computações federadas. A computação `get_average_temperature` pode ser invocada no corpo de outra função Python decorada com `tff.federated_computation` - isso fará com que seja incorporado no corpo do pai, assim como `tff.federated_mean` foi incorporado no próprio corpo antes.\n",
        "\n",
        "Uma restrição importante de saber é que os corpos das funções Python decoradas com `tff.federated_computation` precisam consistir *somente* em operadores federados, ou seja, eles não podem conter diretamente operações do TensorFlow. Por exemplo, você não pode usar diretamente interfaces `tf.nest` para adicionar um par de valores federados. O código TensorFlow precisa estar confinado em blocos de código decorado com uma `tff.tf_computation` discutida na seção a seguir. Somente envolvido dessa maneira o código do TensorFlow pode ser invocado no corpo de uma `tff.federated_computation`.\n",
        "\n",
        "Os motivos dessa separação são técnicos (é difícil enganar operadores como `tf.add` para que funcionem com algo além de tensores) e arquitetônicos. A linguagem das computações federadas (ou seja, a lógica construída a partir dos corpos serializados de funções Python decoradas com `tff.federated_computation`) é criada para servir como uma linguagem *glue* independente de plataforma. Essa linguagem glue é usada atualmente para criar sistemas distribuídos de seções incorporadas do código TensorFlow (confinadas a blocos de `tff.tf_computation`). Algum dia, antecipamos a necessidade de incorporar seções de outras lógicas diferentes do TensorFlow, como consultas de bancos de dados relacionais que podem representar pipelines de entrada, todos conectados juntos usando a mesma linguagem glue (os blocos de `tff.federated_computation`)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RR4EOrl4errh"
      },
      "source": [
        "## Lógica do TensorFlow\n",
        "\n",
        "### Declaração de computações do TensorFlow\n",
        "\n",
        "O TFF foi criado para uso com o TensorFlow. Portanto, grande parte do código que você escreverá no TFF provavelmente será código TensorFlow ordinário (ou seja, executado localmente). Para usar esse código com o TFF, como observado acima, ele só precisa ser decorado com `tff.tf_computation`.\n",
        "\n",
        "Por exemplo, veja como podemos implementar uma função que recebe um número e adiciona `0.5` a ele."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dpdAqMcygnmr"
      },
      "outputs": [],
      "source": [
        "@tff.tf_computation(tf.float32)\n",
        "def add_half(x):\n",
        "  return tf.add(x, 0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXGeOvyTdyix"
      },
      "source": [
        "Novamente, olhando para isso, você talvez se pergunte por que precisamos definir outro decorador `tff.tf_computation` em vez de apenas usar um mecanismo existente como `tf.function`. Ao contrário da seção anterior, aqui estamos lidando com um bloco ordinário de código TensorFlow.\n",
        "\n",
        "Há alguns motivos para isso, que vão além do escopo deste tutorial, mas vale a pena mencionar o principal:\n",
        "\n",
        "- Para incorporar blocos básicos reutilizáveis implementados usando código TensorFlow nos corpos de computações federadas, eles precisam atender a determinadas propriedades, como receber tracing e serialização no tempo de definição, ter assinaturas de tipo etc. Isso geralmente exige algum decorador.\n",
        "\n",
        "Em geral, recomendamos usar os mecanismos nativos do TensorFlow para composição, como `tf.function`, quando possível, já que a maneira exata em que o decorador do TFF interage com as funções eager deve evoluir.\n",
        "\n",
        "Agora, voltando ao fragmento de código de exemplo acima, a computação `add_half` que acabamos de definir pode ser tratada pelo TFF como qualquer outra computação do TFF. Em especial, ela tem uma assinatura de tipo do TFF."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "93UdxrpgkHgj"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'(float32 -> float32)'"
            ]
          },
          "execution_count": 18,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "str(add_half.type_signature)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpiERRtQlBKq"
      },
      "source": [
        "Observe que essa assinatura de tipo não tem colocações. As computações do TensorFlow não podem consumir nem retornar tipos federados.\n",
        "\n",
        "Você agora também pode usar `add_half` como um bloco básico em outras computações. Por exemplo, veja como você pode usar o operador `tff.federated_map` para aplicar o `add_half` pontual a todos os membros constituintes de um float federado nos dispositivos dos clientes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z08K5UKBlSJP"
      },
      "outputs": [],
      "source": [
        "@tff.federated_computation(tff.type_at_clients(tf.float32))\n",
        "def add_half_on_clients(x):\n",
        "  return tff.federated_map(add_half, x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P4wjJgLnlkDW"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'({float32}@CLIENTS -> {float32}@CLIENTS)'"
            ]
          },
          "execution_count": 20,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "str(add_half_on_clients.type_signature)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfaC3DSAgQWk"
      },
      "source": [
        "### Execução de computações do TensorFlow\n",
        "\n",
        "A execução de computações definidas com `tff.tf_computation` segue as mesmas regras que as descritas para `tff.federated_computation`. Elas podem ser invocadas como invocáveis ordinárias no Python da seguinte maneira."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gPsr1oEsl59G"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<tf.Tensor: shape=(), dtype=float32, numpy=1.5>,\n",
              " <tf.Tensor: shape=(), dtype=float32, numpy=3.5>,\n",
              " <tf.Tensor: shape=(), dtype=float32, numpy=2.5>]"
            ]
          },
          "execution_count": 21,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "add_half_on_clients([1.0, 3.0, 2.0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yuUOSG-9kK8J"
      },
      "source": [
        "Novamente, vale a pena destacar que invocar a computação `add_half_on_clients` dessa maneira simula um processo distribuído. Os dados são consumidos nos clientes e retornados nos clientes. Essa computação faz cada cliente realizar uma ação local. Não há `tff.SERVER` mencionado explicitamente nesse sistema (mesmo se, na prática, orquestrar esse processamento talvez envolva um). Pense em uma computação definida dessa forma como conceitualmente análoga à fase `Map` em `MapReduce`.\n",
        "\n",
        "Além disso, o que falamos na seção anterior sobre as computações do TFF serem serializadas no tempo de definição também é válido para o código `tff.tf_computation` — o corpo em Python de `add_half_on_clients` passa pelo tracing uma vez no tempo de definição. Nas invocações seguintes, o TFF usa a representação serializada.\n",
        "\n",
        "A única diferença entre os métodos Python decorados com `tff.federated_computation` e aqueles decorados com `tff.tf_computation` é que estes são serializados como grafos do TensorFlow (enquanto os primeiros não podem conter código TensorFlow diretamente incorporado).\n",
        "\n",
        "Em segundo plano, cada método decorado com `tff.tf_computation` desativa temporariamente a eager execution para permitir que a estrutura computacional seja capturada. Enquanto a eager execution está desativada localmente, você pode usar construtos eager do TensorFlow, AutoGraph, TensorFlow 2.0 etc., desde que escreva a lógica computacional de modo que possa ser serializada corretamente.\n",
        "\n",
        "Por exemplo, o código a seguir falhará:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gxVu5aeGlPGc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Attempting to capture an EagerTensor without building a function.\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "\n",
        "  # Eager mode\n",
        "  constant_10 = tf.constant(10.)\n",
        "\n",
        "  @tff.tf_computation(tf.float32)\n",
        "  def add_ten(x):\n",
        "    return x + constant_10\n",
        "\n",
        "except Exception as err:\n",
        "  print (err)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KnAdsfylPeA"
      },
      "source": [
        "O código acima falha porque `constant_10` já foi construída fora do grafo que `tff.tf_computation` constrói internamente no corpo de `add_ten` durante o processo de serialização.\n",
        "\n",
        "Por outro lado, é possível invocar funções Python que modificam o grafo atual quando chamadas dentro de uma `tff.tf_computation`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y-anTlfWlk2l"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "15.0"
            ]
          },
          "execution_count": 23,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def get_constant_10():\n",
        "  return tf.constant(10.)\n",
        "\n",
        "@tff.tf_computation(tf.float32)\n",
        "def add_ten(x):\n",
        "  return x + get_constant_10()\n",
        "\n",
        "add_ten(5.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Gl2ijcIllOp"
      },
      "source": [
        "Observe que os mecanismos de serialização no TensorFlow estão evoluindo, e os pormenores de como o TFF serializa computações também devem evoluir.\n",
        "\n",
        "### Trabalhando com `tf.data.Dataset`s\n",
        "\n",
        "Como mencionado antes, um recurso único das `tff.tf_computation`s é que elas permitem trabalhar com `tf.data.Dataset`s definidos de maneira abstrata como parâmetros formais pelo seu código. Os parâmetros que serão representados no TensorFlow como datasets precisam ser declarados usando o construtor `tff.SequenceType`.\n",
        "\n",
        "Por exemplo, a especificação de tipo `tff.SequenceType(tf.float32)` define uma sequência abstrata de elementos float no TFF. As sequências podem conter tensores ou estruturas aninhadas complexas (veremos exemplos em seguida). A representação concisa de uma sequência de itens do tipo `T` é `T*`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oufOPP5DrUud"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'float32*'"
            ]
          },
          "execution_count": 24,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "float32_sequence = tff.SequenceType(tf.float32)\n",
        "\n",
        "str(float32_sequence)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnNQsm2prSPB"
      },
      "source": [
        "Suponha que, em nosso exemplo de sensores de temperatura, cada sensor armazene várias leituras de temperatura. Veja como você pode definir uma computação do TFF no TensorFlow que calcula a média das temperaturas em um único dataset local usando o operador `tf.data.Dataset.reduce`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cw0nen-D0Ks8"
      },
      "outputs": [],
      "source": [
        "@tff.tf_computation(tff.SequenceType(tf.float32))\n",
        "def get_local_temperature_average(local_temperatures):\n",
        "  sum_and_count = (\n",
        "      local_temperatures.reduce((0.0, 0), lambda x, y: (x[0] + y, x[1] + 1)))\n",
        "  return sum_and_count[0] / tf.cast(sum_and_count[1], tf.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wT0V9sJlyqKE"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'(float32* -> float32)'"
            ]
          },
          "execution_count": 26,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "str(get_local_temperature_average.type_signature)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olZkwEVl2ORH"
      },
      "source": [
        "No corpo de um método decorado com `tff.tf_computation`, os parâmetros formais de um tipo de sequência do TFF são representados apenas como objetos que se comportam como `tf.data.Dataset`, ou sejam, aceitam as mesmas propriedades e métodos (no momento, eles não são implementados como subclasses desse tipo — isso pode mudar à medida que o suporte a datasets no TensorFlow evoluir)\n",
        "\n",
        "Você pode verificar isso facilmente da seguinte maneira."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_W2tBQxz2wmV"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "execution_count": 27,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "@tff.tf_computation(tff.SequenceType(tf.int32))\n",
        "def foo(x):\n",
        "  return x.reduce(np.int32(0), lambda x, y: x + y)\n",
        "\n",
        "foo([1, 2, 3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1N5mbpF2tEI"
      },
      "source": [
        "Tenha em mente que, ao contrário de `tf.data.Dataset`s ordinários, esses objetos semelhantes a datasets são marcadores de posição. Eles não contêm nenhum elemento, já que representam parâmetros de tipo de sequência abstratos, que serão ligados a dados concretos quando usados em um contexto concreto. O suporte a datasets de marcador de posição definidos abstratamente ainda é um pouco limitado no momento e, na fase inicial do TFF, você talvez se depare com determinadas restrições. Porém, não precisamos nos preocupar com elas neste tutorial (confira mais detalhes nas páginas da documentação).\n",
        "\n",
        "Ao executar localmente uma computação que aceita uma sequência em um modo de simulação, como neste tutorial, você pode alimentar a sequência como uma lista Python, da maneira abaixo (além de outras formas, por exemplo, como um `tf.data.Dataset` no modo eager, mas vamos começar com algo simples)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JyNIc79DyuKK"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "69.53333"
            ]
          },
          "execution_count": 28,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_local_temperature_average([68.5, 70.3, 69.8])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zmsi59JSr-PA"
      },
      "source": [
        "Como todos os outros tipos do TFF, sequências como as definidas acima podem usar o construtor `tff.StructType` para definir estruturas aninhadas. Por exemplo, veja como declarar uma computação que aceita uma sequência de pares `A`, `B` e retorna a soma dos produtos. Incluímos as declarações de tracing no corpo da computação para que você possa ver como a assinatura de tipo do TFF se traduz nos `output_types` e `output_shapes` do dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ySQfOfm5sPjl"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "element_structure = OrderedDict([('A', TensorSpec(shape=(), dtype=tf.int32, name=None)), ('B', TensorSpec(shape=(), dtype=tf.int32, name=None))])\n"
          ]
        }
      ],
      "source": [
        "@tff.tf_computation(tff.SequenceType(collections.OrderedDict([('A', tf.int32), ('B', tf.int32)])))\n",
        "def foo(ds):\n",
        "  print('element_structure = {}'.format(ds.element_spec))\n",
        "  return ds.reduce(np.int32(0), lambda total, x: total + x['A'] * x['B'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "krw5R3ilsvU9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'(<A=int32,B=int32>* -> int32)'"
            ]
          },
          "execution_count": 30,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "str(foo.type_signature)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fYd7CPlYsyY9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "26"
            ]
          },
          "execution_count": 31,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "foo([{'A': 2, 'B': 3}, {'A': 4, 'B': 5}])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Whd5_olh4hxH"
      },
      "source": [
        "O suporte ao uso de `tf.data.Datasets` como parâmetros formais ainda é um pouco limitado e está evoluindo, embora funcione em cenários simples como os usados neste tutorial.\n",
        "\n",
        "## Juntando tudo\n",
        "\n",
        "Agora, vamos tentar usar nossa computação do TensorFlow novamente em um contexto federado. Imagine que temos um grupo de sensores, cada um com uma sequência local de leituras de temperaturas. Podemos computar a média de temperatura global calculando a média das médias locais dos sensores da seguinte maneira."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hZIE1kl340at"
      },
      "outputs": [],
      "source": [
        "@tff.federated_computation(\n",
        "    tff.type_at_clients(tff.SequenceType(tf.float32)))\n",
        "def get_global_temperature_average(sensor_readings):\n",
        "  return tff.federated_mean(\n",
        "      tff.federated_map(get_local_temperature_average, sensor_readings))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfC3LePY5pUX"
      },
      "source": [
        "Essa não é uma média simples de todas as leituras de temperatura locais de todos os clientes, já que exigiria a ponderação das contribuições de diferentes clientes pelo número de leituras que mantêm localmente. Deixamos a atualização do código acima como um exercício para o leitor. O operador `tff.federated_mean` aceita o peso como um segundo argumento opcional (que deve ser um float federado).\n",
        "\n",
        "Observe também que a entrada de `get_global_temperature_average` vira agora uma *sequência de floats federados*. As sequências federadas são como geralmente representamos dados no dispositivo no aprendizado federado, com elementos em sequência normalmente representando lotes de dados (você verá exemplos disso em breve)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SL8-jcqo5krW"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'({float32*}@CLIENTS -> float32@SERVER)'"
            ]
          },
          "execution_count": 33,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "str(get_global_temperature_average.type_signature)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNeQOXA36F4P"
      },
      "source": [
        "Veja como podemos executar localmente a computação em uma amostra de dados em Python. Agora, fornecemos a entrada como uma `list` de `list`s. A lista externa itera os dispositivos no grupo representado por `tff.CLIENTS`, e as internas iteram os elementos na sequência local de cada dispositivo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vMzuaF5p6fDJ"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "70.0"
            ]
          },
          "execution_count": 34,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_global_temperature_average([[68.0, 70.0], [71.0], [68.0, 72.0, 70.0]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBjWB-yftWVc"
      },
      "source": [
        "Isso conclui a primeira parte deste tutorial... Recomendamos que você continue com a [segunda parte](custom_federated_algorithms_2.ipynb)."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "custom_federated_algorithms_1.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
