{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqrD7Yzlmlsk"
      },
      "source": [
        "##### Copyright 2019 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "2k8X1C1nmpKv"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32xflLc4NTx-"
      },
      "source": [
        "# Algoritmos federados personalizados, parte 2: implementando o cálculo federado de médias"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtATV6DlqPs0"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>     <a target=\"_blank\" href=\"https://www.tensorflow.org/federated/tutorials/custom_federated_algorithms_2\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver em TensorFlow.org</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/pt-br/federated/tutorials/custom_federated_algorithms_2.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Executar no Google Colab</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/pt-br/federated/tutorials/custom_federated_algorithms_2.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver fonte no GitHub</a>\n",
        "</td>\n",
        "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/pt-br/federated/tutorials/custom_federated_algorithms_2.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Baixar notebook</a>\n",
        "</td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_igJ2sfaNWS8"
      },
      "source": [
        "Este tutorial é a segunda parte de uma série de duas partes que demonstra como implementar tipos personalizados de algoritmos federados no TFF usando o [Federated Core (FC)](../federated_core.md), que serve como base para a camada de [aprendizado federado (FL)](../federated_learning.md) (`tff.learning`).\n",
        "\n",
        "Recomendamos que você leia a [primeira parte dessa série](custom_federated_algorithms_1.ipynb) antes, que apresenta alguns dos principais conceitos e abstrações de programação usadas aqui.\n",
        "\n",
        "Essa segunda parte da série usa os mecanismos apresentados na primeira parte para implementar uma versão mais simples de algoritmos de avaliação e treinamento federado.\n",
        "\n",
        "Incentivamos você a ler os tutoriais de [classificação de imagens](federated_learning_for_image_classification.ipynb) e [geração de texto](federated_learning_for_text_generation.ipynb) para uma introdução de nível superior mais gentil às APIs de aprendizado federado do TFF, já que ajudarão você a contextualizar os conceitos descritos aqui."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuJuLEh2TfZG"
      },
      "source": [
        "## Antes de começarmos\n",
        "\n",
        "Antes de começar, tente executar o seguinte exemplo \"Olá, mundo\" para garantir que o ambiente esteja configurado corretamente. Se não funcionar, consulte as instruções no guia de [instalação](../install.md)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UqJnbs_1YKi4"
      },
      "outputs": [],
      "source": [
        "#@test {\"skip\": true}\n",
        "!pip install --quiet --upgrade tensorflow-federated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-skNC6aovM46"
      },
      "outputs": [],
      "source": [
        "import collections\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_federated as tff"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "zzXwGnZamIMM"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "b'Hello, World!'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "@tff.federated_computation\n",
        "def hello_world():\n",
        "  return 'Hello, World!'\n",
        "\n",
        "hello_world()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iu5Gd8D6W33s"
      },
      "source": [
        "## Implementação do cálculo federado de médias\n",
        "\n",
        "Como na [classificação de imagens do aprendizado federado](federated_learning_for_image_classification.ipynb), vamos usar o exemplo MNIST. Porém, como a intenção é que este tutorial seja de baixo nível, vamos contornar a API do Keras e a `tff.simulation`, escrever código de modelo bruto e construir um dataset federado do zero.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6qCjef350c_"
      },
      "source": [
        "### Preparação dos datasets federados\n",
        "\n",
        "Para fins de demonstração, vamos simular um cenário em que temos dados de 10 usuários, e cada um contribui com conhecimento de como reconhecer um dígito diferente. Não dá para ser mais não [i.i.d.](https://en.wikipedia.org/wiki/Independent_and_identically_distributed_random_variables) que isso.\n",
        "\n",
        "Primeiro, vamos carregar os dados MNIST padrão:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "uThZM4Ds-KDQ"
      },
      "outputs": [],
      "source": [
        "mnist_train, mnist_test = tf.keras.datasets.mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "PkJc5rHA2no_"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(dtype('uint8'), (60000, 28, 28)), (dtype('uint8'), (60000,))]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "[(x.dtype, x.shape) for x in mnist_train]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFET4BKJFbkP"
      },
      "source": [
        "Os dados são arrays Numpy, um com imagens e outro com rótulos de dígitos, ambos com a primeira dimensão passando os exemplos individuais. Vamos escrever uma função helper que a formate de uma maneira compatível com a forma como alimentamos sequências federadas em computações do TFF, ou seja, como uma lista de listas — a lista externa abrangendo os usuários (dígitos), as internas abrangendo lotes de dados na sequência de cada cliente. Como costume, vamos estruturar cada lote como um par de tensores chamados `x` e `y`, cada um com a dimensão de lote principal. Enquanto isso, também vamos achatar cada imagem em um vetor de 784 elementos e redimensionar os pixels para o intervalo `0..1`. Assim, não precisamos encher a lógica do modelo com conversões de dados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "XTaTLiq5GNqy"
      },
      "outputs": [],
      "source": [
        "NUM_EXAMPLES_PER_USER = 1000\n",
        "BATCH_SIZE = 100\n",
        "\n",
        "\n",
        "def get_data_for_digit(source, digit):\n",
        "  output_sequence = []\n",
        "  all_samples = [i for i, d in enumerate(source[1]) if d == digit]\n",
        "  for i in range(0, min(len(all_samples), NUM_EXAMPLES_PER_USER), BATCH_SIZE):\n",
        "    batch_samples = all_samples[i:i + BATCH_SIZE]\n",
        "    output_sequence.append({\n",
        "        'x':\n",
        "            np.array([source[0][i].flatten() / 255.0 for i in batch_samples],\n",
        "                     dtype=np.float32),\n",
        "        'y':\n",
        "            np.array([source[1][i] for i in batch_samples], dtype=np.int32)\n",
        "    })\n",
        "  return output_sequence\n",
        "\n",
        "\n",
        "federated_train_data = [get_data_for_digit(mnist_train, d) for d in range(10)]\n",
        "\n",
        "federated_test_data = [get_data_for_digit(mnist_test, d) for d in range(10)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpNdBimWaMHD"
      },
      "source": [
        "Como teste rápido de sanidade, vamos ver o tensor `Y` no último lote de dados contribuídos pelo quinto cliente (correspondente ao dígito `5`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "bTNuL1W4bcuc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "federated_train_data[5][-1]['y']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xgvcwv7Obhat"
      },
      "source": [
        "Só para ter certeza, vamos conferir também a imagem correspondente ao último elemento desse lote."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "cI4aat1za525"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90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\nrkJggg==\n",
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "plt.imshow(federated_train_data[5][-1]['x'][-1].reshape(28, 28), cmap='gray')\n",
        "plt.grid(False)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-ox58PA56f8"
      },
      "source": [
        "### Combinando TensorFlow e TFF\n",
        "\n",
        "Neste tutorial, para simplificar, vamos decorar imediatamente funções que introduzem a lógica do TensorFlow com `tff.tf_computation`. Porém, para lógicas mais complexas, não é o padrão que recomendamos. A depuração do TensorFlow já pode ser um desafio, e a depuração do TensorFlow depois de totalmente serializado e reimportado perde necessariamente alguns metadados e limita a interatividade, deixando a depuração ainda mais desafiadora.\n",
        "\n",
        "Portanto, **recomendamos escrever uma lógica do TF complexa como funções Python independentes** (ou seja, sem decoração de `tff.tf_computation`). Assim, a lógica do TensorFlow pode ser desenvolvida e testada usando as práticas recomendadas e ferramentas do TF (como o modo eager), antes de serializar a computação para o TFF (por exemplo, invocando `tff.tf_computation` com uma função Python como argumento)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSd6UatXbzw-"
      },
      "source": [
        "### Definição de uma função de perda\n",
        "\n",
        "Agora que temos os dados, vamos definir uma função de perda que possa ser usada para treinamento. Primeiro, vamos definir o tipo de entrada como uma tupla nomeada do TFF. Como o tamanho dos lotes de dados pode variar, definimos a dimensão do lote como `None`, indicando que o tamanho dessa dimensão é desconhecido."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "653xv5NXd4fy"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<x=float32[?,784],y=int32[?]>'"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "BATCH_SPEC = collections.OrderedDict(\n",
        "    x=tf.TensorSpec(shape=[None, 784], dtype=tf.float32),\n",
        "    y=tf.TensorSpec(shape=[None], dtype=tf.int32))\n",
        "BATCH_TYPE = tff.to_type(BATCH_SPEC)\n",
        "\n",
        "str(BATCH_TYPE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pb6qPUvyh5A1"
      },
      "source": [
        "Você talvez se pergunte por que não podemos apenas definir um tipo Python comum. Lembre-se da discussão na [parte 1](custom_federated_algorithms_1.ipynb), onde explicamos que, embora seja possível expressar a lógica computacional do TFF usando Python, em segundo plano, as computações do TFF *não são* Python. O símbolo `BATCH_TYPE` definido acima representa uma especificação de tipo abstrato do TFF. É importante distinguir esse tipo *abstrato* do TFF dos tipos de *representação* do Python concretos. Por exemplo, containers como `dict` ou `collections.namedtuple` que podem ser usados para representar o tipo do TFF no corpo de uma função Python. Ao contrário do Python, o TFF tem um único construtor de tipo abstrato `tff.StructType` para contêineres semelhantes a tuplas, com elementos que podem ser nomeados individualmente ou deixados sem nome. Esse tipo também é usado para modelar parâmetros formais de computações, já que as computações do TFF podem declarar formalmente apenas um parâmetro e um resultado — você verá exemplos disso em breve.\n",
        "\n",
        "Agora vamos definir o tipo do TFF dos parâmetros do modelo, novamente como uma tupla nomeada do TFF de *pesos* e *bias*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Og7VViafh-30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<weights=float32[784,10],bias=float32[10]>\n"
          ]
        }
      ],
      "source": [
        "MODEL_SPEC = collections.OrderedDict(\n",
        "    weights=tf.TensorSpec(shape=[784, 10], dtype=tf.float32),\n",
        "    bias=tf.TensorSpec(shape=[10], dtype=tf.float32))\n",
        "MODEL_TYPE = tff.to_type(MODEL_SPEC)\n",
        "print(MODEL_TYPE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHhdaWSpfQxo"
      },
      "source": [
        "Depois dessas definições, podemos definir a perda de um determinado modelo, em um único lote. Observe o uso do decorador `@tf.function` dentro do decorador `@tff.tf_computation`. Isso nos permite escrever código TF usando semântica semelhante à do Python, mesmo dentro de um contexto `tf.Graph` criado pelo decorador `tff.tf_computation`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "4EObiz_Ke0uK"
      },
      "outputs": [],
      "source": [
        "# NOTE: `forward_pass` is defined separately from `batch_loss` so that it can \n",
        "# be later called from within another tf.function. Necessary because a\n",
        "# @tf.function  decorated method cannot invoke a @tff.tf_computation.\n",
        "\n",
        "@tf.function\n",
        "def forward_pass(model, batch):\n",
        "  predicted_y = tf.nn.softmax(\n",
        "      tf.matmul(batch['x'], model['weights']) + model['bias'])\n",
        "  return -tf.reduce_mean(\n",
        "      tf.reduce_sum(\n",
        "          tf.one_hot(batch['y'], 10) * tf.math.log(predicted_y), axis=[1]))\n",
        "\n",
        "@tff.tf_computation(MODEL_TYPE, BATCH_TYPE)\n",
        "def batch_loss(model, batch):\n",
        "  return forward_pass(model, batch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8K0UZHGnr8SB"
      },
      "source": [
        "Como esperado, a computação `batch_loss` retorna a perda de `float32` considerando o modelo e um único lote de dados. Observe como `MODEL_TYPE` e `BATCH_TYPE` foram agrupados em duas tuplas de parâmetros formais. Você pode reconhecer o tipo de `batch_loss` como `(<MODEL_TYPE,BATCH_TYPE> -> float32)`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "4WXEAY8Nr89V"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'(<model=<weights=float32[784,10],bias=float32[10]>,batch=<x=float32[?,784],y=int32[?]>> -> float32)'"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "str(batch_loss.type_signature)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAnt_UcdnvGa"
      },
      "source": [
        "Como teste de sanidade, vamos construir um modelo inicial cheio de zeros e calcular a perda no lote de dados visualizado acima."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "U8Ne8igan3os"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2.3025851"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "initial_model = collections.OrderedDict(\n",
        "    weights=np.zeros([784, 10], dtype=np.float32),\n",
        "    bias=np.zeros([10], dtype=np.float32))\n",
        "\n",
        "sample_batch = federated_train_data[5][-1]\n",
        "\n",
        "batch_loss(initial_model, sample_batch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckigEAyDAWFV"
      },
      "source": [
        "Alimentamos a computação do TFF com o modelo inicial definido como um `dict`, mesmo que o corpo da função Python que o define consuma parâmetros do modelo como `model['weight']` e `model['bias']`. Os argumentos da chamada de `batch_loss` não são apenas passados para o corpo dessa função.\n",
        "\n",
        "O que acontece quando invocamos `batch_loss`? Já foi realizado o tracing e a serialização do corpo em Python de `batch_loss` na célula acima onde foi definido. O TFF faz a chamada de `batch_loss` no tempo de definição da computação e é alvo da invocação no momento em que `batch_loss` é invocada. Em ambas as funções, o TFF serve como uma ponte entre o sistema de tipos abstratos do TFF e os tipos de representação do Python. No momento da invocação, o TFF aceitará a maioria dos tipos de contêiner Python padrão (`dict`, `list`, `tuple`, `collections.namedtuple` etc.) como representações concretas de tuplas do TFF abstratas. Além disso, como observado acima, mesmo que as computações do TFF só aceitem formalmente um único parâmetro, você pode usar a sintaxe de chamada familiar do Python com argumentos posicionais e/ou de palavras-chave quando o tipo do parâmetro é uma tupla — funciona como esperado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eB510nILYbId"
      },
      "source": [
        "### Método do gradiente descendente em um único lote\n",
        "\n",
        "Agora, vamos definir uma computação que use essa função de perda para realizar uma única etapa de método do gradiente descendente. Veja como, ao definir essa função, usamos `batch_loss` como um subcomponente. Você pode invocar uma computação construída com `tff.tf_computation` dentro do corpo de outra computação, embora geralmente não seja necessário — como observado acima, a serialização perde informações de depuração, então é geralmente preferível para computações mais complexas para escrever e testar todo o código TensorFlow sem o decorador `tff.tf_computation`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "O4uaVxw3AyYS"
      },
      "outputs": [],
      "source": [
        "@tff.tf_computation(MODEL_TYPE, BATCH_TYPE, tf.float32)\n",
        "def batch_train(initial_model, batch, learning_rate):\n",
        "  # Define a group of model variables and set them to `initial_model`. Must\n",
        "  # be defined outside the @tf.function.\n",
        "  model_vars = collections.OrderedDict([\n",
        "      (name, tf.Variable(name=name, initial_value=value))\n",
        "      for name, value in initial_model.items()\n",
        "  ])\n",
        "  optimizer = tf.keras.optimizers.SGD(learning_rate)\n",
        "\n",
        "  @tf.function\n",
        "  def _train_on_batch(model_vars, batch):\n",
        "    # Perform one step of gradient descent using loss from `batch_loss`.\n",
        "    with tf.GradientTape() as tape:\n",
        "      loss = forward_pass(model_vars, batch)\n",
        "    grads = tape.gradient(loss, model_vars)\n",
        "    optimizer.apply_gradients(\n",
        "        zip(tf.nest.flatten(grads), tf.nest.flatten(model_vars)))\n",
        "    return model_vars\n",
        "\n",
        "  return _train_on_batch(model_vars, batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Y84gQsaohC38"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'(<initial_model=<weights=float32[784,10],bias=float32[10]>,batch=<x=float32[?,784],y=int32[?]>,learning_rate=float32> -> <weights=float32[784,10],bias=float32[10]>)'"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "str(batch_train.type_signature)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ID8xg9FCUL2A"
      },
      "source": [
        "Ao invocar uma função Python decorada com `tff.tf_computation` no corpo de outra função desse tipo, a lógica da computação interna do TFF é incorporada (basicamente, inline) na lógica da externa. Como observado acima, se você estiver escrevendo as duas computações, é provavelmente melhor transformar a função interna (nesse caso, `batch_loss`) em Python normal ou `tf.function` em vez de `tff.tf_computation`. No entanto, ilustramos aqui que chamar uma `tff.tf_computation` dentro de outra funciona basicamente como esperado. Isso pode ser necessário se, por exemplo, você não tiver o código Python que define `batch_loss`, mas apenas a representação do TFF serializada.\n",
        "\n",
        "Agora, vamos aplicar essa função algumas vezes ao modelo inicial para ver se a perda diminui."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "8edcJTlXUULm"
      },
      "outputs": [],
      "source": [
        "model = initial_model\n",
        "losses = []\n",
        "for _ in range(5):\n",
        "  model = batch_train(model, sample_batch, 0.1)\n",
        "  losses.append(batch_loss(model, sample_batch))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "3n1onojT1zHv"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0.19690025, 0.13176318, 0.101132266, 0.08273812, 0.0703014]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "losses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQk4Ha8PU-3P"
      },
      "source": [
        "### Método do gradiente descendente em uma sequência de dados locais\n",
        "\n",
        "Agora, como `batch_train` parece funcionar, vamos escrever uma função de treinamento `local_train`  semelhante que consome a sequência inteira de todos os lotes de um usuário, em vez de apenas um lote. A nova computação agora precisará consumir `tff.SequenceType(BATCH_TYPE)` em vez de `BATCH_TYPE`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "EfPD5a6QVNXM"
      },
      "outputs": [],
      "source": [
        "LOCAL_DATA_TYPE = tff.SequenceType(BATCH_TYPE)\n",
        "\n",
        "@tff.federated_computation(MODEL_TYPE, tf.float32, LOCAL_DATA_TYPE)\n",
        "def local_train(initial_model, learning_rate, all_batches):\n",
        "  \n",
        "  # Reduction function to apply to each batch.\n",
        "  @tff.federated_computation((MODEL_TYPE, tf.float32), BATCH_TYPE)\n",
        "  def batch_fn(model_with_lr, batch):\n",
        "    model, lr = model_with_lr\n",
        "    return batch_train(model, batch, lr), lr\n",
        "\n",
        "  trained_model, _ = tff.sequence_reduce(\n",
        "      all_batches, (initial_model, learning_rate), batch_fn\n",
        "  )\n",
        "  return trained_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "sAhkS5yKUgjC"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'(<initial_model=<weights=float32[784,10],bias=float32[10]>,learning_rate=float32,all_batches=<x=float32[?,784],y=int32[?]>*> -> <weights=float32[784,10],bias=float32[10]>)'"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "str(local_train.type_signature)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYT-SiopYBtH"
      },
      "source": [
        "Essa breve seção de código contém vários detalhes. Vamos analisar cada um.\n",
        "\n",
        "Primeiro, embora seja possível implementar toda essa lógica no TensorFlow, contando com `tf.data.Dataset.reduce` para processar a sequência de forma parecida com o que fizemos antes, desta vez optamos por expressar a lógica na linguagem glue, como uma `tff.federated_computation`. Usamos o operador federado `tff.sequence_reduce` para realizar a redução.\n",
        "\n",
        "O operador `tff.sequence_reduce` é usado de maneira semelhante a `tf.data.Dataset.reduce`. Ele pode ser considerado praticamente igual a `tf.data.Dataset.reduce`, mas é usado em computações federadas, que, como você deve lembrar, não podem conter código TensorFlow. É um operador de modelo com um parâmetro formal de três tuplas que consiste em uma *sequência* de elementos do tipo `T`, o estado inicial da redução (vamos fazer referência a ele abstratamente como *zero*) de um tipo `U` e o *operador de redução* do tipo `(<U,T> -> U)` que altera o estado da redução processando um único elemento. O resultado é o estado final da redução, após processar todos os elementos em ordem sequencial. Em nosso exemplo, o estado da redução é o modelo treinado em um prefixo dos dados, e os elementos são lotes de dados.\n",
        "\n",
        "Em segundo lugar, observe que usamos novamente uma computação (`batch_train`) como um componente dentro de outro (`local_train`), mas não diretamente. Não podemos usá-lo como operador de redução porque ele recebe um parâmetro adicional: a taxa de aprendizado. Para resolver isso, definimos uma computação federada incorporada `batch_fn` que se vincula ao parâmetro `learning_rate` do `local_train` no seu corpo. Uma computação filha definida dessa forma pode capturar um parâmetro formal da sua mãe, desde que a computação filha não seja invocada fora do corpo da mãe. Pense nesse padrão como equivalente a `functools.partial` em Python.\n",
        "\n",
        "A implicação prática de capturar a `learning_rate` dessa maneira é, claro, que o mesmo valor de taxa de aprendizado é usado em todos os lotes.\n",
        "\n",
        "Agora, vamos testar a função de treinamento local recém-definida em toda a sequência de dados do mesmo usuário que contribuiu com o lote de amostra (dígito `5`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "EnWFLoZGcSby"
      },
      "outputs": [],
      "source": [
        "locally_trained_model = local_train(initial_model, 0.1, federated_train_data[5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0UXUqGk9zoF"
      },
      "source": [
        "Funcionou? Para responder a essa pergunta, precisamos implementar a avaliação."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8WDKu6WYy__"
      },
      "source": [
        "### Avaliação local\n",
        "\n",
        "Esta é uma maneira de implementar a avaliação local ao somar as perdas de todos os lotes de dados (também seria possível calcular a média; vamos deixar isso como um exercício para o leitor)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "0RiODuc6z7Ln"
      },
      "outputs": [],
      "source": [
        "@tff.federated_computation(MODEL_TYPE, LOCAL_DATA_TYPE)\n",
        "def local_eval(model, all_batches):\n",
        "\n",
        "  @tff.tf_computation((MODEL_TYPE, tf.float32), BATCH_TYPE)\n",
        "  def accumulate_evaluation(model_and_accumulator, batch):\n",
        "    model, accumulator = model_and_accumulator\n",
        "    return model, accumulator + batch_loss(model, batch)\n",
        "\n",
        "  _, total_loss = tff.sequence_reduce(\n",
        "      all_batches, (model, 0.0), accumulate_evaluation\n",
        "  )\n",
        "  return total_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "pH2XPEAKa4Dg"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'(<model=<weights=float32[784,10],bias=float32[10]>,all_batches=<x=float32[?,784],y=int32[?]>*> -> float32)'"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "str(local_eval.type_signature)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efX81HuE-BcO"
      },
      "source": [
        "Novamente, há alguns elementos novos ilustrados nesse código, vamos analisá-los um a um.\n",
        "\n",
        "Primeiro, usamos dois novos operadores federados para processar sequências: `tff.sequence_map`, que aceita uma *função de mapeamento* `T->U` e uma *sequência* de `T` e emite uma sequência de `U` obtida ao aplicar a função de mapeamento pontual, e `tff.sequence_sum`, que apenas soma todos os elementos. Mapeamos cada lote de dados a um valor de perda e, em seguida, adicionamos os valores de perda resultantes para calcular a perda total.\n",
        "\n",
        "Também seria possível usar `tff.sequence_reduce` novamente, mas essa não é a melhor escolha — o processo de redução é, por definição, sequencial, enquanto o mapeamento e a soma podem ser calculados em paralelo. Quando for possível escolher, é melhor ficar com operadores que não restringem as escolhas de implementação. Assim, quando nossa computação do TFF for compilada no futuro para ser implantada em um ambiente específico, será possível aproveitar ao máximo todas as oportunidades possíveis para uma execução mais rápida, mais escalonável e com maior eficiência de recursos.\n",
        "\n",
        "Segundo, assim como em `local_train`, a função do componente que precisamos (`batch_loss`) aceita mais parâmetros do que o operador federado (`tff.sequence_map`) espera, então definimos novamente uma parcial, desta vez inline, ao envolver diretamente um `lambda` como uma `tff.federated_computation`. Usar wrappers inline com uma função como argumento é a maneira recomendada de usar `tff.tf_computation` para incorporar a lógica do TensorFlow no TFF.\n",
        "\n",
        "Agora, vamos ver se o treinamento funcionou."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "vPw6JSVf5q_x"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "initial_model loss = 23.025854\n",
            "locally_trained_model loss = 0.43484688\n"
          ]
        }
      ],
      "source": [
        "print('initial_model loss =', local_eval(initial_model,\n",
        "                                         federated_train_data[5]))\n",
        "print('locally_trained_model loss =',\n",
        "      local_eval(locally_trained_model, federated_train_data[5]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Tvu70cnBsUf"
      },
      "source": [
        "Realmente, a perda diminuiu. Mas e se avaliarmos isso nos dados de outro usuário?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "gjF0NYAj5wls"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "initial_model loss = 23.025854\n",
            "locally_trained_model loss = 74.50075\n"
          ]
        }
      ],
      "source": [
        "print('initial_model loss =', local_eval(initial_model,\n",
        "                                         federated_train_data[0]))\n",
        "print('locally_trained_model loss =',\n",
        "      local_eval(locally_trained_model, federated_train_data[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WPumnRTBzUs"
      },
      "source": [
        "Como esperado, as coisas pioraram. O modelo foi treinado para reconhecer `5` e nunca viu um `0`. Isso levanta a questão: como é que o treinamento local afetou a qualidade do modelo de uma perspectiva global?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJnL2mQRZKTO"
      },
      "source": [
        "### Avaliação federada\n",
        "\n",
        "Este é o ponto da jornada em que finalmente voltamos aos tipos federados e às computações federadas — o tema com o qual começamos. Confira um par de definições de tipos do TFF para o modelo que se origina no servidor e os dados que permanecem nos clientes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "LjGGhpoEBh_6"
      },
      "outputs": [],
      "source": [
        "SERVER_MODEL_TYPE = tff.type_at_server(MODEL_TYPE)\n",
        "CLIENT_DATA_TYPE = tff.type_at_clients(LOCAL_DATA_TYPE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gTXV2-jZtE3"
      },
      "source": [
        "Com todas as definições apresentadas até agora, expressar a avaliação federada no TFF é trivial: distribuímos o modelo aos clientes, deixamos cada cliente invocar a avaliação local na sua porção de dados local e calculamos a média da perda. Veja uma maneira de escrever isso."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "2zChEPzEBx4T"
      },
      "outputs": [],
      "source": [
        "@tff.federated_computation(SERVER_MODEL_TYPE, CLIENT_DATA_TYPE)\n",
        "def federated_eval(model, data):\n",
        "  return tff.federated_mean(\n",
        "      tff.federated_map(local_eval, [tff.federated_broadcast(model),  data]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWcNONNWaE0N"
      },
      "source": [
        "Já vimos exemplos de `tff.federated_mean` e `tff.federated_map` em cenários mais simples e, a nível intuitivo, elas funcionam como esperado. Porém, essa seção de código é mais complexa do que aparenta, então vamos examiná-la com cuidado.\n",
        "\n",
        "Primeiro, vamos analisar a parte \"*deixamos cada cliente invocar a avaliação local na sua porção de dados local*\". Como mencionamos nas seções anteriores, `local_eval` tem uma assinatura de tipo no formato `(<MODEL_TYPE, LOCAL_DATA_TYPE> -> float32)`.\n",
        "\n",
        "O operador federado `tff.federated_map` é um modelo que aceita como parâmetro duas tuplas que consistem na *função de mapeamento* de um tipo `T->U` e um valor federado do tipo `{T}@CLIENTS` (ou seja, com membros constituintes do mesmo tipo que o parâmetro da função de mapeamento) e retorna um resultado do tipo `{U}@CLIENTES`.\n",
        "\n",
        "Como estamos alimentando `local_eval` como uma função de mapeamento que será aplicada a cada cliente, o segundo argumento deve ser um tipo federado `{<MODEL_TYPE, LOCAL_DATA_TYPE>}@CLIENTS`, ou seja, na nomenclatura das seções anteriores, deve ser uma tupla federada. Cada cliente deve conter um conjunto completo de argumentos para `local_eval` como um membro constituinte. Em vez disso, estamos alimentando-o com uma `list` Python de dois elementos. O que está acontecendo aqui?\n",
        "\n",
        "Isso é um exemplo de uma *conversão de tipo implícito* no TFF, semelhante às conversões de tipo implícito que você talvez tenha visto em outros lugares, por exemplo, ao alimentar um `int` para uma função que aceita um `float`. Por enquanto, a conversão implícita é pouco usada, mas planejamos difundi-la mais no TFF como uma forma de reduzir o boilerplate.\n",
        "\n",
        "A conversão implícita aplicada nesse caso é a equivalência entre tuplas federadas no formato `{<X,Y>}@Z` e tuplas de valores federados `<{X}@Z,{Y}@Z>`. Embora formalmente sejam assinaturas de tipos diferentes, da perspectiva dos programadores, cada dispositivo em `Z` contém duas unidades de dados `X` e `Y`. O que acontece aqui não é diferente do `zip` no Python e, realmente, oferecemos um operador `tff.federated_zip` para realizar essas conversões explicitamente. Quando o `tff.federated_map` se depara com uma tupla como um segundo argumento, ele simplesmente invoca `tff.federated_zip` para você.\n",
        "\n",
        "Diante do exposto acima, agora você reconhece a expressão `tff.federated_broadcast(model)` como a representação de um valor de tipo do TFF `{MODEL_TYPE}@CLIENTS` e `data` como um valor de tipo do TFF `{LOCAL_DATA_TYPE}@CLIENTS` (ou simplesmente `CLIENT_DATA_TYPE`). Os dois são filtrados juntos por um `tff.federated_zip` implícito para formar o segundo argumento de `tff.federated_map`.\n",
        "\n",
        "O operador `tff.federated_broadcast`, como esperado, simplesmente transfere os dados do servidor para os clientes.\n",
        "\n",
        "Agora, vamos ver como nosso treinamento local afetou a perda média do sistema."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "tbmtJItcn94j"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "initial_model loss = 23.025852\n",
            "locally_trained_model loss = 54.43263\n"
          ]
        }
      ],
      "source": [
        "print('initial_model loss =', federated_eval(initial_model,\n",
        "                                             federated_train_data))\n",
        "print('locally_trained_model loss =',\n",
        "      federated_eval(locally_trained_model, federated_train_data))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQi2rGX_fK7i"
      },
      "source": [
        "Como esperado, a perda aumentou. Para melhorar o modelo para todos os usuários, vamos precisar treinar com os dados de todos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkw9f59qfS7o"
      },
      "source": [
        "### Treinamento federado\n",
        "\n",
        "A maneira mais simples de implementar o treinamento federado é treinar localmente e, em seguida, calcular a média dos modelos. Isso utiliza os mesmos blocos básicos e padrões que já discutimos, como você pode ver abaixo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "mBOC4uoG6dd-"
      },
      "outputs": [],
      "source": [
        "SERVER_FLOAT_TYPE = tff.type_at_server(tf.float32)\n",
        "\n",
        "\n",
        "@tff.federated_computation(SERVER_MODEL_TYPE, SERVER_FLOAT_TYPE,\n",
        "                           CLIENT_DATA_TYPE)\n",
        "def federated_train(model, learning_rate, data):\n",
        "  return tff.federated_mean(\n",
        "      tff.federated_map(local_train, [\n",
        "          tff.federated_broadcast(model),\n",
        "          tff.federated_broadcast(learning_rate), data\n",
        "      ]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2vACMsQjzO1"
      },
      "source": [
        "Na implementação completa do cálculo federado de média fornecido por `tff.learning`, em vez de calcular a média dos modelos, preferimos calcular a média dos deltas dos modelos, por vários motivos, como a capacidade de cortar as normas de atualização, para compressão etc.\n",
        "\n",
        "Vamos ver se o treinamento funciona executando algumas rodadas de treinamento e comparando a perda média antes e depois."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "NLx-3rLs9jGY"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "round 0, loss=21.60552406311035\n",
            "round 1, loss=20.365678787231445\n",
            "round 2, loss=19.27480125427246\n",
            "round 3, loss=18.31110954284668\n",
            "round 4, loss=17.457256317138672\n"
          ]
        }
      ],
      "source": [
        "model = initial_model\n",
        "learning_rate = 0.1\n",
        "for round_num in range(5):\n",
        "  model = federated_train(model, learning_rate, federated_train_data)\n",
        "  learning_rate = learning_rate * 0.9\n",
        "  loss = federated_eval(model, federated_train_data)\n",
        "  print('round {}, loss={}'.format(round_num, loss))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0VjSLQzlUIp"
      },
      "source": [
        "Para completar, vamos executar também os dados de teste, confirmando se o modelo generaliza bem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "ZaZT45yFMOaM"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "initial_model test loss = 22.795593\n",
            "trained_model test loss = 17.278767\n"
          ]
        }
      ],
      "source": [
        "print('initial_model test loss =',\n",
        "      federated_eval(initial_model, federated_test_data))\n",
        "print('trained_model test loss =', federated_eval(model, federated_test_data))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxlHHwLGlgFB"
      },
      "source": [
        "Isso conclui nosso tutorial.\n",
        "\n",
        "É claro que nosso exemplo simplificado não reflete uma série de coisas que você precisaria fazer em um cenário mais realista. Por exemplo, não calculamos outras métricas além da perda. Recomendamos que você estude a [implementação](https://github.com/tensorflow/federated/blob/main/tensorflow_federated/python/learning/federated_averaging.py) do cálculo federado de média em `tff.learning` como um exemplo mais completo e uma forma de demonstrar algumas das práticas de programação que queremos incentivar."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "custom_federated_algorithms_2.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
