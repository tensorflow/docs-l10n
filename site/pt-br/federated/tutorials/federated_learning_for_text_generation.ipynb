{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lf7huAiYp-An"
      },
      "source": [
        "##### Copyright 2019 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "YHz2D-oIqBWa"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x44FFES-r6y0"
      },
      "source": [
        "# Aprendizado federado para geração de texto"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPFgLeZIsZ3Q"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>     <a target=\"_blank\" href=\"https://www.tensorflow.org/federated/tutorials/federated_learning_for_text_generation\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver em TensorFlow.org</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/pt-br/federated/tutorials/federated_learning_for_text_generation.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Executar no Google Colab</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/pt-br/federated/tutorials/federated_learning_for_text_generation.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver fonte no GitHub</a>\n",
        "</td>\n",
        "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/pt-br/federated/tutorials/federated_learning_for_text_generation.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Baixar notebook</a>\n",
        "</td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbNz2tuvsAFB"
      },
      "source": [
        "**OBSERVAÇÃO**: foi verificado que este Colab funciona com a [versão mais recente lançada](https://github.com/tensorflow/federated#compatibility) do pacote pip `tensorflow_federated`, mas o projeto TensorFlow Federated ainda está em desenvolvimento pré-lançamento e pode não funcionar no `main`.\n",
        "\n",
        "Este tutorial aprofunda os conceitos do tutorial [Aprendizado federado para classificação de imagens](federated_learning_for_image_classification.ipynb) e demonstra diversas outras estratégias úteis de aprendizado federado.\n",
        "\n",
        "Especificamente, carregamos um modelo do Keras já treinado e o refinamos utilizando treinamento federado em um dataset descentralizado (simulado). Isso é especialmente importante por diversos motivos. A capacidade de usar modelos serializados facilita a combinação de aprendizado federado com outras estratégias de aprendizado de máquina. Além disso, permite usar uma gama cada vez maior de modelos pré-treinados – por exemplo, raramente é necessário treinar modelos de linguagem do zero, pois diversos modelos pré-treinados estão amplamente disponíveis (confira o [TF Hub](https://www.tensorflow.org/hub)). Em vez disso, faz mais sentido começar a partir de um modelo pré-treinado e refiná-lo usando aprendizado federado, fazendo as adaptações para as características particulares dos dados descentralizados para uma aplicação específica.\n",
        "\n",
        "Neste tutorial, vamos começar com uma RNN que gera caracteres ASCII e vamos refiná-la usando aprendizado federado. Também vamos mostrar como os pesos finais podem ser alimentados de volta ao modelo do Keras original, o que permite fazer rapidamente a avaliação e geração de texto usando ferramentas padrão."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9LcC1AwjoqfR"
      },
      "outputs": [],
      "source": [
        "#@test {\"skip\": true}\n",
        "!pip install --quiet --upgrade tensorflow-federated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZjDQysatrc2S"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "b'Hello, World!'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import collections\n",
        "import functools\n",
        "import os\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_federated as tff\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "# Test that TFF is working:\n",
        "tff.federated_computation(lambda: 'Hello, World!')()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lyICXwVAxvW9"
      },
      "source": [
        "## Carregue um modelo pré-treinado\n",
        "\n",
        "Carregamos um modelo pré-treinado seguindo o tutorial [Geração de texto usando uma RNN com execução eager](https://www.tensorflow.org/tutorials/sequences/text_generation) do TensorFlow. Porém, em vez de treinarmos usando [As obras completas de Shakespeare](http://www.gutenberg.org/files/100/100-0.txt), pré-treinamos o modelo usando o texto de [Uma história em duas cidades](http://www.ibiblio.org/pub/docs/books/gutenberg/9/98/98.txt) e [Um conto de Natal](http://www.ibiblio.org/pub/docs/books/gutenberg/4/46/46.txt) de Charles Dickens.\n",
        "\n",
        "Exceto pela expansão do vocabulário, não modificamos o tutorial original, então esse modelo inicial não é o mais avançado, mas gera previsões razoáveis e é suficiente para as finalidades deste tutorial. O modelo final foi salvo com `tf.keras.models.save_model(include_optimizer=False)`.\n",
        "\n",
        "Vamos usar aprendizado federado para fazer os ajustes finos do modelo de Shakespeare para este tutorial usando uma versão federada dos dados fornecida pelo TFF.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgF8e2Ksyq1F"
      },
      "source": [
        "### Gere as tabelas de pesquisa de vocabulário"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IlCgQBRVymwR"
      },
      "outputs": [],
      "source": [
        "# A fixed vocabularly of ASCII chars that occur in the works of Shakespeare and Dickens:\n",
        "vocab = list('dhlptx@DHLPTX $(,048cgkoswCGKOSW[_#\\'/37;?bfjnrvzBFJNRVZ\"&*.26:\\naeimquyAEIMQUY]!%)-159\\r')\n",
        "\n",
        "# Creating a mapping from unique characters to indices\n",
        "char2idx = {u:i for i, u in enumerate(vocab)}\n",
        "idx2char = np.array(vocab)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2EH6MFRdzAwd"
      },
      "source": [
        "### Carregue o modelo pré-treinado e gere algum texto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iIK674SrtCTm"
      },
      "outputs": [],
      "source": [
        "def load_model(batch_size):\n",
        "  urls = {\n",
        "      1: 'https://storage.googleapis.com/tff-models-public/dickens_rnn.batch1.kerasmodel',\n",
        "      8: 'https://storage.googleapis.com/tff-models-public/dickens_rnn.batch8.kerasmodel'}\n",
        "  assert batch_size in urls, 'batch_size must be in ' + str(urls.keys())\n",
        "  url = urls[batch_size]\n",
        "  local_file = tf.keras.utils.get_file(os.path.basename(url), origin=url)  \n",
        "  return tf.keras.models.load_model(local_file, compile=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WvuwZBX5Ogfd"
      },
      "outputs": [],
      "source": [
        "def generate_text(model, start_string):\n",
        "  # From https://www.tensorflow.org/tutorials/sequences/text_generation\n",
        "  num_generate = 200\n",
        "  input_eval = [char2idx[s] for s in start_string]\n",
        "  input_eval = tf.expand_dims(input_eval, 0)\n",
        "  text_generated = []\n",
        "  temperature = 1.0\n",
        "\n",
        "  model.reset_states()\n",
        "  for i in range(num_generate):\n",
        "    predictions = model(input_eval)\n",
        "    predictions = tf.squeeze(predictions, 0)\n",
        "    predictions = predictions / temperature\n",
        "    predicted_id = tf.random.categorical(\n",
        "        predictions, num_samples=1)[-1, 0].numpy()\n",
        "    input_eval = tf.expand_dims([predicted_id], 0)\n",
        "    text_generated.append(idx2char[predicted_id])\n",
        "\n",
        "  return (start_string + ''.join(text_generated))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MGAdStJ5wDPV"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tff-models-public/dickens_rnn.batch1.kerasmodel\n",
            "16193984/16193984 [==============================] - 0s 0us/step\n",
            "What of TensorFlow Federated, you ask? Same yee you? Have I so,\n",
            "often games in a man who rode one knee over his friend, with the\n",
            "stone faces of the dread prisoners, dud a tender mastery. They\n",
            "are not alive is infirmed us--to ever resume\n"
          ]
        }
      ],
      "source": [
        "# Text generation requires a batch_size=1 model.\n",
        "keras_model_batch1 = load_model(batch_size=1)\n",
        "print(generate_text(keras_model_batch1, 'What of TensorFlow Federated, you ask? '))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKMUn-TlgxuP"
      },
      "source": [
        "## Carregue e pré-processe os dados de Shakespeare federados\n",
        "\n",
        "O pacote `tff.simulation.datasets` fornece diversos datasets que são divididos em \"clientes\", em que cada cliente corresponde a um dataset em um dispositivo específico que pode participar do aprendizado federado.\n",
        "\n",
        "Esses datasets fornecem distribuições de dados não distribuídos identicamente que replicam em simulações os desafios de fazer treinamento com dados descentralizados reais. Parte do pré-processamento desses dados foi feita usando-se ferramentas do [Leaf project](https://arxiv.org/abs/1812.01097) ([github](https://github.com/TalwalkarLab/leaf))."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "di3nStTDg0qc"
      },
      "outputs": [],
      "source": [
        "train_data, test_data = tff.simulation.datasets.shakespeare.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_iiY65Vv4QNK"
      },
      "source": [
        "Os datasets fornecidos por `shakespeare.load_data()` consistem de uma sequência `Tensors` string, um para cada fala de um personagem específico de uma peça de Shakespeare. As chaves de cliente consistem do nome da peça combinado com o nome do personagem. Portanto, por exemplo, `MUCH_ADO_ABOUT_NOTHING_OTHELLO` corresponde às falas do personagem Othello na peça *Muito Barulho por Nada (Much Ado About Nothing)*. Observe que, em um cenário real de aprendizado federado, os clientes nunca são identificados ou rastreados por IDs, mas, para simulações, trabalhar com datasets com chaves é muito útil.\n",
        "\n",
        "Aqui, por exemplo, podemos dar uma olhada nos dados de Rei Lear:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FEKiy1ntmmnk"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(b'', shape=(), dtype=string)\n",
            "tf.Tensor(b'What?', shape=(), dtype=string)\n"
          ]
        }
      ],
      "source": [
        "# Here the play is \"The Tragedy of King Lear\" and the character is \"King\".\n",
        "raw_example_dataset = train_data.create_tf_dataset_for_client(\n",
        "    'THE_TRAGEDY_OF_KING_LEAR_KING')\n",
        "# To allow for future extensions, each entry x\n",
        "# is an OrderedDict with a single key 'snippets' which contains the text.\n",
        "for x in raw_example_dataset.take(2):\n",
        "  print(x['snippets'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUnbI5Hp4sXg"
      },
      "source": [
        "Agora usamos as transformações de `tf.data.Dataset` a fim de preparar esses dados para treinar a RNN de caracteres carregada acima.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9kDkmGe-7No7"
      },
      "outputs": [],
      "source": [
        "# Input pre-processing parameters\n",
        "SEQ_LENGTH = 100\n",
        "BATCH_SIZE = 8\n",
        "BUFFER_SIZE = 100  # For dataset shuffling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W95Of6Bwsrfc"
      },
      "outputs": [],
      "source": [
        "# Construct a lookup table to map string chars to indexes,\n",
        "# using the vocab loaded above:\n",
        "table = tf.lookup.StaticHashTable(\n",
        "    tf.lookup.KeyValueTensorInitializer(\n",
        "        keys=vocab, values=tf.constant(list(range(len(vocab))),\n",
        "                                       dtype=tf.int64)),\n",
        "    default_value=0)\n",
        "\n",
        "\n",
        "def to_ids(x):\n",
        "  s = tf.reshape(x['snippets'], shape=[1])\n",
        "  chars = tf.strings.bytes_split(s).values\n",
        "  ids = table.lookup(chars)\n",
        "  return ids\n",
        "\n",
        "\n",
        "def split_input_target(chunk):\n",
        "  input_text = tf.map_fn(lambda x: x[:-1], chunk)\n",
        "  target_text = tf.map_fn(lambda x: x[1:], chunk)\n",
        "  return (input_text, target_text)\n",
        "\n",
        "\n",
        "def preprocess(dataset):\n",
        "  return (\n",
        "      # Map ASCII chars to int64 indexes using the vocab\n",
        "      dataset.map(to_ids)\n",
        "      # Split into individual chars\n",
        "      .unbatch()\n",
        "      # Form example sequences of SEQ_LENGTH +1\n",
        "      .batch(SEQ_LENGTH + 1, drop_remainder=True)\n",
        "      # Shuffle and form minibatches\n",
        "      .shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
        "      # And finally split into (input, target) tuples,\n",
        "      # each of length SEQ_LENGTH.\n",
        "      .map(split_input_target))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jw98HnKmEhuh"
      },
      "source": [
        "Observe que, na formação das sequências originais e na formação dos lotes acima, usamos `drop_remainder=True` por questão de simplicidade. Portanto, todos os personagens (clientes) que não têm pelo menos `(SEQ_LENGTH + 1) * BATCH_SIZE` caracteres de texto terão datasets vazios. Uma estratégia típica para tratar isso seria preencher os lotes com um token especial e depois usar uma máscara na perda para não levar os tokens de preenchimento em consideração.\n",
        "\n",
        "Isso complicaria um pouco o exemplo, então, para este tutorial, usamos somente lotes completos, como no [tutorial padrão](https://www.tensorflow.org/tutorials/sequences/text_generation). Entretanto, em um ambiente federado, esse problema é mais significativo, pois muitos usuários podem ter datasets pequenos.\n",
        "\n",
        "Agora, podemos pré-processar o `raw_example_dataset` e verificar os tipos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7rTal7bksWwc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(TensorSpec(shape=(8, 100), dtype=tf.int64, name=None), TensorSpec(shape=(8, 100), dtype=tf.int64, name=None))\n"
          ]
        }
      ],
      "source": [
        "example_dataset = preprocess(raw_example_dataset)\n",
        "print(example_dataset.element_spec)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePT8Oawm8SRP"
      },
      "source": [
        "## Compile o modelo e teste com os dados pré-processados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEgDsz-48cAq"
      },
      "source": [
        "Carregamos um modelo do Keras não compilado, mas, para executar `keras_model.evaluate`, precisamos compilá-lo com uma perda e métricas. Também vamos compilar em um otimizador, que será usado como o otimizador no dispositivo para o aprendizado federado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsuVZ5KMWnn8"
      },
      "source": [
        "O tutorial original não tinha exatidão em nível de caracteres (a fração das previsões em que a probabilidade mais alta foi colocada no caractere correto). Essa é uma métrica útil, então vamos adicioná-la. Porém, precisamos definir uma nova classe de métricas para isso, pois nossas previsões têm posto 3 (um vetor de logits para cada uma das `BATCH_SIZE * SEQ_LENGTH` previsões), e `SparseCategoricalAccuracy` espera somente previsões de posto 2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gOUiDBvmWlM9"
      },
      "outputs": [],
      "source": [
        "class FlattenedCategoricalAccuracy(tf.keras.metrics.SparseCategoricalAccuracy):\n",
        "\n",
        "  def __init__(self, name='accuracy', dtype=tf.float32):\n",
        "    super().__init__(name, dtype=dtype)\n",
        "\n",
        "  def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "    y_true = tf.reshape(y_true, [-1, 1])\n",
        "    y_pred = tf.reshape(y_pred, [-1, len(vocab), 1])\n",
        "    return super().update_state(y_true, y_pred, sample_weight)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2X9eFgt94PM"
      },
      "source": [
        "Agora podemos compilar um modelo e avaliá-lo para nosso `example_dataset`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3Xd-52-9zGa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tff-models-public/dickens_rnn.batch8.kerasmodel\n",
            "16193984/16193984 [==============================] - 0s 0us/step\n",
            "Evaluating on an example Shakespeare character: 0.45.000\n",
            "Expected accuracy for random guessing: 0.012\n",
            "Evaluating on completely random data: 0.011\n"
          ]
        }
      ],
      "source": [
        "BATCH_SIZE = 8  # The training and eval batch size for the rest of this tutorial.\n",
        "keras_model = load_model(batch_size=BATCH_SIZE)\n",
        "keras_model.compile(\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[FlattenedCategoricalAccuracy()])\n",
        "\n",
        "# Confirm that loss is much lower on Shakespeare than on random data\n",
        "loss, accuracy = keras_model.evaluate(example_dataset.take(5), verbose=0)\n",
        "print(\n",
        "    'Evaluating on an example Shakespeare character: {a:3f}'.format(a=accuracy))\n",
        "\n",
        "# As a sanity check, we can construct some completely random data, where we expect\n",
        "# the accuracy to be essentially random:\n",
        "random_guessed_accuracy = 1.0 / len(vocab)\n",
        "print('Expected accuracy for random guessing: {a:.3f}'.format(\n",
        "    a=random_guessed_accuracy))\n",
        "random_indexes = np.random.randint(\n",
        "    low=0, high=len(vocab), size=1 * BATCH_SIZE * (SEQ_LENGTH + 1))\n",
        "data = collections.OrderedDict(\n",
        "    snippets=tf.constant(\n",
        "        ''.join(np.array(vocab)[random_indexes]), shape=[1, 1]))\n",
        "random_dataset = preprocess(tf.data.Dataset.from_tensor_slices(data))\n",
        "loss, accuracy = keras_model.evaluate(random_dataset, steps=10, verbose=0)\n",
        "print('Evaluating on completely random data: {a:.3f}'.format(a=accuracy))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lH0WzL5L8Lm4"
      },
      "source": [
        "## Faça os ajustes finos do modelo com aprendizado federado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCao4M3L_tsA"
      },
      "source": [
        "O TFF serializa todas as computações do TensorFlow para que elas possam ser executadas em um ambiente que não é Python (muito embora, no momento, somente um runtime de simulação implementado no Python esteja disponível). Embora estejamos fazendo a execução no modo eager (TF 2.0), atualmente o TFF serializa as computações do TensorFlow construindo os operadores necessários dentro do contexto de uma declaração \"`with tf.Graph.as_default()`\". Portanto, precisamos fornecer uma função que o TFF possa usar para apresentar nosso modelo a um grafo que ele controle, o que pode ser feito da seguinte maneira:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5KadIvFp7m6y"
      },
      "outputs": [],
      "source": [
        "# Clone the keras_model inside `create_tff_model()`, which TFF will\n",
        "# call to produce a new copy of the model inside the graph that it will \n",
        "# serialize. Note: we want to construct all the necessary objects we'll need \n",
        "# _inside_ this method.\n",
        "def create_tff_model():\n",
        "  # TFF uses an `input_spec` so it knows the types and shapes\n",
        "  # that your model expects.\n",
        "  input_spec = example_dataset.element_spec\n",
        "  keras_model_clone = tf.keras.models.clone_model(keras_model)\n",
        "  return tff.learning.models.from_keras_model(\n",
        "      keras_model_clone,\n",
        "      input_spec=input_spec,\n",
        "      loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "      metrics=[FlattenedCategoricalAccuracy()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJF_yhJxAi2l"
      },
      "source": [
        "Agora está tudo pronto para construirmos um processo iterativo de cálculo federado de médias, que usaremos para melhorar o modelo (confira detalhes sobre o algoritmo de cálculo federado de médias no artigo [Communication-Efficient Learning of Deep Networks from Decentralized Data](https://arxiv.org/abs/1602.05629) – Aprendizado de redes profundas com comunicação eficiente usando dados descentralizados).\n",
        "\n",
        "Usamos um modelo do Keras compilado para fazer a avaliação padrão (não federada) após cada rodada do treinamento federado, o que é útil para fins de pesquisa ao fazer o aprendizado federado simulado quando há um dataset de teste padrão.\n",
        "\n",
        "Em um ambiente de produção mais realista, essa mesma técnica pode ser usada para pegar modelos treinados com aprendizado federado e avaliá-los com um dataset de benchmark centralizado para fins de teste ou garantia de qualidade."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "my3PW3qhAMDA"
      },
      "outputs": [],
      "source": [
        "# This command builds all the TensorFlow graphs and serializes them: \n",
        "fed_avg = tff.learning.algorithms.build_weighted_fed_avg(\n",
        "    model_fn=create_tff_model,\n",
        "    client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVOkzs9C9kmv"
      },
      "source": [
        "Veja abaixo o loop mais simples possível, em que executamos o cálculo federado de médias para uma rodada para um único cliente em um único lote:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lrjUrkjq9jYk"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss=4.399, accuracy=0.139\n"
          ]
        }
      ],
      "source": [
        "state = fed_avg.initialize()\n",
        "result = fed_avg.next(state, [example_dataset.take(5)])\n",
        "state = result.state\n",
        "train_metrics = result.metrics['client_work']['train']\n",
        "print('loss={l:.3f}, accuracy={a:.3f}'.format(\n",
        "    l=train_metrics['loss'], a=train_metrics['accuracy']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2CjvVg0FZpS"
      },
      "source": [
        "Agora vamos escrever um loop de treinamento e avaliação ligeiramente mais interessante.\n",
        "\n",
        "Para que essa simulação ainda tenha uma execução relativamente rápida, treinamos nos mesmos três clientes em cada rodada, considerando somente dois minilotes para cada um.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wE386-rbMCve"
      },
      "outputs": [],
      "source": [
        "def data(client, source=train_data):\n",
        "  return preprocess(source.create_tf_dataset_for_client(client)).take(5)\n",
        "\n",
        "\n",
        "clients = [\n",
        "    'ALL_S_WELL_THAT_ENDS_WELL_CELIA', 'MUCH_ADO_ABOUT_NOTHING_OTHELLO',\n",
        "]\n",
        "\n",
        "train_datasets = [data(client) for client in clients]\n",
        "\n",
        "# We concatenate the test datasets for evaluation with Keras by creating a \n",
        "# Dataset of Datasets, and then identity flat mapping across all the examples.\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices(\n",
        "    [data(client, test_data) for client in clients]).flat_map(lambda x: x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cU3FuY00MOoX"
      },
      "source": [
        "O estado inicial do modelo gerado por `fed_avg.initialize()` é baseado nos inicializadores aleatórios para o modelo do Keras, e não nos pesos que foram carregados, já que `clone_model()` não clona os pesos. Para começar o treinamento a partir de um modelo pré-treinado, definimos os pesos do modelo no estado do servidor diretamente a partir do modelo carregado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vm_-PU8OFXpY"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Round 0\n",
            "\tEval: loss=3.171, accuracy=0.428\n",
            "\tTrain: loss=4.309, accuracy=0.098\n",
            "Round 1\n",
            "\tEval: loss=4.188, accuracy=0.185\n",
            "\tTrain: loss=4.037, accuracy=0.223\n",
            "Round 2\n",
            "\tEval: loss=3.948, accuracy=0.200\n",
            "\tTrain: loss=3.797, accuracy=0.228\n",
            "Round 3\n",
            "\tEval: loss=3.826, accuracy=0.179\n",
            "\tTrain: loss=3.662, accuracy=0.219\n",
            "Round 4\n",
            "\tEval: loss=3.723, accuracy=0.171\n",
            "\tTrain: loss=3.440, accuracy=0.245\n",
            "Final evaluation\n",
            "\tEval: loss=3.599, accuracy=0.181\n"
          ]
        }
      ],
      "source": [
        "NUM_ROUNDS = 5\n",
        "\n",
        "# The state of the FL server, containing the model and optimization state.\n",
        "state = fed_avg.initialize()\n",
        "\n",
        "# Load our pre-trained Keras model weights into the global model state.\n",
        "pre_trained_weights = tff.learning.models.ModelWeights(\n",
        "    trainable=[v.numpy() for v in keras_model.trainable_weights],\n",
        "    non_trainable=[v.numpy() for v in keras_model.non_trainable_weights]\n",
        ")\n",
        "state = fed_avg.set_model_weights(state, pre_trained_weights)\n",
        "\n",
        "\n",
        "def keras_evaluate(state, round_num):\n",
        "  # Take our global model weights and push them back into a Keras model to\n",
        "  # use its standard `.evaluate()` method.\n",
        "  keras_model = load_model(batch_size=BATCH_SIZE)\n",
        "  keras_model.compile(\n",
        "      loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "      metrics=[FlattenedCategoricalAccuracy()])\n",
        "  model_weights = fed_avg.get_model_weights(state)\n",
        "  model_weights.assign_weights_to(keras_model)\n",
        "  loss, accuracy = keras_model.evaluate(example_dataset, steps=2, verbose=0)\n",
        "  print('\\tEval: loss={l:.3f}, accuracy={a:.3f}'.format(l=loss, a=accuracy))\n",
        "\n",
        "\n",
        "for round_num in range(NUM_ROUNDS):\n",
        "  print('Round {r}'.format(r=round_num))\n",
        "  keras_evaluate(state, round_num)\n",
        "  result = fed_avg.next(state, train_datasets)\n",
        "  state = result.state\n",
        "  train_metrics = result.metrics['client_work']['train']\n",
        "  print('\\tTrain: loss={l:.3f}, accuracy={a:.3f}'.format(\n",
        "      l=train_metrics['loss'], a=train_metrics['accuracy']))\n",
        "\n",
        "print('Final evaluation')\n",
        "keras_evaluate(state, NUM_ROUNDS + 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SoshvcHhXVa6"
      },
      "source": [
        "Com as alterações padrão, não fizemos treinamento suficiente para que a diferença fosse grande, mas, se você treinar por mais tempo e com mais dados de Shakespeare, deverá ver uma diferença no estilo do texto gerado ao usar o modelo atualizado:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NTUig7QmXavy"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "What of TensorFlow Federated, you ask? She will be\r\n",
            "heard of; or whether they recovered her faltering place, that a great mark of\r\n",
            "being so final dark and distrustner the dearer to the chin, all\r\n",
            "staftly towards him, or trot's in foot thro\n"
          ]
        }
      ],
      "source": [
        "# Set our newly trained weights back in the originally created model.\n",
        "keras_model_batch1.set_weights([v.numpy() for v in keras_model.weights])\n",
        "# Text generation requires batch_size=1\n",
        "print(generate_text(keras_model_batch1, 'What of TensorFlow Federated, you ask? '))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DA1Fkf5mN0s"
      },
      "source": [
        "## Extensões sugeridas\n",
        "\n",
        "Este tutorial é apenas o primeiro passo! Veja algumas ideias para estender este notebook:\n",
        "\n",
        "- Escreva um loop de treinamento mais realista, em que você amostre clientes para fazer o treinamento aleatoriamente.\n",
        "- Use \"`.repeat(NUM_EPOCHS)`\" nos datasets clientes para tentar diversas épocas de treinamento local (como em [McMahan et. al.](https://arxiv.org/abs/1602.05629)). Confira [Aprendizado federado para classificação de imagens](federated_learning_for_image_classification.ipynb), que faz isso.\n",
        "- Altere o comando `compile()` para fazer experimentos usando diferentes algoritmos de otimização em cada cliente.\n",
        "- Experimente o argumento `server_optimizer` em `build_weighted_fed_avg` para tentar diferentes algoritmos para aplicar as atualizações do modelo no servidor."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "federated_learning_for_text_generation.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
