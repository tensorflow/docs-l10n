{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djUvWu41mtXa"
      },
      "source": [
        "##### Copyright 2019 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "su2RaORHpReL"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NztQK2uFpXT-"
      },
      "source": [
        "# Escalares do TensorBoard: registro de métricas de treinamento no Keras\n",
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>     <a target=\"_blank\" href=\"https://www.tensorflow.org/tensorboard/scalars_and_keras\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver em TensorFlow.org</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/pt-br/tensorboard/scalars_and_keras.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Executar no Google Colab</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/pt-br/tensorboard/scalars_and_keras.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver fonte no GitHub</a>\n",
        "</td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDXRFe_qp5C3"
      },
      "source": [
        "## Visão geral\n",
        "\n",
        "O aprendizado de máquina sempre envolve a compreensão sobre métricas fundamentais, como a perda, e como elas mudam ao longo do treinamento. Essas métricas podem ajudar você a entender, por exemplo, se está com [overfitting](https://en.wikipedia.org/wiki/Overfitting) ou treinando desnecessariamente por muito tempo. Você deve comparar essas métricas em diferentes execuções de treinamento para depurar e melhorar seu modelo.\n",
        "\n",
        "O **Painel de Controle Time Series** (Série temporal) permite que você visualize essas métricas usando uma API simples com muito pouco esforço. Este tutorial apresenta exemplos bastante básicos para você aprender a usar essas APIs com o TensorBoard ao desenvolver seu modelo do Keras. Você aprenderá a usar a callback do TensorBoard para o Keras e as APIs Summary do TensorFlow para visualizar escalares padrão e personalizados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dG-nnZK9qW9z"
      },
      "source": [
        "## Configuração"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3U5gdCw_nSG3"
      },
      "outputs": [],
      "source": [
        "# Load the TensorBoard notebook extension.\n",
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1qIKtOBrqc9Y"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TensorFlow version:  2.8.2\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "from packaging import version\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "print(\"TensorFlow version: \", tf.__version__)\n",
        "assert version.parse(tf.__version__).release[0] >= 2, \\\n",
        "    \"This notebook requires TensorFlow 2.0 or above.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UbFM4dlnGB3S"
      },
      "outputs": [],
      "source": [
        "# Clear any logs from previous runs\n",
        "!rm -rf ./logs/ "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YDAoNCN3ZNS"
      },
      "source": [
        "## Configure os dados para uma regressão simples\n",
        "\n",
        "Agora, você usará o [Keras](https://www.tensorflow.org/guide/keras) para calcular uma regressão, ou seja, encontrar a linha mais adequada para um dataset emparelhado. (Enquanto o uso das redes neurais e do método do gradiente descendente é [excessivo para esse tipo de problema](https://stats.stackexchange.com/questions/160179/do-we-need-gradient-descent-to-find-the-coefficients-of-a-linear-regression-mode), é um exemplo de fácil compreensão.)\n",
        "\n",
        "Você usará o TensorBoard para observar como a **perda** do treinamento e do teste muda nas épocas. Com sorte, você verá a perda do treinamento e do teste diminuir ao longo do tempo e depois permanecer estável.\n",
        "\n",
        "Primeiro, gere 1000 pontos de dados perto da linha *y = 0.5x + 2*. Divida esses pontos de dados em datasets de treinamento e teste. Sua esperança é que a rede neural aprenda essa relação."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j-ryO6OxnQH_"
      },
      "outputs": [],
      "source": [
        "data_size = 1000\n",
        "# 80% of the data is for training.\n",
        "train_pct = 0.8\n",
        "\n",
        "train_size = int(data_size * train_pct)\n",
        "\n",
        "# Create some input data between -1 and 1 and randomize it.\n",
        "x = np.linspace(-1, 1, data_size)\n",
        "np.random.shuffle(x)\n",
        "\n",
        "# Generate the output data.\n",
        "# y = 0.5x + 2 + noise\n",
        "y = 0.5 * x + 2 + np.random.normal(0, 0.05, (data_size, ))\n",
        "\n",
        "# Split into test and train pairs.\n",
        "x_train, y_train = x[:train_size], y[:train_size]\n",
        "x_test, y_test = x[train_size:], y[train_size:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Je59_8Ts3rq0"
      },
      "source": [
        "## Treinamento do modelo e registro da perda\n",
        "\n",
        "Agora, você está pronto para definir, treinar e avaliar seu modelo.\n",
        "\n",
        "Para registrar o escalar de *perda* ao treinar, faça o seguinte:\n",
        "\n",
        "1. Crie a [callback do TensorBoard](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/TensorBoard) para o Keras\n",
        "2. Especifique um diretório de log\n",
        "3. Passe a callback do TensorBoard ao [Model.fit()](https://www.tensorflow.org/api_docs/python/tf/keras/models/Model#fit) do Keras.\n",
        "\n",
        "O TensorBoard lê os dados de log na hierarquia de diretório de logs. Nesse notebook, o diretório de log raiz é `logs/scalars`, com um subdiretório que inclui carimbo de data/hora como sufixo. Esse subdiretório permite identificar e selecionar execuções de treinamento conforme você usa o TensorBoard e itera seu modelo. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VmEQwCon3i7m"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training ... With default parameters, this takes less than 10 seconds.\n",
            "Average test loss:  0.042797307365108284\n"
          ]
        }
      ],
      "source": [
        "logdir = \"logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Dense(16, input_dim=1),\n",
        "    keras.layers.Dense(1),\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    loss='mse', # keras.losses.mean_squared_error\n",
        "    optimizer=keras.optimizers.SGD(learning_rate=0.2),\n",
        ")\n",
        "\n",
        "print(\"Training ... With default parameters, this takes less than 10 seconds.\")\n",
        "training_history = model.fit(\n",
        "    x_train, # input\n",
        "    y_train, # output\n",
        "    batch_size=train_size,\n",
        "    verbose=0, # Suppress chatty output; use Tensorboard instead\n",
        "    epochs=100,\n",
        "    validation_data=(x_test, y_test),\n",
        "    callbacks=[tensorboard_callback],\n",
        ")\n",
        "\n",
        "print(\"Average test loss: \", np.average(training_history.history['loss']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "042k7GMERVkx"
      },
      "source": [
        "## Análise da perda usando o TensorBoard\n",
        "\n",
        "Agora, inicialize o TensorBoard, especificando o diretório de log raiz que você usou acima.\n",
        "\n",
        "Aguarde alguns segundos para a interface do usuário do TensorBoard inicializar. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6pck56gKReON"
      },
      "outputs": [],
      "source": [
        "%tensorboard --logdir logs/scalars"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmQHlG10Kpu2"
      },
      "source": [
        "<!-- <img class=\"tfo-display-only-on-site\" src=\"https://github.com/tensorflow/tensorboard/blob/master/docs/images/scalars_loss.png?raw=1\"/> -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ciSIRibhRi6N"
      },
      "source": [
        "Talvez você veja a mensagem \"No dashboards are active for the current data set\" (Nenhum painel de controle ativo para o dataset atual) no TensorBoard. Isso ocorre porque o registro de dados inicial ainda não foi salvo. Com o avanço do treinamento, o modelo Keras começará a registrar os dados. O TensorBoard atualizará periodicamente e mostrará suas métricas escalares. Se você estiver impaciente, toque na seta \"Refresh\" (Atualizar) no canto superior direito.\n",
        "\n",
        "Ao observar o avanço do treinamento, note que ambas as perdas de treinamento e de validação diminuem rapidamente e depois permanecem estáveis. Na verdade, você poderia ter parado o treinamento após 25 épocas, porque ele não melhorou muito depois desse ponto.\n",
        "\n",
        "Passe o cursor sobre o grafo para ver pontos de dados específicos. Você também pode tentar aumentar o zoom com o mouse ou selecionar parte deles para ver mais detalhes.\n",
        "\n",
        "Observe o seletor \"Runs\" à esquerda. Uma \"run\", ou execução, representa um conjunto de logs de uma rodada de treinamento, nesse caso, o resultado de Model.fit(). Os desenvolvedores geralmente realizam muitas e muitas execuções, enquanto testam e desenvolvem o modelo ao longo do tempo.\n",
        "\n",
        "Use o seletor \"Runs\" para escolher execuções específicas ou somente de treinamento/validação. A comparação de execuções ajudará você a avaliar qual versão do seu código soluciona melhor seu problema.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "finK0GfYyefe"
      },
      "source": [
        "O grafo de perda do TensorBoard demonstra que a perda diminuiu consistentemente para ambos o treinamento e a validação e depois estabilizou. Isso significa que as métricas do modelo são provavelmente muito boas! Agora veja como o modelo realmente se comporta na vida real.\n",
        "\n",
        "Com os dados de entrada (60, 25, 2), a linha *y = 0.5x + 2* deve gerar (32, 14.5, 3). O modelo está de acordo?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EuiLgxQstt32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[32.148884 ]\n",
            " [14.562463 ]\n",
            " [ 3.0056725]]\n"
          ]
        }
      ],
      "source": [
        "print(model.predict([60, 25, 2]))\n",
        "# True values to compare predictions against: \n",
        "# [[32.0]\n",
        "#  [14.5]\n",
        "#  [ 3.0]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bom4MdeewRKS"
      },
      "source": [
        "Nada mal!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvwGmJK9XWmh"
      },
      "source": [
        "## Registro de escalares personalizados\n",
        "\n",
        "E se você quiser registrar valores personalizados, como uma [taxa de aprendizado dinâmica](https://www.jeremyjordan.me/nn-learning-rate/)? Para fazer isso, você precisa usar a API Summary do TensorFlow.\n",
        "\n",
        "Treine novamente o modelo de regressão e registre uma taxa de aprendizado personalizada. Veja como:\n",
        "\n",
        "1. Crie um escritor de arquivo, usando `tf.summary.create_file_writer()`.\n",
        "2. Defina uma função de taxa de aprendizado personalizada. Ela será passada à callback [LearningRateScheduler](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/LearningRateScheduler) do Keras.\n",
        "3. Dentro da função de taxa de aprendizado, use `tf.summary.scalar()` para registrar a taxa de aprendizado personalizada.\n",
        "4. Passe a callback LearningRateScheduler a Model.fit().\n",
        "\n",
        "Em geral, para registrar um escalar personalizado, você precisa usar `tf.summary.scalar()` com um escritor de arquivo. O escritor de arquivo é responsável por escrever os dados para essa execução no diretório especificado e é usado de maneira implícita ao utilizar o `tf.summary.scalar()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XB95ltRiXVXk"
      },
      "outputs": [],
      "source": [
        "logdir = \"logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "file_writer = tf.summary.create_file_writer(logdir + \"/metrics\")\n",
        "file_writer.set_as_default()\n",
        "\n",
        "def lr_schedule(epoch):\n",
        "  \"\"\"\n",
        "  Returns a custom learning rate that decreases as epochs progress.\n",
        "  \"\"\"\n",
        "  learning_rate = 0.2\n",
        "  if epoch > 10:\n",
        "    learning_rate = 0.02\n",
        "  if epoch > 20:\n",
        "    learning_rate = 0.01\n",
        "  if epoch > 50:\n",
        "    learning_rate = 0.005\n",
        "\n",
        "  tf.summary.scalar('learning rate', data=learning_rate, step=epoch)\n",
        "  return learning_rate\n",
        "\n",
        "lr_callback = keras.callbacks.LearningRateScheduler(lr_schedule)\n",
        "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Dense(16, input_dim=1),\n",
        "    keras.layers.Dense(1),\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    loss='mse', # keras.losses.mean_squared_error\n",
        "    optimizer=keras.optimizers.SGD(),\n",
        ")\n",
        "\n",
        "training_history = model.fit(\n",
        "    x_train, # input\n",
        "    y_train, # output\n",
        "    batch_size=train_size,\n",
        "    verbose=0, # Suppress chatty output; use Tensorboard instead\n",
        "    epochs=100,\n",
        "    validation_data=(x_test, y_test),\n",
        "    callbacks=[tensorboard_callback, lr_callback],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pck8OQEjayDM"
      },
      "source": [
        "Vamos conferir o TensorBoard novamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0sjM2wXGa0mF"
      },
      "outputs": [],
      "source": [
        "%tensorboard --logdir logs/scalars"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkIahGZKK9I7"
      },
      "source": [
        "<!-- <img class=\"tfo-display-only-on-site\" src=\"https://github.com/tensorflow/tensorboard/blob/master/docs/images/scalars_custom_lr.png?raw=1\"/> -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRlUDnhlkN_q"
      },
      "source": [
        "Usando o seletor \"Runs\" à esquerda, observe que você tem uma execução `<timestamp>/metrics`. Ao selecionar essa execução, aparece um grafo \"taxa de aprendizado\" que permite verificar a progressão da taxa de aprendizado durante a execução.\n",
        "\n",
        "Você também pode comparar as curvas de perda de treinamento e validação dessa execução com as execuções anteriores. Além disso, talvez você perceba que o cronograma da taxa de aprendizado retornou valores discretos, dependendo da época, mas a plotagem da taxa de aprendizado parece suave. O TensorBoard tem um parâmetro de suavização que você pode precisar definir como zero para ver valores não suavizados.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0TTI16Nl0nk"
      },
      "source": [
        "Como é o desempenho desse modelo?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "97T4vT3QkQJH"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[31.958094 ]\n",
            " [14.482997 ]\n",
            " [ 2.9993598]]\n"
          ]
        }
      ],
      "source": [
        "print(model.predict([60, 25, 2]))\n",
        "# True values to compare predictions against: \n",
        "# [[32.0]\n",
        "#  [14.5]\n",
        "#  [ 3.0]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxAVfW8lhZ0e"
      },
      "source": [
        "## Registro no nível do lote\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-ltiSuypLVE"
      },
      "source": [
        "Primeiro, vamos carregar o dataset MNIST, normalizar os dados e escrever uma função que cria um modelo simples do Keras para classificar imagens em 10 classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N2kbowJTpJWJ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "def create_model():\n",
        "  return tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "  ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68pV5ZRe1iZ7"
      },
      "source": [
        "### Registro instantâneo no nível do lote"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_QYrBgkTsLH"
      },
      "source": [
        "O registro instantâneo de métricas no nível do lote pode nos mostrar o nível de oscilação entre lotes ao treinar cada época, o que pode ser útil para depuração."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hXsbsXDqgvA"
      },
      "source": [
        "Configure um escritor de resumo para um diretório de log diferente:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7OTD7Vpg2DLv"
      },
      "outputs": [],
      "source": [
        "log_dir = 'logs/batch_level/' + datetime.now().strftime(\"%Y%m%d-%H%M%S\") + '/train'\n",
        "train_writer = tf.summary.create_file_writer(log_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YlVZY2VqrK9D"
      },
      "source": [
        "Para ativar o registro no nível do lote, métricas `tf.summary` personalizadas devem ser definidas ao sobrepor `train_step()` na definição de classe do modelo e envolvidas em um contexto de escritor de resumo. Isso pode ser simplesmente combinado nas definições de modelo de subclasse ou ampliado para editar o modelo de API funcional anterior, conforme mostrado abaixo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IGcNr1ZS1xXL"
      },
      "outputs": [],
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self, model):\n",
        "    super().__init__()\n",
        "    self.model = model\n",
        "  \n",
        "  def train_step(self, data):\n",
        "    x, y = data\n",
        "    with tf.GradientTape() as tape:\n",
        "      y_pred = self.model(x, training=True)\n",
        "      loss = self.compiled_loss(y, y_pred)\n",
        "      mse = tf.keras.losses.mean_squared_error(y, K.max(y_pred, axis=-1))\n",
        "    self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n",
        "    with train_writer.as_default(step=self._train_counter):\n",
        "      tf.summary.scalar('batch_loss', loss)\n",
        "      tf.summary.scalar('batch_mse', mse)\n",
        "    return self.compute_metrics(x, y, y_pred, None)\n",
        "  \n",
        "  def call(self, x):\n",
        "    x = self.model(x)\n",
        "    return x\n",
        "\n",
        "# Adds custom batch-level metrics to our previous Functional API model\n",
        "model = MyModel(create_model())\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wqqNaXP2bLc"
      },
      "source": [
        "Defina a callback do TensorBoard para registrar métricas no nível da época e do lote no diretório de log e chamar `model.fit()` com o `batch_size` selecionado: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YXK-iE0e2UOE"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "120/120 [==============================] - 5s 36ms/step - loss: 0.4379 - accuracy: 0.8788 - val_loss: 0.2041 - val_accuracy: 0.9430\n",
            "Epoch 2/5\n",
            "120/120 [==============================] - 4s 31ms/step - loss: 0.1875 - accuracy: 0.9471 - val_loss: 0.1462 - val_accuracy: 0.9591\n",
            "Epoch 3/5\n",
            "120/120 [==============================] - 3s 27ms/step - loss: 0.1355 - accuracy: 0.9613 - val_loss: 0.1170 - val_accuracy: 0.9670\n",
            "Epoch 4/5\n",
            "120/120 [==============================] - 3s 27ms/step - loss: 0.1058 - accuracy: 0.9694 - val_loss: 0.0954 - val_accuracy: 0.9723\n",
            "Epoch 5/5\n",
            "120/120 [==============================] - 3s 27ms/step - loss: 0.0872 - accuracy: 0.9752 - val_loss: 0.0843 - val_accuracy: 0.9749\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fce165a2fd0>"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir)\n",
        "\n",
        "model.fit(x=x_train, \n",
        "          y=y_train,\n",
        "          epochs=5,\n",
        "          batch_size=500, \n",
        "          validation_data=(x_test, y_test), \n",
        "          callbacks=[tensorboard_callback])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsxwF83h2kiM"
      },
      "source": [
        "Abra o TensorBoard com o novo diretório de log e veja ambas as métricas no nível da época e do lote:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XlcafPNY2oUW"
      },
      "outputs": [],
      "source": [
        "%tensorboard --logdir logs/batch_level"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ReO1LD-g2vgk"
      },
      "source": [
        "### Registro cumulativo no nível do lote"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0eE_yjt45TN"
      },
      "source": [
        "O registro no nível do lote também pode ser implementado de maneira cumulativa, calculando a média das métricas de cada lote com a de lotes anteriores e resultando em uma curva de treinamento mais suave ao registrar métricas no nível do lote."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "He88QGuu25Vm"
      },
      "source": [
        "Configure um escritor de resumo para um diretório de log diferente:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hX3nsdqi28W1"
      },
      "outputs": [],
      "source": [
        "log_dir = 'logs/batch_avg/' + datetime.now().strftime(\"%Y%m%d-%H%M%S\") + '/train'\n",
        "train_writer = tf.summary.create_file_writer(log_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHcpdSR6q5MY"
      },
      "source": [
        "Crie métricas stateful que podem ser registradas por lote:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0cAiVu_KjOVi"
      },
      "outputs": [],
      "source": [
        "batch_loss = tf.keras.metrics.Mean('batch_loss', dtype=tf.float32)\n",
        "batch_accuracy = tf.keras.metrics.SparseCategoricalAccuracy('batch_accuracy')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8ESFevo3Vjz"
      },
      "source": [
        "Como antes, adicione métricas `tf.summary` personalizadas no método `train_step` sobreposto. Para tornar o registro no nível do lote cumulativo, use as métricas stateful que definimos para calcular o resultado cumulativo a partir dos dados de cada passo do treinamento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vQ_-46fpjUVl"
      },
      "outputs": [],
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self, model):\n",
        "    super().__init__()\n",
        "    self.model = model\n",
        "  \n",
        "  def train_step(self, data):\n",
        "    x, y = data\n",
        "    with tf.GradientTape() as tape:\n",
        "      y_pred = self.model(x, training=True)\n",
        "      loss = self.compiled_loss(y, y_pred)\n",
        "    self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n",
        "    batch_loss(loss)\n",
        "    batch_accuracy(y, y_pred)\n",
        "    with train_writer.as_default(step=self._train_counter):\n",
        "      tf.summary.scalar('batch_loss', batch_loss.result())\n",
        "      tf.summary.scalar('batch_accuracy', batch_accuracy.result())\n",
        "    return self.compute_metrics(x, y, y_pred, None)\n",
        "  \n",
        "  def call(self, x):\n",
        "    x = self.model(x)\n",
        "    return x\n",
        "\n",
        "# Adds custom batch-level metrics to our previous Functional API model\n",
        "model = MyModel(create_model())\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NgtSX5E1uNhC"
      },
      "source": [
        "Como antes, defina nossa callback do TensorBoard e chame `model.fit()` com nosso `batch_size` selecionado: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SGWYCUFhjztg"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "120/120 [==============================] - 4s 27ms/step - loss: 0.4266 - accuracy: 0.8813 - val_loss: 0.2055 - val_accuracy: 0.9415\n",
            "Epoch 2/5\n",
            "120/120 [==============================] - 3s 26ms/step - loss: 0.1864 - accuracy: 0.9476 - val_loss: 0.1417 - val_accuracy: 0.9613\n",
            "Epoch 3/5\n",
            "120/120 [==============================] - 3s 27ms/step - loss: 0.1352 - accuracy: 0.9614 - val_loss: 0.1148 - val_accuracy: 0.9665\n",
            "Epoch 4/5\n",
            "120/120 [==============================] - 3s 26ms/step - loss: 0.1066 - accuracy: 0.9702 - val_loss: 0.0932 - val_accuracy: 0.9716\n",
            "Epoch 5/5\n",
            "120/120 [==============================] - 3s 27ms/step - loss: 0.0859 - accuracy: 0.9749 - val_loss: 0.0844 - val_accuracy: 0.9754\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fce15c39f50>"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir)\n",
        "\n",
        "model.fit(x=x_train, \n",
        "          y=y_train,\n",
        "          epochs=5,\n",
        "          batch_size=500, \n",
        "          validation_data=(x_test, y_test), \n",
        "          callbacks=[tensorboard_callback])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSoDvPoDvAci"
      },
      "source": [
        "Abra o TensorBoard com o novo diretório de log e veja ambas as métricas no nível da época e do lote:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kYmYfTeSk7AD"
      },
      "outputs": [],
      "source": [
        "%tensorboard --logdir logs/batch_avg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LXCePQi7_f50"
      },
      "source": [
        "É isso! Agora você sabe como criar métricas de treinamento personalizadas no TensorBoard para uma ampla variedade de casos de uso."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "scalars_and_keras.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
