{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tce3stUlHN0L"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow IO Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tuOe1ymfHZPu"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFdPvlXBOdUN"
      },
      "source": [
        "# API de dataset Avro"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfBg1C5NB3X0"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>     <a target=\"_blank\" href=\"https://www.tensorflow.org/io/tutorials/avro\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver em TensorFlow.org</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/pt-br/io/tutorials/avro.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Executar no Google Colab</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/pt-br/io/tutorials/avro.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver fonte no GitHub</a>\n",
        "</td>\n",
        "      <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/pt-br/io/tutorials/avro.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Baixar notebook</a>\n",
        "</td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHxb-dlhMIzW"
      },
      "source": [
        "## Visão geral\n",
        "\n",
        "O objetivo da API de dataset Avro é carregar dados formatados em Avro nativamente no TensorFlow como um <a target=\"_blank\" href=\"https://www.tensorflow.org/api_docs/python/tf/data/Dataset\">dataset do TensorFlow</a>. O Avro é um sistema de serialização de dados similar ao Protocol Buffers. Ele é amplamente usado no Apache Hadoop e pode fornecer tanto um formato de serialização para dados persistentes quanto um formato para transmissão via rede para comunicação entre os nós do Hadoop. Os dados do Avro ficam em um formato de dados binário, compactado e em linhas. Ele depende do esquema armazenado como um arquivo JSON separado. Confira a especificação do formato Avro e a declaração do esquema no <a target=\"_blank\" href=\"https://avro.apache.org/docs/current/spec.html\">manual oficial</a>.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUXex9ctTuDB"
      },
      "source": [
        "## Configure o pacote\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upgCc3gXybsA"
      },
      "source": [
        "### Instale o pacote tensorflow-io obrigatório"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uUDYyMZRfkX4"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow-io"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjrZNJQRJP-U"
      },
      "source": [
        "### Importe os pacotes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m6KXZuTBWgRm"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_io as tfio\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCgO11GTJaTj"
      },
      "source": [
        "### Valide as importações de tf e tfio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dX74RKfZ_TdF"
      },
      "outputs": [],
      "source": [
        "print(\"tensorflow-io version: {}\".format(tfio.__version__))\n",
        "print(\"tensorflow version: {}\".format(tf.__version__))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0ZKhA6s0Pjp"
      },
      "source": [
        "## Uso"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CfKVmCvwcL7"
      },
      "source": [
        "### Explore o dataset\n",
        "\n",
        "Para este tutorial, vamos baixar o dataset Avro de exemplo.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGnbXuVnSo8T"
      },
      "source": [
        "Baixe um arquivo Avro de amostra:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tu01THzWcE-J"
      },
      "outputs": [],
      "source": [
        "!curl -OL https://github.com/tensorflow/io/raw/master/docs/tutorials/avro/train.avro\n",
        "!ls -l train.avro"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJzE6lMwhY7l"
      },
      "source": [
        "Baixe o arquivo de esquema correspondente ao arquivo Avro de amostra:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cpxa6yhLhY7l"
      },
      "outputs": [],
      "source": [
        "!curl -OL https://github.com/tensorflow/io/raw/master/docs/tutorials/avro/train.avsc\n",
        "!ls -l train.avsc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9GCyPWNuOm7"
      },
      "source": [
        "No exemplo acima, um dataset Avro de teste foi criado com base no dataset MNIST. O dataset MNIST original no formato TFRecord é gerado a partir do <a target=\"_blank\" href=\"https://www.tensorflow.org/datasets/api_docs/python/tfds/load\">dataset nomeado do TF</a>. Porém, o dataset MNIST é grande demais para fins de demonstração. Por questões de simplicidade, a maior parte foi retirada, e somente os primeiros registros foram mantidos. Além disso, outra modificação foi feita para o campo `image` no dataset MNIST original, mapeado para o campo `features` (características) no Avro. Portanto, o arquivo Avro `train.avro` tem 4 registros, cada um com 3 campos: `features`, um array de int, `label` (rótulo), um int ou null, e `dataType` (tipo de dados), uma enumeração. Para ver o arquivo `train.avro` decodificado (Observação: <a target=\"_blank\" href=\"https://github.com/tensorflow/io/raw/master/docs/tutorials/avro/train.avro\">o arquivo de dados Avro original</a> não é legível por humanos, pois o Avro é um formato compactado):\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upgCc3gXybsB"
      },
      "source": [
        "Instale o pacote necessário para ler arquivos Avro:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nS3eTBvjt-O4"
      },
      "outputs": [],
      "source": [
        "!pip install avro\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7XR0agdhY7n"
      },
      "source": [
        "Para ler e exibir um arquivo Avro via print em um formato legível por humanos:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nS3eTBvjt-O5"
      },
      "outputs": [],
      "source": [
        "from avro.io import DatumReader\n",
        "from avro.datafile import DataFileReader\n",
        "\n",
        "import json\n",
        "\n",
        "def print_avro(avro_file, max_record_num=None):\n",
        "    if max_record_num is not None and max_record_num <= 0:\n",
        "        return\n",
        "\n",
        "    with open(avro_file, 'rb') as avro_handler:\n",
        "        reader = DataFileReader(avro_handler, DatumReader())\n",
        "        record_count = 0\n",
        "        for record in reader:\n",
        "            record_count = record_count+1\n",
        "            print(record)\n",
        "            if max_record_num is not None and record_count == max_record_num:\n",
        "               break\n",
        "\n",
        "print_avro(avro_file='train.avro')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKgUPm6JhY7n"
      },
      "source": [
        "E o esquema de `train.avro`, representado por `train.avsc`, é um arquivo em formato JSON. Para ver `train.avsc`:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D-95aom1hY7o"
      },
      "outputs": [],
      "source": [
        "def print_schema(avro_schema_file):\n",
        "    with open(avro_schema_file, 'r') as handle:\n",
        "        parsed = json.load(handle)\n",
        "    print(json.dumps(parsed, indent=4, sort_keys=True))\n",
        "\n",
        "print_schema('train.avsc')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21szKFY1hY7o"
      },
      "source": [
        "### Prepare o dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNeBO9m-hY7o"
      },
      "source": [
        "Carregue `train.avro` como dataset do TensorFlow usando a API de dataset Avro:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v-nbLZHKhY7o"
      },
      "outputs": [],
      "source": [
        "features = {\n",
        "    'features[*]': tfio.experimental.columnar.VarLenFeatureWithRank(dtype=tf.int32),\n",
        "    'label': tf.io.FixedLenFeature(shape=[], dtype=tf.int32, default_value=-100),\n",
        "    'dataType': tf.io.FixedLenFeature(shape=[], dtype=tf.string)\n",
        "}\n",
        "\n",
        "schema = tf.io.gfile.GFile('train.avsc').read()\n",
        "\n",
        "dataset = tfio.experimental.columnar.make_avro_record_dataset(file_pattern=['train.avro'],\n",
        "                                                              reader_schema=schema,\n",
        "                                                              features=features,\n",
        "                                                              shuffle=False,\n",
        "                                                              batch_size=3,\n",
        "                                                              num_epochs=1)\n",
        "\n",
        "for record in dataset:\n",
        "    print(record['features[*]'])\n",
        "    print(record['label'])\n",
        "    print(record['dataType'])\n",
        "    print(\"--------------------\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IF_kYz_o2DH4"
      },
      "source": [
        "O exemplo acima converte `train.avro` em um dataset do TensorFlow. Cada elemento do dataset é um dicionário cuja chave é o nome da característica, e o valor é o tensor esparso ou denso convertido. Por exemplo, ele converte o campo `features`, `label`, `dataType` em um VarLenFeature(SparseTensor), FixedLenFeature(DenseTensor)e FixedLenFeature(DenseTensor), respectivamente. Como batch_size é 3, ele transforma 3 registros de `train.avro` em um elemento no dataset resultante. Para o primeiro registro em `train.avro`, cujo rótulo é null, o leitor do Avro o substitui pelo value(-100) especificado padrão. Neste exemplo, há 4 registros no total em `train.avro`. Como o tamanho do lote é 3, o dataset resultante contém 3 elementos, sendo que o tamanho de lote do último elemento é 1. Entretanto, se o usuário quiser descartar o último lote caso o tamanho seja menor do que o tamanho do lote, basta ativar `drop_final_batch`. Por exemplo:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bc9vDHyghY7p"
      },
      "outputs": [],
      "source": [
        "dataset = tfio.experimental.columnar.make_avro_record_dataset(file_pattern=['train.avro'],\n",
        "                                                              reader_schema=schema,\n",
        "                                                              features=features,\n",
        "                                                              shuffle=False,\n",
        "                                                              batch_size=3,\n",
        "                                                              drop_final_batch=True,\n",
        "                                                              num_epochs=1)\n",
        "\n",
        "for record in dataset:\n",
        "    print(record)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x45KolnDhY7p"
      },
      "source": [
        "Também é possível aumentar num_parallel_reads (número de leituras paralelas) para acelerar o processamento de dados do Avro por meio do aumento de paralelismo de processamento/leitura.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z2x-gPj_hY7p"
      },
      "outputs": [],
      "source": [
        "dataset = tfio.experimental.columnar.make_avro_record_dataset(file_pattern=['train.avro'],\n",
        "                                                              reader_schema=schema,\n",
        "                                                              features=features,\n",
        "                                                              shuffle=False,\n",
        "                                                              num_parallel_reads=16,\n",
        "                                                              batch_size=3,\n",
        "                                                              drop_final_batch=True,\n",
        "                                                              num_epochs=1)\n",
        "\n",
        "for record in dataset:\n",
        "    print(record)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6V-nwDJGhY7p"
      },
      "source": [
        "Confira o uso detalhado de `make_avro_record_dataset` na <a target=\"_blank\" href=\"https://www.tensorflow.org/io/api_docs/python/tfio/experimental/columnar/make_avro_record_dataset\">documentação da API</a>.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIOijGlAhY7p"
      },
      "source": [
        "### Treine modelos do tf.keras com o dataset Avro\n",
        "\n",
        "Agora, vamos conferir um exemplo completo de treinamento de modelos do tf.keras com o dataset Avro baseado no dataset MNIST.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7K85D53hY7q"
      },
      "source": [
        "Carregue `train.avro` como dataset do TensorFlow usando a API de dataset Avro:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VFoeLwIOhY7q"
      },
      "outputs": [],
      "source": [
        "features = {\n",
        "    'features[*]': tfio.experimental.columnar.VarLenFeatureWithRank(dtype=tf.int32),\n",
        "    'label': tf.io.FixedLenFeature(shape=[], dtype=tf.int32, default_value=-100),\n",
        "}\n",
        "\n",
        "\n",
        "schema = tf.io.gfile.GFile('train.avsc').read()\n",
        "\n",
        "dataset = tfio.experimental.columnar.make_avro_record_dataset(file_pattern=['train.avro'],\n",
        "                                                              reader_schema=schema,\n",
        "                                                              features=features,\n",
        "                                                              shuffle=False,\n",
        "                                                              batch_size=1,\n",
        "                                                              num_epochs=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hR2FnIIMhY7q"
      },
      "source": [
        "Defina um modelo simples do Keras:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hGV5rHfJhY7q"
      },
      "outputs": [],
      "source": [
        "def build_and_compile_cnn_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.compile(optimizer='sgd', loss='mse')\n",
        "    return model\n",
        "\n",
        "model = build_and_compile_cnn_model()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tuv9n6HshY7q"
      },
      "source": [
        "### Treine o modelo do Keras com o dataset Avro:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lb44cUuWhY7r"
      },
      "outputs": [],
      "source": [
        "def extract_label(feature):\n",
        "  label = feature.pop('label')\n",
        "  return tf.sparse.to_dense(feature['features[*]']), label\n",
        "\n",
        "model.fit(x=dataset.map(extract_label), epochs=1, steps_per_epoch=1, verbose=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7K6qAv5rhY7r"
      },
      "source": [
        "O dataset Avro pode processar e transformar qualquer dado Avro em tensores do TensorFlow, incluindo registros em registros, mapas, arrays, ramificações e enumerações. As informações processadas são passadas para a implementação do dataset Avro como um mapa, em que as chaves codificam como processar os valores de dados e codificam como transformar os dados em tensores do TensorFlow, decidindo o tipo primitivo (por exemplo, bool, int, long, float, double, string) bem como o tipo de tensor (por exemplo, esparso ou denso). É fornecida uma lista de todos os parsers do TensorFlow (veja a tabela 1) e a transformação de tipos primitivos (veja a tabela 2).\n",
        "\n",
        "Tabela 1 – Tipos de parser do TensorFlow disponíveis\n",
        "\n",
        "Tipos de parser do TensorFlow | Tensores do TensorFlow | Explicação\n",
        "--- | --- | ---\n",
        "tf.FixedLenFeature([], tf.int32) | tensor denso | Processa uma característica de comprimento fixo, ou seja, todas as linhas têm o mesmo número constante de elementos. Por exemplo: somente um elemento ou um array que sempre tem o mesmo número de elementos para cada linha\n",
        "tf.SparseFeature(index_key=['key_1st_index', 'key_2nd_index'], value_key='key_value', dtype=tf.int64, size=[20, 50]) | tensor esparso | Processa uma característica esparsa, em que cada linha tem uma lista de comprimento variável composta por índices e valores. 'index_key' identifica os índices; 'value_key' identifica o valor; 'dtype' é o tipo de dado; 'size' é o valor de índice máximo esperado para cada entrada de índice\n",
        "tfio.experimental.columnar.VarLenFeatureWithRank([],tf.int64) | tensor esparso | Processa uma característica de comprimento variável, ou seja, cada linha de dados pode ter um número variável de elementos. Por exemplo: a linha 1 tem 5 elementos, e a linha 2 tem 7 elementos\n",
        "\n",
        "Table 2 – Conversões de tipos Avro em tipos do TensorFlow permitidas:\n",
        "\n",
        "Tipo primitivo Avro | Tipo primitivo TensorFlow\n",
        "--- | ---\n",
        "boolean: valor binário | tf.bool\n",
        "bytes: sequência de bytes de 8 bits sem sinal | tf.string\n",
        "double: número de ponto flutuante IEEE com precisão dupla de 64 bits | tf.float64\n",
        "enum: tipo enumeração | tf.string usando o mesmo nome de símbolo\n",
        "float: número de ponto flutuante IEEE com precisão simples de 32 bits | tf.float32\n",
        "int: inteiro de 32 bits com sinal | tf.int32\n",
        "long: inteiro de 64 bits com sinal | tf.int64\n",
        "null: sem valor | usa o valor padrão\n",
        "string: sequência de caracteres Unicode | tf.string\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PFQPuy5hY7r"
      },
      "source": [
        "Veja um conjunto abrangente de exemplos da API de dataset Avro <a target=\"_blank\" href=\"https://github.com/tensorflow/io/blob/master/tests/test_parse_avro.py#L437\">nos testes</a>.\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "Tce3stUlHN0L"
      ],
      "name": "avro.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
