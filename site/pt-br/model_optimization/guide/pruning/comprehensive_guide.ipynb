{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tce3stUlHN0L"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "IcfrhafzkZbH"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFdPvlXBOdUN"
      },
      "source": [
        "# Guia completo de pruning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfBg1C5NB3X0"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>     <a target=\"_blank\" href=\"https://www.tensorflow.org/model_optimization/guide/pruning/comprehensive_guide\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver em TensorFlow.org</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/pt-br/model_optimization/guide/pruning/comprehensive_guide.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Executar no Google Colab</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/pt-br/model_optimization/guide/pruning/comprehensive_guide.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver fonte no GitHub</a>\n",
        "</td>\n",
        "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/pt-br/model_optimization/guide/pruning/comprehensive_guide.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Baixar notebook</a>\n",
        "</td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbORZA_bQx1G"
      },
      "source": [
        "Bem-vindo ao guia completo sobre pruning de peso do Keras.\n",
        "\n",
        "Esta página documenta vários casos de uso e mostra como usar a API para cada um. Depois de saber quais APIs são necessárias, encontre os parâmetros e os detalhes de nível inferior na [documentação da API](https://www.tensorflow.org/model_optimization/api_docs/python/tfmot/sparsity).\n",
        "\n",
        "- Se quiser ver os benefícios do pruning e saber o que é compatível, confira a [visão geral](https://www.tensorflow.org/model_optimization/guide/pruning).\n",
        "- Para um único exemplo completo, veja o [exemplo de pruning](https://www.tensorflow.org/model_optimization/guide/pruning/pruning_with_keras).\n",
        "\n",
        "São abordados os seguintes casos de uso:\n",
        "\n",
        "- Defina e treine um modelo após o pruning.\n",
        "    - Sequencial e funcional.\n",
        "    - Model.fit do Keras e loops de treinamento personalizados.\n",
        "- Faça o checkpoint e desserialize um modelo podado.\n",
        "- Implante um modelo podado e veja os benefícios da compressão.\n",
        "\n",
        "Para a configuração do algoritmo de pruning, consulte a documentação da API `tfmot.sparsity.keras.prune_low_magnitude`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nuABqZnXVDvO"
      },
      "source": [
        "## Configuração"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9mRDekZEfnR"
      },
      "source": [
        "Para encontrar as APIs de que você precisa e para fins de compreensão, você pode executar mas pular a leitura desta seção."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "both",
        "id": "lvpH1Hg7ULFz"
      },
      "outputs": [],
      "source": [
        "! pip install -q tensorflow-model-optimization\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import tensorflow_model_optimization as tfmot\n",
        "\n",
        "%load_ext tensorboard\n",
        "\n",
        "import tempfile\n",
        "\n",
        "input_shape = [20]\n",
        "x_train = np.random.randn(1, 20).astype(np.float32)\n",
        "y_train = tf.keras.utils.to_categorical(np.random.randn(1), num_classes=20)\n",
        "\n",
        "def setup_model():\n",
        "  model = tf.keras.Sequential([\n",
        "      tf.keras.layers.Dense(20, input_shape=input_shape),\n",
        "      tf.keras.layers.Flatten()\n",
        "  ])\n",
        "  return model\n",
        "\n",
        "def setup_pretrained_weights():\n",
        "  model = setup_model()\n",
        "\n",
        "  model.compile(\n",
        "      loss=tf.keras.losses.categorical_crossentropy,\n",
        "      optimizer='adam',\n",
        "      metrics=['accuracy']\n",
        "  )\n",
        "\n",
        "  model.fit(x_train, y_train)\n",
        "\n",
        "  _, pretrained_weights = tempfile.mkstemp('.tf')\n",
        "\n",
        "  model.save_weights(pretrained_weights)\n",
        "\n",
        "  return pretrained_weights\n",
        "\n",
        "def get_gzipped_model_size(model):\n",
        "  # Returns size of gzipped model, in bytes.\n",
        "  import os\n",
        "  import zipfile\n",
        "\n",
        "  _, keras_file = tempfile.mkstemp('.h5')\n",
        "  model.save(keras_file, include_optimizer=False)\n",
        "\n",
        "  _, zipped_file = tempfile.mkstemp('.zip')\n",
        "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
        "    f.write(keras_file)\n",
        "\n",
        "  return os.path.getsize(zipped_file)\n",
        "\n",
        "setup_model()\n",
        "pretrained_weights = setup_pretrained_weights()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZyLYFTER4aP"
      },
      "source": [
        "## Defina o modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ybigft1fTn4T"
      },
      "source": [
        "### Faça o pruning do modelo inteiro (sequencial e funcional)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "puZvqnp1xsn-"
      },
      "source": [
        "**Dicas para melhor exatidão do modelo:**\n",
        "\n",
        "- Tente \"podar algumas camadas\" para pular o pruning das camadas que mais reduzem a exatidão.\n",
        "- Geralmente, é melhor fazer ajustes com o pruning, em vez de treinar do zero.\n",
        "\n",
        "Para fazer o modelo inteiro treinar com o pruning, aplique `tfmot.sparsity.keras.prune_low_magnitude` a ele.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aIn-hFO_T_PU"
      },
      "outputs": [],
      "source": [
        "base_model = setup_model()\n",
        "base_model.load_weights(pretrained_weights) # optional but recommended.\n",
        "\n",
        "model_for_pruning = tfmot.sparsity.keras.prune_low_magnitude(base_model)\n",
        "\n",
        "model_for_pruning.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTbTLn3dZM7h"
      },
      "source": [
        "### Faça o pruning de algumas camadas (sequencial e funcional)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbM8o832xTxV"
      },
      "source": [
        "O pruning de um modelo pode ter um efeito negativo na exatidão. Você pode fazer o pruning de camadas selecionadas de um modelo para explorar o trade-off entre exatidão, velocidade e tamanho do modelo.\n",
        "\n",
        "**Dicas para melhor exatidão do modelo:**\n",
        "\n",
        "- Geralmente, é melhor fazer ajustes com o pruning, em vez de treinar do zero.\n",
        "- Tente fazer o pruning das camadas finais, em vez das iniciais.\n",
        "- Evite o pruning de camadas críticas (por exemplo, mecanismo de atenção).\n",
        "\n",
        "**Mais**:\n",
        "\n",
        "- A documentação da API `tfmot.sparsity.keras.prune_low_magnitude` fornece detalhes sobre como variar a configuração do pruning por camada.\n",
        "\n",
        "No exemplo abaixo, faça o pruning apenas das camadas `Dense`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HN0B_QB-ZhE2"
      },
      "outputs": [],
      "source": [
        "# Create a base model\n",
        "base_model = setup_model()\n",
        "base_model.load_weights(pretrained_weights) # optional but recommended for model accuracy\n",
        "\n",
        "# Helper function uses `prune_low_magnitude` to make only the \n",
        "# Dense layers train with pruning.\n",
        "def apply_pruning_to_dense(layer):\n",
        "  if isinstance(layer, tf.keras.layers.Dense):\n",
        "    return tfmot.sparsity.keras.prune_low_magnitude(layer)\n",
        "  return layer\n",
        "\n",
        "# Use `tf.keras.models.clone_model` to apply `apply_pruning_to_dense` \n",
        "# to the layers of the model.\n",
        "model_for_pruning = tf.keras.models.clone_model(\n",
        "    base_model,\n",
        "    clone_function=apply_pruning_to_dense,\n",
        ")\n",
        "\n",
        "model_for_pruning.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HiA28PrrW11H"
      },
      "source": [
        "Enquanto esse exemplo usa o tipo de camada para decidir o que podar, a maneira mais fácil de fazer o pruning de uma camada específica é definir sua propriedade `name` e procurar esse nome na `clone_function`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CjY_JyB808Da"
      },
      "outputs": [],
      "source": [
        "print(base_model.layers[0].name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpb_BydRaSoF"
      },
      "source": [
        "#### Exatidão do modelo mais legível, mas possivelmente mais baixa"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vqXeYffzSHp"
      },
      "source": [
        "Os ajustes com o pruning não são compatíveis. Por isso, pode apresentar menos exatidão do que os exemplos acima, que oferecem suporte aos ajustes.\n",
        "\n",
        "Enquanto `prune_low_magnitude` pode ser aplicado ao definir o modelo inicial, o carregamento de pesos posterior não funciona nos exemplos abaixo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5p5jvH5KznJ"
      },
      "source": [
        "**Exemplo funcional**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Wow55hg5oiM"
      },
      "outputs": [],
      "source": [
        "# Use `prune_low_magnitude` to make the `Dense` layer train with pruning.\n",
        "i = tf.keras.Input(shape=(20,))\n",
        "x = tfmot.sparsity.keras.prune_low_magnitude(tf.keras.layers.Dense(10))(i)\n",
        "o = tf.keras.layers.Flatten()(x)\n",
        "model_for_pruning = tf.keras.Model(inputs=i, outputs=o)\n",
        "\n",
        "model_for_pruning.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIGj-r2of2ls"
      },
      "source": [
        "**Exemplo sequencial**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mQOiDUGgfi4y"
      },
      "outputs": [],
      "source": [
        "# Use `prune_low_magnitude` to make the `Dense` layer train with pruning.\n",
        "model_for_pruning = tf.keras.Sequential([\n",
        "  tfmot.sparsity.keras.prune_low_magnitude(tf.keras.layers.Dense(20, input_shape=input_shape)),\n",
        "  tf.keras.layers.Flatten()\n",
        "])\n",
        "\n",
        "model_for_pruning.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnMguvVSnUqD"
      },
      "source": [
        "### Faça o pruning da camada do Keras personalizada ou modifique partes da camada para podar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLgH1aFMjTK4"
      },
      "source": [
        "**Erro comum:** o pruning do bias geralmente prejudica muito a exatidão do modelo.\n",
        "\n",
        "`tfmot.sparsity.keras.PrunableLayer` atende dois casos de uso:\n",
        "\n",
        "1. Fazer o pruning de uma camada do Keras personalizada\n",
        "2. Modificar partes de uma camada do Keras integrada para fazer o pruning.\n",
        "\n",
        "Por exemplo, o padrão da API é só fazer o pruning do kernel da camada `Dense`. O exemplo abaixo também faz o pruning do bias.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "77jgBjccnTh6"
      },
      "outputs": [],
      "source": [
        "class MyDenseLayer(tf.keras.layers.Dense, tfmot.sparsity.keras.PrunableLayer):\n",
        "\n",
        "  def get_prunable_weights(self):\n",
        "    # Prune bias also, though that usually harms model accuracy too much.\n",
        "    return [self.kernel, self.bias]\n",
        "\n",
        "# Use `prune_low_magnitude` to make the `MyDenseLayer` layer train with pruning.\n",
        "model_for_pruning = tf.keras.Sequential([\n",
        "  tfmot.sparsity.keras.prune_low_magnitude(MyDenseLayer(20, input_shape=input_shape)),\n",
        "  tf.keras.layers.Flatten()\n",
        "])\n",
        "\n",
        "model_for_pruning.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itAyTyzvRroH"
      },
      "source": [
        "## Treine o modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4hnWH2NY5MO"
      },
      "source": [
        "### Model.fit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LYCDIunTE9B"
      },
      "source": [
        "Chame a callback `tfmot.sparsity.keras.UpdatePruningStep` durante o treinamento.\n",
        "\n",
        "Para ajudar a depurar o treinamento, use a callback `tfmot.sparsity.keras.PruningSummaries`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fKZ2PxcpY_WV"
      },
      "outputs": [],
      "source": [
        "# Define the model.\n",
        "base_model = setup_model()\n",
        "base_model.load_weights(pretrained_weights) # optional but recommended for model accuracy\n",
        "model_for_pruning = tfmot.sparsity.keras.prune_low_magnitude(base_model)\n",
        "\n",
        "log_dir = tempfile.mkdtemp()\n",
        "callbacks = [\n",
        "    tfmot.sparsity.keras.UpdatePruningStep(),\n",
        "    # Log sparsity and other metrics in Tensorboard.\n",
        "    tfmot.sparsity.keras.PruningSummaries(log_dir=log_dir)\n",
        "]\n",
        "\n",
        "model_for_pruning.compile(\n",
        "      loss=tf.keras.losses.categorical_crossentropy,\n",
        "      optimizer='adam',\n",
        "      metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model_for_pruning.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    callbacks=callbacks,\n",
        "    epochs=2,\n",
        ")\n",
        "\n",
        "#docs_infra: no_execute\n",
        "%tensorboard --logdir={log_dir}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kcuGmf5MSnJ"
      },
      "source": [
        "Para usuários fora do Colab, é possível ver os [resultados de uma execução anterior](https://tensorboard.dev/experiment/XiNXEBjHQ3Oabc6jRLKiXQ/#scalars&_smoothingWeight=0) desse bloco de código no [TensorBoard.dev](https://tensorboard.dev/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDcSvbNdZA-1"
      },
      "source": [
        "### Loop de treinamento personalizado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQA8GaD6T3-o"
      },
      "source": [
        "Chame a callback `tfmot.sparsity.keras.UpdatePruningStep` durante o treinamento.\n",
        "\n",
        "Para ajudar a depurar o treinamento, use a callback `tfmot.sparsity.keras.PruningSummaries`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hPQUrkodbIF2"
      },
      "outputs": [],
      "source": [
        "# Define the model.\n",
        "base_model = setup_model()\n",
        "base_model.load_weights(pretrained_weights) # optional but recommended for model accuracy\n",
        "model_for_pruning = tfmot.sparsity.keras.prune_low_magnitude(base_model)\n",
        "\n",
        "# Boilerplate\n",
        "loss = tf.keras.losses.categorical_crossentropy\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "log_dir = tempfile.mkdtemp()\n",
        "unused_arg = -1\n",
        "epochs = 2\n",
        "batches = 1 # example is hardcoded so that the number of batches cannot change.\n",
        "\n",
        "# Non-boilerplate.\n",
        "model_for_pruning.optimizer = optimizer\n",
        "step_callback = tfmot.sparsity.keras.UpdatePruningStep()\n",
        "step_callback.set_model(model_for_pruning)\n",
        "log_callback = tfmot.sparsity.keras.PruningSummaries(log_dir=log_dir) # Log sparsity and other metrics in Tensorboard.\n",
        "log_callback.set_model(model_for_pruning)\n",
        "\n",
        "step_callback.on_train_begin() # run pruning callback\n",
        "for _ in range(epochs):\n",
        "  log_callback.on_epoch_begin(epoch=unused_arg) # run pruning callback\n",
        "  for _ in range(batches):\n",
        "    step_callback.on_train_batch_begin(batch=unused_arg) # run pruning callback\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "      logits = model_for_pruning(x_train, training=True)\n",
        "      loss_value = loss(y_train, logits)\n",
        "      grads = tape.gradient(loss_value, model_for_pruning.trainable_variables)\n",
        "      optimizer.apply_gradients(zip(grads, model_for_pruning.trainable_variables))\n",
        "\n",
        "  step_callback.on_epoch_end(batch=unused_arg) # run pruning callback\n",
        "\n",
        "#docs_infra: no_execute\n",
        "%tensorboard --logdir={log_dir}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vh4lJt4zMh1v"
      },
      "source": [
        "Para usuários fora do Colab, é possível ver os [resultados de uma execução anterior](https://tensorboard.dev/experiment/jDeGzF3xQeSyb7Qir1ZcBQ/#scalars&_smoothingWeight=0) desse bloco de código no [TensorBoard.dev](https://tensorboard.dev/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8H-8lQ-cPa-"
      },
      "source": [
        "### Melhore a exatidão do modelo após o pruning\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2t4fYXvAV1V"
      },
      "source": [
        "Primeiro, confira a documentação da API `tfmot.sparsity.keras.prune_low_magnitude` para entender o que é um cronograma de pruning e a matemática de cada tipo de cronograma de pruning.\n",
        "\n",
        "**Dicas**:\n",
        "\n",
        "- Não tenha uma taxa de aprendizado muito alta ou muito baixa durante o pruning do modelo. Considere o [cronograma de pruning](https://www.tensorflow.org/model_optimization/api_docs/python/tfmot/sparsity/keras/PruningSchedule) como um hiperparâmetro.\n",
        "\n",
        "- Como teste rápido, experimente com o pruning de um modelo para a esparsidade final no início do treinamento ao definir `begin_step` como 0 com um cronograma `tfmot.sparsity.keras.ConstantSparsity`. Talvez você tenha a sorte de conseguir bons resultados.\n",
        "\n",
        "- Não faça o pruning com muita frequência, dando tempo para o modelo se recuperar. O [cronograma de pruning](https://www.tensorflow.org/model_optimization/api_docs/python/tfmot/sparsity/keras/PruningSchedule) oferece uma frequência padrão apropriada.\n",
        "\n",
        "- Para ideias gerais sobre como melhorar a exatidão do modelo, procure dicas para seu caso de uso em \"Defina um modelo\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpvX5IqahV1r"
      },
      "source": [
        "## Faça o checkpoint e desserialize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GuZ5wlij1dcJ"
      },
      "source": [
        "Você precisa preservar a etapa do otimizador durante o checkpoint. Isso significa que, embora você possa usar os modelos HDF5 do Keras para o checkpoint, não é possível usar os pesos HDF5 do Keras."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6khQg-q7imfH"
      },
      "outputs": [],
      "source": [
        "# Define the model.\n",
        "base_model = setup_model()\n",
        "base_model.load_weights(pretrained_weights) # optional but recommended for model accuracy\n",
        "model_for_pruning = tfmot.sparsity.keras.prune_low_magnitude(base_model)\n",
        "\n",
        "_, keras_model_file = tempfile.mkstemp('.h5')\n",
        "\n",
        "# Checkpoint: saving the optimizer is necessary (include_optimizer=True is the default).\n",
        "model_for_pruning.save(keras_model_file, include_optimizer=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-CLxooLYnRN"
      },
      "source": [
        "A regra acima se aplica de forma geral. O código abaixo só é necessário para o formato de modelo HDF5 (e não pesos HDF5 e outros formatos).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2nGC1hZnYlzb"
      },
      "outputs": [],
      "source": [
        "# Deserialize model.\n",
        "with tfmot.sparsity.keras.prune_scope():\n",
        "  loaded_model = tf.keras.models.load_model(keras_model_file)\n",
        "\n",
        "loaded_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jew8M217SgQw"
      },
      "source": [
        "## Implante o modelo após o pruning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2uj4SfF1cnTR"
      },
      "source": [
        "### Exporte o modelo com a compressão do tamanho"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57uNm47L4Yro"
      },
      "source": [
        "**Erro comum**: o `strip_pruning` e a aplicação de um algoritmo de compressão padrão (por exemplo, por gzip) são necessários para ver os benefícios de compressão do pruning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EZ3TD8cYkxZM"
      },
      "outputs": [],
      "source": [
        "# Define the model.\n",
        "base_model = setup_model()\n",
        "base_model.load_weights(pretrained_weights) # optional but recommended for model accuracy\n",
        "model_for_pruning = tfmot.sparsity.keras.prune_low_magnitude(base_model)\n",
        "\n",
        "# Typically you train the model here.\n",
        "\n",
        "model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
        "\n",
        "print(\"final model\")\n",
        "model_for_export.summary()\n",
        "\n",
        "print(\"\\n\")\n",
        "print(\"Size of gzipped pruned model without stripping: %.2f bytes\" % (get_gzipped_model_size(model_for_pruning)))\n",
        "print(\"Size of gzipped pruned model with stripping: %.2f bytes\" % (get_gzipped_model_size(model_for_export)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPXvYIHOctem"
      },
      "source": [
        "### Otimizações de hardware específico"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqk0jI49c1mw"
      },
      "source": [
        "Depois que back-ends diferentes [ativarem o pruning para melhorar a latência]((https://github.com/tensorflow/model-optimization/issues/173)), o uso da esparsidade de bloco pode melhorar a latência para hardware específico.\n",
        "\n",
        "O aumento do tamanho do bloco diminuirá o pico de esparsidade possível para uma exatidão de modelo alvo. Apesar disso, a latência ainda pode melhorar.\n",
        "\n",
        "Para mais detalhes sobre o que é compatível com a esparsidade de bloco, veja a documentação da API `tfmot.sparsity.keras.prune_low_magnitude`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xedaVDeFc0bw"
      },
      "outputs": [],
      "source": [
        "base_model = setup_model()\n",
        "\n",
        "# For using intrinsics on a CPU with 128-bit registers, together with 8-bit\n",
        "# quantized weights, a 1x16 block size is nice because the block perfectly\n",
        "# fits into the register.\n",
        "pruning_params = {'block_size': [1, 16]}\n",
        "model_for_pruning = tfmot.sparsity.keras.prune_low_magnitude(base_model, **pruning_params)\n",
        "\n",
        "model_for_pruning.summary()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Tce3stUlHN0L"
      ],
      "name": "comprehensive_guide.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
