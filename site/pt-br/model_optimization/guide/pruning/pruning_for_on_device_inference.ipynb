{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKT-NezBJ4Nd"
      },
      "source": [
        "##### Copyright 2021 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "DwBljPxTJ4Ng"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIb8SDeKJ4Nh"
      },
      "source": [
        "# Pruning para a inferência no dispositivo com XNNPACK"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RX1fje9OJ4Ni"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>     <a target=\"_blank\" href=\"https://www.tensorflow.org/model_optimization/guide/pruning/pruning_for_on_device_inference\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver em TensorFlow.org</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/pt-br/model_optimization/guide/pruning/pruning_for_on_device_inference.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Executar no Google Colab</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/pt-br/model_optimization/guide/pruning/pruning_for_on_device_inference.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver fonte no GitHub</a>\n",
        "</td>\n",
        "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/pt-br/model_optimization/guide/pruning/pruning_for_on_device_inference.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Baixar notebook</a>\n",
        "</td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uCVQVRMJ4Nj"
      },
      "source": [
        "Bem-vindo ao guia sobre o pruning de pesos do Keras para melhorar a latência da inferência no dispositivo via [XNNPACK](https://github.com/google/XNNPACK).\n",
        "\n",
        "Este guia apresenta o uso da API `tfmot.sparsity.keras.PruningPolicy` recém-lançada e demonstra como ela pode ser usada para acelerar principalmente modelos convolucionais em CPUs modernas usando a [inferência esparsa do XNNPACK](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/delegates/xnnpack/README.md#sparse-inference).\n",
        "\n",
        "O guia abrange as seguintes etapas do processo de criação do modelo:\n",
        "\n",
        "- Compilar e treinar o modelo\n",
        "- Ajustar o modelo com o pruning\n",
        "- Converter para o TFLite\n",
        "- Fazer o benchmarking no dispositivo\n",
        "\n",
        "O guia não cobre as práticas recomendadas para os ajustes com o pruning. Para informações mais detalhadas sobre esse tópico, confira nosso [guia completo](https://www.tensorflow.org/model_optimization/guide/pruning/comprehensive_guide.md)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UF5sWYUZJ4Nk"
      },
      "source": [
        "## Configuração"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "re0qdmOAJ4Nk"
      },
      "outputs": [],
      "source": [
        "! pip install -q tensorflow\n",
        "! pip install -q tensorflow-model-optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aIn7sB8-J4Nk"
      },
      "outputs": [],
      "source": [
        "import tempfile\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow import keras\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_model_optimization as tfmot\n",
        "\n",
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOeRh5hvJ4Nl"
      },
      "source": [
        "## Compile e treine o modelo denso"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNxUSmleJ4Nl"
      },
      "source": [
        "Compilamos e treinamos uma CNN de referência simples para a tarefa de classificação no dataset [CIFAR10](https://www.cs.toronto.edu/~kriz/cifar.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ws4cmZCJJ4Nm"
      },
      "outputs": [],
      "source": [
        "# Load CIFAR10 dataset.\n",
        "(ds_train, ds_val, ds_test), ds_info = tfds.load(\n",
        "    'cifar10',\n",
        "    split=['train[:90%]', 'train[90%:]', 'test'],\n",
        "    as_supervised=True,\n",
        "    with_info=True,\n",
        ")\n",
        "\n",
        "# Normalize the input image so that each pixel value is between 0 and 1.\n",
        "def normalize_img(image, label):\n",
        "  \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
        "  return tf.image.convert_image_dtype(image, tf.float32), label\n",
        "\n",
        "# Load the data in batches of 128 images.\n",
        "batch_size = 128\n",
        "def prepare_dataset(ds, buffer_size=None):\n",
        "  ds = ds.map(normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "  ds = ds.cache()\n",
        "  if buffer_size:\n",
        "    ds = ds.shuffle(buffer_size)\n",
        "  ds = ds.batch(batch_size)\n",
        "  ds = ds.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "  return ds\n",
        "\n",
        "ds_train = prepare_dataset(ds_train,\n",
        "                           buffer_size=ds_info.splits['train'].num_examples)\n",
        "ds_val = prepare_dataset(ds_val)\n",
        "ds_test = prepare_dataset(ds_test)\n",
        "\n",
        "# Build the dense baseline model.\n",
        "dense_model = keras.Sequential([\n",
        "    keras.layers.InputLayer(input_shape=(32, 32, 3)),\n",
        "    keras.layers.ZeroPadding2D(padding=1),\n",
        "    keras.layers.Conv2D(\n",
        "        filters=8,\n",
        "        kernel_size=(3, 3),\n",
        "        strides=(2, 2),\n",
        "        padding='valid'),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.ReLU(),\n",
        "    keras.layers.DepthwiseConv2D(kernel_size=(3, 3), padding='same'),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.ReLU(),\n",
        "    keras.layers.Conv2D(filters=16, kernel_size=(1, 1)),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.ReLU(),\n",
        "    keras.layers.ZeroPadding2D(padding=1),\n",
        "    keras.layers.DepthwiseConv2D(\n",
        "        kernel_size=(3, 3), strides=(2, 2), padding='valid'),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.ReLU(),\n",
        "    keras.layers.Conv2D(filters=32, kernel_size=(1, 1)),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.ReLU(),\n",
        "    keras.layers.GlobalAveragePooling2D(),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(10)\n",
        "])\n",
        "\n",
        "# Compile and train the dense model for 10 epochs.\n",
        "dense_model.compile(\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy'])\n",
        "\n",
        "dense_model.fit(\n",
        "  ds_train,\n",
        "  epochs=10,\n",
        "  validation_data=ds_val)\n",
        "\n",
        "# Evaluate the dense model.\n",
        "_, dense_model_accuracy = dense_model.evaluate(ds_test, verbose=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32h7h4YYJ4Nn"
      },
      "source": [
        "## Criar o modelo esparso"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXAXjJcuJ4Nn"
      },
      "source": [
        "Usando as instruções do [guia completo](https://www.tensorflow.org/model_optimization/guide/pruning/comprehensive_guide.md), aplicamos a função `tfmot.sparsity.keras.prune_low_magnitude` com parâmetros direcionados à aceleração no dispositivo pelo pruning, ou seja, a política `tfmot.sparsity.keras.PruneForLatencyOnXNNPack`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N1WQt5dmJ4Nn"
      },
      "outputs": [],
      "source": [
        "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
        "\n",
        "# Compute end step to finish pruning after after 5 epochs.\n",
        "end_epoch = 5\n",
        "\n",
        "num_iterations_per_epoch = len(ds_train)\n",
        "end_step =  num_iterations_per_epoch * end_epoch\n",
        "\n",
        "# Define parameters for pruning.\n",
        "pruning_params = {\n",
        "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.25,\n",
        "                                                               final_sparsity=0.75,\n",
        "                                                               begin_step=0,\n",
        "                                                               end_step=end_step),\n",
        "      'pruning_policy': tfmot.sparsity.keras.PruneForLatencyOnXNNPack()\n",
        "}\n",
        "\n",
        "# Try to apply pruning wrapper with pruning policy parameter.\n",
        "try:\n",
        "  model_for_pruning = prune_low_magnitude(dense_model, **pruning_params)\n",
        "except ValueError as e:\n",
        "  print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzDggTmYJ4No"
      },
      "source": [
        "A chamada `prune_low_magnitude` resulta em `ValueError` com a mensagem `Could not find a GlobalAveragePooling2D layer with keepdims = True in all output branches`. Essa mensagem indica que o modelo não é compatível com o pruning pela política `tfmot.sparsity.keras.PruneForLatencyOnXNNPack` e, especificamente, a camada `GlobalAveragePooling2D` exige o parâmetro `keepdims = True`. Vamos corrigir isso e aplicar a função `prune_low_magnitude`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qvALAbZeJ4No"
      },
      "outputs": [],
      "source": [
        "fixed_dense_model = keras.Sequential([\n",
        "    keras.layers.InputLayer(input_shape=(32, 32, 3)),\n",
        "    keras.layers.ZeroPadding2D(padding=1),\n",
        "    keras.layers.Conv2D(\n",
        "        filters=8,\n",
        "        kernel_size=(3, 3),\n",
        "        strides=(2, 2),\n",
        "        padding='valid'),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.ReLU(),\n",
        "    keras.layers.DepthwiseConv2D(kernel_size=(3, 3), padding='same'),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.ReLU(),\n",
        "    keras.layers.Conv2D(filters=16, kernel_size=(1, 1)),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.ReLU(),\n",
        "    keras.layers.ZeroPadding2D(padding=1),\n",
        "    keras.layers.DepthwiseConv2D(\n",
        "        kernel_size=(3, 3), strides=(2, 2), padding='valid'),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.ReLU(),\n",
        "    keras.layers.Conv2D(filters=32, kernel_size=(1, 1)),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.ReLU(),\n",
        "    keras.layers.GlobalAveragePooling2D(keepdims=True),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(10)\n",
        "])\n",
        "\n",
        "# Use the pretrained model for pruning instead of training from scratch.\n",
        "fixed_dense_model.set_weights(dense_model.get_weights())\n",
        "\n",
        "# Try to reapply pruning wrapper.\n",
        "model_for_pruning = prune_low_magnitude(fixed_dense_model, **pruning_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51K8A0XCJ4Np"
      },
      "source": [
        "A invocação de `prune_low_magnitude` foi concluída sem nenhum erro, o que significa que o modelo é totalmente compatível com a política `tfmot.sparsity.keras.PruneForLatencyOnXNNPack` e pode ser acelerado usando a [inferência esparsa de XNNPACK](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/delegates/xnnpack/README.md#sparse-inference)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NG4yrdNUJ4Np"
      },
      "source": [
        "### Ajuste o modelo esparso"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EqhqM7AtJ4Np"
      },
      "source": [
        "Seguindo o [exemplo de pruning](https://www.tensorflow.org/model_optimization/guide/pruning/pruning_with_keras.md), ajustamos o modelo esparso usando os pesos do modelo denso. Começamos a ajustar o modelo com uma esparsidade de 25% (25% dos pesos são definidos como zero) e terminamos com uma esparsidade de 75%."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GzdS6AgRJ4Np"
      },
      "outputs": [],
      "source": [
        "logdir = tempfile.mkdtemp()\n",
        "\n",
        "callbacks = [\n",
        "  tfmot.sparsity.keras.UpdatePruningStep(),\n",
        "  tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
        "]\n",
        "\n",
        "model_for_pruning.compile(\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy'])\n",
        "\n",
        "model_for_pruning.fit(\n",
        "  ds_train,\n",
        "  epochs=15,\n",
        "  validation_data=ds_val,\n",
        "  callbacks=callbacks)\n",
        "\n",
        "# Evaluate the dense model.\n",
        "_, pruned_model_accuracy = model_for_pruning.evaluate(ds_test, verbose=0)\n",
        "\n",
        "print('Dense model test accuracy:', dense_model_accuracy)\n",
        "print('Pruned model test accuracy:', pruned_model_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EeI9QSIMJ4Nq"
      },
      "source": [
        "Os logs mostram a progressão da esparsidade em cada camada."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fGDkSxKJJ4Nq"
      },
      "outputs": [],
      "source": [
        "#docs_infra: no_execute\n",
        "%tensorboard --logdir={logdir}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hJ5PX_y7psT"
      },
      "source": [
        "Depois de fazer os ajustes com o pruning, a exatidão de teste mostra uma melhoria modesta (de 43% a 44%) em relação ao modelo denso. Vamos comparar a latência no dispositivo usando o [benchmark do TFLite](https://www.tensorflow.org/lite/performance/measurement)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xCRpxczJ4Nq"
      },
      "source": [
        "## Conversão e benchmarking do modelo\n",
        "\n",
        "Para converter o modelo podado para o TFLite, precisamos substituir os wrappers `PruneLowMagnitude` com camadas originais através da função `strip_pruning`. Além disso, como os pesos do modelo podado (`model_for_pruning`) são, em grande parte, zeros, podemos aplicar uma otimização `tf.lite.Optimize.EXPERIMENTAL_SPARSITY` para armazenar com eficiência o modelo do TFLite gerado. Essa flag de otimização não é necessária para o modelo denso."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AAJr2XKCJ4Nr"
      },
      "outputs": [],
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(dense_model)\n",
        "dense_tflite_model = converter.convert()\n",
        "\n",
        "_, dense_tflite_file = tempfile.mkstemp('.tflite')\n",
        "with open(dense_tflite_file, 'wb') as f:\n",
        "  f.write(dense_tflite_model)\n",
        "\n",
        "model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export)\n",
        "converter.optimizations = [tf.lite.Optimize.EXPERIMENTAL_SPARSITY]\n",
        "pruned_tflite_model = converter.convert()\n",
        "\n",
        "_, pruned_tflite_file = tempfile.mkstemp('.tflite')\n",
        "with open(pruned_tflite_file, 'wb') as f:\n",
        "  f.write(pruned_tflite_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLClpRYq7psT"
      },
      "source": [
        "Seguindo as instruções da [Ferramenta de Benchmarking de Modelo do TFLite](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/tools/benchmark), compilamos a ferramenta, fazemos o upload dela para o dispositivo Android com os modelos do TFLite densos e podados e fazemos o benchmarking dos dois modelos no dispositivo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-qamJwAM7psU"
      },
      "outputs": [],
      "source": [
        "! adb shell /data/local/tmp/benchmark_model \\\n",
        "    --graph=/data/local/tmp/dense_model.tflite \\\n",
        "    --use_xnnpack=true \\\n",
        "    --num_runs=100 \\\n",
        "    --num_threads=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fpTxyOcd7psU"
      },
      "outputs": [],
      "source": [
        "! adb shell /data/local/tmp/benchmark_model \\\n",
        "    --graph=/data/local/tmp/pruned_model.tflite \\\n",
        "    --use_xnnpack=true \\\n",
        "    --num_runs=100 \\\n",
        "    --num_threads=1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKOVVoYD7psU"
      },
      "source": [
        "Os benchmarks no Pixel 4 resultam em um tempo de inferência médio de *17us* para o modelo denso e *12us* para o modelo podado. Os benchmarks no dispositivo demonstram uma melhoria clara de **5us** ou **30%** na latência, mesmo para modelos tão pequenos. Em nossa experiência, modelos grandes baseados em [MobileNetV3](https://www.tensorflow.org/api_docs/python/tf/keras/applications/mobilenet_v3) ou [EfficientNet-lite](https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet/lite) mostram melhorias semelhantes no desempenho. Os speed-up variam com base na contribuição relativa das convoluções 1x1 para o modelo em geral.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqL_Nhuw7psU"
      },
      "source": [
        "## Conclusão"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03Icj3vV7psU"
      },
      "source": [
        "Neste tutorial, mostramos como criar modelos esparsos para desempenho mais rápido no dispositivo usando a nova funcionalidade lançada pela API MOT do TF e pelo XNNPack. Esses modelos esparsos são menores e mais rápidos do que suas contrapartes densas, além de reterem ou até mesmo superarem a qualidade.\n",
        "\n",
        "Recomendamos que você teste essa nova capacidade que pode ser especialmente importante para implantar seus modelos no dispositivo."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "pruning_for_on_device_inference.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
