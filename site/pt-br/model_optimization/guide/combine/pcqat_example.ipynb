{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlE_jisTkXY4"
      },
      "source": [
        "**Copyright 2021 The TensorFlow Authors.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "mEE8NFIMSGO-"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J63wSeDoZZwd"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>     <a target=\"_blank\" href=\"https://www.tensorflow.org/model_optimization/guide/combine/pcqat_example\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver em TensorFlow.org</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/pt-br/model_optimization/guide/combine/pcqat_example.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Executar no Google Colab</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/pt-br/model_optimization/guide/combine/pcqat_example.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver no GitHub</a>\n",
        "</td>\n",
        "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/pt-br/model_optimization/guide/combine/pcqat_example.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Baixar notebook</a>\n",
        "</td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyiSRgdtSGPC"
      },
      "source": [
        "# Exemplo do Keras de treinamento consciente de quantização que preserva a esparsidade e os clusters (CQAT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKnJyAaASGPD"
      },
      "source": [
        "## Visão geral\n",
        "\n",
        "Este é um exemplo completo que mostra o uso da API de **treinamento consciente de quantização que preserva a esparsidade e os clusters (PCQAT)**, parte do pipeline de otimização colaborativa do Kit de ferramentas para otimização de modelos do TensorFlow.\n",
        "\n",
        "### Outras páginas\n",
        "\n",
        "Para uma introdução sobre o pipeline e outras técnicas disponíveis, confira a [página de visão geral da otimização colaborativa](https://www.tensorflow.org/model_optimization/guide/combine/collaborative_optimization).\n",
        "\n",
        "### Conteúdo\n",
        "\n",
        "Neste tutorial, você:\n",
        "\n",
        "1. Treinará um modelo `tf.keras` para o dataset MNIST do zero.\n",
        "2. Ajustará o modelo com o pruning, verá a exatidão e observará se o pruning teve êxito.\n",
        "3. Aplicará o clustering que preserva a esparsidade no modelo após o pruning e observará se a esparsidade aplicada antes foi preservada.\n",
        "4. Aplicará o QAT e observará a perda de clusters.\n",
        "5. Aplicará o CQAT e observará se a esparsidade e o clustering aplicados antes foram preservados.\n",
        "6. Gerará um modelo do TFLite e observará os efeitos da aplicação do PCQAT nele.\n",
        "7. Comparará os tamanhos de modelos diferentes para observar os benefícios da compressão ao aplicar a esparsidade, seguida por técnicas de otimização colaborativa: o clustering que preserva a esparsidade e o PCQAT.\n",
        "8. Comparará a exatidão do modelo completamente otimizado com a exatidão do modelo de referência não otimizado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgcQznnZSGPE"
      },
      "source": [
        "## Configuração\n",
        "\n",
        "Você pode executar este Notebook do Jupyter no seu [virtualenv](https://www.tensorflow.org/install/pip?lang=python3#2.-create-a-virtual-environment-recommended) local ou no [colab](https://colab.sandbox.google.com/). Para mais detalhes sobre como configurar as dependências, consulte o [guia de instalação](https://www.tensorflow.org/model_optimization/guide/install)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3asgXMqnSGPE"
      },
      "outputs": [],
      "source": [
        "! pip install -q tensorflow-model-optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gL6JiLXkSGPI"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "import tempfile\n",
        "import zipfile\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKzOfl5FSGPL"
      },
      "source": [
        "## Treine um modelo tf.keras para o MNIST que passará pelo pruning e clustering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w7Fd6jZ7SGPL"
      },
      "outputs": [],
      "source": [
        "# Load MNIST dataset\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# Normalize the input image so that each pixel value is between 0 to 1.\n",
        "train_images = train_images / 255.0\n",
        "test_images  = test_images / 255.0\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.InputLayer(input_shape=(28, 28)),\n",
        "  tf.keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
        "  tf.keras.layers.Conv2D(filters=12, kernel_size=(3, 3),\n",
        "                         activation=tf.nn.relu),\n",
        "  tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(10)\n",
        "])\n",
        "\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
        "\n",
        "# Train the digit classification model\n",
        "model.compile(optimizer=opt,\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(\n",
        "    train_images,\n",
        "    train_labels,\n",
        "    validation_split=0.1,\n",
        "    epochs=10\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBOQ8MeESGPO"
      },
      "source": [
        "### Avalie o modelo de referência e salve-o para usar mais tarde"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HYulekocSGPP"
      },
      "outputs": [],
      "source": [
        "_, baseline_model_accuracy = model.evaluate(\n",
        "    test_images, test_labels, verbose=0)\n",
        "\n",
        "print('Baseline test accuracy:', baseline_model_accuracy)\n",
        "\n",
        "_, keras_file = tempfile.mkstemp('.h5')\n",
        "print('Saving model to: ', keras_file)\n",
        "tf.keras.models.save_model(model, keras_file, include_optimizer=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPoCr4OFkXZE"
      },
      "source": [
        "## Faça o pruning e ajuste o modelo para 50% da esparsidade"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mucwWWikXZE"
      },
      "source": [
        "Aplique a API `prune_low_magnitude()` para obter o modelo com pruning que será agrupado na próxima etapa. Consulte o [guia completo de pruning](https://www.tensorflow.org/model_optimization/guide/pruning/comprehensive_guide) para mais informações sobre a API de pruning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGfTFitgkXZF"
      },
      "source": [
        "### Defina o modelo e aplique a API de esparsidade\n",
        "\n",
        "Observe que é usado o modelo pré-treinado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mqsN5tP-kXZF"
      },
      "outputs": [],
      "source": [
        "import tensorflow_model_optimization as tfmot\n",
        "\n",
        "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
        "\n",
        "pruning_params = {\n",
        "      'pruning_schedule': tfmot.sparsity.keras.ConstantSparsity(0.5, begin_step=0, frequency=100)\n",
        "  }\n",
        "\n",
        "callbacks = [\n",
        "  tfmot.sparsity.keras.UpdatePruningStep()\n",
        "]\n",
        "\n",
        "pruned_model = prune_low_magnitude(model, **pruning_params)\n",
        "\n",
        "# Use smaller learning rate for fine-tuning\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
        "\n",
        "pruned_model.compile(\n",
        "  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "  optimizer=opt,\n",
        "  metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mh6SzEP9kXZF"
      },
      "source": [
        "### Ajuste o modelo e compare a exatidão dele com a referência\n",
        "\n",
        "Ajuste o modelo com o pruning para 3 épocas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2aBxR8uEkXZG"
      },
      "outputs": [],
      "source": [
        "# Fine-tune model\n",
        "pruned_model.fit(\n",
        "  train_images,\n",
        "  train_labels,\n",
        "  epochs=3,\n",
        "  validation_split=0.1,\n",
        "  callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GALLq2ZlkXZG"
      },
      "source": [
        "Defina funções helper para calcular e imprimir a esparsidade e os clusters do modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XL-zWoU4kXZG"
      },
      "outputs": [],
      "source": [
        "def print_model_weights_sparsity(model):\n",
        "    for layer in model.layers:\n",
        "        if isinstance(layer, tf.keras.layers.Wrapper):\n",
        "            weights = layer.trainable_weights\n",
        "        else:\n",
        "            weights = layer.weights\n",
        "        for weight in weights:\n",
        "            if \"kernel\" not in weight.name or \"centroid\" in weight.name:\n",
        "                continue\n",
        "            weight_size = weight.numpy().size\n",
        "            zero_num = np.count_nonzero(weight == 0)\n",
        "            print(\n",
        "                f\"{weight.name}: {zero_num/weight_size:.2%} sparsity \",\n",
        "                f\"({zero_num}/{weight_size})\",\n",
        "            )\n",
        "\n",
        "def print_model_weight_clusters(model):\n",
        "    for layer in model.layers:\n",
        "        if isinstance(layer, tf.keras.layers.Wrapper):\n",
        "            weights = layer.trainable_weights\n",
        "        else:\n",
        "            weights = layer.weights\n",
        "        for weight in weights:\n",
        "            # ignore auxiliary quantization weights\n",
        "            if \"quantize_layer\" in weight.name:\n",
        "                continue\n",
        "            if \"kernel\" in weight.name:\n",
        "                unique_count = len(np.unique(weight))\n",
        "                print(\n",
        "                    f\"{layer.name}/{weight.name}: {unique_count} clusters \"\n",
        "                )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZRAJVqWkXZG"
      },
      "source": [
        "Vamos remover o wrapper de pruning primeiro e verificar se os kernels do modelo foram podados corretamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_8_p--1NkXZG"
      },
      "outputs": [],
      "source": [
        "stripped_pruned_model = tfmot.sparsity.keras.strip_pruning(pruned_model)\n",
        "\n",
        "print_model_weights_sparsity(stripped_pruned_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWPgcnjKSGPR"
      },
      "source": [
        "## Aplique o clustering que preserva a esparsidade e confira o efeito na esparsidade do modelo em ambos os casos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2wKK7w9SGPS"
      },
      "source": [
        "Em seguida, aplique o clustering que preserva a esparsidade no modelo após o pruning, observe o número de clusters e verifique se a esparsidade foi preservada."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RetnGeQnkXZH"
      },
      "outputs": [],
      "source": [
        "import tensorflow_model_optimization as tfmot\n",
        "from tensorflow_model_optimization.python.core.clustering.keras.experimental import (\n",
        "    cluster,\n",
        ")\n",
        "\n",
        "cluster_weights = tfmot.clustering.keras.cluster_weights\n",
        "CentroidInitialization = tfmot.clustering.keras.CentroidInitialization\n",
        "\n",
        "cluster_weights = cluster.cluster_weights\n",
        "\n",
        "clustering_params = {\n",
        "  'number_of_clusters': 8,\n",
        "  'cluster_centroids_init': CentroidInitialization.KMEANS_PLUS_PLUS,\n",
        "  'preserve_sparsity': True\n",
        "}\n",
        "\n",
        "sparsity_clustered_model = cluster_weights(stripped_pruned_model, **clustering_params)\n",
        "\n",
        "sparsity_clustered_model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print('Train sparsity preserving clustering model:')\n",
        "sparsity_clustered_model.fit(train_images, train_labels,epochs=3, validation_split=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_PNNJoQkXZH"
      },
      "source": [
        "Remova o wrapper de clustering primeiro e verifique se o modelo foi podado e agrupado corretamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iHN3NW8OkXZI"
      },
      "outputs": [],
      "source": [
        "stripped_clustered_model = tfmot.clustering.keras.strip_clustering(sparsity_clustered_model)\n",
        "\n",
        "print(\"Model sparsity:\\n\")\n",
        "print_model_weights_sparsity(stripped_clustered_model)\n",
        "\n",
        "print(\"\\nModel clusters:\\n\")\n",
        "print_model_weight_clusters(stripped_clustered_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31qLY2udZIUc"
      },
      "source": [
        "## Aplique o QAT e o PCQAT e confira o efeito nos clusters e na esparsidade do modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMO-h8PgZIUc"
      },
      "source": [
        "Em seguida, aplicamos ambos o QAT e o PCQAT no modelo agrupado esparso e observamos se o PCQAT preserva a esparsidade e os clusters de peso no seu modelo. Observe que o modelo extraído é passado à API de QAT e PCQAT."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nfp-xfHdZIUc"
      },
      "outputs": [],
      "source": [
        "# QAT\n",
        "qat_model = tfmot.quantization.keras.quantize_model(stripped_clustered_model)\n",
        "\n",
        "qat_model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "print('Train qat model:')\n",
        "qat_model.fit(train_images, train_labels, batch_size=128, epochs=1, validation_split=0.1)\n",
        "\n",
        "# PCQAT\n",
        "quant_aware_annotate_model = tfmot.quantization.keras.quantize_annotate_model(\n",
        "              stripped_clustered_model)\n",
        "pcqat_model = tfmot.quantization.keras.quantize_apply(\n",
        "              quant_aware_annotate_model,\n",
        "              tfmot.experimental.combine.Default8BitClusterPreserveQuantizeScheme(preserve_sparsity=True))\n",
        "\n",
        "pcqat_model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "print('Train pcqat model:')\n",
        "pcqat_model.fit(train_images, train_labels, batch_size=128, epochs=1, validation_split=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6kluyg_2ZIUd"
      },
      "outputs": [],
      "source": [
        "print(\"QAT Model clusters:\")\n",
        "print_model_weight_clusters(qat_model)\n",
        "print(\"\\nQAT Model sparsity:\")\n",
        "print_model_weights_sparsity(qat_model)\n",
        "print(\"\\nPCQAT Model clusters:\")\n",
        "print_model_weight_clusters(pcqat_model)\n",
        "print(\"\\nPCQAT Model sparsity:\")\n",
        "print_model_weights_sparsity(pcqat_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9Ywb9bRZIUd"
      },
      "source": [
        "## Veja os benefícios da compressão do modelo de PCQAT\n",
        "\n",
        "Defina a função helper para obter um arquivo de modelo compactado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vehNHBYsZIUe"
      },
      "outputs": [],
      "source": [
        "def get_gzipped_model_size(file):\n",
        "  # It returns the size of the gzipped model in kilobytes.\n",
        "\n",
        "  _, zipped_file = tempfile.mkstemp('.zip')\n",
        "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
        "    f.write(file)\n",
        "\n",
        "  return os.path.getsize(zipped_file)/1000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBwp4GVmZIUe"
      },
      "source": [
        "Observe se aplicar a esparsidade, o clustering e o PCQAT ao modelo gera benefícios de compressão significativos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mbe2jMAyZIUe"
      },
      "outputs": [],
      "source": [
        "# QAT model\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(qat_model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "qat_tflite_model = converter.convert()\n",
        "qat_model_file = 'qat_model.tflite'\n",
        "# Save the model.\n",
        "with open(qat_model_file, 'wb') as f:\n",
        "    f.write(qat_tflite_model)\n",
        "\n",
        "# PCQAT model\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(pcqat_model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "pcqat_tflite_model = converter.convert()\n",
        "pcqat_model_file = 'pcqat_model.tflite'\n",
        "# Save the model.\n",
        "with open(pcqat_model_file, 'wb') as f:\n",
        "    f.write(pcqat_tflite_model)\n",
        "\n",
        "print(\"QAT model size: \", get_gzipped_model_size(qat_model_file), ' KB')\n",
        "print(\"PCQAT model size: \", get_gzipped_model_size(pcqat_model_file), ' KB')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6WBGBJU3ZIUf"
      },
      "source": [
        "## Veja a persistência da exatidão do TF para o TFLite\n",
        "\n",
        "Defina uma função helper para avaliar o modelo do TFLite com o dataset de teste."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9P-1dmQcZIUf"
      },
      "outputs": [],
      "source": [
        "def eval_model(interpreter):\n",
        "  input_index = interpreter.get_input_details()[0][\"index\"]\n",
        "  output_index = interpreter.get_output_details()[0][\"index\"]\n",
        "\n",
        "  # Run predictions on every image in the \"test\" dataset.\n",
        "  prediction_digits = []\n",
        "  for i, test_image in enumerate(test_images):\n",
        "    if i % 1000 == 0:\n",
        "      print(f\"Evaluated on {i} results so far.\")\n",
        "    # Pre-processing: add batch dimension and convert to float32 to match with\n",
        "    # the model's input data format.\n",
        "    test_image = np.expand_dims(test_image, axis=0).astype(np.float32)\n",
        "    interpreter.set_tensor(input_index, test_image)\n",
        "\n",
        "    # Run inference.\n",
        "    interpreter.invoke()\n",
        "\n",
        "    # Post-processing: remove batch dimension and find the digit with highest\n",
        "    # probability.\n",
        "    output = interpreter.tensor(output_index)\n",
        "    digit = np.argmax(output()[0])\n",
        "    prediction_digits.append(digit)\n",
        "\n",
        "  print('\\n')\n",
        "  # Compare prediction results with ground truth labels to calculate accuracy.\n",
        "  prediction_digits = np.array(prediction_digits)\n",
        "  accuracy = (prediction_digits == test_labels).mean()\n",
        "  return accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "276omav-ZIUf"
      },
      "source": [
        "Avalie o modelo após o pruning, o clustering e a quantização e veja se a exatidão do TensorFlow persiste no back-end do TFLite."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6p4RBECpZIUg"
      },
      "outputs": [],
      "source": [
        "interpreter = tf.lite.Interpreter(pcqat_model_file)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "pcqat_test_accuracy = eval_model(interpreter)\n",
        "\n",
        "print('Pruned, clustered and quantized TFLite test_accuracy:', pcqat_test_accuracy)\n",
        "print('Baseline TF test accuracy:', baseline_model_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQFbw88ykXZL"
      },
      "source": [
        "## Conclusão"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7JhbpowqSGP1"
      },
      "source": [
        "Neste tutorial, você aprendeu a criar um modelo, fazer o pruning dele usando a API `prune_low_magnitude()` e aplicar o clustering que preserva a esparsidade usando a API `cluster_weights()` para preservar a esparsidade e agrupar os pesos.\n",
        "\n",
        "Em seguida, o treinamento consciente de quantização que preserva a esparsidade e os clusters (PCQAT) foi aplicado para preservar a esparsidade e os clusters do modelo ao usar o QAT. O modelo PCQAT final foi comparado ao QAT para mostrar que a esparsidade e os clusters são preservados no primeiro e perdidos no último.\n",
        "\n",
        "Em seguida, os modelos foram convertidos para o TFLite, mostrando os benefícios da compressão ao usar as técnicas de esparsidade, clustering e PCQAT em cadeia para a otimização do modelo, e o modelo do TFLite foi avaliado para garantir a persistência da eficácia no back-end do TFLite.\n",
        "\n",
        "Por fim, a exatidão do modelo do TFLite de PCQAT foi comparada ao modelo de referência antes da otimização para mostrar que as técnicas de otimização colaborativa conseguiram obter benefícios de compressão e manter uma exatidão semelhante em comparação ao modelo original."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "pcqat_example.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
