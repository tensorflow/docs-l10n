{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tghWegsjhpkt"
      },
      "source": [
        "##### Copyright 2021 The TensorFlow Authors.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "rSGJWC5biBiG"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-Iyf5gv5oBq"
      },
      "source": [
        "# Pré-processamento de dados com o TensorFlow Transform\n",
        "\n",
        "***O componente de engenharia de características do TensorFlow Extended (TFX)***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5ST8dI25wbA"
      },
      "source": [
        "Observação: recomendamos executar este tutorial em um notebook Colab, sem necessidade de configuração! Basta clicar em “Executar no Google Colab”.\n",
        "\n",
        "<div class=\"devsite-table-wrapper\"><table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "<td>     <a target=\"_blank\" href=\"https://www.tensorflow.org/tfx/tutorials/transform/simple\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver em TensorFlow.org</a>\n",
        "</td>\n",
        "<td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/pt-br/tfx/tutorials/transform/simple.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Executar no Google Colab</a>\n",
        "</td>\n",
        "<td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/pt-br/tfx/tutorials/transform/simple.ipynb\"><img width=\"32px\" src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver fonte no GitHub</a>\n",
        "</td>\n",
        "<td>     <a target=\"_blank\" href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/pt-br/tfx/tutorials/transform/simple.ipynb\"><img width=\"32px\" src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Baixar notebook</a>\n",
        "</td>\n",
        "</table></div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPt5BHTwy_0F"
      },
      "source": [
        "Este exemplo de notebook colab fornece um exemplo muito simples de como o <a target=\"_blank\" href=\"https://www.tensorflow.org/tfx/transform/get_started/\">TensorFlow Transform</a> (<code>tf.Transform</code>) pode ser usado para pré-processar dados usando exatamente o mesmo código para treinar um modelo e servir inferências em produção.\n",
        "\n",
        "O TensorFlow Transform é uma biblioteca para pré-processamento de dados de entrada para TensorFlow, incluindo a criação de características que exigem um passo completo do dataset de treinamento. Por exemplo, usando o TensorFlow Transform você poderia:\n",
        "\n",
        "- Normalizar um valor de entrada usando a média e o desvio padrão\n",
        "- Converter strings em inteiros gerando um vocabulário sobre todos os valores de entrada\n",
        "- Converter números de ponto flutuante em números inteiros atribuindo-os a intervalos, com base na distribuição de dados observada\n",
        "\n",
        "O TensorFlow tem suporte integrado para manipulações em um único exemplo ou num lote de exemplos. O `tf.Transform` estende esses recursos para oferecer suporte a passos completos (full pass) em todo o dataset de treinamento.\n",
        "\n",
        "A saída do `tf.Transform` é exportada como um grafo do TensorFlow que você pode usar para treinamento e serviço. Usar o mesmo grafo para treinamento e serviço pode evitar desvios, uma vez que as mesmas transformações são aplicadas em ambos os estágios."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6c8lD3uQm8m5"
      },
      "source": [
        "### Atualize o Pip\n",
        "\n",
        "Para evitar a atualização do Pip num sistema ao executar localmente, garanta que estamos executando no Colab. Os sistemas locais podem, claro, ser atualizados separadamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EmiQXNLZm8z-"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  import colab\n",
        "  !pip install --upgrade pip\n",
        "except:\n",
        "  pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiBxgnc-m8-X"
      },
      "source": [
        "### Instale o TensorFlow Transform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j2CTKbMNm9I4"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U tensorflow_transform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R0mXLOJR_-dv"
      },
      "outputs": [],
      "source": [
        "# This cell is only necessary because packages were installed while python was\n",
        "# running. It avoids the need to restart the runtime when running in Colab.\n",
        "import pkg_resources\n",
        "import importlib\n",
        "\n",
        "importlib.reload(pkg_resources)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RptgLn2RYuK3"
      },
      "source": [
        "## Importações"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K4QXVIM7iglN"
      },
      "outputs": [],
      "source": [
        "import pathlib\n",
        "import pprint\n",
        "import tempfile\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_transform as tft\n",
        "\n",
        "import tensorflow_transform.beam as tft_beam\n",
        "from tensorflow_transform.tf_metadata import dataset_metadata\n",
        "from tensorflow_transform.tf_metadata import schema_utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxOxaaOYRfl7"
      },
      "source": [
        "## Dados: crie alguns dados fictícios\n",
        "\n",
        "Criaremos alguns dados fictícios simples para nosso exemplo:\n",
        "\n",
        "- `raw_data` são os dados brutos iniciais que iremos pré-processar\n",
        "- `raw_data_metadata` contém o esquema que nos informa os tipos de cada uma das colunas em `raw_data`. Neste caso, é bem simples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-R236Tkf_ON3"
      },
      "outputs": [],
      "source": [
        "raw_data = [\n",
        "      {'x': 1, 'y': 1, 's': 'hello'},\n",
        "      {'x': 2, 'y': 2, 's': 'world'},\n",
        "      {'x': 3, 'y': 3, 's': 'hello'}\n",
        "  ]\n",
        "\n",
        "raw_data_metadata = dataset_metadata.DatasetMetadata(\n",
        "    schema_utils.schema_from_feature_spec({\n",
        "        'y': tf.io.FixedLenFeature([], tf.float32),\n",
        "        'x': tf.io.FixedLenFeature([], tf.float32),\n",
        "        's': tf.io.FixedLenFeature([], tf.string),\n",
        "    }))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xexbWmQEBUBZ"
      },
      "source": [
        "## Transform: crie uma função de pré-processamento\n",
        "\n",
        "A <em>função de pré-processamento</em> é o conceito mais importante do tf.Transform. Uma função de pré-processamento é onde a transformação do dataset realmente acontece. Ela recebe e retorna um dicionário de tensores, onde um tensor significa um <a><code>Tensor</code></a> ou <a><code>SparseTensor</code></a>. Existem dois grupos principais de chamadas de API que normalmente formam o coração de uma função de pré-processamento:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zadh6MXLS3eD"
      },
      "source": [
        "1. **Ops do TensorFlow:** qualquer função que aceita e retorna tensores, o que geralmente correspondem às ops do TensorFlow. Elas adicionam operações do TensorFlow ao grafo que transforma dados brutos em dados transformados, um vetor de características por vez. Eles serão executados para cada exemplo, tanto durante o treinamento quanto durante o serviço.\n",
        "2. **Analisadores/mapeadores do Tensorflow Transform:** qualquer um dos analisadores/mapeadores fornecidos pelo tf.Transform. Eles também recebem e retornam tensores e normalmente contêm uma combinação de ops do Tensorflow e computações do Beam, mas, ao contrário das ops do TensorFlow, eles são executados apenas no pipeline do Beam durante a análise, exigindo uma passagem completa (full pass) por todo o dataset de treinamento. As computações do Beam rodam apenas uma vez (antes do treinamento, durante a análise) e normalmente fazem uma passagem completa por todo o dataset de treinamento. Criam tensores `tf.constant`, que são adicionados ao grafo. Por exemplo, `tft.min` calcula o mínimo de um tensor no dataset de treinamento.\n",
        "\n",
        "Atenção: Quando você aplica sua função de pré-processamento para servir inferências, as constantes que foram criadas pelos analisadores durante o treinamento não mudam. Se seus dados tiverem componentes de tendência ou sazonalidade, planeje levando isso em consideração.\n",
        "\n",
        "Observação: O `preprocessing_fn` não pode ser chamada diretamente. Isso significa que chamar `preprocessing_fn(raw_data)` não funciona. Em vez disso, ela deve ser passada para a API Beam do Transform conforme mostrado nas células a seguir."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H2wANNF_2dCR"
      },
      "outputs": [],
      "source": [
        "def preprocessing_fn(inputs):\n",
        "    \"\"\"Preprocess input columns into transformed columns.\"\"\"\n",
        "    x = inputs['x']\n",
        "    y = inputs['y']\n",
        "    s = inputs['s']\n",
        "    x_centered = x - tft.mean(x)\n",
        "    y_normalized = tft.scale_to_0_1(y)\n",
        "    s_integerized = tft.compute_and_apply_vocabulary(s)\n",
        "    x_centered_times_y_normalized = (x_centered * y_normalized)\n",
        "    return {\n",
        "        'x_centered': x_centered,\n",
        "        'y_normalized': y_normalized,\n",
        "        's_integerized': s_integerized,\n",
        "        'x_centered_times_y_normalized': x_centered_times_y_normalized,\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSl9qyTCbBKR"
      },
      "source": [
        "## Sintaxe\n",
        "\n",
        "Você está quase pronto para juntar tudo e usar o <a target=\"_blank\" href=\"https://beam.apache.org/\">Apache Beam</a> para executá-lo.\n",
        "\n",
        "O Apache Beam usa uma <a target=\"_blank\" href=\"https://beam.apache.org/documentation/programming-guide/#applying-transforms\">sintaxe especial para definir e invocar transformações</a>. Por exemplo, nesta linha:\n",
        "\n",
        "```\n",
        "result = pass_this | 'name this step' >> to_this_call\n",
        "```\n",
        "\n",
        "O método `to_this_call` está sendo invocado e passado ao objeto chamado `pass_this`, e <a target=\"_blank\" href=\"https://stackoverflow.com/questions/50519662/what-does-the-redirection-mean-in-apache-beam-python\">esta operação será chamada de <code>name this step</code> num rastreamento de pilha</a>. O resultado da chamada para `to_this_call` é retornado em `result`. Freqüentemente, você verá estágios de um pipeline encadeados assim:\n",
        "\n",
        "```\n",
        "result = apache_beam.Pipeline() | 'first step' >> do_this_first() | 'second step' >> do_this_last()\n",
        "```\n",
        "\n",
        "e como isso começou com um novo pipeline, você pode continuar assim:\n",
        "\n",
        "```\n",
        "next_result = result | 'doing more stuff' >> another_function()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kLDSxOQ8xgg"
      },
      "source": [
        "## Juntando tudo\n",
        "\n",
        "Agora estamos prontos para transformar nossos dados. Usaremos o Apache Beam com um executor direto e forneceremos três entradas:\n",
        "\n",
        "1. `raw_data` – Os dados de entrada brutos que criamos acima\n",
        "2. `raw_data_metadata` – O esquema para os dados brutos\n",
        "3. `preprocessing_fn` – A função que criamos para fazer nossa transformação"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mAF9w7RTZU7c"
      },
      "outputs": [],
      "source": [
        "def main(output_dir):\n",
        "  # Ignore the warnings\n",
        "  with tft_beam.Context(temp_dir=tempfile.mkdtemp()):\n",
        "    transformed_dataset, transform_fn = (  # pylint: disable=unused-variable\n",
        "        (raw_data, raw_data_metadata) | tft_beam.AnalyzeAndTransformDataset(\n",
        "            preprocessing_fn))\n",
        "\n",
        "  transformed_data, transformed_metadata = transformed_dataset  # pylint: disable=unused-variable\n",
        "\n",
        "  # Save the transform_fn to the output_dir\n",
        "  _ = (\n",
        "      transform_fn\n",
        "      | 'WriteTransformFn' >> tft_beam.WriteTransformFn(output_dir))\n",
        "\n",
        "  return transformed_data, transformed_metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zZPQl0X19ni2"
      },
      "outputs": [],
      "source": [
        "output_dir = pathlib.Path(tempfile.mkdtemp())\n",
        "\n",
        "transformed_data, transformed_metadata = main(str(output_dir))\n",
        "\n",
        "print('\\nRaw data:\\n{}\\n'.format(pprint.pformat(raw_data)))\n",
        "print('Transformed data:\\n{}'.format(pprint.pformat(transformed_data)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NO6LyTneNndy"
      },
      "source": [
        "## Será que esta é a resposta certa?\n",
        "\n",
        "Previamente, usamos o `tf.Transform` para fazer o seguinte:\n",
        "\n",
        "```\n",
        "x_centered = x - tft.mean(x)\n",
        "y_normalized = tft.scale_to_0_1(y)\n",
        "s_integerized = tft.compute_and_apply_vocabulary(s)\n",
        "x_centered_times_y_normalized = (x_centered * y_normalized)\n",
        "```\n",
        "\n",
        "- **x_centered** - Com entrada de `[1, 2, 3]` a média de x é 2, e subtraímos de x para centralizar nossos valores de x em 0. Portanto, nosso resultado de `[-1.0, 0.0, 1.0]` está correto.\n",
        "- **y_normalized** - Queríamos dimensionar nossos valores de y entre 0 e 1. Nossa entrada foi `[1, 2, 3]`, então nosso resultado de `[0.0, 0.5, 1.0]` está correto.\n",
        "- **s_integerized** - Queríamos mapear nossas strings para índices em um vocabulário e havia apenas 2 palavras em nosso vocabulário (\"hello\" e \"world\"). Portanto, com a entrada de `[\"hello\", \"world\", \"hello\"]` nosso resultado de `[0, 1, 0]` está correto. Como “olá” ocorre com mais frequência nesses dados, será a primeira entrada no vocabulário.\n",
        "- **x_centered_times_y_normalized** - Queríamos criar uma nova característicaa cruzando `x_centered` e `y_normalized` usando multiplicação. Observe que isso multiplica os resultados, não os valores originais, e nosso novo resultado de `[-0.0, 0.0, 1.0]` está correto."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXw790Sr8Jws"
      },
      "source": [
        "## Use o `transform_fn` resultante"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "We4Mafrq8id6"
      },
      "outputs": [],
      "source": [
        "!ls -l {output_dir}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SoaaAXxk_vWP"
      },
      "source": [
        "O diretório `transform_fn/` contém uma implementação de `tf.saved_model` com todos os resultados da análise das constantes do Tensorflow Transform incorporadas ao grafo.\n",
        "\n",
        "É possível carregar isso diretamente com `tf.saved_model.load`, mas não é fácil de usar:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cz8dqFW6ANJQ"
      },
      "outputs": [],
      "source": [
        "loaded = tf.saved_model.load(str(output_dir/'transform_fn'))\n",
        "loaded.signatures['serving_default']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCugaxMiBosA"
      },
      "source": [
        "Uma abordagem melhor seria carregá-lo usando `tft.TFTransformOutput`. O método `TFTransformOutput.transform_features_layer` retorna um objeto `tft.TransformFeaturesLayer` que pode ser usado para aplicar a transformação:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HNd4r2gJ75nx"
      },
      "outputs": [],
      "source": [
        "tf_transform_output = tft.TFTransformOutput(output_dir)\n",
        "\n",
        "tft_layer = tf_transform_output.transform_features_layer()\n",
        "tft_layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "se-M1zx49kTY"
      },
      "source": [
        "Este `tft.TransformFeaturesLayer` espera um dicionário de características em lote. Portanto, crie um `Dict[str, tf.Tensor]` de `List[Dict[str, Any]]` em `raw_data`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2nyE1fVj82Gp"
      },
      "outputs": [],
      "source": [
        "raw_data_batch = {\n",
        "    's': tf.constant([ex['s'] for ex in raw_data]),\n",
        "    'x': tf.constant([ex['x'] for ex in raw_data], dtype=tf.float32),\n",
        "    'y': tf.constant([ex['y'] for ex in raw_data], dtype=tf.float32),\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "016sJ_cD_gVC"
      },
      "source": [
        "Você pode usar o `tft.TransformFeaturesLayer` de forma independente:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fIXJYE0Z9Mrs"
      },
      "outputs": [],
      "source": [
        "transformed_batch = tft_layer(raw_data_batch)\n",
        "\n",
        "{key: value.numpy() for key, value in transformed_batch.items()}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBfO5cp-8pqb"
      },
      "source": [
        "## Exportação"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3SN7D-FzrZ3"
      },
      "source": [
        "Um caso de uso mais típico seria usar `tf.Transform` para aplicar a transformação aos datasets de treinamento e avaliação (veja um exemplo no [próximo tutorial](census.ipynb)). Nesse caso, após o treinamento, antes de exportar o modelo, anexe o `tft.TransformFeaturesLayer` como a primeira camada para que você possa exportá-lo como parte do seu `tf.saved_model`. Para um exemplo concreto, continue lendo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYV_oy5s9Dn9"
      },
      "source": [
        "### Um exemplo de modelo de treinamento\n",
        "\n",
        "Abaixo temos um modelo que:\n",
        "\n",
        "1. recebe o lote transformado,\n",
        "2. empilha tudo numa matriz `(batch, features)` simples,\n",
        "3. passa todos por algumas camadas densas e\n",
        "4. produz 10 saídas lineares.\n",
        "\n",
        "Num caso de uso real, você aplicaria um one-hot à característica `s_integerized`.\n",
        "\n",
        "Você poderia treinar este modelo num dataset transformado por `tf.Transform`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xWiEo1ZUzp4x"
      },
      "outputs": [],
      "source": [
        "class StackDict(tf.keras.layers.Layer):\n",
        "  def call(self, inputs):\n",
        "    values = [\n",
        "        tf.cast(v, tf.float32)\n",
        "        for k,v in sorted(inputs.items(), key=lambda kv: kv[0])]\n",
        "    return tf.stack(values, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A0QJpoWT1aUD"
      },
      "outputs": [],
      "source": [
        "class TrainedModel(tf.keras.Model):\n",
        "  def __init__(self):\n",
        "    super().__init__(self)\n",
        "    self.concat = StackDict()\n",
        "    self.body = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.Dense(10),\n",
        "    ])\n",
        "\n",
        "  def call(self, inputs, training=None):\n",
        "    x = self.concat(inputs)\n",
        "    return self.body(x, training)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DkMwREIx2fkD"
      },
      "outputs": [],
      "source": [
        "trained_model = TrainedModel()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBwnbh1Q-TBK"
      },
      "source": [
        "Imagine que treinamos o modelo.\n",
        "\n",
        "```\n",
        "trained_model.compile(loss=..., optimizer='adam')\n",
        "trained_model.fit(...)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "notFxUC0AFs6"
      },
      "source": [
        "Este modelo é executado nas entradas transformadas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d2KJ8nGt228O"
      },
      "outputs": [],
      "source": [
        "trained_model_output = trained_model(transformed_batch)\n",
        "trained_model_output.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzWs35Ki6M5c"
      },
      "source": [
        "### Um exemplo de wrapper de exportação\n",
        "\n",
        "Imagine que você treinou o modelo acima e deseja exportá-lo.\n",
        "\n",
        "Você vai querer incluir a função de transformação no modelo exportado:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pe-nbN123qUt"
      },
      "outputs": [],
      "source": [
        "class ExportModel(tf.Module):\n",
        "  def __init__(self, trained_model, input_transform):\n",
        "    self.trained_model = trained_model\n",
        "    self.input_transform = input_transform\n",
        "\n",
        "  @tf.function\n",
        "  def __call__(self, inputs, training=None):\n",
        "    x = self.input_transform(inputs)\n",
        "    return self.trained_model(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iLUIO-Y87AC0"
      },
      "outputs": [],
      "source": [
        "export_model = ExportModel(trained_model=trained_model,\n",
        "                           input_transform=tft_layer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFDYQDgU7ozE"
      },
      "source": [
        "Esse modelo combinado funciona com dados brutos e produz exatamente os mesmos resultados que chamar diretamente o modelo treinado:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AqwHTex27ILk"
      },
      "outputs": [],
      "source": [
        "export_model_output = export_model(raw_data_batch)\n",
        "export_model_output.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AZQ6_Dfd7xws"
      },
      "outputs": [],
      "source": [
        "tf.reduce_max(abs(export_model_output - trained_model_output)).numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5r-lH_nh8PM-"
      },
      "source": [
        "Este `export_model` inclui o `tft.TransformFeaturesLayer` e é totalmente independente. Você pode salvá-lo e restaurá-lo em outro ambiente e ainda obter exatamente o mesmo resultado:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VK17CShl8F7s"
      },
      "outputs": [],
      "source": [
        "import tempfile\n",
        "model_dir = tempfile.mkdtemp(suffix='tft')\n",
        "\n",
        "tf.saved_model.save(export_model, model_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RTF-yRnA9yrL"
      },
      "outputs": [],
      "source": [
        "reloaded = tf.saved_model.load(model_dir)\n",
        "\n",
        "reloaded_model_output = reloaded(raw_data_batch)\n",
        "reloaded_model_output.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFx1I6FQ9_mj"
      },
      "outputs": [],
      "source": [
        "tf.reduce_max(abs(export_model_output - reloaded_model_output)).numpy()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "tghWegsjhpkt",
        "cSl9qyTCbBKR",
        "NO6LyTneNndy"
      ],
      "name": "simple.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
