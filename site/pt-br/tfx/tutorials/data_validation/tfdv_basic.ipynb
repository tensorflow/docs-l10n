{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tghWegsjhpkt"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "rSGJWC5biBiG"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YuSYVbwEYNHw"
      },
      "source": [
        "# TensorFlow Data Validation\n",
        "\n",
        "***Exemplo de um componente chave do TensorFlow Extended (TFX)***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLsMb4vqY244"
      },
      "source": [
        "Observação: você pode executar este exemplo agora mesmo num notebook estilo Jupyter, sem necessidade de configuração! Basta clicar em \"Executar no Google Colab\"\n",
        "\n",
        "<div class=\"devsite-table-wrapper\"><table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "<td>     <a target=\"_blank\" href=\"https://www.tensorflow.org/tfx/tutorials/data_validation/tfdv_basic\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver em TensorFlow.org</a>\n",
        "</td>\n",
        "<td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/pt-br/tfx/tutorials/data_validation/tfdv_basic.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Executar no Google Colab</a></td>\n",
        "<td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/pt-br/tfx/tutorials/data_validation/tfdv_basic.ipynb\"><img width=\"32px\" src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver fonte no GitHub</a>\n",
        "</td>\n",
        "<td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/pt-br/tfx/tutorials/data_validation/tfdv_basic.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Baixar notebook</a>\n",
        "</td>\n",
        "</table></div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPt5BHTwy_0F"
      },
      "source": [
        "Este exemplo de notebook colab ilustra como o TensorFlow  Data Validation (TFDV) pode ser usado para investigar e visualizar seu dataset. Isto inclui examinar estatísticas descritivas, inferir um esquema, verificar e corrigir anomalias e verificar deriva e desvios em nosso dataset. É importante compreender as características do seu dataset, incluindo como ele pode mudar ao longo do tempo no seu pipeline de produção. Também é importante procurar anomalias nos seus dados e comparar os seus datasets de treinamento, avaliação e serviço para garantir que são consistentes.\n",
        "\n",
        "Usaremos o [dataset Taxi Trips](https://data.cityofchicago.org/Transportation/Taxi-Trips/wrvz-psew) disponibilizado pela cidade de Chicago.\n",
        "\n",
        "Observação: Este site fornece aplicativos que utilizam dados que foram modificados para uso a partir de sua fonte original obtida em www.cityofchicago.org, site oficial da cidade de Chicago. A cidade de Chicago não faz nenhuma reivindicação quanto ao conteúdo, precisão, atualidade ou integridade de qualquer um dos dados fornecidos neste site. Os dados fornecidos neste site estão sujeitos a alterações a qualquer momento. Entende-se que os dados fornecidos neste site são utilizados por sua conta e risco.\n",
        "\n",
        "[Leia mais](https://cloud.google.com/bigquery/public-data/chicago-taxi) sobre o dataset no [Google BigQuery](https://cloud.google.com/bigquery/). Explore o dataset completo no [BigQuery UI](https://bigquery.cloud.google.com/dataset/bigquery-public-data:chicago_taxi_trips).\n",
        "\n",
        "Ponto-chave: como modelador e desenvolvedor, pense em como esses dados são usados ​​e nos possíveis benefícios e danos que as previsões de um modelo podem causar. Um modelo como este poderia reforçar um viés social e disparidades. Uma determinada característica é relevante para o problema que você quer resolver ou será que ela vai introduzir um viés? Para mais informações, leia sobre [Equidade em ML](https://developers.google.com/machine-learning/fairness-overview/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fnm6Mj3vTGLm"
      },
      "source": [
        "As colunas do dataset são:\n",
        "\n",
        "<table>\n",
        "<tr>\n",
        "<td>pickup_community_area</td>\n",
        "<td>fare</td>\n",
        "<td>trip_start_month</td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>trip_start_hour</td>\n",
        "<td>trip_start_day</td>\n",
        "<td>trip_start_timestamp</td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>pickup_latitude</td>\n",
        "<td>pickup_longitude</td>\n",
        "<td>dropoff_latitude</td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>dropoff_longitude</td>\n",
        "<td>trip_miles</td>\n",
        "<td>pickup_census_tract</td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>dropoff_census_tract</td>\n",
        "<td>payment_type</td>\n",
        "<td>company</td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>trip_seconds</td>\n",
        "<td>dropoff_community_area</td>\n",
        "<td>tips</td>\n",
        "</tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsYC3O-DnYro"
      },
      "source": [
        "## Instale e importe os pacotes\n",
        "\n",
        "Instale os pacotes para o TensorFlow Data Validation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATF_g5c2g2Ha"
      },
      "source": [
        "### Atualize o Pip\n",
        "\n",
        "Para evitar a atualização do Pip num sistema ao executar localmente, garanta que estamos executando no Colab. Os sistemas locais podem, claro, ser atualizados separadamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b0ISmRq3nY3-"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  import colab\n",
        "  !pip install --upgrade pip\n",
        "except:\n",
        "  pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qBFH1ARcSNk"
      },
      "source": [
        "### Instale os pacotes do Data Validation\n",
        "\n",
        "Instale os pacotes e dependências do TensorFlow Data Validation, o que leva alguns minutos. Você poderá ver avisos e erros relacionados a versões de dependências incompatíveis, que serão resolvidos na próxima seção."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hPJsE5Gkdp8m"
      },
      "outputs": [],
      "source": [
        "print('Installing TensorFlow Data Validation')\n",
        "!pip install --upgrade 'tensorflow_data_validation[visualization]<2'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_NXX5GaSiZx"
      },
      "source": [
        "### Importe o TensorFlow e recarregue os pacotes atualizados\n",
        "\n",
        "A etapa anterior atualiza os pacotes padrão no ambiente Google Colab, portanto, você deve recarregar os recursos do pacote para resolver as novas dependências.\n",
        "\n",
        "Observação: Esta etapa resolve o erro de dependência da instalação. Se você ainda estiver enfrentando problemas de execução de código depois de executar esse código, reinicie o runtime (Runtime &gt; Restart runtime...)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E2j9VD9HbGWw"
      },
      "outputs": [],
      "source": [
        "import pkg_resources\n",
        "import importlib\n",
        "importlib.reload(pkg_resources)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFXK2AdpSpv0"
      },
      "source": [
        "Confira as versões do TensorFlow e do Data Validation antes de continuar. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F5rPatTDSCHB"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_data_validation as tfdv\n",
        "print('TF version:', tf.__version__)\n",
        "print('TFDV version:', tfdv.version.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5MizoHg1DRlK"
      },
      "source": [
        "## Carregue o dataset\n",
        "\n",
        "Baixaremos nosso dataset do Google Cloud Storage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x5gfFiTeDa6Y"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tempfile, urllib, zipfile\n",
        "\n",
        "# Set up some globals for our file paths\n",
        "BASE_DIR = tempfile.mkdtemp()\n",
        "DATA_DIR = os.path.join(BASE_DIR, 'data')\n",
        "OUTPUT_DIR = os.path.join(BASE_DIR, 'chicago_taxi_output')\n",
        "TRAIN_DATA = os.path.join(DATA_DIR, 'train', 'data.csv')\n",
        "EVAL_DATA = os.path.join(DATA_DIR, 'eval', 'data.csv')\n",
        "SERVING_DATA = os.path.join(DATA_DIR, 'serving', 'data.csv')\n",
        "\n",
        "# Download the zip file from GCP and unzip it\n",
        "zip, headers = urllib.request.urlretrieve('https://storage.googleapis.com/artifacts.tfx-oss-public.appspot.com/datasets/chicago_data.zip')\n",
        "zipfile.ZipFile(zip).extractall(BASE_DIR)\n",
        "zipfile.ZipFile(zip).close()\n",
        "\n",
        "print(\"Here's what we downloaded:\")\n",
        "!ls -R {os.path.join(BASE_DIR, 'data')}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0sFmiTbT8-x"
      },
      "source": [
        "## Compute e visualize estatísticas\n",
        "\n",
        "Primeiro usaremos o [`tfdv.generate_statistics_from_csv`](https://www.tensorflow.org/tfx/data_validation/api_docs/python/tfdv/generate_statistics_from_csv) para computar estatísticas para nossos dados de treinamento. (ignore os avisos rápidos)\n",
        "\n",
        "O TFDV pode computar [estatísticas](https://github.com/tensorflow/metadata/blob/v0.6.0/tensorflow_metadata/proto/v0/statistics.proto) descritivas que fornecem uma visão geral rápida dos dados em termos das características presentes e das formas de suas distribuições de valor.\n",
        "\n",
        "Internamente, o TFDV usa o framework de processamento paralelo de dados do [Apache Beam](https://beam.apache.org/) para dimensionar a computação de estatísticas em grandes datasets. Para aplicações que desejam uma integração mais profunda com TFDV (por exemplo, anexar geração de estatísticas no final de um pipeline de geração de dados), a API também expõe um Beam PTransform para geração de estatísticas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EE481oMbT-H0"
      },
      "outputs": [],
      "source": [
        "train_stats = tfdv.generate_statistics_from_csv(data_location=TRAIN_DATA)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhXQSxJ2dB_6"
      },
      "source": [
        "Agora vamos usar o [`tfdv.visualize_statistics`](https://www.tensorflow.org/tfx/data_validation/api_docs/python/tfdv/visualize_statistics), que usa [Facets](https://pair-code.github.io/facets/) para criar uma visualização sucinta dos nossos dados de treinamento:\n",
        "\n",
        "- Observe que as características numéricas e as características categóricas são visualizadas separadamente e que os gráficos são exibidos mostrando as distribuições de cada característica.\n",
        "- Observe que as características com valores ausentes ou zero exibem uma porcentagem em vermelho como um indicador visual de que pode haver problemas com exemplos nessas características. A porcentagem é a porcentagem de exemplos que possuem valores ausentes ou nulos para essa características.\n",
        "- Observe que não há exemplos com valores para `pickup_census_tract`. Esta é uma oportunidade para redução de dimensionalidade!\n",
        "- Experimente clicar em \"expandir\" acima dos gráficos para alterar a exibição\n",
        "- Experimente passar o mouse sobre as barras nos gráficos para exibir contagens e intervalos de buckets\n",
        "- Experimente alternar entre as escalas logarítmica e linear e observe como a escala logarítmica revela muito mais detalhes sobre a característica categórica `payment_type`\n",
        "- Experimente selecionar \"quantiles\" no menu \"Chart to show\" e passe o mouse sobre os marcadores para mostrar as porcentagens de quantis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U3tUKgh7Up3x"
      },
      "outputs": [],
      "source": [
        "# docs-infra: no-execute\n",
        "tfdv.visualize_statistics(train_stats)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xoc0ijE5LYeQ"
      },
      "source": [
        "<!-- <img class=\"tfo-display-only-on-site\" src=\"images/statistics.png\"/> -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVR02-y4V0uM"
      },
      "source": [
        "## Infira um esquema\n",
        "\n",
        "Agora vamos usar [`tfdv.infer_schema`](https://www.tensorflow.org/tfx/data_validation/api_docs/python/tfdv/infer_schema) para criar um esquema para nossos dados. Um esquema define restrições para os dados que são relevantes para ML. Exemplos de restrições incluem o tipo de dados de cada característica, seja numérico ou categórico, ou a frequência de sua presença nos dados. Para características categóricas, o esquema também define o domínio – a lista de valores aceitáveis. Como escrever um esquema pode ser uma tarefa chata, especialmente para datasets com muitas características, o TFDV fornece um método para gerar uma versão inicial do esquema com base nas estatísticas descritivas.\n",
        "\n",
        "Acertar o esquema é importante porque o resto do nosso pipeline de produção dependerá do esquema que o TFDV gera para estar correto. O esquema também fornece documentação para os dados e, portanto, é útil quando diferentes desenvolvedores trabalham nos mesmos dados. Vamos usar [`tfdv.display_schema`](https://www.tensorflow.org/tfx/data_validation/api_docs/python/tfdv/display_schema) para exibir o esquema inferido para que possamos revisá-lo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6LLkRJThVr9m"
      },
      "outputs": [],
      "source": [
        "schema = tfdv.infer_schema(statistics=train_stats)\n",
        "tfdv.display_schema(schema=schema)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVa3EXE8WEDE"
      },
      "source": [
        "## Confira os dados de avaliação em busca de erros\n",
        "\n",
        "Até agora, analisamos apenas os dados de treinamento. É importante que nossos dados de avaliação sejam consistentes com nossos dados de treinamento, inclusive que usem o mesmo esquema. Também é importante que os dados de avaliação incluam exemplos de aproximadamente os mesmos intervalos de valores para nossas características numéricas que nossos dados de treinamento, para que nossa cobertura da superfície de perda durante a avaliação seja aproximadamente a mesma que durante o treinamento. O mesmo se aplica a características categóricas. Caso contrário, poderemos ter problemas de treinamento que não serão identificados durante a avaliação, pois não avaliamos parte da nossa superfície de perdas.\n",
        "\n",
        "- Observe que cada característica agora inclui estatísticas para os datasets de treinamento e avaliação.\n",
        "- Observe que os gráficos agora têm os datasets de treinamento e avaliação sobrepostos, facilitando sua comparação.\n",
        "- Observe que os gráficos agora incluem uma visualização de porcentagens, que pode ser combinada com o log ou com as escalas lineares padrão.\n",
        "- Observe que a média e a mediana de `trip_miles` são diferentes para os datasets de treinamento e de avaliação. Isto causará problemas?\n",
        "- Uau, as `tips` (gorjetas) máximas são muito diferentes para os datasets de treinamento e de avaliação. Isto causará problemas?\n",
        "- Clique em expandir no gráfico Numeric Features e selecione a escala logarítmica. Revise a característica `trip_seconds` e observe a diferença no máximo. A avaliação perderá partes da superfície de perda?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j_P0RLYlV6XG"
      },
      "outputs": [],
      "source": [
        "# Compute stats for evaluation data\n",
        "eval_stats = tfdv.generate_statistics_from_csv(data_location=EVAL_DATA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qn-3fQWJLimn"
      },
      "outputs": [],
      "source": [
        "# docs-infra: no-execute\n",
        "# Compare evaluation data with training data\n",
        "tfdv.visualize_statistics(lhs_statistics=eval_stats, rhs_statistics=train_stats,\n",
        "                          lhs_name='EVAL_DATASET', rhs_name='TRAIN_DATASET')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MS4u82lzLeRh"
      },
      "source": [
        "<!-- <img class=\"tfo-display-only-on-site\" src=\"images/statistics_eval.png\"/> -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycRRa4leHp84"
      },
      "source": [
        "## Verifique se há anomalias de avaliação\n",
        "\n",
        "Será que nosso dataset de avaliação corresponde ao esquema do nosso dataset de treinamento? Isto é especialmente importante para características categóricas, onde queremos identificar o intervalo de valores aceitáveis.\n",
        "\n",
        "Ponto-chave: O que aconteceria se tentássemos avaliar usando dados com valores de características categóricas que não estivessem em nosso dataset de treinamento? E quanto às características numéricas que estão fora dos intervalos em nosso dataset de treinamento?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T7uGVeL2WOam"
      },
      "outputs": [],
      "source": [
        "# Check eval data for errors by validating the eval data stats using the previously inferred schema.\n",
        "anomalies = tfdv.validate_statistics(statistics=eval_stats, schema=schema)\n",
        "tfdv.display_anomalies(anomalies)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzxx1gBpJIBa"
      },
      "source": [
        "## Corrija anomalias de avaliação no esquema\n",
        "\n",
        "Ops! Parece que temos alguns valores novos para `company` em nossos dados de avaliação, que não tínhamos em nossos dados de treinamento. Também temos um novo valor para `payment_type`. Estas devem ser consideradas anomalias, mas o que decidimos fazer sobre elas depende do nosso conhecimento sobre o domínio dos dados. Se uma anomalia realmente indicar um erro de dados, os dados subjacentes deverão ser corrigidos. Caso contrário, podemos simplesmente atualizar o esquema para incluir os valores no dataset de avaliação.\n",
        "\n",
        "Ponto-chave: Como os resultados da nossa avaliação seriam afetados se não corrigíssemos esses problemas?\n",
        "\n",
        "A menos que alteremos nosso dataset de avaliação, não poderemos corrigir tudo, mas podemos corrigir coisas no esquema que nos sentimos confortáveis ​​em aceitar. Isto inclui relaxar nossa visão do que é e do que não é uma anomalia para características específicas, bem como atualizar nosso esquema para incluir valores ausentes para características categóricas. O TFDV nos permitiu descobrir o que precisamos corrigir.\n",
        "\n",
        "Vamos fazer essas correções agora e depois revisar mais uma vez."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "legN2nXLWZAc"
      },
      "outputs": [],
      "source": [
        "# Relax the minimum fraction of values that must come from the domain for feature company.\n",
        "company = tfdv.get_feature(schema, 'company')\n",
        "company.distribution_constraints.min_domain_mass = 0.9\n",
        "\n",
        "# Add new value to the domain of feature payment_type.\n",
        "payment_type_domain = tfdv.get_domain(schema, 'payment_type')\n",
        "payment_type_domain.value.append('Prcard')\n",
        "\n",
        "# Validate eval stats after updating the schema \n",
        "updated_anomalies = tfdv.validate_statistics(eval_stats, schema)\n",
        "tfdv.display_anomalies(updated_anomalies)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNo72YP9LN98"
      },
      "source": [
        "Ei, olha só isso! Verificamos que os dados de treinamento e avaliação agora são consistentes! Obrigado TFDV ;)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZ1P4ucHJj5o"
      },
      "source": [
        "## Ambientes de esquema"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qb179jczJppA"
      },
      "source": [
        "Também dividimos um dataset de 'serviço' para este exemplo, portanto, devemos verificar isso também. Por padrão, todos os datasets de um pipeline devem usar o mesmo esquema, mas muitas vezes há exceções. Por exemplo, na aprendizagem supervisionada precisamos incluir rótulos em nosso dataset, mas quando servimos o modelo para inferência os rótulos não serão incluídos. Em alguns casos, é necessária a introdução de pequenas variações de esquema.\n",
        "\n",
        "**Ambientes** (environments) podem ser usados ​​para expressar tais requisitos. Em particular, as características do esquema podem ser associadas a um conjunto de ambientes usando `default_environment`, `in_environment` e `not_in_environment`.\n",
        "\n",
        "Por exemplo, neste dataset, a característica `tips` está incluída como rótulo para treinamento, mas está faltando nos dados de veiculação. Sem o ambiente especificado, ela aparecerá como uma anomalia."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wSZfbnifJuTA"
      },
      "outputs": [],
      "source": [
        "serving_stats = tfdv.generate_statistics_from_csv(SERVING_DATA)\n",
        "serving_anomalies = tfdv.validate_statistics(serving_stats, schema)\n",
        "\n",
        "tfdv.display_anomalies(serving_anomalies)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDYHvZ09LfkT"
      },
      "source": [
        "Cuidaremos da característica `tips` abaixo. Também temos um valor INT em nossos segundos de viagem, onde nosso esquema esperava um FLOAT. Ao nos conscientizar dessa diferença, o TFDV ajuda a descobrir inconsistências na forma como os dados são gerados para treinamento e serviço. É muito fácil não ter consciência de problemas como esse até que o desempenho do modelo seja prejudicado, às vezes de forma catastrófica. Pode ou não ser um problema significativo, mas em qualquer caso, deve ser motivo para uma investigação mais aprofundada.\n",
        "\n",
        "Neste caso, podemos converter com segurança valores INT em FLOATs, por isso queremos dizer ao TFDV para usar nosso esquema para inferir o tipo. Vamos fazer isso agora."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OhtYF8aAczpd"
      },
      "outputs": [],
      "source": [
        "options = tfdv.StatsOptions(schema=schema, infer_type_from_schema=True)\n",
        "serving_stats = tfdv.generate_statistics_from_csv(SERVING_DATA, stats_options=options)\n",
        "serving_anomalies = tfdv.validate_statistics(serving_stats, schema)\n",
        "\n",
        "tfdv.display_anomalies(serving_anomalies)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJjh5rigc5xy"
      },
      "source": [
        "Agora só temos a característica `tips` (que é o nosso rótulo) aparecendo como uma anomalia ('Coluna descartada'). É claro que não esperamos ter rótulos em nossos dados de serviço, então vamos dizer ao TFDV para ignorar isso."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bnbnw8H6Lp2M"
      },
      "outputs": [],
      "source": [
        "# All features are by default in both TRAINING and SERVING environments.\n",
        "schema.default_environment.append('TRAINING')\n",
        "schema.default_environment.append('SERVING')\n",
        "\n",
        "# Specify that 'tips' feature is not in SERVING environment.\n",
        "tfdv.get_feature(schema, 'tips').not_in_environment.append('SERVING')\n",
        "\n",
        "serving_anomalies_with_env = tfdv.validate_statistics(\n",
        "    serving_stats, schema, environment='SERVING')\n",
        "\n",
        "tfdv.display_anomalies(serving_anomalies_with_env)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yteMr3AGMYEp"
      },
      "source": [
        "## Verifique se há deriva e desvio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Ftd5k6AMkPV"
      },
      "source": [
        "Além de verificar se um dataset está em conformidade com as expectativas definidas no esquema, o TFDV também fornece funcionalidades para detectar derivas e desvios. O TFDV realiza essa verificação comparando as estatísticas dos diferentes datasets com base nos comparadores de deriva/desvio especificados no esquema.\n",
        "\n",
        "### Drift (deriva)\n",
        "\n",
        "A detecção de deriva (drift) é suportada para características categóricas e entre spans consecutivos de dados (ou seja, entre o span N e o span N+1), como entre diferentes dias de dados de treinamento. Expressamos a deriva em termos de [distância L-infinito](https://en.wikipedia.org/wiki/Chebyshev_distance) e você pode definir a distância limite para receber avisos quando a deriva for maior do que o aceitável. Definir a distância correta normalmente é um processo iterativo que requer conhecimento do domínio e experimentação."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBFuLpXb6qSp"
      },
      "source": [
        "### Skew (desvio)\n",
        "\n",
        "O TFDV pode detectar três tipos diferentes de desvio em seus dados: desvio de esquema, desvio de característica e desvio de distribuição.\n",
        "\n",
        "#### Desvio de esquema\n",
        "\n",
        "O desvio de esquema ocorre quando os dados de treinamento e entrega não estão em conformidade com o mesmo esquema. Espera-se que os dados de treinamento e de entrega sigam o mesmo esquema. Quaisquer desvios esperados entre os dois (como a característica de rótulo estar presente apenas nos dados de treinamento, mas não no serviço) devem ser especificados por meio do campo de ambientes (environments) no esquema.\n",
        "\n",
        "#### Desvio de características\n",
        "\n",
        "O desvio de características ocorre quando os valores de características nos quais um modelo é treinado são diferentes dos valores de características que ele vê no momento do serviço. Por exemplo, isto pode acontecer quando:\n",
        "\n",
        "- Uma fonte de dados que fornece alguns valores de características é modificada entre o tempo de treinamento e o tempo de serviço\n",
        "- Existe uma lógica diferente para gerar características entre treinar e servir. Por exemplo, se você aplicar alguma transformação apenas em um dos dois caminhos de código.\n",
        "\n",
        "#### Desvio de distribuição\n",
        "\n",
        "O desvio de distribuição ocorre quando a distribuição do dataset de treinamento é significativamente diferente da distribuição do dataset de serviço. Uma das principais causas do desvio de distribuição é o uso de código ou fontes de dados diferentes para gerar o dataset de treinamento. Outro motivo é um mecanismo de amostragem defeituoso que escolhe uma subamostra não representativa dos dados de serviço para treinar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wEUsZm_rOd1Q"
      },
      "outputs": [],
      "source": [
        "# Add skew comparator for 'payment_type' feature.\n",
        "payment_type = tfdv.get_feature(schema, 'payment_type')\n",
        "payment_type.skew_comparator.infinity_norm.threshold = 0.01\n",
        "\n",
        "# Add drift comparator for 'company' feature.\n",
        "company=tfdv.get_feature(schema, 'company')\n",
        "company.drift_comparator.infinity_norm.threshold = 0.001\n",
        "\n",
        "skew_anomalies = tfdv.validate_statistics(train_stats, schema,\n",
        "                                          previous_statistics=eval_stats,\n",
        "                                          serving_statistics=serving_stats)\n",
        "\n",
        "tfdv.display_anomalies(skew_anomalies)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GzbbsPgf0Bg"
      },
      "source": [
        "Neste exemplo, vemos alguma deriva, mas está bem abaixo do limite que definimos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJ5saC9eWvHx"
      },
      "source": [
        "## Congele o esquema\n",
        "\n",
        "Agora que o esquema foi revisado e selecionado, iremos armazená-lo num arquivo para refletir seu estado “congelado”."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ydkL4DkIWn18"
      },
      "outputs": [],
      "source": [
        "from tensorflow.python.lib.io import file_io\n",
        "from google.protobuf import text_format\n",
        "\n",
        "file_io.recursive_create_dir(OUTPUT_DIR)\n",
        "schema_file = os.path.join(OUTPUT_DIR, 'schema.pbtxt')\n",
        "tfdv.write_schema_text(schema, schema_file)\n",
        "\n",
        "!cat {schema_file}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8eC59yISdGB"
      },
      "source": [
        "## Quando usar o TFDV\n",
        "\n",
        "É fácil achar que o TFDV se aplica apenas ao início do seu pipeline de treinamento, como fizemos aqui, mas na verdade ele tem muitos usos. Aqui estão mais alguns:\n",
        "\n",
        "- Validar novos dados para inferência para garantir que não começamos repentinamente a receber características ruins\n",
        "- Validar novos dados para inferência para garantir que nosso modelo foi treinado naquela parte da superfície de decisão\n",
        "- Validar nossos dados depois de transformá-los e fazer engenharia de características (provavelmente usando [TensorFlow Transform](https://www.tensorflow.org/tfx/transform/get_started)) para garantir que não fizemos algo errado"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "tghWegsjhpkt"
      ],
      "name": "tfdv_basic.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
