{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdeKOEkv1Fe8"
      },
      "source": [
        "##### Copyright 2021 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "c2jyGuiG1gHr"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23R0Z9RojXYW"
      },
      "source": [
        "# Tutorial do componente TFX Keras\n",
        "\n",
        "***Uma introdução ao TensorFlow Extended (TFX) componente por componente***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LidV2qsXm4XC"
      },
      "source": [
        "Observação: recomendamos executar este tutorial em um notebook Colab, sem necessidade de configuração! Basta clicar em “Executar no Google Colab”.\n",
        "\n",
        "<div class=\"devsite-table-wrapper\"><table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "<td>     <a target=\"_blank\" href=\"https://www.tensorflow.org/tfx/tutorials/tfx/components_keras\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver em TensorFlow.org</a>\n",
        "</td>\n",
        "<td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/pt-br/tfx/tutorials/tfx/components_keras.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Executar no Google Colab</a></td>\n",
        "<td><a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/pt-br/tfx/tutorials/tfx/components_keras.ipynb\"><img width=\"32px\" src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver fonte no GitHub</a></td>\n",
        "<td>     <a target=\"_blank\" href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/pt-br/tfx/tutorials/tfx/components_keras.ipynb\"><img width=\"32px\" src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Baixar notebook</a>\n",
        "</td>\n",
        "</table></div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAD1tLoTm_QS"
      },
      "source": [
        "Este tutorial baseado em Colab percorrerá interativamente cada componente integrado do TensorFlow Extended (TFX).\n",
        "\n",
        "Ele cobre todas as etapas de um pipeline de aprendizado de máquina de ponta a ponta, desde a ingestão de dados até o envio de um modelo até a disponibilização do serviço.\n",
        "\n",
        "Quando terminar, o conteúdo deste notebook poderá ser exportado automaticamente como código-fonte do pipeline TFX, que você poderá orquestrar com Apache Airflow e Apache Beam.\n",
        "\n",
        "Observação: este notebook demonstra o uso de modelos Keras nativos em pipelines do TFX. **O TFX oferece suporte apenas à versão TensorFlow 2 do Keras**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfSQ-kX-MLEr"
      },
      "source": [
        "## Contexto\n",
        "\n",
        "Este notebook demonstra como usar o TFX num ambiente Jupyter/Colab. Aqui, percorremos o exemplo do Chicago Taxi em um notebook interativo.\n",
        "\n",
        "Trabalhar com um notebook interativo é uma maneira útil de se familiarizar com a estrutura de um pipeline TFX. Também é útil ao desenvolver seus próprios pipelines como um ambiente de desenvolvimento leve, mas você deve estar ciente de que há diferenças na forma como os notebooks interativos são orquestrados e como eles acessam artefatos de metadados.\n",
        "\n",
        "### Orquestração\n",
        "\n",
        "Numa implantação TFX em produção, você usará um orquestrador como Apache Airflow, Kubeflow Pipelines ou Apache Beam para orquestrar o grafo de um pipeline predefinido de componentes do TFX. Num notebook interativo, o próprio notebook é o orquestrador, executando cada componente do TFX conforme você executa as células do notebook.\n",
        "\n",
        "### Metadados\n",
        "\n",
        "Numa implantação do TFX em produção, você acessará metadados por meio da API ML Metadata (MLMD). O MLMD armazena propriedades de metadados num banco de dados como MySQL ou SQLite e armazena as payloads de metadados em armazenamento persistente, como seu sistema de arquivos. Num notebook interativo, as propriedades e as cargas são armazenadas num banco de dados SQLite efêmero no diretório `/tmp` do notebook Jupyter ou do servidor Colab."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GivNBNYjb3b"
      },
      "source": [
        "## Configuração\n",
        "\n",
        "Primeiro, instalamos e importamos os pacotes necessários, configuramos caminhos e baixamos os dados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fmgi8ZvQkScg"
      },
      "source": [
        "### Atualize o Pip\n",
        "\n",
        "Para evitar a atualização do Pip num sistema ao executar localmente, garanta que estamos executando no Colab. Os sistemas locais podem, claro, ser atualizados separadamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "as4OTe2ukSqm"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "if 'google.colab' in sys.modules:\n",
        "  !pip install --upgrade pip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZOYTt1RW4TK"
      },
      "source": [
        "### Instale o TFX\n",
        "\n",
        "**Observação: no Google Colab, devido a atualizações de pacotes, na primeira vez que você executar esta célula você deverá reiniciar o runtime (Runtime &gt; Restart runtime...).**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S4SQA7Q5nej3"
      },
      "outputs": [],
      "source": [
        "!pip install tfx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LsH2nlJckghc"
      },
      "source": [
        "### Desinstale o shapely\n",
        "\n",
        "TODO(b/263441833) Esta é uma solução temporária para evitar um ImportError. Em última análise, isto deverá ser resolvido com suporte a uma versão mais recente do Bigquery, em vez de desinstalar outras dependências extras."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7kp0dFH9kgza"
      },
      "outputs": [],
      "source": [
        "!pip uninstall shapely -y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwT0nov5QO1M"
      },
      "source": [
        "## Você reiniciou o runtime?\n",
        "\n",
        "Se você estiver usando o Google Colab, na primeira vez que executar a célula acima, você deve reiniciar o runtime (\"Runtime &gt; Restart runtime ...\"). Isso é necessário devido à maneira como o Colab carrega os pacotes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-ePgV0Lj68Q"
      },
      "source": [
        "### Importe os pacotes\n",
        "\n",
        "Importamos os pacotes necessários, incluindo classes de componentes TFX padrão."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YIqpWK9efviJ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pprint\n",
        "import tempfile\n",
        "import urllib\n",
        "\n",
        "import absl\n",
        "import tensorflow as tf\n",
        "import tensorflow_model_analysis as tfma\n",
        "tf.get_logger().propagate = False\n",
        "pp = pprint.PrettyPrinter()\n",
        "\n",
        "from tfx import v1 as tfx\n",
        "from tfx.orchestration.experimental.interactive.interactive_context import InteractiveContext\n",
        "\n",
        "%load_ext tfx.orchestration.experimental.interactive.notebook_extensions.skip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCZTHRy0N1D6"
      },
      "source": [
        "Vamos verificar as versões das bibliotecas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eZ4K18_DN2D8"
      },
      "outputs": [],
      "source": [
        "print('TensorFlow version: {}'.format(tf.__version__))\n",
        "print('TFX version: {}'.format(tfx.__version__))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufJKQ6OvkJlY"
      },
      "source": [
        "### Configure os caminhos do pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ad5JLpKbf6sN"
      },
      "outputs": [],
      "source": [
        "# This is the root directory for your TFX pip package installation.\n",
        "_tfx_root = tfx.__path__[0]\n",
        "\n",
        "# This is the directory containing the TFX Chicago Taxi Pipeline example.\n",
        "_taxi_root = os.path.join(_tfx_root, 'examples/chicago_taxi_pipeline')\n",
        "\n",
        "# This is the path where your model will be pushed for serving.\n",
        "_serving_model_dir = os.path.join(\n",
        "    tempfile.mkdtemp(), 'serving_model/taxi_simple')\n",
        "\n",
        "# Set up logging.\n",
        "absl.logging.set_verbosity(absl.logging.INFO)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2cMMAbSkGfX"
      },
      "source": [
        "### Baixe dados de exemplo\n",
        "\n",
        "Baixamos o dataset de exemplo para uso em nosso pipeline TFX.\n",
        "\n",
        "O dataset que estamos usando é o [dataset Taxi Trips](https://data.cityofchicago.org/Transportation/Taxi-Trips/wrvz-psew) disponibilizado pela cidade de Chicago. As colunas neste dataset são:\n",
        "\n",
        "<table>\n",
        "<tr>\n",
        "<td>pickup_community_area</td>\n",
        "<td>fare</td>\n",
        "<td>trip_start_month</td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>trip_start_hour</td>\n",
        "<td>trip_start_day</td>\n",
        "<td>trip_start_timestamp</td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>pickup_latitude</td>\n",
        "<td>pickup_longitude</td>\n",
        "<td>dropoff_latitude</td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>dropoff_longitude</td>\n",
        "<td>trip_miles</td>\n",
        "<td>pickup_census_tract</td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>dropoff_census_tract</td>\n",
        "<td>payment_type</td>\n",
        "<td>company</td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>trip_seconds</td>\n",
        "<td>dropoff_community_area</td>\n",
        "<td>tips</td>\n",
        "</tr>\n",
        "</table>\n",
        "\n",
        "Com esse dataset, construiremos um modelo que irá prever as `tips` (gorjetas) de uma viagem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BywX6OUEhAqn"
      },
      "outputs": [],
      "source": [
        "_data_root = tempfile.mkdtemp(prefix='tfx-data')\n",
        "DATA_PATH = 'https://raw.githubusercontent.com/tensorflow/tfx/master/tfx/examples/chicago_taxi_pipeline/data/simple/data.csv'\n",
        "_data_filepath = os.path.join(_data_root, \"data.csv\")\n",
        "urllib.request.urlretrieve(DATA_PATH, _data_filepath)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blZC1sIQOWfH"
      },
      "source": [
        "Dê uma olhada rápida no arquivo CSV."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c5YPeLPFOXaD"
      },
      "outputs": [],
      "source": [
        "!head {_data_filepath}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QioyhunCImwE"
      },
      "source": [
        "*Observação: Este site fornece aplicativos que utilizam dados que foram modificados para uso a partir de sua fonte original obtida em www.cityofchicago.org, site oficial da cidade de Chicago. A cidade de Chicago não faz nenhuma reivindicação quanto ao conteúdo, precisão, atualidade ou integridade de qualquer um dos dados fornecidos neste site. Os dados fornecidos neste site estão sujeitos a alterações a qualquer momento. Entende-se que os dados fornecidos neste site são utilizados por sua conta e risco.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ONIE_hdkPS4"
      },
      "source": [
        "### Crie o InteractiveContext\n",
        "\n",
        "Por último, criamos um InteractiveContext, que nos permitirá executar componentes TFX interativamente neste notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Rh6K5sUf9dd"
      },
      "outputs": [],
      "source": [
        "# Here, we create an InteractiveContext using default parameters. This will\n",
        "# use a temporary directory with an ephemeral ML Metadata database instance.\n",
        "# To use your own pipeline root or database, the optional properties\n",
        "# `pipeline_root` and `metadata_connection_config` may be passed to\n",
        "# InteractiveContext. Calls to InteractiveContext are no-ops outside of the\n",
        "# notebook.\n",
        "context = InteractiveContext()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdQWxfsVkzdJ"
      },
      "source": [
        "## Execute componentes TFX interativamente\n",
        "\n",
        "Nas células a seguir, criamos os componentes TFX um por um, executamos cada um deles e visualizamos seus artefatos de saída."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9fwt9gQk3BR"
      },
      "source": [
        "### ExampleGen\n",
        "\n",
        "O componente `ExampleGen` geralmente está no início de um pipeline TFX. Ele vai:\n",
        "\n",
        "1. Dividir os dados em datasets de treinamento e avaliação (por padrão, 2/3 de treinamento + 1/3 de avaliação)\n",
        "2. Converter dados para o formato `tf.Example` (saiba mais [aqui](https://www.tensorflow.org/tutorials/load_data/tfrecord))\n",
        "3. Copiar dados para o diretório `_tfx_root` para que outros componentes possam acessar\n",
        "\n",
        "O `ExampleGen` toma como entrada o caminho para sua fonte de dados. No nosso caso, este é o caminho `_data_root` que contém o CSV baixado.\n",
        "\n",
        "Observação: neste notebook, podemos instanciar os componentes um por um e executá-los com `InteractiveContext.run()`. Por outro lado, num ambiente de produção, especificaríamos todos os componentes antecipadamente num `Pipeline` para passar ao orquestrador (veja o [Guia de criação de um pipeline TFX](https://www.tensorflow.org/tfx/guide/build_tfx_pipeline)).\n",
        "\n",
        "#### Ativando o Cache\n",
        "\n",
        "Ao usar o `InteractiveContext` num notebook para desenvolver um pipeline, você pode controlar quando componentes individuais armazenarão em cache suas saídas. Configure `enable_cache` como `True` quando desejar reutilizar os artefatos de saída anteriores gerados pelo componente. Defina `enable_cache` como `False` quando desejar recalcular os artefatos de saída de um componente, se estiver fazendo alterações no código, por exemplo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PyXjuMt8f-9u"
      },
      "outputs": [],
      "source": [
        "example_gen = tfx.components.CsvExampleGen(input_base=_data_root)\n",
        "context.run(example_gen, enable_cache=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OqCoZh7KPUm9"
      },
      "source": [
        "Vamos examinar os artefatos de saída de `ExampleGen`. Este componente produz dois artefatos, exemplos de treinamento e exemplos de avaliação:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "880KkTAkPeUg"
      },
      "outputs": [],
      "source": [
        "artifact = example_gen.outputs['examples'].get()[0]\n",
        "print(artifact.split_names, artifact.uri)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6vcbW_wPqvl"
      },
      "source": [
        "Também podemos dar uma olhada nos três primeiros exemplos de treinamento:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H4XIXjiCPwzQ"
      },
      "outputs": [],
      "source": [
        "# Get the URI of the output artifact representing the training examples, which is a directory\n",
        "train_uri = os.path.join(example_gen.outputs['examples'].get()[0].uri, 'Split-train')\n",
        "\n",
        "# Get the list of files in this directory (all compressed TFRecord files)\n",
        "tfrecord_filenames = [os.path.join(train_uri, name)\n",
        "                      for name in os.listdir(train_uri)]\n",
        "\n",
        "# Create a `TFRecordDataset` to read these files\n",
        "dataset = tf.data.TFRecordDataset(tfrecord_filenames, compression_type=\"GZIP\")\n",
        "\n",
        "# Iterate over the first 3 records and decode them.\n",
        "for tfrecord in dataset.take(3):\n",
        "  serialized_example = tfrecord.numpy()\n",
        "  example = tf.train.Example()\n",
        "  example.ParseFromString(serialized_example)\n",
        "  pp.pprint(example)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2gluYjccf-IP"
      },
      "source": [
        "Agora que `ExampleGen` concluiu a ingestão dos dados, a próxima etapa será a análise dos dados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csM6BFhtk5Aa"
      },
      "source": [
        "### StatisticsGen\n",
        "\n",
        "O componente `StatisticsGen` computa estatísticas sobre seu dataset para análise de dados, bem como para uso em componentes downstream. Ele usa a biblioteca [TensorFlow Data Validation](https://www.tensorflow.org/tfx/data_validation/get_started).\n",
        "\n",
        "`StatisticsGen` toma como entrada o dataset que acabamos de ingerir usando `ExampleGen`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MAscCCYWgA-9"
      },
      "outputs": [],
      "source": [
        "statistics_gen = tfx.components.StatisticsGen(\n",
        "    examples=example_gen.outputs['examples'])\n",
        "context.run(statistics_gen, enable_cache=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLI6cb_5WugZ"
      },
      "source": [
        "Depois que `StatisticsGen` terminar a execução, podemos visualizar as estatísticas geradas. Experimente brincar com os diferentes gráficos!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tLjXy7K6Tp_G"
      },
      "outputs": [],
      "source": [
        "context.show(statistics_gen.outputs['statistics'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLKLTO9Nk60p"
      },
      "source": [
        "### SchemaGen\n",
        "\n",
        "O componente `SchemaGen` gera um esquema com base nas suas estatísticas de dados. (Um esquema define os limites, tipos e propriedades esperados das características em seu dataset.) Ele também usa a biblioteca [TensorFlow Data Validation](https://www.tensorflow.org/tfx/data_validation/get_started).\n",
        "\n",
        "Nota: O esquema gerado automaticamente é o de melhor esforço e tenta apenas inferir propriedades básicas dos dados. Espera-se que você o revise e modifique conforme seja necessário.\n",
        "\n",
        "O `SchemaGen` terá como entrada as estatísticas que geramos com `StatisticsGen`, observando a divisão de treinamento por padrão."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ygQvZ6hsiQ_J"
      },
      "outputs": [],
      "source": [
        "schema_gen = tfx.components.SchemaGen(\n",
        "    statistics=statistics_gen.outputs['statistics'],\n",
        "    infer_feature_shape=False)\n",
        "context.run(schema_gen, enable_cache=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zi6TxTUKXM6b"
      },
      "source": [
        "Após a execução do `SchemaGen`, podemos visualizar o esquema gerado como uma tabela."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ec9vqDXpXeMb"
      },
      "outputs": [],
      "source": [
        "context.show(schema_gen.outputs['schema'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZWWdbA-m7zp"
      },
      "source": [
        "Cada característica no seu dataset aparece como uma linha na tabela do esquema, junto com suas propriedades. O esquema também captura todos os valores que uma característica categórica assume, denotados como o seu domínio.\n",
        "\n",
        "Para saber mais sobre esquemas, consulte a [documentação do SchemaGen](https://www.tensorflow.org/tfx/guide/schemagen)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1qcUuO9k9f8"
      },
      "source": [
        "### ExampleValidator\n",
        "\n",
        "O componente `ExampleValidator` detecta anomalias em seus dados, com base nas expectativas definidas pelo esquema. Ele também usa a biblioteca [TensorFlow Data Validation](https://www.tensorflow.org/tfx/data_validation/get_started).\n",
        "\n",
        "O `ExampleValidator` receberá como entrada as estatísticas de `StatisticsGen` e o esquema de `SchemaGen`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XRlRUuGgiXks"
      },
      "outputs": [],
      "source": [
        "example_validator = tfx.components.ExampleValidator(\n",
        "    statistics=statistics_gen.outputs['statistics'],\n",
        "    schema=schema_gen.outputs['schema'])\n",
        "context.run(example_validator, enable_cache=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "855mrHgJcoer"
      },
      "source": [
        "Após a execução do `ExampleValidator`, podemos visualizar as anomalias como uma tabela."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TDyAAozQcrk3"
      },
      "outputs": [],
      "source": [
        "context.show(example_validator.outputs['anomalies'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znMoJj60ybZx"
      },
      "source": [
        "Na tabela de anomalias, podemos observar que não há anomalias. Isto é o que esperávamos, já que este é o primeiro dataset que analisamos e o esquema foi adaptado a ele. Você deve revisar este esquema – qualquer coisa inesperada significa uma anomalia nos dados. Depois de revisado, o esquema poderá ser usado para proteger dados futuros, e as anomalias produzidas aqui podem ser usadas para depurar o desempenho do modelo, entender como seus dados evoluem ao longo do tempo e identificar erros de dados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPViEz5RlA36"
      },
      "source": [
        "### Transform\n",
        "\n",
        "O componente `Transform` realiza engenharia de características para treinamento e serviço. Ele usa a biblioteca [TensorFlow Transform](https://www.tensorflow.org/tfx/transform/get_started).\n",
        "\n",
        "O `Transform` terá como entrada os dados de `ExampleGen`, o esquema de `SchemaGen`, bem como um módulo que contém código Transform definido pelo usuário.\n",
        "\n",
        "Vejamos abaixo um exemplo de código Transform definido pelo usuário (para uma introdução às APIs TensorFlow Transform, [consulte o tutorial](https://www.tensorflow.org/tfx/tutorials/transform/simple)). Primeiro, definimos algumas constantes para engenharia de características:\n",
        "\n",
        "Observação: A magia da célula `%%writefile` salvará o conteúdo da célula como um arquivo `.py` no disco. Isso permite que o componente `Transform` carregar seu código como um módulo.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PuNSiUKb4YJf"
      },
      "outputs": [],
      "source": [
        "_taxi_constants_module_file = 'taxi_constants.py'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HPjhXuIF4YJh"
      },
      "outputs": [],
      "source": [
        "%%writefile {_taxi_constants_module_file}\n",
        "\n",
        "NUMERICAL_FEATURES = ['trip_miles', 'fare', 'trip_seconds']\n",
        "\n",
        "BUCKET_FEATURES = [\n",
        "    'pickup_latitude', 'pickup_longitude', 'dropoff_latitude',\n",
        "    'dropoff_longitude'\n",
        "]\n",
        "# Number of buckets used by tf.transform for encoding each feature.\n",
        "FEATURE_BUCKET_COUNT = 10\n",
        "\n",
        "CATEGORICAL_NUMERICAL_FEATURES = [\n",
        "    'trip_start_hour', 'trip_start_day', 'trip_start_month',\n",
        "    'pickup_census_tract', 'dropoff_census_tract', 'pickup_community_area',\n",
        "    'dropoff_community_area'\n",
        "]\n",
        "\n",
        "CATEGORICAL_STRING_FEATURES = [\n",
        "    'payment_type',\n",
        "    'company',\n",
        "]\n",
        "\n",
        "# Number of vocabulary terms used for encoding categorical features.\n",
        "VOCAB_SIZE = 1000\n",
        "\n",
        "# Count of out-of-vocab buckets in which unrecognized categorical are hashed.\n",
        "OOV_SIZE = 10\n",
        "\n",
        "# Keys\n",
        "LABEL_KEY = 'tips'\n",
        "FARE_KEY = 'fare'\n",
        "\n",
        "def t_name(key):\n",
        "  \"\"\"\n",
        "  Rename the feature keys so that they don't clash with the raw keys when\n",
        "  running the Evaluator component.\n",
        "  Args:\n",
        "    key: The original feature key\n",
        "  Returns:\n",
        "    key with '_xf' appended\n",
        "  \"\"\"\n",
        "  return key + '_xf'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Duj2Ax5z4YJl"
      },
      "source": [
        "Em seguida, escrevemos um `preprocessing_fn` que recebe dados brutos como entrada e retorna características transformadas que nosso modelo pode usar para treinar:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4AJ9hBs94YJm"
      },
      "outputs": [],
      "source": [
        "_taxi_transform_module_file = 'taxi_transform.py'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MYmxxx9A4YJn"
      },
      "outputs": [],
      "source": [
        "%%writefile {_taxi_transform_module_file}\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_transform as tft\n",
        "\n",
        "# Imported files such as taxi_constants are normally cached, so changes are\n",
        "# not honored after the first import.  Normally this is good for efficiency, but\n",
        "# during development when we may be iterating code it can be a problem. To\n",
        "# avoid this problem during development, reload the file.\n",
        "import taxi_constants\n",
        "import sys\n",
        "if 'google.colab' in sys.modules:  # Testing to see if we're doing development\n",
        "  import importlib\n",
        "  importlib.reload(taxi_constants)\n",
        "\n",
        "_NUMERICAL_FEATURES = taxi_constants.NUMERICAL_FEATURES\n",
        "_BUCKET_FEATURES = taxi_constants.BUCKET_FEATURES\n",
        "_FEATURE_BUCKET_COUNT = taxi_constants.FEATURE_BUCKET_COUNT\n",
        "_CATEGORICAL_NUMERICAL_FEATURES = taxi_constants.CATEGORICAL_NUMERICAL_FEATURES\n",
        "_CATEGORICAL_STRING_FEATURES = taxi_constants.CATEGORICAL_STRING_FEATURES\n",
        "_VOCAB_SIZE = taxi_constants.VOCAB_SIZE\n",
        "_OOV_SIZE = taxi_constants.OOV_SIZE\n",
        "_FARE_KEY = taxi_constants.FARE_KEY\n",
        "_LABEL_KEY = taxi_constants.LABEL_KEY\n",
        "\n",
        "\n",
        "def _make_one_hot(x, key):\n",
        "  \"\"\"Make a one-hot tensor to encode categorical features.\n",
        "  Args:\n",
        "    X: A dense tensor\n",
        "    key: A string key for the feature in the input\n",
        "  Returns:\n",
        "    A dense one-hot tensor as a float list\n",
        "  \"\"\"\n",
        "  integerized = tft.compute_and_apply_vocabulary(x,\n",
        "          top_k=_VOCAB_SIZE,\n",
        "          num_oov_buckets=_OOV_SIZE,\n",
        "          vocab_filename=key, name=key)\n",
        "  depth = (\n",
        "      tft.experimental.get_vocabulary_size_by_name(key) + _OOV_SIZE)\n",
        "  one_hot_encoded = tf.one_hot(\n",
        "      integerized,\n",
        "      depth=tf.cast(depth, tf.int32),\n",
        "      on_value=1.0,\n",
        "      off_value=0.0)\n",
        "  return tf.reshape(one_hot_encoded, [-1, depth])\n",
        "\n",
        "\n",
        "def _fill_in_missing(x):\n",
        "  \"\"\"Replace missing values in a SparseTensor.\n",
        "  Fills in missing values of `x` with '' or 0, and converts to a dense tensor.\n",
        "  Args:\n",
        "    x: A `SparseTensor` of rank 2.  Its dense shape should have size at most 1\n",
        "      in the second dimension.\n",
        "  Returns:\n",
        "    A rank 1 tensor where missing values of `x` have been filled in.\n",
        "  \"\"\"\n",
        "  if not isinstance(x, tf.sparse.SparseTensor):\n",
        "    return x\n",
        "\n",
        "  default_value = '' if x.dtype == tf.string else 0\n",
        "  return tf.squeeze(\n",
        "      tf.sparse.to_dense(\n",
        "          tf.SparseTensor(x.indices, x.values, [x.dense_shape[0], 1]),\n",
        "          default_value),\n",
        "      axis=1)\n",
        "\n",
        "\n",
        "def preprocessing_fn(inputs):\n",
        "  \"\"\"tf.transform's callback function for preprocessing inputs.\n",
        "  Args:\n",
        "    inputs: map from feature keys to raw not-yet-transformed features.\n",
        "  Returns:\n",
        "    Map from string feature key to transformed feature operations.\n",
        "  \"\"\"\n",
        "  outputs = {}\n",
        "  for key in _NUMERICAL_FEATURES:\n",
        "    # If sparse make it dense, setting nan's to 0 or '', and apply zscore.\n",
        "    outputs[taxi_constants.t_name(key)] = tft.scale_to_z_score(\n",
        "        _fill_in_missing(inputs[key]), name=key)\n",
        "\n",
        "  for key in _BUCKET_FEATURES:\n",
        "    outputs[taxi_constants.t_name(key)] = tf.cast(tft.bucketize(\n",
        "            _fill_in_missing(inputs[key]), _FEATURE_BUCKET_COUNT, name=key),\n",
        "            dtype=tf.float32)\n",
        "\n",
        "  for key in _CATEGORICAL_STRING_FEATURES:\n",
        "    outputs[taxi_constants.t_name(key)] = _make_one_hot(_fill_in_missing(inputs[key]), key)\n",
        "\n",
        "  for key in _CATEGORICAL_NUMERICAL_FEATURES:\n",
        "    outputs[taxi_constants.t_name(key)] = _make_one_hot(tf.strings.strip(\n",
        "        tf.strings.as_string(_fill_in_missing(inputs[key]))), key)\n",
        "\n",
        "  # Was this passenger a big tipper?\n",
        "  taxi_fare = _fill_in_missing(inputs[_FARE_KEY])\n",
        "  tips = _fill_in_missing(inputs[_LABEL_KEY])\n",
        "  outputs[_LABEL_KEY] = tf.where(\n",
        "      tf.math.is_nan(taxi_fare),\n",
        "      tf.cast(tf.zeros_like(taxi_fare), tf.int64),\n",
        "      # Test if the tip was > 20% of the fare.\n",
        "      tf.cast(\n",
        "          tf.greater(tips, tf.multiply(taxi_fare, tf.constant(0.2))), tf.int64))\n",
        "\n",
        "  return outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgbmZr3sgbWW"
      },
      "source": [
        "Agora, passamos este código de engenharia de características para o componente `Transform` e o executamos para transformar seus dados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jHfhth_GiZI9"
      },
      "outputs": [],
      "source": [
        "transform = tfx.components.Transform(\n",
        "    examples=example_gen.outputs['examples'],\n",
        "    schema=schema_gen.outputs['schema'],\n",
        "    module_file=os.path.abspath(_taxi_transform_module_file))\n",
        "context.run(transform, enable_cache=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwAwb4rARRQ2"
      },
      "source": [
        "Vamos examinar os artefatos de saída de `Transform`. Este componente produz dois tipos de saídas:\n",
        "\n",
        "- `transform_graph` é o grafo que pode realizar as operações de pré-processamento (este grafo será incluído nos modelos de serviço e avaliação).\n",
        "- `transformed_examples` representa os dados pré-processados ​​de treinamento e avaliação."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SClrAaEGR1O5"
      },
      "outputs": [],
      "source": [
        "transform.outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyFkBd9AR1sy"
      },
      "source": [
        "Dê uma olhada no artefato `transform_graph`: ele aponta para um diretório contendo 3 subdiretórios:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5tRw4DneR3i7"
      },
      "outputs": [],
      "source": [
        "train_uri = transform.outputs['transform_graph'].get()[0].uri\n",
        "os.listdir(train_uri)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fqV54CIR6Pu"
      },
      "source": [
        "O subdiretório `transformed_metadata` contém o esquema dos dados pré-processados. O subdiretório `transform_fn` contém o grafo de pré-processamento real. O subdiretório `metadata` contém o esquema dos dados originais.\n",
        "\n",
        "Também podemos dar uma olhada nos três primeiros exemplos transformados:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pwbW2zPKR_S4"
      },
      "outputs": [],
      "source": [
        "# Get the URI of the output artifact representing the transformed examples, which is a directory\n",
        "train_uri = os.path.join(transform.outputs['transformed_examples'].get()[0].uri, 'Split-train')\n",
        "\n",
        "# Get the list of files in this directory (all compressed TFRecord files)\n",
        "tfrecord_filenames = [os.path.join(train_uri, name)\n",
        "                      for name in os.listdir(train_uri)]\n",
        "\n",
        "# Create a `TFRecordDataset` to read these files\n",
        "dataset = tf.data.TFRecordDataset(tfrecord_filenames, compression_type=\"GZIP\")\n",
        "\n",
        "# Iterate over the first 3 records and decode them.\n",
        "for tfrecord in dataset.take(3):\n",
        "  serialized_example = tfrecord.numpy()\n",
        "  example = tf.train.Example()\n",
        "  example.ParseFromString(serialized_example)\n",
        "  pp.pprint(example)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_b_V6eN4f69"
      },
      "source": [
        "Depois que o componente `Transform` transformar seus dados em características, a próxima etapa é treinar um modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBJFtnl6lCg9"
      },
      "source": [
        "### Trainer\n",
        "\n",
        "O componente `Trainer` treinará um modelo definido por você no TensorFlow. Para usar a API Keras, você precisa especificar o [Generic Trainer](https://github.com/tensorflow/community/blob/master/rfcs/20200117-tfx-generic-trainer.md) por configuração `custom_executor_spec=executor_spec.ExecutorClassSpec(GenericExecutor)` no construtor do Trainer.\n",
        "\n",
        "O `Trainer` recebe como entrada o esquema do `SchemaGen`, os dados e o grafo transformados de `Transform`, os parâmetros de treinamento, bem como um módulo que contém código de modelo definido pelo usuário.\n",
        "\n",
        "Vejamos um exemplo de código de modelo definido pelo usuário (para uma introdução às APIs do TensorFlow Estimator, [consulte o tutorial](https://www.tensorflow.org/guide/keras)):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N1376oq04YJt"
      },
      "outputs": [],
      "source": [
        "_taxi_trainer_module_file = 'taxi_trainer.py'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nf9UuNng4YJu"
      },
      "outputs": [],
      "source": [
        "%%writefile {_taxi_trainer_module_file}\n",
        "\n",
        "from typing import Dict, List, Text\n",
        "\n",
        "import os\n",
        "import glob\n",
        "from absl import logging\n",
        "\n",
        "import datetime\n",
        "import tensorflow as tf\n",
        "import tensorflow_transform as tft\n",
        "\n",
        "from tfx import v1 as tfx\n",
        "from tfx_bsl.public import tfxio\n",
        "from tensorflow_transform import TFTransformOutput\n",
        "\n",
        "# Imported files such as taxi_constants are normally cached, so changes are\n",
        "# not honored after the first import.  Normally this is good for efficiency, but\n",
        "# during development when we may be iterating code it can be a problem. To\n",
        "# avoid this problem during development, reload the file.\n",
        "import taxi_constants\n",
        "import sys\n",
        "if 'google.colab' in sys.modules:  # Testing to see if we're doing development\n",
        "  import importlib\n",
        "  importlib.reload(taxi_constants)\n",
        "\n",
        "_LABEL_KEY = taxi_constants.LABEL_KEY\n",
        "\n",
        "_BATCH_SIZE = 40\n",
        "\n",
        "\n",
        "def _input_fn(file_pattern: List[Text],\n",
        "              data_accessor: tfx.components.DataAccessor,\n",
        "              tf_transform_output: tft.TFTransformOutput,\n",
        "              batch_size: int = 200) -> tf.data.Dataset:\n",
        "  \"\"\"Generates features and label for tuning/training.\n",
        "\n",
        "  Args:\n",
        "    file_pattern: List of paths or patterns of input tfrecord files.\n",
        "    data_accessor: DataAccessor for converting input to RecordBatch.\n",
        "    tf_transform_output: A TFTransformOutput.\n",
        "    batch_size: representing the number of consecutive elements of returned\n",
        "      dataset to combine in a single batch\n",
        "\n",
        "  Returns:\n",
        "    A dataset that contains (features, indices) tuple where features is a\n",
        "      dictionary of Tensors, and indices is a single Tensor of label indices.\n",
        "  \"\"\"\n",
        "  return data_accessor.tf_dataset_factory(\n",
        "      file_pattern,\n",
        "      tfxio.TensorFlowDatasetOptions(\n",
        "          batch_size=batch_size, label_key=_LABEL_KEY),\n",
        "      tf_transform_output.transformed_metadata.schema)\n",
        "\n",
        "def _get_tf_examples_serving_signature(model, tf_transform_output):\n",
        "  \"\"\"Returns a serving signature that accepts `tensorflow.Example`.\"\"\"\n",
        "\n",
        "  # We need to track the layers in the model in order to save it.\n",
        "  # TODO(b/162357359): Revise once the bug is resolved.\n",
        "  model.tft_layer_inference = tf_transform_output.transform_features_layer()\n",
        "\n",
        "  @tf.function(input_signature=[\n",
        "      tf.TensorSpec(shape=[None], dtype=tf.string, name='examples')\n",
        "  ])\n",
        "  def serve_tf_examples_fn(serialized_tf_example):\n",
        "    \"\"\"Returns the output to be used in the serving signature.\"\"\"\n",
        "    raw_feature_spec = tf_transform_output.raw_feature_spec()\n",
        "    # Remove label feature since these will not be present at serving time.\n",
        "    raw_feature_spec.pop(_LABEL_KEY)\n",
        "    raw_features = tf.io.parse_example(serialized_tf_example, raw_feature_spec)\n",
        "    transformed_features = model.tft_layer_inference(raw_features)\n",
        "    logging.info('serve_transformed_features = %s', transformed_features)\n",
        "\n",
        "    outputs = model(transformed_features)\n",
        "    # TODO(b/154085620): Convert the predicted labels from the model using a\n",
        "    # reverse-lookup (opposite of transform.py).\n",
        "    return {'outputs': outputs}\n",
        "\n",
        "  return serve_tf_examples_fn\n",
        "\n",
        "\n",
        "def _get_transform_features_signature(model, tf_transform_output):\n",
        "  \"\"\"Returns a serving signature that applies tf.Transform to features.\"\"\"\n",
        "\n",
        "  # We need to track the layers in the model in order to save it.\n",
        "  # TODO(b/162357359): Revise once the bug is resolved.\n",
        "  model.tft_layer_eval = tf_transform_output.transform_features_layer()\n",
        "\n",
        "  @tf.function(input_signature=[\n",
        "      tf.TensorSpec(shape=[None], dtype=tf.string, name='examples')\n",
        "  ])\n",
        "  def transform_features_fn(serialized_tf_example):\n",
        "    \"\"\"Returns the transformed_features to be fed as input to evaluator.\"\"\"\n",
        "    raw_feature_spec = tf_transform_output.raw_feature_spec()\n",
        "    raw_features = tf.io.parse_example(serialized_tf_example, raw_feature_spec)\n",
        "    transformed_features = model.tft_layer_eval(raw_features)\n",
        "    logging.info('eval_transformed_features = %s', transformed_features)\n",
        "    return transformed_features\n",
        "\n",
        "  return transform_features_fn\n",
        "\n",
        "\n",
        "def export_serving_model(tf_transform_output, model, output_dir):\n",
        "  \"\"\"Exports a keras model for serving.\n",
        "  Args:\n",
        "    tf_transform_output: Wrapper around output of tf.Transform.\n",
        "    model: A keras model to export for serving.\n",
        "    output_dir: A directory where the model will be exported to.\n",
        "  \"\"\"\n",
        "  # The layer has to be saved to the model for keras tracking purpases.\n",
        "  model.tft_layer = tf_transform_output.transform_features_layer()\n",
        "\n",
        "  signatures = {\n",
        "      'serving_default':\n",
        "          _get_tf_examples_serving_signature(model, tf_transform_output),\n",
        "      'transform_features':\n",
        "          _get_transform_features_signature(model, tf_transform_output),\n",
        "  }\n",
        "\n",
        "  model.save(output_dir, save_format='tf', signatures=signatures)\n",
        "\n",
        "\n",
        "def _build_keras_model(tf_transform_output: TFTransformOutput\n",
        "                       ) -> tf.keras.Model:\n",
        "  \"\"\"Creates a DNN Keras model for classifying taxi data.\n",
        "\n",
        "  Args:\n",
        "    tf_transform_output: [TFTransformOutput], the outputs from Transform\n",
        "\n",
        "  Returns:\n",
        "    A keras Model.\n",
        "  \"\"\"\n",
        "  feature_spec = tf_transform_output.transformed_feature_spec().copy()\n",
        "  feature_spec.pop(_LABEL_KEY)\n",
        "\n",
        "  inputs = {}\n",
        "  for key, spec in feature_spec.items():\n",
        "    if isinstance(spec, tf.io.VarLenFeature):\n",
        "      inputs[key] = tf.keras.layers.Input(\n",
        "          shape=[None], name=key, dtype=spec.dtype, sparse=True)\n",
        "    elif isinstance(spec, tf.io.FixedLenFeature):\n",
        "      # TODO(b/208879020): Move into schema such that spec.shape is [1] and not\n",
        "      # [] for scalars.\n",
        "      inputs[key] = tf.keras.layers.Input(\n",
        "          shape=spec.shape or [1], name=key, dtype=spec.dtype)\n",
        "    else:\n",
        "      raise ValueError('Spec type is not supported: ', key, spec)\n",
        "  \n",
        "  output = tf.keras.layers.Concatenate()(tf.nest.flatten(inputs))\n",
        "  output = tf.keras.layers.Dense(100, activation='relu')(output)\n",
        "  output = tf.keras.layers.Dense(70, activation='relu')(output)\n",
        "  output = tf.keras.layers.Dense(50, activation='relu')(output)\n",
        "  output = tf.keras.layers.Dense(20, activation='relu')(output)\n",
        "  output = tf.keras.layers.Dense(1)(output)\n",
        "  return tf.keras.Model(inputs=inputs, outputs=output)\n",
        "\n",
        "\n",
        "# TFX Trainer will call this function.\n",
        "def run_fn(fn_args: tfx.components.FnArgs):\n",
        "  \"\"\"Train the model based on given args.\n",
        "\n",
        "  Args:\n",
        "    fn_args: Holds args used to train the model as name/value pairs.\n",
        "  \"\"\"\n",
        "  tf_transform_output = tft.TFTransformOutput(fn_args.transform_output)\n",
        "\n",
        "  train_dataset = _input_fn(fn_args.train_files, fn_args.data_accessor, \n",
        "                            tf_transform_output, _BATCH_SIZE)\n",
        "  eval_dataset = _input_fn(fn_args.eval_files, fn_args.data_accessor, \n",
        "                           tf_transform_output, _BATCH_SIZE)\n",
        "\n",
        "  model = _build_keras_model(tf_transform_output)\n",
        "\n",
        "  model.compile(\n",
        "      loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "      optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "      metrics=[tf.keras.metrics.BinaryAccuracy()])\n",
        "\n",
        "  tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
        "      log_dir=fn_args.model_run_dir, update_freq='batch')\n",
        "\n",
        "  model.fit(\n",
        "      train_dataset,\n",
        "      steps_per_epoch=fn_args.train_steps,\n",
        "      validation_data=eval_dataset,\n",
        "      validation_steps=fn_args.eval_steps,\n",
        "      callbacks=[tensorboard_callback])\n",
        "\n",
        "  # Export the model.\n",
        "  export_serving_model(tf_transform_output, model, fn_args.serving_model_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GY4yTRaX4YJx"
      },
      "source": [
        "Agora, passamos o código deste modelo para o componente `Trainer` e o executamos para treinar o modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "429-vvCWibO0"
      },
      "outputs": [],
      "source": [
        "trainer = tfx.components.Trainer(\n",
        "    module_file=os.path.abspath(_taxi_trainer_module_file),\n",
        "    examples=transform.outputs['transformed_examples'],\n",
        "    transform_graph=transform.outputs['transform_graph'],\n",
        "    schema=schema_gen.outputs['schema'],\n",
        "    train_args=tfx.proto.TrainArgs(num_steps=10000),\n",
        "    eval_args=tfx.proto.EvalArgs(num_steps=5000))\n",
        "context.run(trainer, enable_cache=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Cql1G35StJp"
      },
      "source": [
        "#### Analise o treinamento com o TensorBoard\n",
        "\n",
        "Dê uma olhada no artefato do trainer. Aponta para um diretório que contém os subdiretórios do modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bXe62WE0S0Ek"
      },
      "outputs": [],
      "source": [
        "model_artifact_dir = trainer.outputs['model'].get()[0].uri\n",
        "pp.pprint(os.listdir(model_artifact_dir))\n",
        "model_dir = os.path.join(model_artifact_dir, 'Format-Serving')\n",
        "pp.pprint(os.listdir(model_dir))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfjOmSro6Q3Y"
      },
      "source": [
        "Opcionalmente, podemos conectar o TensorBoard ao Trainer para analisar as curvas de treinamento do nosso modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-APzqz2NeAyj"
      },
      "outputs": [],
      "source": [
        "model_run_artifact_dir = trainer.outputs['model_run'].get()[0].uri\n",
        "\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir {model_run_artifact_dir}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmPftrv0lEQy"
      },
      "source": [
        "### Evaluator\n",
        "\n",
        "O componente `Evaluator` calcula métricas de desempenho do modelo no dataset de avaliação. Ele usa a biblioteca [TensorFlow Model Analysis](https://www.tensorflow.org/tfx/model_analysis/get_started). O `Evaluator` também pode validar opcionalmente se um modelo recém-treinado é melhor que o modelo anterior. Isto é útil numa configuração de pipeline de produção onde você pode treinar e validar automaticamente um modelo todos os dias. Neste notebook, treinamos apenas um modelo, então o `Evaluator` irá rotular automaticamente o modelo como \"bom\".\n",
        "\n",
        "O `Evaluator` terá como entrada os dados de `ExampleGen`, o modelo treinado de `Trainer` e a configuração de fatiamento. A configuração de fatiamento permite dividir suas métricas em valores de características (por exemplo, como é o desempenho do seu modelo em viagens de táxi que começam às 8h versus 20h?). Veja abaixo um exemplo dessa configuração:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fVhfzzh9PDEx"
      },
      "outputs": [],
      "source": [
        "# Imported files such as taxi_constants are normally cached, so changes are\n",
        "# not honored after the first import.  Normally this is good for efficiency, but\n",
        "# during development when we may be iterating code it can be a problem. To\n",
        "# avoid this problem during development, reload the file.\n",
        "import taxi_constants\n",
        "import sys\n",
        "if 'google.colab' in sys.modules:  # Testing to see if we're doing development\n",
        "  import importlib\n",
        "  importlib.reload(taxi_constants)\n",
        "\n",
        "eval_config = tfma.EvalConfig(\n",
        "    model_specs=[\n",
        "        # This assumes a serving model with signature 'serving_default'. If\n",
        "        # using estimator based EvalSavedModel, add signature_name: 'eval' and\n",
        "        # remove the label_key.\n",
        "        tfma.ModelSpec(\n",
        "            signature_name='serving_default',\n",
        "            label_key=taxi_constants.LABEL_KEY,\n",
        "            preprocessing_function_names=['transform_features'],\n",
        "            )\n",
        "        ],\n",
        "    metrics_specs=[\n",
        "        tfma.MetricsSpec(\n",
        "            # The metrics added here are in addition to those saved with the\n",
        "            # model (assuming either a keras model or EvalSavedModel is used).\n",
        "            # Any metrics added into the saved model (for example using\n",
        "            # model.compile(..., metrics=[...]), etc) will be computed\n",
        "            # automatically.\n",
        "            # To add validation thresholds for metrics saved with the model,\n",
        "            # add them keyed by metric name to the thresholds map.\n",
        "            metrics=[\n",
        "                tfma.MetricConfig(class_name='ExampleCount'),\n",
        "                tfma.MetricConfig(class_name='BinaryAccuracy',\n",
        "                  threshold=tfma.MetricThreshold(\n",
        "                      value_threshold=tfma.GenericValueThreshold(\n",
        "                          lower_bound={'value': 0.5}),\n",
        "                      # Change threshold will be ignored if there is no\n",
        "                      # baseline model resolved from MLMD (first run).\n",
        "                      change_threshold=tfma.GenericChangeThreshold(\n",
        "                          direction=tfma.MetricDirection.HIGHER_IS_BETTER,\n",
        "                          absolute={'value': -1e-10})))\n",
        "            ]\n",
        "        )\n",
        "    ],\n",
        "    slicing_specs=[\n",
        "        # An empty slice spec means the overall slice, i.e. the whole dataset.\n",
        "        tfma.SlicingSpec(),\n",
        "        # Data can be sliced along a feature column. In this case, data is\n",
        "        # sliced along feature column trip_start_hour.\n",
        "        tfma.SlicingSpec(\n",
        "            feature_keys=['trip_start_hour'])\n",
        "    ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mBdKH1F8JuT"
      },
      "source": [
        "Em seguida, damos esta configuração ao `Evaluator` e o executamos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zjcx8g6mihSt"
      },
      "outputs": [],
      "source": [
        "# Use TFMA to compute a evaluation statistics over features of a model and\n",
        "# validate them against a baseline.\n",
        "\n",
        "# The model resolver is only required if performing model validation in addition\n",
        "# to evaluation. In this case we validate against the latest blessed model. If\n",
        "# no model has been blessed before (as in this case) the evaluator will make our\n",
        "# candidate the first blessed model.\n",
        "model_resolver = tfx.dsl.Resolver(\n",
        "      strategy_class=tfx.dsl.experimental.LatestBlessedModelStrategy,\n",
        "      model=tfx.dsl.Channel(type=tfx.types.standard_artifacts.Model),\n",
        "      model_blessing=tfx.dsl.Channel(\n",
        "          type=tfx.types.standard_artifacts.ModelBlessing)).with_id(\n",
        "              'latest_blessed_model_resolver')\n",
        "context.run(model_resolver, enable_cache=True)\n",
        "\n",
        "evaluator = tfx.components.Evaluator(\n",
        "    examples=example_gen.outputs['examples'],\n",
        "    model=trainer.outputs['model'],\n",
        "    baseline_model=model_resolver.outputs['model'],\n",
        "    eval_config=eval_config)\n",
        "context.run(evaluator, enable_cache=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AeCVkBusS_8g"
      },
      "source": [
        "Agora vamos examinar os artefatos de saída do `Evaluator`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k4GghePOTJxL"
      },
      "outputs": [],
      "source": [
        "evaluator.outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5TMskWe9LL0"
      },
      "source": [
        "Usando a saída `evaluation` podemos mostrar a visualização padrão das métricas globais em todo o dataset de avaliação."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U729j5X5QQUQ"
      },
      "outputs": [],
      "source": [
        "context.show(evaluator.outputs['evaluation'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-tI4p6m-OAn"
      },
      "source": [
        "Para ver a visualização das métricas de avaliação fatiadas, podemos chamar diretamente a biblioteca TensorFlow Model Analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pyis6iy0HLdi"
      },
      "outputs": [],
      "source": [
        "import tensorflow_model_analysis as tfma\n",
        "\n",
        "# Get the TFMA output result path and load the result.\n",
        "PATH_TO_RESULT = evaluator.outputs['evaluation'].get()[0].uri\n",
        "tfma_result = tfma.load_eval_result(PATH_TO_RESULT)\n",
        "\n",
        "# Show data sliced along feature column trip_start_hour.\n",
        "tfma.view.render_slicing_metrics(\n",
        "    tfma_result, slicing_column='trip_start_hour')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uvYrUf2-r_6"
      },
      "source": [
        "Esta visualização mostra as mesmas métricas, mas calculadas em cada valor de característica de `trip_start_hour` em vez de em todo o dataset de avaliação.\n",
        "\n",
        "O TensorFlow Model Analysis oferece suporte a muitas outras visualizações, como Fairness Indicators (indicadores de imparcialidade) e plotagem de uma série temporal de desempenho do modelo. Para saber mais, veja o [tutorial](https://www.tensorflow.org/tfx/tutorials/model_analysis/tfma_basic)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEotnkxEswUb"
      },
      "source": [
        "Como adicionamos limites à nossa configuração, a saída de validação também estará disponível. A presença de um artefato `blessing` indica que nosso modelo passou na validação. Como esta é a primeira validação realizada, o candidato é automaticamente abençoado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FZmiRtg6TKtR"
      },
      "outputs": [],
      "source": [
        "blessing_uri = evaluator.outputs['blessing'].get()[0].uri\n",
        "!ls -l {blessing_uri}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hM1tFkOVSBa0"
      },
      "source": [
        "Agora também podemos verificar o sucesso carregando o registro do resultado da validação:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lxa5G08bSJ8a"
      },
      "outputs": [],
      "source": [
        "PATH_TO_RESULT = evaluator.outputs['evaluation'].get()[0].uri\n",
        "print(tfma.load_validation_result(PATH_TO_RESULT))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8DYekCZlHfj"
      },
      "source": [
        "### Pusher\n",
        "\n",
        "O componente `Pusher` geralmente está no final de um pipeline do TFX. Ele verifica se um modelo passou na validação e, em caso afirmativo, exporta o modelo para `_serving_model_dir`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r45nQ69eikc9"
      },
      "outputs": [],
      "source": [
        "pusher = tfx.components.Pusher(\n",
        "    model=trainer.outputs['model'],\n",
        "    model_blessing=evaluator.outputs['blessing'],\n",
        "    push_destination=tfx.proto.PushDestination(\n",
        "        filesystem=tfx.proto.PushDestination.Filesystem(\n",
        "            base_directory=_serving_model_dir)))\n",
        "context.run(pusher, enable_cache=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctUErBYoTO9I"
      },
      "source": [
        "Vamos examinar os artefatos de saída do `Pusher`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pRkWo-MzTSss"
      },
      "outputs": [],
      "source": [
        "pusher.outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peH2PPS3VgkL"
      },
      "source": [
        "Em particular, o Pusher exportará seu modelo no formato SavedModel, que se parece com o seguinte:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4zyIqWl9TSdG"
      },
      "outputs": [],
      "source": [
        "push_uri = pusher.outputs['pushed_model'].get()[0].uri\n",
        "model = tf.saved_model.load(push_uri)\n",
        "\n",
        "for item in model.signatures.items():\n",
        "  pp.pprint(item)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-YPNUuHANtj"
      },
      "source": [
        "Terminamos nosso tour pelos componentes integrados do TFX!"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "wdeKOEkv1Fe8"
      ],
      "name": "components_keras.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
