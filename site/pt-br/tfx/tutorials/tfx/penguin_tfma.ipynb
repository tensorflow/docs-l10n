{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjUA6S30k52h"
      },
      "source": [
        "##### Copyright 2021 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "SpNWyqewk8fE"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6x1ypzczQCwy"
      },
      "source": [
        "# Análise de modelo usando o TFX Pipeline e o TensorFlow Model Analysis\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HU9YYythm0dx"
      },
      "source": [
        "Observação: recomendamos executar este tutorial em um notebook Colab, sem necessidade de configuração! Basta clicar em “Executar no Google Colab”.\n",
        "\n",
        "<div class=\"devsite-table-wrapper\"><table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "<td>     <a target=\"_blank\" href=\"https://www.tensorflow.org/tfx/tutorials/tfx/penguin_tfma\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver em TensorFlow.org</a>\n",
        "</td>\n",
        "<td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/pt-br/tfx/tutorials/tfx/penguin_tfma.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Executar no Google Colab</a>\n",
        "</td>\n",
        "<td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/pt-br/tfx/tutorials/tfx/penguin_tfma.ipynb\"><img width=\"32px\" src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver fonte no GitHub</a>\n",
        "</td>\n",
        "<td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/pt-br/tfx/tutorials/tfx/penguin_tfma.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Baixar notebook</a>\n",
        "</td>\n",
        "</table></div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_VuwrlnvQJ5k"
      },
      "source": [
        "Neste tutorial baseado em notebook, criaremos e executaremos um pipeline TFX que cria um modelo de classificação simples e analisa seu desempenho em múltiplas execuções. Este notebook é baseado no pipeline TFX que construímos no [Tutorial pipeline TFX simples](https://www.tensorflow.org/tfx/tutorials/tfx/penguin_simple). Se você ainda não leu esse tutorial, leia-o antes de prosseguir com este notebook.\n",
        "\n",
        "Ao ajustar seu modelo ou treiná-lo com um novo dataset, você precisa verificar se seu modelo melhorou ou piorou. Apenas verificar as métricas de nível superior, como a exatidão, pode não ser suficiente. Cada modelo treinado deve ser avaliado antes de ser enviado para produção.\n",
        "\n",
        "Adicionaremos um componente `Evaluator` ao pipeline criado no tutorial anterior. O componente Evaluator realiza análises profundas de seus modelos e compara o novo modelo com uma referência para determinar se eles são \"bons o suficiente\". Ele é implementado usando a biblioteca [TensorFlow Model Analysis](https://www.tensorflow.org/tfx/guide/tfma).\n",
        "\n",
        "Veja [Introdução aos pipelines do TFX](https://www.tensorflow.org/tfx/guide/understanding_tfx_pipelines) para saber mais sobre vários conceitos do TFX."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fmgi8ZvQkScg"
      },
      "source": [
        "## Configuração\n",
        "\n",
        "O processo de configuração é igual ao do tutorial anterior.\n",
        "\n",
        "Primeiro precisamos instalar o pacote TFX Python e baixar o dataset que usaremos para nosso modelo.\n",
        "\n",
        "### Atualize o Pip\n",
        "\n",
        "Para evitar a atualização do Pip num sistema ao executar localmente, garanta que estamos executando no Colab. Os sistemas locais podem, claro, ser atualizados separadamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "as4OTe2ukSqm"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  import colab\n",
        "  !pip install --upgrade pip\n",
        "except:\n",
        "  pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZOYTt1RW4TK"
      },
      "source": [
        "### Instale o TFX\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iyQtljP-qPHY"
      },
      "outputs": [],
      "source": [
        "!pip install -U tfx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfT4ubk9_dJy"
      },
      "source": [
        "### Desinstale o shapely\n",
        "\n",
        "TODO(b/263441833) Esta é uma solução temporária para evitar um ImportError. Em última análise, isto deverá ser resolvido com suporte a uma versão mais recente do Bigquery, em vez de desinstalar outras dependências extras."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RhieH4y1_d3n"
      },
      "outputs": [],
      "source": [
        "!pip uninstall shapely -y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwT0nov5QO1M"
      },
      "source": [
        "### Você reiniciou o runtime?\n",
        "\n",
        "Se você estiver usando o Google Colab, na primeira vez que executar a célula acima, você deve reiniciar o runtime clicando no botão \"RESTART RUNTIME\" acima ou usando o menu \"Runtime &gt; Restart runtime ...\". Isso é necessário devido à maneira como o Colab carrega os pacotes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDnPgN8UJtzN"
      },
      "source": [
        "Verifique as versões do TensorFlow e TFX."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6jh7vKSRqPHb"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "print('TensorFlow version: {}'.format(tf.__version__))\n",
        "from tfx import v1 as tfx\n",
        "print('TFX version: {}'.format(tfx.__version__))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDtLdSkvqPHe"
      },
      "source": [
        "### Configuração de variáveis\n",
        "\n",
        "Existem algumas variáveis ​​usadas para definir um pipeline. Você pode personalizar essas variáveis ​​como desejar. Por padrão, toda a saída do pipeline será gerada no diretório atual."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EcUseqJaE2XN"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "PIPELINE_NAME = \"penguin-tfma\"\n",
        "\n",
        "# Output directory to store artifacts generated from the pipeline.\n",
        "PIPELINE_ROOT = os.path.join('pipelines', PIPELINE_NAME)\n",
        "# Path to a SQLite DB file to use as an MLMD storage.\n",
        "METADATA_PATH = os.path.join('metadata', PIPELINE_NAME, 'metadata.db')\n",
        "# Output directory where created models from the pipeline will be exported.\n",
        "SERVING_MODEL_DIR = os.path.join('serving_model', PIPELINE_NAME)\n",
        "\n",
        "from absl import logging\n",
        "logging.set_verbosity(logging.INFO)  # Set default logging level."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8F2SRwRLSYGa"
      },
      "source": [
        "### Preparação dos dados de exemplo\n",
        "\n",
        "Usaremos o mesmo [dataset Palmer Penguins](https://allisonhorst.github.io/palmerpenguins/articles/intro.html).\n",
        "\n",
        "Existem quatro características numéricas neste dataset que já foram normalizados para ter intervalo [0,1]. Construiremos um modelo de classificação que prevê as `species` de pinguins."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11J7XiCq6AFP"
      },
      "source": [
        "Como o TFX ExampleGen lê entradas de um diretório, precisamos criar um diretório e copiar o dataset para ele."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4fxMs6u86acP"
      },
      "outputs": [],
      "source": [
        "import urllib.request\n",
        "import tempfile\n",
        "\n",
        "DATA_ROOT = tempfile.mkdtemp(prefix='tfx-data')  # Create a temporary directory.\n",
        "_data_url = 'https://raw.githubusercontent.com/tensorflow/tfx/master/tfx/examples/penguin/data/labelled/penguins_processed.csv'\n",
        "_data_filepath = os.path.join(DATA_ROOT, \"data.csv\")\n",
        "urllib.request.urlretrieve(_data_url, _data_filepath)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nH6gizcpSwWV"
      },
      "source": [
        "## Crie um pipeline\n",
        "\n",
        "Adicionaremos um componente [`Evaluator`](https://www.tensorflow.org/tfx/guide/evaluator) ao pipeline que criamos no [Tutorial pipeline TFX simples](https://www.tensorflow.org/tfx/tutorials/tfx/penguin_simple).\n",
        "\n",
        "Um componente Evaluator requer dados de entrada de um componente `ExampleGen` e um modelo de um componente `Trainer` e um objeto [`tfma.EvalConfig`](https://www.tensorflow.org/tfx/model_analysis/api_docs/python/tfma/EvalConfig). Opcionalmente, podemos fornecer um modelo de referência que pode ser usado para comparar métricas com o modelo recém-treinado.\n",
        "\n",
        "Um evaluator cria dois tipos de artefatos de saída, `ModelEvaluation` e `ModelBlessing`. ModelEvaluation contém o resultado detalhado da avaliação que pode ser investigado e visualizado posteriormente com a biblioteca TFMA. ModelBlessing contém um resultado booleano se o modelo passou em determinados critérios e pode ser usado em componentes posteriores, como um Pusher, como um sinal.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOjDv93eS5xV"
      },
      "source": [
        "### Escreva o código para treinamento do modelo\n",
        "\n",
        "Usaremos o mesmo código de modelo do [Tutorial pipeline TFX simples](https://www.tensorflow.org/tfx/tutorials/tfx/penguin_simple)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aES7Hv5QTDK3"
      },
      "outputs": [],
      "source": [
        "_trainer_module_file = 'penguin_trainer.py'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gnc67uQNTDfW"
      },
      "outputs": [],
      "source": [
        "%%writefile {_trainer_module_file}\n",
        "\n",
        "# Copied from https://www.tensorflow.org/tfx/tutorials/tfx/penguin_simple\n",
        "\n",
        "from typing import List\n",
        "from absl import logging\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow_transform.tf_metadata import schema_utils\n",
        "\n",
        "from tfx.components.trainer.executor import TrainerFnArgs\n",
        "from tfx.components.trainer.fn_args_utils import DataAccessor\n",
        "from tfx_bsl.tfxio import dataset_options\n",
        "from tensorflow_metadata.proto.v0 import schema_pb2\n",
        "\n",
        "_FEATURE_KEYS = [\n",
        "    'culmen_length_mm', 'culmen_depth_mm', 'flipper_length_mm', 'body_mass_g'\n",
        "]\n",
        "_LABEL_KEY = 'species'\n",
        "\n",
        "_TRAIN_BATCH_SIZE = 20\n",
        "_EVAL_BATCH_SIZE = 10\n",
        "\n",
        "# Since we're not generating or creating a schema, we will instead create\n",
        "# a feature spec.  Since there are a fairly small number of features this is\n",
        "# manageable for this dataset.\n",
        "_FEATURE_SPEC = {\n",
        "    **{\n",
        "        feature: tf.io.FixedLenFeature(shape=[1], dtype=tf.float32)\n",
        "           for feature in _FEATURE_KEYS\n",
        "       },\n",
        "    _LABEL_KEY: tf.io.FixedLenFeature(shape=[1], dtype=tf.int64)\n",
        "}\n",
        "\n",
        "\n",
        "def _input_fn(file_pattern: List[str],\n",
        "              data_accessor: DataAccessor,\n",
        "              schema: schema_pb2.Schema,\n",
        "              batch_size: int = 200) -> tf.data.Dataset:\n",
        "  \"\"\"Generates features and label for training.\n",
        "\n",
        "  Args:\n",
        "    file_pattern: List of paths or patterns of input tfrecord files.\n",
        "    data_accessor: DataAccessor for converting input to RecordBatch.\n",
        "    schema: schema of the input data.\n",
        "    batch_size: representing the number of consecutive elements of returned\n",
        "      dataset to combine in a single batch\n",
        "\n",
        "  Returns:\n",
        "    A dataset that contains (features, indices) tuple where features is a\n",
        "      dictionary of Tensors, and indices is a single Tensor of label indices.\n",
        "  \"\"\"\n",
        "  return data_accessor.tf_dataset_factory(\n",
        "      file_pattern,\n",
        "      dataset_options.TensorFlowDatasetOptions(\n",
        "          batch_size=batch_size, label_key=_LABEL_KEY),\n",
        "      schema=schema).repeat()\n",
        "\n",
        "\n",
        "def _build_keras_model() -> tf.keras.Model:\n",
        "  \"\"\"Creates a DNN Keras model for classifying penguin data.\n",
        "\n",
        "  Returns:\n",
        "    A Keras Model.\n",
        "  \"\"\"\n",
        "  # The model below is built with Functional API, please refer to\n",
        "  # https://www.tensorflow.org/guide/keras/overview for all API options.\n",
        "  inputs = [keras.layers.Input(shape=(1,), name=f) for f in _FEATURE_KEYS]\n",
        "  d = keras.layers.concatenate(inputs)\n",
        "  for _ in range(2):\n",
        "    d = keras.layers.Dense(8, activation='relu')(d)\n",
        "  outputs = keras.layers.Dense(3)(d)\n",
        "\n",
        "  model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "  model.compile(\n",
        "      optimizer=keras.optimizers.Adam(1e-2),\n",
        "      loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "      metrics=[keras.metrics.SparseCategoricalAccuracy()])\n",
        "\n",
        "  model.summary(print_fn=logging.info)\n",
        "  return model\n",
        "\n",
        "\n",
        "# TFX Trainer will call this function.\n",
        "def run_fn(fn_args: TrainerFnArgs):\n",
        "  \"\"\"Train the model based on given args.\n",
        "\n",
        "  Args:\n",
        "    fn_args: Holds args used to train the model as name/value pairs.\n",
        "  \"\"\"\n",
        "\n",
        "  # This schema is usually either an output of SchemaGen or a manually-curated\n",
        "  # version provided by pipeline author. A schema can also derived from TFT\n",
        "  # graph if a Transform component is used. In the case when either is missing,\n",
        "  # `schema_from_feature_spec` could be used to generate schema from very simple\n",
        "  # feature_spec, but the schema returned would be very primitive.\n",
        "  schema = schema_utils.schema_from_feature_spec(_FEATURE_SPEC)\n",
        "\n",
        "  train_dataset = _input_fn(\n",
        "      fn_args.train_files,\n",
        "      fn_args.data_accessor,\n",
        "      schema,\n",
        "      batch_size=_TRAIN_BATCH_SIZE)\n",
        "  eval_dataset = _input_fn(\n",
        "      fn_args.eval_files,\n",
        "      fn_args.data_accessor,\n",
        "      schema,\n",
        "      batch_size=_EVAL_BATCH_SIZE)\n",
        "\n",
        "  model = _build_keras_model()\n",
        "  model.fit(\n",
        "      train_dataset,\n",
        "      steps_per_epoch=fn_args.train_steps,\n",
        "      validation_data=eval_dataset,\n",
        "      validation_steps=fn_args.eval_steps)\n",
        "\n",
        "  # The result of the training should be saved in `fn_args.serving_model_dir`\n",
        "  # directory.\n",
        "  model.save(fn_args.serving_model_dir, save_format='tf')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3OkNz3gTLwM"
      },
      "source": [
        "### Escreva uma definição de pipeline\n",
        "\n",
        "Definiremos uma função para criar um pipeline TFX. Além do componente Evaluator que mencionamos acima, adicionaremos mais um nó chamado [`Resolver`](https://www.tensorflow.org/tfx/api_docs/python/tfx/v1/dsl/Resolver). Para verificar se um novo modelo está ficando melhor que o modelo anterior, precisamos compará-lo com um modelo publicado anteriormente, chamado de referência (baseline). O [ML Metadata (MLMD)](https://www.tensorflow.org/tfx/guide/mlmd) rastreia todos os artefatos anteriores do pipeline e o `Resolver` pode encontrar qual foi o modelo *abençoado* mais recente - um modelo aprovado no Evaluator com sucesso - do MLMD usando uma classe de estratégia chamada `LatestBlessedModelStrategy`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M49yYVNBTPd4"
      },
      "outputs": [],
      "source": [
        "import tensorflow_model_analysis as tfma\n",
        "\n",
        "def _create_pipeline(pipeline_name: str, pipeline_root: str, data_root: str,\n",
        "                     module_file: str, serving_model_dir: str,\n",
        "                     metadata_path: str) -> tfx.dsl.Pipeline:\n",
        "  \"\"\"Creates a three component penguin pipeline with TFX.\"\"\"\n",
        "  # Brings data into the pipeline.\n",
        "  example_gen = tfx.components.CsvExampleGen(input_base=data_root)\n",
        "\n",
        "  # Uses user-provided Python function that trains a model.\n",
        "  trainer = tfx.components.Trainer(\n",
        "      module_file=module_file,\n",
        "      examples=example_gen.outputs['examples'],\n",
        "      train_args=tfx.proto.TrainArgs(num_steps=100),\n",
        "      eval_args=tfx.proto.EvalArgs(num_steps=5))\n",
        "\n",
        "  # NEW: Get the latest blessed model for Evaluator.\n",
        "  model_resolver = tfx.dsl.Resolver(\n",
        "      strategy_class=tfx.dsl.experimental.LatestBlessedModelStrategy,\n",
        "      model=tfx.dsl.Channel(type=tfx.types.standard_artifacts.Model),\n",
        "      model_blessing=tfx.dsl.Channel(\n",
        "          type=tfx.types.standard_artifacts.ModelBlessing)).with_id(\n",
        "              'latest_blessed_model_resolver')\n",
        "\n",
        "  # NEW: Uses TFMA to compute evaluation statistics over features of a model and\n",
        "  #   perform quality validation of a candidate model (compared to a baseline).\n",
        "\n",
        "  eval_config = tfma.EvalConfig(\n",
        "      model_specs=[tfma.ModelSpec(label_key='species')],\n",
        "      slicing_specs=[\n",
        "          # An empty slice spec means the overall slice, i.e. the whole dataset.\n",
        "          tfma.SlicingSpec(),\n",
        "          # Calculate metrics for each penguin species.\n",
        "          tfma.SlicingSpec(feature_keys=['species']),\n",
        "          ],\n",
        "      metrics_specs=[\n",
        "          tfma.MetricsSpec(per_slice_thresholds={\n",
        "              'sparse_categorical_accuracy':\n",
        "                  tfma.PerSliceMetricThresholds(thresholds=[\n",
        "                      tfma.PerSliceMetricThreshold(\n",
        "                          slicing_specs=[tfma.SlicingSpec()],\n",
        "                          threshold=tfma.MetricThreshold(\n",
        "                              value_threshold=tfma.GenericValueThreshold(\n",
        "                                   lower_bound={'value': 0.6}),\n",
        "                              # Change threshold will be ignored if there is no\n",
        "                              # baseline model resolved from MLMD (first run).\n",
        "                              change_threshold=tfma.GenericChangeThreshold(\n",
        "                                  direction=tfma.MetricDirection.HIGHER_IS_BETTER,\n",
        "                                  absolute={'value': -1e-10}))\n",
        "                       )]),\n",
        "          })],\n",
        "      )\n",
        "  evaluator = tfx.components.Evaluator(\n",
        "      examples=example_gen.outputs['examples'],\n",
        "      model=trainer.outputs['model'],\n",
        "      baseline_model=model_resolver.outputs['model'],\n",
        "      eval_config=eval_config)\n",
        "\n",
        "  # Checks whether the model passed the validation steps and pushes the model\n",
        "  # to a file destination if check passed.\n",
        "  pusher = tfx.components.Pusher(\n",
        "      model=trainer.outputs['model'],\n",
        "      model_blessing=evaluator.outputs['blessing'], # Pass an evaluation result.\n",
        "      push_destination=tfx.proto.PushDestination(\n",
        "          filesystem=tfx.proto.PushDestination.Filesystem(\n",
        "              base_directory=serving_model_dir)))\n",
        "\n",
        "  components = [\n",
        "      example_gen,\n",
        "      trainer,\n",
        "\n",
        "      # Following two components were added to the pipeline.\n",
        "      model_resolver,\n",
        "      evaluator,\n",
        "\n",
        "      pusher,\n",
        "  ]\n",
        "\n",
        "  return tfx.dsl.Pipeline(\n",
        "      pipeline_name=pipeline_name,\n",
        "      pipeline_root=pipeline_root,\n",
        "      metadata_connection_config=tfx.orchestration.metadata\n",
        "      .sqlite_metadata_connection_config(metadata_path),\n",
        "      components=components)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIcu1LeeQbMt"
      },
      "source": [
        "Precisamos fornecer as seguintes informações ao Evaluator via `eval_config`:\n",
        "\n",
        "- Métricas adicionais para configurar (se desejar mais métricas do que as definidas no modelo).\n",
        "- Fatias para configurar\n",
        "- Limites de validações do modelo para verificar se a validação deve ser incluída\n",
        "\n",
        "Como o `SparseCategoricalAccuracy` já foi incluído na chamada `model.compile()`, ele será incluído na análise automaticamente. Portanto, não adicionamos nenhuma métrica adicional aqui. O `SparseCategoricalAccuracy` será usado para decidir se o modelo também é bom o suficiente.\n",
        "\n",
        "Computamos as métricas para todo o dataset e para cada espécie de pinguim. `SlicingSpec` especifica como agregamos as métricas declaradas.\n",
        "\n",
        "Existem dois limites que um novo modelo deve ultrapassar, um é um limite absoluto de 0,6 e o ​​outro é um limite relativo que deve ser superior ao modelo de referência. Ao executar o pipeline pela primeira vez, `change_threshold` será ignorado e apenas value_threshold será verificado. Se você executar o pipeline mais de uma vez, o `Resolver` encontrará um modelo da execução anterior que será usado como modelo de referência para comparação.\n",
        "\n",
        "Consulte o [Guia do componente Evaluator](https://www.tensorflow.org/tfx/guide/evaluator#using_the_evaluator_component) para mais informações."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJbq07THU2GV"
      },
      "source": [
        "## Execute o pipeline\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mp0AkmrPdUb"
      },
      "source": [
        "Usaremos o `LocalDagRunner` como no tutorial anterior."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fAtfOZTYWJu-"
      },
      "outputs": [],
      "source": [
        "tfx.orchestration.LocalDagRunner().run(\n",
        "  _create_pipeline(\n",
        "      pipeline_name=PIPELINE_NAME,\n",
        "      pipeline_root=PIPELINE_ROOT,\n",
        "      data_root=DATA_ROOT,\n",
        "      module_file=_trainer_module_file,\n",
        "      serving_model_dir=SERVING_MODEL_DIR,\n",
        "      metadata_path=METADATA_PATH))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppERq0Mj6xvW"
      },
      "source": [
        "Quando o pipeline for concluído, você deverá ver algo como o seguinte:\n",
        "\n",
        "```\n",
        "INFO:absl:Blessing result True written to pipelines/penguin-tfma/Evaluator/blessing/4.\n",
        "```\n",
        "\n",
        "Ou você também pode verificar manualmente o diretório de saída onde os artefatos gerados estão armazenados. Se você visitar `pipelines/penguin-tfma/Evaluator/blessing/` com um navegador de arquivos, poderá ver um arquivo com o nome `BLESSED` (abençoado) ou `NOT_BLESSED` (não abençoado) de acordo com o resultado da avaliação.\n",
        "\n",
        "Se o resultado da bênção for `False`, o Pusher se recusará a enviar o modelo para `serving_model_dir`, porque o modelo não é bom o suficiente para ser usado em produção."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zR9HcqMSTizW"
      },
      "source": [
        "Você pode executar o pipeline novamente, possivelmente com configurações de avaliação diferentes. Mesmo que você execute o pipeline exatamente com a mesma configuração e dataset, o modelo treinado poderá ser um pouco diferente devido à aleatoriedade inerente ao treinamento do modelo, que pode levar a um modelo `NOT_BLESSED`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWcBI-bjoVTO"
      },
      "source": [
        "### Examine as saídas do pipeline\n",
        "\n",
        "Você pode usar o TFMA para investigar e visualizar o resultado da avaliação no artefato ModelEvaluation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXZ0N5GHm_tX"
      },
      "source": [
        "> **OBSERVAÇÃO: Se você não estiver no Colab, instale o Jupyter Extensions.** Você precisa de uma extensão TensorFlow Model Analysis para ver a visualização do TFMA. Esta extensão já está instalada no Google Colab, mas pode ser necessário instalá-la se você estiver executando este notebook em outros ambientes. Consulte as instruções de instalação da extensão Jupyter no [guia de instalação](https://github.com/tensorflow/model-analysis#installation).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VIWOBq0opag"
      },
      "source": [
        "#### Obtenha o resultado da análise dos artefatos de saída\n",
        "\n",
        "Você pode usar APIs MLMD para localizar essas saídas programaticamente. Primeiro, definiremos algumas funções utilitárias para procurar os artefatos de saída que acabaram de ser produzidos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aiK6zbeAg3X5"
      },
      "outputs": [],
      "source": [
        "from ml_metadata.proto import metadata_store_pb2\n",
        "# Non-public APIs, just for showcase.\n",
        "from tfx.orchestration.portable.mlmd import execution_lib\n",
        "\n",
        "# TODO(b/171447278): Move these functions into the TFX library.\n",
        "\n",
        "def get_latest_artifacts(metadata, pipeline_name, component_id):\n",
        "  \"\"\"Output artifacts of the latest run of the component.\"\"\"\n",
        "  context = metadata.store.get_context_by_type_and_name(\n",
        "      'node', f'{pipeline_name}.{component_id}')\n",
        "  executions = metadata.store.get_executions_by_context(context.id)\n",
        "  latest_execution = max(executions,\n",
        "                         key=lambda e:e.last_update_time_since_epoch)\n",
        "  return execution_lib.get_output_artifacts(metadata, latest_execution.id)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tujLG8sTGZiv"
      },
      "source": [
        "Podemos encontrar a execução mais recente do componente `Evaluator` e obter artefatos de saída dele."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4FOo6PV5g5Mm"
      },
      "outputs": [],
      "source": [
        "# Non-public APIs, just for showcase.\n",
        "from tfx.orchestration.metadata import Metadata\n",
        "from tfx.types import standard_component_specs\n",
        "\n",
        "metadata_connection_config = tfx.orchestration.metadata.sqlite_metadata_connection_config(\n",
        "    METADATA_PATH)\n",
        "\n",
        "with Metadata(metadata_connection_config) as metadata_handler:\n",
        "  # Find output artifacts from MLMD.\n",
        "  evaluator_output = get_latest_artifacts(metadata_handler, PIPELINE_NAME,\n",
        "                                          'Evaluator')\n",
        "  eval_artifact = evaluator_output[standard_component_specs.EVALUATION_KEY][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXIJR840GpEq"
      },
      "source": [
        "O `Evaluator` sempre retorna um artefato de avaliação e podemos visualizá-lo usando a biblioteca TensorFlow Model Analysis. Por exemplo, o código a seguir renderizará as métricas de precisão para cada espécie de pinguim."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wTaKoEHrj0Gs"
      },
      "outputs": [],
      "source": [
        "import tensorflow_model_analysis as tfma\n",
        "\n",
        "eval_result = tfma.load_eval_result(eval_artifact.uri)\n",
        "tfma.view.render_slicing_metrics(eval_result, slicing_column='species')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSwaiRQ0JYMZ"
      },
      "source": [
        "Se você escolher 'sparse_categorical_accuracy' na lista suspensa `Show`, poderá ver os valores de exatidão por espécie. Você pode querer adicionar mais fatias e verificar se o seu modelo é bom para todas as distribuições e se existe algum possível bias."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08R8qvweThRf"
      },
      "source": [
        "## Próximos passos\n",
        "\n",
        "Saiba mais sobre análise de modelos no [Tutorial da biblioteca TensorFlow Model Analysis](https://www.tensorflow.org/tfx/tutorials/model_analysis/tfma_basic).\n",
        "\n",
        "Você encontrará mais recursos em https://www.tensorflow.org/tfx/tutorials.\n",
        "\n",
        "Veja [Introdução aos pipelines do TFX](https://www.tensorflow.org/tfx/guide/understanding_tfx_pipelines) para saber mais sobre vários conceitos do TFX.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "DjUA6S30k52h",
        "lOjDv93eS5xV"
      ],
      "name": "penguin_tfma.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
