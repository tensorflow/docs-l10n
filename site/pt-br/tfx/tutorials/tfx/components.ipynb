{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdeKOEkv1Fe8"
      },
      "source": [
        "##### Copyright 2021 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "c2jyGuiG1gHr"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23R0Z9RojXYW"
      },
      "source": [
        "# Tutorial do componente TFX Estimator\n",
        "\n",
        "***Uma introdução ao TensorFlow Extended (TFX) componente por componente***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LidV2qsXm4XC"
      },
      "source": [
        "Observação: recomendamos executar este tutorial em um notebook Colab, sem necessidade de configuração! Basta clicar em “Executar no Google Colab”.\n",
        "\n",
        "<div class=\"devsite-table-wrapper\"><table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "<td>     <a target=\"_blank\" href=\"https://www.tensorflow.org/tfx/tutorials/tfx/components\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver em TensorFlow.org</a>\n",
        "</td>\n",
        "<td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/pt-br/tfx/tutorials/tfx/components.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Executar no Google Colab</a>\n",
        "</td>\n",
        "<td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/pt-br/tfx/tutorials/tfx/components.ipynb\"><img width=\"32px\" src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver fonte no GitHub</a>\n",
        "</td>\n",
        "<td>     <a target=\"_blank\" href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/pt-br/tfx/tutorials/tfx/components.ipynb\"><img width=\"32px\" src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Baixar notebook</a>\n",
        "</td>\n",
        "</table></div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBbTLeWmWs8q"
      },
      "source": [
        "> Aviso: os Estimadores não são recomendados para novos códigos. Os Estimadores executam código `v1.Session`, que é mais difícil de escrever corretamente e pode se comportar de forma inesperada, ainda mais quando usado em conjunto com código do TF 2. Os Estimadores são abarcados pelas [garantias de compatibilidade](https://tensorflow.org/guide/versions), mas não recebem mais correções, exceto para vulnerabilidades de segurança. Confira mais detalhes no [guia de migração](https://tensorflow.org/guide/migrate)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAD1tLoTm_QS"
      },
      "source": [
        "Este tutorial baseado em Colab percorrerá interativamente cada componente integrado do TensorFlow Extended (TFX).\n",
        "\n",
        "Ele cobre todas as etapas de um pipeline de aprendizado de máquina de ponta a ponta, desde a ingestão de dados até o envio de um modelo até a disponibilização do serviço.\n",
        "\n",
        "Quando terminar, o conteúdo deste notebook poderá ser exportado automaticamente como código-fonte do pipeline TFX, que você poderá orquestrar com Apache Airflow e Apache Beam.\n",
        "\n",
        "Observação: este notebook e suas APIs associadas são **experimentais** e estão em desenvolvimento ativo. São esperadas grandes mudanças na funcionalidade, comportamento e apresentação."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfSQ-kX-MLEr"
      },
      "source": [
        "## Contexto\n",
        "\n",
        "Este notebook demonstra como usar o TFX num ambiente Jupyter/Colab. Aqui, percorremos o exemplo do Chicago Taxi em um notebook interativo.\n",
        "\n",
        "Trabalhar com um notebook interativo é uma maneira útil de se familiarizar com a estrutura de um pipeline TFX. Também é útil ao desenvolver seus próprios pipelines como um ambiente de desenvolvimento leve, mas você deve estar ciente de que há diferenças na forma como os notebooks interativos são orquestrados e como eles acessam artefatos de metadados.\n",
        "\n",
        "### Orquestração\n",
        "\n",
        "Numa implantação TFX em produção, você usará um orquestrador como Apache Airflow, Kubeflow Pipelines ou Apache Beam para orquestrar o grafo de um pipeline predefinido de componentes do TFX. Num notebook interativo, o próprio notebook é o orquestrador, executando cada componente do TFX conforme você executa as células do notebook.\n",
        "\n",
        "### Metadados\n",
        "\n",
        "Numa implantação do TFX em produção, você acessará metadados por meio da API ML Metadata (MLMD). O MLMD armazena propriedades de metadados num banco de dados como MySQL ou SQLite e armazena as payloads de metadados em armazenamento persistente, como seu sistema de arquivos. Num notebook interativo, as propriedades e as cargas são armazenadas num banco de dados SQLite efêmero no diretório `/tmp` do notebook Jupyter ou do servidor Colab."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GivNBNYjb3b"
      },
      "source": [
        "## Configuração\n",
        "\n",
        "Primeiro, instalamos e importamos os pacotes necessários, configuramos caminhos e baixamos os dados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDl_6DkqJ-pG"
      },
      "source": [
        "### Atualize o Pip\n",
        "\n",
        "Para evitar a atualização do Pip num sistema ao executar localmente, garanta que estamos executando no Colab. Os sistemas locais podem, claro, ser atualizados separadamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFhBChv4J_PD"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  import colab\n",
        "  !pip install --upgrade pip\n",
        "except:\n",
        "  pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZOYTt1RW4TK"
      },
      "source": [
        "### Instale o TFX\n",
        "\n",
        "**Observação: no Google Colab, devido a atualizações de pacotes, na primeira vez que você executar esta célula você deverá reiniciar o runtime (Runtime &gt; Restart runtime...).**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S4SQA7Q5nej3"
      },
      "outputs": [],
      "source": [
        "!pip install tfx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "waGd75L0ktVw"
      },
      "source": [
        "### Desinstale o shapely\n",
        "\n",
        "TODO(b/263441833) Esta é uma solução temporária para evitar um ImportError. Em última análise, isto deverá ser resolvido com suporte a uma versão mais recente do Bigquery, em vez de desinstalar outras dependências extras."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y8hwtlmbktkV"
      },
      "outputs": [],
      "source": [
        "!pip uninstall shapely -y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szPQ2MDYPZ5j"
      },
      "source": [
        "## Você reiniciou o runtime?\n",
        "\n",
        "Se você estiver usando o Google Colab, na primeira vez que executar a célula acima, você deve reiniciar o runtime (\"Runtime &gt; Restart runtime ...\"). Isso é necessário devido à maneira como o Colab carrega os pacotes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-ePgV0Lj68Q"
      },
      "source": [
        "### Importe os pacotes\n",
        "\n",
        "Importamos os pacotes necessários, incluindo classes de componentes TFX padrão."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YIqpWK9efviJ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pprint\n",
        "import tempfile\n",
        "import urllib\n",
        "\n",
        "import absl\n",
        "import tensorflow as tf\n",
        "import tensorflow_model_analysis as tfma\n",
        "tf.get_logger().propagate = False\n",
        "pp = pprint.PrettyPrinter()\n",
        "\n",
        "from tfx import v1 as tfx\n",
        "from tfx.orchestration.experimental.interactive.interactive_context import InteractiveContext\n",
        "\n",
        "%load_ext tfx.orchestration.experimental.interactive.notebook_extensions.skip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCZTHRy0N1D6"
      },
      "source": [
        "Vamos verificar as versões das bibliotecas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eZ4K18_DN2D8"
      },
      "outputs": [],
      "source": [
        "print('TensorFlow version: {}'.format(tf.__version__))\n",
        "print('TFX version: {}'.format(tfx.__version__))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufJKQ6OvkJlY"
      },
      "source": [
        "### Configure os caminhos do pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ad5JLpKbf6sN"
      },
      "outputs": [],
      "source": [
        "# This is the root directory for your TFX pip package installation.\n",
        "_tfx_root = tfx.__path__[0]\n",
        "\n",
        "# This is the directory containing the TFX Chicago Taxi Pipeline example.\n",
        "_taxi_root = os.path.join(_tfx_root, 'examples/chicago_taxi_pipeline')\n",
        "\n",
        "# This is the path where your model will be pushed for serving.\n",
        "_serving_model_dir = os.path.join(\n",
        "    tempfile.mkdtemp(), 'serving_model/taxi_simple')\n",
        "\n",
        "# Set up logging.\n",
        "absl.logging.set_verbosity(absl.logging.INFO)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2cMMAbSkGfX"
      },
      "source": [
        "### Baixe dados de exemplo\n",
        "\n",
        "Baixamos o dataset de exemplo para uso em nosso pipeline TFX.\n",
        "\n",
        "O dataset que estamos usando é o [dataset Taxi Trips](https://data.cityofchicago.org/Transportation/Taxi-Trips/wrvz-psew) disponibilizado pela cidade de Chicago. As colunas neste dataset são:\n",
        "\n",
        "<table>\n",
        "<tr>\n",
        "<td>pickup_community_area</td>\n",
        "<td>fare</td>\n",
        "<td>trip_start_month</td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>trip_start_hour</td>\n",
        "<td>trip_start_day</td>\n",
        "<td>trip_start_timestamp</td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>pickup_latitude</td>\n",
        "<td>pickup_longitude</td>\n",
        "<td>dropoff_latitude</td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>dropoff_longitude</td>\n",
        "<td>trip_miles</td>\n",
        "<td>pickup_census_tract</td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>dropoff_census_tract</td>\n",
        "<td>payment_type</td>\n",
        "<td>company</td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>trip_seconds</td>\n",
        "<td>dropoff_community_area</td>\n",
        "<td>tips</td>\n",
        "</tr>\n",
        "</table>\n",
        "\n",
        "Com esse dataset, construiremos um modelo que irá prever as `tips` (gorjetas) de uma viagem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BywX6OUEhAqn"
      },
      "outputs": [],
      "source": [
        "_data_root = tempfile.mkdtemp(prefix='tfx-data')\n",
        "DATA_PATH = 'https://raw.githubusercontent.com/tensorflow/tfx/master/tfx/examples/chicago_taxi_pipeline/data/simple/data.csv'\n",
        "_data_filepath = os.path.join(_data_root, \"data.csv\")\n",
        "urllib.request.urlretrieve(DATA_PATH, _data_filepath)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blZC1sIQOWfH"
      },
      "source": [
        "Dê uma olhada rápida no arquivo CSV."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c5YPeLPFOXaD"
      },
      "outputs": [],
      "source": [
        "!head {_data_filepath}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QioyhunCImwE"
      },
      "source": [
        "*Observação: Este site fornece aplicativos que utilizam dados que foram modificados para uso a partir de sua fonte original obtida em www.cityofchicago.org, site oficial da cidade de Chicago. A cidade de Chicago não faz nenhuma reivindicação quanto ao conteúdo, precisão, atualidade ou integridade de qualquer um dos dados fornecidos neste site. Os dados fornecidos neste site estão sujeitos a alterações a qualquer momento. Entende-se que os dados fornecidos neste site são utilizados por sua conta e risco.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ONIE_hdkPS4"
      },
      "source": [
        "### Crie o InteractiveContext\n",
        "\n",
        "Por último, criamos um InteractiveContext, que nos permitirá executar componentes TFX interativamente neste notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Rh6K5sUf9dd"
      },
      "outputs": [],
      "source": [
        "# Here, we create an InteractiveContext using default parameters. This will\n",
        "# use a temporary directory with an ephemeral ML Metadata database instance.\n",
        "# To use your own pipeline root or database, the optional properties\n",
        "# `pipeline_root` and `metadata_connection_config` may be passed to\n",
        "# InteractiveContext. Calls to InteractiveContext are no-ops outside of the\n",
        "# notebook.\n",
        "context = InteractiveContext()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdQWxfsVkzdJ"
      },
      "source": [
        "## Execute componentes TFX interativamente\n",
        "\n",
        "Nas células a seguir, criamos os componentes TFX um por um, executamos cada um deles e visualizamos seus artefatos de saída."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9fwt9gQk3BR"
      },
      "source": [
        "### ExampleGen\n",
        "\n",
        "O componente `ExampleGen` geralmente está no início de um pipeline TFX. Ele vai:\n",
        "\n",
        "1. Dividir os dados em datasets de treinamento e avaliação (por padrão, 2/3 de treinamento + 1/3 de avaliação)\n",
        "2. Converter dados para o formato `tf.Example` (saiba mais [aqui](https://www.tensorflow.org/tutorials/load_data/tfrecord))\n",
        "3. Copiar dados para o diretório `_tfx_root` para que outros componentes possam acessar\n",
        "\n",
        "O `ExampleGen` toma como entrada o caminho para sua fonte de dados. No nosso caso, este é o caminho `_data_root` que contém o CSV baixado.\n",
        "\n",
        "Observação: neste notebook, podemos instanciar os componentes um por um e executá-los com `InteractiveContext.run()`. Por outro lado, num ambiente de produção, especificaríamos todos os componentes antecipadamente num `Pipeline` para passar ao orquestrador (veja o [Guia de criação de um pipeline TFX](https://www.tensorflow.org/tfx/guide/build_tfx_pipeline))."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PyXjuMt8f-9u"
      },
      "outputs": [],
      "source": [
        "example_gen = tfx.components.CsvExampleGen(input_base=_data_root)\n",
        "context.run(example_gen)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OqCoZh7KPUm9"
      },
      "source": [
        "Vamos examinar os artefatos de saída de `ExampleGen`. Este componente produz dois artefatos, exemplos de treinamento e exemplos de avaliação:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "880KkTAkPeUg"
      },
      "outputs": [],
      "source": [
        "artifact = example_gen.outputs['examples'].get()[0]\n",
        "print(artifact.split_names, artifact.uri)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6vcbW_wPqvl"
      },
      "source": [
        "Também podemos dar uma olhada nos três primeiros exemplos de treinamento:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H4XIXjiCPwzQ"
      },
      "outputs": [],
      "source": [
        "# Get the URI of the output artifact representing the training examples, which is a directory\n",
        "train_uri = os.path.join(example_gen.outputs['examples'].get()[0].uri, 'Split-train')\n",
        "\n",
        "# Get the list of files in this directory (all compressed TFRecord files)\n",
        "tfrecord_filenames = [os.path.join(train_uri, name)\n",
        "                      for name in os.listdir(train_uri)]\n",
        "\n",
        "# Create a `TFRecordDataset` to read these files\n",
        "dataset = tf.data.TFRecordDataset(tfrecord_filenames, compression_type=\"GZIP\")\n",
        "\n",
        "# Iterate over the first 3 records and decode them.\n",
        "for tfrecord in dataset.take(3):\n",
        "  serialized_example = tfrecord.numpy()\n",
        "  example = tf.train.Example()\n",
        "  example.ParseFromString(serialized_example)\n",
        "  pp.pprint(example)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2gluYjccf-IP"
      },
      "source": [
        "Agora que `ExampleGen` concluiu a ingestão dos dados, a próxima etapa será a análise dos dados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csM6BFhtk5Aa"
      },
      "source": [
        "### StatisticsGen\n",
        "\n",
        "O componente `StatisticsGen` computa estatísticas sobre seu dataset para análise de dados, bem como para uso em componentes downstream. Ele usa a biblioteca [TensorFlow Data Validation](https://www.tensorflow.org/tfx/data_validation/get_started).\n",
        "\n",
        "`StatisticsGen` toma como entrada o dataset que acabamos de ingerir usando `ExampleGen`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MAscCCYWgA-9"
      },
      "outputs": [],
      "source": [
        "statistics_gen = tfx.components.StatisticsGen(examples=example_gen.outputs['examples'])\n",
        "context.run(statistics_gen)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLI6cb_5WugZ"
      },
      "source": [
        "Depois que `StatisticsGen` terminar a execução, podemos visualizar as estatísticas geradas. Experimente brincar com os diferentes gráficos!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tLjXy7K6Tp_G"
      },
      "outputs": [],
      "source": [
        "context.show(statistics_gen.outputs['statistics'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLKLTO9Nk60p"
      },
      "source": [
        "### SchemaGen\n",
        "\n",
        "O componente `SchemaGen` gera um esquema com base nas suas estatísticas de dados. (Um esquema define os limites, tipos e propriedades esperados das características em seu dataset.) Ele também usa a biblioteca [TensorFlow Data Validation](https://www.tensorflow.org/tfx/data_validation/get_started).\n",
        "\n",
        "O `SchemaGen` terá como entrada as estatísticas que geramos com `StatisticsGen`, observando a divisão de treinamento por padrão."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ygQvZ6hsiQ_J"
      },
      "outputs": [],
      "source": [
        "schema_gen = tfx.components.SchemaGen(\n",
        "    statistics=statistics_gen.outputs['statistics'],\n",
        "    infer_feature_shape=False)\n",
        "context.run(schema_gen)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zi6TxTUKXM6b"
      },
      "source": [
        "Após a execução do `SchemaGen`, podemos visualizar o esquema gerado como uma tabela."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ec9vqDXpXeMb"
      },
      "outputs": [],
      "source": [
        "context.show(schema_gen.outputs['schema'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZWWdbA-m7zp"
      },
      "source": [
        "Cada característica no seu dataset aparece como uma linha na tabela do esquema, junto com suas propriedades. O esquema também captura todos os valores que uma característica categórica assume, denotados como o seu domínio.\n",
        "\n",
        "Para saber mais sobre esquemas, consulte a [documentação do SchemaGen](https://www.tensorflow.org/tfx/guide/schemagen)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1qcUuO9k9f8"
      },
      "source": [
        "### ExampleValidator\n",
        "\n",
        "O componente `ExampleValidator` detecta anomalias em seus dados, com base nas expectativas definidas pelo esquema. Ele também usa a biblioteca [TensorFlow Data Validation](https://www.tensorflow.org/tfx/data_validation/get_started).\n",
        "\n",
        "O `ExampleValidator` receberá como entrada as estatísticas de `StatisticsGen` e o esquema de `SchemaGen`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XRlRUuGgiXks"
      },
      "outputs": [],
      "source": [
        "example_validator = tfx.components.ExampleValidator(\n",
        "    statistics=statistics_gen.outputs['statistics'],\n",
        "    schema=schema_gen.outputs['schema'])\n",
        "context.run(example_validator)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "855mrHgJcoer"
      },
      "source": [
        "Após a execução do `ExampleValidator`, podemos visualizar as anomalias como uma tabela."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TDyAAozQcrk3"
      },
      "outputs": [],
      "source": [
        "context.show(example_validator.outputs['anomalies'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znMoJj60ybZx"
      },
      "source": [
        "Na tabela de anomalias, podemos observar que não há anomalias. Isto é o que esperávamos, já que este é o primeiro dataset que analisamos e o esquema foi adaptado a ele. Você deve revisar este esquema – qualquer coisa inesperada significa uma anomalia nos dados. Depois de revisado, o esquema poderá ser usado para proteger dados futuros, e as anomalias produzidas aqui podem ser usadas para depurar o desempenho do modelo, entender como seus dados evoluem ao longo do tempo e identificar erros de dados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPViEz5RlA36"
      },
      "source": [
        "### Transform\n",
        "\n",
        "O componente `Transform` realiza engenharia de características para treinamento e serviço. Ele usa a biblioteca [TensorFlow Transform](https://www.tensorflow.org/tfx/transform/get_started).\n",
        "\n",
        "O `Transform` terá como entrada os dados de `ExampleGen`, o esquema de `SchemaGen`, bem como um módulo que contém código Transform definido pelo usuário.\n",
        "\n",
        "Vejamos abaixo um exemplo de código Transform definido pelo usuário (para uma introdução às APIs TensorFlow Transform, [consulte o tutorial](https://www.tensorflow.org/tfx/tutorials/transform/simple)). Primeiro, definimos algumas constantes para engenharia de características:\n",
        "\n",
        "Observação: A magia da célula `%%writefile` salvará o conteúdo da célula como um arquivo `.py` no disco. Isso permite que o componente `Transform` carregar seu código como um módulo.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PuNSiUKb4YJf"
      },
      "outputs": [],
      "source": [
        "_taxi_constants_module_file = 'taxi_constants.py'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HPjhXuIF4YJh"
      },
      "outputs": [],
      "source": [
        "%%writefile {_taxi_constants_module_file}\n",
        "\n",
        "# Categorical features are assumed to each have a maximum value in the dataset.\n",
        "MAX_CATEGORICAL_FEATURE_VALUES = [24, 31, 12]\n",
        "\n",
        "CATEGORICAL_FEATURE_KEYS = [\n",
        "    'trip_start_hour', 'trip_start_day', 'trip_start_month',\n",
        "    'pickup_census_tract', 'dropoff_census_tract', 'pickup_community_area',\n",
        "    'dropoff_community_area'\n",
        "]\n",
        "\n",
        "DENSE_FLOAT_FEATURE_KEYS = ['trip_miles', 'fare', 'trip_seconds']\n",
        "\n",
        "# Number of buckets used by tf.transform for encoding each feature.\n",
        "FEATURE_BUCKET_COUNT = 10\n",
        "\n",
        "BUCKET_FEATURE_KEYS = [\n",
        "    'pickup_latitude', 'pickup_longitude', 'dropoff_latitude',\n",
        "    'dropoff_longitude'\n",
        "]\n",
        "\n",
        "# Number of vocabulary terms used for encoding VOCAB_FEATURES by tf.transform\n",
        "VOCAB_SIZE = 1000\n",
        "\n",
        "# Count of out-of-vocab buckets in which unrecognized VOCAB_FEATURES are hashed.\n",
        "OOV_SIZE = 10\n",
        "\n",
        "VOCAB_FEATURE_KEYS = [\n",
        "    'payment_type',\n",
        "    'company',\n",
        "]\n",
        "\n",
        "# Keys\n",
        "LABEL_KEY = 'tips'\n",
        "FARE_KEY = 'fare'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Duj2Ax5z4YJl"
      },
      "source": [
        "Em seguida, escrevemos um `preprocessing_fn` que recebe dados brutos como entrada e retorna características transformadas que nosso modelo pode usar para treinar:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4AJ9hBs94YJm"
      },
      "outputs": [],
      "source": [
        "_taxi_transform_module_file = 'taxi_transform.py'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MYmxxx9A4YJn"
      },
      "outputs": [],
      "source": [
        "%%writefile {_taxi_transform_module_file}\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_transform as tft\n",
        "\n",
        "import taxi_constants\n",
        "\n",
        "_DENSE_FLOAT_FEATURE_KEYS = taxi_constants.DENSE_FLOAT_FEATURE_KEYS\n",
        "_VOCAB_FEATURE_KEYS = taxi_constants.VOCAB_FEATURE_KEYS\n",
        "_VOCAB_SIZE = taxi_constants.VOCAB_SIZE\n",
        "_OOV_SIZE = taxi_constants.OOV_SIZE\n",
        "_FEATURE_BUCKET_COUNT = taxi_constants.FEATURE_BUCKET_COUNT\n",
        "_BUCKET_FEATURE_KEYS = taxi_constants.BUCKET_FEATURE_KEYS\n",
        "_CATEGORICAL_FEATURE_KEYS = taxi_constants.CATEGORICAL_FEATURE_KEYS\n",
        "_FARE_KEY = taxi_constants.FARE_KEY\n",
        "_LABEL_KEY = taxi_constants.LABEL_KEY\n",
        "\n",
        "\n",
        "def preprocessing_fn(inputs):\n",
        "  \"\"\"tf.transform's callback function for preprocessing inputs.\n",
        "  Args:\n",
        "    inputs: map from feature keys to raw not-yet-transformed features.\n",
        "  Returns:\n",
        "    Map from string feature key to transformed feature operations.\n",
        "  \"\"\"\n",
        "  outputs = {}\n",
        "  for key in _DENSE_FLOAT_FEATURE_KEYS:\n",
        "    # If sparse make it dense, setting nan's to 0 or '', and apply zscore.\n",
        "    outputs[key] = tft.scale_to_z_score(\n",
        "        _fill_in_missing(inputs[key]))\n",
        "\n",
        "  for key in _VOCAB_FEATURE_KEYS:\n",
        "    # Build a vocabulary for this feature.\n",
        "    outputs[key] = tft.compute_and_apply_vocabulary(\n",
        "        _fill_in_missing(inputs[key]),\n",
        "        top_k=_VOCAB_SIZE,\n",
        "        num_oov_buckets=_OOV_SIZE)\n",
        "\n",
        "  for key in _BUCKET_FEATURE_KEYS:\n",
        "    outputs[key] = tft.bucketize(\n",
        "        _fill_in_missing(inputs[key]), _FEATURE_BUCKET_COUNT)\n",
        "\n",
        "  for key in _CATEGORICAL_FEATURE_KEYS:\n",
        "    outputs[key] = _fill_in_missing(inputs[key])\n",
        "\n",
        "  # Was this passenger a big tipper?\n",
        "  taxi_fare = _fill_in_missing(inputs[_FARE_KEY])\n",
        "  tips = _fill_in_missing(inputs[_LABEL_KEY])\n",
        "  outputs[_LABEL_KEY] = tf.where(\n",
        "      tf.math.is_nan(taxi_fare),\n",
        "      tf.cast(tf.zeros_like(taxi_fare), tf.int64),\n",
        "      # Test if the tip was > 20% of the fare.\n",
        "      tf.cast(\n",
        "          tf.greater(tips, tf.multiply(taxi_fare, tf.constant(0.2))), tf.int64))\n",
        "\n",
        "  return outputs\n",
        "\n",
        "\n",
        "def _fill_in_missing(x):\n",
        "  \"\"\"Replace missing values in a SparseTensor.\n",
        "  Fills in missing values of `x` with '' or 0, and converts to a dense tensor.\n",
        "  Args:\n",
        "    x: A `SparseTensor` of rank 2.  Its dense shape should have size at most 1\n",
        "      in the second dimension.\n",
        "  Returns:\n",
        "    A rank 1 tensor where missing values of `x` have been filled in.\n",
        "  \"\"\"\n",
        "  if not isinstance(x, tf.sparse.SparseTensor):\n",
        "    return x\n",
        "\n",
        "  default_value = '' if x.dtype == tf.string else 0\n",
        "  return tf.squeeze(\n",
        "      tf.sparse.to_dense(\n",
        "          tf.SparseTensor(x.indices, x.values, [x.dense_shape[0], 1]),\n",
        "          default_value),\n",
        "      axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgbmZr3sgbWW"
      },
      "source": [
        "Agora, passamos este código de engenharia de características para o componente `Transform` e o executamos para transformar seus dados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jHfhth_GiZI9"
      },
      "outputs": [],
      "source": [
        "transform = tfx.components.Transform(\n",
        "    examples=example_gen.outputs['examples'],\n",
        "    schema=schema_gen.outputs['schema'],\n",
        "    module_file=os.path.abspath(_taxi_transform_module_file))\n",
        "context.run(transform)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwAwb4rARRQ2"
      },
      "source": [
        "Vamos examinar os artefatos de saída de `Transform`. Este componente produz dois tipos de saídas:\n",
        "\n",
        "- `transform_graph` é o grafo que pode realizar as operações de pré-processamento (este grafo será incluído nos modelos de serviço e avaliação).\n",
        "- `transformed_examples` representa os dados pré-processados ​​de treinamento e avaliação."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SClrAaEGR1O5"
      },
      "outputs": [],
      "source": [
        "transform.outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyFkBd9AR1sy"
      },
      "source": [
        "Dê uma olhada no artefato `transform_graph`: ele aponta para um diretório contendo 3 subdiretórios:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5tRw4DneR3i7"
      },
      "outputs": [],
      "source": [
        "train_uri = transform.outputs['transform_graph'].get()[0].uri\n",
        "os.listdir(train_uri)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fqV54CIR6Pu"
      },
      "source": [
        "O subdiretório `transformed_metadata` contém o esquema dos dados pré-processados. O subdiretório `transform_fn` contém o grafo de pré-processamento real. O subdiretório `metadata` contém o esquema dos dados originais.\n",
        "\n",
        "Também podemos dar uma olhada nos três primeiros exemplos transformados:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pwbW2zPKR_S4"
      },
      "outputs": [],
      "source": [
        "# Get the URI of the output artifact representing the transformed examples, which is a directory\n",
        "train_uri = os.path.join(transform.outputs['transformed_examples'].get()[0].uri, 'Split-train')\n",
        "\n",
        "# Get the list of files in this directory (all compressed TFRecord files)\n",
        "tfrecord_filenames = [os.path.join(train_uri, name)\n",
        "                      for name in os.listdir(train_uri)]\n",
        "\n",
        "# Create a `TFRecordDataset` to read these files\n",
        "dataset = tf.data.TFRecordDataset(tfrecord_filenames, compression_type=\"GZIP\")\n",
        "\n",
        "# Iterate over the first 3 records and decode them.\n",
        "for tfrecord in dataset.take(3):\n",
        "  serialized_example = tfrecord.numpy()\n",
        "  example = tf.train.Example()\n",
        "  example.ParseFromString(serialized_example)\n",
        "  pp.pprint(example)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_b_V6eN4f69"
      },
      "source": [
        "Depois que o componente `Transform` transformar seus dados em características, a próxima etapa é treinar um modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBJFtnl6lCg9"
      },
      "source": [
        "### Trainer\n",
        "\n",
        "O componente `Trainer` treinará um modelo que você definir no TensorFlow (usando a API Estimator ou a API Keras com [`model_to_estimator`](https://www.tensorflow.org/api_docs/python/tf/keras/estimator/model_to_estimator)).\n",
        "\n",
        "O `Trainer` recebe como entrada o esquema do `SchemaGen`, os dados e o grafo transformados de `Transform`, os parâmetros de treinamento, bem como um módulo que contém código de modelo definido pelo usuário.\n",
        "\n",
        "Vejamos abaixo um exemplo de código de modelo definido pelo usuário (para uma introdução às APIs do TensorFlow Estimator, [consulte o tutorial](https://www.tensorflow.org/tutorials/estimator/premade)):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N1376oq04YJt"
      },
      "outputs": [],
      "source": [
        "_taxi_trainer_module_file = 'taxi_trainer.py'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nf9UuNng4YJu"
      },
      "outputs": [],
      "source": [
        "%%writefile {_taxi_trainer_module_file}\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_model_analysis as tfma\n",
        "import tensorflow_transform as tft\n",
        "from tensorflow_transform.tf_metadata import schema_utils\n",
        "from tfx_bsl.tfxio import dataset_options\n",
        "\n",
        "import taxi_constants\n",
        "\n",
        "_DENSE_FLOAT_FEATURE_KEYS = taxi_constants.DENSE_FLOAT_FEATURE_KEYS\n",
        "_VOCAB_FEATURE_KEYS = taxi_constants.VOCAB_FEATURE_KEYS\n",
        "_VOCAB_SIZE = taxi_constants.VOCAB_SIZE\n",
        "_OOV_SIZE = taxi_constants.OOV_SIZE\n",
        "_FEATURE_BUCKET_COUNT = taxi_constants.FEATURE_BUCKET_COUNT\n",
        "_BUCKET_FEATURE_KEYS = taxi_constants.BUCKET_FEATURE_KEYS\n",
        "_CATEGORICAL_FEATURE_KEYS = taxi_constants.CATEGORICAL_FEATURE_KEYS\n",
        "_MAX_CATEGORICAL_FEATURE_VALUES = taxi_constants.MAX_CATEGORICAL_FEATURE_VALUES\n",
        "_LABEL_KEY = taxi_constants.LABEL_KEY\n",
        "\n",
        "\n",
        "# Tf.Transform considers these features as \"raw\"\n",
        "def _get_raw_feature_spec(schema):\n",
        "  return schema_utils.schema_as_feature_spec(schema).feature_spec\n",
        "\n",
        "\n",
        "def _build_estimator(config, hidden_units=None, warm_start_from=None):\n",
        "  \"\"\"Build an estimator for predicting the tipping behavior of taxi riders.\n",
        "  Args:\n",
        "    config: tf.estimator.RunConfig defining the runtime environment for the\n",
        "      estimator (including model_dir).\n",
        "    hidden_units: [int], the layer sizes of the DNN (input layer first)\n",
        "    warm_start_from: Optional directory to warm start from.\n",
        "  Returns:\n",
        "    A dict of the following:\n",
        "      - estimator: The estimator that will be used for training and eval.\n",
        "      - train_spec: Spec for training.\n",
        "      - eval_spec: Spec for eval.\n",
        "      - eval_input_receiver_fn: Input function for eval.\n",
        "  \"\"\"\n",
        "  real_valued_columns = [\n",
        "      tf.feature_column.numeric_column(key, shape=())\n",
        "      for key in _DENSE_FLOAT_FEATURE_KEYS\n",
        "  ]\n",
        "  categorical_columns = [\n",
        "      tf.feature_column.categorical_column_with_identity(\n",
        "          key, num_buckets=_VOCAB_SIZE + _OOV_SIZE, default_value=0)\n",
        "      for key in _VOCAB_FEATURE_KEYS\n",
        "  ]\n",
        "  categorical_columns += [\n",
        "      tf.feature_column.categorical_column_with_identity(\n",
        "          key, num_buckets=_FEATURE_BUCKET_COUNT, default_value=0)\n",
        "      for key in _BUCKET_FEATURE_KEYS\n",
        "  ]\n",
        "  categorical_columns += [\n",
        "      tf.feature_column.categorical_column_with_identity(  # pylint: disable=g-complex-comprehension\n",
        "          key,\n",
        "          num_buckets=num_buckets,\n",
        "          default_value=0) for key, num_buckets in zip(\n",
        "              _CATEGORICAL_FEATURE_KEYS,\n",
        "              _MAX_CATEGORICAL_FEATURE_VALUES)\n",
        "  ]\n",
        "  return tf.estimator.DNNLinearCombinedClassifier(\n",
        "      config=config,\n",
        "      linear_feature_columns=categorical_columns,\n",
        "      dnn_feature_columns=real_valued_columns,\n",
        "      dnn_hidden_units=hidden_units or [100, 70, 50, 25],\n",
        "      warm_start_from=warm_start_from)\n",
        "\n",
        "\n",
        "def _example_serving_receiver_fn(tf_transform_graph, schema):\n",
        "  \"\"\"Build the serving in inputs.\n",
        "  Args:\n",
        "    tf_transform_graph: A TFTransformOutput.\n",
        "    schema: the schema of the input data.\n",
        "  Returns:\n",
        "    Tensorflow graph which parses examples, applying tf-transform to them.\n",
        "  \"\"\"\n",
        "  raw_feature_spec = _get_raw_feature_spec(schema)\n",
        "  raw_feature_spec.pop(_LABEL_KEY)\n",
        "\n",
        "  raw_input_fn = tf.estimator.export.build_parsing_serving_input_receiver_fn(\n",
        "      raw_feature_spec, default_batch_size=None)\n",
        "  serving_input_receiver = raw_input_fn()\n",
        "\n",
        "  transformed_features = tf_transform_graph.transform_raw_features(\n",
        "      serving_input_receiver.features)\n",
        "\n",
        "  return tf.estimator.export.ServingInputReceiver(\n",
        "      transformed_features, serving_input_receiver.receiver_tensors)\n",
        "\n",
        "\n",
        "def _eval_input_receiver_fn(tf_transform_graph, schema):\n",
        "  \"\"\"Build everything needed for the tf-model-analysis to run the model.\n",
        "  Args:\n",
        "    tf_transform_graph: A TFTransformOutput.\n",
        "    schema: the schema of the input data.\n",
        "  Returns:\n",
        "    EvalInputReceiver function, which contains:\n",
        "      - Tensorflow graph which parses raw untransformed features, applies the\n",
        "        tf-transform preprocessing operators.\n",
        "      - Set of raw, untransformed features.\n",
        "      - Label against which predictions will be compared.\n",
        "  \"\"\"\n",
        "  # Notice that the inputs are raw features, not transformed features here.\n",
        "  raw_feature_spec = _get_raw_feature_spec(schema)\n",
        "\n",
        "  serialized_tf_example = tf.compat.v1.placeholder(\n",
        "      dtype=tf.string, shape=[None], name='input_example_tensor')\n",
        "\n",
        "  # Add a parse_example operator to the tensorflow graph, which will parse\n",
        "  # raw, untransformed, tf examples.\n",
        "  features = tf.io.parse_example(serialized_tf_example, raw_feature_spec)\n",
        "\n",
        "  # Now that we have our raw examples, process them through the tf-transform\n",
        "  # function computed during the preprocessing step.\n",
        "  transformed_features = tf_transform_graph.transform_raw_features(\n",
        "      features)\n",
        "\n",
        "  # The key name MUST be 'examples'.\n",
        "  receiver_tensors = {'examples': serialized_tf_example}\n",
        "\n",
        "  # NOTE: Model is driven by transformed features (since training works on the\n",
        "  # materialized output of TFT, but slicing will happen on raw features.\n",
        "  features.update(transformed_features)\n",
        "\n",
        "  return tfma.export.EvalInputReceiver(\n",
        "      features=features,\n",
        "      receiver_tensors=receiver_tensors,\n",
        "      labels=transformed_features[_LABEL_KEY])\n",
        "\n",
        "\n",
        "def _input_fn(file_pattern, data_accessor, tf_transform_output, batch_size=200):\n",
        "  \"\"\"Generates features and label for tuning/training.\n",
        "\n",
        "  Args:\n",
        "    file_pattern: List of paths or patterns of input tfrecord files.\n",
        "    data_accessor: DataAccessor for converting input to RecordBatch.\n",
        "    tf_transform_output: A TFTransformOutput.\n",
        "    batch_size: representing the number of consecutive elements of returned\n",
        "      dataset to combine in a single batch\n",
        "\n",
        "  Returns:\n",
        "    A dataset that contains (features, indices) tuple where features is a\n",
        "      dictionary of Tensors, and indices is a single Tensor of label indices.\n",
        "  \"\"\"\n",
        "  return data_accessor.tf_dataset_factory(\n",
        "      file_pattern,\n",
        "      dataset_options.TensorFlowDatasetOptions(\n",
        "          batch_size=batch_size, label_key=_LABEL_KEY),\n",
        "      tf_transform_output.transformed_metadata.schema)\n",
        "\n",
        "\n",
        "# TFX will call this function\n",
        "def trainer_fn(trainer_fn_args, schema):\n",
        "  \"\"\"Build the estimator using the high level API.\n",
        "  Args:\n",
        "    trainer_fn_args: Holds args used to train the model as name/value pairs.\n",
        "    schema: Holds the schema of the training examples.\n",
        "  Returns:\n",
        "    A dict of the following:\n",
        "      - estimator: The estimator that will be used for training and eval.\n",
        "      - train_spec: Spec for training.\n",
        "      - eval_spec: Spec for eval.\n",
        "      - eval_input_receiver_fn: Input function for eval.\n",
        "  \"\"\"\n",
        "  # Number of nodes in the first layer of the DNN\n",
        "  first_dnn_layer_size = 100\n",
        "  num_dnn_layers = 4\n",
        "  dnn_decay_factor = 0.7\n",
        "\n",
        "  train_batch_size = 40\n",
        "  eval_batch_size = 40\n",
        "\n",
        "  tf_transform_graph = tft.TFTransformOutput(trainer_fn_args.transform_output)\n",
        "\n",
        "  train_input_fn = lambda: _input_fn(  # pylint: disable=g-long-lambda\n",
        "      trainer_fn_args.train_files,\n",
        "      trainer_fn_args.data_accessor,\n",
        "      tf_transform_graph,\n",
        "      batch_size=train_batch_size)\n",
        "\n",
        "  eval_input_fn = lambda: _input_fn(  # pylint: disable=g-long-lambda\n",
        "      trainer_fn_args.eval_files,\n",
        "      trainer_fn_args.data_accessor,\n",
        "      tf_transform_graph,\n",
        "      batch_size=eval_batch_size)\n",
        "\n",
        "  train_spec = tf.estimator.TrainSpec(  # pylint: disable=g-long-lambda\n",
        "      train_input_fn,\n",
        "      max_steps=trainer_fn_args.train_steps)\n",
        "\n",
        "  serving_receiver_fn = lambda: _example_serving_receiver_fn(  # pylint: disable=g-long-lambda\n",
        "      tf_transform_graph, schema)\n",
        "\n",
        "  exporter = tf.estimator.FinalExporter('chicago-taxi', serving_receiver_fn)\n",
        "  eval_spec = tf.estimator.EvalSpec(\n",
        "      eval_input_fn,\n",
        "      steps=trainer_fn_args.eval_steps,\n",
        "      exporters=[exporter],\n",
        "      name='chicago-taxi-eval')\n",
        "\n",
        "  run_config = tf.estimator.RunConfig(\n",
        "      save_checkpoints_steps=999, keep_checkpoint_max=1)\n",
        "\n",
        "  run_config = run_config.replace(model_dir=trainer_fn_args.serving_model_dir)\n",
        "\n",
        "  estimator = _build_estimator(\n",
        "      # Construct layers sizes with exponetial decay\n",
        "      hidden_units=[\n",
        "          max(2, int(first_dnn_layer_size * dnn_decay_factor**i))\n",
        "          for i in range(num_dnn_layers)\n",
        "      ],\n",
        "      config=run_config,\n",
        "      warm_start_from=trainer_fn_args.base_model)\n",
        "\n",
        "  # Create an input receiver for TFMA processing\n",
        "  receiver_fn = lambda: _eval_input_receiver_fn(  # pylint: disable=g-long-lambda\n",
        "      tf_transform_graph, schema)\n",
        "\n",
        "  return {\n",
        "      'estimator': estimator,\n",
        "      'train_spec': train_spec,\n",
        "      'eval_spec': eval_spec,\n",
        "      'eval_input_receiver_fn': receiver_fn\n",
        "  }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GY4yTRaX4YJx"
      },
      "source": [
        "Agora, passamos o código deste modelo para o componente `Trainer` e o executamos para treinar o modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "429-vvCWibO0"
      },
      "outputs": [],
      "source": [
        "from tfx.components.trainer.executor import Executor\n",
        "from tfx.dsl.components.base import executor_spec\n",
        "\n",
        "trainer = tfx.components.Trainer(\n",
        "    module_file=os.path.abspath(_taxi_trainer_module_file),\n",
        "    custom_executor_spec=executor_spec.ExecutorClassSpec(Executor),\n",
        "    examples=transform.outputs['transformed_examples'],\n",
        "    schema=schema_gen.outputs['schema'],\n",
        "    transform_graph=transform.outputs['transform_graph'],\n",
        "    train_args=tfx.proto.TrainArgs(num_steps=10000),\n",
        "    eval_args=tfx.proto.EvalArgs(num_steps=5000))\n",
        "context.run(trainer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Cql1G35StJp"
      },
      "source": [
        "#### Analise o treinamento com o TensorBoard\n",
        "\n",
        "Opcionalmente, podemos conectar o TensorBoard ao Trainer para analisar as curvas de treinamento do nosso modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bXe62WE0S0Ek"
      },
      "outputs": [],
      "source": [
        "# Get the URI of the output artifact representing the training logs, which is a directory\n",
        "model_run_dir = trainer.outputs['model_run'].get()[0].uri\n",
        "\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir {model_run_dir}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmPftrv0lEQy"
      },
      "source": [
        "### Evaluator\n",
        "\n",
        "O componente `Evaluator` calcula métricas de desempenho do modelo no dataset de avaliação. Ele usa a biblioteca [TensorFlow Model Analysis](https://www.tensorflow.org/tfx/model_analysis/get_started). O `Evaluator` também pode validar opcionalmente se um modelo recém-treinado é melhor que o modelo anterior. Isto é útil numa configuração de pipeline de produção onde você pode treinar e validar automaticamente um modelo todos os dias. Neste notebook, treinamos apenas um modelo, então o `Evaluator` irá rotular automaticamente o modelo como \"bom\".\n",
        "\n",
        "O `Evaluator` terá como entrada os dados de `ExampleGen`, o modelo treinado de `Trainer` e a configuração de fatiamento. A configuração de fatiamento permite dividir suas métricas em valores de características (por exemplo, como é o desempenho do seu modelo em viagens de táxi que começam às 8h versus 20h?). Veja abaixo um exemplo dessa configuração:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fVhfzzh9PDEx"
      },
      "outputs": [],
      "source": [
        "eval_config = tfma.EvalConfig(\n",
        "    model_specs=[\n",
        "        # Using signature 'eval' implies the use of an EvalSavedModel. To use\n",
        "        # a serving model remove the signature to defaults to 'serving_default'\n",
        "        # and add a label_key.\n",
        "        tfma.ModelSpec(signature_name='eval')\n",
        "    ],\n",
        "    metrics_specs=[\n",
        "        tfma.MetricsSpec(\n",
        "            # The metrics added here are in addition to those saved with the\n",
        "            # model (assuming either a keras model or EvalSavedModel is used).\n",
        "            # Any metrics added into the saved model (for example using\n",
        "            # model.compile(..., metrics=[...]), etc) will be computed\n",
        "            # automatically.\n",
        "            metrics=[\n",
        "                tfma.MetricConfig(class_name='ExampleCount')\n",
        "            ],\n",
        "            # To add validation thresholds for metrics saved with the model,\n",
        "            # add them keyed by metric name to the thresholds map.\n",
        "            thresholds = {\n",
        "                'accuracy': tfma.MetricThreshold(\n",
        "                    value_threshold=tfma.GenericValueThreshold(\n",
        "                        lower_bound={'value': 0.5}),\n",
        "                    # Change threshold will be ignored if there is no\n",
        "                    # baseline model resolved from MLMD (first run).\n",
        "                    change_threshold=tfma.GenericChangeThreshold(\n",
        "                       direction=tfma.MetricDirection.HIGHER_IS_BETTER,\n",
        "                       absolute={'value': -1e-10}))\n",
        "            }\n",
        "        )\n",
        "    ],\n",
        "    slicing_specs=[\n",
        "        # An empty slice spec means the overall slice, i.e. the whole dataset.\n",
        "        tfma.SlicingSpec(),\n",
        "        # Data can be sliced along a feature column. In this case, data is\n",
        "        # sliced along feature column trip_start_hour.\n",
        "        tfma.SlicingSpec(feature_keys=['trip_start_hour'])\n",
        "    ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mBdKH1F8JuT"
      },
      "source": [
        "Em seguida, damos esta configuração ao `Evaluator` e o executamos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zjcx8g6mihSt"
      },
      "outputs": [],
      "source": [
        "# Use TFMA to compute a evaluation statistics over features of a model and\n",
        "# validate them against a baseline.\n",
        "\n",
        "# The model resolver is only required if performing model validation in addition\n",
        "# to evaluation. In this case we validate against the latest blessed model. If\n",
        "# no model has been blessed before (as in this case) the evaluator will make our\n",
        "# candidate the first blessed model.\n",
        "model_resolver = tfx.dsl.Resolver(\n",
        "      strategy_class=tfx.dsl.experimental.LatestBlessedModelStrategy,\n",
        "      model=tfx.dsl.Channel(type=tfx.types.standard_artifacts.Model),\n",
        "      model_blessing=tfx.dsl.Channel(\n",
        "          type=tfx.types.standard_artifacts.ModelBlessing)).with_id(\n",
        "              'latest_blessed_model_resolver')\n",
        "context.run(model_resolver)\n",
        "\n",
        "evaluator = tfx.components.Evaluator(\n",
        "    examples=example_gen.outputs['examples'],\n",
        "    model=trainer.outputs['model'],\n",
        "    eval_config=eval_config)\n",
        "context.run(evaluator)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AeCVkBusS_8g"
      },
      "source": [
        "Agora vamos examinar os artefatos de saída do `Evaluator`. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k4GghePOTJxL"
      },
      "outputs": [],
      "source": [
        "evaluator.outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5TMskWe9LL0"
      },
      "source": [
        "Usando a saída `evaluation` podemos mostrar a visualização padrão das métricas globais em todo o dataset de avaliação."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U729j5X5QQUQ"
      },
      "outputs": [],
      "source": [
        "context.show(evaluator.outputs['evaluation'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-tI4p6m-OAn"
      },
      "source": [
        "Para ver a visualização das métricas de avaliação fatiadas, podemos chamar diretamente a biblioteca TensorFlow Model Analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pyis6iy0HLdi"
      },
      "outputs": [],
      "source": [
        "import tensorflow_model_analysis as tfma\n",
        "\n",
        "# Get the TFMA output result path and load the result.\n",
        "PATH_TO_RESULT = evaluator.outputs['evaluation'].get()[0].uri\n",
        "tfma_result = tfma.load_eval_result(PATH_TO_RESULT)\n",
        "\n",
        "# Show data sliced along feature column trip_start_hour.\n",
        "tfma.view.render_slicing_metrics(\n",
        "    tfma_result, slicing_column='trip_start_hour')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uvYrUf2-r_6"
      },
      "source": [
        "Esta visualização mostra as mesmas métricas, mas calculadas em cada valor de característica de `trip_start_hour` em vez de em todo o dataset de avaliação.\n",
        "\n",
        "O TensorFlow Model Analysis oferece suporte a muitas outras visualizações, como Fairness Indicators (indicadores de imparcialidade) e plotagem de uma série temporal de desempenho do modelo. Para saber mais, veja o [tutorial](https://www.tensorflow.org/tfx/tutorials/model_analysis/tfma_basic)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEotnkxEswUb"
      },
      "source": [
        "Como adicionamos limites à nossa configuração, a saída de validação também estará disponível. A presença de um artefato `blessing` indica que nosso modelo passou na validação. Como esta é a primeira validação realizada, o candidato é automaticamente abençoado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FZmiRtg6TKtR"
      },
      "outputs": [],
      "source": [
        "blessing_uri = evaluator.outputs['blessing'].get()[0].uri\n",
        "!ls -l {blessing_uri}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hM1tFkOVSBa0"
      },
      "source": [
        "Agora também podemos verificar o sucesso carregando o registro do resultado da validação:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lxa5G08bSJ8a"
      },
      "outputs": [],
      "source": [
        "PATH_TO_RESULT = evaluator.outputs['evaluation'].get()[0].uri\n",
        "print(tfma.load_validation_result(PATH_TO_RESULT))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8DYekCZlHfj"
      },
      "source": [
        "### Pusher\n",
        "\n",
        "O componente `Pusher` geralmente está no final de um pipeline do TFX. Ele verifica se um modelo passou na validação e, em caso afirmativo, exporta o modelo para `_serving_model_dir`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r45nQ69eikc9"
      },
      "outputs": [],
      "source": [
        "pusher = tfx.components.Pusher(\n",
        "    model=trainer.outputs['model'],\n",
        "    model_blessing=evaluator.outputs['blessing'],\n",
        "    push_destination=tfx.proto.PushDestination(\n",
        "        filesystem=tfx.proto.PushDestination.Filesystem(\n",
        "            base_directory=_serving_model_dir)))\n",
        "context.run(pusher)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctUErBYoTO9I"
      },
      "source": [
        "Vamos examinar os artefatos de saída do `Pusher`. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pRkWo-MzTSss"
      },
      "outputs": [],
      "source": [
        "pusher.outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peH2PPS3VgkL"
      },
      "source": [
        "Em particular, o Pusher exportará seu modelo no formato SavedModel, que se parece com o seguinte:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4zyIqWl9TSdG"
      },
      "outputs": [],
      "source": [
        "push_uri = pusher.outputs['pushed_model'].get()[0].uri\n",
        "model = tf.saved_model.load(push_uri)\n",
        "\n",
        "for item in model.signatures.items():\n",
        "  pp.pprint(item)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-YPNUuHANtj"
      },
      "source": [
        "Terminamos nosso tour pelos componentes integrados do TFX!"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "wdeKOEkv1Fe8"
      ],
      "name": "components.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
