{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pknVo1kM2wI2"
      },
      "source": [
        "##### Copyright 2021 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "SoFqANDE222Y"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6x1ypzczQCwy"
      },
      "source": [
        "# Treinamento e serviço Vertex AI com TFX e Vertex Pipelines\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_445qeKq8e3-"
      },
      "source": [
        "<div class=\"devsite-table-wrapper\"><table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "<td>     <a target=\"_blank\" href=\"https://www.tensorflow.org/tfx/tutorials/tfx/gcp/vertex_pipelines_vertex_training\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver em TensorFlow.org</a>\n",
        "</td>\n",
        "<td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/pt-br/tfx/tutorials/tfx/gcp/vertex_pipelines_vertex_training.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Executar no Google Colab</a>\n",
        "</td>\n",
        "<td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/pt-br/tfx/tutorials/tfx/gcp/vertex_pipelines_vertex_training.ipynb\"><img width=\"32px\" src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver fonte no GitHub</a>\n",
        "</td>\n",
        "<td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/pt-br/tfx/tutorials/tfx/gcp/vertex_pipelines_vertex_training.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Baixar notebook</a>\n",
        "</td>\n",
        "<td><a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?q=download_url%3Dhttps://storage.googleapis.com/tensorflow_docs/docs-l10n/site/pt-br/tfx/tutorials/tfx/gcp/vertex_pipelines_vertex_training.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Executar no Google Cloud Vertex AI Workbench</a></td>\n",
        "</table></div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_VuwrlnvQJ5k"
      },
      "source": [
        "Este tutorial baseado em notebook criará e executará um pipeline TFX que treina um modelo de ML usando o serviço Vertex AI Training e o publica na Vertex AI para disponibilização do serviço.\n",
        "\n",
        "Este notebook é baseado no pipeline TFX que construímos no [Tutorial Pipeline TFX simples para Vertex Pipelines](https://www.tensorflow.org/tfx/tutorials/tfx/gcp/vertex_pipelines_simple). Se você ainda não leu esse tutorial, leia-o antes de prosseguir com este notebook.\n",
        "\n",
        "Você pode treinar modelos na Vertex AI usando AutoML ou usar treinamento personalizado. No treinamento personalizado, você pode selecionar vários tipos de máquinas diferentes para potencializar seus trabalhos de treinamento, permitir treinamento distribuído, usar tunagem de hiperparâmetros e acelerar com GPUs.\n",
        "\n",
        "Você também pode servir solicitações de previsão implantando o modelo treinado em modelos Vertex AI e criando um endpoint.\n",
        "\n",
        "Neste tutorial, usaremos o Vertex AI Training com trabalhos personalizados para treinar um modelo em um pipeline do TFX. Também implantaremos o modelo para atender solicitações de previsão usando o Vertex AI.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5Pv2qm3wfpL"
      },
      "source": [
        "Este notebook foi criado para ser executado no [Google Colab](https://colab.research.google.com/notebooks/intro.ipynb) ou em [AI Platform Notebooks](https://cloud.google.com/ai-platform-notebooks). Se você não estiver usando um deles, basta clicar no botão \"Executar no Google Colab\" acima.\n",
        "\n",
        "## Configuração\n",
        "\n",
        "Se você concluiu o [Tutorial pipeline TFX simples para Vertex Pipelines](https://www.tensorflow.org/tfx/tutorials/tfx/gcp/vertex_pipelines_simple), você terá um projeto GCP funcional e um bucket GCS e isso é tudo que precisamos para este tutorial. Por favor, leia esse tutorial primeiro se você já não o fez."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwZ0aXisoBFW"
      },
      "source": [
        "### Instale os pacotes Python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WC9W_S-bONgl"
      },
      "source": [
        "Instalaremos os pacotes Python necessários, incluindo TFX e KFP, para criar pipelines de ML e enviar trabalhos para o Vertex Pipelines."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iyQtljP-qPHY"
      },
      "outputs": [],
      "source": [
        "# Use the latest version of pip.\n",
        "!pip install --upgrade pip\n",
        "!pip install --upgrade \"tfx[kfp]<2\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUDADpuKiXPb"
      },
      "source": [
        "### Desinstale o shapely\n",
        "\n",
        "TODO(b/263441833) Esta é uma solução temporária para evitar um ImportError. Em última análise, isto deverá ser resolvido com suporte a uma versão mais recente do Bigquery, em vez de desinstalar outras dependências extras."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wzBCmlXBiXgX"
      },
      "outputs": [],
      "source": [
        "!pip uninstall shapely -y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwT0nov5QO1M"
      },
      "source": [
        "#### Você reiniciou o runtime?\n",
        "\n",
        "Se você estiver usando o Google Colab, na primeira vez que executar a célula acima, você deve reiniciar o runtime clicando no botão \"RESTART RUNTIME\" acima ou usando o menu \"Runtime &gt; Restart runtime ...\". Isso é necessário devido à maneira como o Colab carrega os pacotes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CRyIL4LVDlQ"
      },
      "source": [
        "Se você não estiver no Colab, poderá reiniciar o runtime com a seguinte célula."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KHTSzMygoBF6"
      },
      "outputs": [],
      "source": [
        "# docs_infra: no_execute\n",
        "import sys\n",
        "if not 'google.colab' in sys.modules:\n",
        "  # Automatically restart kernel after installs\n",
        "  import IPython\n",
        "  app = IPython.Application.instance()\n",
        "  app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gckGHdW9iPrq"
      },
      "source": [
        "### Faça login no Google para este notebook\n",
        "\n",
        "Se você estiver executando este notebook no Colab, autentique-se com sua conta de usuário:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kZQA0KrfXCvU"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "if 'google.colab' in sys.modules:\n",
        "  from google.colab import auth\n",
        "  auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaqJjbmk6o0o"
      },
      "source": [
        "**Se você estiver no AI Platform Notebooks**, autentique-se no Google Cloud antes de executar a próxima seção, executando\n",
        "\n",
        "```sh\n",
        "gcloud auth login\n",
        "```\n",
        "\n",
        "**na janela do Terminal** (que você pode abrir em **File** &gt; **New** no menu). Você só precisa fazer isso uma vez por instância de notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_SveIKxaENu"
      },
      "source": [
        "Verifique as versões dos pacotes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xd-iP9wEaENu"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "print('TensorFlow version: {}'.format(tf.__version__))\n",
        "from tfx import v1 as tfx\n",
        "print('TFX version: {}'.format(tfx.__version__))\n",
        "import kfp\n",
        "print('KFP version: {}'.format(kfp.__version__))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDtLdSkvqPHe"
      },
      "source": [
        "### Configuração de variáveis\n",
        "\n",
        "Definiremos algumas variáveis ​​usadas para personalizar os pipelines abaixo. As seguintes informações são necessárias:\n",
        "\n",
        "- ID do projeto GCP. Consulte [Identificando o ID do seu projeto](https://cloud.google.com/resource-manager/docs/creating-managing-projects#identifying_projects).\n",
        "- Região do GCP para executar pipelines. Para obter mais informações sobre as regiões em que o Vertex Pipelines está disponível, veja o [guia de locais do Vertex AI](https://cloud.google.com/vertex-ai/docs/general/locations#feature-availability).\n",
        "- Bucket do Google Cloud Storage para armazenar saídas de pipeline.\n",
        "\n",
        "**Insira os valores necessários na célula abaixo antes de executá-la**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EcUseqJaE2XN"
      },
      "outputs": [],
      "source": [
        "GOOGLE_CLOUD_PROJECT = ''     # <--- ENTER THIS\n",
        "GOOGLE_CLOUD_REGION = ''      # <--- ENTER THIS\n",
        "GCS_BUCKET_NAME = ''          # <--- ENTER THIS\n",
        "\n",
        "if not (GOOGLE_CLOUD_PROJECT and GOOGLE_CLOUD_REGION and GCS_BUCKET_NAME):\n",
        "    from absl import logging\n",
        "    logging.error('Please set all required parameters.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAaCPLjgiJrO"
      },
      "source": [
        "Defina o `gcloud` para usar seu projeto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VkWdxe4TXRHk"
      },
      "outputs": [],
      "source": [
        "!gcloud config set project {GOOGLE_CLOUD_PROJECT}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CPN6UL5CazNy"
      },
      "outputs": [],
      "source": [
        "PIPELINE_NAME = 'penguin-vertex-training'\n",
        "\n",
        "# Path to various pipeline artifact.\n",
        "PIPELINE_ROOT = 'gs://{}/pipeline_root/{}'.format(GCS_BUCKET_NAME, PIPELINE_NAME)\n",
        "\n",
        "# Paths for users' Python module.\n",
        "MODULE_ROOT = 'gs://{}/pipeline_module/{}'.format(GCS_BUCKET_NAME, PIPELINE_NAME)\n",
        "\n",
        "# Paths for users' data.\n",
        "DATA_ROOT = 'gs://{}/data/{}'.format(GCS_BUCKET_NAME, PIPELINE_NAME)\n",
        "\n",
        "# Name of Vertex AI Endpoint.\n",
        "ENDPOINT_NAME = 'prediction-' + PIPELINE_NAME\n",
        "\n",
        "print('PIPELINE_ROOT: {}'.format(PIPELINE_ROOT))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8F2SRwRLSYGa"
      },
      "source": [
        "### Preparação dos dados de exemplo\n",
        "\n",
        "Usaremos o mesmo [dataset Palmer Penguins](https://allisonhorst.github.io/palmerpenguins/articles/intro.html) do [Tutorial pipeline TFX simples](https://www.tensorflow.org/tfx/tutorials/tfx/penguin_simple).\n",
        "\n",
        "Existem quatro características numéricas neste dataset que já foram normalizados para ter intervalo [0,1]. Construiremos um modelo de classificação que prevê as `species` de pinguins."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11J7XiCq6AFP"
      },
      "source": [
        "Precisamos fazer nossa própria cópia do dataset. Como o TFX ExampleGen lê entradas de um diretório, precisamos criar um diretório e copiar o dataset para ele no GCS."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4fxMs6u86acP"
      },
      "outputs": [],
      "source": [
        "!gsutil cp gs://download.tensorflow.org/data/palmer_penguins/penguins_processed.csv {DATA_ROOT}/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASpoNmxKSQjI"
      },
      "source": [
        "Dê uma olhada rápida no arquivo CSV."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-eSz28UDSnlG"
      },
      "outputs": [],
      "source": [
        "!gsutil cat {DATA_ROOT}/penguins_processed.csv | head"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nH6gizcpSwWV"
      },
      "source": [
        "## Crie um pipeline\n",
        "\n",
        "Nosso pipeline será muito semelhante ao pipeline que criamos no [Tutorial pipeline TFX simples para Vertex Pipelines](https://www.tensorflow.org/tfx/tutorials/tfx/gcp/vertex_pipelines_simple). O pipeline consistirá em três componentes, CsvExampleGen, Trainer e Pusher. Mas usaremos um componente Trainer e Pusher especial. O componente Trainer moverá as cargas de trabalho de treinamento para a Vertex AI, e o componente Pusher publicará o modelo de ML treinado na Vertex AI em vez de num sistema de arquivos.\n",
        "\n",
        "O TFX fornece um `Trainer` especial para enviar trabalhos de treinamento ao serviço Vertex AI Training. Tudo o que precisamos fazer é usar `Trainer` no módulo de extensão em vez do componente `Trainer` padrão junto com alguns parâmetros necessários do GCP.\n",
        "\n",
        "Neste tutorial, executaremos jobs do Vertex AI Training inicialmente usando apenas CPUs e depois com uma GPU.\n",
        "\n",
        "O TFX também fornece um `Pusher` especial para fazer upload do modelo para *Vertex AI Models*. O `Pusher` também criará o recurso *Vertex AI Endpoint* para atender previsões on-line. Veja a [documentação do Vertex AI](https://cloud.google.com/vertex-ai/docs/predictions/getting-predictions) para saber mais sobre as previsões on-line fornecidas pela Vertex AI."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOjDv93eS5xV"
      },
      "source": [
        "### Escreva o código do modelo.\n",
        "\n",
        "O modelo em si é muito parecido com o modelo do [Tutorial pipeline TFX simples](https://www.tensorflow.org/tfx/tutorials/tfx/penguin_simple).\n",
        "\n",
        "Adicionaremos a função `_get_distribution_strategy()` que cria uma [estratégia de distribuição TensorFlow](https://www.tensorflow.org/guide/distributed_training) e é usada em `run_fn` para usar MirroredStrategy se a GPU estiver disponível."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aES7Hv5QTDK3"
      },
      "outputs": [],
      "source": [
        "_trainer_module_file = 'penguin_trainer.py'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gnc67uQNTDfW"
      },
      "outputs": [],
      "source": [
        "%%writefile {_trainer_module_file}\n",
        "\n",
        "# Copied from https://www.tensorflow.org/tfx/tutorials/tfx/penguin_simple and\n",
        "# slightly modified run_fn() to add distribution_strategy.\n",
        "\n",
        "from typing import List\n",
        "from absl import logging\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow_metadata.proto.v0 import schema_pb2\n",
        "from tensorflow_transform.tf_metadata import schema_utils\n",
        "\n",
        "from tfx import v1 as tfx\n",
        "from tfx_bsl.public import tfxio\n",
        "\n",
        "_FEATURE_KEYS = [\n",
        "    'culmen_length_mm', 'culmen_depth_mm', 'flipper_length_mm', 'body_mass_g'\n",
        "]\n",
        "_LABEL_KEY = 'species'\n",
        "\n",
        "_TRAIN_BATCH_SIZE = 20\n",
        "_EVAL_BATCH_SIZE = 10\n",
        "\n",
        "# Since we're not generating or creating a schema, we will instead create\n",
        "# a feature spec.  Since there are a fairly small number of features this is\n",
        "# manageable for this dataset.\n",
        "_FEATURE_SPEC = {\n",
        "    **{\n",
        "        feature: tf.io.FixedLenFeature(shape=[1], dtype=tf.float32)\n",
        "        for feature in _FEATURE_KEYS\n",
        "    }, _LABEL_KEY: tf.io.FixedLenFeature(shape=[1], dtype=tf.int64)\n",
        "}\n",
        "\n",
        "\n",
        "def _input_fn(file_pattern: List[str],\n",
        "              data_accessor: tfx.components.DataAccessor,\n",
        "              schema: schema_pb2.Schema,\n",
        "              batch_size: int) -> tf.data.Dataset:\n",
        "  \"\"\"Generates features and label for training.\n",
        "\n",
        "  Args:\n",
        "    file_pattern: List of paths or patterns of input tfrecord files.\n",
        "    data_accessor: DataAccessor for converting input to RecordBatch.\n",
        "    schema: schema of the input data.\n",
        "    batch_size: representing the number of consecutive elements of returned\n",
        "      dataset to combine in a single batch\n",
        "\n",
        "  Returns:\n",
        "    A dataset that contains (features, indices) tuple where features is a\n",
        "      dictionary of Tensors, and indices is a single Tensor of label indices.\n",
        "  \"\"\"\n",
        "  return data_accessor.tf_dataset_factory(\n",
        "      file_pattern,\n",
        "      tfxio.TensorFlowDatasetOptions(\n",
        "          batch_size=batch_size, label_key=_LABEL_KEY),\n",
        "      schema=schema).repeat()\n",
        "\n",
        "\n",
        "def _make_keras_model() -> tf.keras.Model:\n",
        "  \"\"\"Creates a DNN Keras model for classifying penguin data.\n",
        "\n",
        "  Returns:\n",
        "    A Keras Model.\n",
        "  \"\"\"\n",
        "  # The model below is built with Functional API, please refer to\n",
        "  # https://www.tensorflow.org/guide/keras/overview for all API options.\n",
        "  inputs = [keras.layers.Input(shape=(1,), name=f) for f in _FEATURE_KEYS]\n",
        "  d = keras.layers.concatenate(inputs)\n",
        "  for _ in range(2):\n",
        "    d = keras.layers.Dense(8, activation='relu')(d)\n",
        "  outputs = keras.layers.Dense(3)(d)\n",
        "\n",
        "  model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "  model.compile(\n",
        "      optimizer=keras.optimizers.Adam(1e-2),\n",
        "      loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "      metrics=[keras.metrics.SparseCategoricalAccuracy()])\n",
        "\n",
        "  model.summary(print_fn=logging.info)\n",
        "  return model\n",
        "\n",
        "\n",
        "# NEW: Read `use_gpu` from the custom_config of the Trainer.\n",
        "#      if it uses GPU, enable MirroredStrategy.\n",
        "def _get_distribution_strategy(fn_args: tfx.components.FnArgs):\n",
        "  if fn_args.custom_config.get('use_gpu', False):\n",
        "    logging.info('Using MirroredStrategy with one GPU.')\n",
        "    return tf.distribute.MirroredStrategy(devices=['device:GPU:0'])\n",
        "  return None\n",
        "\n",
        "\n",
        "# TFX Trainer will call this function.\n",
        "def run_fn(fn_args: tfx.components.FnArgs):\n",
        "  \"\"\"Train the model based on given args.\n",
        "\n",
        "  Args:\n",
        "    fn_args: Holds args used to train the model as name/value pairs.\n",
        "  \"\"\"\n",
        "\n",
        "  # This schema is usually either an output of SchemaGen or a manually-curated\n",
        "  # version provided by pipeline author. A schema can also derived from TFT\n",
        "  # graph if a Transform component is used. In the case when either is missing,\n",
        "  # `schema_from_feature_spec` could be used to generate schema from very simple\n",
        "  # feature_spec, but the schema returned would be very primitive.\n",
        "  schema = schema_utils.schema_from_feature_spec(_FEATURE_SPEC)\n",
        "\n",
        "  train_dataset = _input_fn(\n",
        "      fn_args.train_files,\n",
        "      fn_args.data_accessor,\n",
        "      schema,\n",
        "      batch_size=_TRAIN_BATCH_SIZE)\n",
        "  eval_dataset = _input_fn(\n",
        "      fn_args.eval_files,\n",
        "      fn_args.data_accessor,\n",
        "      schema,\n",
        "      batch_size=_EVAL_BATCH_SIZE)\n",
        "\n",
        "  # NEW: If we have a distribution strategy, build a model in a strategy scope.\n",
        "  strategy = _get_distribution_strategy(fn_args)\n",
        "  if strategy is None:\n",
        "    model = _make_keras_model()\n",
        "  else:\n",
        "    with strategy.scope():\n",
        "      model = _make_keras_model()\n",
        "\n",
        "  model.fit(\n",
        "      train_dataset,\n",
        "      steps_per_epoch=fn_args.train_steps,\n",
        "      validation_data=eval_dataset,\n",
        "      validation_steps=fn_args.eval_steps)\n",
        "\n",
        "  # The result of the training should be saved in `fn_args.serving_model_dir`\n",
        "  # directory.\n",
        "  model.save(fn_args.serving_model_dir, save_format='tf')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LsYx8MpYvPv"
      },
      "source": [
        "Copie o arquivo do módulo para o GCS, que pode ser acessado nos componentes do pipeline.\n",
        "\n",
        "Caso contrário, você talvez queira criar uma imagem de container incluindo o arquivo do módulo e usar a imagem para executar o pipeline e os jobs do AI Platform Training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rMMs5wuNYAbc"
      },
      "outputs": [],
      "source": [
        "!gsutil cp {_trainer_module_file} {MODULE_ROOT}/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3OkNz3gTLwM"
      },
      "source": [
        "### Escreva uma definição de pipeline\n",
        "\n",
        "Definiremos uma função para criar um pipeline TFX. Ela terá os mesmos três componentes do [Tutorial pipeline TFX simples](https://www.tensorflow.org/tfx/tutorials/tfx/penguin_simple), mas usamos um componente `Trainer` e `Pusher` no módulo de extensão GCP.\n",
        "\n",
        "O `tfx.extensions.google_cloud_ai_platform.Trainer` se comporta como um `Trainer` normal, mas apenas move o cálculo do treinamento do modelo para a nuvem. Ele inicia um job personalizado no serviço Vertex AI Training e o componente de treinamento no sistema de orquestração irá apenas aguardar até que o trabalho do Vertex AI Training seja concluído.\n",
        "\n",
        "O `tfx.extensions.google_cloud_ai_platform.Pusher` cria um modelo Vertex AI e um endpoint Vertex AI usando o modelo treinado.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M49yYVNBTPd4"
      },
      "outputs": [],
      "source": [
        "def _create_pipeline(pipeline_name: str, pipeline_root: str, data_root: str,\n",
        "                     module_file: str, endpoint_name: str, project_id: str,\n",
        "                     region: str, use_gpu: bool) -> tfx.dsl.Pipeline:\n",
        "  \"\"\"Implements the penguin pipeline with TFX.\"\"\"\n",
        "  # Brings data into the pipeline or otherwise joins/converts training data.\n",
        "  example_gen = tfx.components.CsvExampleGen(input_base=data_root)\n",
        "\n",
        "  # NEW: Configuration for Vertex AI Training.\n",
        "  # This dictionary will be passed as `CustomJobSpec`.\n",
        "  vertex_job_spec = {\n",
        "      'project': project_id,\n",
        "      'worker_pool_specs': [{\n",
        "          'machine_spec': {\n",
        "              'machine_type': 'n1-standard-4',\n",
        "          },\n",
        "          'replica_count': 1,\n",
        "          'container_spec': {\n",
        "              'image_uri': 'gcr.io/tfx-oss-public/tfx:{}'.format(tfx.__version__),\n",
        "          },\n",
        "      }],\n",
        "  }\n",
        "  if use_gpu:\n",
        "    # See https://cloud.google.com/vertex-ai/docs/reference/rest/v1/MachineSpec#acceleratortype\n",
        "    # for available machine types.\n",
        "    vertex_job_spec['worker_pool_specs'][0]['machine_spec'].update({\n",
        "        'accelerator_type': 'NVIDIA_TESLA_K80',\n",
        "        'accelerator_count': 1\n",
        "    })\n",
        "\n",
        "  # Trains a model using Vertex AI Training.\n",
        "  # NEW: We need to specify a Trainer for GCP with related configs.\n",
        "  trainer = tfx.extensions.google_cloud_ai_platform.Trainer(\n",
        "      module_file=module_file,\n",
        "      examples=example_gen.outputs['examples'],\n",
        "      train_args=tfx.proto.TrainArgs(num_steps=100),\n",
        "      eval_args=tfx.proto.EvalArgs(num_steps=5),\n",
        "      custom_config={\n",
        "          tfx.extensions.google_cloud_ai_platform.ENABLE_VERTEX_KEY:\n",
        "              True,\n",
        "          tfx.extensions.google_cloud_ai_platform.VERTEX_REGION_KEY:\n",
        "              region,\n",
        "          tfx.extensions.google_cloud_ai_platform.TRAINING_ARGS_KEY:\n",
        "              vertex_job_spec,\n",
        "          'use_gpu':\n",
        "              use_gpu,\n",
        "      })\n",
        "\n",
        "  # NEW: Configuration for pusher.\n",
        "  vertex_serving_spec = {\n",
        "      'project_id': project_id,\n",
        "      'endpoint_name': endpoint_name,\n",
        "      # Remaining argument is passed to aiplatform.Model.deploy()\n",
        "      # See https://cloud.google.com/vertex-ai/docs/predictions/deploy-model-api#deploy_the_model\n",
        "      # for the detail.\n",
        "      #\n",
        "      # Machine type is the compute resource to serve prediction requests.\n",
        "      # See https://cloud.google.com/vertex-ai/docs/predictions/configure-compute#machine-types\n",
        "      # for available machine types and acccerators.\n",
        "      'machine_type': 'n1-standard-4',\n",
        "  }\n",
        "\n",
        "  # Vertex AI provides pre-built containers with various configurations for\n",
        "  # serving.\n",
        "  # See https://cloud.google.com/vertex-ai/docs/predictions/pre-built-containers\n",
        "  # for available container images.\n",
        "  serving_image = 'us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-6:latest'\n",
        "  if use_gpu:\n",
        "    vertex_serving_spec.update({\n",
        "        'accelerator_type': 'NVIDIA_TESLA_K80',\n",
        "        'accelerator_count': 1\n",
        "    })\n",
        "    serving_image = 'us-docker.pkg.dev/vertex-ai/prediction/tf2-gpu.2-6:latest'\n",
        "\n",
        "  # NEW: Pushes the model to Vertex AI.\n",
        "  pusher = tfx.extensions.google_cloud_ai_platform.Pusher(\n",
        "      model=trainer.outputs['model'],\n",
        "      custom_config={\n",
        "          tfx.extensions.google_cloud_ai_platform.ENABLE_VERTEX_KEY:\n",
        "              True,\n",
        "          tfx.extensions.google_cloud_ai_platform.VERTEX_REGION_KEY:\n",
        "              region,\n",
        "          tfx.extensions.google_cloud_ai_platform.VERTEX_CONTAINER_IMAGE_URI_KEY:\n",
        "              serving_image,\n",
        "          tfx.extensions.google_cloud_ai_platform.SERVING_ARGS_KEY:\n",
        "            vertex_serving_spec,\n",
        "      })\n",
        "\n",
        "  components = [\n",
        "      example_gen,\n",
        "      trainer,\n",
        "      pusher,\n",
        "  ]\n",
        "\n",
        "  return tfx.dsl.Pipeline(\n",
        "      pipeline_name=pipeline_name,\n",
        "      pipeline_root=pipeline_root,\n",
        "      components=components)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJbq07THU2GV"
      },
      "source": [
        "## Execute o pipeline no Vertex Pipelines.\n",
        "\n",
        "Usaremos Vertex Pipelines para executar o pipeline, como fizemos no [Tutorial Pipeline TFX simples para Vertex Pipelines](https://www.tensorflow.org/tfx/tutorials/tfx/gcp/vertex_pipelines_simple)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fAtfOZTYWJu-"
      },
      "outputs": [],
      "source": [
        "# docs_infra: no_execute\n",
        "import os\n",
        "\n",
        "PIPELINE_DEFINITION_FILE = PIPELINE_NAME + '_pipeline.json'\n",
        "\n",
        "runner = tfx.orchestration.experimental.KubeflowV2DagRunner(\n",
        "    config=tfx.orchestration.experimental.KubeflowV2DagRunnerConfig(),\n",
        "    output_filename=PIPELINE_DEFINITION_FILE)\n",
        "_ = runner.run(\n",
        "    _create_pipeline(\n",
        "        pipeline_name=PIPELINE_NAME,\n",
        "        pipeline_root=PIPELINE_ROOT,\n",
        "        data_root=DATA_ROOT,\n",
        "        module_file=os.path.join(MODULE_ROOT, _trainer_module_file),\n",
        "        endpoint_name=ENDPOINT_NAME,\n",
        "        project_id=GOOGLE_CLOUD_PROJECT,\n",
        "        region=GOOGLE_CLOUD_REGION,\n",
        "        # We will use CPUs only for now.\n",
        "        use_gpu=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWyITYSDd8w4"
      },
      "source": [
        "O arquivo de definição gerado pode ser enviado usando o cliente Google Cloud aiplatform no pacote `google-cloud-aiplatform`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tI71jlEvWMV7"
      },
      "outputs": [],
      "source": [
        "# docs_infra: no_execute\n",
        "from google.cloud import aiplatform\n",
        "from google.cloud.aiplatform import pipeline_jobs\n",
        "import logging\n",
        "logging.getLogger().setLevel(logging.INFO)\n",
        "\n",
        "aiplatform.init(project=GOOGLE_CLOUD_PROJECT, location=GOOGLE_CLOUD_REGION)\n",
        "\n",
        "job = pipeline_jobs.PipelineJob(template_path=PIPELINE_DEFINITION_FILE,\n",
        "                                display_name=PIPELINE_NAME)\n",
        "job.submit()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3k9f5IVQXcQ"
      },
      "source": [
        "Agora você pode visitar o link na saída acima ou visitar 'Vertex AI &gt; Pipelines' no [Console do Google Cloud](https://console.cloud.google.com/) para acompanhar o andamento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyN4bM8GOHHt"
      },
      "source": [
        "## Teste com uma solicitação de previsão\n",
        "\n",
        "Assim que o pipeline for concluído, você encontrará um modelo *implantado* em um dos endpoints em 'Vertex AI &gt; Endpoints'. Precisamos saber o ID do endpoint para enviar uma solicitação de previsão ao novo endpoint. Isto é diferente do *nome do endpoint* que inserimos acima. Você pode encontrar o ID na [página Endpoints](https://console.cloud.google.com/vertex-ai/endpoints) no `Google Cloud Console`. É um número bem longo.\n",
        "\n",
        "**Defina o ENDPOINT_ID abaixo antes de executá-lo.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "51EWzkj8Wdly"
      },
      "outputs": [],
      "source": [
        "ENDPOINT_ID=''     # <--- ENTER THIS\n",
        "if not ENDPOINT_ID:\n",
        "    from absl import logging\n",
        "    logging.error('Please set the endpoint id.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9maWD7pK-yf"
      },
      "source": [
        "Usamos o mesmo cliente aiplatform para enviar uma solicitação ao endpoint. Enviaremos uma solicitação de previsão para classificação de espécies de pinguins. A entrada são as quatro características que usamos, e o modelo retornará três valores, porque nosso modelo gera um valor para cada espécie.\n",
        "\n",
        "Por exemplo, o exemplo específico a seguir tem o maior valor no índice '2' e imprimirá '2'.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gdzxst2_OoXH"
      },
      "outputs": [],
      "source": [
        "# docs_infra: no_execute\n",
        "import numpy as np\n",
        "\n",
        "# The AI Platform services require regional API endpoints.\n",
        "client_options = {\n",
        "    'api_endpoint': GOOGLE_CLOUD_REGION + '-aiplatform.googleapis.com'\n",
        "    }\n",
        "# Initialize client that will be used to create and send requests.\n",
        "client = aiplatform.gapic.PredictionServiceClient(client_options=client_options)\n",
        "\n",
        "# Set data values for the prediction request.\n",
        "# Our model expects 4 feature inputs and produces 3 output values for each\n",
        "# species. Note that the output is logit value rather than probabilities.\n",
        "# See the model code to understand input / output structure.\n",
        "instances = [{\n",
        "    'culmen_length_mm':[0.71],\n",
        "    'culmen_depth_mm':[0.38],\n",
        "    'flipper_length_mm':[0.98],\n",
        "    'body_mass_g': [0.78],\n",
        "}]\n",
        "\n",
        "endpoint = client.endpoint_path(\n",
        "    project=GOOGLE_CLOUD_PROJECT,\n",
        "    location=GOOGLE_CLOUD_REGION,\n",
        "    endpoint=ENDPOINT_ID,\n",
        ")\n",
        "# Send a prediction request and get response.\n",
        "response = client.predict(endpoint=endpoint, instances=instances)\n",
        "\n",
        "# Uses argmax to find the index of the maximum value.\n",
        "print('species:', np.argmax(response.predictions[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5OBJLMLOowD"
      },
      "source": [
        "Para obter informações detalhadas sobre a previsão on-line, visite a [página Endpoints](https://console.cloud.google.com/vertex-ai/endpoints) no `Google Cloud Console`, onde você encontrará um guia sobre como enviar exemplos de solicitações e links para mais características."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DgVvdYPzzW6k"
      },
      "source": [
        "## Execute o pipeline usando uma GPU\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ht0Zpgx3L82g"
      },
      "source": [
        "A Vertex AI oferece suporte ao treinamento usando vários tipos de máquinas, incluindo suporte para GPUs. Consulte a [ referência de especificações de máquina](https://cloud.google.com/vertex-ai/docs/reference/rest/v1/MachineSpec#acceleratortype) para obter as opções disponíveis.\n",
        "\n",
        "Já definimos nosso pipeline para dar suporte ao treinamento usando GPU. Tudo o que precisamos fazer é definir o sinalizador `use_gpu` como True. Em seguida, um pipeline será criado com uma especificação de máquina incluindo NVIDIA_TESLA_K80 e nosso código de treinamento de modelo usará `tf.distribute.MirroredStrategy`.\n",
        "\n",
        "Observe que o sinalizador `use_gpu` não faz parte da API Vertex ou TFX. Ele é usado apenas para controlar o código de treinamento neste tutorial."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1TwX6bcsLo_g"
      },
      "outputs": [],
      "source": [
        "# docs_infra: no_execute\n",
        "runner.run(\n",
        "    _create_pipeline(\n",
        "        pipeline_name=PIPELINE_NAME,\n",
        "        pipeline_root=PIPELINE_ROOT,\n",
        "        data_root=DATA_ROOT,\n",
        "        module_file=os.path.join(MODULE_ROOT, _trainer_module_file),\n",
        "        endpoint_name=ENDPOINT_NAME,\n",
        "        project_id=GOOGLE_CLOUD_PROJECT,\n",
        "        region=GOOGLE_CLOUD_REGION,\n",
        "        # Updated: Use GPUs. We will use a NVIDIA_TESLA_K80 and \n",
        "        # the model code will use tf.distribute.MirroredStrategy.\n",
        "        use_gpu=True))\n",
        "\n",
        "job = pipeline_jobs.PipelineJob(template_path=PIPELINE_DEFINITION_FILE,\n",
        "                                display_name=PIPELINE_NAME)\n",
        "job.submit()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xc9XsjlyKoZe"
      },
      "source": [
        "Agora você pode visitar o link na saída acima ou visitar 'Vertex AI &gt; Pipelines' no [Console do Google Cloud](https://console.cloud.google.com/) para acompanhar o andamento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_coFG3sqSJQ"
      },
      "source": [
        "## Limpeza\n",
        "\n",
        "Você criou um modelo e um endpoint Vertex AI neste tutorial. Exclua esses recursos para evitar cobranças indesejadas, acessando [Endpoints](https://console.cloud.google.com/vertex-ai/endpoints) e fazendo *undeploy* do modelo do endpoint primeiro. Depois você pode excluir o endpoint e o modelo separadamente."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "pknVo1kM2wI2",
        "8F2SRwRLSYGa"
      ],
      "name": "vertex_pipelines_vertex_training.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
