{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjUA6S30k52h"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "SpNWyqewk8fE"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TyrY7lV0oke"
      },
      "source": [
        "# Crie um pipeline TFX para seus dados com o template Penguin\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQmvgl9nsqPW"
      },
      "source": [
        "Observação: recomendamos executar este tutorial no Google Cloud [Vertex AI Workbench](https://cloud.google.com/vertex-ai-workbench). [Acessar o Vertex AI Workbench](https://console.cloud.google.com/vertex-ai/workbench).\n",
        "\n",
        "<div class=\"devsite-table-wrapper\"><table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "<td>     <a target=\"_blank\" href=\"https://www.tensorflow.org/tfx/tutorials/tfx/penguin_template\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver em TensorFlow.org</a>\n",
        "</td>\n",
        "<td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/pt-br/tfx/tutorials/tfx/penguin_template.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Executar no Google Colab</a>\n",
        "</td>\n",
        "<td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/pt-br/tfx/tutorials/tfx/penguin_template.ipynb\"><img width=\"32px\" src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver fonte no GitHub</a>\n",
        "</td>\n",
        "<td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/pt-br/tfx/tutorials/tfx/penguin_template.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Baixar notebook</a>\n",
        "</td>\n",
        "</table></div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLYriYe10okf"
      },
      "source": [
        "## Introdução\n",
        "\n",
        "Este documento fornecerá instruções para criar um pipeline TensorFlow Extended (TFX) para seu próprio dataset usando o *template Penguin* fornecido com o pacote TFX em Python. O pipeline criado usará inicialmente o dataset [Palmer Penguins](https://allisonhorst.github.io/palmerpenguins/articles/intro.html), mas vamos transformar o pipeline para seu dataset.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0HDv9FAbUy9"
      },
      "source": [
        "### Pré-requisitos\n",
        "\n",
        "- Linux / MacOS\n",
        "- Python 3.6-3.8\n",
        "- Jupyter notebook\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaXSIXh9czAX"
      },
      "source": [
        "## Etapa 1. Copie o template predefinido para o diretório do seu projeto.\n",
        "\n",
        "Nesta etapa, criaremos um diretório de projeto de pipeline funcional e arquivos copiando os arquivos do *template Penguin* no TFX. Você pode pensar nisso como uma estrutura básica para seu projeto de pipeline TFX."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WoUaCyNF_YlF"
      },
      "source": [
        "### Atualize o pip\n",
        "\n",
        "Se estivermos rodando no Colab, devemos ter certeza de que temos a versão mais recente do Pip. É claro que os sistemas locais podem ser atualizados separadamente.\n",
        "\n",
        "Observação: a atualização provavelmente também é uma boa ideia se você estiver trabalhando no Vertex AI Workbench."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iQIUEpFp_ZA2"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "if 'google.colab' in sys.modules:\n",
        "  !pip install --upgrade pip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmVR97AgacoP"
      },
      "source": [
        "### Instale o pacote obrigatório\n",
        "\n",
        "Primeiro, instale o TFX e o TensorFlow Model Analysis (TFMA).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XNiqq_kN0okj"
      },
      "outputs": [],
      "source": [
        "!pip install -U tfx tensorflow-model-analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hX1rqpbQ0okp"
      },
      "source": [
        "Vamos verificar as versões do TFX."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XAIoKMNG0okq"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_model_analysis as tfma\n",
        "import tfx\n",
        "\n",
        "print('TF version: {}'.format(tf.__version__))\n",
        "print('TFMA version: {}'.format(tfma.__version__))\n",
        "print('TFX version: {}'.format(tfx.__version__))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOsQbkky0ok7"
      },
      "source": [
        "Estamos prontos para criar um pipeline.\n",
        "\n",
        "Defina o `PROJECT_DIR` para o destino apropriado para seu ambiente. O valor padrão é `~/imported/${PIPELINE_NAME}`, que é apropriado para o ambiente do [Google Cloud AI Platform Notebook](https://console.cloud.google.com/ai-platform/notebooks/).\n",
        "\n",
        "Você pode dar um nome diferente ao seu pipeline alterando `PIPELINE_NAME` abaixo. Este também se tornará o nome do diretório do projeto onde seus arquivos serão colocados.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cIPlt-700ok-"
      },
      "outputs": [],
      "source": [
        "PIPELINE_NAME=\"my_pipeline\"\n",
        "import os\n",
        "# Set this project directory to your new tfx pipeline project.\n",
        "PROJECT_DIR=os.path.join(os.path.expanduser(\"~\"), \"imported\", PIPELINE_NAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozHIomcd0olB"
      },
      "source": [
        "### Copie os arquivos do template.\n",
        "\n",
        "O TFX inclui o template `penguin` com o pacote TFX python. O template `penguin` contém muitas instruções para trazer seu dataset para o pipeline, que é o objetivo deste tutorial.\n",
        "\n",
        "O comando CLI `tfx template copy` copia arquivos de template predefinidos no diretório do projeto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VLXpTTjU0olD"
      },
      "outputs": [],
      "source": [
        "# Set `PATH` to include user python binary directory and a directory containing `skaffold`.\n",
        "PATH=%env PATH\n",
        "%env PATH={PATH}:/home/jupyter/.local/bin\n",
        "\n",
        "!tfx template copy \\\n",
        "  --pipeline-name={PIPELINE_NAME} \\\n",
        "  --destination-path={PROJECT_DIR} \\\n",
        "  --model=penguin"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxOT19QS0olH"
      },
      "source": [
        "Altere o contexto do diretório de trabalho neste notebook para o diretório do projeto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6P-HljcU0olI"
      },
      "outputs": [],
      "source": [
        "%cd {PROJECT_DIR}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1tEYUQxH0olO"
      },
      "source": [
        "> OBSERVAÇÃO: Se você estiver usando o JupyterLab ou o Google Cloud AI Platform Notebook, não se esqueça de alterar o diretório no `File Browser` à esquerda clicando no diretório do projeto assim que ele for criado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzT2PFrN0olQ"
      },
      "source": [
        "### Inspecione os arquivos-fonte copiados\n",
        "\n",
        "O template TFX fornece arquivos de estrutura básicos para construir um pipeline, incluindo código-fonte Python e dados de amostra. O template `penguin` usa o mesmo dataset e modelo de ML *Palmer Penguins* que o [exemplo Penguin](https://github.com/tensorflow/tfx/tree/master/tfx/examples/penguin).\n",
        "\n",
        "Aqui está uma breve introdução a cada um dos arquivos Python.\n",
        "\n",
        "- `pipeline` - este diretório contém a definição do pipeline\n",
        "    - `configs.py` — define constantes comuns para executores de pipeline\n",
        "    - `pipeline.py` — define componentes TFX e um pipeline\n",
        "- `models` - este diretório contém definições de modelo de ML.\n",
        "    - `features.py`, `features_test.py` — define características para o modelo\n",
        "    - `preprocessing.py`, `preprocessing_test.py` — define rotinas de pré-processamento para os dados\n",
        "    - `constants.py` — define constantes do modelo\n",
        "    - `model.py` , `model_test.py` – define o modelo de ML usando frameworks de ML como o TensorFlow\n",
        "- `local_runner.py` — define um executor para ambiente local que usa mecanismo de orquestração local\n",
        "- `kubeflow_runner.py` — define um executor para o mecanismo de orquestração do Kubeflow Pipelines\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "saF1CpVefaf1"
      },
      "source": [
        "Por padrão, o template inclui apenas componentes TFX padrão. Se precisar de algumas ações personalizadas, você pode criar componentes personalizados para seu pipeline. Veja o [guia de componentes personalizados do TFX](https://www.tensorflow.org/tfx/guide/understanding_custom_components) para mais detalhes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROwHAsDK0olT"
      },
      "source": [
        "#### Arquivos de teste de unidade.\n",
        "\n",
        "Você poderá perceber que existem alguns arquivos com `_test.py` em seus nomes. Estes são testes unitários do pipeline e é recomendado adicionar mais testes unitários à medida que você for implementando seus próprios pipelines. Você pode executar testes de unidade fornecendo o nome do módulo dos arquivos de teste com o sinalizador `-m`. Geralmente você pode obter um nome de módulo excluindo a extensão `.py` e substituindo `/` por `.`. Por exemplo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M0cMdE2Z0olU"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "!{sys.executable} -m models.features_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tO9Jhplo0olX"
      },
      "source": [
        "### Crie um pipeline TFX em ambiente local.\n",
        "\n",
        "O TFX oferece suporte a vários mecanismos de orquestração para executar pipelines. Usaremos um mecanismo de orquestração local. O mecanismo de orquestração local é executado sem quaisquer dependências adicionais e é adequado para desenvolvimento e depuração porque é executado em ambiente local, em vez de depender de clusters de computação remotos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZO6yR8lOo5GZ"
      },
      "source": [
        "Usaremos o `local_runner.py` para executar seu pipeline usando o orquestrador local. Você precisa criar um pipeline antes de executá-lo. Você pode criar um pipeline com o comando `pipeline create`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_9unbcHlo7Yi"
      },
      "outputs": [],
      "source": [
        "!tfx pipeline create --engine=local --pipeline_path=local_runner.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrRL6R06o99S"
      },
      "source": [
        "O comando `pipeline create` registra seu pipeline definido em `local_runner.py` sem realmente executá-lo.\n",
        "\n",
        "Você executará o pipeline criado com o comando `run create` nas etapas a seguir.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7p73589GbTFi"
      },
      "source": [
        "## Etapa 2. Ingira os SEUS dados no pipeline\n",
        "\n",
        "O pipeline inicial ingere o dataset do pinguim incluído no template. Você precisa colocar seus dados no pipeline, e a maioria dos pipelines do TFX começa com o componente ExampleGen."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEVwa28qtjwi"
      },
      "source": [
        "### Escolha um ExampleGen\n",
        "\n",
        "Seus dados podem ser armazenados em qualquer lugar que seu pipeline possa acessar, num sistema de arquivos local ou distribuído, ou num sistema com capacidade de pesquisa. O TFX fornece vários [componentes `ExampleGen`](https://www.tensorflow.org/tfx/guide/examplegen) para trazer seus dados para um pipeline do TFX. Você pode escolher um dos seguintes componentes geradores de exemplo.\n",
        "\n",
        "- CsvExampleGen: lê arquivos CSV em um diretório. Usado no [exemplo Penguin](https://github.com/tensorflow/tfx/tree/master/tfx/examples/penguin) e no [exemplo Chicago Taxi](https://github.com/tensorflow/tfx/tree/master/tfx/examples/chicago_taxi_pipeline).\n",
        "- ImportExampleGen: recebe arquivos TFRecord com formato de dados TF Example. Usado em [exemplos com MNIST](https://github.com/tensorflow/tfx/tree/master/tfx/examples/mnist).\n",
        "- FileBasedExampleGen para formato [Avro](https://github.com/tensorflow/tfx/blob/master/tfx/components/example_gen/custom_executors/avro_executor.py) ou [Parquet](https://github.com/tensorflow/tfx/blob/master/tfx/components/example_gen/custom_executors/parquet_executor.py).\n",
        "- [BigQueryExampleGen](https://www.tensorflow.org/tfx/api_docs/python/tfx/extensions/google_cloud_big_query/example_gen/component/BigQueryExampleGen): lê dados diretamente no Google Cloud BigQuery. Usado em [exemplos do Chicago Taxi](https://github.com/tensorflow/tfx/tree/master/tfx/examples/chicago_taxi_pipeline).\n",
        "\n",
        "Você também pode criar seu próprio ExampleGen, por exemplo, tfx inclui [um ExampleGen personalizado que usa o Presto](https://github.com/tensorflow/tfx/tree/master/tfx/examples/custom_components/presto_example_gen) como fonte de dados. Consulte o [guia](https://www.tensorflow.org/tfx/guide/examplegen#custom_examplegen) para obter mais informações sobre como usar e desenvolver executores customizados.\n",
        "\n",
        "Depois de decidir qual ExampleGen usar, você precisará modificar a definição do pipeline para usar seus dados.\n",
        "\n",
        "1. Altere o `DATA_PATH` em `local_runner.py` e defina-o como o local dos seus arquivos.\n",
        "\n",
        "- Se você tiver arquivos em ambiente local, especifique o caminho. Esta é a melhor opção para desenvolver ou depurar um pipeline.\n",
        "- Se os arquivos estiverem armazenados no GCS, você poderá usar um caminho começando com `gs://{bucket_name}/...`. Certifique-se de que você pode acessar o GCS a partir do seu terminal, por exemplo, usando [`gsutil`](https://cloud.google.com/storage/docs/gsutil). Siga [o guia de autorização no Google Cloud](https://cloud.google.com/sdk/docs/authorizing) se necessário.\n",
        "- Se quiser usar um ExampleGen baseado em consulta como BigQueryExampleGen, você precisará de uma instrução Query para selecionar dados da fonte de dados. Há mais algumas coisas que você precisa definir para usar o Google Cloud BigQuery como fonte de dados.\n",
        "    - Em `pipeline/configs.py`:\n",
        "        - Altere `GOOGLE_CLOUD_PROJECT` e `GCS_BUCKET_NAME` para seu projeto GCP e nome do bucket. O bucket deve existir antes de executarmos o pipeline.\n",
        "        - Descomente a variável `BIG_QUERY_WITH_DIRECT_RUNNER_BEAM_PIPELINE_ARGS`.\n",
        "        - Descomente e defina a variável `BIG_QUERY_QUERY` para **sua instrução de query**.\n",
        "    - Em `local_runner.py`:\n",
        "        - Comente o argumento `data_path` e descomente o argumento `query` em `pipeline.create_pipeline()`.\n",
        "    - Em `pipeline/pipeline.py`:\n",
        "        - Comente o argumento `data_path` e descomente o argumento `query` em `create_pipeline()`.\n",
        "        - Use [BigQueryExampleGen](https://www.tensorflow.org/tfx/api_docs/python/tfx/extensions/google_cloud_big_query/example_gen/component/BigQueryExampleGen) em vez de CsvExampleGen.\n",
        "\n",
        "1. Substitua o CsvExampleGen existente pela sua classe ExampleGen em `pipeline/pipeline.py`. Cada classe ExampleGen possui uma assinatura diferente. Consulte o [guia do componente ExampleGen](https://www.tensorflow.org/tfx/guide/examplegen) para mais detalhes. Não esqueça de importar os módulos necessários com instruções `import` em `pipeline/pipeline.py`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xiAG6acjbl5U"
      },
      "source": [
        "O pipeline inicial consiste em quatro componentes, `ExampleGen`, `StatisticsGen`, `SchemaGen` e `ExampleValidator`. Não precisamos alterar nada para `StatisticsGen`, `SchemaGen` e `ExampleValidator`. Vamos executar o pipeline pela primeira vez."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tKOI48WumF7h"
      },
      "outputs": [],
      "source": [
        "# Update and run the pipeline.\n",
        "!tfx pipeline update --engine=local --pipeline_path=local_runner.py \\\n",
        " && tfx run create --engine=local --pipeline_name={PIPELINE_NAME}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFbYFNVbbzna"
      },
      "source": [
        "Você deverá ver a mensagem \"Component ExampleValidator is finished.\" se o pipeline foi executado com sucesso."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uuD5FRPAcOn8"
      },
      "source": [
        "### Examine a saída do pipeline."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tL1wWoDh5wkj"
      },
      "source": [
        "O pipeline TFX produz dois tipos de saída, artefatos e um [banco de dados de metadados (MLMD)](https://www.tensorflow.org/tfx/guide/mlmd) que contém metadados de artefatos e execuções de pipeline. O local da saída é definido em `local_runner.py`. Por padrão, os artefatos são armazenados no diretório `tfx_pipeline_output` e os metadados são armazenados como um banco de dados sqlite no diretório `tfx_metadata`.\n",
        "\n",
        "Você pode usar APIs MLMD para examinar essas saídas. Primeiro, definiremos algumas funções utilitárias para pesquisar artefatos de saída que acabaram de ser produzidos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K0i_jTvOI8mv"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tfx\n",
        "from ml_metadata import errors\n",
        "from ml_metadata.proto import metadata_store_pb2\n",
        "from tfx.types import artifact_utils\n",
        "\n",
        "# TODO(b/171447278): Move these functions into TFX library.\n",
        "\n",
        "def get_latest_executions(store, pipeline_name, component_id = None):\n",
        "  \"\"\"Fetch all pipeline runs.\"\"\"\n",
        "  if component_id is None:  # Find entire pipeline runs.\n",
        "    run_contexts = [\n",
        "        c for c in store.get_contexts_by_type('run')\n",
        "        if c.properties['pipeline_name'].string_value == pipeline_name\n",
        "    ]\n",
        "  else:  # Find specific component runs.\n",
        "    run_contexts = [\n",
        "        c for c in store.get_contexts_by_type('component_run')\n",
        "        if c.properties['pipeline_name'].string_value == pipeline_name and\n",
        "           c.properties['component_id'].string_value == component_id\n",
        "    ]\n",
        "  if not run_contexts:\n",
        "    return []\n",
        "  # Pick the latest run context.\n",
        "  latest_context = max(run_contexts,\n",
        "                       key=lambda c: c.last_update_time_since_epoch)\n",
        "  return store.get_executions_by_context(latest_context.id)\n",
        "\n",
        "def get_latest_artifacts(store, pipeline_name, component_id = None):\n",
        "  \"\"\"Fetch all artifacts from latest pipeline execution.\"\"\"\n",
        "  executions = get_latest_executions(store, pipeline_name, component_id)\n",
        "\n",
        "  # Fetch all artifacts produced from the given executions.\n",
        "  execution_ids = [e.id for e in executions]\n",
        "  events = store.get_events_by_execution_ids(execution_ids)\n",
        "  artifact_ids = [\n",
        "      event.artifact_id for event in events\n",
        "      if event.type == metadata_store_pb2.Event.OUTPUT\n",
        "  ]\n",
        "  return store.get_artifacts_by_id(artifact_ids)\n",
        "\n",
        "def find_latest_artifacts_by_type(store, artifacts, artifact_type):\n",
        "  \"\"\"Get the latest artifacts of a specified type.\"\"\"\n",
        "  # Get type information from MLMD\n",
        "  try:\n",
        "    artifact_type = store.get_artifact_type(artifact_type)\n",
        "  except errors.NotFoundError:\n",
        "    return []\n",
        "  # Filter artifacts with type.\n",
        "  filtered_artifacts = [aritfact for aritfact in artifacts\n",
        "                        if aritfact.type_id == artifact_type.id]\n",
        "  # Convert MLMD artifact data into TFX Artifact instances.\n",
        "  return [artifact_utils.deserialize_artifact(artifact_type, artifact)\n",
        "      for artifact in filtered_artifacts]\n",
        "\n",
        "\n",
        "from tfx.orchestration.experimental.interactive import visualizations\n",
        "\n",
        "def visualize_artifacts(artifacts):\n",
        "  \"\"\"Visualizes artifacts using standard visualization modules.\"\"\"\n",
        "  for artifact in artifacts:\n",
        "    visualization = visualizations.get_registry().get_visualization(\n",
        "        artifact.type_name)\n",
        "    if visualization:\n",
        "      visualization.display(artifact)\n",
        "\n",
        "from tfx.orchestration.experimental.interactive import standard_visualizations\n",
        "standard_visualizations.register_standard_visualizations()\n",
        "\n",
        "import pprint\n",
        "\n",
        "from tfx.orchestration import metadata\n",
        "from tfx.types import artifact_utils\n",
        "from tfx.types import standard_artifacts\n",
        "\n",
        "def preview_examples(artifacts):\n",
        "  \"\"\"Preview a few records from Examples artifacts.\"\"\"\n",
        "  pp = pprint.PrettyPrinter()\n",
        "  for artifact in artifacts:\n",
        "    print(\"==== Examples artifact:{}({})\".format(artifact.name, artifact.uri))\n",
        "    for split in artifact_utils.decode_split_names(artifact.split_names):\n",
        "      print(\"==== Reading from split:{}\".format(split))\n",
        "      split_uri = artifact_utils.get_split_uri([artifact], split)\n",
        "\n",
        "      # Get the list of files in this directory (all compressed TFRecord files)\n",
        "      tfrecord_filenames = [os.path.join(split_uri, name)\n",
        "                            for name in os.listdir(split_uri)]\n",
        "      # Create a `TFRecordDataset` to read these files\n",
        "      dataset = tf.data.TFRecordDataset(tfrecord_filenames,\n",
        "                                        compression_type=\"GZIP\")\n",
        "      # Iterate over the first 2 records and decode them.\n",
        "      for tfrecord in dataset.take(2):\n",
        "        serialized_example = tfrecord.numpy()\n",
        "        example = tf.train.Example()\n",
        "        example.ParseFromString(serialized_example)\n",
        "        pp.pprint(example)\n",
        "\n",
        "import local_runner\n",
        "\n",
        "metadata_connection_config = metadata.sqlite_metadata_connection_config(\n",
        "              local_runner.METADATA_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmwor9nVcmxy"
      },
      "source": [
        "Agora podemos ler metadados de artefatos de saída do MLMD."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TtsrZEUB1-J4"
      },
      "outputs": [],
      "source": [
        "with metadata.Metadata(metadata_connection_config) as metadata_handler:\n",
        "    # Search all aritfacts from the previous pipeline run.\n",
        "    artifacts = get_latest_artifacts(metadata_handler.store, PIPELINE_NAME)\n",
        "    # Find artifacts of Examples type.\n",
        "    examples_artifacts = find_latest_artifacts_by_type(\n",
        "        metadata_handler.store, artifacts,\n",
        "        standard_artifacts.Examples.TYPE_NAME)\n",
        "    # Find artifacts generated from StatisticsGen.\n",
        "    stats_artifacts = find_latest_artifacts_by_type(\n",
        "        metadata_handler.store, artifacts,\n",
        "        standard_artifacts.ExampleStatistics.TYPE_NAME)\n",
        "    # Find artifacts generated from SchemaGen.\n",
        "    schema_artifacts = find_latest_artifacts_by_type(\n",
        "        metadata_handler.store, artifacts,\n",
        "        standard_artifacts.Schema.TYPE_NAME)\n",
        "    # Find artifacts generated from ExampleValidator.\n",
        "    anomalies_artifacts = find_latest_artifacts_by_type(\n",
        "        metadata_handler.store, artifacts,\n",
        "        standard_artifacts.ExampleAnomalies.TYPE_NAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3U5MNAUIdBtN"
      },
      "source": [
        "Agora podemos examinar os resultados de cada componente. [Tensorflow Data Validation (TFDV)](https://www.tensorflow.org/tfx/data_validation/get_started) é usado em `StatisticsGen`, `SchemaGen` e `ExampleValidator`, e TFDV pode ser usado para visualizar os resultados desses componentes.\n",
        "\n",
        "Neste tutorial, usaremos métodos helper de visualização no TFX que usam TFDV internamente para mostrar a visualização. Consulte o [tutorial dos componentes TFX](https://www.tensorflow.org/tfx/tutorials/tfx/components_keras) para saber mais sobre cada componente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxS6FsgU2IoZ"
      },
      "source": [
        "#### Examine a saída do ExampleGen\n",
        "\n",
        "Vamos examinar a saída de ExampleGen. Dê uma olhada nos dois primeiros exemplos para cada divisão:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3NWzXEcE13tW"
      },
      "outputs": [],
      "source": [
        "preview_examples(examples_artifacts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0uiuPhkGEBz"
      },
      "source": [
        "Por padrão, o TFX ExampleGen divide os exemplos em duas divisões, *train* e *eval*, mas você pode [ajustar a configuração da divisão](https://www.tensorflow.org/tfx/guide/examplegen#span_version_and_split)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVh13wJu-IRv"
      },
      "source": [
        "#### Examine a saída do StatisticsGen\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9LipxUp7-IRw"
      },
      "outputs": [],
      "source": [
        "visualize_artifacts(stats_artifacts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8aebEY4c0Ju7"
      },
      "source": [
        "Essas estatísticas são fornecidas ao SchemaGen para construir um esquema de dados automaticamente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExEKbdw8-IRx"
      },
      "source": [
        "#### Examine a saída do SchemaGen\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M2IURBSp-IRy"
      },
      "outputs": [],
      "source": [
        "visualize_artifacts(schema_artifacts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTvj8yeBHDdU"
      },
      "source": [
        "Este esquema é inferido automaticamente da saída do StatisticsGen. Usaremos esse esquema gerado neste tutorial, mas você também pode [modificar e personalizar o esquema](https://www.tensorflow.org/tfx/guide/statsgen#creating_a_curated_schema)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rl1PEUgo-IRz"
      },
      "source": [
        "#### Examine a saída de ExampleValidator\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F-4oAjGR-IR0"
      },
      "outputs": [],
      "source": [
        "visualize_artifacts(anomalies_artifacts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t026ZzbU0961"
      },
      "source": [
        "Se alguma anomalia foi encontrada, você poderá revisar seus dados para que todos os exemplos sigam suas suposições. Os resultados de outros componentes como StatisticsGen podem ser úteis. As anomalias encontradas não bloqueiam a execução do pipeline."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFMmqy1W-IR1"
      },
      "source": [
        "Você poderá ver as características disponíveis nas saídas do `SchemaGen`. Se suas características puderem ser usadas ​​para construir o modelo de ML diretamente no `Trainer`, você pode pular a próxima etapa e ir para a Etapa 4. Caso contrário, você terá que fazer uma engenharia de recursos na próxima etapa. O componente `Transform` é necessário quando são necessárias operações de full-pass, como cálculo de médias, especialmente quando você precisa escalar."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYH8Y2KB0olm"
      },
      "source": [
        "## Etapa 3. (Opcional) Engenharia de características com o componente Transform.\n",
        "\n",
        "Nesta etapa, você definirá vários jobs de engenharia de características que serão usados ​​pelo componente `Transform` no pipeline. Consulte o [guia do componente Transform](https://www.tensorflow.org/tfx/guide/transform) para mais informações.\n",
        "\n",
        "Isso só será necessário se o código de treinamento exigir características adicionais que não estão disponíveis na saída de ExampleGen. Caso contrário, sinta-se à vontade para avançar para a próxima etapa de uso do Trainer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qm_JjQUydbbb"
      },
      "source": [
        "### Defina as características do modelo\n",
        "\n",
        "`models/features.py` contém constantes para definir características para o modelo, incluindo nomes de características, tamanho do vocabulário e assim por diante. Por padrão, o modelo `penguin` tem duas constantes, `FEATURE_KEYS` e `LABEL_KEY`, porque nosso modelo `penguin` resolve um problema de classificação usando aprendizado supervisionado e todas as características são características numéricas contínuas. Veja as [definições de características do exemplo Chicago Taxi](https://github.com/tensorflow/tfx/blob/master/tfx/experimental/templates/taxi/models/features.py) como outro exemplo.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATUeHXvJdcBn"
      },
      "source": [
        "### Implemente pré-processamento para treinamento/serviço em preprocessing_fn().\n",
        "\n",
        "A engenharia de características real acontece na função `preprocessing_fn()` em `models/preprocessing.py`.\n",
        "\n",
        "Em `preprocessing_fn` você pode definir uma série de funções que manipulam o dict de tensores de entrada para produzir o dict de tensores de saída. Tem as funções helper como `scale_to_0_1` e `compute_and_apply_vocabulary` na API TensorFlow Transform ou você pode simplesmente usar funções regulares do TensorFlow. Por padrão, o template `penguin` inclui exemplos de uso da função [tft.scale_to_z_score](https://www.tensorflow.org/tfx/transform/api_docs/python/tft/scale_to_z_score) para normalizar os valores das características.\n",
        "\n",
        "Consulte o guia [TensorFlow Transform](https://www.tensorflow.org/tfx/transform/get_started) para mais informações sobre a criação de `preprocessing_fn`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUg_Lc43dbTp"
      },
      "source": [
        "### Inclua o componente Transform no pipeline.\n",
        "\n",
        "Se seu preprocessing_fn estiver pronto, adicione o componente `Transform` ao pipeline.\n",
        "\n",
        "1. No arquivo `pipeline/pipeline.py`, descomente `# components.append(transform)` para adicionar o componente ao pipeline.\n",
        "\n",
        "Você pode atualizar o pipeline e executá-lo novamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VE-Pqvto0olm"
      },
      "outputs": [],
      "source": [
        "!tfx pipeline update --engine=local --pipeline_path=local_runner.py \\\n",
        " && tfx run create --engine=local --pipeline_name={PIPELINE_NAME}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8q1ZYEHX0olo"
      },
      "source": [
        "Se o pipeline foi executado com sucesso, você verá \"Component Transform is finished\" *em algum lugar* do log. Como o componente `Transform` e o componente `ExampleValidator` não dependem um do outro, a ordem das execuções não é fixa. Dito isto, `Transform` e `ExampleValidator` podem ser o último componente na execução do pipeline."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrPEnZt0E_0m"
      },
      "source": [
        "### Examine a saída do Transform\n",
        "\n",
        "O componente Transform cria dois tipos de saída, um grafo TensorFlow e exemplos transformados. Os exemplos transformados são do tipo de artefato Examples que também é produzido por ExampleGen, mas este contém valores de características transformadas.\n",
        "\n",
        "Você pode examiná-las como fizemos na etapa anterior."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FvC5S66ZU5g6"
      },
      "outputs": [],
      "source": [
        "with metadata.Metadata(metadata_connection_config) as metadata_handler:\n",
        "    # Search all aritfacts from the previous run of Transform component.\n",
        "    artifacts = get_latest_artifacts(metadata_handler.store,\n",
        "                                     PIPELINE_NAME, \"Transform\")\n",
        "    # Find artifacts of Examples type.\n",
        "    transformed_examples_artifacts = find_latest_artifacts_by_type(\n",
        "        metadata_handler.store, artifacts,\n",
        "        standard_artifacts.Examples.TYPE_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CAFiEPKuC6Ib"
      },
      "outputs": [],
      "source": [
        "preview_examples(transformed_examples_artifacts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWMBXU510olp"
      },
      "source": [
        "## Etapa 4. Treine seu modelo com o componente Trainer.\n",
        "\n",
        "Construiremos um modelo de ML usando o componente `Trainer`. Consulte o [guia do componente Trainer](https://www.tensorflow.org/tfx/guide/trainer) para obter mais informações. Você precisa fornecer o código do seu modelo para o componente Trainer.\n",
        "\n",
        "### Defina seu modelo.\n",
        "\n",
        "No template Penguin, `models.model.run_fn` é usado como argumento `run_fn` para o componente `Trainer`. Isto significa que a função `run_fn()` em `models/model.py` será chamada quando o componente `Trainer` for executado. Você pode ver o código para construir um modelo DNN simples usando a API `keras` em determinado código. Consulte o guia [TensorFlow 2.x no TFX](https://www.tensorflow.org/tfx/guide/keras) para mais informações sobre como usar a API keras no TFX.\n",
        "\n",
        "Neste `run_fn`, você deve construir um modelo e salvá-lo em um diretório apontado por `fn_args.serving_model_dir` que é especificado pelo componente. Você pode usar outros argumentos em `fn_args` que são passados ​​para `run_fn`. Consulte os [códigos relacionados](https://github.com/tensorflow/tfx/blob/b01482442891a49a1487c67047e85ab971717b75/tfx/components/trainer/executor.py#L141) para obter a lista completa de argumentos em `fn_args`.\n",
        "\n",
        "Defina suas características em `models/features.py` e use-as conforme necessário. Se você transformou suas características na Etapa 3, deverá usar as características transformadas como entradas para seu modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFiLIaCm-IR4"
      },
      "source": [
        "### Adicione o componente Trainer ao pipeline.\n",
        "\n",
        "Se o seu run_fn estiver pronto, adicione o componente `Trainer` ao pipeline.\n",
        "\n",
        "1. No arquivo `pipeline/pipeline.py`, descomente `# components.append(trainer)` para adicionar o componente ao pipeline.\n",
        "\n",
        "Os argumentos para o componente trainer podem depender de você usar o componente Transform ou não.\n",
        "\n",
        "- Se você **NÃO** usa o componente `Transform`, não precisa alterar os argumentos.\n",
        "\n",
        "- Se você usar o componente `Transform`, precisará alterar os argumentos ao criar uma instância do componente `Trainer`.\n",
        "\n",
        "    - Altere o argumento de `examples` para `examples=transform.outputs['transformed_examples'],`. Precisamos usar exemplos transformados para treinamento.\n",
        "    - Adicione o argumento `transform_graph` como `transform_graph=transform.outputs['transform_graph'],`. Este grafo contém o grafo do TensorFlow para as operações de transformação.\n",
        "    - Após as alterações acima, o código para criação do componente Trainer ficará semelhante ao seguinte.\n",
        "\n",
        "    ```python\n",
        "    # If you use a Transform component.\n",
        "    trainer = Trainer(\n",
        "        run_fn=run_fn,\n",
        "        examples=transform.outputs['transformed_examples'],\n",
        "        transform_graph=transform.outputs['transform_graph'],\n",
        "        schema=schema_gen.outputs['schema'],\n",
        "        ...\n",
        "    ```\n",
        "\n",
        "Você pode atualizar o pipeline e executá-lo novamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VQDNitkH0olq"
      },
      "outputs": [],
      "source": [
        "!tfx pipeline update --engine=local --pipeline_path=local_runner.py \\\n",
        " && tfx run create --engine=local --pipeline_name={PIPELINE_NAME}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksWfVQUnMYCX"
      },
      "source": [
        "Quando esta execução for executada com sucesso, você terá criado e executado seu primeiro pipeline TFX para seu modelo. Parabéns!\n",
        "\n",
        "Seu novo modelo estará localizado em algum lugar no diretório de saída, mas seria melhor ter um modelo em local fixo ou serviço fora do pipeline do TFX que contenha muitos resultados provisórios. Melhor ainda com avaliação contínua do modelo construído, que é fundamental em sistemas de ML em produção. Veremos como a avaliação contínua e as implantações funcionam no TFX na próxima etapa."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DRTFdTy0ol3"
      },
      "source": [
        "## Etapa 5. (Opcional) Avalie o modelo com o Evaluator e publique com o pusher.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DID2nzH-IR7"
      },
      "source": [
        "O componente [`Evaluator`](https://www.tensorflow.org/tfx/guide/evaluator) avalia continuamente cada modelo construído no `Trainer` e [`Pusher`](https://www.tensorflow.org/tfx/guide/pusher) copia o modelo para um local predefinido no sistema de arquivos ou até mesmo para o [Google Cloud AI Platform Models](https://console.cloud.google.com/ai-platform/models).\n",
        "\n",
        "### Adiciona o componente Evaluator ao pipeline.\n",
        "\n",
        "No arquivo `pipeline/pipeline.py`:\n",
        "\n",
        "1. Descomente `# components.append(model_resolver)` para adicionar o resolvedor de modelo mais recente ao pipeline. O Evaluator pode ser usado para comparar um modelo com o modelo de referência antigo que passou no Evaluator na última execução do pipeline. `LatestBlessedModelResolver` encontra o modelo mais recente que passou no Evaluator.\n",
        "2. Defina um `tfma.MetricsSpec` adequado para seu modelo. A avaliação pode ser diferente para cada modelo de ML. No template Penguin, `SparseCategoricalAccuracy` foi usado porque estamos resolvendo um problema de classificação multicategoria. Você também precisa especificar `tfma.SliceSpec` para analisar seu modelo para fatias específicas. Para mais detalhes, consulte o [Guia do componente Evaluator](https://www.tensorflow.org/tfx/guide/evaluator).\n",
        "3. Descomente `# components.append(evaluator)` para adicionar o componente ao pipeline.\n",
        "\n",
        "Você pode atualizar o pipeline e executá-lo novamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i5_ojoZZmaDQ"
      },
      "outputs": [],
      "source": [
        "# Update and run the pipeline.\n",
        "!tfx pipeline update --engine=local --pipeline_path=local_runner.py \\\n",
        " && tfx run create --engine=local --pipeline_name={PIPELINE_NAME}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apZX74qJ-IR7"
      },
      "source": [
        "### Examine a saída do Evaluator\n",
        "\n",
        "Esta etapa requer a extensão do notebook Jupyter do TensorFlow Model Analysis (TFMA). Observe que a versão da extensão do notebook TFMA deve ser idêntica à versão do pacote python TFMA.\n",
        "\n",
        "O comando a seguir instalará a extensão do notebook TFMA do registro NPM. Pode levar vários minutos para ser concluído."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VoL46D5Pw5FX"
      },
      "outputs": [],
      "source": [
        "# Install TFMA notebook extension.\n",
        "!jupyter labextension install tensorflow_model_analysis@{tfma.__version__}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKMo4j8ww5PB"
      },
      "source": [
        "Se a instalação estiver concluída, **reinicie seu navegador** para que a extensão tenha efeito."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ztotdqS-IR8"
      },
      "outputs": [],
      "source": [
        "with metadata.Metadata(metadata_connection_config) as metadata_handler:\n",
        "  # Search all aritfacts from the previous pipeline run.\n",
        "  artifacts = get_latest_artifacts(metadata_handler.store, PIPELINE_NAME)\n",
        "  model_evaluation_artifacts = find_latest_artifacts_by_type(\n",
        "      metadata_handler.store, artifacts,\n",
        "      standard_artifacts.ModelEvaluation.TYPE_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tVojwMCuDJuk"
      },
      "outputs": [],
      "source": [
        "if model_evaluation_artifacts:\n",
        "  tfma_result = tfma.load_eval_result(model_evaluation_artifacts[0].uri)\n",
        "  tfma.view.render_slicing_metrics(tfma_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18tqjyHN-IR9"
      },
      "source": [
        "### Adiciona o componente Pusher ao pipeline.\n",
        "\n",
        "Se o modelo parecer promissor, precisamos publicá-lo. [O componente Pusher](https://www.tensorflow.org/tfx/guide/pusher) pode publicar o modelo em um local do sistema de arquivos ou para GCP AI Platform Models usando [um executor personalizado](https://github.com/tensorflow/tfx/blob/master/tfx/extensions/google_cloud_ai_platform/pusher/executor.py).\n",
        "\n",
        "O componente <a><code data-md-type=\"codespan\">Evaluator</code></a> avalia continuamente cada modelo construído no <code>Trainer</code> e <a><code>Pusher</code></a> copia o modelo para um local predefinido no sistema de arquivos ou até mesmo para o <a>Google Cloud AI Platform Models</a>.\n",
        "\n",
        "1. Em `local_runner.py`, defina `SERVING_MODEL_DIR` como um diretório para publicar.\n",
        "2. No arquivo `pipeline/pipeline.py`, descomente `# components.append(pusher)` para adicionar o Pusher ao pipeline.\n",
        "\n",
        "Você pode atualizar o pipeline e executá-lo novamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QH81d9FsrSXS"
      },
      "outputs": [],
      "source": [
        "# Update and run the pipeline.\n",
        "!tfx pipeline update --engine=local --pipeline_path=local_runner.py \\\n",
        " && tfx run create --engine=local --pipeline_name={PIPELINE_NAME}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_K6Z18tC-IR-"
      },
      "source": [
        "Você deverá encontrar seu novo modelo em `SERVING_MODEL_DIR`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20KRGsPX0ol3"
      },
      "source": [
        "## Etapa 6. (Opcional) Implante seu pipeline para o Kubeflow Pipelines no GCP.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0X6vfy7s-IR-"
      },
      "source": [
        "Conforme mencionado anteriormente, `local_runner.py` é bom para fins de depuração ou desenvolvimento, mas não é a melhor solução para cargas de trabalho em produção. Nesta etapa, implantaremos o pipeline no Kubeflow Pipelines no Google Cloud.\n",
        "\n",
        "### Preparação\n",
        "\n",
        "Precisamos do pacote `kfp` python e do programa `skaffold` para implantar um pipeline em um cluster Kubeflow Pipelines."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ge1bMUtU-IR_"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade -q kfp\n",
        "\n",
        "# Download skaffold and set it executable.\n",
        "!curl -Lo skaffold https://storage.googleapis.com/skaffold/releases/latest/skaffold-linux-amd64 && chmod +x skaffold"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZsbnGq52-ISB"
      },
      "source": [
        "Você precisa mover o binário `skaffold` para o local onde seu shell possa encontrá-lo. Ou você pode especificar o caminho para o skaffold ao executar o binário `tfx` com o sinalizador `--skaffold-cmd` ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4amQ0Elz-ISC"
      },
      "outputs": [],
      "source": [
        "# Move skaffold binary into your path\n",
        "!mv skaffold /home/jupyter/.local/bin/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rmyns-o-ISD"
      },
      "source": [
        "Você também precisa de um cluster Kubeflow Pipelines para executar o pipeline. Siga as etapas 1 e 2 no [Tutorial TFX on Cloud AI Platform Pipelines](https://www.tensorflow.org/tfx/tutorials/tfx/cloud-ai-platform-pipelines).\n",
        "\n",
        "Quando seu cluster estiver pronto, abra o painel do pipeline clicando em *Open Pipelines Dashboard* na [página `Pipelines` do Google Cloud Console](http://console.cloud.google.com/ai-platform/pipelines). A URL desta página é `ENDPOINT` para solicitar a execução de um pipeline. O valor do endpoint é tudo na URL depois di https://, até e incluindo googleusercontent.com. Coloque seu endpoint no seguinte bloco de código.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hGyj-Qa3-ISD"
      },
      "outputs": [],
      "source": [
        "ENDPOINT='' # Enter your ENDPOINT here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igTo05YI-ISF"
      },
      "source": [
        "Para executar nosso código num cluster Kubeflow Pipelines, precisamos compactar nosso código numa imagem de container. A imagem será construída automaticamente durante a implantação do nosso pipeline, e você só precisa definir um nome e um registro de container para sua imagem. Em nosso exemplo, usaremos o [Google Container Registry](https://cloud.google.com/container-registry) e o nomearemos `tfx-pipeline`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5J3LrI0K-ISF"
      },
      "outputs": [],
      "source": [
        "# Read GCP project id from env.\n",
        "shell_output=!gcloud config list --format 'value(core.project)' 2>/dev/null\n",
        "GOOGLE_CLOUD_PROJECT=shell_output[0]\n",
        "\n",
        "# Docker image name for the pipeline image.\n",
        "CUSTOM_TFX_IMAGE='gcr.io/' + GOOGLE_CLOUD_PROJECT + '/tfx-pipeline'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gg11pLmU-ISH"
      },
      "source": [
        "### Defina a localização dos dados.\n",
        "\n",
        "Seus dados devem estar acessíveis no cluster Kubeflow Pipelines. Se você usou dados em seu ambiente local, talvez seja necessário carregá-los para um armazenamento remoto, como o Google Cloud Storage. Por exemplo, podemos fazer upload de dados do Penguin para um bucket padrão que é criado automaticamente quando um cluster Kubeflow Pipelines é implantado como a seguir."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y8MmRIHi-ISH"
      },
      "outputs": [],
      "source": [
        "!gsutil cp data/data.csv gs://{GOOGLE_CLOUD_PROJECT}-kubeflowpipelines-default/tfx-template/data/penguin/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASc1tDMm-ISJ"
      },
      "source": [
        "Atualize o local dos dados armazenados em `DATA_PATH` em `kubeflow_runner.py`.\n",
        "\n",
        "Se você estiver usando BigQueryExampleGen, não há necessidade de fazer upload do arquivo de dados, mas certifique-se de que `kubeflow_runner.py` use a mesma `query` e argumento `beam_pipeline_args` para a função `pipeline.create_pipeline()`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q42gn3XS-ISK"
      },
      "source": [
        "### Implante o pipeline.\n",
        "\n",
        "Se tudo estiver pronto, você pode criar um pipeline usando o comando `tfx pipeline create`.\n",
        "\n",
        "> Observação: ao criar um pipeline para o Kubeflow Pipelines, precisamos de uma imagem de container que será usada para executar nosso pipeline. E o `skaffold` vai criar a imagem para nós. Como o `skaffold` extrai imagens base do docker hub, levará de 5 a 10 minutos quando criarmos a imagem pela primeira vez, mas levará muito menos tempo na segunda vez.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ytZ0liBn-ISK"
      },
      "outputs": [],
      "source": [
        "!tfx pipeline create  \\\n",
        "--engine=kubeflow \\\n",
        "--pipeline-path=kubeflow_runner.py \\\n",
        "--endpoint={ENDPOINT} \\\n",
        "--build-target-image={CUSTOM_TFX_IMAGE}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFqUQxQG-ISM"
      },
      "source": [
        "Agora inicie uma execução com o pipeline recém-criado usando o comando `tfx run create`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ps-4RHz-ISM"
      },
      "outputs": [],
      "source": [
        "!tfx run create --engine=kubeflow --pipeline-name={PIPELINE_NAME} --endpoint={ENDPOINT}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fx3LtAL0-ISN"
      },
      "source": [
        "Ou você também pode executar o pipeline no painel do Kubeflow Pipelines. A nova execução será listada em `Experiments` no Painel do Kubeflow Pipelines. Clicar no experimento permitirá monitorar o progresso e visualizar os artefatos criados durante a execução."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mP8W6zjD-ISO"
      },
      "source": [
        "Se você estiver interessado em executar seu pipeline no Kubeflow Pipelines, procure mais instruções no [Tutorial TFX on Cloud AI Platform Pipelines](https://www.tensorflow.org/tfx/tutorials/tfx/cloud-ai-platform-pipelines)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTsgD_Kz-ISO"
      },
      "source": [
        "### Limpeza\n",
        "\n",
        "Para limpar todos os recursos do Google Cloud usados ​​nesta etapa, [exclua o projeto do Google Cloud](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects) usado no tutorial.\n",
        "\n",
        "Como alternativa, você pode limpar recursos individuais acessando cada console individualmente:\n",
        "\n",
        "- [Google Cloud Storage](https://console.cloud.google.com/storage)\n",
        "- [Google Container Registry](https://console.cloud.google.com/gcr)\n",
        "- [Google Kubernetes Engine](https://console.cloud.google.com/kubernetes)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "DjUA6S30k52h"
      ],
      "name": "penguin_template.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
