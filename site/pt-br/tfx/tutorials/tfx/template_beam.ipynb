{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjUA6S30k52h"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "SpNWyqewk8fE"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqZC7Cv942w0"
      },
      "source": [
        "# Crie um pipeline TFX usando templates com orquestrador local"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdSXv1DrxdLL"
      },
      "source": [
        "<div class=\"devsite-table-wrapper\"><table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "<td>     <a target=\"_blank\" href=\"https://www.tensorflow.org/tfx/tutorials/tfx/template_local\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver em TensorFlow.org</a>\n",
        "</td>\n",
        "<td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/tfx/blob/master/docs/tutorials/tfx/template_local.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Executar no Google Colab</a>\n",
        "</td>\n",
        "<td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/tfx/tree/master/docs/tutorials/tfx/template_local.ipynb\"> <img width=\"32px\" src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\"> Ver fonte no GitHub</a>\n",
        "</td>\n",
        "<td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/tfx/docs/tutorials/tfx/template_local.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Baixar notebook</a>\n",
        "</td>\n",
        "</table></div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRBoc5la42w0"
      },
      "source": [
        "## Introdução\n",
        "\n",
        "Este documento fornecerá instruções para criar um pipeline TensorFlow Extended (TFX) usando *templates* fornecidos com o pacote TFX Python. A maioria das instruções são comandos shell do Linux. Células de código correspondentes do Jupyter Notebook que invocam esses comandos usando `!` são fornecidos.\n",
        "\n",
        "Você construirá um pipeline usando o [dataset Taxi Trips](https://data.cityofchicago.org/Transportation/Taxi-Trips/wrvz-psew) divulgado pela cidade de Chicago. Recomendamos fortemente que você tente construir seu pipeline usando seu próprio dataset, utilizando esse pipeline como referência.\n",
        "\n",
        "Construiremos um pipeline que roda em ambiente local. Se você estiver interessado em usar o orquestrador Kubeflow no Google Cloud, consulte o [tutorial TFX no Cloud AI Platform Pipelines](https://www.tensorflow.org/tfx/tutorials/tfx/cloud-ai-platform-pipelines).\n",
        "\n",
        "## Pré-requisitos\n",
        "\n",
        "- Linux / MacOS\n",
        "- Python &gt;= 3.5.3\n",
        "\n",
        "Você pode obter todos os pré-requisitos facilmente [executando este notebook no Google Colab](https://colab.sandbox.google.com/github/tensorflow/tfx/blob/master/docs/tutorials/tfx/template_local.ipynb).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRW5apUw42w1"
      },
      "source": [
        "## Etapa 1. Configure seu ambiente.\n",
        "\n",
        "**Ao longo deste documento, apresentaremos comandos duas vezes. Uma vez como um comando shell pronto para copiar e colar, uma vez como uma célula do notebook jupyter. Se você estiver usando o Colab, basta pular os blocos de script shell e executar as células do notebook.**\n",
        "\n",
        "Você deve preparar um ambiente de desenvolvimento para construir um pipeline.\n",
        "\n",
        "Instale o pacote `tfx` python. Recomendamos o uso de `virtualenv` no ambiente local. Você pode usar o seguinte snippet de script de shell para configurar seu ambiente.\n",
        "\n",
        "```sh\n",
        "# Create a virtualenv for tfx.\n",
        "virtualenv -p python3 venv\n",
        "source venv/bin/activate\n",
        "# Install python packages.\n",
        "python -m pip install --upgrade \"tfx<2\"\n",
        "```\n",
        "\n",
        "Se você estiver usando o colab:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "llKzIjr442w1"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "!{sys.executable} -m pip install --upgrade \"tfx<2\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NA86S2v42w1"
      },
      "source": [
        "OBSERVAÇÃO: Pode haver alguns erros durante a instalação do pacote. Por exemplo,\n",
        "\n",
        "> ERROR: some-package 0.some_version.1 has requirement other-package!=2.0.,&lt;3,&gt;=1.15, but you'll have other-package 2.0.0 which is incompatible.\n",
        "\n",
        "Por favor, ignore esses erros neste momento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m6-DrWm042w4"
      },
      "outputs": [],
      "source": [
        "# Set `PATH` to include user python binary directory.\n",
        "HOME=%env HOME\n",
        "PATH=%env PATH\n",
        "%env PATH={PATH}:{HOME}/.local/bin"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YszwBVuS42w6"
      },
      "source": [
        "Vamos verificar a versão do TFX.\n",
        "\n",
        "```bash\n",
        "python -c \"from tfx import version ; print('TFX version: {}'.format(version.__version__))\"\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sBLyQWYF42w6"
      },
      "outputs": [],
      "source": [
        "!python3 -c \"from tfx import version ; print('TFX version: {}'.format(version.__version__))\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycspntQk42xF"
      },
      "source": [
        "E está feito. Estamos prontos para criar um pipeline."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BoSOcmEB42xF"
      },
      "source": [
        "## Etapa 2. Copie o template predefinido para o diretório do seu projeto.\n",
        "\n",
        "Nesta etapa, criaremos um diretório e arquivos de projeto de pipeline funcionais, copiando arquivos adicionais de um template predefinido.\n",
        "\n",
        "Você pode dar um nome diferente ao seu pipeline alterando `PIPELINE_NAME` abaixo. Este também se tornará o nome do diretório do projeto onde seus arquivos serão colocados.\n",
        "\n",
        "```bash\n",
        "export PIPELINE_NAME=\"my_pipeline\"\n",
        "export PROJECT_DIR=~/tfx/${PIPELINE_NAME}\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IYGyT4ib42xG"
      },
      "outputs": [],
      "source": [
        "PIPELINE_NAME=\"my_pipeline\"\n",
        "import os\n",
        "# Create a project directory under Colab content directory.\n",
        "PROJECT_DIR=os.path.join(os.sep,\"content\",PIPELINE_NAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GjXe_3oY42xI"
      },
      "source": [
        "O TFX inclui o template `taxi` com o pacote TFX python. Se você está planejando resolver um problema de previsão pontual, incluindo classificação e regressão, este template pode ser usado como ponto de partida.\n",
        "\n",
        "O comando CLI `tfx template copy` copia arquivos de template predefinidos no diretório do projeto.\n",
        "\n",
        "```sh\n",
        "tfx template copy \\\n",
        "   --pipeline_name=\"${PIPELINE_NAME}\" \\\n",
        "   --destination_path=\"${PROJECT_DIR}\" \\\n",
        "   --model=taxi\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3PmXatBD42xI"
      },
      "outputs": [],
      "source": [
        "!tfx template copy \\\n",
        "  --pipeline_name={PIPELINE_NAME} \\\n",
        "  --destination_path={PROJECT_DIR} \\\n",
        "  --model=taxi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fyhkhhxY42xK"
      },
      "source": [
        "Altere o contexto do diretório de trabalho neste notebook para o diretório do projeto.\n",
        "\n",
        "```bash\n",
        "cd ${PROJECT_DIR}\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y9e_g5rc42xL"
      },
      "outputs": [],
      "source": [
        "%cd {PROJECT_DIR}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rKBRbE342xN"
      },
      "source": [
        "## Etapa 3. Navegue pelos arquivos-fonte copiados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdiHik_w42xN"
      },
      "source": [
        "O template TFX fornece arquivos de scaffold básicos para construir um pipeline, incluindo código-fonte Python, dados de amostra e Jupyter Notebooks para analisar a saída do pipeline. O template `taxi` usa o mesmo dataset do *Chicago Taxi* e modelo de ML do [Tutorial Airflow](https://www.tensorflow.org/tfx/tutorials/tfx/airflow_workshop).\n",
        "\n",
        "No Google Colab, você pode navegar pelos arquivos clicando no ícone de uma pasta à esquerda. Os arquivos devem ser copiados no diretório do projeto, cujo nome é `my_pipeline` neste caso. Você pode clicar nos nomes dos diretórios para ver o conteúdo do diretório e clicar duas vezes nos nomes dos arquivos para abri-los.\n",
        "\n",
        "Aqui está uma breve introdução a cada um dos arquivos Python.\n",
        "\n",
        "- `pipeline` - Este diretório contém a definição do pipeline\n",
        "    - `configs.py` — define constantes comuns para executores de pipeline\n",
        "    - `pipeline.py` — define componentes TFX e um pipeline\n",
        "- `models` - Este diretório contém definições de modelo de ML.\n",
        "    - `features.py`, `features_test.py` — define características para o modelo\n",
        "    - `preprocessing.py`, `preprocessing_test.py` — define jobs de pré-processamento usando `tf::Transform`\n",
        "    - `estimator` — este diretório contém um modelo baseado em Estimator.\n",
        "        - `constants.py` — define constantes do modelo\n",
        "        - `model.py`, `model_test.py` — define o modelo DNN usando o estimador TF\n",
        "    - `keras` — este diretório contém um modelo baseado em Keras.\n",
        "        - `constants.py` — define constantes do modelo\n",
        "        - `model.py`, `model_test.py` — define o modelo DNN usando Keras\n",
        "- `local_runner.py`, `kubeflow_runner.py` — define executores para cada mecanismo de orquestração\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmWtR_Eq42xQ"
      },
      "source": [
        "Você poderá perceber que existem alguns arquivos com `_test.py` em seus nomes. Estes são testes unitários do pipeline e é recomendado adicionar mais testes unitários à medida que você for implementando seus próprios pipelines. Você pode executar testes de unidade fornecendo o nome do módulo dos arquivos de teste com o sinalizador `-m`. Geralmente você pode obter um nome de módulo excluindo a extensão `.py` e substituindo `/` por `.`. Por exemplo:\n",
        "\n",
        "```bash\n",
        "python -m models.features_test\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H0DzGg-642xQ"
      },
      "outputs": [],
      "source": [
        "!{sys.executable} -m models.features_test\n",
        "!{sys.executable} -m models.keras.model_test\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fK_C6C6g42xS"
      },
      "source": [
        "## Etapa 4. Execute seu primeiro pipeline TFX\n",
        "\n",
        "Você pode criar um pipeline usando o comando `pipeline create`.\n",
        "\n",
        "```bash\n",
        "tfx pipeline create --engine=local --pipeline_path=local_runner.py\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D5YikNik42xX"
      },
      "outputs": [],
      "source": [
        "!tfx pipeline create --engine=local --pipeline_path=local_runner.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kvZIn8142xZ"
      },
      "source": [
        "Em seguida, você pode executar o pipeline criado usando o comando `run create`.\n",
        "\n",
        "```sh\n",
        "tfx run create --engine=local --pipeline_name=\"${PIPELINE_NAME}\"\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SnTC_Rql42xZ"
      },
      "outputs": [],
      "source": [
        "!tfx run create --engine=local --pipeline_name={PIPELINE_NAME}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GM1G1Efw42xb"
      },
      "source": [
        "Se for bem-sucedido, você verá `Component CsvExampleGen is finished.` Ao copiar o template, apenas um componente, o CsvExampleGen, será incluído no pipeline."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pfQcePs42xc"
      },
      "source": [
        "## Etapa 5. Adicione componentes para validação de dados.\n",
        "\n",
        "Nesta etapa, você adicionará componentes para validação de dados, incluindo `StatisticsGen`, `SchemaGen` e `ExampleValidator`. Se você estiver interessado na validação de dados, consulte [Introdução ao Tensorflow Data Validation](https://www.tensorflow.org/tfx/data_validation/get_started).\n",
        "\n",
        "Modificaremos a definição do pipeline copiado em `pipeline/pipeline.py`. Se você estiver trabalhando em seu ambiente local, use seu editor favorito para editar o arquivo. Se você estiver trabalhando no Google Colab,\n",
        "\n",
        "> **Clique no ícone da pasta à esquerda para abrir a visualização `Files`**.\n",
        "\n",
        "> **Clique em `my_pipeline` para abrir o diretório, depois clique no diretório `pipeline` para abrir e dê um duplo-clique em `pipeline.py` para abrir o arquivo**.\n",
        "\n",
        "> Encontre e descomente as 3 linhas que adicionam `StatisticsGen`, `SchemaGen` e `ExampleValidator` ao pipeline. (Dica: encontre comentários contendo `TODO(step 5):`).\n",
        "\n",
        "> Sua alteração será salva automaticamente em alguns segundos. Certifique-se de que a marca `*` na frente de `pipeline.py` tenha desaparecido no título da aba. **Não há botão para salvar ou atalho para o editor de arquivos no Colab. Os arquivos Python no editor de arquivos podem ser salvos no ambiente de execução, mesmo no modo `playground`.**\n",
        "\n",
        "Agora você precisa atualizar o pipeline existente com a definição de pipeline modificada. Use o comando `tfx pipeline update` para atualizar seu pipeline, seguido pelo comando `tfx run create` para criar uma nova execução de seu pipeline atualizado.\n",
        "\n",
        "```sh\n",
        "# Update the pipeline\n",
        "tfx pipeline update --engine=local --pipeline_path=local_runner.py\n",
        "# You can run the pipeline the same way.\n",
        "tfx run create --engine local --pipeline_name \"${PIPELINE_NAME}\"\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wMsT-5EX42xc"
      },
      "outputs": [],
      "source": [
        "# Update the pipeline\n",
        "!tfx pipeline update --engine=local --pipeline_path=local_runner.py\n",
        "# You can run the pipeline the same way.\n",
        "!tfx run create --engine local --pipeline_name {PIPELINE_NAME}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUU5_3yR42xe"
      },
      "source": [
        "Você deverá conseguir ver o log de saída dos componentes adicionados. Nosso pipeline cria artefatos de saída no diretório `tfx_pipeline_output/my_pipeline`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7p7CLDvD42xe"
      },
      "source": [
        "## Etapa 6. Adicione componentes para treinamento.\n",
        "\n",
        "Nesta etapa, você adicionará componentes para treinamento e validação de modelo, incluindo `Transform`, `Trainer`, `Resolver`, `Evaluator` e `Pusher`.\n",
        "\n",
        "> **Abra `pipeline/pipeline.py`**. Encontre e descomente 5 linhas que adicionam `Transform`, `Trainer`, `Resolver`, `Evaluator` e `Pusher` ao pipeline. (Dica: encontre `TODO(step 6):`)\n",
        "\n",
        "Como fez antes, agora você precisa atualizar o pipeline existente com a definição de pipeline modificada. As instruções são as mesmas da Etapa 5. Atualize o pipeline usando `tfx pipeline update` e crie uma execução usando `tfx run create`.\n",
        "\n",
        "```sh\n",
        "tfx pipeline update --engine=local --pipeline_path=local_runner.py\n",
        "tfx run create --engine local --pipeline_name \"${PIPELINE_NAME}\"\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ik8JbnRq42xf"
      },
      "outputs": [],
      "source": [
        "!tfx pipeline update --engine=local --pipeline_path=local_runner.py\n",
        "!tfx run create --engine local --pipeline_name {PIPELINE_NAME}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3L3NEPanUGY"
      },
      "source": [
        "Quando esta execução for concluída com sucesso, você terá criado e executado seu primeiro pipeline TFX usando o orquestrador local!\n",
        "\n",
        "**OBSERVAÇÃO:** Você deve ter percebido que toda vez que criamos uma execução de pipeline, cada componente é executado repetidamente, mesmo que a entrada e os parâmetros não tenham sido alterados. É uma perda de tempo e recursos, e você pode pular essas execuções com o cache do pipeline. Você pode ativar o cache especificando `enable_cache=True` para o objeto `Pipeline` em `pipeline.py`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjcMwjov42xh"
      },
      "source": [
        "## Etapa 7. (*Opcional*) Experimente BigQueryExampleGen.\n",
        "\n",
        "[BigQuery] é um data warehouse em nuvem sem servidor, altamente escalonável e econômico. O BigQuery pode ser usado como fonte para exemplos de treinamento no TFX. Nesta etapa, adicionaremos `BigQueryExampleGen` ao pipeline.\n",
        "\n",
        "Você precisa de uma conta [do Google Cloud Platform](https://cloud.google.com/gcp/getting-started) para usar o BigQuery. Prepare um projeto GCP.\n",
        "\n",
        "Faça login no seu projeto usando a biblioteca de autenticação colab ou o utilitário `gcloud`.\n",
        "\n",
        "```sh\n",
        "# You need `gcloud` tool to login in local shell environment.\n",
        "gcloud auth login\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2K7nuHZ4uNXc"
      },
      "outputs": [],
      "source": [
        "if 'google.colab' in sys.modules:\n",
        "  from google.colab import auth\n",
        "  auth.authenticate_user()\n",
        "  print('Authenticated')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Win212lr03zP"
      },
      "source": [
        "Você deve especificar o nome do seu projeto GCP para acessar os recursos do BigQuery usando o TFX. Defina a variável de ambiente `GOOGLE_CLOUD_PROJECT` como o nome do seu projeto.\n",
        "\n",
        "```sh\n",
        "export GOOGLE_CLOUD_PROJECT=YOUR_PROJECT_NAME_HERE\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vvpw_lGByxSx"
      },
      "outputs": [],
      "source": [
        "# Set your project name below.\n",
        "# WARNING! ENTER your project name before running this cell.\n",
        "%env GOOGLE_CLOUD_PROJECT=YOUR_PROJECT_NAME_HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhClPWEuuOaP"
      },
      "source": [
        "> **Abra `pipeline/pipeline.py`**. Comente `CsvExampleGen` e remova o comentário da linha que cria uma instância de `BigQueryExampleGen`. Você também precisa descomentar o argumento `query` da função `create_pipeline`.\n",
        "\n",
        "Precisamos especificar qual projeto GCP usar para o BigQuery novamente, e isso é feito definindo `--project` em `beam_pipeline_args` ao criar um pipeline.\n",
        "\n",
        "> **Abra `pipeline/configs.py`**. Remova o comentário da definição de `BIG_QUERY__WITH_DIRECT_RUNNER_BEAM_PIPELINE_ARGS` e `BIG_QUERY_QUERY`. Você deve substituir o ID do projeto e o valor da região neste arquivo pelos valores corretos para o seu projeto do GCP.\n",
        "\n",
        "> **Abra `local_runner.py`**. Remova o comentário de dois argumentos, `query` e `beam_pipeline_args`, para o método create_pipeline().\n",
        "\n",
        "Agora o pipeline está pronto para usar o BigQuery como fonte de exemplos. Atualize o pipeline e crie uma execução como fizemos nas etapas 5 e 6."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w8rOdC3r42xi"
      },
      "outputs": [],
      "source": [
        "!tfx pipeline update --engine=local --pipeline_path=local_runner.py\n",
        "!tfx run create --engine local --pipeline_name {PIPELINE_NAME}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxYxNHLN42xo"
      },
      "source": [
        "## O que vem depois: fornecer SEUS próprios dados ao pipeline.\n",
        "\n",
        "Fizemos um pipeline para um modelo usando o dataset Chicago Taxi. Agora é hora de colocar seus dados no pipeline.\n",
        "\n",
        "Seus dados podem ser armazenados em qualquer lugar que seu pipeline possa acessar, incluindo GCS ou BigQuery. Você precisará modificar a definição do pipeline para acessar seus dados.\n",
        "\n",
        "1. Se seus dados estiverem armazenados em arquivos, modifique `DATA_PATH` em `kubeflow_runner.py` ou `local_runner.py` e defina-o como o local de seus arquivos. Se seus dados estiverem armazenados no BigQuery, modifique `BIG_QUERY_QUERY` em `pipeline/configs.py` para consultar seus dados corretamente.\n",
        "2. Adicione características em `models/features.py`.\n",
        "3. Modifique `models/preprocessing.py` para [transformar os dados de entrada para treinamento](https://www.tensorflow.org/tfx/guide/transform).\n",
        "4. Modifique `models/keras/model.py` e `models/keras/constants.py` para [descrever seu modelo de ML](https://www.tensorflow.org/tfx/guide/trainer).\n",
        "    - Você também pode usar um modelo baseado em estimador. Altere a constante `RUN_FN` para `models.estimator.model.run_fn` em `pipeline/configs.py`.\n",
        "\n",
        "Consulte o [Guia do componente Trainer](https://www.tensorflow.org/tfx/guide/trainer) para mais informações."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "template_beam.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
