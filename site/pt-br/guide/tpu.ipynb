{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tce3stUlHN0L"
      },
      "source": [
        "##### Copyright 2018 The TensorFlow Authors.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tuOe1ymfHZPu"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfBg1C5NB3X0"
      },
      "source": [
        "# Use TPUs\n",
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>     <a target=\"_blank\" href=\"https://www.tensorflow.org/guide/tpu\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Veja em TensorFlow.org</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/pt-br/guide/tpu.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Executar no Google Colab</a>   </td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/pt-br/guide/tpu.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver fonte em GitHub</a>   </td>\n",
        "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/pt-br/guide/tpu.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Baixar notebook</a> </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ys81cOhXOWUP"
      },
      "source": [
        "Este guia demonstra como realizar treinamento básico em [Unidades de Processamento de Tensores (TPUs)](https://cloud.google.com/tpu/) e TPU Pods, uma coleção de dispositivos de TPU conectados por interfaces de rede de alta velocidade dedicadas, com `tf.keras` e loops de treinamento personalizados.\n",
        "\n",
        "TPUs são circuitos integrados de aplicação específica (ASICs) desenvolvidos sob medida pelo Google e usados para acelerar as cargas de trabalho de aprendizado de máquina. Eles estão disponíveis no [Google Colab](https://colab.research.google.com/), [TPU Research Cloud](https://sites.research.google/trc/) e [Cloud TPU](https://cloud.google.com/tpu)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ek5Hop74NVKm"
      },
      "source": [
        "## Configuração"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebf7f8489bb7"
      },
      "source": [
        "Antes de executar este notebook do Colab, confira se o acelerador de hardware é um TPU ao verificar as configurações do seu notebook: **Runtime** &gt; **Change runtime type** &gt; **Hardware accelerator** &gt; **TPU**.\n",
        "\n",
        "Importe algumas bibliotecas necessárias, incluindo o TensorFlow Datasets:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cw0WRaChRxTL"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import os\n",
        "import tensorflow_datasets as tfds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDWaRxSpwBN1"
      },
      "source": [
        "## Inicialização da TPU\n",
        "\n",
        "TPUs são tipicamente workers [da Cloud TPU](https://cloud.google.com/tpu/docs/), que são diferentes do processo local que executa o programa Python do usuário. Portanto, você precisa fazer algum trabalho de inicialização para conectar-se ao cluster remoto e inicializar as TPUs. Observe que o argumento `tpu` recebido por `tf.distribute.cluster_resolver.TPUClusterResolver` é um endereço especial apenas para o Colab. Se você estiver executando seu código no Google Compute Engine (GCE), deverá passar o nome do Cloud TPU."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCqWMqvtwOLs"
      },
      "source": [
        "Observação: O código de inicialização da TPU deve estar no início do seu programa."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dKPqF8d1wJCV"
      },
      "outputs": [],
      "source": [
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "# This is the TPU initialization code that has to be at the beginning.\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "print(\"All devices: \", tf.config.list_logical_devices('TPU'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mv7kehTZ1Lq_"
      },
      "source": [
        "## Posicionamento manual dos dispositivos\n",
        "\n",
        "Depois que a TPU for inicializada, você poderá usar o posicionamento manual do dispositivo para colocar a computação num único dispositivo de TPU:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XRZ4kMoxBNND"
      },
      "outputs": [],
      "source": [
        "a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
        "b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
        "\n",
        "with tf.device('/TPU:0'):\n",
        "  c = tf.matmul(a, b)\n",
        "\n",
        "print(\"c device: \", c.device)\n",
        "print(c)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_NJm-kgFO0cC"
      },
      "source": [
        "## Estratégias de distribuição\n",
        "\n",
        "Geralmente você executará seu modelo em múltiplas TPUs de maneira paralela aos dados. Para distribuir seu modelo em múltiplas TPUs (assim como em múltiplas GPUs ou em múltiplas máquinas), o TensorFlow oferece a API `tf.distribute.Strategy`. Você pode substituir sua estratégia de distribuição e o modelo será executado em qualquer dispositivo (TPU). Saiba mais no guia [Treinamento distribuído com TensorFlow](./distributed_training.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcDPMZs-9uLJ"
      },
      "source": [
        "O uso da opção `tf.distribute.TPUStrategy` implementa treinamento distribuído síncrono. As TPUs fornecem sua própria implementação de operações all-reduce eficientes e outras operações coletivas em múltiplos cores de TPU, que são usados ​​na `TPUStrategy`.\n",
        "\n",
        "Para demonstrar isso, crie um objeto `tf.distribute.TPUStrategy`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7SO23K8oRpjI"
      },
      "outputs": [],
      "source": [
        "strategy = tf.distribute.TPUStrategy(resolver)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlaAmswWPsU6"
      },
      "source": [
        "Para replicar uma computação para que ela possa ser executada em todos os cores da TPU, você pode passá-la para a API `Strategy.run`. Abaixo está um exemplo que mostra todos os cores recebendo as mesmas entradas `(a, b)` e realizando multiplicação matricial em cada core de forma independente. As saídas serão os valores obtidos de todas as réplicas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-90CL5uFPTOa"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def matmul_fn(x, y):\n",
        "  z = tf.matmul(x, y)\n",
        "  return z\n",
        "\n",
        "z = strategy.run(matmul_fn, args=(a, b))\n",
        "print(z)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxgYl6kGHJLc"
      },
      "source": [
        "## Classificação em TPUs\n",
        "\n",
        "Tendo coberto os conceitos básicos, considere um exemplo mais concreto. Esta seção demonstra como usar a estratégia de distribuição (`tf.distribute.TPUStrategy`) para treinar um modelo Keras numa Cloud TPU."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKRALGgt_kCo"
      },
      "source": [
        "### Defina um modelo Keras\n",
        "\n",
        "Comece com uma definição de um [modelo `Sequential` Keras](https://www.tensorflow.org/guide/keras/sequential_model) para classificação de imagens no dataset MNIST. Não é diferente do que você usaria se estivesse treinando em CPUs ou GPUs. Observe que a criação do modelo Keras precisa estar dentro do `Strategy.scope`, para que as variáveis ​​possam ser criadas em cada dispositivo TPU. Outras partes do código não são necessárias para estarem dentro do escopo de `Strategy`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DiBiN-Z_R7P7"
      },
      "outputs": [],
      "source": [
        "def create_model():\n",
        "  regularizer = tf.keras.regularizers.L2(1e-5)\n",
        "  return tf.keras.Sequential(\n",
        "      [tf.keras.layers.Conv2D(256, 3, input_shape=(28, 28, 1),\n",
        "                              activation='relu',\n",
        "                              kernel_regularizer=regularizer),\n",
        "       tf.keras.layers.Conv2D(256, 3,\n",
        "                              activation='relu',\n",
        "                              kernel_regularizer=regularizer),\n",
        "       tf.keras.layers.Flatten(),\n",
        "       tf.keras.layers.Dense(256,\n",
        "                             activation='relu',\n",
        "                             kernel_regularizer=regularizer),\n",
        "       tf.keras.layers.Dense(128,\n",
        "                             activation='relu',\n",
        "                             kernel_regularizer=regularizer),\n",
        "       tf.keras.layers.Dense(10,\n",
        "                             kernel_regularizer=regularizer)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-2qaXgfyONQ"
      },
      "source": [
        "Este modelo coloca os termos de regularização L2 nos pesos de cada camada, para que o loop de treinamento personalizado abaixo possa mostrar como obtê-los de `Model.losses`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYOYjYTg_31l"
      },
      "source": [
        "### Carregue o dataset\n",
        "\n",
        "O uso eficiente da API `tf.data.Dataset` é fundamental ao usar uma Cloud TPU. Você pode saber mais sobre o desempenho do dataset no [Guia de desempenho do pipeline de entrada](./data_performance.ipynb).\n",
        "\n",
        "Se você estiver usando [TPU Nodes](https://cloud.google.com/tpu/docs/managing-tpus-tpu-vm), precisará armazenar todos os arquivos de dados lidos pelo `Dataset` do TensorFlow nos [buckets do Google Cloud Storage (GCS)](https://cloud.google.com/tpu/docs/storage-buckets). Se você estiver usando [TPU VMs](https://cloud.google.com/tpu/docs/users-guide-tpu-vm), poderá armazenar dados onde quiser. Para mais informações sobre TPU Nodes e TPU VMs, consulte a documentação da [Arquitetura do Sistema TPU](https://cloud.google.com/tpu/docs/system-architecture-tpu-vm).\n",
        "\n",
        "Para a maioria dos casos de uso, é recomendado converter seus dados para o formato `TFRecord` e usar `tf.data.TFRecordDataset` para lê-los. Verifique o [tutorial sobre TFRecord e tf.Example](../tutorials/load_data/tfrecord.ipynb) para detalhes sobre como fazer isso. Não é um requisito difícil e você pode usar outros leitores de dataset, como `tf.data.FixedLengthRecordDataset` ou `tf.data.TextLineDataset`.\n",
        "\n",
        "Você pode carregar pequenos datasets inteiros na memória usando `tf.data.Dataset.cache`.\n",
        "\n",
        "Independentemente do formato de dados utilizado, é altamente recomendável usar arquivos grandes, da ordem de 100 MB. Isto é especialmente importante neste ambiente de rede, pois o overhead na abertura de um arquivo é significativamente maior.\n",
        "\n",
        "Conforme mostrado no código abaixo, você deve usar o módulo `tfds.load` do Tensorflow Datasets para obter uma cópia dos dados de treinamento e teste do MNIST. Observe que `try_gcs` é especificado para usar uma cópia que está disponível num bucket público do GCS. Se você não especificar isso, a TPU não poderá acessar os dados baixados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "noAd416KSCo7"
      },
      "outputs": [],
      "source": [
        "def get_dataset(batch_size, is_training=True):\n",
        "  split = 'train' if is_training else 'test'\n",
        "  dataset, info = tfds.load(name='mnist', split=split, with_info=True,\n",
        "                            as_supervised=True, try_gcs=True)\n",
        "\n",
        "  # Normalize the input data.\n",
        "  def scale(image, label):\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    image /= 255.0\n",
        "    return image, label\n",
        "\n",
        "  dataset = dataset.map(scale)\n",
        "\n",
        "  # Only shuffle and repeat the dataset in training. The advantage of having an\n",
        "  # infinite dataset for training is to avoid the potential last partial batch\n",
        "  # in each epoch, so that you don't need to think about scaling the gradients\n",
        "  # based on the actual batch size.\n",
        "  if is_training:\n",
        "    dataset = dataset.shuffle(10000)\n",
        "    dataset = dataset.repeat()\n",
        "\n",
        "  dataset = dataset.batch(batch_size)\n",
        "\n",
        "  return dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgUC6A-zCMEr"
      },
      "source": [
        "### Treine o modelo usando APIs de alto nível do Keras\n",
        "\n",
        "Você pode treinar seu modelo com APIs Keras `Model.fit` e `Model.compile`. Não há nada específico de TPU nesta etapa – você escreve o código como se estivesse usando múltiplas GPUs e uma `MirroredStrategy` em vez de `TPUStrategy`. Você pode aprender mais no tutorial [Treinamento distribuído com Keras](../tutorials/distribute/keras.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ubmDchPqSIx0"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "  model = create_model()\n",
        "  model.compile(optimizer='adam',\n",
        "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                metrics=['sparse_categorical_accuracy'])\n",
        "\n",
        "batch_size = 200\n",
        "steps_per_epoch = 60000 // batch_size\n",
        "validation_steps = 10000 // batch_size\n",
        "\n",
        "train_dataset = get_dataset(batch_size, is_training=True)\n",
        "test_dataset = get_dataset(batch_size, is_training=False)\n",
        "\n",
        "model.fit(train_dataset,\n",
        "          epochs=5,\n",
        "          steps_per_epoch=steps_per_epoch,\n",
        "          validation_data=test_dataset,\n",
        "          validation_steps=validation_steps)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hSGBIYtUugJ"
      },
      "source": [
        "Para reduzir o overhead do Python e maximizar o desempenho da sua TPU, passe o argumento `steps_per_execution` para o Keras `Model.compile`. Neste exemplo, isto aumenta o rendimento em cerca de 50%:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M6e3aVVLUorL"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "  model = create_model()\n",
        "  model.compile(optimizer='adam',\n",
        "                # Anything between 2 and `steps_per_epoch` could help here.\n",
        "                steps_per_execution = 50,\n",
        "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                metrics=['sparse_categorical_accuracy'])\n",
        "\n",
        "model.fit(train_dataset,\n",
        "          epochs=5,\n",
        "          steps_per_epoch=steps_per_epoch,\n",
        "          validation_data=test_dataset,\n",
        "          validation_steps=validation_steps)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rRALBZNCO4A"
      },
      "source": [
        "### Treine o modelo usando um loop de treinamento personalizado\n",
        "\n",
        "Você também pode criar e treinar seu modelo usando as APIs `tf.function` e `tf.distribute` diretamente. Você pode usar a API `Strategy.experimental_distribute_datasets_from_function` para distribuir o `tf.data.Dataset` dada uma função de dataset. Observe que no exemplo abaixo o tamanho do lote passado para o `Dataset` é o tamanho do lote por réplica em vez do tamanho do lote global. Para saber mais, confira o tutorial [Treinamento personalizado com `tf.distribute.Strategy`](../tutorials/distribute/custom_training.ipynb).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxdgXPAL6iFE"
      },
      "source": [
        "Primeiro, crie o modelo, os datasets e as `tf.function`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9aHhqwao2Fxi"
      },
      "outputs": [],
      "source": [
        "# Create the model, optimizer and metrics inside the `tf.distribute.Strategy`\n",
        "# scope, so that the variables can be mirrored on each device.\n",
        "with strategy.scope():\n",
        "  model = create_model()\n",
        "  optimizer = tf.keras.optimizers.Adam()\n",
        "  training_loss = tf.keras.metrics.Mean('training_loss', dtype=tf.float32)\n",
        "  training_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
        "      'training_accuracy', dtype=tf.float32)\n",
        "\n",
        "# Calculate per replica batch size, and distribute the `tf.data.Dataset`s\n",
        "# on each TPU worker.\n",
        "per_replica_batch_size = batch_size // strategy.num_replicas_in_sync\n",
        "\n",
        "train_dataset = strategy.experimental_distribute_datasets_from_function(\n",
        "    lambda _: get_dataset(per_replica_batch_size, is_training=True))\n",
        "\n",
        "@tf.function\n",
        "def train_step(iterator):\n",
        "  \"\"\"The step function for one training step.\"\"\"\n",
        "\n",
        "  def step_fn(inputs):\n",
        "    \"\"\"The computation to run on each TPU device.\"\"\"\n",
        "    images, labels = inputs\n",
        "    with tf.GradientTape() as tape:\n",
        "      logits = model(images, training=True)\n",
        "      per_example_loss = tf.keras.losses.sparse_categorical_crossentropy(\n",
        "          labels, logits, from_logits=True)\n",
        "      loss = tf.nn.compute_average_loss(per_example_loss)\n",
        "      model_losses = model.losses\n",
        "      if model_losses:\n",
        "        loss += tf.nn.scale_regularization_loss(tf.add_n(model_losses))\n",
        "\n",
        "    grads = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(list(zip(grads, model.trainable_variables)))\n",
        "    training_loss.update_state(loss * strategy.num_replicas_in_sync)\n",
        "    training_accuracy.update_state(labels, logits)\n",
        "\n",
        "  strategy.run(step_fn, args=(next(iterator),))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ibi7Z97V6xsQ"
      },
      "source": [
        "Em seguida, execute o loop de treinamento:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1du5cXWt6Vtw"
      },
      "outputs": [],
      "source": [
        "steps_per_eval = 10000 // batch_size\n",
        "\n",
        "train_iterator = iter(train_dataset)\n",
        "for epoch in range(5):\n",
        "  print('Epoch: {}/5'.format(epoch))\n",
        "\n",
        "  for step in range(steps_per_epoch):\n",
        "    train_step(train_iterator)\n",
        "  print('Current step: {}, training loss: {}, training accuracy: {}%'.format(\n",
        "      optimizer.iterations.numpy(),\n",
        "      round(float(training_loss.result()), 4),\n",
        "      round(float(training_accuracy.result()) * 100, 2)))\n",
        "  training_loss.reset_states()\n",
        "  training_accuracy.reset_states()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnZJUM3qIjKu"
      },
      "source": [
        "### Melhorando o desempenho com múltiplos passos dentro de `tf.function`\n",
        "\n",
        "Você pode melhorar o desempenho executando múltiplos passos numa `tf.function`. Isso é conseguido empacotando a chamada `Strategy.run` com um `tf.range` dentro de `tf.function`, e o AutoGraph irá convertê-la num `tf.while_loop` no worker TPU. Você pode aprender mais sobre `tf.function` no guia <a data-md-type=\"raw_html\" href=\"./function.ipynb\">Melhor desempenho com `tf.function`</a>.\n",
        "\n",
        "Apesar do desempenho aprimorado, há vantagens e desvantagens nesse método em comparação com a execução de um único passo dentro de um `tf.function`. Executar vários passos em uma `tf.function` é menos flexível – você não pode executar coisas de forma eager ou código Python arbitrário dentro dos passos.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2grYvXLzJYkP"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def train_multiple_steps(iterator, steps):\n",
        "  \"\"\"The step function for one training step.\"\"\"\n",
        "\n",
        "  def step_fn(inputs):\n",
        "    \"\"\"The computation to run on each TPU device.\"\"\"\n",
        "    images, labels = inputs\n",
        "    with tf.GradientTape() as tape:\n",
        "      logits = model(images, training=True)\n",
        "      per_example_loss = tf.keras.losses.sparse_categorical_crossentropy(\n",
        "          labels, logits, from_logits=True)\n",
        "      loss = tf.nn.compute_average_loss(per_example_loss)\n",
        "      model_losses = model.losses\n",
        "      if model_losses:\n",
        "        loss += tf.nn.scale_regularization_loss(tf.add_n(model_losses))\n",
        "    grads = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(list(zip(grads, model.trainable_variables)))\n",
        "    training_loss.update_state(loss * strategy.num_replicas_in_sync)\n",
        "    training_accuracy.update_state(labels, logits)\n",
        "\n",
        "  for _ in tf.range(steps):\n",
        "    strategy.run(step_fn, args=(next(iterator),))\n",
        "\n",
        "# Convert `steps_per_epoch` to `tf.Tensor` so the `tf.function` won't get\n",
        "# retraced if the value changes.\n",
        "train_multiple_steps(train_iterator, tf.convert_to_tensor(steps_per_epoch))\n",
        "\n",
        "print('Current step: {}, training loss: {}, training accuracy: {}%'.format(\n",
        "      optimizer.iterations.numpy(),\n",
        "      round(float(training_loss.result()), 4),\n",
        "      round(float(training_accuracy.result()) * 100, 2)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBKVhMvWjibf"
      },
      "source": [
        "## Próximos passos\n",
        "\n",
        "Para saber mais sobre as Cloud TPUs e como usá-las, consulte:\n",
        "\n",
        "- [Google Cloud TPU](https://cloud.google.com/tpu): a página principal da Google Cloud TPU.\n",
        "- [Documentação da Google Cloud TPU documentation](https://cloud.google.com/tpu/docs/): toda a documentação da Google Cloud TPU, que inclui:\n",
        "    - [Introdução à Cloud TPU](https://cloud.google.com/tpu/docs/intro-to-tpu): uma visão geral de como trabalhar com Cloud TPUs.\n",
        "    - [Guias de início rápido do Cloud TPU](https://cloud.google.com/tpu/docs/quick-starts): guias introdutórios de como trabalhar com VMs da Cloud TPU usando o TensorFlow e outros frameworks de machine learning.\n",
        "- [Notebooks Colab do Google Cloud TPU](https://cloud.google.com/tpu/docs/colabs): exemplos de treinamento completo.\n",
        "- [Guia de desempenho do Google Cloud TPU](https://cloud.google.com/tpu/docs/performance-guide): melhore ainda mais o desempenho do Cloud TPU ajustando os parâmetros de configuração do Cloud TPU para seu aplicativo\n",
        "- [Treinamento distribuído com TensorFlow](./distributed_training.ipynb): como usar estratégias de distribuição, incluindo `tf.distribute.TPUStrategy`, com exemplos que mostram as práticas recomendadas.\n",
        "- Embeddings de TPU: o TensorFlow inclui suporte especializado para treinamento de embeddings em TPUs por meio de `tf.tpu.experimental.embedding`. Além disso, o [TensorFlow Tecommenders](https://www.tensorflow.org/recommenders) possui `tfrs.layers.embedding.TPUEmbedding`. Os embeddings fornecem representações eficientes e densas, capturando similaridades e relacionamentos complexos entre características. O suporte a embeddings específicos para TPU do TensorFlow permite treinar embeddings maiores que a memória de um único dispositivo TPU e usar entradas esparsas e irregulares em TPUs.\n",
        "- [TPU Research Cloud (TRC)](https://sites.research.google/trc/about/): o TRC permite que pesquisadores solicitem acesso a um cluster de mais de 1.000 dispositivos Cloud TPU.\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [],
      "name": "tpu.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
