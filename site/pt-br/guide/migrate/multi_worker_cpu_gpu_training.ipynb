{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJcYs_ERTnnI"
      },
      "source": [
        "##### Copyright 2021 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "HMUDt0CiUJk9"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77z2OchJTk0l"
      },
      "source": [
        "# Como migrar o treinamento de múltiplos workers com CPUs/GPUs\n",
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>     <a target=\"_blank\" href=\"https://www.tensorflow.org/guide/migrate/multi_worker_cpu_gpu_training\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver em TensorFlow.org</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/pt-br/guide/migrate/multi_worker_cpu_gpu_training.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Executar no Google Colab</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/pt-br/guide/migrate/multi_worker_cpu_gpu_training.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver fonte no GitHub</a>\n",
        "</td>\n",
        "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/pt-br/guide/migrate/multi_worker_cpu_gpu_training.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Baixar notebook</a>\n",
        "</td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "meUTrR4I6m1C"
      },
      "source": [
        "Este guia demonstra como migrar seu workflow de treinamento distribuído de múltiplos workers do TensorFlow 1 para o TensorFlow 2.\n",
        "\n",
        "Para realizar treinamento multi-worker com CPUs/GPUs:\n",
        "\n",
        "- No TensorFlow 1, você geralmente usa as APIs `tf.estimator.train_and_evaluate` e `tf.estimator.Estimator`.\n",
        "- No TensorFlow 2, use as APIs Keras para escrever o modelo, a função de perda, o otimizador e as métricas. Em seguida, distribua o treinamento com a API Keras `Model.fit` ou com um loop de treinamento personalizado (com `tf.GradientTape`) entre múltiplos workers com `tf.distribute.experimental.ParameterServerStrategy` ou `tf.distribute.MultiWorkerMirroredStrategy`. Para mais detalhes, consulte os seguintes tutoriais:\n",
        "    - [Treinamento distribuído com TensorFlow](../../guide/distributed_training.ipynb)\n",
        "    - [Treinamento do servidor de parâmetros com Keras Model.fit / um loop de treinamento personalizado](../../tutorials/distribute/parameter_server_training.ipynb)\n",
        "    - [MultiWorkerMirroredStrategy com Keras Model.fit](../../tutorials/distribute/multi_worker_with_keras.ipynb)\n",
        "    - [MultiWorkerMirroredStrategy com um loop de treinamento personalizado](../../tutorials/distribute/multi_worker_with_ctl.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdZSoIXEbhg-"
      },
      "source": [
        "## Configuração"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28f46832b54d"
      },
      "source": [
        "Comece com alguns imports necessários e um dataset simples para fins de demonstração:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iE0vSfMXumKI"
      },
      "outputs": [],
      "source": [
        "# The notebook uses a dataset instance for `Model.fit` with\n",
        "# `ParameterServerStrategy`, which depends on symbols in TF 2.7.\n",
        "# Install a utility needed for this demonstration\n",
        "!pip install portpicker\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.compat.v1 as tf1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m7rnGxsXtDkV"
      },
      "outputs": [],
      "source": [
        "features = [[1., 1.5], [2., 2.5], [3., 3.5]]\n",
        "labels = [[0.3], [0.5], [0.7]]\n",
        "eval_features = [[4., 4.5], [5., 5.5], [6., 6.5]]\n",
        "eval_labels = [[0.8], [0.9], [1.]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2uaw9QaDM_X"
      },
      "source": [
        "Você vai precisar da variável de ambiente de configuração `'TF_CONFIG'` para treinar em múltiplas máquinas no TensorFlow. Use `'TF_CONFIG'` para especificar os endereços `'cluster'` e `'task'`. (Saiba mais no guia [Treinamento distribuído](../...guide/distributed_training.ipynb).)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4OUzwoQgXgkG"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "tf_config = {\n",
        "    'cluster': {\n",
        "        'chief': ['localhost:11111'],\n",
        "        'worker': ['localhost:12345', 'localhost:23456', 'localhost:21212'],\n",
        "        'ps': ['localhost:12121', 'localhost:13131'],\n",
        "    },\n",
        "    'task': {'type': 'chief', 'index': 0}\n",
        "}\n",
        "\n",
        "os.environ['TF_CONFIG'] = json.dumps(tf_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbeoSbbmDdc0"
      },
      "source": [
        "Observação: infelizmente, já que o treinamento multi-worker com APIs `tf.estimator` no TensorFlow 1 requer múltiplos clientes (o que seria bastante complicado de ser feito aqui neste notebook Colab), você vai tornar o notebook executável sem uma variável de ambiente `'TF_CONFIG'`, então ele volta para o treinamento local. (Saiba mais na seção <em data-md-type=\"emphasis\">Configurando a variável de ambiente `'TF_CONFIG'`</em> no guia [Treinamento distribuído com TensorFlow](../../guide/distributed_training.ipynb).)\n",
        "\n",
        "Use a instrução `del` para remover a variável (mas num treinamento multi-worker real no TensorFlow 1, você não precisa fazer isso):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AHuynAR5D8sU"
      },
      "outputs": [],
      "source": [
        "del os.environ['TF_CONFIG']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4uXff1BEssdE"
      },
      "source": [
        "## TensorFlow 1: treinamento distribuído multi-worker com APIs tf.estimator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpyINdiLEN3c"
      },
      "source": [
        "O trecho de código a seguir demonstra o fluxo de trabalho canônico do treinamento multi-worker no TF1: você usará um `tf.estimator.Estimator`, um `tf.estimator.TrainSpec`, um `tf.estimator.EvalSpec` e a API `tf.estimator.train_and_evaluate` para distribuir o treinamento:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lqe9obf7suIj"
      },
      "outputs": [],
      "source": [
        "def _input_fn():\n",
        "  return tf1.data.Dataset.from_tensor_slices((features, labels)).batch(1)\n",
        "\n",
        "def _eval_input_fn():\n",
        "  return tf1.data.Dataset.from_tensor_slices(\n",
        "      (eval_features, eval_labels)).batch(1)\n",
        "\n",
        "def _model_fn(features, labels, mode):\n",
        "  logits = tf1.layers.Dense(1)(features)\n",
        "  loss = tf1.losses.mean_squared_error(labels=labels, predictions=logits)\n",
        "  optimizer = tf1.train.AdagradOptimizer(0.05)\n",
        "  train_op = optimizer.minimize(loss, global_step=tf1.train.get_global_step())\n",
        "  return tf1.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)\n",
        "\n",
        "estimator = tf1.estimator.Estimator(model_fn=_model_fn)\n",
        "train_spec = tf1.estimator.TrainSpec(input_fn=_input_fn)\n",
        "eval_spec = tf1.estimator.EvalSpec(input_fn=_eval_input_fn)\n",
        "tf1.estimator.train_and_evaluate(estimator, train_spec, eval_spec)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEmzBjfnsxwT"
      },
      "source": [
        "## TensorFlow 2: treinamento multi-worker com estratégias de distribuição"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Syb66qsbEp1x"
      },
      "source": [
        "No TensorFlow 2, o treinamento distribuído por múltiplos workers com CPUs, GPUs e TPUs é feito via estratégias `tf.distribute.Strategy`.\n",
        "\n",
        "O exemplo a seguir demonstra como usar duas dessas estratégias: `tf.distribute.experimental.ParameterServerStrategy` e `tf.distribute.MultiWorkerMirroredStrategy`, ambas projetadas para o treinamento de CPU/GPU com múltiplos workers.\n",
        "\n",
        "O `ParameterServerStrategy` emprega um *coordenador* (`'chief'`), o deixa ele mais amigável com o ambiente deste notebook Colab. Você usará alguns utilitários aqui para configurar os elementos de suporte essenciais para uma experiência executável aqui: você criará um *cluster no mesmo processo*, onde threads são usados ​​para simular os servidores de parâmetro (`'ps'`) e workers (`'worker'`). Para mais informações sobre treinamento do servidor de parâmetros, consulte o tutorial [Treinamento do servidor de parâmetros com ParameterServerStrategy](../../tutorials/distribute/parameter_server_training.ipynb).\n",
        "\n",
        "Neste exemplo, primeiro defina a variável de ambiente `'TF_CONFIG'` com um `tf.distribute.cluster_resolver.TFConfigClusterResolver` para fornecer as informações do cluster. Se você estiver usando um sistema de gerenciamento de cluster para seu treinamento distribuído, verifique se ele já fornece `'TF_CONFIG'` para você; nesse caso, você não precisa definir explicitamente essa variável de ambiente. (Saiba mais na seção <em data-md-type=\"emphasis\">Configurando a variável de ambiente `'TF_CONFIG'`</em> no guia [Treinamento distribuído com TensorFlow](../../guide/distributed_training.ipynb).)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rp-gFY0H5rF-"
      },
      "outputs": [],
      "source": [
        "# Find ports that are available for the `'chief'` (the coordinator),\n",
        "# `'worker'`s, and `'ps'` (parameter servers).\n",
        "import portpicker\n",
        "\n",
        "chief_port = portpicker.pick_unused_port()\n",
        "worker_ports = [portpicker.pick_unused_port() for _ in range(3)]\n",
        "ps_ports = [portpicker.pick_unused_port() for _ in range(2)]\n",
        "\n",
        "# Dump the cluster information to `'TF_CONFIG'`.\n",
        "tf_config = {\n",
        "    'cluster': {\n",
        "        'chief': [\"localhost:%s\" % chief_port],\n",
        "        'worker': [\"localhost:%s\" % port for port in worker_ports],\n",
        "        'ps':  [\"localhost:%s\" % port for port in ps_ports],\n",
        "    },\n",
        "    'task': {'type': 'chief', 'index': 0}\n",
        "}\n",
        "os.environ['TF_CONFIG'] = json.dumps(tf_config)\n",
        "\n",
        "# Use a cluster resolver to bridge the information to the strategy created below.\n",
        "cluster_resolver = tf.distribute.cluster_resolver.TFConfigClusterResolver()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_8uVvJb6dqq"
      },
      "source": [
        "Em seguida, crie um `tf.distribute.Server` para cada worker e servidor de parâmetro um por um:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJopinmG6b2z"
      },
      "outputs": [],
      "source": [
        "# Workers need some inter_ops threads to work properly.\n",
        "# This is only needed for this notebook to demo. Real servers\n",
        "# should not need this.\n",
        "worker_config = tf.compat.v1.ConfigProto()\n",
        "worker_config.inter_op_parallelism_threads = 4\n",
        "\n",
        "for i in range(3):\n",
        "  tf.distribute.Server(\n",
        "      cluster_resolver.cluster_spec(),\n",
        "      job_name=\"worker\",\n",
        "      task_index=i,\n",
        "      config=worker_config)\n",
        "\n",
        "for i in range(2):\n",
        "  tf.distribute.Server(\n",
        "      cluster_resolver.cluster_spec(),\n",
        "      job_name=\"ps\",\n",
        "      task_index=i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IpfCcF0g6Ao8"
      },
      "source": [
        "Num treinamento distribuído real, em vez de iniciar todos os `tf.distribute.Server` no coordenador, você usará várias máquinas, e cada uma das designadas como `\"worker\"` e `\"ps\"` (servidores de parâmetro) irá executar um `tf.distribute.Server`. Consulte a seção *Clusters no mundo real* no tutorial [Treinamento do servidor de parâmetros](../../tutorials/distribute/parameter_server_training.ipynb) para mais detalhes.\n",
        "\n",
        "Com tudo pronto, crie o objeto `ParameterServerStrategy`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t45iQeBT7Us_"
      },
      "outputs": [],
      "source": [
        "strategy = tf.distribute.experimental.ParameterServerStrategy(cluster_resolver)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "diNsps1MGRS6"
      },
      "source": [
        "Depois de criar um objeto de estratégia, defina o modelo, o otimizador e outras variáveis ​​e chame o Keras `Model.compile` na API `Strategy.scope` para distribuir o treinamento. (Consulte os documentos da API `Strategy.scope` para obter mais informações.)\n",
        "\n",
        "Se você preferir personalizar seu treinamento, por exemplo, definindo os passos para frente e para trás, consulte a seção *Treinamento com um loop de treinamento personalizado* no Tutorial [Treinamento do servidor de parâmetros](../../tutorials/distribute/parameter_server_training.ipynb) para mais detalhes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "atVciNgPs0fw"
      },
      "outputs": [],
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices(\n",
        "      (features, labels)).shuffle(10).repeat().batch(64)\n",
        "\n",
        "eval_dataset = tf.data.Dataset.from_tensor_slices(\n",
        "      (eval_features, eval_labels)).repeat().batch(1)\n",
        "\n",
        "with strategy.scope():\n",
        "  model = tf.keras.models.Sequential([tf.keras.layers.Dense(1)])\n",
        "  optimizer = tf.keras.optimizers.legacy.Adagrad(learning_rate=0.05)\n",
        "  model.compile(optimizer, \"mse\")\n",
        "\n",
        "model.fit(dataset, epochs=5, steps_per_epoch=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "akZ0aaaS1vA9"
      },
      "outputs": [],
      "source": [
        "model.evaluate(eval_dataset, steps=10, return_dict=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXbS71XmMSoO"
      },
      "source": [
        "> **Particionadores (`tf.distribute.experimental.partitioners`)**\n",
        ">\n",
        "> A `ParameterServerStrategy` no TensorFlow 2 oferece suporte ao particionamento variável e oferece os mesmos particionadores do TensorFlow 1, com nomes menos confusos:\n",
        ">\n",
        "> - `tf.compat.v1.variable_axis_size_partitioner` -&gt; `tf.distribute.experimental.partitioners.MaxSizePartitioner`: um particionador que mantém os fragmentos abaixo de um tamanho máximo).\n",
        "> - `tf.compat.v1.min_max_variable_partitioner` -&gt; `tf.distribute.experimental.partitioners.MinSizePartitioner`: um particionador que aloca um tamanho mínimo por fragmento.\n",
        "> - `tf.compat.v1.fixed_size_partitioner` -&gt; `tf.distribute.experimental.partitioners.FixedShardsPartitioner`: um particionador que aloca um número fixo de fragmentos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ig0-uCUbGprd"
      },
      "source": [
        "Como alternativa, você pode usar um objeto `MultiWorkerMirroredStrategy`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xHXP8bOBGtXL"
      },
      "outputs": [],
      "source": [
        "# To clean up the `TF_CONFIG` used for `ParameterServerStrategy`.\n",
        "del os.environ['TF_CONFIG']\n",
        "strategy = tf.distribute.MultiWorkerMirroredStrategy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOsmqefTGwUf"
      },
      "source": [
        "Você pode substituir a estratégia usada acima por um objeto `MultiWorkerMirroredStrategy` para realizar o treinamento com esta estratégia.\n",
        "\n",
        "Assim como as APIs `tf.estimator`, como `MultiWorkerMirroredStrategy` é uma estratégia multicliente, não existe uma maneira fácil de executar treinamento distribuído neste notebook Colab. Portanto, substituir o código acima por essa estratégia acaba rodando as coisas localmente. Os tutoriais de treinamento multi-worker [com Keras Model.fit](../../tutorials/distribute/multi_worker_with_keras.ipynb) / [um loop de treinamento personalizado](../../tutorials/distribute/multi_worker_with_ctl.ipynb) demonstram como executar o treinamento multi-worker com a variável `'TF_CONFIG'` configurada, com dois workers num host local no Colab. Na prática, você criaria múltiplos workers em endereços/portas IP externos e usaria a variável `'TF_CONFIG'` para especificar a configuração do cluster para cada worker."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "917ef6135660"
      },
      "source": [
        "## Próximos passos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e76fd9d5c98c"
      },
      "source": [
        "Para saber mais sobre o treinamento multi-worker distribuído com `tf.distribute.experimental.ParameterServerStrategy` e `tf.distribute.MultiWorkerMirroredStrategy` no TensorFlow 2, considere os seguintes recursos:\n",
        "\n",
        "- Tutorial: [Treinamento do servidor de parâmetros com ParameterServerStrategy e Keras Model.fit / um loop de treinamento personalizado](../../tutorials/distribute/parameter_server_training.ipynb)\n",
        "- Tutorial: [Treinamento multi-worker com MultiWorkerMirroredStrategy e Keras Model.fit](../../tutorials/distribute/multi_worker_with_keras.ipynb)\n",
        "- Tutorial: [Treinamento multi-worker com MultiWorkerMirroredStrategy e um loop de treinamento personalizado](../../tutorials/distribute/multi_worker_with_ctl.ipynb)\n",
        "- Guia: [Treinamento distribuído com o TensorFlow](../../guide/distributed_training.ipynb)\n",
        "- Guia: [Otimize o desempenho da GPU do TensorFlow com o TensorFlow Profiler](../../guide/gpu_performance_analysis.ipynb)\n",
        "- Guia: [Use uma GPU](../../guide/gpu.ipynb) (na seção Usando múltiplas GPUs)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "multi_worker_cpu_gpu_training.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
