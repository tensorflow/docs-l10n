{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJcYs_ERTnnI"
      },
      "source": [
        "##### Copyright 2021 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "HMUDt0CiUJk9"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77z2OchJTk0l"
      },
      "source": [
        "# Como migrar de TPU embedding_columns para a camada TPUEmbedding\n",
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>     <a target=\"_blank\" href=\"https://www.tensorflow.org/guide/migrate/tpu_embedding\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver em TensorFlow.org</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/pt-br/guide/migrate/tpu_embedding.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Executar no Google Colab</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/pt-br/guide/migrate/tpu_embedding.ipynb\"> <img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\"> Ver fonte no GitHub</a>\n",
        "</td>\n",
        "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/pt-br/guide/migrate/tpu_embedding.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Baixar notebook</a>\n",
        "</td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "meUTrR4I6m1C"
      },
      "source": [
        "Este guia mostra como migrar o treinamento de embedding em [TPUs](../../guide/tpu.ipynb) da API `embedding_column` do TensorFlow 1 com `TPUEstimator`, para a API da camada `TPUEmbedding` do TensorFlow 2 com `TPUStrategy`.\n",
        "\n",
        "Embeddings são (grandes) matrizes. Eles são tabelas de associação que mapeiam de um espaço de características esparso para vetores densos. Embeddings fornecem representações eficientes e densas, capturando semelhanças complexas e relacionamentos entre características.\n",
        "\n",
        "O TensorFlow inclui suporte especializado para treinar embeddings em TPUs. Esse suporte a embeddings, específico para TPUs, permite que você treine embeddings que são maiores do que a memória de um único dispositivo TPU e use entradas esparsas e irregulares em TPUs.\n",
        "\n",
        "- No TensorFlow 1, `tf.compat.v1.estimator.tpu.TPUEstimator` é uma API de alto nível que encapsula treinamento, avaliação, previsão e exportação para servir com TPUs. Tem suporte especial para `tf.compat.v1.tpu.experimental.embedding_column`.\n",
        "- Para implementar no TensorFlow 2, use a camada `tfrs.layers.embedding.TPUEmbedding` do TensorFlow Recommenders. Para treinamento e avaliação, use uma estratégia de distribuição de TPUs — `tf.distribute.TPUStrategy` — que é compatível com as APIs Keras para, por exemplo, construção de modelos (`tf.keras.Model`), otimizadores (`tf.keras.optimizers.Optimizer`), e treinamento com `Model.fit` ou um loop de treinamento personalizado com `tf.function` e `tf.GradientTape`.\n",
        "\n",
        "Para informações adicionais, consulte a documentação da API da camada `tfrs.layers.embedding.TPUEmbedding`, bem como a documentação `tf.tpu.experimental.embedding.TableConfig` e `tf.tpu.experimental.embedding.FeatureConfig` para obter informações adicionais. Para obter uma visão geral de `tf.distribute.TPUStrategy`, confira o guia [Treinamento distribuído](../../guide/distributed_training.ipynb) e o guia [Usando TPUs](../../guide/tpu.ipynb). Se você estiver migrando de `TPUEstimator` para `TPUStrategy`, confira o [O guia de migração de TPUs](tpu_estimator.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdZSoIXEbhg-"
      },
      "source": [
        "## Configuração\n",
        "\n",
        "Comece instalando o [TensorFlow Recommenders](https://www.tensorflow.org/recommenders) e importando alguns pacotes necessários:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tYE3RnRN2jNu"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow-recommenders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iE0vSfMXumKI"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.compat.v1 as tf1\n",
        "\n",
        "# TPUEmbedding layer is not part of TensorFlow.\n",
        "import tensorflow_recommenders as tfrs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jsm9Rxx7s1OZ"
      },
      "source": [
        "E prepare um dataset simples para fins de demonstração:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m7rnGxsXtDkV"
      },
      "outputs": [],
      "source": [
        "features = [[1., 1.5]]\n",
        "embedding_features_indices = [[0, 0], [0, 1]]\n",
        "embedding_features_values = [0, 5]\n",
        "labels = [[0.3]]\n",
        "eval_features = [[4., 4.5]]\n",
        "eval_embedding_features_indices = [[0, 0], [0, 1]]\n",
        "eval_embedding_features_values = [4, 3]\n",
        "eval_labels = [[0.8]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4uXff1BEssdE"
      },
      "source": [
        "## TensorFlow 1: treine incorporações em TPUs com o TPUEstimator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pc-WSeYG2oje"
      },
      "source": [
        "No TensorFlow 1, você configura os embeddings de TPU usando a API `tf.compat.v1.tpu.experimental.embedding_column` e treina/avalia o modelo em TPUs com `tf.compat.v1.estimator.tpu.TPUEstimator`.\n",
        "\n",
        "As entradas são números inteiros que variam de zero ao tamanho do vocabulário para a tabela de embeddings da TPU. Comece codificando as entradas para um ID categórico com `tf.feature_column.categorical_column_with_identity`. Use `\"sparse_feature\"` para o parâmetro `key`, já que os recursos de entrada são de valor inteiro, enquanto `num_buckets` é o tamanho do vocabulário para a tabela de embeddings (`10`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sO_y-IRT3dcM"
      },
      "outputs": [],
      "source": [
        "embedding_id_column = (\n",
        "      tf1.feature_column.categorical_column_with_identity(\n",
        "          key=\"sparse_feature\", num_buckets=10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57e2dec8ed4a"
      },
      "source": [
        "Em seguida, converta as entradas categóricas esparsas numa representação densa com `tpu.experimental.embedding_column`, onde `dimension` é a largura da tabela de embedding. Ela armazenará um vetor de embedding para cada um dos `num_buckets`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6d61c855011f"
      },
      "outputs": [],
      "source": [
        "embedding_column = tf1.tpu.experimental.embedding_column(\n",
        "    embedding_id_column, dimension=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6061452ee5a"
      },
      "source": [
        "Agora, defina a configuração de incorporação específica para a TPU através de `tf.estimator.tpu.experimental.EmbeddingConfigSpec`. Você vai passá-la depois para `tf.estimator.tpu.TPUEstimator` como um parâmetro `embedding_config_spec`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6abbf967fc82"
      },
      "outputs": [],
      "source": [
        "embedding_config_spec = tf1.estimator.tpu.experimental.EmbeddingConfigSpec(\n",
        "    feature_columns=(embedding_column,),\n",
        "    optimization_parameters=(\n",
        "        tf1.tpu.experimental.AdagradParameters(0.05)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVWHEQj5a7rN"
      },
      "source": [
        "Em seguida, para usar um `TPUEstimator`, defina:\n",
        "\n",
        "- Uma função de entrada para os dados de treinamento\n",
        "- Uma função de entrada de avaliação para os dados de avaliação\n",
        "- Uma função de modelo para instruir o `TPUEstimator` como a operação de treinamento será definida com as características e rótulos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lqe9obf7suIj"
      },
      "outputs": [],
      "source": [
        "def _input_fn(params):\n",
        "  dataset = tf1.data.Dataset.from_tensor_slices((\n",
        "      {\"dense_feature\": features,\n",
        "       \"sparse_feature\": tf1.SparseTensor(\n",
        "           embedding_features_indices,\n",
        "           embedding_features_values, [1, 2])},\n",
        "           labels))\n",
        "  dataset = dataset.repeat()\n",
        "  return dataset.batch(params['batch_size'], drop_remainder=True)\n",
        "\n",
        "def _eval_input_fn(params):\n",
        "  dataset = tf1.data.Dataset.from_tensor_slices((\n",
        "      {\"dense_feature\": eval_features,\n",
        "       \"sparse_feature\": tf1.SparseTensor(\n",
        "           eval_embedding_features_indices,\n",
        "           eval_embedding_features_values, [1, 2])},\n",
        "           eval_labels))\n",
        "  dataset = dataset.repeat()\n",
        "  return dataset.batch(params['batch_size'], drop_remainder=True)\n",
        "\n",
        "def _model_fn(features, labels, mode, params):\n",
        "  embedding_features = tf1.keras.layers.DenseFeatures(embedding_column)(features)\n",
        "  concatenated_features = tf1.keras.layers.Concatenate(axis=1)(\n",
        "      [embedding_features, features[\"dense_feature\"]])\n",
        "  logits = tf1.layers.Dense(1)(concatenated_features)\n",
        "  loss = tf1.losses.mean_squared_error(labels=labels, predictions=logits)\n",
        "  optimizer = tf1.train.AdagradOptimizer(0.05)\n",
        "  optimizer = tf1.tpu.CrossShardOptimizer(optimizer)\n",
        "  train_op = optimizer.minimize(loss, global_step=tf1.train.get_global_step())\n",
        "  return tf1.estimator.tpu.TPUEstimatorSpec(mode, loss=loss, train_op=train_op)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYnP3Dszc-2R"
      },
      "source": [
        "Com essas funções definidas, crie um `tf.distribute.cluster_resolver.TPUClusterResolver` que forneça as informações do cluster e um objeto `tf.compat.v1.estimator.tpu.RunConfig`.\n",
        "\n",
        "Junto com a função de modelo que você definiu, agora você pode criar um `TPUEstimator`. Aqui, você simplificará o fluxo ignorando o salvamento de checkpoints. Em seguida, você especificará o tamanho do lote para treinamento e avaliação para o `TPUEstimator`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WAqyqawemlcl"
      },
      "outputs": [],
      "source": [
        "cluster_resolver = tf1.distribute.cluster_resolver.TPUClusterResolver(tpu='')\n",
        "print(\"All devices: \", tf1.config.list_logical_devices('TPU'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HsOpjW5plH9Q"
      },
      "outputs": [],
      "source": [
        "tpu_config = tf1.estimator.tpu.TPUConfig(\n",
        "    iterations_per_loop=10,\n",
        "    per_host_input_for_training=tf1.estimator.tpu.InputPipelineConfig\n",
        "          .PER_HOST_V2)\n",
        "config = tf1.estimator.tpu.RunConfig(\n",
        "    cluster=cluster_resolver,\n",
        "    save_checkpoints_steps=None,\n",
        "    tpu_config=tpu_config)\n",
        "estimator = tf1.estimator.tpu.TPUEstimator(\n",
        "    model_fn=_model_fn, config=config, train_batch_size=8, eval_batch_size=8,\n",
        "    embedding_config_spec=embedding_config_spec)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uxw7tWrcepaZ"
      },
      "source": [
        "Chame `TPUEstimator.train` para começar a treinar o modelo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZPKFOMAcyrP"
      },
      "outputs": [],
      "source": [
        "estimator.train(_input_fn, steps=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ev1vjIz9euIw"
      },
      "source": [
        "Em seguida, chame `TPUEstimator.evaluate` para avaliar o modelo usando os dados de avaliação:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bqiKRiwWc0cz"
      },
      "outputs": [],
      "source": [
        "estimator.evaluate(_eval_input_fn, steps=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEmzBjfnsxwT"
      },
      "source": [
        "## TensorFlow 2: treine incorporações em TPUs com o TPUStrategy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UesuXNbShrbi"
      },
      "source": [
        "No TensorFlow 2, para treinar os workers da TPU, use `tf.distribute.TPUStrategy` junto com as APIs Keras para a definição do modelo e do treinamento/avaliação. (Consulte o guia [Usando TPUs](https://render.githubusercontent.com/guide/tpu.ipynb) para mais exemplos de treinamento com Keras Model.fit e um loop de treinamento personalizado (com `tf.function` e `tf.GradientTape`).)\n",
        "\n",
        "Já que você precisa realizar alguma inicialização para se conectar ao cluster remoto e inicializar os workers da TPU, comece criando um `TPUClusterResolver` para fornecer as informações do cluster e conectar-se ao cluster. (Saiba mais na seção *Inicialização da TPU* do guia [Usando TPUs](../../guide/tpu.ipynb).)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_TgdPNgXoS63"
      },
      "outputs": [],
      "source": [
        "cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\n",
        "tf.config.experimental_connect_to_cluster(cluster_resolver)\n",
        "tf.tpu.experimental.initialize_tpu_system(cluster_resolver)\n",
        "print(\"All devices: \", tf.config.list_logical_devices('TPU'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94JBD0HxmdPI"
      },
      "source": [
        "Em seguida, prepare seus dados. Isto é semelhante a como você criou um dataset no exemplo do TensorFlow 1, exceto que a função do dataset agora é transmitida a um objeto `tf.distribute.InputContext` em vez de um dict `params`. Você pode usar esse objeto para determinar o tamanho do lote local (e para qual host esse pipeline se destina, para que você possa particionar seus dados adequadamente).\n",
        "\n",
        "- Ao usar a API `tfrs.layers.embedding.TPUEmbedding`, é importante incluir a opção `drop_remainder=True` ao agrupar o dataset com `Dataset.batch`, pois `TPUEmbedding` requer um tamanho de lote fixo.\n",
        "- Além disso, o mesmo tamanho de lote deve ser usado para avaliação e treinamento se estiverem ocorrendo no mesmo conjunto de dispositivos.\n",
        "- Por fim, você deve usar `tf.keras.utils.experimental.DatasetCreator` junto com a opção de entrada especial — `experimental_fetch_to_device=False` — em `tf.distribute.InputOptions` (que contém configurações específicas da estratégia). Isto é demonstrado a seguir:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9NTruOw6mcy9"
      },
      "outputs": [],
      "source": [
        "global_batch_size = 8\n",
        "\n",
        "def _input_dataset(context: tf.distribute.InputContext):\n",
        "  dataset = tf.data.Dataset.from_tensor_slices((\n",
        "      {\"dense_feature\": features,\n",
        "       \"sparse_feature\": tf.SparseTensor(\n",
        "           embedding_features_indices,\n",
        "           embedding_features_values, [1, 2])},\n",
        "           labels))\n",
        "  dataset = dataset.shuffle(10).repeat()\n",
        "  dataset = dataset.batch(\n",
        "      context.get_per_replica_batch_size(global_batch_size),\n",
        "      drop_remainder=True)\n",
        "  return dataset.prefetch(2)\n",
        "\n",
        "def _eval_dataset(context: tf.distribute.InputContext):\n",
        "  dataset = tf.data.Dataset.from_tensor_slices((\n",
        "      {\"dense_feature\": eval_features,\n",
        "       \"sparse_feature\": tf.SparseTensor(\n",
        "           eval_embedding_features_indices,\n",
        "           eval_embedding_features_values, [1, 2])},\n",
        "           eval_labels))\n",
        "  dataset = dataset.repeat()\n",
        "  dataset = dataset.batch(\n",
        "      context.get_per_replica_batch_size(global_batch_size),\n",
        "      drop_remainder=True)\n",
        "  return dataset.prefetch(2)\n",
        "\n",
        "input_options = tf.distribute.InputOptions(\n",
        "    experimental_fetch_to_device=False)\n",
        "\n",
        "input_dataset = tf.keras.utils.experimental.DatasetCreator(\n",
        "    _input_dataset, input_options=input_options)\n",
        "\n",
        "eval_dataset = tf.keras.utils.experimental.DatasetCreator(\n",
        "    _eval_dataset, input_options=input_options)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4EHXhN3CVmo"
      },
      "source": [
        "Em seguida, depois de preparar os dados, você criará um `TPUStrategy` e definirá um modelo, métricas e um otimizador no escopo dessa estratégia (`Strategy.scope`).\n",
        "\n",
        "Você deve escolher um número para `steps_per_execution` em `Model.compile`, pois ele especifica a quantidade de lotes a serem executados durante cada chamada `tf.function` e é crítico para o desempenho. Esse argumento é semelhante ao `iterations_per_loop` usado em `TPUEstimator`.\n",
        "\n",
        "As características e a configuração da tabela que foram especificadas no TensorFlow 1 através de `tf.tpu.experimental.embedding_column` (e `tf.tpu.experimental.shared_embedding_column`) podem ser especificados diretamente no TensorFlow 2 através de um par de objetos de configuração:\n",
        "\n",
        "- `tf.tpu.experimental.embedding.FeatureConfig`\n",
        "- `tf.tpu.experimental.embedding.TableConfig`\n",
        "\n",
        "(Consulte a documentação da API associada para mais detalhes.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "atVciNgPs0fw"
      },
      "outputs": [],
      "source": [
        "strategy = tf.distribute.TPUStrategy(cluster_resolver)\n",
        "with strategy.scope():\n",
        "  if hasattr(tf.keras.optimizers, \"legacy\"):\n",
        "    optimizer = tf.keras.optimizers.legacy.Adagrad(learning_rate=0.05)\n",
        "  else:\n",
        "    optimizer = tf.keras.optimizers.Adagrad(learning_rate=0.05)\n",
        "  dense_input = tf.keras.Input(shape=(2,), dtype=tf.float32, batch_size=global_batch_size)\n",
        "  sparse_input = tf.keras.Input(shape=(), dtype=tf.int32, batch_size=global_batch_size)\n",
        "  embedded_input = tfrs.layers.embedding.TPUEmbedding(\n",
        "      feature_config=tf.tpu.experimental.embedding.FeatureConfig(\n",
        "          table=tf.tpu.experimental.embedding.TableConfig(\n",
        "              vocabulary_size=10,\n",
        "              dim=5,\n",
        "              initializer=tf.initializers.TruncatedNormal(mean=0.0, stddev=1)),\n",
        "          name=\"sparse_input\"),\n",
        "      optimizer=optimizer)(sparse_input)\n",
        "  input = tf.keras.layers.Concatenate(axis=1)([dense_input, embedded_input])\n",
        "  result = tf.keras.layers.Dense(1)(input)\n",
        "  model = tf.keras.Model(inputs={\"dense_feature\": dense_input, \"sparse_feature\": sparse_input}, outputs=result)\n",
        "  model.compile(optimizer, \"mse\", steps_per_execution=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkM2VZyni98F"
      },
      "source": [
        "Com isso, você está pronto para treinar o modelo com o dataset de treinamento:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kip65sYBlKiu"
      },
      "outputs": [],
      "source": [
        "model.fit(input_dataset, epochs=5, steps_per_epoch=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0AEK8sNjLOj"
      },
      "source": [
        "Por fim, avalie o modelo usando o dataset de avaliação:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6tMRkyfKhqSL"
      },
      "outputs": [],
      "source": [
        "model.evaluate(eval_dataset, steps=1, return_dict=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a97b888c1911"
      },
      "source": [
        "## Próximos passos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHx_RUL8xcJ3"
      },
      "source": [
        "Saiba mais sobre como configurar embeddings específicos para TPUs na documentação da API:\n",
        "\n",
        "- `tfrs.layers.embedding.TPUEmbedding`: particularmente sobre configuração de características e tabelas, configuração do otimizador, criação de um modelo (usando a API [funcional](https://www.tensorflow.org/guide/keras/functional) Keras ou através de uma [subclasse](../..guide/keras/custom_layers_and_models.ipynb) de `tf.keras.Model`), treinamento/avaliação, e servndo modelos com `tf.saved_model`\n",
        "- `tf.tpu.experimental.embedding.TableConfig`\n",
        "- `tf.tpu.experimental.embedding.FeatureConfig`\n",
        "\n",
        "Para mais informações sobre `TPUStrategy` no TensorFlow 2, considere os seguintes recursos:\n",
        "\n",
        "- Guia: [Usando TPUs](../../guide/tpu.ipynb) (cobre treinamento com Keras `Model.fit` / um loop de treinamento personalizado com `tf.distribute.TPUStrategy`, bem como dicas sobre como melhorar o desempenho com `tf.function`)\n",
        "- Guia: [Treinamento distribuído com o TensorFlow](../../guide/distributed_training.ipynb)\n",
        "- [Como migrar de TPUEstimator para TPUStrategy](tpu_estimator.ipynb)\n",
        "\n",
        "Para saber mais sobre como personalizar seu treinamento, consulte:\n",
        "\n",
        "- Guia: [Personalize o que acontece em Model.fit](../..guide/keras/customizing_what_happens_in_fit.ipynb)\n",
        "- Guia: [Escrevendo um loop de treinamento do zero](https://www.tensorflow.org/guide/keras/writing_a_training_loop_from_scratch)\n",
        "\n",
        "As TPUs, os ASICs especializados do Google para aprendizado de máquina, estão disponíveis através do [Google Colab](https://colab.research.google.com/), [TPU Research Cloud](https://sites.research.google/trc/) e [Cloud TPU](https://cloud.google.com/tpu)."
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [],
      "name": "tpu_embedding.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
