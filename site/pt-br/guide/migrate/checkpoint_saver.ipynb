{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJcYs_ERTnnI"
      },
      "source": [
        "##### Copyright 2021 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "HMUDt0CiUJk9"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77z2OchJTk0l"
      },
      "source": [
        "# Como migrar salvamento de checkpoints\n",
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>     <a target=\"_blank\" href=\"https://www.tensorflow.org/guide/migrate/checkpoint_saver\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver em TensorFlow.org</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/guide/migrate/checkpoint_saver.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Executar no Google Colab</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/checkpoint_saver.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver fonte no GitHub</a>\n",
        "</td>\n",
        "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/guide/migrate/checkpoint_saver.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Baixar notebook</a>\n",
        "</td>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIo_p2FWFIRx"
      },
      "source": [
        "Salvar continuamente o \"melhor\" modelo ou pesos/parâmetros do modelo traz muitos benefícios. Isto inclui a capacidade de rastrear o progresso do treinamento e carregar modelos salvos de diferentes estados salvos.\n",
        "\n",
        "No TensorFlow 1, para configurar o salvamento de checkpoints durante o treinamento/validação com as APIs `tf.estimator.Estimator`, especifique um agendamento em `tf.estimator.RunConfig` ou use `tf.estimator.CheckpointSaverHook`. Este guia demonstra como migrar deste fluxo de trabalho para as APIs TensorFlow 2 Keras.\n",
        "\n",
        "No TensorFlow 2, você pode configurar `tf.keras.callbacks.ModelCheckpoint` de várias maneiras:\n",
        "\n",
        "- Salvar a \"melhor\" versão de acordo com uma métrica monitorada usando o parâmetro `save_best_only=True`, onde `monitor` pode ser, por exemplo, `'loss'`, `'val_loss'`, `'accuracy', or` 'val_accuracy'`.\n",
        "- Salvar continuamente numa certa frequência (usando o argumento `save_freq`).\n",
        "- Salve apenas os pesos/parâmetros em vez de todo o modelo definindo `save_weights_only` como `True`.\n",
        "\n",
        "Para mais detalhes, consulte os documentos da API `tf.keras.callbacks.ModelCheckpoint` e a seção *Salve checkpoints durante o treinamento* no tutorial [Como salvar e carregar modelos](../../tutorials/keras/save_and_load.ipynb). Saiba mais sobre o formato Checkpoint na seção *Formato Checkpoint do TF* no guia [Como salvar e carregar modelos Keras](https://www.tensorflow.org/guide/keras/save_and_serialize). Além disso, para incluir tolerância a falhas, você pode usar `tf.keras.callbacks.BackupAndRestore` ou `tf.train.Checkpoint` para aplicar checkpoints manualmente. Saiba mais no [Guia de migração de tolerância a falhas](fault_tolerance.ipynb).\n",
        "\n",
        "Os [callbacks](https://www.tensorflow.org/guide/keras/custom_callback) do Keras são objetos que são chamados em diferentes pontos durante o treinamento/avaliação/previsão nas APIs integradas Keras `Model.fit`/`Model.evaluate`/`Model.predict`. Saiba mais na seção *Próximas etapas* no final do guia."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f55c103999de"
      },
      "source": [
        "## Configuração\n",
        "\n",
        "Comece com os imports e um dataset simples para fins de demonstração:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X74yjOb-e18w"
      },
      "outputs": [],
      "source": [
        "import tensorflow.compat.v1 as tf1\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import tempfile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2r8r4d8FfMny"
      },
      "outputs": [],
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrqBkG4RFLP_"
      },
      "source": [
        "## TensorFlow 1: salve checkpoints com APIs tf.estimator\n",
        "\n",
        "Este exemplo do TensorFlow 1 mostra como configurar `tf.estimator.RunConfig` para salvar checkpoints em cada passo durante o treinamento/avaliação com as APIs `tf.estimator.Estimator`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "upA8nuf3FEq5"
      },
      "outputs": [],
      "source": [
        "feature_columns = [tf1.feature_column.numeric_column(\"x\", shape=[28, 28])]\n",
        "\n",
        "config = tf1.estimator.RunConfig(save_summary_steps=1,\n",
        "                                 save_checkpoints_steps=1)\n",
        "\n",
        "path = tempfile.mkdtemp()\n",
        "\n",
        "classifier = tf1.estimator.DNNClassifier(\n",
        "    feature_columns=feature_columns,\n",
        "    hidden_units=[256, 32],\n",
        "    optimizer=tf1.train.AdamOptimizer(0.001),\n",
        "    n_classes=10,\n",
        "    dropout=0.2,\n",
        "    model_dir=path,\n",
        "    config = config\n",
        ")\n",
        "\n",
        "train_input_fn = tf1.estimator.inputs.numpy_input_fn(\n",
        "    x={\"x\": x_train},\n",
        "    y=y_train.astype(np.int32),\n",
        "    num_epochs=10,\n",
        "    batch_size=50,\n",
        "    shuffle=True,\n",
        ")\n",
        "\n",
        "test_input_fn = tf1.estimator.inputs.numpy_input_fn(\n",
        "    x={\"x\": x_test},\n",
        "    y=y_test.astype(np.int32),\n",
        "    num_epochs=10,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "train_spec = tf1.estimator.TrainSpec(input_fn=train_input_fn, max_steps=10)\n",
        "eval_spec = tf1.estimator.EvalSpec(input_fn=test_input_fn,\n",
        "                                   steps=10,\n",
        "                                   throttle_secs=0)\n",
        "\n",
        "tf1.estimator.train_and_evaluate(estimator=classifier,\n",
        "                                train_spec=train_spec,\n",
        "                                eval_spec=eval_spec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3u96G4MtRVqU"
      },
      "outputs": [],
      "source": [
        "%ls {classifier.model_dir}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvE_uxDJFUX-"
      },
      "source": [
        "## TensorFlow 2: salve checkpoints com um callback Keras para Model.fit\n",
        "\n",
        "No TensorFlow 2, quando voce usa o Keras `Model.fit` integrado (ou `Model.evaluate`) para treinamento/avaliação, você pode configurar `tf.keras.callbacks.ModelCheckpoint` e passá-lo para o parâmetro `callbacks` de `Model.fit` (ou `Model.evaluate`). (Saiba mais na documentação da API e na seção *Usando callbacks* no guia [Treinamento e avaliação com métodos integrados](https://www.tensorflow.org/guide/keras/train_and_evaluate).)\n",
        "\n",
        "No exemplo abaixo, você usará um callback `tf.keras.callbacks.ModelCheckpoint` para armazenar checkpoints num diretório temporário:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9FLBhT2BFX2H"
      },
      "outputs": [],
      "source": [
        "def create_model():\n",
        "  return tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "  ])\n",
        "\n",
        "model = create_model()\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'],\n",
        "              steps_per_execution=10)\n",
        "\n",
        "log_dir = tempfile.mkdtemp()\n",
        "\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=log_dir)\n",
        "\n",
        "model.fit(x=x_train,\n",
        "          y=y_train,\n",
        "          epochs=10,\n",
        "          validation_data=(x_test, y_test),\n",
        "          callbacks=[model_checkpoint_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SROSmhyyLBA-"
      },
      "outputs": [],
      "source": [
        "%ls {model_checkpoint_callback.filepath}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQUS8nO9FZlH"
      },
      "source": [
        "## Próximos passos\n",
        "\n",
        "Saiba mais sobre o uso de checkpoints em:\n",
        "\n",
        "- Documentação da API: `tf.keras.callbacks.ModelCheckpoint`\n",
        "- Tutorial: [Como salvar e carregar modelos](../../tutorials/keras/save_and_load.ipynb) (na seção *Salve checkpoints durante o treinamento*)\n",
        "- Guia: [Salve e carregue modelos Keras](https://www.tensorflow.org/guide/keras/save_and_serialize) (na seção *Formato Checkpoint do TF*)\n",
        "\n",
        "Saiba mais sobre callbacks em:\n",
        "\n",
        "- Documentação da API: `tf.keras.callbacks.Callback`\n",
        "- Guia: [Escrevendo seus próprios callbacks](https://www.tensorflow.org/guide/keras/guide/keras/custom_callback)\n",
        "- Guia: [Treinamento e avaliação com os métodos integrados](https://www.tensorflow.org/guide/keras/train_and_evaluate) (a seção *Usando callbacks* )\n",
        "\n",
        "Você talvez também ache úteis os seguintes recursos relacionados à migração:\n",
        "\n",
        "- O [Guia de migração de tolerância a falhas](fault_tolerance.ipynb): `tf.keras.callbacks.BackupAndRestore` para `Model.fit` ou APIs `tf.train.Checkpoint` e `tf.train.CheckpointManager` para um loop de treinamento personalizado\n",
        "- O [Guia de migração de paradas antecipadas](early_stopping.ipynb) : `tf.keras.callbacks.EarlyStopping` é um callback integrado para paradas antecipadas (early stopping).\n",
        "- O [Guia de migração do TensorBoard](tensorboard.ipynb): o TensorBoard permite rastrear e exibir métricas\n",
        "- O [Guia de migração LoggingTensorHook e StopAtStepHook para callbacks Keras](logging_stop_hook.ipynb)\n",
        "- O [Guia SessionRunHook para callbacks Keras](sessionrunhook_callback.ipynb)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "checkpoint_saver.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
