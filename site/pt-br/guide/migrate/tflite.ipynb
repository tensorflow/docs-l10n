{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJcYs_ERTnnI"
      },
      "source": [
        "##### Copyright 2021 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "HMUDt0CiUJk9"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77z2OchJTk0l"
      },
      "source": [
        "# Migrando seu código TFLite para TF2\n",
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>     <a target=\"_blank\" href=\"https://www.tensorflow.org/guide/migrate/tflite\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver em TensorFlow.org</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/pt-br/guide/migrate/tflite.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Executar no Google Colab</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/pt-br/guide/migrate/tflite.ipynb\"> <img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\"> Ver fonte no GitHub</a>\n",
        "</td>\n",
        "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/pt-br/guide/migrate/tflite.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Baixar notebook</a>\n",
        "</td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "meUTrR4I6m1C"
      },
      "source": [
        "O [TensorFlow Lite](https://www.tensorflow.org/lite/guide) (TFLite) é um conjunto de ferramentas que ajuda os desenvolvedores a executar a inferência de aprendizado de máquina em um dispositivo (dispositivos móveis, embarcados e IoT). O [conversor TFLite](https://www.tensorflow.org/lite/convert) é uma dessas ferramentas que converte modelos TF existentes num formato de modelo TFLite otimizado que pode ser executado com eficiência no dispositivo.\n",
        "\n",
        "Neste documento, você aprenderá quais alterações precisa fazer no seu código de conversão de TF para TFLite, e verá alguns exemplos que fazem a mesma coisa.\n",
        "\n",
        "## Alterações no seu código de conversão de TF para TFLite\n",
        "\n",
        "- Se você estiver usando um formato de modelo TF1 legado (como um arquivo Keras, frozen GraphDef, checkpoints, tf.Session), atualize-o para TF1/TF2 SavedModel e use a API do conversor TF2 `tf.lite.TFLiteConverter.from_saved_model(...)` para convertê-lo num modelo TFLite (consulte a Tabela 1).\n",
        "\n",
        "- Atualize os sinalizadores da API do conversor (consulte a Tabela 2).\n",
        "\n",
        "- Remova as APIs legadas, como `tf.lite.constants`. (por exemplo: substitua `tf.lite.constants.INT8` por `tf.int8`)\n",
        "\n",
        "// Tabela 1 // Atualização da API TFLite Python Converter\n",
        "\n",
        "API TF1 | API TF2\n",
        "--- | ---\n",
        "`tf.lite.TFLiteConverter.from_saved_model('saved_model/',..)` | *suportado*\n",
        "`tf.lite.TFLiteConverter.from_keras_model_file('model.h5',..)` | *removido (atualize para o formato SavedModel)*\n",
        "`tf.lite.TFLiteConverter.from_frozen_graph('model.pb',..)` | *removido (atualize para o formato SavedModel)*\n",
        "`tf.lite.TFLiteConverter.from_session(sess,...)` | *removido (atualize para o formato SavedModel)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rf75rjeedigq"
      },
      "source": [
        "&lt;style&gt;   .table {margin-left: 0 !important;} &lt;/style&gt;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbVlZNizW1-Y"
      },
      "source": [
        "// Tabela 2 // Atualização de sinalizadores da API do TFLite Python Converter\n",
        "\n",
        "API TF1 | API TF2\n",
        "--- | ---\n",
        "`allow_custom_ops`<br>`optimizations`<br> `representative_dataset`<br>`target_spec` <br>`inference_input_type`<br>`inference_output_type`<br>`experimental_new_converter`<br> `experimental_new_quantizer` | *suportado* <br><br><br><br><br><br><br><br>\n",
        "`input_tensors`<br>`output_tensors`<br>`input_arrays_with_shape`<br>`output_arrays`<br>`experimental_debug_info_func` | *removido (argumentos da API do conversor não suportados)*<br><br><br><br><br>\n",
        "`change_concat_input_ranges`<br>`default_ranges_stats`<br>`get_input_arrays()`<br>`inference_type`<br>`quantized_input_stats`<br> `reorder_across_fake_quant` | *removido (workflows de quantização não suportados)*<br><br><br><br><br><br>\n",
        "`conversion_summary_dir`<br>`dump_graphviz_dir`<br>`dump_graphviz_video` | *removido (visualize os modelos usando [Netron](https://lutzroeder.github.io/netron/) ou [visualize.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/tools/visualize.py))*<br><br><br>\n",
        "`output_format`<br>`drop_control_dependency` | *removido (recursos não suportados no TF2)*<br><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdZSoIXEbhg-"
      },
      "source": [
        "## Exemplos\n",
        "\n",
        "Agora você percorrerá alguns exemplos para converter modelos TF1 legados para SavedModels do TF1/TF2 e, em seguida, convertê-los em modelos TF2 TFLite.\n",
        "\n",
        "### Configuração\n",
        "\n",
        "Comece com os imports necessários do TensorFlow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iE0vSfMXumKI"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.compat.v1 as tf1\n",
        "import numpy as np\n",
        "\n",
        "import logging\n",
        "logger = tf.get_logger()\n",
        "logger.setLevel(logging.ERROR)\n",
        "\n",
        "import shutil\n",
        "def remove_dir(path):\n",
        "  try:\n",
        "    shutil.rmtree(path)\n",
        "  except:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89VllCprnFto"
      },
      "source": [
        "Crie todos os formatos de modelo TF1 necessários."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bwq8EFiwjzjx"
      },
      "outputs": [],
      "source": [
        "# Create a TF1 SavedModel\n",
        "SAVED_MODEL_DIR = \"tf_saved_model/\"\n",
        "remove_dir(SAVED_MODEL_DIR)\n",
        "with tf1.Graph().as_default() as g:\n",
        "  with tf1.Session() as sess:\n",
        "    input = tf1.placeholder(tf.float32, shape=(3,), name='input')\n",
        "    output = input + 2\n",
        "    # print(\"result: \", sess.run(output, {input: [0., 2., 4.]}))\n",
        "    tf1.saved_model.simple_save(\n",
        "        sess, SAVED_MODEL_DIR,\n",
        "        inputs={'input': input}, \n",
        "        outputs={'output': output})\n",
        "print(\"TF1 SavedModel path: \", SAVED_MODEL_DIR)\n",
        "\n",
        "# Create a TF1 Keras model\n",
        "KERAS_MODEL_PATH = 'tf_keras_model.h5'\n",
        "model = tf1.keras.models.Sequential([\n",
        "    tf1.keras.layers.InputLayer(input_shape=(128, 128, 3,), name='input'),\n",
        "    tf1.keras.layers.Dense(units=16, input_shape=(128, 128, 3,), activation='relu'),\n",
        "    tf1.keras.layers.Dense(units=1, name='output')\n",
        "])\n",
        "model.save(KERAS_MODEL_PATH, save_format='h5')\n",
        "print(\"TF1 Keras Model path: \", KERAS_MODEL_PATH)\n",
        "\n",
        "# Create a TF1 frozen GraphDef model\n",
        "GRAPH_DEF_MODEL_PATH = tf.keras.utils.get_file(\n",
        "    'mobilenet_v1_0.25_128',\n",
        "    origin='https://storage.googleapis.com/download.tensorflow.org/models/mobilenet_v1_0.25_128_frozen.tgz',\n",
        "    untar=True,\n",
        ") + '/frozen_graph.pb'\n",
        "\n",
        "print(\"TF1 frozen GraphDef path: \", GRAPH_DEF_MODEL_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzMBpG5rdt-7"
      },
      "source": [
        "### 1. Converta um TF1 SavedModel para um modelo TFLite\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFWIlVridt_F"
      },
      "source": [
        "#### Antes: Convertendo com TF1\n",
        "\n",
        "Este é um código típico para conversão TFlite no estilo TF1.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dzXHHBQRdt_F"
      },
      "outputs": [],
      "source": [
        "converter = tf1.lite.TFLiteConverter.from_saved_model(\n",
        "    saved_model_dir=SAVED_MODEL_DIR,\n",
        "    input_arrays=['input'],\n",
        "    input_shapes={'input' : [3]}\n",
        ")\n",
        "converter.optimizations = {tf.lite.Optimize.DEFAULT}\n",
        "converter.change_concat_input_ranges = True\n",
        "tflite_model = converter.convert()\n",
        "# Ignore warning: \"Use '@tf.function' or '@defun' to decorate the function.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUptsxK_MUy2"
      },
      "source": [
        "#### Depois: Convertendo com TF2\n",
        "\n",
        "Converta diretamente o TF1 SavedModel para um modelo TFLite, com um conjunto menor de sinalizadores do conversor v2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0OyBjZ6Kdt_F"
      },
      "outputs": [],
      "source": [
        "# Convert TF1 SavedModel to a TFLite model.\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir=SAVED_MODEL_DIR)\n",
        "converter.optimizations = {tf.lite.Optimize.DEFAULT}\n",
        "tflite_model = converter.convert()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yiwu3sso__fH"
      },
      "source": [
        "### 2. Converta um arquivo de modelo TF1 Keras para um modelo TFLite"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WTPvPih__fR"
      },
      "source": [
        "#### Antes: Convertendo com TF1\n",
        "\n",
        "Este é um código típico para conversão TFlite no estilo TF1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9EXO0xYq__fR"
      },
      "outputs": [],
      "source": [
        "converter = tf1.lite.TFLiteConverter.from_keras_model_file(model_file=KERAS_MODEL_PATH)\n",
        "converter.optimizations = {tf.lite.Optimize.DEFAULT}\n",
        "converter.change_concat_input_ranges = True\n",
        "tflite_model = converter.convert()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9l6ppTtTZ5Bz"
      },
      "source": [
        "#### Depois: Convertendo com TF2\n",
        "\n",
        "Primeiro, converta o arquivo de modelo TF1 Keras para um TF2 SavedModel e, em seguida, converta-o para um modelo TFLite, com um conjunto menor de sinalizadores do conversor v2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IGB5ZMGl__fR"
      },
      "outputs": [],
      "source": [
        "# Convert TF1 Keras model file to TF2 SavedModel.\n",
        "model = tf.keras.models.load_model(KERAS_MODEL_PATH)\n",
        "model.save(filepath='saved_model_2/')\n",
        "\n",
        "# Convert TF2 SavedModel to a TFLite model.\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir='saved_model_2/')\n",
        "tflite_model = converter.convert()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5Zf6G4M-sZz"
      },
      "source": [
        "### 3. Converta um frozen GraphDef TF1 para um modelo TFLite\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzCJOV7AUlGZ"
      },
      "source": [
        "#### Antes: Convertendo com TF1\n",
        "\n",
        "Este é um código típico para conversão TFlite no estilo TF1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r7RvcdRv6lll"
      },
      "outputs": [],
      "source": [
        "converter = tf1.lite.TFLiteConverter.from_frozen_graph(\n",
        "    graph_def_file=GRAPH_DEF_MODEL_PATH,\n",
        "    input_arrays=['input'],\n",
        "    input_shapes={'input' : [1, 128, 128, 3]},\n",
        "    output_arrays=['MobilenetV1/Predictions/Softmax'],\n",
        ")\n",
        "converter.optimizations = {tf.lite.Optimize.DEFAULT}\n",
        "converter.change_concat_input_ranges = True\n",
        "tflite_model = converter.convert()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdIogJsKaMNH"
      },
      "source": [
        "#### Depois: Convertendo com TF2\n",
        "\n",
        "Primeiro, converta o frozen GraphDef TF1 para um SavedModel TF1 e, em seguida, converta-o para um modelo TFLite, com um conjunto menor de sinalizadores do conversor v2.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oigap0TZxjWG"
      },
      "outputs": [],
      "source": [
        "## Convert TF1 frozen Graph to TF1 SavedModel.\n",
        "\n",
        "# Load the graph as a v1.GraphDef\n",
        "import pathlib\n",
        "gdef = tf.compat.v1.GraphDef()\n",
        "gdef.ParseFromString(pathlib.Path(GRAPH_DEF_MODEL_PATH).read_bytes())\n",
        "\n",
        "# Convert the GraphDef to a tf.Graph\n",
        "with tf.Graph().as_default() as g:\n",
        "  tf.graph_util.import_graph_def(gdef, name=\"\")\n",
        "\n",
        "# Look up the input and output tensors.\n",
        "input_tensor = g.get_tensor_by_name('input:0') \n",
        "output_tensor = g.get_tensor_by_name('MobilenetV1/Predictions/Softmax:0')\n",
        "\n",
        "# Save the graph as a TF1 Savedmodel\n",
        "remove_dir('saved_model_3/')\n",
        "with tf.compat.v1.Session(graph=g) as s:\n",
        "  tf.compat.v1.saved_model.simple_save(\n",
        "      session=s,\n",
        "      export_dir='saved_model_3/',\n",
        "      inputs={'input':input_tensor},\n",
        "      outputs={'output':output_tensor})\n",
        "\n",
        "# Convert TF1 SavedModel to a TFLite model.\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir='saved_model_3/')\n",
        "converter.optimizations = {tf.lite.Optimize.DEFAULT}\n",
        "tflite_model = converter.convert()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFbsddkOw4Wl"
      },
      "source": [
        "# Mais recursos\n",
        "\n",
        "- Consulte o [Guia TFLite](https://www.tensorflow.org/lite/guide) para saber mais sobre os workflows e os recursos mais recentes.\n",
        "- Se você estiver usando código TF1 ou formatos de modelo TF1 legados (arquivos Keras `.h5`, frozen GraphDef `.pb`, etc.), atualize seu código e migre seus modelos para o [formato TF2 SavedModel](https://www.tensorflow.org/guide/saved_model).\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "tflite.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
