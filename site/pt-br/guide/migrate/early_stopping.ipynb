{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJcYs_ERTnnI"
      },
      "source": [
        "##### Copyright 2021 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "HMUDt0CiUJk9"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77z2OchJTk0l"
      },
      "source": [
        "# Como migrar paradas antecipadas (early stopping)\n",
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>     <a target=\"_blank\" href=\"https://www.tensorflow.org/guide/migrate/early_stopping\">     <img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">     Ver em TensorFlow.org</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/pt-br/guide/migrate/early_stopping.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Executar no Google Colab</a> </td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/pt-br/guide/migrate/early_stopping.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver fonte no GitHub</a> </td>\n",
        "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/pt-br/guide/migrate/early_stopping.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Baixar notebook</a> </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "meUTrR4I6m1C"
      },
      "source": [
        "Este notebook demonstra como configurar o treinamento de modelos com parada antecipada (early stopping), primeiro no TensorFlow 1 com `tf.estimator.Estimator` e um hook de parada antecipada e, em seguida, no TensorFlow 2 com APIs Keras ou um loop de treinamento personalizado. A parada antecipada é uma técnica de regularização que interrompe o treinamento se, por exemplo, a perda de validação atingir um determinado limite.\n",
        "\n",
        "No TensorFlow 2, há três maneiras de implementar a parada antecipada:\n",
        "\n",
        "- Use um callback integrado do Keras — `tf.keras.callbacks.EarlyStopping` — e passe-o para `Model.fit`.\n",
        "- Defina um callback personalizado e passe-o para Keras `Model.fit`.\n",
        "- Escreva uma regra de parada antecipada personalizada num [loop de treinamento personalizado](https://www.tensorflow.org/guide/keras/writing_a_training_loop_from_scratch) (com `tf.GradientTape`)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdZSoIXEbhg-"
      },
      "source": [
        "## Configuração"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iE0vSfMXumKI"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow.compat.v1 as tf1\n",
        "import tensorflow_datasets as tfds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4uXff1BEssdE"
      },
      "source": [
        "## TensorFlow 1: parada antecipada com um hook de parada antecipada e tf.estimator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaHhhhW5o8lL"
      },
      "source": [
        "Comece definindo funções para carregamento e pré-processamento do dataset MNIST e definição do modelo a ser usado com `tf.estimator.Estimator`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lqe9obf7suIj"
      },
      "outputs": [],
      "source": [
        "def normalize_img(image, label):\n",
        "  return tf.cast(image, tf.float32) / 255., label\n",
        "\n",
        "def _input_fn():\n",
        "  ds_train = tfds.load(\n",
        "    name='mnist',\n",
        "    split='train',\n",
        "    shuffle_files=True,\n",
        "    as_supervised=True)\n",
        "\n",
        "  ds_train = ds_train.map(\n",
        "      normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "  ds_train = ds_train.batch(128)\n",
        "  ds_train = ds_train.repeat(100)\n",
        "  return ds_train\n",
        "\n",
        "def _eval_input_fn():\n",
        "  ds_test = tfds.load(\n",
        "    name='mnist',\n",
        "    split='test',\n",
        "    shuffle_files=True,\n",
        "    as_supervised=True)\n",
        "  ds_test = ds_test.map(\n",
        "    normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "  ds_test = ds_test.batch(128)\n",
        "  return ds_test\n",
        "\n",
        "def _model_fn(features, labels, mode):\n",
        "  flatten = tf1.layers.Flatten()(features)\n",
        "  features = tf1.layers.Dense(128, 'relu')(flatten)\n",
        "  logits = tf1.layers.Dense(10)(features)\n",
        "\n",
        "  loss = tf1.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
        "  optimizer = tf1.train.AdagradOptimizer(0.005)\n",
        "  train_op = optimizer.minimize(loss, global_step=tf1.train.get_global_step())\n",
        "\n",
        "  return tf1.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hC_AY7KwqD0p"
      },
      "source": [
        "No TensorFlow 1, a parada antecipada funciona configurando um hook de parada antecipada com `tf.estimator.experimental.make_early_stopping_hook`. Você passa o hook para o método `make_early_stopping_hook` como um parâmetro para `should_stop_fn`, que pode aceitar uma função sem nenhum argumento. O treinamento para assim que `should_stop_fn` retorna `True`.\n",
        "\n",
        "O exemplo a seguir demonstra como implementar uma técnica de parada antecipada que limita o tempo de treinamento a um máximo de 20 segundos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HsOpjW5plH9Q"
      },
      "outputs": [],
      "source": [
        "estimator = tf1.estimator.Estimator(model_fn=_model_fn)\n",
        "\n",
        "start_time = time.time()\n",
        "max_train_seconds = 20\n",
        "\n",
        "def should_stop_fn():\n",
        "  return time.time() - start_time > max_train_seconds\n",
        "\n",
        "early_stopping_hook = tf1.estimator.experimental.make_early_stopping_hook(\n",
        "    estimator=estimator,\n",
        "    should_stop_fn=should_stop_fn,\n",
        "    run_every_secs=1,\n",
        "    run_every_steps=None)\n",
        "\n",
        "train_spec = tf1.estimator.TrainSpec(\n",
        "    input_fn=_input_fn,\n",
        "    hooks=[early_stopping_hook])\n",
        "\n",
        "eval_spec = tf1.estimator.EvalSpec(input_fn=_eval_input_fn)\n",
        "\n",
        "tf1.estimator.train_and_evaluate(estimator, train_spec, eval_spec)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEmzBjfnsxwT"
      },
      "source": [
        "### TensorFlow 2: parada antecipada com callback integrado e Model.fit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKwxnkIksPFW"
      },
      "source": [
        "Prepare o dataset MNIST e um modelo Keras simples:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "atVciNgPs0fw"
      },
      "outputs": [],
      "source": [
        "(ds_train, ds_test), ds_info = tfds.load(\n",
        "    'mnist',\n",
        "    split=['train', 'test'],\n",
        "    shuffle_files=True,\n",
        "    as_supervised=True,\n",
        "    with_info=True,\n",
        ")\n",
        "\n",
        "ds_train = ds_train.map(\n",
        "    normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "ds_train = ds_train.batch(128)\n",
        "\n",
        "ds_test = ds_test.map(\n",
        "    normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "ds_test = ds_test.batch(128)\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dense(10)\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(0.005),\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "559Goxp3tOMl"
      },
      "source": [
        "No TensorFlow 2, ao usar Keras `Model.fit` integrado (ou `Model.evaluate`), você pode configurar a parada antecipada passando um callback integrado — `tf.keras.callbacks.EarlyStopping` — para o parâmetro `callbacks` de `Model.fit`.\n",
        "\n",
        "O callback `EarlyStopping` monitora uma métrica especificada pelo usuário e encerra o treinamento quando ele para de melhorar. (Veja [Treinamento e avaliação com os métodos integrados](https://www.tensorflow.org/guide/keras/train_and_evaluate#using_callbacks) ou a [Documentação da API](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping) para mais informações.)\n",
        "\n",
        "Abaixo está um exemplo de um callback de parada antecipada que monitora a perda e interrompe o treinamento após o número de épocas que não mostram melhorias ser definido como `3` (`patience`): "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kip65sYBlKiu"
      },
      "outputs": [],
      "source": [
        "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
        "\n",
        "# Only around 25 epochs are run during training, instead of 100.\n",
        "history = model.fit(\n",
        "    ds_train,\n",
        "    epochs=100,\n",
        "    validation_data=ds_test,\n",
        "    callbacks=[callback]\n",
        ")\n",
        "\n",
        "len(history.history['loss'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a92c6ebb1a1c"
      },
      "source": [
        "### TensorFlow 2: parada antecipada com callback personalizado e Model.fit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCwZ4BA8jaHY"
      },
      "source": [
        "Você também pode implementar um [callback personalizado de parada antecipada](https://www.tensorflow.org/guide/keras/custom_callback/#early_stopping_at_minimum_loss), que também pode ser passado para o parâmetro `callbacks` de `Model.fit` (ou `Model.evaluate`).\n",
        "\n",
        "Neste exemplo, o processo de treinamento é interrompido quando `self.model.stop_training` é definido como `True`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hns1fmwtjCg2"
      },
      "outputs": [],
      "source": [
        "class LimitTrainingTime(tf.keras.callbacks.Callback):\n",
        "  def __init__(self, max_time_s):\n",
        "    super().__init__()\n",
        "    self.max_time_s = max_time_s\n",
        "    self.start_time = None\n",
        "\n",
        "  def on_train_begin(self, logs):\n",
        "    self.start_time = time.time()\n",
        "\n",
        "  def on_train_batch_end(self, batch, logs):\n",
        "    now = time.time()\n",
        "    if now - self.start_time >  self.max_time_s:\n",
        "      self.model.stop_training = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s5mIzDOAkUKA"
      },
      "outputs": [],
      "source": [
        "# Limit the training time to 30 seconds.\n",
        "callback = LimitTrainingTime(30)\n",
        "history = model.fit(\n",
        "    ds_train,\n",
        "    epochs=100,\n",
        "    validation_data=ds_test,\n",
        "    callbacks=[callback]\n",
        ")\n",
        "len(history.history['loss'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kro_lKyEu60-"
      },
      "source": [
        "## TensorFlow 2: parada antecipada com um loop de treinamento personalizado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5LU0lebvuIk"
      },
      "source": [
        "No TensorFlow 2, você pode implementar a parada antecipada em um [loop de treinamento personalizado](https://www.tensorflow.org/tutorials/customization/custom_training_walkthrough#training_loop) se não estiver treinando e avaliando com os [métodos Keras integrados](https://www.tensorflow.org/guide/keras/train_and_evaluate).\n",
        "\n",
        "Comece usando as APIs Keras para definir outro modelo simples, um otimizador, uma função de perda e métricas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oTGxr0PwAiQ4"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dense(10)\n",
        "])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(0.005)\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "train_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "train_loss_metric = tf.keras.metrics.SparseCategoricalCrossentropy()\n",
        "val_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "val_loss_metric = tf.keras.metrics.SparseCategoricalCrossentropy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zecsnqRxvy0Q"
      },
      "source": [
        "Defina as funções de atualização de parâmetro [com tf.GradientTape](https://www.tensorflow.org/guide/keras/writing_a_training_loop_from_scratch) e o decorador `@tf.function` [para acelerar](https://www.tensorflow.org/guide/function):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s3w_55n0Ah7L"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def train_step(x, y):\n",
        "  with tf.GradientTape() as tape:\n",
        "      logits = model(x, training=True)\n",
        "      loss_value = loss_fn(y, logits)\n",
        "  grads = tape.gradient(loss_value, model.trainable_weights)\n",
        "  optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
        "  train_acc_metric.update_state(y, logits)\n",
        "  train_loss_metric.update_state(y, logits)\n",
        "  return loss_value\n",
        "\n",
        "@tf.function\n",
        "def test_step(x, y):\n",
        "  logits = model(x, training=False)\n",
        "  val_acc_metric.update_state(y, logits)\n",
        "  val_loss_metric.update_state(y, logits)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ZKS9ePGwd9r"
      },
      "source": [
        "Em seguida, escreva um loop de treinamento personalizado, no qual você pode implementar manualmente sua regra de parada antecipada.\n",
        "\n",
        "O exemplo abaixo mostra como interromper o treinamento quando a perda de validação não melhora depois de um determinado número de épocas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iZOzHqqSAkpK"
      },
      "outputs": [],
      "source": [
        "epochs = 100\n",
        "patience = 5\n",
        "wait = 0\n",
        "best = float('inf')\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(\"\\nStart of epoch %d\" % (epoch,))\n",
        "    start_time = time.time()\n",
        "\n",
        "    for step, (x_batch_train, y_batch_train) in enumerate(ds_train):\n",
        "      loss_value = train_step(x_batch_train, y_batch_train)\n",
        "      if step % 200 == 0:\n",
        "        print(\"Training loss at step %d: %.4f\" % (step, loss_value.numpy()))\n",
        "        print(\"Seen so far: %s samples\" % ((step + 1) * 128))        \n",
        "    train_acc = train_acc_metric.result()\n",
        "    train_loss = train_loss_metric.result()\n",
        "    train_acc_metric.reset_states()\n",
        "    train_loss_metric.reset_states()\n",
        "    print(\"Training acc over epoch: %.4f\" % (train_acc.numpy()))\n",
        "\n",
        "    for x_batch_val, y_batch_val in ds_test:\n",
        "      test_step(x_batch_val, y_batch_val)\n",
        "    val_acc = val_acc_metric.result()\n",
        "    val_loss = val_loss_metric.result()\n",
        "    val_acc_metric.reset_states()\n",
        "    val_loss_metric.reset_states()\n",
        "    print(\"Validation acc: %.4f\" % (float(val_acc),))\n",
        "    print(\"Time taken: %.2fs\" % (time.time() - start_time))\n",
        "\n",
        "    # The early stopping strategy: stop the training if `val_loss` does not\n",
        "    # decrease over a certain number of epochs.\n",
        "    wait += 1\n",
        "    if val_loss < best:\n",
        "      best = val_loss\n",
        "      wait = 0\n",
        "    if wait >= patience:\n",
        "      break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e85558980a4b"
      },
      "source": [
        "## Próximos passos\n",
        "\n",
        "- Saiba mais sobre a API de callbacks de parada antecipada integrada ao Keras na [Documentação da API](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping).\n",
        "- Aprenda a [escrever callbacks Keras personalizados](https://www.tensorflow.org/guide/keras/custom_callback), incluindo [parada antecipada com perda mínima](https://www.tensorflow.org/guide/keras/custom_callback/#early_stopping_at_minimum_loss).\n",
        "- Saiba mais sobre [Treinamento e avaliação com os métodos integrados do Keras](https://www.tensorflow.org/guide/keras/train_and_evaluate#using_callbacks).\n",
        "- Explore as técnicas comuns de regularização no tutorial [Overfit e underfit](tensorflow.org/tutorials/keras/overfit_and_underfit) que usa o callback `EarlyStopping`."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "early_stopping.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
