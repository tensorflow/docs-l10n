{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FEL3NlTTDlSX"
      },
      "source": [
        "##### Copyright 2021 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "FlUw7tSKbtg4"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77z2OchJTk0l"
      },
      "source": [
        "# Como depurar um pipeline de treinamento migrado do TensorFlow 2\n",
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>     <a target=\"_blank\" href=\"https://www.tensorflow.org/guide/migrate/migration_debugging\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver em TensorFlow.org</a> </td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/pt-br/guide/migrate/migration_debugging.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Executar no Google Colab</a> </td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/pt-br/guide/migrate/migration_debugging.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver fonte no GitHub</a> </td>\n",
        "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/pt-br/guide/migrate/migration_debugging.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Baixar notebook</a> </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTwPu-w6M5sz"
      },
      "source": [
        "Este notebook demonstra como depurar um pipeline de treinamento ao migrar para o TensorFlow 2 (TF2). É composto pelos seguintes componentes:\n",
        "\n",
        "1. Etapas sugeridas e amostras de código para depurar o pipeline de treinamento\n",
        "2. Ferramentas para depuração\n",
        "3. Outros recursos relacionados\n",
        "\n",
        "Uma suposição é que você tem o código do TensorFlow 1 (TF1.x) e modelos treinados para comparação e deseja criar um modelo TF2 que alcance uma exatidão de validação semelhante.\n",
        "\n",
        "Este notebook **NÃO** cobre problemas de desempenho de depuração para velocidade de inferência/treinamento, ou uso de memória."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKm9R4CtOAP3"
      },
      "source": [
        "## Workflow de depuração\n",
        "\n",
        "Um workflow geral para depurar seus pipelines de treinamento TF2 está mostrado abaixo. Observe que você não precisa seguir essas etapas nessa ordem. Você também pode usar uma abordagem de pesquisa binária onde testa o modelo numa etapa intermediária e depois restringe o escopo da depuração.\n",
        "\n",
        "1. Corrigir erros de compilação e de tempo de execução\n",
        "\n",
        "2. Validação única de passo para a frente (num [guia](./validate_correctness.ipynb) separado)\n",
        "\n",
        "    a. Num único dispositivo CPU\n",
        "\n",
        "    - Verificar se as variáveis ​​são criadas apenas uma vez\n",
        "    - Verificar a correspondência de contagens, nomes e formas de variáveis\n",
        "    - Reiniciar todas as variáveis, verificar a equivalência numérica com toda a aleatoriedade desativada\n",
        "    - Alinhar a geração de números aleatórios, verificar a equivalência numérica na inferência\n",
        "    - (Opcional) Verificar se os checkpoints estão carregados corretamente e os modelos TF1.x/TF2 geram saída idêntica\n",
        "\n",
        "    b. Num único dispositivo GPU/TPU\n",
        "\n",
        "    c. Com estratégias para múltiplos dispositivos\n",
        "\n",
        "3. Validação de equivalência numérica de treinamento de modelos para alguns passos (exemplos de código disponíveis abaixo)\n",
        "\n",
        "    a. Validação de etapa de treinamento único usando dados pequenos e fixos num único dispositivo de CPU. Especificamente, verificar a equivalência numérica para os seguintes componentes\n",
        "\n",
        "    - cálculo de perdas\n",
        "    - métricas\n",
        "    - taxa de aprendizagem\n",
        "    - cálculo de gradiente e atualização\n",
        "\n",
        "    b. Verificar as estatísticas depois do treinamento de 3 ou mais passos para verificar os comportamentos do otimizador, como o momento, ainda com dados fixos num único dispositivo de CPU\n",
        "\n",
        "    c. Em um único dispositivo GPU/TPU\n",
        "\n",
        "    d. Com estratégias para múltiplos dispositivos (veja a introdução de [MultiProcessRunner](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/distribute/multi_process_runner.py#L108) no final deste artigo)\n",
        "\n",
        "4. Teste de convergência de ponta a ponta em dataset real\n",
        "\n",
        "    a. Verificar os comportamentos de treinamento com o TensorBoard\n",
        "\n",
        "    - usar otimizadores simples, por exemplo, SGD e estratégias de distribuição simples, por exemplo, `tf.distribute.OneDeviceStrategy` primeiro\n",
        "    - métricas de treinamento\n",
        "    - métricas de avaliação\n",
        "    - descobrir qual é a tolerância razoável para a aleatoriedade inerente\n",
        "\n",
        "    b. Verificar a equivalência com otimizador avançado/agendador de taxa de aprendizado/estratégias de distribuição\n",
        "\n",
        "    c. Verificar a equivalência ao usar precisão mista\n",
        "\n",
        "5. Benchmarks de produto adicionais"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKakQBI9-FLb"
      },
      "source": [
        "## Configuração"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i1ghHyXl-Oqd"
      },
      "outputs": [],
      "source": [
        "# The `DeterministicRandomTestTool` is only available from Tensorflow 2.8:\n",
        "!pip install -q \"tensorflow==2.9.*\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usyRSlIRl3r2"
      },
      "source": [
        "### Validação única de passo para frente\n",
        "\n",
        "A validação única de passo para frente, incluindo o carregamento do checkpoint, é abordada num [colab](./validate_correctness.ipynb) diferente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HVBQbsZeVL_V"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import unittest\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.compat.v1 as v1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4M104dt7m5cC"
      },
      "source": [
        "### Validação de equivalência numérica de treinamento de modelos para alguns passos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2Nz2Ni1EkMz"
      },
      "source": [
        "Defina a configuração do modelo e prepare um dataset falso."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hUxXadzKU9rT"
      },
      "outputs": [],
      "source": [
        "params = {\n",
        "    'input_size': 3,\n",
        "    'num_classes': 3,\n",
        "    'layer_1_size': 2,\n",
        "    'layer_2_size': 2,\n",
        "    'num_train_steps': 100,\n",
        "    'init_lr': 1e-3,\n",
        "    'end_lr': 0.0,\n",
        "    'decay_steps': 1000,\n",
        "    'lr_power': 1.0,\n",
        "}\n",
        "\n",
        "# make a small fixed dataset\n",
        "fake_x = np.ones((2, params['input_size']), dtype=np.float32)\n",
        "fake_y = np.zeros((2, params['num_classes']), dtype=np.int32)\n",
        "fake_y[0][0] = 1\n",
        "fake_y[1][1] = 1\n",
        "\n",
        "step_num = 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lV_n3Ukmz4Un"
      },
      "source": [
        "Defina o modelo TF1.x."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ATa5fzL8mAwl"
      },
      "outputs": [],
      "source": [
        "# Assume there is an existing TF1.x model using estimator API\n",
        "# Wrap the model_fn to log necessary tensors for result comparison\n",
        "class SimpleModelWrapper():\n",
        "  def __init__(self):\n",
        "    self.logged_ops = {}\n",
        "    self.logs = {\n",
        "        'step': [],\n",
        "        'lr': [],\n",
        "        'loss': [],\n",
        "        'grads_and_vars': [],\n",
        "        'layer_out': []}\n",
        "     \n",
        "  def model_fn(self, features, labels, mode, params):\n",
        "      out_1 = tf.compat.v1.layers.dense(features, units=params['layer_1_size'])\n",
        "      out_2 = tf.compat.v1.layers.dense(out_1, units=params['layer_2_size'])\n",
        "      logits = tf.compat.v1.layers.dense(out_2, units=params['num_classes'])\n",
        "      loss = tf.compat.v1.losses.softmax_cross_entropy(labels, logits)\n",
        "\n",
        "      # skip EstimatorSpec details for prediction and evaluation \n",
        "      if mode == tf.estimator.ModeKeys.PREDICT:\n",
        "          pass\n",
        "      if mode == tf.estimator.ModeKeys.EVAL:\n",
        "          pass\n",
        "      assert mode == tf.estimator.ModeKeys.TRAIN\n",
        "\n",
        "      global_step = tf.compat.v1.train.get_or_create_global_step()\n",
        "      lr = tf.compat.v1.train.polynomial_decay(\n",
        "        learning_rate=params['init_lr'],\n",
        "        global_step=global_step,\n",
        "        decay_steps=params['decay_steps'],\n",
        "        end_learning_rate=params['end_lr'],\n",
        "        power=params['lr_power'])\n",
        "      \n",
        "      optmizer = tf.compat.v1.train.GradientDescentOptimizer(lr)\n",
        "      grads_and_vars = optmizer.compute_gradients(\n",
        "          loss=loss,\n",
        "          var_list=graph.get_collection(\n",
        "              tf.compat.v1.GraphKeys.TRAINABLE_VARIABLES))\n",
        "      train_op = optmizer.apply_gradients(\n",
        "          grads_and_vars,\n",
        "          global_step=global_step)\n",
        "      \n",
        "      # log tensors\n",
        "      self.logged_ops['step'] = global_step\n",
        "      self.logged_ops['lr'] = lr\n",
        "      self.logged_ops['loss'] = loss\n",
        "      self.logged_ops['grads_and_vars'] = grads_and_vars\n",
        "      self.logged_ops['layer_out'] = {\n",
        "          'layer_1': out_1,\n",
        "          'layer_2': out_2,\n",
        "          'logits': logits}\n",
        "\n",
        "      return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)\n",
        "\n",
        "  def update_logs(self, logs):\n",
        "    for key in logs.keys():\n",
        "      model_tf1.logs[key].append(logs[key])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kki9yILSKS7f"
      },
      "source": [
        "A seguinte classe [`v1.keras.utils.DeterministicRandomTestTool`](https://www.tensorflow.org/api_docs/python/tf/compat/v1/keras/utils/DeterministicRandomTestTool) fornece um gerenciador de contexto `scope()` que pode fazer com que operações aleatórias stateful usem a mesma semente em ambos os grafos/sessões TF1 e execução antecipada (eager).\n",
        "\n",
        "A ferramenta fornece dois modos de teste:\n",
        "\n",
        "1. `constant` que usa a mesma semente para cada operação, não importa quantas vezes tenha sido chamada e,\n",
        "2. `num_random_ops` que usa o número de operações stateful aleatórias observadas anteriormente como a semente da operação.\n",
        "\n",
        "Isto se aplica tanto às operações aleatórias stateful usadas para criar e inicializar variáveis ​​quanto às operações aleatórias stateful usadas no cálculo (como para camadas de dropout)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X6Y3RWMoKOl8"
      },
      "outputs": [],
      "source": [
        "random_tool = v1.keras.utils.DeterministicRandomTestTool(mode='num_random_ops')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mk5-ZzxcErX5"
      },
      "source": [
        "Execute o modelo TF1.x no modo grafo. Colete estatísticas para as 3 primeiras etapas de treinamento para comparação de equivalência numérica."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r5zhJHvsWA24"
      },
      "outputs": [],
      "source": [
        "with random_tool.scope():\n",
        "  graph = tf.Graph()\n",
        "  with graph.as_default(), tf.compat.v1.Session(graph=graph) as sess:\n",
        "    model_tf1 = SimpleModelWrapper()\n",
        "    # build the model\n",
        "    inputs = tf.compat.v1.placeholder(tf.float32, shape=(None, params['input_size']))\n",
        "    labels = tf.compat.v1.placeholder(tf.float32, shape=(None, params['num_classes']))\n",
        "    spec = model_tf1.model_fn(inputs, labels, tf.estimator.ModeKeys.TRAIN, params)\n",
        "    train_op = spec.train_op\n",
        "\n",
        "    sess.run(tf.compat.v1.global_variables_initializer())\n",
        "    for step in range(step_num):\n",
        "      # log everything and update the model for one step\n",
        "      logs, _ = sess.run(\n",
        "          [model_tf1.logged_ops, train_op],\n",
        "          feed_dict={inputs: fake_x, labels: fake_y})\n",
        "      model_tf1.update_logs(logs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZxjI8Nxz9Ea"
      },
      "source": [
        "Defina o modelo TF2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AA67rh2TkS1M"
      },
      "outputs": [],
      "source": [
        "class SimpleModel(tf.keras.Model):\n",
        "  def __init__(self, params, *args, **kwargs):\n",
        "    super(SimpleModel, self).__init__(*args, **kwargs)\n",
        "    # define the model\n",
        "    self.dense_1 = tf.keras.layers.Dense(params['layer_1_size'])\n",
        "    self.dense_2 = tf.keras.layers.Dense(params['layer_2_size'])\n",
        "    self.out = tf.keras.layers.Dense(params['num_classes'])\n",
        "    learning_rate_fn = tf.keras.optimizers.schedules.PolynomialDecay(\n",
        "      initial_learning_rate=params['init_lr'],\n",
        "      decay_steps=params['decay_steps'],\n",
        "      end_learning_rate=params['end_lr'],\n",
        "      power=params['lr_power'])  \n",
        "    self.optimizer = tf.keras.optimizers.legacy.SGD(learning_rate_fn)\n",
        "    self.compiled_loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "    self.logs = {\n",
        "        'lr': [],\n",
        "        'loss': [],\n",
        "        'grads': [],\n",
        "        'weights': [],\n",
        "        'layer_out': []}\n",
        "\n",
        "  def call(self, inputs):\n",
        "    out_1 = self.dense_1(inputs)\n",
        "    out_2 = self.dense_2(out_1)\n",
        "    logits = self.out(out_2)\n",
        "    # log output features for every layer for comparison\n",
        "    layer_wise_out = {\n",
        "        'layer_1': out_1,\n",
        "        'layer_2': out_2,\n",
        "        'logits': logits}\n",
        "    self.logs['layer_out'].append(layer_wise_out)\n",
        "    return logits\n",
        "\n",
        "  def train_step(self, data):\n",
        "    x, y = data\n",
        "    with tf.GradientTape() as tape:\n",
        "      logits = self(x)\n",
        "      loss = self.compiled_loss(y, logits)\n",
        "    grads = tape.gradient(loss, self.trainable_weights)\n",
        "    # log training statistics\n",
        "    step = self.optimizer.iterations.numpy()\n",
        "    self.logs['lr'].append(self.optimizer.learning_rate(step).numpy())\n",
        "    self.logs['loss'].append(loss.numpy())\n",
        "    self.logs['grads'].append(grads)\n",
        "    self.logs['weights'].append(self.trainable_weights)\n",
        "    # update model\n",
        "    self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
        "    return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5smAcaEE8nX"
      },
      "source": [
        "Execute o modelo TF2 no modo eager. Colete estatísticas para as 3 primeiras etapas de treinamento para comparação de equivalência numérica."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q0AbXF_eE8cS"
      },
      "outputs": [],
      "source": [
        "random_tool = v1.keras.utils.DeterministicRandomTestTool(mode='num_random_ops')\n",
        "with random_tool.scope():\n",
        "  model_tf2 = SimpleModel(params)\n",
        "  for step in range(step_num):\n",
        "    model_tf2.train_step([fake_x, fake_y])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjJDjLcAz_gU"
      },
      "source": [
        "Compare a equivalência numérica para os primeiros passos de treinamento.\n",
        "\n",
        "Você também pode dar uma olhada no notebook [Validando exatidão e equivalência numérica](./validate_correctness.ipynb) para conselhos adicionais sobre equivalência numérica."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6CbCUbsCiabC"
      },
      "outputs": [],
      "source": [
        "np.testing.assert_allclose(model_tf1.logs['lr'], model_tf2.logs['lr'])\n",
        "np.testing.assert_allclose(model_tf1.logs['loss'], model_tf2.logs['loss'])\n",
        "for step in range(step_num):\n",
        "  for name in model_tf1.logs['layer_out'][step]:\n",
        "    np.testing.assert_allclose(\n",
        "        model_tf1.logs['layer_out'][step][name],\n",
        "        model_tf2.logs['layer_out'][step][name])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhVuuciimLIY"
      },
      "source": [
        "#### Testes de unidade"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXZYFC6Hhqeb"
      },
      "source": [
        "Existem alguns tipos de teste de unidade que podem ajudar a depurar seu código de migração.\n",
        "\n",
        "1. Validação única de passo para frente\n",
        "2. Validação de equivalência numérica de treinamento de modelos para alguns passos\n",
        "3. Benchmark de desempenho de inferência\n",
        "4. O modelo treinado faz previsões corretas em pontos de dados fixos e simples\n",
        "\n",
        "Você pode usar `@parameterized.parameters` para testar modelos com diferentes configurações. [Detalhes com amostra de código](https://github.com/abseil/abseil-py/blob/master/absl/testing/parameterized.py).\n",
        "\n",
        "Veja que é possível executar APIs de sessão e execução antecipada (eager) no mesmo caso de teste. Os trechos de código abaixo mostram como."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CdHqkgPPM2Bj"
      },
      "outputs": [],
      "source": [
        "import unittest\n",
        "\n",
        "class TestNumericalEquivalence(unittest.TestCase):\n",
        "\n",
        "  # copied from code samples above\n",
        "  def setup(self):\n",
        "    # record statistics for 100 training steps\n",
        "    step_num = 100\n",
        "\n",
        "    # setup TF 1 model\n",
        "    random_tool = v1.keras.utils.DeterministicRandomTestTool(mode='num_random_ops')\n",
        "    with random_tool.scope():\n",
        "      # run TF1.x code in graph mode with context management\n",
        "      graph = tf.Graph()\n",
        "      with graph.as_default(), tf.compat.v1.Session(graph=graph) as sess:\n",
        "        self.model_tf1 = SimpleModelWrapper()\n",
        "        # build the model\n",
        "        inputs = tf.compat.v1.placeholder(tf.float32, shape=(None, params['input_size']))\n",
        "        labels = tf.compat.v1.placeholder(tf.float32, shape=(None, params['num_classes']))\n",
        "        spec = self.model_tf1.model_fn(inputs, labels, tf.estimator.ModeKeys.TRAIN, params)\n",
        "        train_op = spec.train_op\n",
        "\n",
        "        sess.run(tf.compat.v1.global_variables_initializer())\n",
        "        for step in range(step_num):\n",
        "          # log everything and update the model for one step\n",
        "          logs, _ = sess.run(\n",
        "              [self.model_tf1.logged_ops, train_op],\n",
        "              feed_dict={inputs: fake_x, labels: fake_y})\n",
        "          self.model_tf1.update_logs(logs)\n",
        "\n",
        "    # setup TF2 model\n",
        "    random_tool = v1.keras.utils.DeterministicRandomTestTool(mode='num_random_ops')\n",
        "    with random_tool.scope():\n",
        "      self.model_tf2 = SimpleModel(params)\n",
        "      for step in range(step_num):\n",
        "        self.model_tf2.train_step([fake_x, fake_y])\n",
        "  \n",
        "  def test_learning_rate(self):\n",
        "    np.testing.assert_allclose(\n",
        "        self.model_tf1.logs['lr'],\n",
        "        self.model_tf2.logs['lr'])\n",
        "\n",
        "  def test_training_loss(self):\n",
        "    # adopt different tolerance strategies before and after 10 steps\n",
        "    first_n_step = 10\n",
        "\n",
        "    # absolute difference is limited below 1e-5\n",
        "    # set `equal_nan` to be False to detect potential NaN loss issues\n",
        "    abosolute_tolerance = 1e-5\n",
        "    np.testing.assert_allclose(\n",
        "        actual=self.model_tf1.logs['loss'][:first_n_step],\n",
        "        desired=self.model_tf2.logs['loss'][:first_n_step],\n",
        "        atol=abosolute_tolerance,\n",
        "        equal_nan=False)\n",
        "    \n",
        "    # relative difference is limited below 5%\n",
        "    relative_tolerance = 0.05\n",
        "    np.testing.assert_allclose(self.model_tf1.logs['loss'][first_n_step:],\n",
        "                               self.model_tf2.logs['loss'][first_n_step:],\n",
        "                               rtol=relative_tolerance,\n",
        "                               equal_nan=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gshSQdKIddpZ"
      },
      "source": [
        "## Ferramentas de depuração"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkMfCaJRclKv"
      },
      "source": [
        "### tf.print\n",
        "\n",
        "tf.print vs print/logging.info\n",
        "\n",
        "- Com argumentos configuráveis, `tf.print` pode exibir recursivamente os primeiros e últimos elementos de cada dimensão para tensores impressos. Veja a [Documentação da API](https://www.tensorflow.org/api_docs/python/tf/print) para mais detalhes.\n",
        "- Para execução antecipada (eager), `print` e `tf.print` imprimem o valor do tensor. Mas `print` pode envolver a cópia do dispositivo para o host, o que poderá desacelerar seu código.\n",
        "- Para o modo grafo, incluindo o uso dentro `tf.function`, você precisa usar `tf.print` para imprimir o valor real do tensor. `tf.print` é compilado em um op no grafo, enquanto `print` e `logging.info` registram apenas no tempo de rastreamento, o que geralmente não é o que você deseja.\n",
        "- `tf.print` também suporta a impressão de tensores compostos como `tf.RaggedTensor` e `tf.sparse.SparseTensor`.\n",
        "- Você também pode usar um callback para monitorar métricas e variáveis. Verifique como usar callbacks personalizados com [logs dict](https://www.tensorflow.org/guide/keras/custom_callback#usage_of_logs_dict) e com o atributo [self.model](https://www.tensorflow.org/guide/keras/custom_callback#usage_of_selfmodel_attribute)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-5h3cX8Dc50"
      },
      "source": [
        "tf.print vs print dentro de tf.function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gRED9FMyDKih"
      },
      "outputs": [],
      "source": [
        "# `print` prints info of tensor object\n",
        "# `tf.print` prints the tensor value\n",
        "@tf.function\n",
        "def dummy_func(num):\n",
        "  num += 1\n",
        "  print(num)\n",
        "  tf.print(num)\n",
        "  return num\n",
        "\n",
        "_ = dummy_func(tf.constant([1.0]))\n",
        "\n",
        "# Output:\n",
        "# Tensor(\"add:0\", shape=(1,), dtype=float32)\n",
        "# [2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3QroLA_zDK2w"
      },
      "source": [
        "tf.distribute.Strategy\n",
        "\n",
        "- Se a `tf.function` contendo `tf.print` for executada nos workers, por exemplo, ao usar `TPUStrategy` ou `ParameterServerStrategy`, será necessário verificar os logs do worker/servidor de parâmetros para encontrar os valores impressos.\n",
        "- Para `print` ou `logging.info` , os logs serão impressos no coordenador ao usar `ParameterServerStrategy` e os logs serão impressos no STDOUT em worker0 ao usar TPUs.\n",
        "\n",
        "tf.keras.Model\n",
        "\n",
        "- Ao usar modelo das APIs Sequential e Functional, se você deseja imprimir valores, por exemplo, entradas de modelo ou características intermediárias após algumas camadas, você pode dispor das seguintes alternativas.\n",
        "    1. [Escrever uma camada personalizada](https://www.tensorflow.org/guide/keras/custom_layers_and_models) que use `tf.print` para imprimir as entradas.\n",
        "    2. Incluir as saídas intermediárias que deseja inspecionar nas saídas do modelo.\n",
        "- As camadas `tf.keras.layers.Lambda` têm limitações de (des)serialização. Para evitar problemas de carregamento de checkpoint, escreva uma camada de personalizada numa subclasse. Veja a [documentação da API](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Lambda) para mais detalhes.\n",
        "- Você não pode usar `tf.print` com saídas intermediárias em um `tf.keras.callbacks.LambdaCallback` se não tiver acesso aos valores reais, mas apenas aos objetos simbólicos do tensor Keras.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKazGTr1ZUMG"
      },
      "source": [
        "Opção 1: escrever uma camada personalizada"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8w4aY7wO0B4W"
      },
      "outputs": [],
      "source": [
        "class PrintLayer(tf.keras.layers.Layer):\n",
        "  def call(self, inputs):\n",
        "    tf.print(inputs)\n",
        "    return inputs\n",
        "\n",
        "def get_model():\n",
        "  inputs = tf.keras.layers.Input(shape=(1,))\n",
        "  out_1 = tf.keras.layers.Dense(4)(inputs)\n",
        "  out_2 = tf.keras.layers.Dense(1)(out_1)\n",
        "  # use custom layer to tf.print intermediate features\n",
        "  out_3 = PrintLayer()(out_2)\n",
        "  model = tf.keras.Model(inputs=inputs, outputs=out_3)\n",
        "  return model\n",
        "\n",
        "model = get_model()\n",
        "model.compile(optimizer=\"adam\", loss=\"mse\")\n",
        "model.fit([1, 2, 3], [0.0, 0.0, 1.0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNESOatq7iM9"
      },
      "source": [
        "Opção 2: incluir as saídas intermediárias que deseja inspecionar nas saídas do modelo.\n",
        "\n",
        "Observe que, nesse caso, você poderá precisar de algumas [personalizações](https://www.tensorflow.org/guide/keras/customizing_what_happens_in_fit) para usar `Model.fit`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MiifvdLk7g9J"
      },
      "outputs": [],
      "source": [
        "def get_model():\n",
        "  inputs = tf.keras.layers.Input(shape=(1,))\n",
        "  out_1 = tf.keras.layers.Dense(4)(inputs)\n",
        "  out_2 = tf.keras.layers.Dense(1)(out_1)\n",
        "  # include intermediate values in model outputs\n",
        "  model = tf.keras.Model(\n",
        "      inputs=inputs,\n",
        "      outputs={\n",
        "          'inputs': inputs,\n",
        "          'out_1': out_1,\n",
        "          'out_2': out_2})\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvIKDZpHSLmQ"
      },
      "source": [
        "### pdb\n",
        "\n",
        "Você pode usar [o pdb](https://docs.python.org/3/library/pdb.html) tanto no terminal como no Colab para inspecionar valores intermediários para depuração.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qu0n4O2umyT7"
      },
      "source": [
        "### Visualização do grafo com o TensorBoard\n",
        "\n",
        "Você pode [examinar o grafo do TensorFlow com o TensorBoard](https://www.tensorflow.org/tensorboard/graphs). O TensorBoard também é [suportado no colab](https://www.tensorflow.org/tensorboard/tensorboard_in_notebooks). O TensorBoard é uma ótima ferramenta para visualizar resumos. Você pode usá-lo para comparar a taxa de aprendizado, pesos do modelo, escala de gradiente, métricas de treinamento/validação ou até mesmo modelar resultados intermediários entre o modelo TF1.x e o modelo TF2 migrado por meio do processo de treinamento e ver se os valores são os esperados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBnxB6_xzlnT"
      },
      "source": [
        "### TensorFlow Profiler\n",
        "\n",
        "O [TensorFlow Profiler](https://www.tensorflow.org/guide/profiler) pode ajudar você a visualizar a linha do tempo de execução em GPUs/TPUs. Veja o uso básico nesta [demonstração do Colab](https://www.tensorflow.org/tensorboard/tensorboard_profiling_keras)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wNmCSHBpiGM"
      },
      "source": [
        "### MultiProcessRunner\n",
        "\n",
        "O [MultiProcessRunner](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/distribute/multi_process_runner.py#L108) é uma ferramenta útil ao depurar com MultiWorkerMirroredStrategy e ParameterServerStrategy. Você pode dar uma olhada [neste exemplo concreto](https://github.com/keras-team/keras/blob/master/keras/integration_test/mwms_multi_process_runner_test.py) para ver como usar.\n",
        "\n",
        "Especificamente, para essas duas estratégias, é recomendável 1) não depender apenas de testes de unidade para cobrir seu fluxo, 2) mas também tentar reproduzir falhas usando-o num teste de unidade para evitar que uma tarefa distribuída real seja executada toda vez que houver uma tentativa de consertar a falha."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "migration_debugging.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
