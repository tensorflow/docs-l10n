{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bYaCABobL5q"
      },
      "source": [
        "##### Copyright 2018 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "FlUw7tSKbtg4"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xc1srSc51n_4"
      },
      "source": [
        "# <a>Usando o formato SavedModel</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nBUqG2rchGH"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>     <a target=\"_blank\" href=\"https://www.tensorflow.org/guide/saved_model\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver em TensorFlow.org</a> </td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/pt-br/guide/saved_model.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Executar no Google Colab</a>   </td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/pt-br/guide/saved_model.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver fonte em GitHub</a>   </td>\n",
        "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/pt-br/guide/saved_model.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Baixar notebook</a> </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPE-fshLTsXU"
      },
      "source": [
        "Um SavedModel contém um programa TensorFlow completo, incluindo parâmetros treinados (ou seja, objetos `tf.Variable`) e computação. Ele não requer a execução do código de construção do modelo original, o que o torna útil para compartilhamento ou implantação com [TFLite](https://tensorflow.org/lite), [TensorFlow.js](https://js.tensorflow.org/), [TensorFlow Serving](https://www.tensorflow.org/tfx/serving/tutorials/Serving_REST_simple) ou [TensorFlow Hub](https://tensorflow.org/hub).\n",
        "\n",
        "Você pode salvar e carregar um modelo no formato SavedModel usando as seguintes APIs:\n",
        "\n",
        "- API `tf.saved_model` de baixo nível. Este documento descreve detalhadamente como usar esta API.\n",
        "    - Salvar: `tf.saved_model.save(model, path_to_dir)`\n",
        "    - Carregar: `model = tf.saved_model.load(path_to_dir)`\n",
        "- API `tf.keras.Model` de alto nível. Consulte o [guia de salvamento e serialização do keras](https://www.tensorflow.org/guide/keras/save_and_serialize).\n",
        "- Se quiser apenas salvar/carregar pesos durante o treino, consulte o [guia de checkpoints](./checkpoint.ipynb).\n",
        "\n",
        "Atenção: os modelos do TensorFlow são códigos, e é importante ter cuidado com código não confiável. Saiba mais em [Como usar o TensorFlow com segurança](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9SuIC7FiI9g8"
      },
      "source": [
        "## Criando um SavedModel a partir do Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtSmftAvhJvE"
      },
      "source": [
        "Obsoleto: para objetos do Keras, recomenda-se usar o novo formato de alto nível `.keras` e `tf.keras.Model.export`, conforme demonstrado [neste guia](https://www.tensorflow.org/guide/keras/save_and_serialize). O formato de baixo nível SavedModel continua com suporte para códigos existentes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLSOptpYhJvE"
      },
      "source": [
        "Para uma introdução rápida, esta seção exporta um modelo Keras pré-treinado e atende solicitações de classificação de imagem com ele. O restante do guia preencherá detalhes e discutirá outras maneiras de criar SavedModels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Le5OB-fBHHW7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tempfile\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "tmpdir = tempfile.mkdtemp()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wlho4HEWoHUT"
      },
      "outputs": [],
      "source": [
        "physical_devices = tf.config.list_physical_devices('GPU')\n",
        "for device in physical_devices:\n",
        "  tf.config.experimental.set_memory_growth(device, True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SofdPKo0G8Lb"
      },
      "outputs": [],
      "source": [
        "file = tf.keras.utils.get_file(\n",
        "    \"grace_hopper.jpg\",\n",
        "    \"https://storage.googleapis.com/download.tensorflow.org/example_images/grace_hopper.jpg\")\n",
        "img = tf.keras.utils.load_img(file, target_size=[224, 224])\n",
        "plt.imshow(img)\n",
        "plt.axis('off')\n",
        "x = tf.keras.utils.img_to_array(img)\n",
        "x = tf.keras.applications.mobilenet.preprocess_input(\n",
        "    x[tf.newaxis,...])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqVcFL10JkF0"
      },
      "source": [
        "Você usará uma imagem de Grace Hopper como exemplo em execução e um modelo de classificação de imagens pré-treinado do Keras, pois é mais fácil de usar. Modelos personalizados também funcionam e serão abordados em detalhes posteriormente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JhVecdzJTsKE"
      },
      "outputs": [],
      "source": [
        "labels_path = tf.keras.utils.get_file(\n",
        "    'ImageNetLabels.txt',\n",
        "    'https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt')\n",
        "imagenet_labels = np.array(open(labels_path).read().splitlines())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aEHSYjW6JZHV"
      },
      "outputs": [],
      "source": [
        "pretrained_model = tf.keras.applications.MobileNet()\n",
        "result_before_save = pretrained_model(x)\n",
        "\n",
        "decoded = imagenet_labels[np.argsort(result_before_save)[0,::-1][:5]+1]\n",
        "\n",
        "print(\"Result before saving:\\n\", decoded)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4KIsQDZJ5PS"
      },
      "source": [
        "A principal previsão para esta imagem é “uniforme militar”."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8nfznDmHCW6F"
      },
      "outputs": [],
      "source": [
        "mobilenet_save_path = os.path.join(tmpdir, \"mobilenet/1/\")\n",
        "tf.saved_model.save(pretrained_model, mobilenet_save_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pyX-ETE3wX63"
      },
      "source": [
        "O caminho de salvamento (save-path) segue uma convenção usada pelo TensorFlow Serving, onde o último componente do caminho (`1/` aqui) é um número de versão do seu modelo. Ele permite que ferramentas como o Tensorflow Serving raciocinem sobre a atualização relativa.\n",
        "\n",
        "Você pode carregar o SavedModel de volta no Python com `tf.saved_model.load` e ver como a imagem do Admiral Hopper é classificada."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NP2UpVFRV7N_"
      },
      "outputs": [],
      "source": [
        "loaded = tf.saved_model.load(mobilenet_save_path)\n",
        "print(list(loaded.signatures.keys()))  # [\"serving_default\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5srGzowfWff"
      },
      "source": [
        "Assinaturas importadas sempre retornam dicionários. Para personalizar nomes de assinaturas e chaves de dicionários de saída, veja [Especificando assinaturas durante a exportação](#specifying_signatures_during_export)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ChFLpegYfQGR"
      },
      "outputs": [],
      "source": [
        "infer = loaded.signatures[\"serving_default\"]\n",
        "print(infer.structured_outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJYyZnptfuru"
      },
      "source": [
        "Executar a inferência do SavedModel fornece o mesmo resultado que o modelo original."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9WjGEaS3XfX7"
      },
      "outputs": [],
      "source": [
        "labeling = infer(tf.constant(x))[pretrained_model.output_names[0]]\n",
        "\n",
        "decoded = imagenet_labels[np.argsort(labeling)[0,::-1][:5]+1]\n",
        "\n",
        "print(\"Result after saving and loading:\\n\", decoded)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJEkdXjTWbtl"
      },
      "source": [
        "## Executando um SavedModel no TensorFlow Serving\n",
        "\n",
        "Os SavedModels podem ser usados ​​a partir do Python (mais sobre isso abaixo), mas ambientes de produção normalmente usam um serviço dedicado para inferência sem executar código Python. Isto é fácil de configurar a partir de um SavedModel usando o TensorFlow Serving.\n",
        "\n",
        "Consulte o [Tutorial REST do TensorFlow Serving](https://www.tensorflow.org/tfx/tutorials/serving/rest_simple) para um exemplo completo com o tensorflow-serving."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bi0ILzu1XdWw"
      },
      "source": [
        "## O formato SavedModel no disco\n",
        "\n",
        "Um SavedModel é um diretório que contém assinaturas serializadas e o estado necessário para executá-las, incluindo valores de variáveis ​​e vocabulários.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6u3YZuYZXyTO"
      },
      "outputs": [],
      "source": [
        "!ls {mobilenet_save_path}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ple4X5utX8ue"
      },
      "source": [
        "O arquivo `saved_model.pb` armazena o programa ou modelo real do TensorFlow e um conjunto de assinaturas nomeadas, cada uma identificando uma função que aceita entradas de tensor e produz saídas de tensor.\n",
        "\n",
        "Os SavedModels podem conter múltiplas variantes do modelo (múltiplas `v1.MetaGraphDefs`, identificadas com o sinalizador `--tag_set` para `saved_model_cli`), mas isto é raro. APIs que criam múltiplas variantes de um modelo incluem [`tf.Estimator.experimental_export_all_saved_models`](https://www.tensorflow.org/api_docs/python/tf/estimator/Estimator#experimental_export_all_saved_models) e no TensorFlow 1.x `tf.saved_model.Builder`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pus0dOYTYXbI"
      },
      "outputs": [],
      "source": [
        "!saved_model_cli show --dir {mobilenet_save_path} --tag_set serve"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eALHpGvRZOhk"
      },
      "source": [
        "O diretório `variables` ​​contém um checkpoint de treinamento padrão (veja o [guia de checkpoints de treinamento](./checkpoint.ipynb))."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EDYqhDlNZAC2"
      },
      "outputs": [],
      "source": [
        "!ls {mobilenet_save_path}/variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKmaZQpHahGh"
      },
      "source": [
        "O diretório `assets` contém arquivos usados ​​pelo grafo do TensorFlow, por exemplo, arquivos de texto usados ​​para inicializar tabelas de vocabulário. Não é utilizado neste exemplo.\n",
        "\n",
        "SavedModels pode ter um diretório `assets.extra` para quaisquer arquivos não usados ​​pelo grafo do TensorFlow, por exemplo, informações para consumidores sobre o que fazer com o SavedModel. O próprio TensorFlow não usa esse diretório.\n",
        "\n",
        "O arquivo `fingerprint.pb` contém a [impressão digital](https://en.wikipedia.org/wiki/Fingerprint_(computing)) do SavedModel, que é composta por vários hashes de 64 bits que identificam exclusivamente o conteúdo do SavedModel. A API de impressão digital é atualmente experimental, mas `tf.saved_model.experimental.read_fingerprint` pode ser usado para ler a impressão digital SavedModel num objeto `tf.saved_model.experimental.Fingerprint`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIceoF_CYmaF"
      },
      "source": [
        "## Salvando um modelo personalizado\n",
        "\n",
        "`tf.saved_model.save` suporta o salvamento de objetos `tf.Module` e suas subclasses, como `tf.keras.Layer` e `tf.keras.Model`.\n",
        "\n",
        "Vejamos um exemplo de como salvar e restaurar um `tf.Module`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6EPvKiqXMm3d"
      },
      "outputs": [],
      "source": [
        "class CustomModule(tf.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(CustomModule, self).__init__()\n",
        "    self.v = tf.Variable(1.)\n",
        "\n",
        "  @tf.function\n",
        "  def __call__(self, x):\n",
        "    print('Tracing with', x)\n",
        "    return x * self.v\n",
        "\n",
        "  @tf.function(input_signature=[tf.TensorSpec([], tf.float32)])\n",
        "  def mutate(self, new_v):\n",
        "    self.v.assign(new_v)\n",
        "\n",
        "module = CustomModule()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4FcP-Co3Fnw"
      },
      "source": [
        "Quando você salva um `tf.Module`, quaisquer atributos `tf.Variable`, métodos decorados `tf.function` e `tf.Module` encontrados via travessia recursiva são salvos. (Consulte o [tutorial sobre checkpoints](./checkpoint.ipynb) para saber mais sobre essa travessia recursiva.) No entanto, quaisquer atributos, funções e dados do Python são perdidos. Isto significa que quando uma `tf.function` é salva, nenhum código Python é salvo.\n",
        "\n",
        "Se nenhum código Python for salvo, como o SavedModel saberá restaurar a função?\n",
        "\n",
        "Resumidamente, `tf.function` funciona rastreando o código Python para gerar um ConcreteFunction (um wrapper em torno de `tf.Graph` que pode ser chamado). Ao salvar um `tf.function`, você está na verdade salvando o cache `tf.function` de ConcreteFunctions.\n",
        "\n",
        "Para saber mais sobre o relacionamento entre `tf.function` e ConcreteFunctions, veja o [guia sobre tf.function](function.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "85PUO9iWH7xn"
      },
      "outputs": [],
      "source": [
        "module_no_signatures_path = os.path.join(tmpdir, 'module_no_signatures')\n",
        "module(tf.constant(0.))\n",
        "print('Saving model...')\n",
        "tf.saved_model.save(module, module_no_signatures_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ujwmMQg7OUo"
      },
      "source": [
        "## Carregando e usando um modelo personalizado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpxQy5Eb77qJ"
      },
      "source": [
        "Quando você carrega um SavedModel em Python, todos os atributos de `tf.Variable`, métodos decorados com `tf.function` e `tf.Module` são restaurados na mesma estrutura de objeto do `tf.Module` salvo originalmente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EMASjADPxPso"
      },
      "outputs": [],
      "source": [
        "imported = tf.saved_model.load(module_no_signatures_path)\n",
        "assert imported(tf.constant(3.)).numpy() == 3\n",
        "imported.mutate(tf.constant(2.))\n",
        "assert imported(tf.constant(3.)).numpy() == 6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDiauvb_99uk"
      },
      "source": [
        "Como nenhum código Python é salvo, a chamada de `tf.function` com uma nova assinatura de entrada falhará:\n",
        "\n",
        "```python\n",
        "imported(tf.constant([3.]))\n",
        "```\n",
        "\n",
        "<pre>\n",
        "ValueError: Could not find matching function to call for canonicalized inputs ((&lt;tf.Tensor 'args_0:0' shape=(1,) dtype=float32&gt;,), {}). Only existing signatures are [((TensorSpec(shape=(), dtype=tf.float32, name=u'x'),), {})].\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Vsva3UZ-2sf"
      },
      "source": [
        "### Tuning básico\n",
        "\n",
        "Objetos variáveis ​​estão disponíveis e você pode fazer backprop através de funções importadas. Isto é suficiente para fazer um ajuste fino (ou seja, treinar novamente) um SavedModel em casos simples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PEkQNarJ-7nT"
      },
      "outputs": [],
      "source": [
        "optimizer = tf.keras.optimizers.SGD(0.05)\n",
        "\n",
        "def train_step():\n",
        "  with tf.GradientTape() as tape:\n",
        "    loss = (10. - imported(tf.constant(2.))) ** 2\n",
        "  variables = tape.watched_variables()\n",
        "  grads = tape.gradient(loss, variables)\n",
        "  optimizer.apply_gradients(zip(grads, variables))\n",
        "  return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p41NM6fF---3"
      },
      "outputs": [],
      "source": [
        "for _ in range(10):\n",
        "  # \"v\" approaches 5, \"loss\" approaches 0\n",
        "  print(\"loss={:.2f} v={:.2f}\".format(train_step(), imported.v.numpy()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuXtkHSD_KSW"
      },
      "source": [
        "### Tuning geral\n",
        "\n",
        "Um SavedModel da Keras fornece [mais detalhes](https://github.com/tensorflow/community/blob/master/rfcs/20190509-keras-saved-model.md#serialization-details) do que uma simples `__call__` para abordar casos mais avançados de ajuste fino. O TensorFlow Hub recomenda fornecer o seguinte, se aplicável, em SavedModels compartilhados para fins de tuning:\n",
        "\n",
        "- Se o modelo usar dropout ou outra técnica na qual o passo para frente difere no treinamento e na inferência (como normalização em lote), o método `__call__` usará um argumento `training=` opcional com valor Python cujo padrão é `False`, mas pode ser definido como `True`.\n",
        "- Depois do atributo `__call__`, existem os atributos `.variable` e `.trainable_variable` com listas de variáveis ​​correspondentes. Uma variável que era originalmente treinável, mas que deveria ser congelada durante o ajuste fino, é omitida de `.trainable_variables`.\n",
        "- Para o bem de estruturas como Keras, que representam regularizadores de peso como atributos de camadas ou submodelos, também poderá haver um atributo `.regularization_losses`. Ele contém uma lista de funções com argumento zero cujos valores devem ser adicionados à perda total.\n",
        "\n",
        "Voltando ao exemplo inicial do MobileNet, você poderá ver alguns desses em ação:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y6EUFdY8_PRD"
      },
      "outputs": [],
      "source": [
        "loaded = tf.saved_model.load(mobilenet_save_path)\n",
        "print(\"MobileNet has {} trainable variables: {}, ...\".format(\n",
        "          len(loaded.trainable_variables),\n",
        "          \", \".join([v.name for v in loaded.trainable_variables[:5]])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B-mQJ8iP_R0h"
      },
      "outputs": [],
      "source": [
        "trainable_variable_ids = {id(v) for v in loaded.trainable_variables}\n",
        "non_trainable_variables = [v for v in loaded.variables\n",
        "                           if id(v) not in trainable_variable_ids]\n",
        "print(\"MobileNet also has {} non-trainable variables: {}, ...\".format(\n",
        "          len(non_trainable_variables),\n",
        "          \", \".join([v.name for v in non_trainable_variables[:3]])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGlHlbd3_eyO"
      },
      "source": [
        "## Especificando assinaturas durante a exportação\n",
        "\n",
        "Ferramentas como TensorFlow Serving e `saved_model_cli` podem interagir com SavedModels. Para ajudar essas ferramentas a determinar quais ConcreteFunctions usar, você precisa especificar assinaturas de serviço. Os `tf.keras.Model` especificam automaticamente assinaturas de serviço, mas você terá que declarar explicitamente uma assinatura de serviço para nossos módulos personalizados.\n",
        "\n",
        "IMPORTANTE: a menos que você precise exportar seu modelo para um ambiente diferente do TensorFlow 2.x com Python, provavelmente não será necessário exportar assinaturas explicitamente. Se você está procurando uma maneira de impor uma assinatura de entrada para uma função específica, veja o argumento [`input_signature`](https://www.tensorflow.org/api_docs/python/tf/function#args_1) para `tf.function`.\n",
        "\n",
        "Por padrão, nenhuma assinatura é declarada num `tf.Module` personalizado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h-IB5Xa0NxLa"
      },
      "outputs": [],
      "source": [
        "assert len(imported.signatures) == 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BiNtaMZSI8Tb"
      },
      "source": [
        "Para declarar uma assinatura de serviço, especifique uma ConcreteFunction usando o kwarg `signatures`. Ao especificar uma única assinatura, sua chave de assinatura será `'serving_default'`, que é salva como a constante `tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_pAdgIORR2yH"
      },
      "outputs": [],
      "source": [
        "module_with_signature_path = os.path.join(tmpdir, 'module_with_signature')\n",
        "call = module.__call__.get_concrete_function(tf.TensorSpec(None, tf.float32))\n",
        "tf.saved_model.save(module, module_with_signature_path, signatures=call)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nAzRHR0UT4hv"
      },
      "outputs": [],
      "source": [
        "imported_with_signatures = tf.saved_model.load(module_with_signature_path)\n",
        "list(imported_with_signatures.signatures.keys())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_gH91j1IR4tq"
      },
      "source": [
        "Para exportar múltiplas assinaturas, passe um dicionário de chaves de assinatura para ConcreteFunctions. Cada chave de assinatura corresponde a uma ConcreteFunction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6VYAiQmLUiox"
      },
      "outputs": [],
      "source": [
        "module_multiple_signatures_path = os.path.join(tmpdir, 'module_with_multiple_signatures')\n",
        "signatures = {\"serving_default\": call,\n",
        "              \"array_input\": module.__call__.get_concrete_function(tf.TensorSpec([None], tf.float32))}\n",
        "\n",
        "tf.saved_model.save(module, module_multiple_signatures_path, signatures=signatures)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8IPx_0RWEx07"
      },
      "outputs": [],
      "source": [
        "imported_with_multiple_signatures = tf.saved_model.load(module_multiple_signatures_path)\n",
        "list(imported_with_multiple_signatures.signatures.keys())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43_Qv2W_DJZZ"
      },
      "source": [
        "Por padrão, os nomes dos tensores de saída são bastante genéricos, como `output_0`. Para controlar os nomes das saídas, modifique seu `tf.function` para retornar um dicionário que mapeia nomes de saída para saídas. Os nomes das entradas são derivados dos nomes dos argumentos da função Python."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ACKPl1X8G1gw"
      },
      "outputs": [],
      "source": [
        "class CustomModuleWithOutputName(tf.Module):\n",
        "  def __init__(self):\n",
        "    super(CustomModuleWithOutputName, self).__init__()\n",
        "    self.v = tf.Variable(1.)\n",
        "\n",
        "  @tf.function(input_signature=[tf.TensorSpec(None, tf.float32)])\n",
        "  def __call__(self, x):\n",
        "    return {'custom_output_name': x * self.v}\n",
        "\n",
        "module_output = CustomModuleWithOutputName()\n",
        "call_output = module_output.__call__.get_concrete_function(tf.TensorSpec(None, tf.float32))\n",
        "module_output_path = os.path.join(tmpdir, 'module_with_output_name')\n",
        "tf.saved_model.save(module_output, module_output_path,\n",
        "                    signatures={'serving_default': call_output})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1yGVy4MuH-V0"
      },
      "outputs": [],
      "source": [
        "imported_with_output_name = tf.saved_model.load(module_output_path)\n",
        "imported_with_output_name.signatures['serving_default'].structured_outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4bCK55x1IBW"
      },
      "source": [
        "## Divisão de arquivos proto\n",
        "\n",
        "Observação: este recurso fará parte da versão 2.15 do TensorFlow. No momento, ele está disponível em build noturno, que você pode instalar com `pip install tf-nightly`.\n",
        "\n",
        "Devido aos limites da implementação do protobuf, os tamanhos do proto não podem ultrapassar 2 GB. Isso pode levar aos seguintes erros ao tentar salvar modelos muito grandes:\n",
        "\n",
        "```\n",
        "ValueError: Message tensorflow.SavedModel exceeds maximum protobuf size of 2GB: ...\n",
        "```\n",
        "\n",
        "```\n",
        "google.protobuf.message.DecodeError: Error parsing message as the message exceeded the protobuf limit with type 'tensorflow.GraphDef'\n",
        "```\n",
        "\n",
        "Se você quiser salvar modelos que ultrapassam o limite de 2 GB, será necessário salvar usando a nova opção de divisão de proto:\n",
        "\n",
        "```python\n",
        "tf.saved_model.save(\n",
        "  ...,\n",
        "  options=tf.saved_model.SaveOptions(experimental_image_format=True)\n",
        ")\n",
        "```\n",
        "\n",
        "Encontre mais informações no [guia da biblioteca de divisão / fusão de proto](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/proto_splitter/in-depth-guide.md)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Co6fDbzw_UnD"
      },
      "source": [
        "## Carregue um SavedModel em C++\n",
        "\n",
        "A versão C++ do [carregador](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/cc/saved_model/loader.h) do SavedModel fornece uma API para carregar um SavedModel de um caminho, enquanto permite SessionOptions e RunOptions. Você deve especificar as tags associadas ao grafo a ser carregado. A versão carregada do SavedModel é chamada de SavedModelBundle e contém o MetaGraphDef e a sessão na qual ele é carregado.\n",
        "\n",
        "```C++\n",
        "const string export_dir = ...\n",
        "SavedModelBundle bundle;\n",
        "...\n",
        "LoadSavedModel(session_options, run_options, export_dir, {kSavedModelTagTrain},\n",
        "               &amp;bundle);\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b33KuyEuAO3Z"
      },
      "source": [
        "<a id=\"saved_model_cli\"></a>\n",
        "\n",
        "## Detalhes da interface de linha de comando SavedModel\n",
        "\n",
        "Você pode usar a interface de linha de comando (CLI) do SavedModel para inspecionar e executar um SavedModel. Por exemplo, você pode usar a CLI para inspecionar os `SignatureDef` do modelo. A CLI permite que você confirme rapidamente se o dtype e o formato do Tensor de entrada correspondem ao modelo. Além disso, se quiser testar seu modelo, você pode usar a CLI para fazer uma verificação de integridade, passando amostras de entradas em vários formatos (por exemplo, expressões Python) e, em seguida, obtendo a saída.\n",
        "\n",
        "### Instale a SavedModel CLI\n",
        "\n",
        "Em termos gerais, você pode instalar o TensorFlow de uma das duas maneiras a seguir:\n",
        "\n",
        "- Instalando um binário TensorFlow pré-compilado.\n",
        "- Compilando o TensorFlow a partir do código-fonte.\n",
        "\n",
        "Se você instalou o TensorFlow através de um binário pré-compilado do TensorFlow, a CLI do SavedModel já estará instalada no seu sistema no caminho `bin/saved_model_cli`.\n",
        "\n",
        "Se você compilou o TensorFlow a partir do código-fonte, deverá executar o seguinte comando adicional para compilar o `saved_model_cli`:\n",
        "\n",
        "```\n",
        "$ bazel build //tensorflow/python/tools:saved_model_cli\n",
        "```\n",
        "\n",
        "### Visão geral dos comandos\n",
        "\n",
        "A CLI do SavedModel oferece suporte aos dois comandos a seguir num SavedModel:\n",
        "\n",
        "- `show`, que mostra as computações disponíveis num SavedModel.\n",
        "- `run`, que executa uma computação em um SavedModel.\n",
        "\n",
        "### Comando `show`\n",
        "\n",
        "Um SavedModel contém uma ou mais variantes de modelos (tecnicamente, `v1.MetaGraphDef`), identificadas por seus conjuntos de tags. Para servir um modelo, você pode se perguntar que tipo de `SignatureDef` existem em cada variante de modelo e quais são suas entradas e saídas. O comando `show` permite examinar o conteúdo do SavedModel em ordem hierárquica. Aqui está a sintaxe:\n",
        "\n",
        "```\n",
        "usage: saved_model_cli show [-h] --dir DIR [--all]\n",
        "[--tag_set TAG_SET] [--signature_def SIGNATURE_DEF_KEY]\n",
        "```\n",
        "\n",
        "Por exemplo, o comando a seguir mostra todos os conjuntos de tags disponíveis no SavedModel:\n",
        "\n",
        "```\n",
        "$ saved_model_cli show --dir /tmp/saved_model_dir\n",
        "The given SavedModel contains the following tag-sets:\n",
        "serve\n",
        "serve, gpu\n",
        "```\n",
        "\n",
        "O comando a seguir mostra todas as chaves `SignatureDef` disponíveis para um conjunto de tags:\n",
        "\n",
        "```\n",
        "$ saved_model_cli show --dir /tmp/saved_model_dir --tag_set serve\n",
        "The given SavedModel `MetaGraphDef` contains `SignatureDefs` with the\n",
        "following keys:\n",
        "SignatureDef key: \"classify_x2_to_y3\"\n",
        "SignatureDef key: \"classify_x_to_y\"\n",
        "SignatureDef key: \"regress_x2_to_y3\"\n",
        "SignatureDef key: \"regress_x_to_y\"\n",
        "SignatureDef key: \"regress_x_to_y2\"\n",
        "SignatureDef key: \"serving_default\"\n",
        "```\n",
        "\n",
        "Se houver *múltiplos* tags no conjunto de tags, você deverá especificar todas as tags, cada tag separada por uma vírgula. Por exemplo:\n",
        "\n",
        "<pre>\n",
        "$ saved_model_cli show --dir /tmp/saved_model_dir --tag_set serve,gpu\n",
        "</pre>\n",
        "\n",
        "Para mostrar todas as entradas e saídas do TensorInfo para um `SignatureDef` específico, passe a chave `SignatureDef` para a opção `signature_def`. Isso é muito útil quando você deseja saber o valor da chave do tensor, o dtype e formato dos tensores de entrada para executar o grafo de computação posteriormente. Por exemplo:\n",
        "\n",
        "```\n",
        "$ saved_model_cli show --dir \\\n",
        "/tmp/saved_model_dir --tag_set serve --signature_def serving_default\n",
        "The given SavedModel SignatureDef contains the following input(s):\n",
        "  inputs['x'] tensor_info:\n",
        "      dtype: DT_FLOAT\n",
        "      shape: (-1, 1)\n",
        "      name: x:0\n",
        "The given SavedModel SignatureDef contains the following output(s):\n",
        "  outputs['y'] tensor_info:\n",
        "      dtype: DT_FLOAT\n",
        "      shape: (-1, 1)\n",
        "      name: y:0\n",
        "Method name is: tensorflow/serving/predict\n",
        "```\n",
        "\n",
        "Para mostrar todas as informações disponíveis no SavedModel, use a opção `--all`. Por exemplo:\n",
        "\n",
        "<pre>\n",
        "$ saved_model_cli show --dir /tmp/saved_model_dir --all\n",
        "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n",
        "\n",
        "signature_def['classify_x2_to_y3']:\n",
        "  The given SavedModel SignatureDef contains the following input(s):\n",
        "    inputs['inputs'] tensor_info:\n",
        "        dtype: DT_FLOAT\n",
        "        shape: (-1, 1)\n",
        "        name: x2:0\n",
        "  The given SavedModel SignatureDef contains the following output(s):\n",
        "    outputs['scores'] tensor_info:\n",
        "        dtype: DT_FLOAT\n",
        "        shape: (-1, 1)\n",
        "        name: y3:0\n",
        "  Method name is: tensorflow/serving/classify\n",
        "\n",
        "...\n",
        "\n",
        "signature_def['serving_default']:\n",
        "  The given SavedModel SignatureDef contains the following input(s):\n",
        "    inputs['x'] tensor_info:\n",
        "        dtype: DT_FLOAT\n",
        "        shape: (-1, 1)\n",
        "        name: x:0\n",
        "  The given SavedModel SignatureDef contains the following output(s):\n",
        "    outputs['y'] tensor_info:\n",
        "        dtype: DT_FLOAT\n",
        "        shape: (-1, 1)\n",
        "        name: y:0\n",
        "  Method name is: tensorflow/serving/predict\n",
        "</pre>\n",
        "\n",
        "### Comando `run`\n",
        "\n",
        "Chame o comando `run` para executar uma computação do grafo, passando entradas e exibindo (e opcionalmente salvando) as saídas. Aqui está a sintaxe:\n",
        "\n",
        "```\n",
        "usage: saved_model_cli run [-h] --dir DIR --tag_set TAG_SET --signature_def\n",
        "                           SIGNATURE_DEF_KEY [--inputs INPUTS]\n",
        "                           [--input_exprs INPUT_EXPRS]\n",
        "                           [--input_examples INPUT_EXAMPLES] [--outdir OUTDIR]\n",
        "                           [--overwrite] [--tf_debug]\n",
        "```\n",
        "\n",
        "O comando `run` fornece três maneiras de passar entradas para o modelo, mostradas a seguir:\n",
        "\n",
        "- A opção `--inputs` permite que você passe numpy ndarray em arquivos.\n",
        "- A opção `--input_exprs` permite que você passe expressões Python.\n",
        "- A opção `--input_examples` permite que você passe `tf.train.Example`.\n",
        "\n",
        "#### `--inputs`\n",
        "\n",
        "Para passar dados de entrada em arquivos, especifique a opção `--inputs`, que assume o seguinte formato geral:\n",
        "\n",
        "```bsh\n",
        "--inputs <INPUTS>\n",
        "```\n",
        "\n",
        "onde *INPUTS* é um dos seguintes formatos:\n",
        "\n",
        "- `<input_key>=<filename>`\n",
        "- `<input_key>=<filename>[<variable_name>]`\n",
        "\n",
        "Você pode passar múltiplos *INPUTS*. Se você fizer isso, use ponto e vírgula para separar cada uma das *INPUTS*.\n",
        "\n",
        "`saved_model_cli` usa `numpy.load` para carregar o nome do arquivo *filename*. O *filename* pode estar em qualquer um dos seguintes formatos:\n",
        "\n",
        "- `.npy`\n",
        "- `.npz`\n",
        "- formato pickle\n",
        "\n",
        "Um arquivo `.npy` sempre contém um ndarray numpy. Portanto, ao carregar de um arquivo `.npy`, o conteúdo será diretamente atribuído ao tensor de entrada especificado. Se você especificar um *nome_variável* com esse arquivo `.npy`, o *nome_variável* será ignorado e um aviso será emitido.\n",
        "\n",
        "Ao carregar de um arquivo `.npz` (zip), você poderá opcionalmente especificar um *nome_da_variável* para identificar a variável dentro do arquivo zip a ser carregada para a chave do tensor de entrada. Se você não especificar um *variable_name*, a CLI SavedModel verificará se apenas um arquivo está incluído no arquivo zip e o carregará para a chave do tensor de entrada especificada.\n",
        "\n",
        "Ao carregar a partir de um arquivo pickle, se nenhum `variable_name` for especificado entre colchetes, tudo o que estiver dentro do arquivo pickle será passado para a chave de entrada especificada do tensor. Caso contrário, a CLI do SavedModel assumirá que um dicionário está armazenado no arquivo pickle e o valor correspondente ao *nome_variável* será usado.\n",
        "\n",
        "#### `--input_exprs`\n",
        "\n",
        "Para passar entradas via expressões Python, especifique a opção `--input_exprs`. Isto pode ser útil quando você não tem arquivos de dados disponíveis, mas ainda deseja verificar a integridade do modelo com algumas entradas simples que correspondem ao dtype e ao formato dos `SignatureDef` do modelo. Por exemplo:\n",
        "\n",
        "```bsh\n",
        "`<input_key>=[[1],[2],[3]]`\n",
        "```\n",
        "\n",
        "Além das expressões Python, você também pode passar funções numpy. Por exemplo:\n",
        "\n",
        "```bsh\n",
        "`<input_key>=np.ones((32,32,3))`\n",
        "```\n",
        "\n",
        "(Observe que o módulo `numpy` já está disponível para você como `np`.)\n",
        "\n",
        "#### `--input_examples`\n",
        "\n",
        "Para passar objetos `tf.train.Example` como entradas, especifique a opção `--input_examples`. Para cada chave de entrada, é necessária uma lista de dicionários, onde cada dicionário é uma instância de `tf.train.Example`. As chaves do dicionário são as características e os valores são as listas de valores de cada característica. Por exemplo:\n",
        "\n",
        "```bsh\n",
        "`<input_key>=[{\"age\":[22,24],\"education\":[\"BS\",\"MS\"]}]`\n",
        "```\n",
        "\n",
        "#### Salvando a saída\n",
        "\n",
        "Por padrão, a CLI do SavedModel grava a saída em stdout. Se um diretório for passado para a opção `--outdir`, as saídas serão salvas como arquivos `.npy` nomeados com base nas chaves do tensor de saída no diretório fornecido.\n",
        "\n",
        "Use `--overwrite` para sobrescrever arquivos de saída existentes.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "saved_model.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
