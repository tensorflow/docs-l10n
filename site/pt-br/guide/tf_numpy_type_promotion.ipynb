{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjN_IJ8mhJ-4"
      },
      "source": [
        "##### Copyright 2023 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "sY3Ffd83hK3b"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03Pw58e6mTHI"
      },
      "source": [
        "# Promoção de tipo do TF-NumPy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9nPKvxK-_pM"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>     <a target=\"_blank\" href=\"https://www.tensorflow.org/guide/tf_numpy_type_promotion\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver em TensorFlow.org</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/pt-br/guide/tf_numpy_type_promotion.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Executar no Google Colab</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/pt-br/guide/tf_numpy_type_promotion.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver fonte no GitHub</a>\n",
        "</td>\n",
        "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/pt-br/guide/tf_numpy_type_promotion.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Baixar notebook</a>\n",
        "</td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uma-W5v__DYh"
      },
      "source": [
        "## Visão geral\n",
        "\n",
        "Há 4 opções para a promoção de tipo no TensorFlow.\n",
        "\n",
        "- Por padrão, o TensorFlow gera erros em vez de promover tipos para operações de tipo misto.\n",
        "- A execução de `tf.numpy.experimental_enable_numpy_behavior()` faz o TensorFlow trocar para as [regras de promoção de tipo do NumPy](https://www.tensorflow.org/guide/tf_numpy#type_promotion).\n",
        "- **Este documento** descreve duas novas opções que estarão disponíveis no TensorFlow 2.15 (ou atualmente em `tf-nightly`):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vMvEKDFOsau7"
      },
      "outputs": [],
      "source": [
        "!pip install -q tf_nightly"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6hOFBfPsd3y"
      },
      "source": [
        "**Observação**: `experimental_enable_numpy_behavior` muda o comportamento de todo o TensorFlow."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ob1HNwUmYR5b"
      },
      "source": [
        "## Configuração"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AJR558zjAZQu"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow.experimental.numpy as tnp\n",
        "\n",
        "print(\"Using TensorFlow version %s\" % tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6tacoy0DU6e"
      },
      "source": [
        "### Ativando a nova promoção de tipo\n",
        "\n",
        "Para usar a [promoção de tipo semelhante ao JAX](https://jax.readthedocs.io/en/latest/type_promotion.html) no TF-Numpy, especifique `'all'` ou `'safe'` como o modo de conversão dtype ao ativar o comportamento do NumPy para o TensorFlow.\n",
        "\n",
        "Esse novo sistema (com `dtype_conversion_mode=\"all\"`) é associativo, comutativo e facilita controlar a largura do float gerado (não converte automaticamente para floats mais largos). Ele apresenta alguns riscos de overflows e perda de precisão, mas `dtype_conversion_mode=\"safe\"` força você a lidar com esses casos de maneira explícita. Os dois modos são explicados em mais detalhes na [próxima seção](#two_modes)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TfCyofpFDQxm"
      },
      "outputs": [],
      "source": [
        "tnp.experimental_enable_numpy_behavior(dtype_conversion_mode=\"all\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEMXK8-ZWMun"
      },
      "source": [
        "<a name=\"two_modes\">\n",
        "</a>\n",
        "\n",
        "## Dois modos: modo ALL x modo SAFE\n",
        "\n",
        "No novo sistema de promoção de tipo, apresentamos dois modos: `ALL` e `SAFE`. O modo `SAFE` é usado para mitigar as preocupações de promoções \"arriscadas\" que podem resultar na perda de precisão ou no widening de bits."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ULvTWj_KnHU"
      },
      "source": [
        "### Dtypes\n",
        "\n",
        "Vamos usar as seguintes abreviações por questões de brevidade.\n",
        "\n",
        "- `b` significa `tf.bool`\n",
        "- `u8` significa `tf.uint8`\n",
        "- `i16` significa `tf.int16`\n",
        "- `i32` significa `tf.int32`\n",
        "- `bf16` significa `tf.bfloat16`\n",
        "- `f32` significa `tf.float32`\n",
        "- `f64` significa `tf.float64`\n",
        "- `i32*` significa `int` do Python ou `i32` fracamente tipado\n",
        "- `f32*` significa `float` do Python ou `f32` fracamente tipado\n",
        "- `c128*` significa `complex` do Python ou `c128` fracamente tipado\n",
        "\n",
        "O asterisco (*) indica que o tipo correspondente é \"fraco\": esse dtype é temporariamente inferido pelo sistema e pode ceder a outros dtypes. Esse conceito é explicado em mais detalhes [aqui](#weak_tensor)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXZxLCkuzzq3"
      },
      "source": [
        "### Exemplo de operações que perdem precisão\n",
        "\n",
        "No exemplo a seguir, `i32` + `f32` é permitido no modo `ALL`, mas não no modo `SAFE`, devido ao risco de perda da precisão."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y-yeIvstWStL"
      },
      "outputs": [],
      "source": [
        "# i32 + f32 returns a f32 result in ALL mode.\n",
        "tnp.experimental_enable_numpy_behavior(dtype_conversion_mode=\"all\")\n",
        "a = tf.constant(10, dtype = tf.int32)\n",
        "b = tf.constant(5.0, dtype = tf.float32)\n",
        "a + b  # <tf.Tensor: shape=(), dtype=float32, numpy=15.0>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JNNmZow2WY3G"
      },
      "outputs": [],
      "source": [
        "# This promotion is not allowed in SAFE mode.\n",
        "tnp.experimental_enable_numpy_behavior(dtype_conversion_mode=\"safe\")\n",
        "a = tf.constant(10, dtype = tf.int32)\n",
        "b = tf.constant(5.0, dtype = tf.float32)\n",
        "try:\n",
        "  a + b\n",
        "except TypeError as e:\n",
        "   print(f'{type(e)}: {e}')  # TypeError: explicitly specify the dtype or switch to ALL mode."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0x4Qhff0AKS"
      },
      "source": [
        "### Exemplo de operações com widening de bits\n",
        "\n",
        "No exemplo a seguir, `i8` + `u32` é permitido no modo `ALL`, mas não no modo `SAFE`, devido ao widening de bits, ou seja, o uso de mais bits que o número de bits nas entradas. Observe que a semântica da nova promoção de tipo só permite o widening de bits necessário."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Etbv-WoWzUXf"
      },
      "outputs": [],
      "source": [
        "# i8 + u32 returns an i64 result in ALL mode.\n",
        "tnp.experimental_enable_numpy_behavior(dtype_conversion_mode=\"all\")\n",
        "a = tf.constant(10, dtype = tf.int8)\n",
        "b = tf.constant(5, dtype = tf.uint32)\n",
        "a + b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yKRdvtvw0Lvt"
      },
      "outputs": [],
      "source": [
        "# This promotion is not allowed in SAFE mode.\n",
        "tnp.experimental_enable_numpy_behavior(dtype_conversion_mode=\"safe\")\n",
        "a = tf.constant(10, dtype = tf.int8)\n",
        "b = tf.constant(5, dtype = tf.uint32)\n",
        "try:\n",
        "  a + b\n",
        "except TypeError as e:\n",
        "   print(f'{type(e)}: {e}')  # TypeError: explicitly specify the dtype or switch to ALL mode."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yh2BwqUzH3C3"
      },
      "source": [
        "## Um sistema baseado em lattice"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHUnfTPiYVN5"
      },
      "source": [
        "### Lattice de promoção de tipo\n",
        "\n",
        "O novo comportamento da promoção de tipo é determinado pelo seguinte lattice de promoção de tipo:\n",
        "\n",
        "![Lattice de promoção de tipo](https://tensorflow.org/guide/images/new_type_promotion/type_promotion_lattice.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QykluwRyDDle"
      },
      "source": [
        "Mais especificamente, a promoção entre qualquer dois tipos é determinada ao encontrar o primeiro filho em comum de dois nós (incluindo os próprios nós).\n",
        "\n",
        "Por exemplo, no diagrama acima, o primeiro filho em comum de `i8` e `i32` é `i32`, porque os dois nós se encontram pela primeira vez em `i32` ao seguir a direção das setas.\n",
        "\n",
        "De maneira semelhante a outro exemplo, o tipo de promoção de resultado entre `u64` e `f16` seria `f16`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nthziRHaDAUY"
      },
      "source": [
        "<a name=\"promotion_table\">\n",
        "</a>\n",
        "\n",
        "### Tabela de promoção de tipo\n",
        "\n",
        "Ao seguir o lattice, é gerada a tabela de promoção binária abaixo:\n",
        "\n",
        "**Observação**: o modo `SAFE` proíbe as células destacadas. O modo `ALL` permite todos os casos.\n",
        "\n",
        "![Tabela de promoção de tipo](https://tensorflow.org/guide/images/new_type_promotion/type_promotion_table.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPDt5QTkucSC"
      },
      "source": [
        "## Vantagens da nova promoção de tipo\n",
        "\n",
        "Adotamos um sistema baseado em lattice semelhante ao JAX para nossa promoção de tipo, que oferece as seguintes vantagens:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUS_b13nue1p"
      },
      "source": [
        "<a name=\"lattice_system_design\">\n",
        "</a>\n",
        "\n",
        "#### Vantagens do sistema baseado em lattice\n",
        "\n",
        "Primeiro, o uso de um sistema baseado em lattice permite três propriedades muito importantes:\n",
        "\n",
        "- Existência: há um tipo de promoção de resultado único para qualquer combinação de tipos.\n",
        "- Comutatividade: `a + b = b + a`\n",
        "- Associatividade: `a + (b + c) = (a + b) = c`\n",
        "\n",
        "Essas três propriedades são fundamentais para construir uma semântica de promoção de tipo consistente e previsível."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sz88hRR6uhls"
      },
      "source": [
        "#### Vantagens do sistema de lattice semelhante ao JAX\n",
        "\n",
        "Outra vantagem crucial do sistema de lattice semelhante ao JAX é que, fora ints não assinados, ele evita todas as promoções maiores do que o necessário. Isso significa que você não pode obter resultados de 64 bits sem entradas de 64 bits. Isso é especialmente vantajoso para trabalhar com aceleradores, já que evita valores de 64 bits desnecessários, o que era frequente na promoção de tipo antiga."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlylb7ieOVbJ"
      },
      "source": [
        "No entanto, isso tem um lado ruim: a promoção de float/número inteiro mista é bastante propensa à perda de precisão. No exemplo abaixo, `i64` + `f16` resulta na promoção de `i64` a `f16`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "abqIkV02OXEF"
      },
      "outputs": [],
      "source": [
        "# The first input is promoted to f16 in ALL mode.\n",
        "tnp.experimental_enable_numpy_behavior(dtype_conversion_mode=\"all\")\n",
        "tf.constant(1, tf.int64) + tf.constant(3.2, tf.float16)  # <tf.Tensor: shape=(), dtype=float16, numpy=4.2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYnh1gZdObfI"
      },
      "source": [
        "Para reduzir essa preocupação, apresentamos um modo `SAFE` que proibirá essas promoções \"arriscadas\".\n",
        "\n",
        "**Observação**: para saber mais sobre as considerações de design ao construir o sistema de lattice, consulte [Design da semântica de promoção de tipo para JAX](https://jax.readthedocs.io/en/latest/jep/9407-type-promotion.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAc7LFV0S2dP"
      },
      "source": [
        "<a name=\"weak_tensor\">\n",
        "</a>\n",
        "\n",
        "## WeakTensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olQ2gsFlS9BH"
      },
      "source": [
        "### Visão geral\n",
        "\n",
        "*Tensores fracos* são tensores \"fracamente tipados\", semelhante a um [conceito no JAX](https://jax.readthedocs.io/en/latest/type_promotion.html#weakly-typed-values-in-jax).\n",
        "\n",
        "O dtype do `WeakTensor` é temporariamente inferido pelo sistema e pode ceder a outros dtypes. Esse conceito é apresentado na nova promoção de tipo para evitar a promoção de tipo indesejada em operações binárias entre valores do TF e valores sem tipo explicitamente especificado pelo usuário, como literais escalares do Python."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYmoFIqZTFtw"
      },
      "source": [
        "No exemplo abaixo, `tf.constant(1.2)` é considerado \"fraco\" porque não tem um dtype específico. Por isso, `tf.constant(1.2)` cede para o tipo `tf.constant(3.1, tf.float16)`, resultando na saída `f16`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eSBv_mzyTE97"
      },
      "outputs": [],
      "source": [
        "tf.constant(1.2) + tf.constant(3.1, tf.float16)  # <tf.Tensor: shape=(), dtype=float16, numpy=4.3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxuqBIFuTm5Z"
      },
      "source": [
        "### Construção do WeakTensor\n",
        "\n",
        "WeakTensors são gerados quando você cria um tensor sem especificar um dtype. Você pode conferir se um Tensor é \"fraco\" ou não ao verificar o atributo weak no final da representação de string do Tensor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7UmunnJ8Tru3"
      },
      "source": [
        "**Primeiro caso**: quando `tf.constant` é chamada com uma entrada sem dtype especificado pelo usuário."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fLEtMluNTsI5"
      },
      "outputs": [],
      "source": [
        "tf.constant(5)  # <tf.Tensor: shape=(), dtype=int32, numpy=5, weak=True>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZQX6MBWHTt__"
      },
      "outputs": [],
      "source": [
        "tf.constant([5.0, 10.0, 3])  # <tf.Tensor: shape=(3,), dtype=float32, numpy=array([ 5., 10.,  3.], dtype=float32), weak=True>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ftsKSC5BTweP"
      },
      "outputs": [],
      "source": [
        "# A normal Tensor is created when dtype arg is specified.\n",
        "tf.constant(5, tf.int32)  # <tf.Tensor: shape=(), dtype=int32, numpy=5>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqhoRy5iTyag"
      },
      "source": [
        "**Segundo caso**: quando uma entrada sem dtype especificado pelo usuário é passada para uma [API compatível com WeakTensors](#weak_tensor_apis)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DuwpgoQJTzE-"
      },
      "outputs": [],
      "source": [
        "tf.math.abs([100.0, 4.0])  # <tf.Tensor: shape=(2,), dtype=float32, numpy=array([100., 4.], dtype=float32), weak=True>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTcoR1xvR39k"
      },
      "source": [
        "##Efeitos da ativação da nova promoção de tipo\n",
        "\n",
        "Confira abaixo uma lista não exaustiva das mudanças resultantes da ativação da nova promoção de tipo.\n",
        "\n",
        "- Resultados de promoção mais consistentes e previsíveis.\n",
        "- Menor risco de widening de bits.\n",
        "- Os métodos mágicos matemáticos do `tf.Tensor` usam a nova promoção de tipo.\n",
        "- `tf.constant` pode retornar `WeakTensor`.\n",
        "- `tf.constant` permite conversões implícitas quando a entrada de um Tensor com um dtype diferente do arg `dtype` é passada.\n",
        "- As operações in-place `tf.Variable` (`assign`, `assign-add` e `assign-sub`) permitem conversões implícitas.\n",
        "- `tnp.array(1)` e `tnp.array(1.0)` retornam um WeakTensor de 32 bits.\n",
        "- `WeakTensor`s serão criados e usados para [ APIs unárias e binárias compatíveis com WeakTensor](#weak_tensor_apis).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KyvonwYcsFX2"
      },
      "source": [
        "### Resultados de promoção mais consistentes e previsíveis\n",
        "\n",
        "O uso de um [sistema baseado em lattice](#lattice_system_design) permite que a nova promoção de tipo produza resultados consistentes e previsíveis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0Z1njfb7lRa"
      },
      "source": [
        "#### Promoção de tipo antiga\n",
        "\n",
        "Com a promoção de tipo antiga, a mudança da ordem das operações produz resultados inconsistentes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M1Ca9v4m7z8e"
      },
      "outputs": [],
      "source": [
        "# Setup\n",
        "tnp.experimental_enable_numpy_behavior(dtype_conversion_mode=\"legacy\")\n",
        "a = np.array(1, dtype=np.int8)\n",
        "b = tf.constant(1)\n",
        "c = np.array(1, dtype=np.float16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WwhTzJ-a4rTc"
      },
      "outputs": [],
      "source": [
        "# (a + b) + c throws an InvalidArgumentError.\n",
        "try:\n",
        "  tf.add(tf.add(a, b), c)\n",
        "except tf.errors.InvalidArgumentError as e:\n",
        "  print(f'{type(e)}: {e}')  # InvalidArgumentError"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d3qDgVYn7ezT"
      },
      "outputs": [],
      "source": [
        "# (b + a) + c returns an i32 result.\n",
        "tf.add(tf.add(b, a), c)  # <tf.Tensor: shape=(), dtype=int32, numpy=3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMH1skEs7oI5"
      },
      "source": [
        "#### Nova promoção de tipo\n",
        "\n",
        "A nova promoção de tipo produz resultados consistentes independentemente da ordem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BOHyJJ8z8uCN"
      },
      "outputs": [],
      "source": [
        "tnp.experimental_enable_numpy_behavior(dtype_conversion_mode=\"all\")\n",
        "a = np.array(1, dtype=np.int8)\n",
        "b = tf.constant(1)\n",
        "c = np.array(1, dtype=np.float16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZUKU70jf7E1l"
      },
      "outputs": [],
      "source": [
        "# (a + b) + c returns a f16 result.\n",
        "tf.add(tf.add(a, b), c)  # <tf.Tensor: shape=(), dtype=float16, numpy=3.0>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YOEycjFx7qDn"
      },
      "outputs": [],
      "source": [
        "# (b + a) + c also returns a f16 result.\n",
        "tf.add(tf.add(b, a), c)  # <tf.Tensor: shape=(), dtype=float16, numpy=3.0>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpGMkm6aJsn6"
      },
      "source": [
        "### Menor risco de widening de bits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxV2AL-U9Grg"
      },
      "source": [
        "#### Promoção de tipo antiga\n",
        "\n",
        "A promoção de tipo antiga frequentemente gerava resultados de 64 bits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7L1pxyvn9MlP"
      },
      "outputs": [],
      "source": [
        "tnp.experimental_enable_numpy_behavior(dtype_conversion_mode=\"legacy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zMJVFdWf4XHp"
      },
      "outputs": [],
      "source": [
        "np.array(3.2, np.float16) + tf.constant(1, tf.int8) + tf.constant(50)  # <tf.Tensor: shape=(), dtype=float64, numpy=54.19921875>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBhUH_wD9Is7"
      },
      "source": [
        "#### Nova promoção de tipo\n",
        "\n",
        "A nova promoção de tipo retorna resultados com o número mínimo de bits necessário."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aJsj2ZyI9T9Y"
      },
      "outputs": [],
      "source": [
        "tnp.experimental_enable_numpy_behavior(dtype_conversion_mode=\"all\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jj0N_Plp4X9l"
      },
      "outputs": [],
      "source": [
        "np.array(3.2, np.float16) + tf.constant(1, tf.int8) + tf.constant(50)  # <tf.Tensor: shape=(), dtype=float16, numpy=54.2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKUx7xe-KZ5O"
      },
      "source": [
        "### Métodos mágicos matemáticos do tf.Tensor\n",
        "\n",
        "Todos os métodos mágicos matemáticos do `tf.Tensor` seguirão a nova promoção de tipo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2c3icBUX4wNl"
      },
      "outputs": [],
      "source": [
        "-tf.constant(5)  # <tf.Tensor: shape=(), dtype=int32, numpy=-5, weak=True>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ydJHQjid45s7"
      },
      "outputs": [],
      "source": [
        "tf.constant(5, tf.int16) - tf.constant(1, tf.float32)  # <tf.Tensor: shape=(), dtype=float32, numpy=4.0>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLbIjIvbKqcU"
      },
      "source": [
        "### Ops in-place de tf.Variable\n",
        "\n",
        "As conversões implícitas serão permitidas nas ops in-place de `tf.Variable`.\n",
        "\n",
        "**Observação**: qualquer promoção que resultar em um dtype diferente do dtype original da variável não será permitida. Isso ocorre porque `tf.Variable` não pode mudar seu dtype."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QsXhyK1h-i5S"
      },
      "outputs": [],
      "source": [
        "tnp.experimental_enable_numpy_behavior(dtype_conversion_mode=\"all\")\n",
        "a = tf.Variable(10, tf.int32)\n",
        "a.assign_add(tf.constant(5, tf.int16))  # <tf.Variable shape=() dtype=int32, numpy=15>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PiA4H-otLDit"
      },
      "source": [
        "### Conversões implícitas de tf.constant\n",
        "\n",
        "Na antiga promoção de tipo, `tf.constant` exigia que um Tensor de entrada tivesse o mesmo dtype que o argumento dtype. No entanto, na nova promoção de tipo, convertemos implicitamente o Tensor para o dtype especificado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ArrQ9Dj0_OR8"
      },
      "outputs": [],
      "source": [
        "tnp.experimental_enable_numpy_behavior(dtype_conversion_mode=\"all\")\n",
        "a = tf.constant(10, tf.int16)\n",
        "tf.constant(a, tf.float32)  # <tf.Tensor: shape=(), dtype=float32, numpy=10.0>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAcK_-XnLWaP"
      },
      "source": [
        "### Array do TF-NumPy\n",
        "\n",
        "`tnp.array` reverte a `i32*` e `f32*` para entradas do Python usando a nova promoção de tipo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K1pZnYNh_ahm"
      },
      "outputs": [],
      "source": [
        "tnp.array(1)  # <tf.Tensor: shape=(), dtype=int32, numpy=1, weak=True>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QoQl2PYP_fMT"
      },
      "outputs": [],
      "source": [
        "tnp.array(1.0)  # <tf.Tensor: shape=(), dtype=int32, numpy=1, weak=True>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wK5DpQ3Pz3k5"
      },
      "source": [
        "##Inferência de tipo da entrada\n",
        "\n",
        "É assim que diferentes tipos de entradas são inferidos na nova promoção de tipo.\n",
        "\n",
        "- `tf.Tensor`: como `tf.Tensor` tem uma propriedade dtype, não realizamos inferência adicional.\n",
        "- Tipos do NumPy: isso inclui tipos como `np.array(1)`, `np.int16(1)` e `np.float`. Como as entradas do NumPy também tem uma propriedade dtype, tomamos a propriedade dtype como o tipo de inferência do resultado. Observe que o NumPy reverte a `i64` e `f64`.\n",
        "- Tipos escalares/aninhados do Python: isso inclui tipos como `1`, `[1, 2, 3]` e `(1.0, 2.0)`.\n",
        "    - `int` do Python é inferido como `i32*`.\n",
        "    - `float` do Python é inferido como `f32*`.\n",
        "    - `complex` do Python é inferido como `c128*`.\n",
        "- Se a entrada não se enquadrar em nenhuma das categorias acima, mas tiver uma propriedade dtype, tomaremos a propriedade dtype como o tipo de inferência do resultado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_SPfalfSPgg"
      },
      "source": [
        "# Leituras adicionais\n",
        "\n",
        "A nova promoção de tipo se assemelha muito à promoção de tipo do JAX-NumPy. Se você quiser saber mais detalhes sobre a nova promoção de tipo e as escolhas de design, confira os recursos abaixo.\n",
        "\n",
        "- [Semântica de promoção de tipo do JAX](https://jax.readthedocs.io/en/latest/type_promotion.html)\n",
        "- [Design da semântica de promoção de tipo para JAX](https://jax.readthedocs.io/en/latest/jep/9407-type-promotion.html)\n",
        "- [Antiga semântica de promoção do TF-NumPy](https://www.tensorflow.org/guide/tf_numpy#type_promotion)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qg5xBbImT31S"
      },
      "source": [
        "# Referências"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjB0CVhVXBfW"
      },
      "source": [
        "<a name=\"weak_tensor_apis\">\n",
        "</a>\n",
        "\n",
        "## APIs compatíveis com WeakTensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GVbqlN9aBS2"
      },
      "source": [
        "Confira abaixo uma lista de APIs compatíveis com `WeakTensor`.\n",
        "\n",
        "Para uma operação unária, isso significa que, se uma entrada sem tipo especificado pelo usuário for passada, ela retornará um `WeakTensor`.\n",
        "\n",
        "Para uma op binária, ela seguirá esta [tabela de promoção](#promotion_table). Ela pode ou não retornar um `WeakTensor` dependendo do resultado da promoção das duas entradas.\n",
        "\n",
        "**Observação**: todas as operações matemáticas (`+`, `-`, `*`, ...) são compatíveis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gi-G68Z8WN2P"
      },
      "source": [
        "- `tf.bitwise.invert`\n",
        "- `tf.clip_by_value`\n",
        "- `tf.debugging.check_numerics`\n",
        "- `tf.expand_dims`\n",
        "- `tf.identity`\n",
        "- `tf.image.adjust_brightness`\n",
        "- `tf.image.adjust_gamma`\n",
        "- `tf.image.extract_patches`\n",
        "- `tf.image.random_brightness`\n",
        "- `tf.image.stateless_random_brightness`\n",
        "- `tf.linalg.diag`\n",
        "- `tf.linalg.diag_part`\n",
        "- `tf.linalg.matmul`\n",
        "- `tf.linalg.matrix_transpose`\n",
        "- `tf.linalg.tensor_diag_part`\n",
        "- `tf.linalg.trace`\n",
        "- `tf.math.abs`\n",
        "- `tf.math.acos`\n",
        "- `tf.math.acosh`\n",
        "- `tf.math.add`\n",
        "- `tf.math.angle`\n",
        "- `tf.math.asin`\n",
        "- `tf.math.asinh`\n",
        "- `tf.math.atan`\n",
        "- `tf.math.atanh`\n",
        "- `tf.math.ceil`\n",
        "- `tf.math.conj`\n",
        "- `tf.math.cos`\n",
        "- `tf.math.cosh`\n",
        "- `tf.math.digamma`\n",
        "- `tf.math.divide_no_nan`\n",
        "- `tf.math.divide`\n",
        "- `tf.math.erf`\n",
        "- `tf.math.erfc`\n",
        "- `tf.math.erfcinv`\n",
        "- `tf.math.erfinv`\n",
        "- `tf.math.exp`\n",
        "- `tf.math.expm1`\n",
        "- `tf.math.floor`\n",
        "- `tf.math.floordiv`\n",
        "- `tf.math.floormod`\n",
        "- `tf.math.imag`\n",
        "- `tf.math.lgamma`\n",
        "- `tf.math.log1p`\n",
        "- `tf.math.log_sigmoid`\n",
        "- `tf.math.log`\n",
        "- `tf.math.multiply_no_nan`\n",
        "- `tf.math.multiply`\n",
        "- `tf.math.ndtri`\n",
        "- `tf.math.negative`\n",
        "- `tf.math.pow`\n",
        "- `tf.math.real`\n",
        "- `tf.math.real`\n",
        "- `tf.math.reciprocal_no_nan`\n",
        "- `tf.math.reciprocal`\n",
        "- `tf.math.reduce_euclidean_norm`\n",
        "- `tf.math.reduce_logsumexp`\n",
        "- `tf.math.reduce_max`\n",
        "- `tf.math.reduce_mean`\n",
        "- `tf.math.reduce_min`\n",
        "- `tf.math.reduce_prod`\n",
        "- `tf.math.reduce_std`\n",
        "- `tf.math.reduce_sum`\n",
        "- `tf.math.reduce_variance`\n",
        "- `tf.math.rint`\n",
        "- `tf.math.round`\n",
        "- `tf.math.rsqrt`\n",
        "- `tf.math.scalar_mul`\n",
        "- `tf.math.sigmoid`\n",
        "- `tf.math.sign`\n",
        "- `tf.math.sin`\n",
        "- `tf.math.sinh`\n",
        "- `tf.math.softplus`\n",
        "- `tf.math.special.bessel_i0`\n",
        "- `tf.math.special.bessel_i0e`\n",
        "- `tf.math.special.bessel_i1`\n",
        "- `tf.math.special.bessel_i1e`\n",
        "- `tf.math.special.bessel_j0`\n",
        "- `tf.math.special.bessel_j1`\n",
        "- `tf.math.special.bessel_k0`\n",
        "- `tf.math.special.bessel_k0e`\n",
        "- `tf.math.special.bessel_k1`\n",
        "- `tf.math.special.bessel_k1e`\n",
        "- `tf.math.special.bessel_y0`\n",
        "- `tf.math.special.bessel_y1`\n",
        "- `tf.math.special.dawsn`\n",
        "- `tf.math.special.expint`\n",
        "- `tf.math.special.fresnel_cos`\n",
        "- `tf.math.special.fresnel_sin`\n",
        "- `tf.math.special.spence`\n",
        "- `tf.math.sqrt`\n",
        "- `tf.math.square`\n",
        "- `tf.math.subtract`\n",
        "- `tf.math.tan`\n",
        "- `tf.math.tanh`\n",
        "- `tf.nn.depth_to_space`\n",
        "- `tf.nn.elu`\n",
        "- `tf.nn.gelu`\n",
        "- `tf.nn.leaky_relu`\n",
        "- `tf.nn.log_softmax`\n",
        "- `tf.nn.relu6`\n",
        "- `tf.nn.relu`\n",
        "- `tf.nn.selu`\n",
        "- `tf.nn.softsign`\n",
        "- `tf.nn.space_to_depth`\n",
        "- `tf.nn.swish`\n",
        "- `tf.ones_like`\n",
        "- `tf.realdiv`\n",
        "- `tf.reshape`\n",
        "- `tf.squeeze`\n",
        "- `tf.stop_gradient`\n",
        "- `tf.transpose`\n",
        "- `tf.truncatediv`\n",
        "- `tf.truncatemod`\n",
        "- `tf.zeros_like`\n",
        "- `tf.experimental.numpy.abs`\n",
        "- `tf.experimental.numpy.absolute`\n",
        "- `tf.experimental.numpy.amax`\n",
        "- `tf.experimental.numpy.amin`\n",
        "- `tf.experimental.numpy.angle`\n",
        "- `tf.experimental.numpy.arange`\n",
        "- `tf.experimental.numpy.arccos`\n",
        "- `tf.experimental.numpy.arccosh`\n",
        "- `tf.experimental.numpy.arcsin`\n",
        "- `tf.experimental.numpy.arcsinh`\n",
        "- `tf.experimental.numpy.arctan`\n",
        "- `tf.experimental.numpy.arctanh`\n",
        "- `tf.experimental.numpy.around`\n",
        "- `tf.experimental.numpy.array`\n",
        "- `tf.experimental.numpy.asanyarray`\n",
        "- `tf.experimental.numpy.asarray`\n",
        "- `tf.experimental.numpy.ascontiguousarray`\n",
        "- `tf.experimental.numpy.average`\n",
        "- `tf.experimental.numpy.bitwise_not`\n",
        "- `tf.experimental.numpy.cbrt`\n",
        "- `tf.experimental.numpy.ceil`\n",
        "- `tf.experimental.numpy.conj`\n",
        "- `tf.experimental.numpy.conjugate`\n",
        "- `tf.experimental.numpy.copy`\n",
        "- `tf.experimental.numpy.cos`\n",
        "- `tf.experimental.numpy.cosh`\n",
        "- `tf.experimental.numpy.cumprod`\n",
        "- `tf.experimental.numpy.cumsum`\n",
        "- `tf.experimental.numpy.deg2rad`\n",
        "- `tf.experimental.numpy.diag`\n",
        "- `tf.experimental.numpy.diagflat`\n",
        "- `tf.experimental.numpy.diagonal`\n",
        "- `tf.experimental.numpy.diff`\n",
        "- `tf.experimental.numpy.empty_like`\n",
        "- `tf.experimental.numpy.exp2`\n",
        "- `tf.experimental.numpy.exp`\n",
        "- `tf.experimental.numpy.expand_dims`\n",
        "- `tf.experimental.numpy.expm1`\n",
        "- `tf.experimental.numpy.fabs`\n",
        "- `tf.experimental.numpy.fix`\n",
        "- `tf.experimental.numpy.flatten`\n",
        "- `tf.experimental.numpy.flip`\n",
        "- `tf.experimental.numpy.fliplr`\n",
        "- `tf.experimental.numpy.flipud`\n",
        "- `tf.experimental.numpy.floor`\n",
        "- `tf.experimental.numpy.full_like`\n",
        "- `tf.experimental.numpy.imag`\n",
        "- `tf.experimental.numpy.log10`\n",
        "- `tf.experimental.numpy.log1p`\n",
        "- `tf.experimental.numpy.log2`\n",
        "- `tf.experimental.numpy.log`\n",
        "- `tf.experimental.numpy.max`\n",
        "- `tf.experimental.numpy.mean`\n",
        "- `tf.experimental.numpy.min`\n",
        "- `tf.experimental.numpy.moveaxis`\n",
        "- `tf.experimental.numpy.nanmean`\n",
        "- `tf.experimental.numpy.negative`\n",
        "- `tf.experimental.numpy.ones_like`\n",
        "- `tf.experimental.numpy.positive`\n",
        "- `tf.experimental.numpy.prod`\n",
        "- `tf.experimental.numpy.rad2deg`\n",
        "- `tf.experimental.numpy.ravel`\n",
        "- `tf.experimental.numpy.real`\n",
        "- `tf.experimental.numpy.reciprocal`\n",
        "- `tf.experimental.numpy.repeat`\n",
        "- `tf.experimental.numpy.reshape`\n",
        "- `tf.experimental.numpy.rot90`\n",
        "- `tf.experimental.numpy.round`\n",
        "- `tf.experimental.numpy.signbit`\n",
        "- `tf.experimental.numpy.sin`\n",
        "- `tf.experimental.numpy.sinc`\n",
        "- `tf.experimental.numpy.sinh`\n",
        "- `tf.experimental.numpy.sort`\n",
        "- `tf.experimental.numpy.sqrt`\n",
        "- `tf.experimental.numpy.square`\n",
        "- `tf.experimental.numpy.squeeze`\n",
        "- `tf.experimental.numpy.std`\n",
        "- `tf.experimental.numpy.sum`\n",
        "- `tf.experimental.numpy.swapaxes`\n",
        "- `tf.experimental.numpy.tan`\n",
        "- `tf.experimental.numpy.tanh`\n",
        "- `tf.experimental.numpy.trace`\n",
        "- `tf.experimental.numpy.transpose`\n",
        "- `tf.experimental.numpy.triu`\n",
        "- `tf.experimental.numpy.vander`\n",
        "- `tf.experimental.numpy.var`\n",
        "- `tf.experimental.numpy.zeros_like`"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "tf_numpy_type_promotion.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
