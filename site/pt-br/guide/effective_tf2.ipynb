{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tce3stUlHN0L"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tuOe1ymfHZPu"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFdPvlXBOdUN"
      },
      "source": [
        "# TensorFlow 2 efetivo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfBg1C5NB3X0"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>     <a target=\"_blank\" href=\"https://www.tensorflow.org/guide/effective_tf2\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver em TensorFlow.org</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/pt-br/guide/effective_tf2.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Executar no Google Colab</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/pt-br/guide/effective_tf2.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver no GitHub</a>\n",
        "</td>\n",
        "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/pt-br/guide/effective_tf2.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Baixar notebook</a>\n",
        "</td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHxb-dlhMIzW"
      },
      "source": [
        "## Visão geral\n",
        "\n",
        "Este guia apresenta uma lista de práticas recomendadas ao escrever código usando o TensorFlow 2 (TF2) e é destinado a usuários que tenham mudado recentemente do TensorFlow 1 (TF1) para o TF2. Confira mais informações sobre como migrar código do TF1 para o TF2 na [seção de migração do guia](https://tensorflow.org/guide/migrate)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUXex9ctTuDB"
      },
      "source": [
        "## Configuração\n",
        "\n",
        "Importe o TensorFlow e outras dependências para os exemplos deste guia."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IqR2PQG4ZaZ0"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ngds9zateIY8"
      },
      "source": [
        "## Recomendações para o TensorFlow 2 idiomático"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3RdHaroMAi4"
      },
      "source": [
        "### Refatore seu código em módulos menores\n",
        "\n",
        "Uma boa prática é refatorar seu código em funções menores que são chamadas conforme necessário. Para ter o melhor desempenho, tente decorar os maiores blocos de computação que você puder em uma `tf.function` (as funções do Python aninhadas chamadas por uma `tf.function` não requerem suas próprias decorações separadas, a menos que você deseje usar configurações diferentes de `jit_compile` para a `tf.function`). Dependendo do seu caso de uso, podem ser diversos passos de treinamento ou até mesmo seu loop de treinamento inteiro. Para inferência, talvez seja um único passo para frente do modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rua1l8et3Evd"
      },
      "source": [
        "### Ajuste a taxa de aprendizado padrão para alguns `tf.keras.optimizer`s\n",
        "\n",
        "<a name=\"optimizer_defaults\"></a>\n",
        "\n",
        "Alguns otimizadores do Keras têm taxas de aprendizados diferentes no TF2. Se você notar uma alteração no comportamento de convergências dos seus modelos, verifique as taxas de aprendizado padrão.\n",
        "\n",
        "Não há mudanças nos otimizadores `optimizers.SGD`, `optimizers.Adam` ou `optimizers.RMSprop`.\n",
        "\n",
        "As seguintes taxas de aprendizado padrão mudaram:\n",
        "\n",
        "- `optimizers.Adagrad`: de `0.01` para `0.001`\n",
        "- `optimizers.Adadelta`: de `1.0` para `0.001`\n",
        "- `optimizers.Adamax`: de `0.002` para `0.001`\n",
        "- `optimizers.Nadam`: de `0.002` para `0.001`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6LfkpsEldEV"
      },
      "source": [
        "### Use `tf.Module`s e camadas do Keras para gerenciar variáveis\n",
        "\n",
        "`tf.Module`s e `tf.keras.layers.Layer`s do Keras oferecem as convenientes propriedades `variables` e `trainable_variables`, que reúnem recursivamente todas as variáveis dependentes. Assim, fica mais fácil gerenciar variáveis localmente, no lugar onde estão sendo usadas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQ2U0rj1oBlc"
      },
      "source": [
        "Os modelos/camadas do Keras herdam de `tf.train.Checkpointable` e estão integrados a `@tf.function`, o que permite fazer o checkpoint ou exportar SavedModels diretamente a partir de objetos do Keras. Você não precisa necessariamente usar a API `Model.fit` do Keras para aproveitar essas integrações.\n",
        "\n",
        "Confira a seção sobre [aprendizado por transferência e ajustes finos](https://www.tensorflow.org/guide/keras/transfer_learning#transfer_learning_fine-tuning_with_a_custom_training_loop) no guia do Keras para aprender a coletar um subconjunto de variáveis relevantes usando o Keras."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j34MsfxWodG6"
      },
      "source": [
        "### Combine `tf.data.Dataset`s e `tf.function`\n",
        "\n",
        "O pacote [TensorFlow Datasets](https://tensorflow.org/datasets) (`tfds`) contém utilitários para carregar datasets pré-definidos como objetos `tf.data.Dataset`. Neste exemplo, você pode carregar o dataset MNIST usando `tfds`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BMgxaLH74_s-"
      },
      "outputs": [],
      "source": [
        "datasets, info = tfds.load(name='mnist', with_info=True, as_supervised=True)\n",
        "mnist_train, mnist_test = datasets['train'], datasets['test']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPJhEuvj5VfR"
      },
      "source": [
        "Em seguida, prepare os dados para o treinamento:\n",
        "\n",
        "- Redimensione cada imagem.\n",
        "- Misture a ordem dos exemplos.\n",
        "- Colete lotes de imagens e rótulos.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "StBRHtJM2S7o"
      },
      "outputs": [],
      "source": [
        "BUFFER_SIZE = 10 # Use a much larger value for real code\n",
        "BATCH_SIZE = 64\n",
        "NUM_EPOCHS = 5\n",
        "\n",
        "\n",
        "def scale(image, label):\n",
        "  image = tf.cast(image, tf.float32)\n",
        "  image /= 255\n",
        "\n",
        "  return image, label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKq14zKKFAdv"
      },
      "source": [
        "Para manter o exemplo curto, corte o dataset para retornar somente 5 lotes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_J-o4YjG2mkM"
      },
      "outputs": [],
      "source": [
        "train_data = mnist_train.map(scale).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "test_data = mnist_test.map(scale).batch(BATCH_SIZE)\n",
        "\n",
        "STEPS_PER_EPOCH = 5\n",
        "\n",
        "train_data = train_data.take(STEPS_PER_EPOCH)\n",
        "test_data = test_data.take(STEPS_PER_EPOCH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XEqdkH54VM6c"
      },
      "outputs": [],
      "source": [
        "image_batch, label_batch = next(iter(train_data))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loTPH2Pz4_Oj"
      },
      "source": [
        "Use a iteração comum do Python ao iterar dados de treinamento que cabem na memória, Caso contrário, `tf.data.Dataset` é a melhor maneira de transmitir dados de treinamento a partir do disco. Os datasets são [iteráveis (e não iteradores)](https://docs.python.org/3/glossary.html#term-iterable) e funcionam como qualquer outro iterável do Python na execução adiantada (eager). Você pode utilizar totalmente os recursos assíncronos de pré-busca/streaming dos datasets ao encapsular seu código em `tf.function`, que substitui uma iteração do Python pelas operações equivalentes de grafo usando o AutoGraph.\n",
        "\n",
        "```python\n",
        "@tf.function\n",
        "def train(model, dataset, optimizer):\n",
        "  for x, y in dataset:\n",
        "    with tf.GradientTape() as tape:\n",
        "      # training=True is only needed if there are layers with different\n",
        "      # behavior during training versus inference (e.g. Dropout).\n",
        "      prediction = model(x, training=True)\n",
        "      loss = loss_fn(prediction, y)\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "```\n",
        "\n",
        "Se você usar a API `Model.fit` do Keras, não precisará se preocupar com a iteração de datasets.\n",
        "\n",
        "```python\n",
        "model.compile(optimizer=optimizer, loss=loss_fn)\n",
        "model.fit(dataset)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSev7vZC5GJB"
      },
      "source": [
        "<a name=\"keras_training_loops\"></a>\n",
        "\n",
        "### Use os loops de treinamento do Keras\n",
        "\n",
        "Se você não precisar de um controle de baixo nível do processo de treinamento, é recomendável usar os métodos integrados do Keras `fit`, `evaluate` e `predict`, que oferecem uma interface uniforme para treinar o modelo, independentemente da implementação (sequencial, funcional ou de subclasse).\n",
        "\n",
        "Veja algumas vantagens desses métodos:\n",
        "\n",
        "- Aceitam matrizes Numpy, geradores Python e `tf.data.Datasets`.\n",
        "- Aplicam regularização e perdas de ativação atuomaticamente.\n",
        "- Têm suporte a `tf.distribute`, em que o código de treinamento permanece o mesmo [independentemente da configuração de hardware](distributed_training.ipynb).\n",
        "- Têm suporte a callables arbitrários, como perdas e métricas.\n",
        "- Têm suporte a callbacks, como `tf.keras.callbacks.TensorBoard`, e a callbacks personalizados.\n",
        "- Têm bom desempenho usando automaticamente os grafos do TensorFlow.\n",
        "\n",
        "Veja um exemplo de treinamento de um modelo usando um `Dataset`. Confira mais detalhes de como isso funciona nos [tutoriais](https://tensorflow.org/tutorials)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uzHFCzd45Rae"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, 3, activation='relu',\n",
        "                           kernel_regularizer=tf.keras.regularizers.l2(0.02),\n",
        "                           input_shape=(28, 28, 1)),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dropout(0.1),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dense(10)\n",
        "])\n",
        "\n",
        "# Model is the full model w/o custom layers\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_data, epochs=NUM_EPOCHS)\n",
        "loss, acc = model.evaluate(test_data)\n",
        "\n",
        "print(\"Loss {}, Accuracy {}\".format(loss, acc))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQTaHTuK5S5A"
      },
      "source": [
        "<a name=\"custom_loop\"></a>\n",
        "\n",
        "### Personalize o treinamento e escreva seu próprio loop\n",
        "\n",
        "Se os modelos do Keras funcionarem para você, mas você precisar de mais flexibilidade e controle do passo de treinamento ou dos loops de treinamento externos, você pode implementar seus próprios passos de treinamento ou até mesmo loops de treinamento inteiros. Saiba mais no guia do Keras sobre [como personalizar `fit`](https://www.tensorflow.org/guide/keras/customizing_what_happens_in_fit).\n",
        "\n",
        "Você também pode implementar diversas coisas como um `tf.keras.callbacks.Callback`.\n",
        "\n",
        "Este método tem muitas das vantagens [mencionadas anteriormente](#keras_training_loops), mas te dá controle do passo de treinamento e até mesmo do loop externo.\n",
        "\n",
        "Existem três passos em um loop de treinamento padrão:\n",
        "\n",
        "1. Fazer a interação de um gerador do Python ou de `tf.data.Dataset` para obter lotes de exemplos.\n",
        "2. Usar `tf.GradientTape` para coletar gradientes.\n",
        "3. Usar um dos otimizadores `tf.keras.optimizers` para aplicar atualizações de peso às variáveis do modelo.\n",
        "\n",
        "Lembre-se:\n",
        "\n",
        "- Sempre inclua um argumento `training` no método `call` de modelos e camadas que são uma subclasse.\n",
        "- Você deve chamar o modelo com o argumento `training` definido corretamente.\n",
        "- Dependendo do uso, as variáveis do modelo podem não existir até que ele seja executado em um lote de dados.\n",
        "- Você precisa tratar alguns aspectos manualmente, como perdas de regularização do modelo.\n",
        "\n",
        "Não há necessidade de executar inicializadores de variáveis ou de adicionar dependências de controle manual. `tf.function` trata as dependências de controle automático e a inicialização de variáveis durante a criação para você."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gQooejfYlQeF"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, 3, activation='relu',\n",
        "                           kernel_regularizer=tf.keras.regularizers.l2(0.02),\n",
        "                           input_shape=(28, 28, 1)),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dropout(0.1),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dense(10)\n",
        "])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(0.001)\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "@tf.function\n",
        "def train_step(inputs, labels):\n",
        "  with tf.GradientTape() as tape:\n",
        "    predictions = model(inputs, training=True)\n",
        "    regularization_loss=tf.math.add_n(model.losses)\n",
        "    pred_loss=loss_fn(labels, predictions)\n",
        "    total_loss=pred_loss + regularization_loss\n",
        "\n",
        "  gradients = tape.gradient(total_loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  for inputs, labels in train_data:\n",
        "    train_step(inputs, labels)\n",
        "  print(\"Finished epoch\", epoch)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WikxMFGgo3oZ"
      },
      "source": [
        "### Use `tf.function` com fluxo de controle do Python\n",
        "\n",
        "`tf.function` fornece uma maneira de converter fluxos de controle dependentes de dados em equivalentes no modo grafo, como `tf.cond` e `tf.while_loop`.\n",
        "\n",
        "Um caso comum de uso de fluxos de controle dependentes de dados são os modelos sequenciais. `tf.keras.layers.RNN` encapsula uma célula de RNN, permitindo que você desdobre a recorrência de maneira estática ou dinâmica. Por exemplo, você poderia implementar novamente o desdobramento dinâmico da seguinte maneira:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n5UebfChRu4T"
      },
      "outputs": [],
      "source": [
        "class DynamicRNN(tf.keras.Model):\n",
        "\n",
        "  def __init__(self, rnn_cell):\n",
        "    super(DynamicRNN, self).__init__(self)\n",
        "    self.cell = rnn_cell\n",
        "\n",
        "  @tf.function(input_signature=[tf.TensorSpec(dtype=tf.float32, shape=[None, None, 3])])\n",
        "  def call(self, input_data):\n",
        "\n",
        "    # [batch, time, features] -> [time, batch, features]\n",
        "    input_data = tf.transpose(input_data, [1, 0, 2])\n",
        "    timesteps =  tf.shape(input_data)[0]\n",
        "    batch_size = tf.shape(input_data)[1]\n",
        "    outputs = tf.TensorArray(tf.float32, timesteps)\n",
        "    state = self.cell.get_initial_state(batch_size = batch_size, dtype=tf.float32)\n",
        "    for i in tf.range(timesteps):\n",
        "      output, state = self.cell(input_data[i], state)\n",
        "      outputs = outputs.write(i, output)\n",
        "    return tf.transpose(outputs.stack(), [1, 0, 2]), state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NhBI_SGKQVIB"
      },
      "outputs": [],
      "source": [
        "lstm_cell = tf.keras.layers.LSTMCell(units = 13)\n",
        "\n",
        "my_rnn = DynamicRNN(lstm_cell)\n",
        "outputs, state = my_rnn(tf.random.normal(shape=[10,20,3]))\n",
        "print(outputs.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "du7bn3NX7iIr"
      },
      "source": [
        "Confira mais informações no [guia de `tf.function`](https://www.tensorflow.org/guide/function)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUAYhgL_NomT"
      },
      "source": [
        "### Métricas e perdas com estilo novo\n",
        "\n",
        "As métricas e perdas são objetos que funcionam em modo adiantado (eager) e em `tf.function`s.\n",
        "\n",
        "Um objeto de perda é chamável e espera (`y_true`, `y_pred`) como argumentos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pf5gcwMzNs8F"
      },
      "outputs": [],
      "source": [
        "cce = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "cce([[1, 0]], [[-1.0,3.0]]).numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a89m-wRfxyfV"
      },
      "source": [
        "#### Use métricas para coletar e exibir dados\n",
        "\n",
        "Você pode usar `tf.metrics` para agregar dados e `tf.summary` para criar um log de resumos e redirecioná-lo para um writer usando um gerenciador de contexto. Os resumos são enviados diretamente para o writer, ou seja, você precisa fornecer o valor `step` no local da chamada.\n",
        "\n",
        "```python\n",
        "summary_writer = tf.summary.create_file_writer('/tmp/summaries')\n",
        "with summary_writer.as_default():\n",
        "  tf.summary.scalar('loss', 0.1, step=42)\n",
        "```\n",
        "\n",
        "Use `tf.metrics` para agregar os dados antes de criar os logs resumos. As métricas são stateful: elas acumulam valores e retornam um resultado cumulativo quando você chama o método `result` (como `Mean.result`). Use `Model.reset_states` para limpar os valores acumulados.\n",
        "\n",
        "```python\n",
        "def train(model, optimizer, dataset, log_freq=10):\n",
        "  avg_loss = tf.keras.metrics.Mean(name='loss', dtype=tf.float32)\n",
        "  for images, labels in dataset:\n",
        "    loss = train_step(model, optimizer, images, labels)\n",
        "    avg_loss.update_state(loss)\n",
        "    if tf.equal(optimizer.iterations % log_freq, 0):\n",
        "      tf.summary.scalar('loss', avg_loss.result(), step=optimizer.iterations)\n",
        "      avg_loss.reset_states()\n",
        "\n",
        "def test(model, test_x, test_y, step_num):\n",
        "  # training=False is only needed if there are layers with different\n",
        "  # behavior during training versus inference (e.g. Dropout).\n",
        "  loss = loss_fn(model(test_x, training=False), test_y)\n",
        "  tf.summary.scalar('loss', loss, step=step_num)\n",
        "\n",
        "train_summary_writer = tf.summary.create_file_writer('/tmp/summaries/train')\n",
        "test_summary_writer = tf.summary.create_file_writer('/tmp/summaries/test')\n",
        "\n",
        "with train_summary_writer.as_default():\n",
        "  train(model, optimizer, dataset)\n",
        "\n",
        "with test_summary_writer.as_default():\n",
        "  test(model, test_x, test_y, optimizer.iterations)\n",
        "```\n",
        "\n",
        "Visualize os resumos gerados apontando o TensorBoard para o diretório de logs de resumos:\n",
        "\n",
        "```shell\n",
        "tensorboard --logdir /tmp/summaries\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tx7FyM_RHwJ"
      },
      "source": [
        "Use a API `tf.summary` para gravar dados de resumo para visualização no TensorBoard. Confira mais informações no <a href=\"https://www.tensorflow.org/tensorboard/migrate#in_tf_2x\" data-md-type=\"link\">guia de `tf.summary`</a>."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HAbA0fKW58CH"
      },
      "outputs": [],
      "source": [
        "# Create the metrics\n",
        "loss_metric = tf.keras.metrics.Mean(name='train_loss')\n",
        "accuracy_metric = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
        "\n",
        "@tf.function\n",
        "def train_step(inputs, labels):\n",
        "  with tf.GradientTape() as tape:\n",
        "    predictions = model(inputs, training=True)\n",
        "    regularization_loss=tf.math.add_n(model.losses)\n",
        "    pred_loss=loss_fn(labels, predictions)\n",
        "    total_loss=pred_loss + regularization_loss\n",
        "\n",
        "  gradients = tape.gradient(total_loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "  # Update the metrics\n",
        "  loss_metric.update_state(total_loss)\n",
        "  accuracy_metric.update_state(labels, predictions)\n",
        "\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  # Reset the metrics\n",
        "  loss_metric.reset_states()\n",
        "  accuracy_metric.reset_states()\n",
        "\n",
        "  for inputs, labels in train_data:\n",
        "    train_step(inputs, labels)\n",
        "  # Get the metric results\n",
        "  mean_loss=loss_metric.result()\n",
        "  mean_accuracy = accuracy_metric.result()\n",
        "\n",
        "  print('Epoch: ', epoch)\n",
        "  print('  loss:     {:.3f}'.format(mean_loss))\n",
        "  print('  accuracy: {:.3f}'.format(mean_accuracy))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bG9AaMzih3eh"
      },
      "source": [
        "#### Nomes de métricas do Keras\n",
        "\n",
        "<a name=\"keras_metric_names\"></a>\n",
        "\n",
        "Os modelos do Keras são consistentes no tratamento de nomes de métricas. Quando você passa uma string na lista de métricas, essa string *exata* é usada como o `name` (nome) da métrica. Esses nomes ficam visíveis no objeto de histórico retornado por `model.fit` e nos logs passados para `keras.callbacks`, que é definido como a string que você passou na lista de métricas. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1iODIsGDgyYd"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    optimizer = tf.keras.optimizers.Adam(0.001),\n",
        "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics = ['acc', 'accuracy', tf.keras.metrics.SparseCategoricalAccuracy(name=\"my_accuracy\")])\n",
        "history = model.fit(train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8oGzs_TlisKJ"
      },
      "outputs": [],
      "source": [
        "history.history.keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaB2z2XIyhcr"
      },
      "source": [
        "### Depuração\n",
        "\n",
        "Use a execução adiantada (eager) para executar o código passo a passo a fim de inspecionar formatos, tipos de dados e valores. Determinadas APIs, como `tf.function`, `tf.keras`, etc., foram concebidas para usar a execução de grafo por questões de desempenho e portabilidade. Ao depurar, use `tf.config.run_functions_eagerly(True)` para utilizar a execução adiantada dentro desse código.\n",
        "\n",
        "Por exemplo:\n",
        "\n",
        "```python\n",
        "@tf.function\n",
        "def f(x):\n",
        "  if x > 0:\n",
        "    import pdb\n",
        "    pdb.set_trace()\n",
        "    x = x + 1\n",
        "  return x\n",
        "\n",
        "tf.config.run_functions_eagerly(True)\n",
        "f(tf.constant(1))\n",
        "```\n",
        "\n",
        "```\n",
        ">>> f()\n",
        "-> x = x + 1\n",
        "(Pdb) l\n",
        "  6     @tf.function\n",
        "  7     def f(x):\n",
        "  8       if x > 0:\n",
        "  9         import pdb\n",
        " 10         pdb.set_trace()\n",
        " 11  ->     x = x + 1\n",
        " 12       return x\n",
        " 13\n",
        " 14     tf.config.run_functions_eagerly(True)\n",
        " 15     f(tf.constant(1))\n",
        "[EOF]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdvGF2FvbBXZ"
      },
      "source": [
        "Isso também funciona dentro dos modelos do Keras e de outras APIs que têm suporte à execução adiantada (eager):\n",
        "\n",
        "```python\n",
        "class CustomModel(tf.keras.models.Model):\n",
        "\n",
        "  @tf.function\n",
        "  def call(self, input_data):\n",
        "    if tf.reduce_mean(input_data) > 0:\n",
        "      return input_data\n",
        "    else:\n",
        "      import pdb\n",
        "      pdb.set_trace()\n",
        "      return input_data // 2\n",
        "\n",
        "\n",
        "tf.config.run_functions_eagerly(True)\n",
        "model = CustomModel()\n",
        "model(tf.constant([-2, -4]))\n",
        "```\n",
        "\n",
        "```\n",
        ">>> call()\n",
        "-> return input_data // 2\n",
        "(Pdb) l\n",
        " 10         if tf.reduce_mean(input_data) > 0:\n",
        " 11           return input_data\n",
        " 12         else:\n",
        " 13           import pdb\n",
        " 14           pdb.set_trace()\n",
        " 15  ->       return input_data // 2\n",
        " 16\n",
        " 17\n",
        " 18     tf.config.run_functions_eagerly(True)\n",
        " 19     model = CustomModel()\n",
        " 20     model(tf.constant([-2, -4]))\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0-F-bvJXKD8"
      },
      "source": [
        "Observações:\n",
        "\n",
        "- Os métodos de `tf.keras.Model`, como `fit`, `evaluate` e `predict`, são executados como [grafos](https://www.tensorflow.org/guide/intro_to_graphs) com `tf.function` por baixo dos panos.\n",
        "\n",
        "- Ao usar `tf.keras.Model.compile`, defina `run_eagerly = True` para desativar a lógica de `Model` de encapsulamento em uma `tf.function`.\n",
        "\n",
        "- Use `tf.data.experimental.enable_debug_mode` para ativar o modo de depuração para `tf.data`. Confira mais detalhes na [documentação da API](https://www.tensorflow.org/api_docs/python/tf/data/experimental/enable_debug_mode).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxa5yKK7bym0"
      },
      "source": [
        "### Não mantenha `tf.Tensors` em seus objetos\n",
        "\n",
        "Esses objetos tensores podem ser criados em uma `tf.function` ou no contexto eager e se comportam de maneira diferente. Sempre use `tf.Tensor`s somente para valores intermediários.\n",
        "\n",
        "Para monitorar o estado, use `tf.Variable`s, pois elas sempre podem ser usadas em ambos os contextos. Confira mais informações no <a href=\"https://www.tensorflow.org/guide/variable\" data-md-type=\"link\">guia de `tf.Variable`</a>.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FdXLLYa2uAyx"
      },
      "source": [
        "## Recursos e leitura adicional\n",
        "\n",
        "- Saiba mais sobre como usar o TF2 nos [guias](https://tensorflow.org/guide) e [tutoriais](https://tensorflow.org/tutorials).\n",
        "\n",
        "- Se você estava usando o TF1.x anteriormente, é altamente recomendável migrar seu código para o TF2. Saiba mais nos [guias de migração](https://tensorflow.org/guide/migrate)."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "effective_tf2.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
