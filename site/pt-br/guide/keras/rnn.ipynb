{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b518b04cbfe0"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "906e07f6e562"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ca65cda94c8"
      },
      "source": [
        "# Redes Neurais Recorrentes (RNN) com Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1e4938db0e55"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>     <a target=\"_blank\" href=\"https://www.tensorflow.org/guide/keras/rnn\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Veja em TensorFlow.org</a> </td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/pt-br/guide/keras/rnn.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Executar no Google Colab</a> </td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/pt-br/guide/keras/rnn.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver fonte no GitHub</a> </td>\n",
        "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/pt-br/guide/keras/rnn.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Baixar notebook</a> </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6873211b02d4"
      },
      "source": [
        "## Introdução\n",
        "\n",
        "Redes neurais recorrentes (RNN - Recurrent neural networks) são uma classe de redes neurais poderosas para modelar dados sequenciais, tais como séries temporais ou linguagem natural.\n",
        "\n",
        "Esquematicamente, uma camada RNN usa um loop `for` para iterar sobre os timesteps de uma sequência, enquanto mantém um estado interno que codifica informações sobre os timesteps vistos até o momento.\n",
        "\n",
        "A API Keras RNN foi projetada com foco em:\n",
        "\n",
        "- **Facilidade de uso**: as camadas incorporadas `keras.layers.RNN`, `keras.layers.LSTM`, `keras.layers.GRU` permitem que você construa rapidamente modelos recorrentes sem ter que tomar decisões difíceis de configuração.\n",
        "\n",
        "- **Facilidade de personalização**: Você também pode definir sua própria camada de célula RNN (a parte interna do loop `for` ) com comportamento personalizado e usá-la com a camada `keras.layers.RNN` genérica (o próprio loop `for`). Isto permite que você crie rapidamente protótipos de diferentes ideias de pesquisa de maneira flexível com o mínimo de código."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3600ee25c8e"
      },
      "source": [
        "## Configuração"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "71c626bbac35"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4041a2e9b310"
      },
      "source": [
        "## Camadas RNN integradas: um exemplo simples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98e0c38cf95d"
      },
      "source": [
        "Existem três camadas RNN integradas no Keras:\n",
        "\n",
        "1. `keras.layers.SimpleRNN`, uma RNN totalmente conectada onde a saída do timestep anterior deve ser alimentada ao próximo timestep.\n",
        "\n",
        "2. `keras.layers.GRU`, proposta pela primeira vez em [Cho et al., 2014](https://arxiv.org/abs/1406.1078).\n",
        "\n",
        "3. `keras.layers.LSTM`, proposta pela primeira vez em [Hochreiter &amp; Schmidhuber, 1997](https://www.bioinf.jku.at/publications/older/2604.pdf).\n",
        "\n",
        "No início de 2015, foram criadas as primeiras implementações Python de código aberto reutilizáveis ​​de LSTM e GRU do Keras.\n",
        "\n",
        "Aqui está um exemplo simples de um modelo `Sequential` que processa sequências de números inteiros, incorpora cada número inteiro em um vetor de 64 dimensões e, em seguida, processa a sequência de vetores usando uma camada `LSTM`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a5617759e54e"
      },
      "outputs": [],
      "source": [
        "model = keras.Sequential()\n",
        "# Add an Embedding layer expecting input vocab of size 1000, and\n",
        "# output embedding dimension of size 64.\n",
        "model.add(layers.Embedding(input_dim=1000, output_dim=64))\n",
        "\n",
        "# Add a LSTM layer with 128 internal units.\n",
        "model.add(layers.LSTM(128))\n",
        "\n",
        "# Add a Dense layer with 10 units.\n",
        "model.add(layers.Dense(10))\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cb8ef33660a0"
      },
      "source": [
        "RNNs integrados oferecem suporte a vários recursos úteis:\n",
        "\n",
        "- Dropout recorrente, por meio dos argumentos `dropout` e `recurrent_dropout`\n",
        "- Capacidade de processar uma sequência de entrada ao contrário, através do argumento `go_backwards`\n",
        "- Desenrolamento de loop (que pode causar uma grande aceleração ao processar sequências curtas na CPU), por meio do argumento `unroll`\n",
        "- ...e mais.\n",
        "\n",
        "Para obter mais informações, consulte a [documentação da API RNN](https://keras.io/api/layers/recurrent_layers/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43aa4e4f344d"
      },
      "source": [
        "## Saídas e estados\n",
        "\n",
        "Por padrão, a saída de uma camada RNN contém um único vetor por amostra. Este vetor é a saída da célula RNN correspondente ao último timestep, contendo informações sobre toda a sequência de entrada. O formato desta saída é `(batch_size, units)` onde `units` corresponde ao argumento `units` passado para o construtor da camada.\n",
        "\n",
        "Uma camada RNN também pode retornar toda a sequência de saídas para cada amostra (um vetor por timestep por amostra), se você definir `return_sequences=True`. O formato dessa saída é `(batch_size, timesteps, units)`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3294dec91e4"
      },
      "outputs": [],
      "source": [
        "model = keras.Sequential()\n",
        "model.add(layers.Embedding(input_dim=1000, output_dim=64))\n",
        "\n",
        "# The output of GRU will be a 3D tensor of shape (batch_size, timesteps, 256)\n",
        "model.add(layers.GRU(256, return_sequences=True))\n",
        "\n",
        "# The output of SimpleRNN will be a 2D tensor of shape (batch_size, 128)\n",
        "model.add(layers.SimpleRNN(128))\n",
        "\n",
        "model.add(layers.Dense(10))\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "266812a04bb2"
      },
      "source": [
        "Além disso, uma camada RNN pode retornar seu(s) estado(s) interno(s) final(ais). Os estados retornados podem ser usados ​​para retomar a execução da RNN posteriormente ou [para inicializar outra RNN](https://arxiv.org/abs/1409.3215). Essa configuração é frequentemente usada no modelo sequence-to-sequence do encoder-decoder, em que o estado final do encoder é usado como o estado inicial do decoder.\n",
        "\n",
        "Para configurar uma camada RNN para retornar seu estado interno, defina o parâmetro `return_state` como `True` ao criar a camada. Observe que `LSTM` possui 2 tensores de estado, mas `GRU` possui apenas um.\n",
        "\n",
        "Para configurar o estado inicial da camada, basta chamar a camada com o argumento de palavra-chave adicional `initial_state`. Observe que o formato do estado precisa corresponder ao tamanho da unidade da camada, como no exemplo abaixo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ece412e6afbe"
      },
      "outputs": [],
      "source": [
        "encoder_vocab = 1000\n",
        "decoder_vocab = 2000\n",
        "\n",
        "encoder_input = layers.Input(shape=(None,))\n",
        "encoder_embedded = layers.Embedding(input_dim=encoder_vocab, output_dim=64)(\n",
        "    encoder_input\n",
        ")\n",
        "\n",
        "# Return states in addition to output\n",
        "output, state_h, state_c = layers.LSTM(64, return_state=True, name=\"encoder\")(\n",
        "    encoder_embedded\n",
        ")\n",
        "encoder_state = [state_h, state_c]\n",
        "\n",
        "decoder_input = layers.Input(shape=(None,))\n",
        "decoder_embedded = layers.Embedding(input_dim=decoder_vocab, output_dim=64)(\n",
        "    decoder_input\n",
        ")\n",
        "\n",
        "# Pass the 2 states to a new LSTM layer, as initial state\n",
        "decoder_output = layers.LSTM(64, name=\"decoder\")(\n",
        "    decoder_embedded, initial_state=encoder_state\n",
        ")\n",
        "output = layers.Dense(10)(decoder_output)\n",
        "\n",
        "model = keras.Model([encoder_input, decoder_input], output)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e97a845a372a"
      },
      "source": [
        "## Camadas RNN e células RNN\n",
        "\n",
        "Além das camadas RNN integradas, a API RNN também fornece APIs em nível de célula. Ao contrário das camadas RNN, que processam lotes inteiros de sequências de entrada, a célula RNN processa apenas um único timestep.\n",
        "\n",
        "A célula é o interior do loop `for` de uma camada RNN. Envolver uma célula dentro de uma camada `keras.layers.RNN` fornece uma camada capaz de processar lotes de sequências, por exemplo `RNN(LSTMCell(10))`.\n",
        "\n",
        "Matematicamente, `RNN(LSTMCell(10))` produz o mesmo resultado que `LSTM(10)`. Na verdade, a implementação dessa camada no TF v1.x foi apenas criar a célula RNN correspondente e empacotá-la numa camada RNN. No entanto, usar as camadas integradas `GRU` e `LSTM` permite o uso de CuDNN e você pode assim obter um melhor desempenho.\n",
        "\n",
        "Existem três células RNN integradas, cada uma delas correspondendo à camada RNN correspondente.\n",
        "\n",
        "- `keras.layers.SimpleRNNCell` corresponde à camada `SimpleRNN`.\n",
        "\n",
        "- `keras.layers.GRUCell` corresponde à camada `GRU`.\n",
        "\n",
        "- `keras.layers.LSTMCell` corresponde à camada `LSTM`.\n",
        "\n",
        "A abstração de célula, juntamente com a classe genérica `keras.layers.RNN`, facilita muito a implementação de arquiteturas RNN customizadas para sua pesquisa."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60b3b721d500"
      },
      "source": [
        "## Statefulness entre lotes\n",
        "\n",
        "Ao processar sequências muito longas (possivelmente infinitas), você talvez queira usar o padrão **statefulness entre lotes** (cross-batch statefulness).\n",
        "\n",
        "Geralmente, o estado interno de uma camada RNN é reiniciado toda vez que ela encontra um novo lote (ou seja, cada amostra vista pela camada é considerada independente do seu passado). A camada só irá preserver um estado enquanto processa uma determinada amostra.\n",
        "\n",
        "No entanto, se você tiver sequências muito longas, é útil dividi-las em sequências mais curtas e alimentar essas sequências mais curtas sequencialmente numa camada RNN sem reiniciar o estado da camada. Dessa forma, a camada pode reter informações sobre toda a sequência, mesmo que esteja vendo apenas uma subsequência de cada vez.\n",
        "\n",
        "Você pode fazer isso definindo `stateful=True` no construtor.\n",
        "\n",
        "Se você tiver uma sequência `s = [t0, t1, ... t1546, t1547]` , você poderia dividi-la da forma a seguir:\n",
        "\n",
        "```\n",
        "s1 = [t0, t1, ... t100]\n",
        "s2 = [t101, ... t201]\n",
        "...\n",
        "s16 = [t1501, ... t1547]\n",
        "```\n",
        "\n",
        "E depois você poderia processá-la da usando:\n",
        "\n",
        "```python\n",
        "lstm_layer = layers.LSTM(64, stateful=True)\n",
        "for s in sub_sequences:\n",
        "  output = lstm_layer(s)\n",
        "```\n",
        "\n",
        "Quando quiser limpar o estado, você pode usar `layer.reset_states()`.\n",
        "\n",
        "> Observação: Nesta configuração, a amostra `i` em um determinado lote é considerada a continuação da amostra `i` do lote anterior. Isto significa que todos os lotes devem conter o mesmo número de amostras (tamanho do lote). Por exemplo, se um lote contém `[sequence_A_from_t0_to_t100, sequence_B_from_t0_to_t100]`, o próximo lote deve conter `[sequence_A_from_t101_to_t200, sequence_B_from_t101_to_t200]`.\n",
        "\n",
        "Aqui está um exemplo completo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "19e72be49a42"
      },
      "outputs": [],
      "source": [
        "paragraph1 = np.random.random((20, 10, 50)).astype(np.float32)\n",
        "paragraph2 = np.random.random((20, 10, 50)).astype(np.float32)\n",
        "paragraph3 = np.random.random((20, 10, 50)).astype(np.float32)\n",
        "\n",
        "lstm_layer = layers.LSTM(64, stateful=True)\n",
        "output = lstm_layer(paragraph1)\n",
        "output = lstm_layer(paragraph2)\n",
        "output = lstm_layer(paragraph3)\n",
        "\n",
        "# reset_states() will reset the cached state to the original initial_state.\n",
        "# If no initial_state was provided, zero-states will be used by default.\n",
        "lstm_layer.reset_states()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ec7c316b19a1"
      },
      "source": [
        "### Reuso de estado em RNNs\n",
        "\n",
        "<a id=\"rnn_state_reuse\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cb7a8ac464a"
      },
      "source": [
        "Os estados registrados da camada RNN não são incluídos em `layer.weights()`. Se quiser reutilizar o estado de uma camada RNN, você pode recuperar o valor dos estados por `layer.states` e usá-lo como o estado inicial para uma nova camada através da API funcional Keras como `new_layer(inputs, initial_state=layer.states)`, ou através da subclasse de um modelo.\n",
        "\n",
        "Observe que o modelo sequencial pode não ser usado neste caso, pois ele suporta apenas camadas com entrada e saída únicas, a entrada adicional do estado inicial faz com que seja impossível usá-lo aqui."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "009c5b393adf"
      },
      "outputs": [],
      "source": [
        "paragraph1 = np.random.random((20, 10, 50)).astype(np.float32)\n",
        "paragraph2 = np.random.random((20, 10, 50)).astype(np.float32)\n",
        "paragraph3 = np.random.random((20, 10, 50)).astype(np.float32)\n",
        "\n",
        "lstm_layer = layers.LSTM(64, stateful=True)\n",
        "output = lstm_layer(paragraph1)\n",
        "output = lstm_layer(paragraph2)\n",
        "\n",
        "existing_state = lstm_layer.states\n",
        "\n",
        "new_lstm_layer = layers.LSTM(64)\n",
        "new_output = new_lstm_layer(paragraph3, initial_state=existing_state)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66c1d7f1ccba"
      },
      "source": [
        "## RNNs bidirecionais\n",
        "\n",
        "Para sequências que não sejam séries temporais (por exemplo, texto), é comum que um modelo RNN tenha um desempenho melhor se não apenas processar a sequência do início ao fim, mas também de trás para frente. Por exemplo, para prever a próxima palavra numa frase, geralmente é útil conhecer o contexto em torno da palavra, não apenas as palavras que vêm antes dela.\n",
        "\n",
        "Keras fornece uma API prática para você construir RNNs bidirecionais desse tipo: o wrapper `keras.layers.Bidirectional`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8cea1781a0c2"
      },
      "outputs": [],
      "source": [
        "model = keras.Sequential()\n",
        "\n",
        "model.add(\n",
        "    layers.Bidirectional(layers.LSTM(64, return_sequences=True), input_shape=(5, 10))\n",
        ")\n",
        "model.add(layers.Bidirectional(layers.LSTM(32)))\n",
        "model.add(layers.Dense(10))\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dab57c97a566"
      },
      "source": [
        "Nos bastidores, `Bidirectional` copiará a camada RNN passada e inverterá o campo `go_backwards` da camada recém-copiada, para processar as entradas na ordem inversa.\n",
        "\n",
        "A saída da RNN `Bidirectional` será, por padrão, a concatenação da saída da camada \"para frente\" e da saída da camada \"para trás\". Se você precisar de um comportamento de fusão diferente, por exemplo, a concatenação, altere o parâmetro `merge_mode` no construtor do wrapper `Bidirectional`. Para mais detalhes sobre `Bidirectional`, consulte a [documentação da API](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Bidirectional/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18a254dfaa73"
      },
      "source": [
        "## Otimização de desempenho e kernels CuDNN\n",
        "\n",
        "No TensorFlow 2.0, as camadas LSTM e GRU incorporadas foram atualizadas para aproveitar os kernels CuDNN por padrão quando uma GPU está disponível. Com essa alteração, as camadas anteriores `keras.layers.CuDNNLSTM/CuDNNGRU` foram descontinuadas e você pode criar seu modelo sem se preocupar com o hardware em que ele será executado.\n",
        "\n",
        "Já que o kernel CuDNN foi construído levando em conta determinadas suposições, isto significa que a camada **não poderá usar o kernel CuDNN se você alterar os padrões das camadas LSTM ou GRU integradas**. Por exemplo:\n",
        "\n",
        "- Alterar a função `activation` de `tanh` para outra coisa.\n",
        "- Alterar a função `recurrent_activation` de `sigmoid` para outra coisa.\n",
        "- Usar `recurrent_dropout` &gt; 0.\n",
        "- Definir `unroll` como True, o que força o LSTM/GRU a decompor o `tf.while_loop` interno em um loop `for` desenrolado.\n",
        "- Definir `use_bias` como False.\n",
        "- Usar mascaramento quando os dados de entrada não forem preenchidos estritamente à direita (se a máscara corresponder a dados preenchidos estritamente à direita, o CuDNN ainda pode ser usado. Este é o caso mais comum).\n",
        "\n",
        "Para obter uma lista detalhada de restrições, consulte a documentação das camadas [LSTM](https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM/) e [GRU](https://www.tensorflow.org/api_docs/python/tf/keras/layers/GRU/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fb8de09c4343"
      },
      "source": [
        "### Usando kernels CuDNN quando disponíveis\n",
        "\n",
        "Vamos construir um modelo LSTM simples para demonstrar a diferença de desempenho.\n",
        "\n",
        "Usaremos como sequências de entrada a sequência de linhas de dígitos MNIST (tratando cada linha de pixels como um timestep) e faremos a previsão do rótulo do dígito."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e88aab9e73c7"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "# Each MNIST image batch is a tensor of shape (batch_size, 28, 28).\n",
        "# Each input sequence will be of size (28, 28) (height is treated like time).\n",
        "input_dim = 28\n",
        "\n",
        "units = 64\n",
        "output_size = 10  # labels are from 0 to 9\n",
        "\n",
        "# Build the RNN model\n",
        "def build_model(allow_cudnn_kernel=True):\n",
        "    # CuDNN is only available at the layer level, and not at the cell level.\n",
        "    # This means `LSTM(units)` will use the CuDNN kernel,\n",
        "    # while RNN(LSTMCell(units)) will run on non-CuDNN kernel.\n",
        "    if allow_cudnn_kernel:\n",
        "        # The LSTM layer with default options uses CuDNN.\n",
        "        lstm_layer = keras.layers.LSTM(units, input_shape=(None, input_dim))\n",
        "    else:\n",
        "        # Wrapping a LSTMCell in a RNN layer will not use CuDNN.\n",
        "        lstm_layer = keras.layers.RNN(\n",
        "            keras.layers.LSTMCell(units), input_shape=(None, input_dim)\n",
        "        )\n",
        "    model = keras.models.Sequential(\n",
        "        [\n",
        "            lstm_layer,\n",
        "            keras.layers.BatchNormalization(),\n",
        "            keras.layers.Dense(output_size),\n",
        "        ]\n",
        "    )\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcde82cb14d6"
      },
      "source": [
        "Vamos carregar o dataset MNIST:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "98292f8e71a9"
      },
      "outputs": [],
      "source": [
        "mnist = keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "sample, sample_label = x_train[0], y_train[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "443e5458284f"
      },
      "source": [
        "Vamos criar uma instância de modelo e treiná-la.\n",
        "\n",
        "Escolhemos `sparse_categorical_crossentropy` como a função de perda para o modelo. A saída do modelo tem formato de `[batch_size, 10]`. O alvo para o modelo é um vetor inteiro, cada um dos inteiros está no intervalo de 0 a 9."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f85b57b010e5"
      },
      "outputs": [],
      "source": [
        "model = build_model(allow_cudnn_kernel=True)\n",
        "\n",
        "model.compile(\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    optimizer=\"sgd\",\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "\n",
        "model.fit(\n",
        "    x_train, y_train, validation_data=(x_test, y_test), batch_size=batch_size, epochs=1\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99ea5495e375"
      },
      "source": [
        "Agora, vamos comparar com um modelo que não usa o kernel CuDNN:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d4bdff02e617"
      },
      "outputs": [],
      "source": [
        "noncudnn_model = build_model(allow_cudnn_kernel=False)\n",
        "noncudnn_model.set_weights(model.get_weights())\n",
        "noncudnn_model.compile(\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    optimizer=\"sgd\",\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "noncudnn_model.fit(\n",
        "    x_train, y_train, validation_data=(x_test, y_test), batch_size=batch_size, epochs=1\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90fc64fbd4ea"
      },
      "source": [
        "Ao rodar numa máquina com GPU NVIDIA e CuDNN instalados, o modelo construído com CuDNN pode ser treinado com muito mais rapidez em comparação com o modelo que usa o kernel TensorFlow comum.\n",
        "\n",
        "O mesmo modelo habilitado para CuDNN também pode ser usado para rodar inferências num ambiente CPU-only. A anotação `tf.device` abaixo está apenas forçando o posicionamento do dispositivo. O modelo será executado na CPU por padrão se nenhuma GPU estiver disponível.\n",
        "\n",
        "Você simplesmente não precisa mais se preocupar com o hardware onde está executando. Não é legal?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7e33c62b6029"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "with tf.device(\"CPU:0\"):\n",
        "    cpu_model = build_model(allow_cudnn_kernel=True)\n",
        "    cpu_model.set_weights(model.get_weights())\n",
        "    result = tf.argmax(cpu_model.predict_on_batch(tf.expand_dims(sample, 0)), axis=1)\n",
        "    print(\n",
        "        \"Predicted result is: %s, target result is: %s\" % (result.numpy(), sample_label)\n",
        "    )\n",
        "    plt.imshow(sample, cmap=plt.get_cmap(\"gray\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2f940b73a2a6"
      },
      "source": [
        "## RNNs com entradas list/dict ou entradas aninhadas\n",
        "\n",
        "Estruturas aninhadas permitem que os implementadores incluam mais informações num único timestep. Por exemplo, um quadro de vídeo pode ter entradas de áudio e vídeo simultâneas. A forma de dados neste caso poderia ser:\n",
        "\n",
        "`[batch, timestep, {\"video\": [height, width, channel], \"audio\": [frequency]}]`\n",
        "\n",
        "Em outro exemplo, dados de caligrafia poderiam armazenar as coordenadas x e y para a posição atual da caneta, assim como informações de pressão da caneta sobre o papel. Assim, a representação dos dados poderia ser:\n",
        "\n",
        "`[batch, timestep, {\"location\": [x, y], \"pressure\": [force]}]`\n",
        "\n",
        "O código a seguir mostra um exemplo de como criar uma célula RNN personalizada que aceite essas entradas estruturadas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f78dc4c1c516"
      },
      "source": [
        "### Defina uma célula personalizada que suporte entrada/saída aninhada"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "199faf57f0c5"
      },
      "source": [
        "Veja [Criando novas camadas e modelos através de subclasses](https://www.tensorflow.org/guide/keras/custom_layers_and_models/) para mais detalhes sobre como escrever suas próprias camadas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "451cfd5f0cc4"
      },
      "outputs": [],
      "source": [
        "class NestedCell(keras.layers.Layer):\n",
        "    def __init__(self, unit_1, unit_2, unit_3, **kwargs):\n",
        "        self.unit_1 = unit_1\n",
        "        self.unit_2 = unit_2\n",
        "        self.unit_3 = unit_3\n",
        "        self.state_size = [tf.TensorShape([unit_1]), tf.TensorShape([unit_2, unit_3])]\n",
        "        self.output_size = [tf.TensorShape([unit_1]), tf.TensorShape([unit_2, unit_3])]\n",
        "        super(NestedCell, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shapes):\n",
        "        # expect input_shape to contain 2 items, [(batch, i1), (batch, i2, i3)]\n",
        "        i1 = input_shapes[0][1]\n",
        "        i2 = input_shapes[1][1]\n",
        "        i3 = input_shapes[1][2]\n",
        "\n",
        "        self.kernel_1 = self.add_weight(\n",
        "            shape=(i1, self.unit_1), initializer=\"uniform\", name=\"kernel_1\"\n",
        "        )\n",
        "        self.kernel_2_3 = self.add_weight(\n",
        "            shape=(i2, i3, self.unit_2, self.unit_3),\n",
        "            initializer=\"uniform\",\n",
        "            name=\"kernel_2_3\",\n",
        "        )\n",
        "\n",
        "    def call(self, inputs, states):\n",
        "        # inputs should be in [(batch, input_1), (batch, input_2, input_3)]\n",
        "        # state should be in shape [(batch, unit_1), (batch, unit_2, unit_3)]\n",
        "        input_1, input_2 = tf.nest.flatten(inputs)\n",
        "        s1, s2 = states\n",
        "\n",
        "        output_1 = tf.matmul(input_1, self.kernel_1)\n",
        "        output_2_3 = tf.einsum(\"bij,ijkl->bkl\", input_2, self.kernel_2_3)\n",
        "        state_1 = s1 + output_1\n",
        "        state_2_3 = s2 + output_2_3\n",
        "\n",
        "        output = (output_1, output_2_3)\n",
        "        new_states = (state_1, state_2_3)\n",
        "\n",
        "        return output, new_states\n",
        "\n",
        "    def get_config(self):\n",
        "        return {\"unit_1\": self.unit_1, \"unit_2\": unit_2, \"unit_3\": self.unit_3}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51355b4089d2"
      },
      "source": [
        "### Construa um modelo RNN com entrada/saída aninhada\n",
        "\n",
        "Vamos construir um modelo Keras que use uma camada `keras.layers.RNN` e a célula personalizada que acabamos de definir."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b2eba7a248eb"
      },
      "outputs": [],
      "source": [
        "unit_1 = 10\n",
        "unit_2 = 20\n",
        "unit_3 = 30\n",
        "\n",
        "i1 = 32\n",
        "i2 = 64\n",
        "i3 = 32\n",
        "batch_size = 64\n",
        "num_batches = 10\n",
        "timestep = 50\n",
        "\n",
        "cell = NestedCell(unit_1, unit_2, unit_3)\n",
        "rnn = keras.layers.RNN(cell)\n",
        "\n",
        "input_1 = keras.Input((None, i1))\n",
        "input_2 = keras.Input((None, i2, i3))\n",
        "\n",
        "outputs = rnn((input_1, input_2))\n",
        "\n",
        "model = keras.models.Model([input_1, input_2], outputs)\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "452a99c63b7c"
      },
      "source": [
        "### Treine o modelo com dados gerados aleatoriamente\n",
        "\n",
        "Já que não há um bom candidato a dataset para este modelo, usamos dados aleatórios do Numpy para demonstração."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3987993cb7be"
      },
      "outputs": [],
      "source": [
        "input_1_data = np.random.random((batch_size * num_batches, timestep, i1))\n",
        "input_2_data = np.random.random((batch_size * num_batches, timestep, i2, i3))\n",
        "target_1_data = np.random.random((batch_size * num_batches, unit_1))\n",
        "target_2_data = np.random.random((batch_size * num_batches, unit_2, unit_3))\n",
        "input_data = [input_1_data, input_2_data]\n",
        "target_data = [target_1_data, target_2_data]\n",
        "\n",
        "model.fit(input_data, target_data, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b51e87780b0f"
      },
      "source": [
        "Com a camada Keras `keras.layers.RNN` você só precisa definir a lógica matemática para uma etapa individual dentro da sequência, e a camada `keras.layers.RNN` cuidará da iteração da sequência para você. É uma maneira incrivelmente poderosa de prototipar rapidamente novos tipos de RNNs (por exemplo, uma variante LSTM).\n",
        "\n",
        "Para mais informações, consulte os [documentos da API](https://https://www.tensorflow.org/api_docs/python/tf/keras/layers/RNN/)."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "rnn.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
