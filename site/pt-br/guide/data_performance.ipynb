{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tce3stUlHN0L"
      },
      "source": [
        "##### Copyright 2019 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tuOe1ymfHZPu"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFdPvlXBOdUN"
      },
      "source": [
        "# Desempenho melhor com a API tf.data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfBg1C5NB3X0"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td data-parent-segment-id=\"13650222\" data-segment-approved=\"false\">     <a target=\"_blank\" href=\"https://www.tensorflow.org/guide/data_performance\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver em TensorFlow.org</a>\n",
        "</td>\n",
        "  <td data-parent-segment-id=\"13650223\" data-segment-approved=\"false\">     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/pt-br/guide/data_performance.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Executar no Google Colab</a>\n",
        "</td>\n",
        "  <td data-parent-segment-id=\"13650224\" data-segment-approved=\"false\">     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/pt-br/guide/data_performance.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver fonte no GitHub</a>\n",
        "</td>\n",
        "  <td data-parent-segment-id=\"13650225\" data-segment-approved=\"false\">     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/pt-br/guide/data_performance.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Baixar notebook</a>\n",
        "</td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHxb-dlhMIzW"
      },
      "source": [
        "## Visão geral\n",
        "\n",
        "As GPUs e TPUs diminuem drasticamente o tempo necessário para executar um único passo de treinamento. Para conseguir o pico de desempenho, é necessário ter um pipeline de entrada eficiente que entregue os dados para o próximo passo antes da conclusão do passo atual. A API `tf.data` ajuda a criar pipelines de entrada flexíveis e eficientes. Este documento demonstra como usar a API `tf.data` para criar pipelines de entrada do TensorFlow com desempenho muito alto.\n",
        "\n",
        "Antes de continuar, confira o guia [Crie pipelines de entrada do TensorFlow](./data.ipynb) para aprender a usar a API `tf.data`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhNtHfuxCGVy"
      },
      "source": [
        "## Recursos:\n",
        "\n",
        "- [Crie pipelines de entrada do TensorFlow](./data.ipynb)\n",
        "- API `tf.data.Dataset`\n",
        "- [Análise do desempenho de <code>tf.data</code> com o TF Profiler](./data_performance_analysis.md)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUXex9ctTuDB"
      },
      "source": [
        "## Configuração"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IqR2PQG4ZaZ0"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QthTHCKF-jKD"
      },
      "source": [
        "Neste tutorial, você vai fazer a interação de um dataset e mensurar o desempenho. Pode ser difícil criar referenciais de desempenho que possam ser reproduzidos. Diferentes fatores afetam a capacidade de reprodução, como:\n",
        "\n",
        "- Carga atual da CPU\n",
        "- Tráfego da rede\n",
        "- Mecanismos complexos, como cache\n",
        "\n",
        "Para ter um referencial que possa ser reproduzido, você criará um exemplo artificial."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bU5gsSI-jKF"
      },
      "source": [
        "### Dataset\n",
        "\n",
        "Comece definindo uma classe que herde de `tf.data.Dataset` chamada `ArtificialDataset`. Este dataset:\n",
        "\n",
        "- Gera `num_samples` amostras (o padrão é 3)\n",
        "- Repousa por um tempo antes do primeiro item para simular a abertura de um arquivo\n",
        "- Repousa por um tempo antes de gerar cada item para simular a leitura de dados de um arquivo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zUQv4kCd-jKH"
      },
      "outputs": [],
      "source": [
        "class ArtificialDataset(tf.data.Dataset):\n",
        "    def _generator(num_samples):\n",
        "        # Opening the file\n",
        "        time.sleep(0.03)\n",
        "        \n",
        "        for sample_idx in range(num_samples):\n",
        "            # Reading data (line, record) from the file\n",
        "            time.sleep(0.015)\n",
        "            \n",
        "            yield (sample_idx,)\n",
        "    \n",
        "    def __new__(cls, num_samples=3):\n",
        "        return tf.data.Dataset.from_generator(\n",
        "            cls._generator,\n",
        "            output_signature = tf.TensorSpec(shape = (1,), dtype = tf.int64),\n",
        "            args=(num_samples,)\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9y1WjNv-jKL"
      },
      "source": [
        "Este dataset é similar ao `tf.data.Dataset.range`, com um atraso fixo no começo de cada amostra e entre as amostras."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGK1Y4jn-jKM"
      },
      "source": [
        "### Loop de treinamento\n",
        "\n",
        "Agora, escreva um loop de treinamento simulado que mensure quanto tempo demora para fazer a interação de um dataset. O tempo de treinamento é simulado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MIaM3u00-jKP"
      },
      "outputs": [],
      "source": [
        "def benchmark(dataset, num_epochs=2):\n",
        "    start_time = time.perf_counter()\n",
        "    for epoch_num in range(num_epochs):\n",
        "        for sample in dataset:\n",
        "            # Performing a training step\n",
        "            time.sleep(0.01)\n",
        "    print(\"Execution time:\", time.perf_counter() - start_time)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KK58SuXS-jKT"
      },
      "source": [
        "## Otimize o desempenho\n",
        "\n",
        "Para demonstrar como o desempenho pode ser otimizado, você vai melhorar o desempenho de `ArtificialDataset`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xi8t26y7-jKV"
      },
      "source": [
        "### Estratégia ingênua\n",
        "\n",
        "Comece com um pipeline ingênuo, sem usar truques, fazendo a iteração do dataset como ele está."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_gP7J1y4-jKY"
      },
      "outputs": [],
      "source": [
        "benchmark(ArtificialDataset())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lxeat5dH-jKf"
      },
      "source": [
        "Por baixo dos panos, veja como o tempo de execução foi gasto:\n",
        "\n",
        "![Data execution time plot - a naive method](https://www.tensorflow.org/guide/images/data_performance/naive.svg)\n",
        "\n",
        "O gráfico mostra que fazer um passo de treinamento envolve:\n",
        "\n",
        "- Abrir um arquivo, se ainda não tiver sido aberto.\n",
        "- Buscar uma entrada de dados no arquivo.\n",
        "- Usar os dados para o treinamento.\n",
        "\n",
        "Entretanto, em uma implementação síncrona ingênua como esta, embora seu pipeline esteja buscando os dados, o modelo está ocioso. Em contrapartida, enquanto o modelo está sendo treinado, o pipeline de entrada está ocioso. Portanto, o tempo do passo de treinamento é a soma dos tempos de abertura, leitura e treinamento.\n",
        "\n",
        "As próximas seções expandem esse pipeline de entrada, ilustrando as práticas recomendadas para criar pipelines de entrada do TensorFlow com bom desempenho."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfukBGNz-jKh"
      },
      "source": [
        "### Pré-busca\n",
        "\n",
        "A pré-busca faz a sobreposição entre o pré-processamento e a execução do modelo em um passo de treinamento. Enquanto o modelo está executando o passo de treinamento `s`, o pipeline de entrada está lendo os dados da etapa `s+1`. Ao fazer isso, o tempo do passo é reduzido para o tempo máximo (em vez da soma) do treinamento e o tempo que leva para extrair os dados.\n",
        "\n",
        "A API `tf.data` conta com a transformação `tf.data.Dataset.prefetch`, que pode ser usada para desacoplar o tempo quando os dados são gerados do tempo quando os dados são consumidos. Especificamente, a transformação usa um thread em segundo plano e um buffer interno para fazer a pré-busca de elementos do dataset de entrada antes do momento em que são solicitados. O número de elementos da pré-busca deve ser igual ao número de lotes consumidos por um único passo de treinamento (ou possivelmente maior). Você pode ajustar esse valor manualmente ou defini-lo como `tf.data.AUTOTUNE`, o que fará o runtime do `tf.data` ajustar o valor dinamicamente em tempo de execução.\n",
        "\n",
        "Observe que a transformação de pré-busca traz benefícios sempre que há uma oportunidade de fazer a sobreposição entre o trabalho de um \"gerador\" e o trabalho de um \"consumidor\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DHpUVqH1-jKi"
      },
      "outputs": [],
      "source": [
        "benchmark(\n",
        "    ArtificialDataset()\n",
        "    .prefetch(tf.data.AUTOTUNE)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7z_kzo--jKn"
      },
      "source": [
        "![Data execution time plot - prefetching method](https://www.tensorflow.org/guide/images/data_performance/prefetched.svg)\n",
        "\n",
        "Agora, conforme mostrado pelo gráfico do tempo de execução dos dados, enquanto o passo de treinamento está sendo executado com a amostra 0, o pipeline de entrada está lendo os dados da amostra 1, e assim por diante."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52QMKfaY-jKq"
      },
      "source": [
        "### Paralelização da extração de dados\n",
        "\n",
        "Em um ambiente real, os dados de entrada poderão estar armazenados remotamente (por exemplo, no Google Cloud Storage ou HDFS). Um pipeline de dataset que tenha bom desempenho ao ler dados localmente poderá sofrer gargalos de I/O ao ler dados remotamente devido às seguintes diferenças entre armazenamento local e remoto:\n",
        "\n",
        "- **Time-to-first-byte** (tempo até o primeiro byte): a leitura do primeiro byte de um arquivo em um armazenamento remoto pode ter um tempo com ordens de magnitude maior em relação ao armazenamento local.\n",
        "- **Taxa de transferência de leitura**: embora geralmente os armazenamentos remotos ofereçam grande largura de banda agregada, a leitura de um único arquivo poderá conseguir utilizar somente uma pequena fração dessa largura de banda.\n",
        "\n",
        "Além disso, quando os bytes brutos forem carregados na memória, também poderá ser necessário desserializar e/ou decodificar os dados (por exemplo, [protobuf](https://developers.google.com/protocol-buffers/)), o que requer computação adicional. Essa sobrecarga está presente independentemente de os dados serem armazenados local ou remotamente, mas pode ser pior no armazenamento remoto se não for feita uma pré-busca eficiente dos dados.\n",
        "\n",
        "Para mitigar o impacto das diversas sobrecargas de extração dos dados, a transformação `tf.data.Dataset.interleave` pode ser usada para paralelizar o passo de carregamento dos dados, intercalando o conteúdo de outros datasets (como leitores de arquivos de dados). O número de datasets a serem sobrepostos pode ser especificado pelo argumento `cycle_length`, enquanto o nível de paralelismo pode ser especificado pelo argumento `num_parallel_calls`. De maneira similar à transformação `prefetch`, a transformação `interleave` tem suporte ao `tf.data.AUTOTUNE`, que delegará a decisão sobre o nível de paralelismo usado para o runtime do `tf.data`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gs8O8Vbu-jKu"
      },
      "source": [
        "#### Intercalação sequencial\n",
        "\n",
        "Os argumentos padrão da transformação `tf.data.Dataset.interleave` fazem a intercalação de uma única amostra de dois datasets sequencialmente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fDH12GiK-jKw"
      },
      "outputs": [],
      "source": [
        "benchmark(\n",
        "    tf.data.Dataset.range(2)\n",
        "    .interleave(lambda _: ArtificialDataset())\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78CsSOnf-jK0"
      },
      "source": [
        "![Data execution time plot - sequential interleave](https://www.tensorflow.org/guide/images/data_performance/sequential_interleave.svg)\n",
        "\n",
        "Esse gráfico do tempo de execução dos dados demonstra o comportamento da transformação `interleave`, buscando amostras dos dois datasets disponíveis de forma alternada. Entretanto, não há nenhuma melhoria de desempenho aqui."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3cqqmYl-jK2"
      },
      "source": [
        "#### Intercalação paralela\n",
        "\n",
        "Agora, use o argumento `num_parallel_calls` da transformação `interleave`, que carrega diversos datasets em paralelo, diminuindo o tempo de espera para a abertura dos arquivos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a3FQcTPY-jK4"
      },
      "outputs": [],
      "source": [
        "benchmark(\n",
        "    tf.data.Dataset.range(2)\n",
        "    .interleave(\n",
        "        lambda _: ArtificialDataset(),\n",
        "        num_parallel_calls=tf.data.AUTOTUNE\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RxRLPB6C-jLA"
      },
      "source": [
        "![Data execution time plot - parallel interleave method](https://www.tensorflow.org/guide/images/data_performance/parallel_interleave.svg)\n",
        "\n",
        "Desta vez, conforme exibido no gráfico de tempo de execução dos dados, a leitura dos dois datasets está paralelizada, diminuindo o tempo global de processamento dos dados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ZCLFWyv-jLB"
      },
      "source": [
        "### Paralelização da transformação de dados\n",
        "\n",
        "Ao preparar os dados, talvez seja necessário pré-processar os elementos de entrada. Para isso, a API `tf.data` conta com a transformação `tf.data.Dataset.map`, que aplica uma função definida pelo usuário a cada elemento do dataset de entrada. Como os elementos de entrada são independentes entre si, o pré-processamento pode ser paralelizado em diversos núcleos das CPUs. Para que isso seja possível, de forma similar às transformações `prefetch` e `interleave`, a transformação `map` conta com o argumento `num_parallel_calls` para especificar o nível de paralelismo.\n",
        "\n",
        "A escolha do melhor valor para o argumento `num_parallel_calls` depende do hardware, das características dos dados de treinamento (como tamanho e formato), do custo da função de mapeamento e dos outros processamentos sendo feitos na CPU ao mesmo tempo. Uma heurística simples é usar o número de núcleos de CPU disponíveis. Entretanto, assim como para as transformações `prefetch` e `interleave`, a transformação `map` tem suporte ao `tf.data.AUTOTUNE`, que delegará a decisão sobre o nível de paralelismo usado para o runtime do `tf.data`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GSkKetpx-jLD"
      },
      "outputs": [],
      "source": [
        "def mapped_function(s):\n",
        "    # Do some hard pre-processing\n",
        "    tf.py_function(lambda: time.sleep(0.03), [], ())\n",
        "    return s"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wiU7W_QC-jLI"
      },
      "source": [
        "#### Mapeamento sequencial\n",
        "\n",
        "Comece usando a transformação `map` sem paralelismo como um exemplo de linha de base."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZSBvDpJG-jLL"
      },
      "outputs": [],
      "source": [
        "benchmark(\n",
        "    ArtificialDataset()\n",
        "    .map(mapped_function)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngwMTDb6-jLR"
      },
      "source": [
        "![Data execution time plot - sequential mapping method](https://www.tensorflow.org/guide/images/data_performance/sequential_map.svg)\n",
        "\n",
        "Quanto à [estratégia ingênua](#The-naive-approach), aqui, conforme mostrado pelo gráfico, os tempos gastos para abrir, ler, fazer o pré-processamento (mapear) e fazer os passos de treinamento são somados para uma única iteração."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-10PE1D-jLU"
      },
      "source": [
        "#### Mapeamento paralelo\n",
        "\n",
        "Agora, use a mesma função de pré-processamento, mas aplique-a a diversas amostras de forma paralela."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F8AYLZbg-jLV"
      },
      "outputs": [],
      "source": [
        "benchmark(\n",
        "    ArtificialDataset()\n",
        "    .map(\n",
        "        mapped_function,\n",
        "        num_parallel_calls=tf.data.AUTOTUNE\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MoJklzP-jLe"
      },
      "source": [
        "![Data execution time - parallel mapping](https://www.tensorflow.org/guide/images/data_performance/parallel_map.svg)\n",
        "\n",
        "Conforme o gráfico dos dados demonstra, os passos de pré-processamento se sobrepõem, diminuindo o tempo geral de uma única iteração."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY1Q9kJO-jLh"
      },
      "source": [
        "### Cache\n",
        "\n",
        "A transformação `tf.data.Dataset.cache` pode fazer cache de um dataset, seja na memória ou no armazenamento local, o que evitará que algumas operações (como abertura de arquivos e leitura de dados) sejam executadas em cada época."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xieLApaI-jLi"
      },
      "outputs": [],
      "source": [
        "benchmark(\n",
        "    ArtificialDataset()\n",
        "    .map(  # Apply time consuming operations before cache\n",
        "        mapped_function\n",
        "    ).cache(\n",
        "    ),\n",
        "    5\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeMgW9XI-jLn"
      },
      "source": [
        "![Data execution time - cached dataset method](https://www.tensorflow.org/guide/images/data_performance/cached_dataset.svg)\n",
        "\n",
        "Aqui, o gráfico do tempo de execução dos dados mostra que, ao fazer cache de um dataset, as transformações antes da transformação `cache` (como abertura de arquivos e leitura de dados) são executadas somente durante a primeira época. As épocas subsequentes reutilizarão os dados armazenados em cache pela transformação `cache`.\n",
        "\n",
        "Se a função definida pelo usuário passada para a transformação `map` for cara, aplique a transformação `cache` após a transformação `map`, desde que o dataset resultante ainda caiba na memória ou no armazenamento local. Se a função definida pelo usuário aumentar o espaço necessário para armazenar o dataset para além da capacidade de cache, aplique-a após a transformação `cache` ou considere fazer o pré-processamento dos dados antes do trabalho de treinamento para reduzir o uso de recursos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3NtGI3r-jLp"
      },
      "source": [
        "### Vetorização do mapeamento\n",
        "\n",
        "Fazer uma chamada à função definida pelo usuário passada para a transformação `map` traz uma sobrecarga relacionada ao agendamento e à execução dessa função. Vetorize a função definida pelo usuário (ou seja, ela deve operar um lote de entradas ao mesmo tempo) e aplique a transformação `batch` *antes* da transformação `map`.\n",
        "\n",
        "Para ilustrar essa prática recomendada, seu dataset artificial não é adequado. O atraso de agendamento é de cerca de 10 microssegundos (10e-6 segundos), muito menor do que as dezenas de milissegundos usadas no `ArtificialDataset` e, portanto, é difícil observar o impacto.\n",
        "\n",
        "Neste exemplo, use a função base `tf.data.Dataset.range` e simplifique o loop de treinamento para a forma mais simples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xqtiYPmb-jLt"
      },
      "outputs": [],
      "source": [
        "fast_dataset = tf.data.Dataset.range(10000)\n",
        "\n",
        "def fast_benchmark(dataset, num_epochs=2):\n",
        "    start_time = time.perf_counter()\n",
        "    for _ in tf.data.Dataset.range(num_epochs):\n",
        "        for _ in dataset:\n",
        "            pass\n",
        "    tf.print(\"Execution time:\", time.perf_counter() - start_time)\n",
        "    \n",
        "def increment(x):\n",
        "    return x+1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fj2gmsMT-jL5"
      },
      "source": [
        "#### Mapeamento de escalar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Imn3SslJ-jMA"
      },
      "outputs": [],
      "source": [
        "fast_benchmark(\n",
        "    fast_dataset\n",
        "    # Apply function one item at a time\n",
        "    .map(increment)\n",
        "    # Batch\n",
        "    .batch(256)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWUNbPqv-jMF"
      },
      "source": [
        "![Data execution time - scalar map method](https://www.tensorflow.org/guide/images/data_performance/scalar_map.svg)\n",
        "\n",
        "O gráfico acima ilustra o que está acontecendo (com menos amostras) usando o método de mapeamento de escalar. Ele mostra que a função mapeada é aplicada a cada amostra. Embora essa função seja muito rápida, há uma certa sobrecarga que impacta o desempenho do tempo de execução."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDVSM0A--jMG"
      },
      "source": [
        "#### Mapeamento vetorizado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nAw1mDLw-jMI"
      },
      "outputs": [],
      "source": [
        "fast_benchmark(\n",
        "    fast_dataset\n",
        "    .batch(256)\n",
        "    # Apply function on a batch of items\n",
        "    # The tf.Tensor.__add__ method already handle batches\n",
        "    .map(increment)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbMteMY9-jMO"
      },
      "source": [
        "![Data execution time - vectorized map method](https://www.tensorflow.org/guide/images/data_performance/vectorized_map.svg)\n",
        "\n",
        "Desta vez, a função mapeada é chamada uma vez e aplicada a um lote de amostras. Como o gráfico do tempo de execução dos dados mostra, embora a função possa demorar mais tempo para executar, a sobrecarga aparece somente uma vez, aumentando o desempenho geral do tempo de execução."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfueG0Wj-jMR"
      },
      "source": [
        "### Redução do volume de memória\n",
        "\n",
        "Diversas transformações, incluindo `interleave`, `prefetch` e `shuffle`, mantêm um buffer interno de elementos. Se a função definida pelo usuário passada para a transformação `map` alterar o tamanho dos elementos, então a ordem da transformação de mapeamento e das transformações que fazem buffer dos elementos afeta o uso de memória. De forma geral, escolha a ordem que resulte no menor volume de memória, a menos que uma ordem diferente seja desejável por questões de desempenho.\n",
        "\n",
        "#### Cache das computações parciais\n",
        "\n",
        "É recomendável fazer o cache do dataset após a transformação `map`, a não ser que essa transformação faça os dados ficarem grandes demais e não caberem na memória. Uma contrapartida é se sua função mapeada puder ser dividida em duas partes: uma que consuma tempo e outra que consuma memória. Neste caso, você pode encadear as transformações da seguinte forma:\n",
        "\n",
        "```python\n",
        "dataset.map(time_consuming_mapping).cache().map(memory_consuming_mapping)\n",
        "```\n",
        "\n",
        "Desta forma, a parte que consome tempo é executada somente durante a primeira época, e você evita usar espaço do cache demais."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYOHG69M-jMT"
      },
      "source": [
        "## Resumo das práticas recomendadas\n",
        "\n",
        "Veja um resumo das práticas recomendadas para criar pipelines de entrada do TensorFlow com bom desempenho:\n",
        "\n",
        "- [Use a transformação `prefetch`](#Pipelining) para fazer a sobreposição entre o trabalho de um gerador e de um consumidor\n",
        "- [Paralelize a transformação de leitura dos dados](#Parallelizing-data-extraction) usando a transformação `interleave`\n",
        "- [Paralelize a transformação `map`](#Parallelizing-data-transformation) definindo o argumento `num_parallel_calls`\n",
        "- [Use a transformação `cache`](#Caching) para fazer o cache dos dados na memória durante a primeira época\n",
        "- [Vetorize as funções definidas pelo usuário](#Map-and-batch) passadas para a transformação `map`\n",
        "- [Reduza o uso de memória](#Reducing-memory-footprint) ao aplicar as transformações `interleave`, `prefetch` e `shuffle`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mP_EMFsQ-jMU"
      },
      "source": [
        "## Reprodução dos números\n",
        "\n",
        "Observação: o restante deste notebook fala sobre como reproduzir os números acima. Fique à vontade para mexer no código, mas entendê-lo não é essencial para este tutorial.\n",
        "\n",
        "Para aprofundar sua compreensão da API `tf.data.Dataset`, você pode fazer seus próprios pipelines. Veja abaixo o código usado para gerar as imagens deste guia. Pode ser um bom ponto de partida, mostrando alguns caminhos alternativos para dificuldades comuns, como:\n",
        "\n",
        "- Capacidade de reprodução do tempo de execução\n",
        "- Execução adiantada (eager) das funções mapeadas\n",
        "- Transformação `interleave` que pode ser chamada"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7M_jFLer-jMV"
      },
      "outputs": [],
      "source": [
        "import itertools\n",
        "from collections import defaultdict\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3pjnxtK-jMa"
      },
      "source": [
        "### Dataset\n",
        "\n",
        "Similar ao `ArtificialDataset`, você pode criar um dataset que retorne o tempo gasto em cada passo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OgGl4U7t-jMc"
      },
      "outputs": [],
      "source": [
        "class TimeMeasuredDataset(tf.data.Dataset):\n",
        "    # OUTPUT: (steps, timings, counters)\n",
        "    OUTPUT_TYPES = (tf.dtypes.string, tf.dtypes.float32, tf.dtypes.int32)\n",
        "    OUTPUT_SHAPES = ((2, 1), (2, 2), (2, 3))\n",
        "    \n",
        "    _INSTANCES_COUNTER = itertools.count()  # Number of datasets generated\n",
        "    _EPOCHS_COUNTER = defaultdict(itertools.count)  # Number of epochs done for each dataset\n",
        "    \n",
        "    def _generator(instance_idx, num_samples):\n",
        "        epoch_idx = next(TimeMeasuredDataset._EPOCHS_COUNTER[instance_idx])\n",
        "        \n",
        "        # Opening the file\n",
        "        open_enter = time.perf_counter()\n",
        "        time.sleep(0.03)\n",
        "        open_elapsed = time.perf_counter() - open_enter\n",
        "        \n",
        "        for sample_idx in range(num_samples):\n",
        "            # Reading data (line, record) from the file\n",
        "            read_enter = time.perf_counter()\n",
        "            time.sleep(0.015)\n",
        "            read_elapsed = time.perf_counter() - read_enter\n",
        "            \n",
        "            yield (\n",
        "                [(\"Open\",), (\"Read\",)],\n",
        "                [(open_enter, open_elapsed), (read_enter, read_elapsed)],\n",
        "                [(instance_idx, epoch_idx, -1), (instance_idx, epoch_idx, sample_idx)]\n",
        "            )\n",
        "            open_enter, open_elapsed = -1., -1.  # Negative values will be filtered\n",
        "            \n",
        "    \n",
        "    def __new__(cls, num_samples=3):\n",
        "        return tf.data.Dataset.from_generator(\n",
        "            cls._generator,\n",
        "            output_types=cls.OUTPUT_TYPES,\n",
        "            output_shapes=cls.OUTPUT_SHAPES,\n",
        "            args=(next(cls._INSTANCES_COUNTER), num_samples)\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQqDP4jk-jMj"
      },
      "source": [
        "Este dataset conta com amostras de formato `[[2, 1], [2, 2], [2, 3]]` e tipo `[tf.dtypes.string, tf.dtypes.float32, tf.dtypes.int32]`. Cada amostra é:\n",
        "\n",
        "```\n",
        "(\n",
        "  [(\"Open\"), (\"Read\")],\n",
        "  [(t0, d), (t0, d)],\n",
        "  [(i, e, -1), (i, e, s)]\n",
        ")\n",
        "```\n",
        "\n",
        "Em que:\n",
        "\n",
        "- `Open` e `Read` são identificadores de passos\n",
        "- `t0` é o timestamp de quando o passo correspondente começou\n",
        "- `d` é o tempo gasto no passo correspondente\n",
        "- `i` é o índice da instância\n",
        "- `e` é o índice da época (número de vezes em que foi feita a iteração do dataset)\n",
        "- `s` é o índice da amostra"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQK913bB-jMm"
      },
      "source": [
        "### Loop de iteração\n",
        "\n",
        "Complique um pouco mais o loop de iteração fazendo a agregação de todos os tempos, o que funcionará apenas com datasets que gerem amostras, conforme detalhado acima."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zAy-K_Cq-jMn"
      },
      "outputs": [],
      "source": [
        "def timelined_benchmark(dataset, num_epochs=2):\n",
        "    # Initialize accumulators\n",
        "    steps_acc = tf.zeros([0, 1], dtype=tf.dtypes.string)\n",
        "    times_acc = tf.zeros([0, 2], dtype=tf.dtypes.float32)\n",
        "    values_acc = tf.zeros([0, 3], dtype=tf.dtypes.int32)\n",
        "    \n",
        "    start_time = time.perf_counter()\n",
        "    for epoch_num in range(num_epochs):\n",
        "        epoch_enter = time.perf_counter()\n",
        "        for (steps, times, values) in dataset:\n",
        "            # Record dataset preparation informations\n",
        "            steps_acc = tf.concat((steps_acc, steps), axis=0)\n",
        "            times_acc = tf.concat((times_acc, times), axis=0)\n",
        "            values_acc = tf.concat((values_acc, values), axis=0)\n",
        "            \n",
        "            # Simulate training time\n",
        "            train_enter = time.perf_counter()\n",
        "            time.sleep(0.01)\n",
        "            train_elapsed = time.perf_counter() - train_enter\n",
        "            \n",
        "            # Record training informations\n",
        "            steps_acc = tf.concat((steps_acc, [[\"Train\"]]), axis=0)\n",
        "            times_acc = tf.concat((times_acc, [(train_enter, train_elapsed)]), axis=0)\n",
        "            values_acc = tf.concat((values_acc, [values[-1]]), axis=0)\n",
        "        \n",
        "        epoch_elapsed = time.perf_counter() - epoch_enter\n",
        "        # Record epoch informations\n",
        "        steps_acc = tf.concat((steps_acc, [[\"Epoch\"]]), axis=0)\n",
        "        times_acc = tf.concat((times_acc, [(epoch_enter, epoch_elapsed)]), axis=0)\n",
        "        values_acc = tf.concat((values_acc, [[-1, epoch_num, -1]]), axis=0)\n",
        "        time.sleep(0.001)\n",
        "    \n",
        "    tf.print(\"Execution time:\", time.perf_counter() - start_time)\n",
        "    return {\"steps\": steps_acc, \"times\": times_acc, \"values\": values_acc}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jw_WSQC8-jMs"
      },
      "source": [
        "### Método de plotagem\n",
        "\n",
        "Por fim, defina uma função que consiga plotar uma linha do tempo dados os valores retornados pela função `timelined_benchmark`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1j73RxiP-jMw"
      },
      "outputs": [],
      "source": [
        "def draw_timeline(timeline, title, width=0.5, annotate=False, save=False):\n",
        "    # Remove invalid entries (negative times, or empty steps) from the timelines\n",
        "    invalid_mask = np.logical_and(timeline['times'] > 0, timeline['steps'] != b'')[:,0]\n",
        "    steps = timeline['steps'][invalid_mask].numpy()\n",
        "    times = timeline['times'][invalid_mask].numpy()\n",
        "    values = timeline['values'][invalid_mask].numpy()\n",
        "    \n",
        "    # Get a set of different steps, ordered by the first time they are encountered\n",
        "    step_ids, indices = np.stack(np.unique(steps, return_index=True))\n",
        "    step_ids = step_ids[np.argsort(indices)]\n",
        "\n",
        "    # Shift the starting time to 0 and compute the maximal time value\n",
        "    min_time = times[:,0].min()\n",
        "    times[:,0] = (times[:,0] - min_time)\n",
        "    end = max(width, (times[:,0]+times[:,1]).max() + 0.01)\n",
        "    \n",
        "    cmap = mpl.cm.get_cmap(\"plasma\")\n",
        "    plt.close()\n",
        "    fig, axs = plt.subplots(len(step_ids), sharex=True, gridspec_kw={'hspace': 0})\n",
        "    fig.suptitle(title)\n",
        "    fig.set_size_inches(17.0, len(step_ids))\n",
        "    plt.xlim(-0.01, end)\n",
        "    \n",
        "    for i, step in enumerate(step_ids):\n",
        "        step_name = step.decode()\n",
        "        ax = axs[i]\n",
        "        ax.set_ylabel(step_name)\n",
        "        ax.set_ylim(0, 1)\n",
        "        ax.set_yticks([])\n",
        "        ax.set_xlabel(\"time (s)\")\n",
        "        ax.set_xticklabels([])\n",
        "        ax.grid(which=\"both\", axis=\"x\", color=\"k\", linestyle=\":\")\n",
        "        \n",
        "        # Get timings and annotation for the given step\n",
        "        entries_mask = np.squeeze(steps==step)\n",
        "        serie = np.unique(times[entries_mask], axis=0)\n",
        "        annotations = values[entries_mask]\n",
        "        \n",
        "        ax.broken_barh(serie, (0, 1), color=cmap(i / len(step_ids)), linewidth=1, alpha=0.66)\n",
        "        if annotate:\n",
        "            for j, (start, width) in enumerate(serie):\n",
        "                annotation = \"\\n\".join([f\"{l}: {v}\" for l,v in zip((\"i\", \"e\", \"s\"), annotations[j])])\n",
        "                ax.text(start + 0.001 + (0.001 * (j % 2)), 0.55 - (0.1 * (j % 2)), annotation,\n",
        "                        horizontalalignment='left', verticalalignment='center')\n",
        "    if save:\n",
        "        plt.savefig(title.lower().translate(str.maketrans(\" \", \"_\")) + \".svg\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xto6GNdO-jM1"
      },
      "source": [
        "### Use encapsuladores para a função mapeada\n",
        "\n",
        "Para executar a função mapeada em um contexto eager, você precisa encapsulá-la dentro de uma chamada `tf.py_function`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "39v7JD4L-jM2"
      },
      "outputs": [],
      "source": [
        "def map_decorator(func):\n",
        "    def wrapper(steps, times, values):\n",
        "        # Use a tf.py_function to prevent auto-graph from compiling the method\n",
        "        return tf.py_function(\n",
        "            func,\n",
        "            inp=(steps, times, values),\n",
        "            Tout=(steps.dtype, times.dtype, values.dtype)\n",
        "        )\n",
        "    return wrapper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7eJRCinb-jM5"
      },
      "source": [
        "### Comparação dos pipelines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YwX4ndHE-jM6"
      },
      "outputs": [],
      "source": [
        "_batch_map_num_items = 50\n",
        "\n",
        "def dataset_generator_fun(*args):\n",
        "    return TimeMeasuredDataset(num_samples=_batch_map_num_items)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwxJT2aR-jNA"
      },
      "source": [
        "#### Ingênuo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wLKgurx_-jNC"
      },
      "outputs": [],
      "source": [
        "@map_decorator\n",
        "def naive_map(steps, times, values):\n",
        "    map_enter = time.perf_counter()\n",
        "    time.sleep(0.001)  # Time consuming step\n",
        "    time.sleep(0.0001)  # Memory consuming step\n",
        "    map_elapsed = time.perf_counter() - map_enter\n",
        "\n",
        "    return (\n",
        "        tf.concat((steps, [[\"Map\"]]), axis=0),\n",
        "        tf.concat((times, [[map_enter, map_elapsed]]), axis=0),\n",
        "        tf.concat((values, [values[-1]]), axis=0)\n",
        "    )\n",
        "\n",
        "naive_timeline = timelined_benchmark(\n",
        "    tf.data.Dataset.range(2)\n",
        "    .flat_map(dataset_generator_fun)\n",
        "    .map(naive_map)\n",
        "    .batch(_batch_map_num_items, drop_remainder=True)\n",
        "    .unbatch(),\n",
        "    5\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJqUMDsO-jNG"
      },
      "source": [
        "### Otimizado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HYHcwabr-jNH"
      },
      "outputs": [],
      "source": [
        "@map_decorator\n",
        "def time_consuming_map(steps, times, values):\n",
        "    map_enter = time.perf_counter()\n",
        "    time.sleep(0.001 * values.shape[0])  # Time consuming step\n",
        "    map_elapsed = time.perf_counter() - map_enter\n",
        "\n",
        "    return (\n",
        "        tf.concat((steps, tf.tile([[[\"1st map\"]]], [steps.shape[0], 1, 1])), axis=1),\n",
        "        tf.concat((times, tf.tile([[[map_enter, map_elapsed]]], [times.shape[0], 1, 1])), axis=1),\n",
        "        tf.concat((values, tf.tile([[values[:][-1][0]]], [values.shape[0], 1, 1])), axis=1)\n",
        "    )\n",
        "\n",
        "\n",
        "@map_decorator\n",
        "def memory_consuming_map(steps, times, values):\n",
        "    map_enter = time.perf_counter()\n",
        "    time.sleep(0.0001 * values.shape[0])  # Memory consuming step\n",
        "    map_elapsed = time.perf_counter() - map_enter\n",
        "\n",
        "    # Use tf.tile to handle batch dimension\n",
        "    return (\n",
        "        tf.concat((steps, tf.tile([[[\"2nd map\"]]], [steps.shape[0], 1, 1])), axis=1),\n",
        "        tf.concat((times, tf.tile([[[map_enter, map_elapsed]]], [times.shape[0], 1, 1])), axis=1),\n",
        "        tf.concat((values, tf.tile([[values[:][-1][0]]], [values.shape[0], 1, 1])), axis=1)\n",
        "    )\n",
        "\n",
        "\n",
        "optimized_timeline = timelined_benchmark(\n",
        "    tf.data.Dataset.range(2)\n",
        "    .interleave(  # Parallelize data reading\n",
        "        dataset_generator_fun,\n",
        "        num_parallel_calls=tf.data.AUTOTUNE\n",
        "    )\n",
        "    .batch(  # Vectorize your mapped function\n",
        "        _batch_map_num_items,\n",
        "        drop_remainder=True)\n",
        "    .map(  # Parallelize map transformation\n",
        "        time_consuming_map,\n",
        "        num_parallel_calls=tf.data.AUTOTUNE\n",
        "    )\n",
        "    .cache()  # Cache data\n",
        "    .map(  # Reduce memory usage\n",
        "        memory_consuming_map,\n",
        "        num_parallel_calls=tf.data.AUTOTUNE\n",
        "    )\n",
        "    .prefetch(  # Overlap producer and consumer works\n",
        "        tf.data.AUTOTUNE\n",
        "    )\n",
        "    .unbatch(),\n",
        "    5\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b_CSUbxL-jNK"
      },
      "outputs": [],
      "source": [
        "draw_timeline(naive_timeline, \"Naive\", 15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DoovY7qr-jNR"
      },
      "outputs": [],
      "source": [
        "draw_timeline(optimized_timeline, \"Optimized\", 15)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "data_performance.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
