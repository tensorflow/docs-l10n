{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pnn4rDWGqDZL"
      },
      "source": [
        "##### Copyright 2018 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "l534d35Gp68G"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TI3Q3XBesaS"
      },
      "source": [
        "# Treinando checkpoints"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yw_a0iGucY8z"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>     <a target=\"_blank\" href=\"https://www.tensorflow.org/guide/checkpoint\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver em TensorFlow.org</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/pt-br/guide/checkpoint.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Executar no Google Colab</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/pt-br/guide/checkpoint.ipynb\"> <img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\"> Ver fonte no GitHub</a>\n",
        "</td>\n",
        "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/pt-br/guide/checkpoint.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Baixar notebook</a>\n",
        "</td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LeDp7dovcbus"
      },
      "source": [
        "A frase \"Salvando um modelo do TensorFlow\" normalmente significa uma das duas coisas a seguir:\n",
        "\n",
        "1. Checkpoints, OU\n",
        "2. SavedModel.\n",
        "\n",
        "Os checkpoints capturam o valor exato de todos os parâmetros (objetos `tf.Variable`) usados ​​por um modelo. Os checkpoints não contêm nenhuma descrição da computação definida pelo modelo e, portanto, normalmente são úteis apenas quando o código-fonte que usará os valores de parâmetro salvos estiver disponível.\n",
        "\n",
        "O formato SavedModel, por outro lado, inclui uma descrição serializada da computação definida pelo modelo, além dos valores dos parâmetros (checkpoint). Os modelos neste formato são independentes do código-fonte que criou o modelo. Eles são, portanto, adequados para implantação via TensorFlow Serving, TensorFlow Lite, TensorFlow.js ou programas em outras linguagens de programação (C, C++, Java, Go, Rust, C# etc. APIs do TensorFlow).\n",
        "\n",
        "Este guia trata de APIs para escrever e ler checkpoints."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0nm8k-6xfh2"
      },
      "source": [
        "## Configuração"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VEvpMYAKsC4z"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OEQCseyeC4Ev"
      },
      "outputs": [],
      "source": [
        "class Net(tf.keras.Model):\n",
        "  \"\"\"A simple linear model.\"\"\"\n",
        "\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "    self.l1 = tf.keras.layers.Dense(5)\n",
        "\n",
        "  def call(self, x):\n",
        "    return self.l1(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "utqeoDADC5ZR"
      },
      "outputs": [],
      "source": [
        "net = Net()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vsq3-pffo1I"
      },
      "source": [
        "## Salvando de APIs de treinamento `tf.keras`\n",
        "\n",
        "Veja o [Guia `tf.keras` sobre como salvar e restaurar](https://www.tensorflow.org/guide/keras/save_and_serialize).\n",
        "\n",
        "O `tf.keras.Model.save_weights` salva um checkpoint do TensorFlow. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SuhmrYPEl4D_"
      },
      "outputs": [],
      "source": [
        "net.save_weights('easy_checkpoint')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XseWX5jDg4lQ"
      },
      "source": [
        "## Escrevendo checkpoints\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jpZPz76ZP3K"
      },
      "source": [
        "O estado persistente de um modelo TensorFlow é armazenado em objetos `tf.Variable`. Eles podem ser construídos diretamente, mas geralmente são criados via APIs de alto nível, como `tf.keras.layers` ou `tf.keras.Model`.\n",
        "\n",
        "A maneira mais fácil de gerenciar variáveis ​​é anexá-las a objetos Python e, em seguida, fazer referência a esses objetos.\n",
        "\n",
        "Subclasses de `tf.train.Checkpoint`, `tf.keras.layers.Layer` e `tf.keras.Model` rastreiam automaticamente as variáveis ​​atribuídas a seus atributos. O exemplo a seguir constrói um modelo linear simples e, em seguida, grava checkpoints que contêm valores para todas as variáveis ​​do modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0vFBr_Im73_"
      },
      "source": [
        "Você pode salvar um checkpoint de modelo facilmente com `Model.save_weights`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHTJ1JzxCi8a"
      },
      "source": [
        "### Definição manual de checkpoints"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cF9fqYOCrEO"
      },
      "source": [
        "#### Configuração"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNjf9KaLdIRP"
      },
      "source": [
        "Para ajudar a demonstrar todos os recursos de `tf.train.Checkpoint`, defina um dataset de brinquedo e uma etapa de otimização:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tSNyP4IJ9nkU"
      },
      "outputs": [],
      "source": [
        "def toy_dataset():\n",
        "  inputs = tf.range(10.)[:, None]\n",
        "  labels = inputs * 5. + tf.range(5.)[None, :]\n",
        "  return tf.data.Dataset.from_tensor_slices(\n",
        "    dict(x=inputs, y=labels)).repeat().batch(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ICm1cufh_JH8"
      },
      "outputs": [],
      "source": [
        "def train_step(net, example, optimizer):\n",
        "  \"\"\"Trains `net` on `example` using `optimizer`.\"\"\"\n",
        "  with tf.GradientTape() as tape:\n",
        "    output = net(example['x'])\n",
        "    loss = tf.reduce_mean(tf.abs(output - example['y']))\n",
        "  variables = net.trainable_variables\n",
        "  gradients = tape.gradient(loss, variables)\n",
        "  optimizer.apply_gradients(zip(gradients, variables))\n",
        "  return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxzGpHRbOVO6"
      },
      "source": [
        "#### Crie os objetos do checkpoint\n",
        "\n",
        "Use um objeto `tf.train.Checkpoint` para criar um checkpoint manualmente, onde os objetos que você deseja verificar com o checkpoint são definidos como atributos no objeto.\n",
        "\n",
        "Um `tf.train.CheckpointManager` também pode ser útil para gerenciar múltiplos checkpoints."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ou5qarOQOWYl"
      },
      "outputs": [],
      "source": [
        "opt = tf.keras.optimizers.Adam(0.1)\n",
        "dataset = toy_dataset()\n",
        "iterator = iter(dataset)\n",
        "ckpt = tf.train.Checkpoint(step=tf.Variable(1), optimizer=opt, net=net, iterator=iterator)\n",
        "manager = tf.train.CheckpointManager(ckpt, './tf_ckpts', max_to_keep=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZbYSD4uCy96"
      },
      "source": [
        "#### Treine o modelo e aplique checkpoints"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NP9IySmCeCkn"
      },
      "source": [
        "O loop de treinamento a seguir cria uma instância do modelo e de um otimizador e os reúne num objeto `tf.train.Checkpoint`. Ele chama a etapa de treinamento dentro de um loop em cada lote de dados e grava checkpoints periodicamente no disco."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BbCS5A6K1VSH"
      },
      "outputs": [],
      "source": [
        "def train_and_checkpoint(net, manager):\n",
        "  ckpt.restore(manager.latest_checkpoint)\n",
        "  if manager.latest_checkpoint:\n",
        "    print(\"Restored from {}\".format(manager.latest_checkpoint))\n",
        "  else:\n",
        "    print(\"Initializing from scratch.\")\n",
        "\n",
        "  for _ in range(50):\n",
        "    example = next(iterator)\n",
        "    loss = train_step(net, example, opt)\n",
        "    ckpt.step.assign_add(1)\n",
        "    if int(ckpt.step) % 10 == 0:\n",
        "      save_path = manager.save()\n",
        "      print(\"Saved checkpoint for step {}: {}\".format(int(ckpt.step), save_path))\n",
        "      print(\"loss {:1.2f}\".format(loss.numpy()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ik3IBMTdPW41"
      },
      "outputs": [],
      "source": [
        "train_and_checkpoint(net, manager)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wzcc1xYN-sH"
      },
      "source": [
        "#### Restaure e continue treinando"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lw1QeyRBgsLE"
      },
      "source": [
        "Depois do primeiro ciclo de treinamento, você pode passar por um novo modelo e gerente, mas retome o treinamento exatamente de onde parou:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UjilkTOV2PBK"
      },
      "outputs": [],
      "source": [
        "opt = tf.keras.optimizers.Adam(0.1)\n",
        "net = Net()\n",
        "dataset = toy_dataset()\n",
        "iterator = iter(dataset)\n",
        "ckpt = tf.train.Checkpoint(step=tf.Variable(1), optimizer=opt, net=net, iterator=iterator)\n",
        "manager = tf.train.CheckpointManager(ckpt, './tf_ckpts', max_to_keep=3)\n",
        "\n",
        "train_and_checkpoint(net, manager)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxJT9vV-2PnZ"
      },
      "source": [
        "O objeto `tf.train.CheckpointManager` exclui checkpoints antigos. Acima, ele está configurado para manter apenas os três checkpoints mais recentes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3zmM0a-F5XqC"
      },
      "outputs": [],
      "source": [
        "print(manager.checkpoints)  # List the three remaining checkpoints"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwlYDyjemY4P"
      },
      "source": [
        "Esses caminhos, por exemplo `'./tf_ckpts/ckpt-10'`, não são arquivos no disco. Na verdade eles são prefixos para um arquivo `index` e um ou mais arquivos de dados que contêm os valores das variáveis. Esses prefixos são agrupados num único arquivo `checkpoint` (`'./tf_ckpts/checkpoint'`) onde o `CheckpointManager` salva seu estado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t1feej9JntV_"
      },
      "outputs": [],
      "source": [
        "!ls ./tf_ckpts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DR2wQc9x6b3X"
      },
      "source": [
        "<a id=\"loading_mechanics\"></a>\n",
        "\n",
        "## Mecânica de carregamento\n",
        "\n",
        "O TensorFlow combina variáveis ​​com valores dos checkpoints percorrendo um grafo direcionado com arestas nomeadas, começando pelo objeto que está sendo carregado. Nomes de arestas geralmente vêm de nomes de atributos dos objetos, por exemplo, o `\"l1\"` em `self.l1 = tf.keras.layers.Dense(5)`. `tf.train.Checkpoint` usa nomes de argumento de palavras-chave, como `\"step\"` em `tf.train.Checkpoint(step=...)`.\n",
        "\n",
        "O grafo de dependência do exemplo está mostrado a seguir:\n",
        "\n",
        "![Visualization of the dependency graph for the example training loop](https://tensorflow.org/images/guide/whole_checkpoint.svg)\n",
        "\n",
        "O otimizador aparece em vermelho, as variáveis ​​regulares em azul e as variáveis ​​de slot do otimizador em laranja. Os outros nós — por exemplo, representando o `tf.train.Checkpoint` — estão em preto.\n",
        "\n",
        "As variáveis ​​de slot fazem parte do estado do otimizador, mas são criadas para uma variável específica. Por exemplo, as arestas `'m'` acima correspondem ao momento, que o otimizador Adam rastreia para cada variável. As variáveis ​​de slot só são salvas num checkpoint se a variável e também o otimizador forem salvos, por isso as bordas tracejadas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpY5IuanUEQ0"
      },
      "source": [
        "Chamar `restore` num objeto `tf.train.Checkpoint` enfileira as restaurações solicitadas, restaurando valores das variáveis ​​assim que houver um caminho correspondente do objeto `Checkpoint`. Por exemplo, você pode carregar apenas o bias do modelo definido acima reconstruindo um caminho para ele através da rede e da camada."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wmX2AuyH7TVt"
      },
      "outputs": [],
      "source": [
        "to_restore = tf.Variable(tf.zeros([5]))\n",
        "print(to_restore.numpy())  # All zeros\n",
        "fake_layer = tf.train.Checkpoint(bias=to_restore)\n",
        "fake_net = tf.train.Checkpoint(l1=fake_layer)\n",
        "new_root = tf.train.Checkpoint(net=fake_net)\n",
        "status = new_root.restore(tf.train.latest_checkpoint('./tf_ckpts/'))\n",
        "print(to_restore.numpy())  # This gets the restored value."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqEW-_pJDAnE"
      },
      "source": [
        "O grafo de dependência para esses novos objetos é um subgráfico muito menor do checkpoint maior que você escreveu acima. Ele inclui apenas o bias e um contador de salvamento que `tf.train.Checkpoint` usa para numerar os checkpoints.\n",
        "\n",
        "![Visualization of a subgraph for the bias variable](https://tensorflow.org/images/guide/partial_checkpoint.svg)\n",
        "\n",
        "`restore` retorna um objeto de status, que contém asserções opcionais. Todos os objetos criados no novo `Checkpoint` foram restaurados, então `status.assert_existing_objects_matched` passa."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P9TQXl81Dq5r"
      },
      "outputs": [],
      "source": [
        "status.assert_existing_objects_matched()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GoMwf8CFDu9r"
      },
      "source": [
        "Existem muitos objetos no checkpoint que não correspondem, incluindo o kernel da camada e as variáveis ​​do otimizador. `status.assert_consumed` passaria apenas se houvesse uma correspondência exata entre o checkpoint e o programa, e causaria o lançamento de uma exceção nesse ponto."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCcmJ-2j9RUP"
      },
      "source": [
        "### Restaurações adiadas\n",
        "\n",
        "Objetos `Layer` no TensorFlow podem adiar a criação de variáveis ​​para sua primeira chamada, quando os formatos de entrada estiverem disponíveis. Por exemplo, o formato do kernel de uma camada `Dense` depende dos formatos de entrada e saída da camada e, portanto, o formato de saída necessário como um argumento do construtor não seria informação suficiente para criar a variável. Como a chamada de um `Layer` também lê o valor da variável, uma restauração deve acontecer entre a criação da variável e seu primeiro uso.\n",
        "\n",
        "Para oferecer suporte a esse padrão, `tf.train.Checkpoint` adia restaurações que ainda não possuem uma variável correspondente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TXYUCO3v-I72"
      },
      "outputs": [],
      "source": [
        "deferred_restore = tf.Variable(tf.zeros([1, 5]))\n",
        "print(deferred_restore.numpy())  # Not restored; still zeros\n",
        "fake_layer.kernel = deferred_restore\n",
        "print(deferred_restore.numpy())  # Restored"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DWhJ3glyobN"
      },
      "source": [
        "### Inspeção manual de checkpoints\n",
        "\n",
        "`tf.train.load_checkpoint` retorna um `CheckpointReader` que fornece acesso de nível inferior ao conteúdo do checkpoint. Ele contém mapeamentos da chave de cada variável, para o formato e para o dtype de cada variável no checkpoint. A chave de uma variável é o caminho do objeto, como nos grafos exibidos acima.\n",
        "\n",
        "Observação: Não existe estrutura de nível superior para o checkpoint. Ele conhece apenas os caminhos e valores das variáveis, e não tem noção de `models` (modelos), `layers` (camadas) ou como eles estão conectados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RlRsADTezoBD"
      },
      "outputs": [],
      "source": [
        "reader = tf.train.load_checkpoint('./tf_ckpts/')\n",
        "shape_from_key = reader.get_variable_to_shape_map()\n",
        "dtype_from_key = reader.get_variable_to_dtype_map()\n",
        "\n",
        "sorted(shape_from_key.keys())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVrdvbNvgq5V"
      },
      "source": [
        "Portanto, se você tiver interesse no valor de `net.l1.kernel`, poderá obter o valor com o seguinte código:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lYhX_XWCgl92"
      },
      "outputs": [],
      "source": [
        "key = 'net/l1/kernel/.ATTRIBUTES/VARIABLE_VALUE'\n",
        "\n",
        "print(\"Shape:\", shape_from_key[key])\n",
        "print(\"Dtype:\", dtype_from_key[key].name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Zk92jM5gRDW"
      },
      "source": [
        "Ele também fornece um método `get_tensor` que permite inspecionar o valor de uma variável:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cDJO3cgmecvi"
      },
      "outputs": [],
      "source": [
        "reader.get_tensor(key)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fxk_BnZ4W1b"
      },
      "source": [
        "### Rastreamento de objetos\n",
        "\n",
        "Os checkpoints salvam e restauram os valores dos objetos `tf.Variable` \"rastreando\" qualquer variável ou objeto rastreável definido em um dos seus atributos. Ao executar um salvamento, as variáveis ​​são obtidas recursivamente de todos os objetos rastreados que forem alcançáveis.\n",
        "\n",
        "Tal como acontece com as atribuições diretas de atributos como `self.l1 = tf.keras.layers.Dense(5)`, atribuir listas e dicionários a atributos rastreará seu conteúdo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rfaIbDtDHAr_"
      },
      "outputs": [],
      "source": [
        "save = tf.train.Checkpoint()\n",
        "save.listed = [tf.Variable(1.)]\n",
        "save.listed.append(tf.Variable(2.))\n",
        "save.mapped = {'one': save.listed[0]}\n",
        "save.mapped['two'] = save.listed[1]\n",
        "save_path = save.save('./tf_list_example')\n",
        "\n",
        "restore = tf.train.Checkpoint()\n",
        "v2 = tf.Variable(0.)\n",
        "assert 0. == v2.numpy()  # Not restored yet\n",
        "restore.mapped = {'two': v2}\n",
        "restore.restore(save_path)\n",
        "assert 2. == v2.numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTKvbxHcI3T2"
      },
      "source": [
        "Você poderá perceber objetos wrapper para listas e dicionários. Esses wrappers são versões passíveis de verificação com checkpoints das estruturas de dados subjacentes. Assim como o carregamento baseado em atributos, esses wrappers restauram o valor de uma variável assim que ela é adicionada ao container."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s0Uq1Hv5JCmm"
      },
      "outputs": [],
      "source": [
        "restore.listed = []\n",
        "print(restore.listed)  # ListWrapper([])\n",
        "v1 = tf.Variable(0.)\n",
        "restore.listed.append(v1)  # Restores v1, from restore() in the previous cell\n",
        "assert 1. == v1.numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxCIf2J6JyQ8"
      },
      "source": [
        "Objetos rastreáveis ​​incluem `tf.train.Checkpoint`, `tf.Module` e suas subclasses (por exemplo, `keras.layers.Layer` e `keras.Model`) além de containers Python reconhecidos:\n",
        "\n",
        "- `dict` (e `collections.OrderedDict`)\n",
        "- `list`\n",
        "- `tuple` (e `collections.namedtuple`, `typing.NamedTuple`)\n",
        "\n",
        "Outros tipos de container **não são suportados**, incluindo:\n",
        "\n",
        "- `collections.defaultdict`\n",
        "- `set`\n",
        "\n",
        "Todos os outros objetos Python são **ignorados**, incluindo:\n",
        "\n",
        "- `int`\n",
        "- `string`\n",
        "- `float`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knyUFMrJg8y4"
      },
      "source": [
        "## Resumo\n",
        "\n",
        "Os objetos TensorFlow fornecem um mecanismo automático fácil de usar para salvar e restaurar os valores das variáveis ​​que eles usam.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "checkpoint.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
