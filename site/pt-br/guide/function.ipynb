{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISubpr_SSsiM"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow Authors.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "3jTMb1dySr3V"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6DWfyNThSziV"
      },
      "source": [
        "# Melhor desempenho com tf.function\n",
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>     <a target=\"_blank\" href=\"https://www.tensorflow.org/guide/function\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver em TensorFlow.org</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/pt-br/guide/function.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Executar no Google Colab</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/pt-br/guide/function.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver fonte no GitHub</a>\n",
        "</td>\n",
        "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/pt-br/guide/function.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Baixar notebook</a>\n",
        "</td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J122XQYG7W6w"
      },
      "source": [
        "No TensorFlow 2, a [execução eager](eager.ipynb) está ativada por padrão. A interface do usuário é intuitiva e flexível (executar operações únicas é muito mais fácil e rápida), mas isso pode prejudicar o desempenho e a capacidade de implantação.\n",
        "\n",
        "Você pode usar `tf.function` para criar grafos de seus programas. É uma ferramenta de transformação que cria grafos de dataflow independentes do Python a partir do seu código Python. Isto vai ajudar você a criar modelos portáteis e de alto desempenho, além de ser necessário para poder usar o `SavedModel`.\n",
        "\n",
        "Este guia vai ajudar você a conceituar como `tf.function` funciona nos bastidores, para que você possa usá-lo de maneira eficaz.\n",
        "\n",
        "As principais conclusões e recomendações são:\n",
        "\n",
        "- Depure no modo eager e decore com `@tf.function`.\n",
        "- Não conte com os efeitos colaterais do Python, como mutação de objetos ou appends de listas.\n",
        "- `tf.function` funciona melhor com as ops do TensorFlow. As chamadas NumPy e Python são convertidas em constantes.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SjvqpgepHJPd"
      },
      "source": [
        "## Configuração"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "otIdN1TS8N7S"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0xDjO4SHLUD"
      },
      "source": [
        "Defina uma função helper para demonstrar os tipos de erros que você poderá encontrar:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D25apou9IOXa"
      },
      "outputs": [],
      "source": [
        "import traceback\n",
        "import contextlib\n",
        "\n",
        "# Some helper code to demonstrate the kinds of errors you might encounter.\n",
        "@contextlib.contextmanager\n",
        "def assert_raises(error_class):\n",
        "  try:\n",
        "    yield\n",
        "  except error_class as e:\n",
        "    print('Caught expected exception \\n  {}:'.format(error_class))\n",
        "    traceback.print_exc(limit=2)\n",
        "  except Exception as e:\n",
        "    raise e\n",
        "  else:\n",
        "    raise Exception('Expected {} to be raised but no error was raised!'.format(\n",
        "        error_class))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPSfepzTHThq"
      },
      "source": [
        "## Fundamentos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNwYTIJ8r56W"
      },
      "source": [
        "### Uso\n",
        "\n",
        "Uma `Function` que você define (por exemplo, aplicando o decorador `@tf.function`) é como uma operação do TensorFlow core: você pode executá-la de forma eager; você pode computar gradientes; e assim por diante."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SbtT1-Wm70F2"
      },
      "outputs": [],
      "source": [
        "@tf.function  # The decorator converts `add` into a `Function`.\n",
        "def add(a, b):\n",
        "  return a + b\n",
        "\n",
        "add(tf.ones([2, 2]), tf.ones([2, 2]))  #  [[2., 2.], [2., 2.]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uP-zUelB8DbX"
      },
      "outputs": [],
      "source": [
        "v = tf.Variable(1.0)\n",
        "with tf.GradientTape() as tape:\n",
        "  result = add(v, 1.0)\n",
        "tape.gradient(result, v)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocWZvqrmHnmX"
      },
      "source": [
        "Você pode usar uma `Function` dentro de outra `Function`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l5qRjdbBVdU6"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def dense_layer(x, w, b):\n",
        "  return add(tf.matmul(x, w), b)\n",
        "\n",
        "dense_layer(tf.ones([3, 2]), tf.ones([2, 2]), tf.ones([2]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "piBhz7gYsHqU"
      },
      "source": [
        "Uma `Function` pode ser mais rápida que o código eager, especialmente em grafos com muitas pequenas ops. Mas para grafos com algumas poucas operações caras (como convoluções), talvez você não perceba muita diferença.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zuXt4wRysI03"
      },
      "outputs": [],
      "source": [
        "import timeit\n",
        "conv_layer = tf.keras.layers.Conv2D(100, 3)\n",
        "\n",
        "@tf.function\n",
        "def conv_fn(image):\n",
        "  return conv_layer(image)\n",
        "\n",
        "image = tf.zeros([1, 200, 200, 100])\n",
        "# Warm up\n",
        "conv_layer(image); conv_fn(image)\n",
        "print(\"Eager conv:\", timeit.timeit(lambda: conv_layer(image), number=10))\n",
        "print(\"Function conv:\", timeit.timeit(lambda: conv_fn(image), number=10))\n",
        "print(\"Note how there's not much difference in performance for convolutions\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZ4Do2AV80cO"
      },
      "source": [
        "### Tracing\n",
        "\n",
        "Esta seção expõe como `Function` funciona nos bastidores, incluindo detalhes de implementação *que podem mudar no futuro*. No entanto, depois que você entender por que e quando o tracing ocorre, ficará muito mais fácil usar `tf.function` de maneira eficaz!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhpUtRqsXoyM"
      },
      "source": [
        "#### O que é \"tracing\"?\n",
        "\n",
        "Uma `Function` executa seu programa num [TensorFlow Graph](https://www.tensorflow.org/guide/intro_to_graphs#what_are_graphs). No entanto, um `tf.Graph` não pode ser usado para representar tudo o que você poderia escrever num programa TensorFlow em modo eager. Por exemplo, Python suporta polimorfismo, mas `tf.Graph` exige que suas entradas tenham um tipo de dados e dimensão especificados. Ou você talvez queira realizar tarefas paralelas, como ler argumentos de linha de comando, gerar um erro ou trabalhar com um objeto Python mais complexo; nenhuma dessas coisas irá rodar num `tf.Graph`.\n",
        "\n",
        "`Function` preenche essa lacuna separando seu código em dois estágios:\n",
        "\n",
        "1. No primeiro estágio, chamado de \"**tracing**\", `Function` cria um novo `tf.Graph`. O código Python é executado normalmente, mas todas as operações do TensorFlow (como adicionar dois Tensores) são *adiadas*: elas são capturadas pelo `tf.Graph` e não são executadas.\n",
        "\n",
        "2. No segundo estágio é executado um `tf.Graph` que contém tudo o que foi adiado na primeira etapa. Este estágio é muito mais rápido que o estágio de tracing.\n",
        "\n",
        "Dependendo de suas entradas, `Function` nem sempre executará o primeiro estágio quando for chamada. Consulte [\"Regras de tracing\"](#rules_of_tracing) abaixo para ter uma ideia melhor de como essa determinação é feita. Pular o primeiro estágio e executar apenas o segundo é o que proporciona o alto desempenho do TensorFlow.\n",
        "\n",
        "Quando `Function` decide fazer tracing, o estágio de tracing é imediatamente seguido pelo segundo estágio, portanto, chamar `Function` cria e executa o `tf.Graph`. Mais tarde, você verá como executar apenas o estágio de tracing com [`get_concrete_function`](#obtaining_concrete_functions)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7scSzLx662f"
      },
      "source": [
        "Quando você passa argumentos de tipos diferentes para um `Function`, ambos os estágios são executados:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kojmJrgq8U9v"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def double(a):\n",
        "  print(\"Tracing with\", a)\n",
        "  return a + a\n",
        "\n",
        "print(double(tf.constant(1)))\n",
        "print()\n",
        "print(double(tf.constant(1.1)))\n",
        "print()\n",
        "print(double(tf.constant(\"a\")))\n",
        "print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPfouGUQrcNb"
      },
      "source": [
        "Observe que se você chamar repetidamente uma `Function` com o mesmo tipo de argumento, o TensorFlow ignorará o estágio de tracing e reutilizará um grafo que tenha passado pelo tracing anteriormente, pois o grafo gerado seria idêntico."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hFccbWFRrsBp"
      },
      "outputs": [],
      "source": [
        "# This doesn't print 'Tracing with ...'\n",
        "print(double(tf.constant(\"b\")))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgIO_XEzcB9o"
      },
      "source": [
        "Você pode usar `pretty_printed_concrete_signatures()` para ver todos os traces disponíveis:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IiQc4IKAb-NX"
      },
      "outputs": [],
      "source": [
        "print(double.pretty_printed_concrete_signatures())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKQ92VEWI7n8"
      },
      "source": [
        "Até aqui, você viu que `tf.function` cria uma camada de despacho dinâmico e em cache sobre a lógica de tracing de grafos do TensorFlow. Para sermos mais específicos sobre a terminologia:\n",
        "\n",
        "- Um `tf.Graph` é a representação bruta, independente de linguagem e portátil de uma computação do TensorFlow.\n",
        "- Uma `ConcreteFunction` é um wrapper que envolve um `tf.Graph`.\n",
        "- Uma `Function` gerencia um cache de `ConcreteFunction` e escolhe a função correta para suas entradas.\n",
        "- `tf.function` é um wrapper que envolve uma função Python, retornando um objeto `Function`.\n",
        "- **Tracing** cria um `tf.Graph` e o empacota num `ConcreteFunction` , também conhecido como **trace**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "129-iRsPS-gY"
      },
      "source": [
        "#### Regras do tracing\n",
        "\n",
        "Quando chamada, uma `Function` combina os argumentos de chamada com as `ConcreteFunction` existentes usando `tf.types.experimental.TraceType` de cada argumento. Se uma `ConcreteFunction` correspondente for encontrada, a chamada será enviada para ela. Se nenhuma correspondência for encontrada, será feito o tracing de uma nova `ConcreteFunction`.\n",
        "\n",
        "Se forem encontradas múltiplas correspondências, a assinatura mais específica será escolhida. A correspondência é feita por meio de [subtipos](https://en.wikipedia.org/wiki/Subtyping), de forma similar a chamadas de função comuns em C++ ou Java. Por exemplo, `TensorShape([1, 2])` é um subtipo de `TensorShape([None, None])` e, portanto, uma chamada para tf.function com `TensorShape([1, 2])` pode ser despachada para `ConcreteFunction` produzida com `TensorShape([None, None])` mas se um `ConcreteFunction` com `TensorShape([1, None])` também existir, ele será priorizado por ser mais específico.\n",
        "\n",
        "O `TraceType` é determinado a partir de argumentos de entrada da seguinte forma:\n",
        "\n",
        "- Para `Tensor`, o tipo é parametrizado pelo `dtype` e `shape` do `Tensor`; os formatos classificados são um subtipo de formatos não classificados; dimensões fixas são um subtipo de dimensões desconhecidas\n",
        "\n",
        "- Para `Variable`, o tipo é semelhante a `Tensor`, mas também inclui um ID de recurso exclusivo da variável, necessário para interligar corretamente as dependências de controle\n",
        "\n",
        "- Para valores primitivos do Python, o tipo corresponde ao próprio **valor**. Por exemplo, o `TraceType` do valor `3` é `LiteralTraceType<3>`, não `int`.\n",
        "\n",
        "- Para containers ordenados em Python, como `list` e `tuple`, etc., o tipo é parametrizado pelos tipos de seus elementos; por exemplo, o tipo de `[1, 2]` é `ListTraceType<LiteralTraceType<1>, LiteralTraceType<2>>` e o tipo de `[2, 1]` é `ListTraceType<LiteralTraceType<2>, LiteralTraceType<1>>` que é diferente.\n",
        "\n",
        "- Para mapeamentos Python como `dict`, o tipo também é um mapeamento das mesmas chaves, mas para os tipos de valores, em vez dos valores reais. Por exemplo, o tipo de `{1: 2, 3: 4}`, é `MappingTraceType<<KeyValue<1, LiteralTraceType<2>>>, <KeyValue<3, LiteralTraceType<4>>>>`. No entanto, diferentemente dos containers ordenados, `{1: 2, 3: 4}` e `{3: 4, 1: 2}` possuem tipos equivalentes.\n",
        "\n",
        "- Para objetos Python que implementam o método `__tf_tracing_type__`, o tipo é o que o método retorna\n",
        "\n",
        "- Para quaisquer outros objetos Python, o tipo é um `TraceType` genérico, seu procedimento correspondente é:\n",
        "\n",
        "    - Primeiro ele verifica se o objeto é o mesmo usado no tracing anterior (usando `id()` ou `is`, do Python). Observe que isto ainda vai corresponder se o objeto tiver sido alterado; portanto, se você usar objetos Python como argumentos `tf.function`, é melhor que sejam objetos *imutáveis*.\n",
        "    - Em seguida, verifica se o objeto é igual ao objeto usado no tracing anterior (usando `==` do Python).\n",
        "\n",
        "    Observe que este procedimento apenas mantém uma [referência fraca](https://docs.python.org/3/library/weakref.html) para o objeto e, portanto, só funciona enquanto o objeto estiver no escopo/não for excluído.)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNNN4lgRzpIs"
      },
      "source": [
        "Observação: `TraceType` é baseado nos parâmetros de entrada de `Function`, portanto, alterações apenas nas [variáveis ​​globais e livres](https://docs.python.org/3/reference/executionmodel.html#binding-of-names) não criarão um novo trace. Consulte [esta seção](#depending_on_python_global_and_free_variables) para conhecer as práticas recomendadas ao lidar com variáveis ​​globais e livres do Python."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEDwbumO32Wh"
      },
      "source": [
        "### Controle do retracing\n",
        "\n",
        "O retracing, que ocorre quando sua `Function` cria mais de um trace, ajuda a garantir que o TensorFlow gere grafos corretos para cada conjunto de entradas. No entanto, o tracing é uma operação cara! Se sua `Function` fizer retracing de um novo gráfico para cada chamada, você vai perceber que seu código roda mais lentamente do que se você não usasse `tf.function`.\n",
        "\n",
        "Para controlar o comportamento do tracing, você pode usar as seguintes técnicas:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUtycWJa34TT"
      },
      "source": [
        "#### Passe uma `input_signature` fixa para `tf.function`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_BDMIRmu1RGB"
      },
      "outputs": [],
      "source": [
        "@tf.function(input_signature=(tf.TensorSpec(shape=[None], dtype=tf.int32),))\n",
        "def next_collatz(x):\n",
        "  print(\"Tracing with\", x)\n",
        "  return tf.where(x % 2 == 0, x // 2, 3 * x + 1)\n",
        "\n",
        "print(next_collatz(tf.constant([1, 2])))\n",
        "# You specified a 1-D tensor in the input signature, so this should fail.\n",
        "with assert_raises(TypeError):\n",
        "  next_collatz(tf.constant([[1, 2], [3, 4]]))\n",
        "\n",
        "# You specified an int32 dtype in the input signature, so this should fail.\n",
        "with assert_raises(TypeError):\n",
        "  next_collatz(tf.constant([1.0, 2.0]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocxX-HVk7P2o"
      },
      "source": [
        "#### Use dimensões desconhecidas para maior flexibilidade\n",
        "\n",
        "Como o TensorFlow compara tensores com base no seu formato, usar uma dimensão `None` como curinga permitirá que as `Function` reutilizem traces para entradas de tamanhos variáveis. Entradas de tamanhos variáveis ​​podem ocorrer se você tiver sequências de comprimentos diferentes ou imagens de tamanhos diferentes para cada lote (veja os tutoriais [Transformer](../tutorials/text/transformer.ipynb) e [Deep Dream](../tutorials/generative/deepdream.ipynb), por exemplo)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Viun7dh7PmF"
      },
      "outputs": [],
      "source": [
        "@tf.function(input_signature=(tf.TensorSpec(shape=[None], dtype=tf.int32),))\n",
        "def g(x):\n",
        "  print('Tracing with', x)\n",
        "  return x\n",
        "\n",
        "# No retrace!\n",
        "print(g(tf.constant([1, 2, 3])))\n",
        "print(g(tf.constant([1, 2, 3, 4, 5])))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AY5oiQN0XIyA"
      },
      "source": [
        "#### Passe tensores em vez de literais python\n",
        "\n",
        "Freqüentemente, argumentos do Python são usados ​​para controlar hiperparâmetros e construções de grafos, por exemplo, `num_layers=10` ou `training=True` ou `nonlinearity='relu'`. Portanto, se o argumento Python mudar, faz sentido que você tenha que fazer o retracing do grafo.\n",
        "\n",
        "No entanto, é possível que um argumento Python não esteja sendo usado para controlar a construção do grafo. Nesses casos, uma alteração no valor Python pode desencadear um retracing desnecessário. Veja, por exemplo, este loop de treinamento, que o AutoGraph irá desenrolar dinamicamente. Apesar dos múltiplos traces, o gráfico gerado é na verdade idêntico, portanto, fazer retracing aqui é desnecessário."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uydzR5JYUU8H"
      },
      "outputs": [],
      "source": [
        "def train_one_step():\n",
        "  pass\n",
        "\n",
        "@tf.function\n",
        "def train(num_steps):\n",
        "  print(\"Tracing with num_steps = \", num_steps)\n",
        "  tf.print(\"Executing with num_steps = \", num_steps)\n",
        "  for _ in tf.range(num_steps):\n",
        "    train_one_step()\n",
        "\n",
        "print(\"Retracing occurs for different Python arguments.\")\n",
        "train(num_steps=10)\n",
        "train(num_steps=20)\n",
        "\n",
        "print()\n",
        "print(\"Traces are reused for Tensor arguments.\")\n",
        "train(num_steps=tf.constant(10))\n",
        "train(num_steps=tf.constant(20))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pJqkDR_Q2wz"
      },
      "source": [
        "Se você precisar forçar o retracing, crie uma nova `Function`. É garantido que objetos `Function` separados não compartilhem traces."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uHp4ousu4DdN"
      },
      "outputs": [],
      "source": [
        "def f():\n",
        "  print('Tracing!')\n",
        "  tf.print('Executing')\n",
        "\n",
        "tf.function(f)()\n",
        "tf.function(f)()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tZoWrA6INvc"
      },
      "source": [
        "#### Use o protocolo de tracing\n",
        "\n",
        "Sempre que possível, você deve dar preferência a converter o tipo Python em `tf.experimental.ExtensionType`. Além disso, o `TraceType` de um `ExtensionType` é o `tf.TypeSpec` associado a ele. Portanto, se necessário, você pode simplesmente sobrepor o `tf.TypeSpec` padrão para assumir o controle de um `Tracing Protocol` do `ExtensionType`. Consulte a seção *Personalizando o TypeSpec do ExtensionType* no guia [Extension types](extension_type.ipynb) para mais detalhes.\n",
        "\n",
        "Caso contrário, para ter controle direto sobre quando `Function` deve fazer retracing quanto a um tipo específico do Python, você mesmo pode implementar o `Tracing Protocol` para ela."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gZkIh7UaIKc6"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def get_mixed_flavor(fruit_a, fruit_b):\n",
        "  return fruit_a.flavor + fruit_b.flavor\n",
        "\n",
        "class Fruit:\n",
        "  flavor = tf.constant([0, 0])\n",
        "\n",
        "class Apple(Fruit):\n",
        "  flavor = tf.constant([1, 2])\n",
        "\n",
        "class Mango(Fruit):\n",
        "  flavor = tf.constant([3, 4])\n",
        "\n",
        "# As described in the above rules, a generic TraceType for `Apple` and `Mango`\n",
        "# is generated (and a corresponding ConcreteFunction is traced) but it fails to\n",
        "# match the second function call since the first pair of Apple() and Mango()\n",
        "# have gone out out of scope by then and deleted.\n",
        "get_mixed_flavor(Apple(), Mango()) # Traces a new concrete function\n",
        "get_mixed_flavor(Apple(), Mango()) # Traces a new concrete function again\n",
        "\n",
        "# However, each subclass of the `Fruit` class has a fixed flavor, and you\n",
        "# can reuse an existing traced concrete function if it was the same\n",
        "# subclass. Avoiding such unnecessary tracing of concrete functions\n",
        "# can have significant performance benefits.\n",
        "\n",
        "class FruitTraceType(tf.types.experimental.TraceType):\n",
        "  def __init__(self, fruit):\n",
        "    self.fruit_type = type(fruit)\n",
        "    self.fruit_value = fruit\n",
        "\n",
        "  def is_subtype_of(self, other):\n",
        "      # True if self subtypes `other` and `other`'s type matches FruitTraceType.\n",
        "      return (type(other) is FruitTraceType and\n",
        "              self.fruit_type is other.fruit_type)\n",
        "\n",
        "  def most_specific_common_supertype(self, others):\n",
        "      # `self` is the specific common supertype if all input types match it.\n",
        "      return self if all(self == other for other in others) else None\n",
        "\n",
        "  def placeholder_value(self, placeholder_context=None):\n",
        "      # Use the fruit itself instead of the type for correct tracing.\n",
        "      return self.fruit_value\n",
        "\n",
        "  def __eq__(self, other):\n",
        "    return type(other) is FruitTraceType and self.fruit_type == other.fruit_type\n",
        "\n",
        "  def __hash__(self):\n",
        "    return hash(self.fruit_type)\n",
        "\n",
        "class FruitWithTraceType:\n",
        "\n",
        "  def __tf_tracing_type__(self, context):\n",
        "    return FruitTraceType(self)\n",
        "\n",
        "class AppleWithTraceType(FruitWithTraceType):\n",
        "  flavor = tf.constant([1, 2])\n",
        "\n",
        "class MangoWithTraceType(FruitWithTraceType):\n",
        "  flavor = tf.constant([3, 4])\n",
        "\n",
        "# Now if you try calling it again:\n",
        "get_mixed_flavor(AppleWithTraceType(), MangoWithTraceType()) # Traces a new concrete function\n",
        "get_mixed_flavor(AppleWithTraceType(), MangoWithTraceType()) # Re-uses the traced concrete function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96IxS2WR37fF"
      },
      "source": [
        "### Obtendo funções concretas\n",
        "\n",
        "Cada vez que o tracing de uma função é realizado, uma nova função concreta é criada. Você pode obter diretamente uma função concreta usando `get_concrete_function`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mHg2CGtPQ3Hz"
      },
      "outputs": [],
      "source": [
        "print(\"Obtaining concrete trace\")\n",
        "double_strings = double.get_concrete_function(tf.constant(\"a\"))\n",
        "print(\"Executing traced function\")\n",
        "print(double_strings(tf.constant(\"a\")))\n",
        "print(double_strings(a=tf.constant(\"b\")))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6IVZ-NVf9vsx"
      },
      "outputs": [],
      "source": [
        "# You can also call get_concrete_function on an InputSpec\n",
        "double_strings_from_inputspec = double.get_concrete_function(tf.TensorSpec(shape=[], dtype=tf.string))\n",
        "print(double_strings_from_inputspec(tf.constant(\"c\")))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iR4fVmG34xvF"
      },
      "source": [
        "Imprimir uma `ConcreteFunction` mostra um resumo de seus argumentos de entrada (com tipos) e seu tipo de saída."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o3-JbkIk41r8"
      },
      "outputs": [],
      "source": [
        "print(double_strings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtqfvljZeuOV"
      },
      "source": [
        "Você também pode recuperar diretamente a assinatura de uma função concreta."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nzbrqFABe0zG"
      },
      "outputs": [],
      "source": [
        "print(double_strings.structured_input_signature)\n",
        "print(double_strings.structured_outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lar5A_5m5IG1"
      },
      "source": [
        "Usar um trace concreto com tipos incompatíveis gerará um erro"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G5eeTK-T5KYj"
      },
      "outputs": [],
      "source": [
        "with assert_raises(tf.errors.InvalidArgumentError):\n",
        "  double_strings(tf.constant(1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "st2L9VNQVtSG"
      },
      "source": [
        "Você talvez perceba que os argumentos Python recebem tratamento especial na assinatura de entrada de uma função concreta. Antes do TensorFlow 2.3, os argumentos Python eram simplesmente removidos da assinatura da função concreta. A partir do TensorFlow 2.3, os argumentos Python permanecem na assinatura, mas são limitados a aceitar o valor definido durante o tracing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U_QyPSGoaC35"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def pow(a, b):\n",
        "  return a ** b\n",
        "\n",
        "square = pow.get_concrete_function(a=tf.TensorSpec(None, tf.float32), b=2)\n",
        "print(square)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E76vIDhQbXIb"
      },
      "outputs": [],
      "source": [
        "assert square(tf.constant(10.0)) == 100\n",
        "\n",
        "with assert_raises(TypeError):\n",
        "  square(tf.constant(10.0), b=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41gJh_JGIfuA"
      },
      "source": [
        "### Obtendo grafos\n",
        "\n",
        "Cada função concreta é um wrapper em torno de um `tf.Graph` que pode ser chamado. Embora recuperar o objeto `tf.Graph` real não seja algo que você normalmente precisará fazer, você pode obtê-lo facilmente a partir de qualquer função concreta."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5UENeGHfaX8g"
      },
      "outputs": [],
      "source": [
        "graph = double_strings.graph\n",
        "for node in graph.as_graph_def().node:\n",
        "  print(f'{node.input} -> {node.name}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIKkgr6qdtp4"
      },
      "source": [
        "### Depuração\n",
        "\n",
        "Em geral, depurar código é mais fácil no modo eager do que dentro de `tf.function`. Você deve garantir que seu código seja executado sem erros no modo eager antes de decorar com `tf.function`. Para auxiliar no processo de depuração, você pode chamar `tf.config.run_functions_eagerly(True)` para desativar e reativar globalmente `tf.function`.\n",
        "\n",
        "Ao rastrear problemas que aparecem apenas em `tf.function`, aqui estão algumas dicas:\n",
        "\n",
        "- Chamadas `print` do Python são executadas apenas durante o tracing, ajudando você a rastrear quando ocorrer o (re)tracing da sua função.\n",
        "- As chamadas `tf.print` serão executadas sempre e podem ajudá-lo a rastrear valores intermediários durante a execução.\n",
        "- `tf.debugging.enable_check_numerics` é uma maneira fácil de rastrear onde NaNs e Inf são criados.\n",
        "- `pdb` (o [depurador Python](https://docs.python.org/3/library/pdb.html) ) pode ajudá-lo a entender o que está acontecendo durante o tracing. (Ressalva: o `pdb` vai mandar você para o código-fonte transformado pelo AutoGraph.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5f05Vr_YBUCz"
      },
      "source": [
        "## Transformações AutoGraph\n",
        "\n",
        "AutoGraph é uma biblioteca ativada por padrão em `tf.function` e transforma um subconjunto de código eager do Python em ops do TensorFlow compatíveis com grafos. Isto inclui operações de controle de fluxo como `if`, `for`, `while`.\n",
        "\n",
        "Ops do TensorFlow como `tf.cond` e `tf.while_loop` continuam funcionando, mas o controle de fluxo geralmente é mais fácil de escrever e entender quando escrito em Python."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yCQTtTPTW3WF"
      },
      "outputs": [],
      "source": [
        "# A simple loop\n",
        "\n",
        "@tf.function\n",
        "def f(x):\n",
        "  while tf.reduce_sum(x) > 1:\n",
        "    tf.print(x)\n",
        "    x = tf.tanh(x)\n",
        "  return x\n",
        "\n",
        "f(tf.random.uniform([5]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxwJ8znPI0Cg"
      },
      "source": [
        "Se você tiver curiosidade, pode inspecionar o código gerado pelo AutoGraph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jlQD1ffRXJhl"
      },
      "outputs": [],
      "source": [
        "print(tf.autograph.to_code(f.python_function))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgKmkrNTZSyz"
      },
      "source": [
        "### Condicionais\n",
        "\n",
        "O AutoGraph converterá algumas instruções `if <condition>` em chamadas `tf.cond` equivalentes. Esta substituição é feita se `<condition>` for um Tensor. Caso contrário, a instrução `if` será executada como uma condicional Python.\n",
        "\n",
        "Uma expressão condicional Python é executada durante o tracing, portanto, exatamente um ramo da expressão condicional será adicionada ao grafo. Sem o AutoGraph, este grafo rastreado não seria capaz de seguir o ramo alternativo se houvesse controle de fluxo dependente de dados.\n",
        "\n",
        "`tf.cond` faz o tracing e adiciona ambos os ramos da expressão condicional ao grafo, selecionando dinamicamente um ramo em tempo de execução. O tracing pode ter efeitos colaterais indesejados; veja [Efeitos de tracing do AutoGraph](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/g3doc/reference/control_flow.md#effects-of-the-tracing-process) para mais informações."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BOQl8PMq2Sf3"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def fizzbuzz(n):\n",
        "  for i in tf.range(1, n + 1):\n",
        "    print('Tracing for loop')\n",
        "    if i % 15 == 0:\n",
        "      print('Tracing fizzbuzz branch')\n",
        "      tf.print('fizzbuzz')\n",
        "    elif i % 3 == 0:\n",
        "      print('Tracing fizz branch')\n",
        "      tf.print('fizz')\n",
        "    elif i % 5 == 0:\n",
        "      print('Tracing buzz branch')\n",
        "      tf.print('buzz')\n",
        "    else:\n",
        "      print('Tracing default branch')\n",
        "      tf.print(i)\n",
        "\n",
        "fizzbuzz(tf.constant(5))\n",
        "fizzbuzz(tf.constant(20))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rBO5AQ15HVC"
      },
      "source": [
        "Consulte a [documentação de referência](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/g3doc/reference/control_flow.md#if-statements) para saber de restrições adicionais sobre instruções if convertidas em AutoGraph."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yho4J0a0ZkQS"
      },
      "source": [
        "### Loops\n",
        "\n",
        "O AutoGraph converterá algumas instruções `for` e `while` em operações de loop equivalentes do TensorFlow, como `tf.while_loop`. Se não for convertido, o loop `for` ou `while` será executado como um loop Python.\n",
        "\n",
        "Esta substituição é feita nas seguintes situações:\n",
        "\n",
        "- `for x in y`: se `y` for um Tensor, converta para `tf.while_loop`. No caso especial em que `y` é um `tf.data.Dataset`, uma combinação de operações de `tf.data.Dataset` é gerada.\n",
        "- `while <condition>`: se `<condition>` for um Tensor, converta para `tf.while_loop`.\n",
        "\n",
        "Um loop Python é executado durante o tracing, adicionando ops adicionais ao `tf.Graph` para cada iteração do loop.\n",
        "\n",
        "Um loop do TensorFlow faz tracing do corpo do loop e seleciona dinamicamente quantas iterações serão executadas em tempo de execução. O corpo do loop aparece apenas uma vez no `tf.Graph` gerado.\n",
        "\n",
        "Veja a [documentação de referência](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/g3doc/reference/control_flow.md#while-statements) para conhecer restrições adicionais nas instruções `for` e `while` convertidas pelo AutoGraph."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sp4rbIdfbM6s"
      },
      "source": [
        "#### Loop sobre dados Python\n",
        "\n",
        "Uma armadilha comum é fazer um loop nos dados Python/NumPy dentro de um `tf.function`. Este loop será executado durante o processo de tracing, adicionando uma cópia do seu modelo ao `tf.Graph` para cada iteração do loop.\n",
        "\n",
        "Se você quiser encapsular todo o loop de treinamento em `tf.function`, a maneira mais segura de fazer isso é encapsular seus dados usando um `tf.data.Dataset` como wrapper para que o AutoGraph desenrole dinamicamente o loop de treinamento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WGZ19LspbZ27"
      },
      "outputs": [],
      "source": [
        "def measure_graph_size(f, *args):\n",
        "  g = f.get_concrete_function(*args).graph\n",
        "  print(\"{}({}) contains {} nodes in its graph\".format(\n",
        "      f.__name__, ', '.join(map(str, args)), len(g.as_graph_def().node)))\n",
        "\n",
        "@tf.function\n",
        "def train(dataset):\n",
        "  loss = tf.constant(0)\n",
        "  for x, y in dataset:\n",
        "    loss += tf.abs(y - x) # Some dummy computation.\n",
        "  return loss\n",
        "\n",
        "small_data = [(1, 1)] * 3\n",
        "big_data = [(1, 1)] * 10\n",
        "measure_graph_size(train, small_data)\n",
        "measure_graph_size(train, big_data)\n",
        "\n",
        "measure_graph_size(train, tf.data.Dataset.from_generator(\n",
        "    lambda: small_data, (tf.int32, tf.int32)))\n",
        "measure_graph_size(train, tf.data.Dataset.from_generator(\n",
        "    lambda: big_data, (tf.int32, tf.int32)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JeD2U-yrbfVb"
      },
      "source": [
        "Ao encapsular dados Python/NumPy num dataset, lembre-se de `tf.data.Dataset.from_generator` versus `tf.data.Dataset.from_tensor_slices`. O primeiro manterá os dados em Python e os buscará via `tf.py_function`, o que pode ter implicações no desempenho, enquanto o último agrupará uma cópia dos dados como uma grande `tf.constant()` no grafo, o que pode ter implicações no uso de memória.\n",
        "\n",
        "Ler dados de arquivos via `TFRecordDataset`, `CsvDataset`, etc. é a maneira mais eficaz de consumir dados, pois o próprio TensorFlow pode gerenciar o carregamento assíncrono e a pré-busca de dados, sem a necessidade de envolver o Python. Para saber mais, consulte o guia [`tf.data`: Criando pipelines de entrada no TensorFlow](../../guide/data)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyksHW9TCukR"
      },
      "source": [
        "#### Acumulando valores em um loop\n",
        "\n",
        "Um padrão comum é acumular valores intermediários de um loop. Normalmente, isso é feito anexando-se a uma lista Python ou adicionando entradas a um dicionário Python. No entanto, como esses são efeitos colaterais do Python, eles não funcionarão como esperado num loop desenrolado dinamicamente. Use `tf.TensorArray` para acumular resultados de um loop desenrolado dinamicamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HJ3Vb3dXfefN"
      },
      "outputs": [],
      "source": [
        "batch_size = 2\n",
        "seq_len = 3\n",
        "feature_size = 4\n",
        "\n",
        "def rnn_step(inp, state):\n",
        "  return inp + state\n",
        "\n",
        "@tf.function\n",
        "def dynamic_rnn(rnn_step, input_data, initial_state):\n",
        "  # [batch, time, features] -> [time, batch, features]\n",
        "  input_data = tf.transpose(input_data, [1, 0, 2])\n",
        "  max_seq_len = input_data.shape[0]\n",
        "\n",
        "  states = tf.TensorArray(tf.float32, size=max_seq_len)\n",
        "  state = initial_state\n",
        "  for i in tf.range(max_seq_len):\n",
        "    state = rnn_step(input_data[i], state)\n",
        "    states = states.write(i, state)\n",
        "  return tf.transpose(states.stack(), [1, 0, 2])\n",
        "\n",
        "dynamic_rnn(rnn_step,\n",
        "            tf.random.uniform([batch_size, seq_len, feature_size]),\n",
        "            tf.zeros([batch_size, feature_size]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2MVoIVaNApG"
      },
      "source": [
        "## Limitações\n",
        "\n",
        "TensorFlow `Function` tem algumas limitações de design que você deve conhecer ao converter uma função Python em `Function`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJqHGFSVLIKl"
      },
      "source": [
        "### Executando efeitos colaterais do Python\n",
        "\n",
        "Os efeitos colaterais, como impressão, anexação a listas e mutação de variáveis globais, podem se comportar inesperadamente dentro de uma `Function`, às vezes executando duas vezes ou nunca. Isto só acontece na primeira vez que você chama uma `Function` com um conjunto de entradas. Posteriormente, o `tf.Graph` traçado é reexecutado, e não executará o código Python.\n",
        "\n",
        "A regra geral é evitar depender dos efeitos colaterais do Python em sua lógica e usá-los apenas para depurar seus traces. Caso contrário, APIs do TensorFlow como `tf.data`, `tf.print`, `tf.summary`, `tf.Variable.assign` e `tf.TensorArray` são a melhor maneira de garantir que seu código será executado pelo runtime do TensorFlow a cada chamada."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w2sACuZ9TTRk"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def f(x):\n",
        "  print(\"Traced with\", x)\n",
        "  tf.print(\"Executed with\", x)\n",
        "\n",
        "f(1)\n",
        "f(1)\n",
        "f(2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1I0dPiqTV8H"
      },
      "source": [
        "Se você quiser executar o código Python durante cada chamada de uma `Function`, `tf.py_function` é uma saída. A desvantagem de `tf.py_function` é que ela não é portátil nem tem bom desempenho, não pode ser salva com SavedModel e não funciona bem em configurações distribuídas (multi-GPU, TPU). Além disso, como `tf.py_function` precisa ser interligado ao grafo, ela converte todas as entradas/saídas em tensores."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOW1v9WVKGgH"
      },
      "source": [
        "#### Alterando variáveis ​​globais e livres do Python\n",
        "\n",
        "Alterar [as variáveis ​​globais e livres](https://docs.python.org/3/reference/executionmodel.html#binding-of-names) do Python conta como um efeito colateral do Python, então só acontece durante o tracing.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7aJD--9qTWmg"
      },
      "outputs": [],
      "source": [
        "external_list = []\n",
        "\n",
        "@tf.function\n",
        "def side_effect(x):\n",
        "  print('Python side effect')\n",
        "  external_list.append(x)\n",
        "\n",
        "side_effect(1)\n",
        "side_effect(1)\n",
        "side_effect(1)\n",
        "# The list append only happened once!\n",
        "assert len(external_list) == 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5eZTFRv_k_nR"
      },
      "source": [
        "Às vezes, comportamentos inesperados são muito difíceis de perceber. No exemplo abaixo, o `counter` tem como objetivo salvaguardar o incremento de uma variável. No entanto, como é um inteiro Python e não um objeto TensorFlow, seu valor é capturado durante o primeiro trace. Quando `tf.function` for usado, `assign_add` será registrado incondicionalmente no grafo subjacente. Portanto `v` aumentará em 1, todas as vezes que a `tf.function` for chamada. Esse problema é comum entre usuários que tentam migrar seu código Tensorflow no modo grafo para o Tensorflow 2 usando decoradores `tf.function`, quando os efeitos colaterais do Python (o `counter` no exemplo) são usados ​​para determinar quais operações executar (`assign_add` no exemplo). Normalmente, os usuários percebem isso somente depois de verem resultados numéricos suspeitos ou um desempenho significativamente inferior ao esperado (por exemplo, se a operação protegida for muito ineficiente)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5r6p7-9jk_3L"
      },
      "outputs": [],
      "source": [
        "class Model(tf.Module):\n",
        "  def __init__(self):\n",
        "    self.v = tf.Variable(0)\n",
        "    self.counter = 0\n",
        "\n",
        "  @tf.function\n",
        "  def __call__(self):\n",
        "    if self.counter == 0:\n",
        "      # A python side-effect\n",
        "      self.counter += 1\n",
        "      self.v.assign_add(1)\n",
        "\n",
        "    return self.v\n",
        "\n",
        "m = Model()\n",
        "for n in range(3):\n",
        "  print(m().numpy()) # prints 1, 2, 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXCTcHoVcxhX"
      },
      "source": [
        "Uma solução alternativa para alcançar o comportamento esperado é usar [`tf.init_scope`](https://www.tensorflow.org/api_docs/python/tf/init_scope) para transferir as operações para fora do grafo de função. Isto garante que o incremento da variável seja feito apenas uma vez durante o tempo de tracing. Deve-se observar que `init_scope` tem outros efeitos colaterais, incluindo fluxo de controle limpo e fita gradiente. Às vezes, o uso de `init_scope` pode se tornar muito complexo para ser gerenciado de forma realista."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "An4MrIbrcvi8"
      },
      "outputs": [],
      "source": [
        "class Model(tf.Module):\n",
        "  def __init__(self):\n",
        "    self.v = tf.Variable(0)\n",
        "    self.counter = 0\n",
        "\n",
        "  @tf.function\n",
        "  def __call__(self):\n",
        "    if self.counter == 0:\n",
        "      # Lifts ops out of function-building graphs\n",
        "      with tf.init_scope():\n",
        "        self.counter += 1\n",
        "        self.v.assign_add(1)\n",
        "\n",
        "    return self.v\n",
        "\n",
        "m = Model()\n",
        "for n in range(3):\n",
        "  print(m().numpy()) # prints 1, 1, 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbFG5CX4LwQA"
      },
      "source": [
        "Em suma, como regra geral, você deve evitar a mutação de objetos python, como números inteiros ou containers, como listas que residem fora de `Function`. Em vez disso, use argumentos e objetos do TF. Por exemplo, a seção [\"Acumulando valores em um loop\"](#accumulating_values_in_a_loop) traz um exemplo de como operações do tipo lista podem ser implementadas.\n",
        "\n",
        "Você pode, em alguns casos, capturar e manipular o estado se for uma [`tf.Variable`](https://www.tensorflow.org/guide/variable). É assim que os pesos dos modelos Keras são atualizados com chamadas repetidas para a mesma `ConcreteFunction`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_oNNGrAqPJ1"
      },
      "source": [
        "#### Usando iteradores e geradores Python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "msTmv-oyUNaf"
      },
      "source": [
        "Muitos recursos do Python, como geradores e iteradores, dependem do runtime do Python para controlar o estado. Em geral, embora esses construtos funcionem conforme o esperado no modo eager, elas são exemplos de efeitos colaterais do Python e, portanto, só acontecem durante o tracing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FNPD4unZUedH"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def buggy_consume_next(iterator):\n",
        "  tf.print(\"Value:\", next(iterator))\n",
        "\n",
        "iterator = iter([1, 2, 3])\n",
        "buggy_consume_next(iterator)\n",
        "# This reuses the first value from the iterator, rather than consuming the next value.\n",
        "buggy_consume_next(iterator)\n",
        "buggy_consume_next(iterator)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcS3TAgCjTWR"
      },
      "source": [
        "Assim como o TensorFlow possui um `tf.TensorArray` especializado para construtos de lista, ele possui um `tf.data.Iterator` especializado para construtos de iteração. Veja a seção sobre [transformações do AutoGraph](#autograph_transformations) para uma visão geral. Além disso, a API [`tf.data`](https://www.tensorflow.org/guide/data) pode ajudar a implementar padrões de gerador:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8D_iKetXW6VE"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def good_consume_next(iterator):\n",
        "  # This is ok, iterator is a tf.data.Iterator\n",
        "  tf.print(\"Value:\", next(iterator))\n",
        "\n",
        "ds = tf.data.Dataset.from_tensor_slices([1, 2, 3])\n",
        "iterator = iter(ds)\n",
        "good_consume_next(iterator)\n",
        "good_consume_next(iterator)\n",
        "good_consume_next(iterator)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8YAMYb6KEh4"
      },
      "source": [
        "### Todas as saídas de uma tf.function devem ser valores de retorno\n",
        "\n",
        "Com exceção de `tf.Variable`, uma tf.function deve retornar todas as suas saídas. Tentar acessar diretamente qualquer tensor de uma função sem passar pelos valores de retorno causa \"vazamentos\".\n",
        "\n",
        "Por exemplo, a função abaixo \"vaza\" o tensor `a` através da variável global `x` declarada em Python:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zrdp4rjxg6jo"
      },
      "outputs": [],
      "source": [
        "x = None\n",
        "\n",
        "@tf.function\n",
        "def leaky_function(a):\n",
        "  global x\n",
        "  x = a + 1  # Bad - leaks local tensor\n",
        "  return a + 2\n",
        "\n",
        "correct_a = leaky_function(tf.constant(1))\n",
        "\n",
        "print(correct_a.numpy())  # Good - value obtained from function's returns\n",
        "try:\n",
        "  x.numpy()  # Bad - tensor leaked from inside the function, cannot be used here\n",
        "except AttributeError as expected:\n",
        "  print(expected)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-d4_J_DC5rxX"
      },
      "source": [
        "Isso é verdade mesmo que o valor vazado também seja retornado:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PrcpPB8C5s9T"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def leaky_function(a):\n",
        "  global x\n",
        "  x = a + 1  # Bad - leaks local tensor\n",
        "  return x  # Good - uses local tensor\n",
        "\n",
        "correct_a = leaky_function(tf.constant(1))\n",
        "\n",
        "print(correct_a.numpy())  # Good - value obtained from function's returns\n",
        "try:\n",
        "  x.numpy()  # Bad - tensor leaked from inside the function, cannot be used here\n",
        "except AttributeError as expected:\n",
        "  print(expected)\n",
        "\n",
        "@tf.function\n",
        "def captures_leaked_tensor(b):\n",
        "  b += x  # Bad - `x` is leaked from `leaky_function`\n",
        "  return b\n",
        "\n",
        "with assert_raises(TypeError):\n",
        "  captures_leaked_tensor(tf.constant(2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sm2ghjyy50D4"
      },
      "source": [
        "Geralmente, vazamentos como esses ocorrem quando você usa instruções ou estruturas de dados do Python. Além de vazar tensores inacessíveis, tais instruções provavelmente também estão erradas porque contam como efeitos colaterais do Python e não têm garantia de execução a cada chamada de função.\n",
        "\n",
        "Maneiras comuns de vazar tensores locais também incluem a mutação de uma coleção Python externa ou de um objeto:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D7bLe8y652wU"
      },
      "outputs": [],
      "source": [
        "class MyClass:\n",
        "\n",
        "  def __init__(self):\n",
        "    self.field = None\n",
        "\n",
        "external_list = []\n",
        "external_object = MyClass()\n",
        "\n",
        "def leaky_function():\n",
        "  a = tf.constant(1)\n",
        "  external_list.append(a)  # Bad - leaks tensor\n",
        "  external_object.field = a  # Bad - leaks tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-XVQcD-wf5K"
      },
      "source": [
        "### Funções tf.function recursivas não são suportadas\n",
        "\n",
        "`Function` recursivas não são suportadas e podem causar loops infinitos. Por exemplo,"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QSN-T1m5EFcR"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def recursive_fn(n):\n",
        "  if n > 0:\n",
        "    return recursive_fn(n - 1)\n",
        "  else:\n",
        "    return 1\n",
        "\n",
        "with assert_raises(Exception):\n",
        "  recursive_fn(tf.constant(5))  # Bad - maximum recursion error."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LyRyooKGUxNV"
      },
      "source": [
        "Mesmo que uma `Function` recursiva pareça funcionar, ocorrerá tracing da função Python várias vezes e isto poderá ter implicações no desempenho. Por exemplo,"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7FlmTqfMUwmT"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def recursive_fn(n):\n",
        "  if n > 0:\n",
        "    print('tracing')\n",
        "    return recursive_fn(n - 1)\n",
        "  else:\n",
        "    return 1\n",
        "\n",
        "recursive_fn(5)  # Warning - multiple tracings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-D6nh3QirXAd"
      },
      "source": [
        "## Problemas conhecidos\n",
        "\n",
        "Se a sua `Function` não estiver sendo avaliada corretamente, o erro pode ser explicado por esses problemas conhecidos que devem ser corrigidos no futuro."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZoPg5w1Pjqna"
      },
      "source": [
        "### Depender de variáveis ​​globais e livres do Python\n",
        "\n",
        "`Function` cria uma nova `ConcreteFunction` quando chamada com um novo valor de um argumento Python. No entanto, ele não faz isso para o closure do Python, nem valores globais ou não locais dessa `Function`. Se o valor deles mudar entre as chamadas para `Function`, a `Function` ainda usará os valores que tinham quando ela passou pelo tracing. Isso difere da forma como funcionam as funções comuns do Python.\n",
        "\n",
        "Por esse motivo, você deve seguir um estilo de programação funcional que use argumentos em vez de closures sobre nomes externos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oeJMdXd3M0cM"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def buggy_add():\n",
        "  return 1 + foo\n",
        "\n",
        "@tf.function\n",
        "def recommended_add(foo):\n",
        "  return 1 + foo\n",
        "\n",
        "foo = 1\n",
        "print(\"Buggy:\", buggy_add())\n",
        "print(\"Correct:\", recommended_add(foo))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L3q7sUJWZOSU"
      },
      "outputs": [],
      "source": [
        "print(\"Updating the value of `foo` to 100!\")\n",
        "foo = 100\n",
        "print(\"Buggy:\", buggy_add())  # Did not change!\n",
        "print(\"Correct:\", recommended_add(foo))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZoPg5w1Pjqnb"
      },
      "source": [
        "Outra maneira de atualizar um valor global é torná-lo uma `tf.Variable` e usar o método `Variable.assign`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oeJMdXd3M0cc"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def variable_add():\n",
        "  return 1 + foo\n",
        "\n",
        "foo = tf.Variable(1)\n",
        "print(\"Variable:\", variable_add())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L3q7sUJWZOSd"
      },
      "outputs": [],
      "source": [
        "print(\"Updating the value of `foo` to 100!\")\n",
        "foo.assign(100)\n",
        "print(\"Variable:\", variable_add())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvwe9gTIWfx6"
      },
      "source": [
        "### Depender de objetos Python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJkZS-SwPvOQ"
      },
      "source": [
        "Você pode passar objetos Python personalizados como argumentos para `tf.function` mas isso traz algumas limitações.\n",
        "\n",
        "Para cobertura máxima de recursos, considere transformar os objetos em [tipos de extensão](extension_type.ipynb) antes de passá-los para `tf.function`. Você também pode usar primitivos Python e estruturas compatíveis com `tf.nest`.\n",
        "\n",
        "No entanto, conforme abordado nas [regras de tracing](#rules_of_tracing), quando um `TraceType` personalizado não é fornecido pela classe Python personalizada, a `tf.function` é obrigada a usar igualdade baseada em instância, o que significa que **não criará um novo trace** quando você passar o **mesmo objeto com atributos modificados**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ux8KJESVWDxX"
      },
      "outputs": [],
      "source": [
        "class SimpleModel(tf.Module):\n",
        "  def __init__(self):\n",
        "    # These values are *not* tf.Variables.\n",
        "    self.bias = 0.\n",
        "    self.weight = 2.\n",
        "\n",
        "@tf.function\n",
        "def evaluate(model, x):\n",
        "  return model.weight * x + model.bias\n",
        "\n",
        "simple_model = SimpleModel()\n",
        "x = tf.constant(10.)\n",
        "print(evaluate(simple_model, x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mUxRF4ghZZvX"
      },
      "outputs": [],
      "source": [
        "print(\"Adding bias!\")\n",
        "simple_model.bias += 5.0\n",
        "print(evaluate(simple_model, x))  # Didn't change :("
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ytcgg2qFWaBF"
      },
      "source": [
        "Usar a mesma `Function` para avaliar a instância modificada do modelo será problemático, pois ele ainda possui o [mesmo TraceType baseado em instância](#rules_of_tracing) do modelo original.\n",
        "\n",
        "Por esse motivo, é recomendável escrever sua `Function` para evitar depender de atributos de objetos mutáveis ​​ou implementar o [Protocolo de Tracing](#use_the_tracing_protocol) para os objetos para informar `Function` sobre tais atributos.\n",
        "\n",
        "Se isso não for possível, uma solução alternativa é criar novos objetos `Function` cada vez que você modificar seu objeto para forçar o retracing:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pFvWmWAAQjrv"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, x):\n",
        "  return model.weight * x + model.bias\n",
        "\n",
        "new_model = SimpleModel()\n",
        "evaluate_no_bias = tf.function(evaluate).get_concrete_function(new_model, x)\n",
        "# Don't pass in `new_model`, `Function` already captured its state during tracing.\n",
        "print(evaluate_no_bias(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bdU2-jF4ZH0B"
      },
      "outputs": [],
      "source": [
        "print(\"Adding bias!\")\n",
        "new_model.bias += 5.0\n",
        "# Create new Function and ConcreteFunction since you modified new_model.\n",
        "evaluate_with_bias = tf.function(evaluate).get_concrete_function(new_model, x)\n",
        "print(evaluate_with_bias(x)) # Don't pass in `new_model`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFgEZClsZrEi"
      },
      "source": [
        "Como o [retracing pode ter um custo elevado](https://www.tensorflow.org/guide/intro_to_graphs#tracing_and_performance), você pode usar objetos `tf.Variable` como atributos de objeto, que podem ser alterados (mas não trocados, cuidado!) para um efeito semelhante sem a necessidade de um retrace.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "daAP_lucwS6w"
      },
      "outputs": [],
      "source": [
        "class BetterModel:\n",
        "\n",
        "  def __init__(self):\n",
        "    self.bias = tf.Variable(0.)\n",
        "    self.weight = tf.Variable(2.)\n",
        "\n",
        "@tf.function\n",
        "def evaluate(model, x):\n",
        "  return model.weight * x + model.bias\n",
        "\n",
        "better_model = BetterModel()\n",
        "print(evaluate(better_model, x))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ktqwMJBqwTFj"
      },
      "outputs": [],
      "source": [
        "print(\"Adding bias!\")\n",
        "better_model.bias.assign_add(5.0)  # Note: instead of better_model.bias += 5\n",
        "print(evaluate(better_model, x))  # This works!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lPr_6mK_AQWL"
      },
      "source": [
        "### Criação de tf.Variables\n",
        "\n",
        "`Function` suporta apenas objetos `tf.Variable` singleton, criados uma vez na primeira chamada e reutilizados nas chamadas de função subsequentes. O trecho de código abaixo criaria um novo `tf.Variable` em cada chamada de função, o que resulta numa exceção `ValueError`.\n",
        "\n",
        "Exemplo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tx0Vvnb_9OB-"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def f(x):\n",
        "  v = tf.Variable(1.0)\n",
        "  return v\n",
        "\n",
        "with assert_raises(ValueError):\n",
        "  f(1.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYm6-5GCILXQ"
      },
      "source": [
        "Um padrão comum usado para contornar essa limitação é começar com um valor Python None e, em seguida, criar condicionalmente o `tf.Variable` se o valor for None:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HQrG5_kOiKl_"
      },
      "outputs": [],
      "source": [
        "class Count(tf.Module):\n",
        "  def __init__(self):\n",
        "    self.count = None\n",
        "\n",
        "  @tf.function\n",
        "  def __call__(self):\n",
        "    if self.count is None:\n",
        "      self.count = tf.Variable(0)\n",
        "    return self.count.assign_add(1)\n",
        "\n",
        "c = Count()\n",
        "print(c())\n",
        "print(c())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uD6qI7aJwbR"
      },
      "source": [
        "#### Uso com múltiplos otimizadores Keras\n",
        "\n",
        "Você talvez encontre o erro `ValueError: tf.function only supports singleton tf.Variables created on the first call.` ao usar mais de um otimizador Keras com um `tf.function`. Esse erro ocorre porque os otimizadores criam `tf.Variables` internamente quando aplicam gradientes pela primeira vez."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yWQ3-r99Jvze"
      },
      "outputs": [],
      "source": [
        "opt1 = tf.keras.optimizers.Adam(learning_rate = 1e-2)\n",
        "opt2 = tf.keras.optimizers.Adam(learning_rate = 1e-3)\n",
        "\n",
        "@tf.function\n",
        "def train_step(w, x, y, optimizer):\n",
        "   with tf.GradientTape() as tape:\n",
        "       L = tf.reduce_sum(tf.square(w*x - y))\n",
        "   gradients = tape.gradient(L, [w])\n",
        "   optimizer.apply_gradients(zip(gradients, [w]))\n",
        "\n",
        "w = tf.Variable(2.)\n",
        "x = tf.constant([-1.])\n",
        "y = tf.constant([2.])\n",
        "\n",
        "train_step(w, x, y, opt1)\n",
        "print(\"Calling `train_step` with different optimizer...\")\n",
        "with assert_raises(ValueError):\n",
        "  train_step(w, x, y, opt2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Q8BRPCThTjB"
      },
      "source": [
        "Se você precisar trocar o otimizador durante o treinamento, uma solução alternativa é criar uma nova `Function` para cada otimizador, chamando [`ConcreteFunction`](#obtaining_concrete_functions) diretamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YV5F2Gy9hSI3"
      },
      "outputs": [],
      "source": [
        "opt1 = tf.keras.optimizers.Adam(learning_rate = 1e-2)\n",
        "opt2 = tf.keras.optimizers.Adam(learning_rate = 1e-3)\n",
        "\n",
        "# Not a tf.function.\n",
        "def train_step(w, x, y, optimizer):\n",
        "   with tf.GradientTape() as tape:\n",
        "       L = tf.reduce_sum(tf.square(w*x - y))\n",
        "   gradients = tape.gradient(L, [w])\n",
        "   optimizer.apply_gradients(zip(gradients, [w]))\n",
        "\n",
        "w = tf.Variable(2.)\n",
        "x = tf.constant([-1.])\n",
        "y = tf.constant([2.])\n",
        "\n",
        "# Make a new Function and ConcreteFunction for each optimizer.\n",
        "train_step_1 = tf.function(train_step)\n",
        "train_step_2 = tf.function(train_step)\n",
        "for i in range(10):\n",
        "  if i % 2 == 0:\n",
        "    train_step_1(w, x, y, opt1)\n",
        "  else:\n",
        "    train_step_2(w, x, y, opt2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xjnz5CcuqQac"
      },
      "source": [
        "#### Uso com múltiplos modelos Keras\n",
        "\n",
        "Você talvez também encontre `ValueError: tf.function only supports singleton tf.Variables created on the first call.` ao passar diferentes instâncias de modelo para a mesma `Function`.\n",
        "\n",
        "Este erro ocorre porque os modelos Keras (que [não têm seu formato de entrada definido](https://www.tensorflow.org/guide/keras/custom_layers_and_models#best_practice_deferring_weight_creation_until_the_shape_of_the_inputs_is_known)) e as camadas Keras criam objetos `tf.Variables` quando são chamados pela primeira vez. Você pode estar tentando inicializar essas variáveis ​​dentro de uma `Function`, que já foi chamada. Para evitar esse erro, tente chamar `model.build(input_shape)` para inicializar todos os pesos antes de treinar o modelo.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKyrEY5GVX3M"
      },
      "source": [
        "## Leituras adicionais\n",
        "\n",
        "Para saber como exportar e carregar uma `Function`, consulte o [guia do SavedModel](../../guide/saved_model). Para saber mais sobre otimizações de grafos executadas após o tracing, consulte o [guia do Grappler](../../guide/graph_optimization). Para saber como otimizar seu pipeline de dados e fazer um profiling do seu modelo, consulte o [Guia do profiler](../../guide/profiler.md)."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "function.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
