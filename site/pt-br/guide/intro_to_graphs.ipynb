{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7ITxKLUkX0v"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "yOYx6tzSnWQ3"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xgB0Oz5eGSQ"
      },
      "source": [
        "# Introdução aos grafos e a tf.function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4zzZVZtQb1w"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>     <a target=\"_blank\" href=\"https://www.tensorflow.org/guide/intro_to_graphs\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver em TensorFlow.org</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/pt-br/guide/intro_to_graphs.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Executar no Google Colab</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/pt-br/guide/intro_to_graphs.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver fonte no GitHub</a>\n",
        "</td>\n",
        "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/pt-br/guide/intro_to_graphs.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Baixar notebook</a>\n",
        "</td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBKqnXI9GOax"
      },
      "source": [
        "## Visão geral\n",
        "\n",
        "Este guia se aprofunda no TensorFlow e Keras para demonstrar como o TensorFlow funciona. Se, em vez disso, você quiser começar pelo Keras imediatamente, confira a [coleção de guias do Keras](https://www.tensorflow.org/guide/keras/).\n",
        "\n",
        "Neste guia, você verá com o TensorFlow permite fazer alterações simples no código para obter grafos, como os grafos são armazenados e representados, além de como usá-los para acelerar os seus modelos.\n",
        "\n",
        "Observação: para quem já conhece bem o TensorFlow 1.x, este guia demonstra um conjunto muito diferente de grafos.\n",
        "\n",
        "**Esta é uma visão geral que demonstra como `tf.function` permite mudar da execução adiantada (eager) para a execução de grafo. **Para ver uma especificação mais completa de `tf.function`, confira o guia <a href=\"./function.ipynb\" data-md-type=\"link\">Desempenho melhor com `tf.function`</a>.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0DdlfacAdTZ"
      },
      "source": [
        "### O que são grafos?\n",
        "\n",
        "Nos três guias anteriores, você executou o TensorFlow no modo **adiantado (eager)**. Portanto, as operações do TensorFlow eram executadas pelo Python, operação por operação, retornando os resultados para o Python.\n",
        "\n",
        "Embora a execução adiantada (eager) tenha diversas vantagens exclusivas, a execução de grafo permite portabilidade para fora do Python e costuma ter melhor desempenho. **Execução de grafo** significa que as computações de tensores são executadas como um *grafo do TensorFlow*, às vezes chamado de `tf.Graph` ou simplesmente \"grafo\".\n",
        "\n",
        "**Os grafos são estruturas de dados que contêm um conjunto de objetos `tf.Operation`, que representam unidades de computação; e objetos `tf.Tensor`, que representam as unidades de dados que fluem entre as operações.** Eles são definidos em um contexto de `tf.Graph`. Como esses grafos são estruturas de dados, podem ser salvos, executados e restaurados sem o código Python original.\n",
        "\n",
        "Veja abaixo um grafo do TensorFlow representando uma rede neural de duas camadas quando visualizado no TensorBoard:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FvQ5aBuRGT1o"
      },
      "source": [
        "<img src=\"https://github.com/tensorflow/docs/blob/master/site/en/guide/images/intro_to_graphs/two-layer-network.png?raw=1\" alt=\"A simple TensorFlow graph\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHpY3avXGITP"
      },
      "source": [
        "### Benefícios dos grafos\n",
        "\n",
        "Com um grafo, você tem muita flexibilidade. É possível usar o grafo do TensorFlow em ambientes que não tenham um interpretador Python, como aplicativos móveis, dispositivos embarcados e servidores de back-end. O TensorFlow usa grafos como o formato de [modelos salvos](./saved_model.ipynb) ao exportá-los do Python.\n",
        "\n",
        "Também é fácil otimizar grafos, o que permite ao compilador fazer as seguintes tarefas:\n",
        "\n",
        "- Inferir estatisticamente o valor de tensores fazendo o *\"constant folding\"* de nós em sua computação.\n",
        "- Separar subpartes de uma computação que são independentes e dividi-las entre os threads ou dispositivos.\n",
        "- Simplificar operações aritméticas eliminando subexpressões comuns.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1x1EOD9GjnB"
      },
      "source": [
        "Existe um sistema de otimização completo, chamado [Grappler](./graph_optimization.ipynb), que faz essas três tarefas e outras acelerações.\n",
        "\n",
        "Resumindo, os grafos são muito úteis e permitem que o TensorFlow seja executado **com rapidez**, **em paralelo** e com eficiência **em vários dispositivos**.\n",
        "\n",
        "Entretanto, ainda é importante definir seus modelos de aprendizado de máquina (ou outras computações) no Python por conveniência e depois construir os grafos automaticamente quando você precisar deles."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-6Qi0thw2i9"
      },
      "source": [
        "## Configuração"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0d1689fa928f"
      },
      "source": [
        "Importe algumas bibliotecas necessárias:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "goZwOXp_xyQj"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import timeit\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSZebVuWxDXu"
      },
      "source": [
        "## Como aproveitar os grafos\n",
        "\n",
        "Para criar e executar um grafo no TensorFlow, utilizamos `tf.function`, seja como uma chamada direta ou um decorador. `tf.function` recebe uma função comum como entrada e retorna uma `Function`. <strong data-md-type=\"double_emphasis\">Uma `Function` (Função) é um callable que cria grafos do TensorFlow usando a função do Python. Uma `Function` é usada da mesma forma que seu equivalente do Python.</strong>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HKbLeJ1y0Umi"
      },
      "outputs": [],
      "source": [
        "# Define a Python function.\n",
        "def a_regular_function(x, y, b):\n",
        "  x = tf.matmul(x, y)\n",
        "  x = x + b\n",
        "  return x\n",
        "\n",
        "# `a_function_that_uses_a_graph` is a TensorFlow `Function`.\n",
        "a_function_that_uses_a_graph = tf.function(a_regular_function)\n",
        "\n",
        "# Make some tensors.\n",
        "x1 = tf.constant([[1.0, 2.0]])\n",
        "y1 = tf.constant([[2.0], [3.0]])\n",
        "b1 = tf.constant(4.0)\n",
        "\n",
        "orig_value = a_regular_function(x1, y1, b1).numpy()\n",
        "# Call a `Function` like a Python function.\n",
        "tf_function_value = a_function_that_uses_a_graph(x1, y1, b1).numpy()\n",
        "assert(orig_value == tf_function_value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNvuAYpdrTOf"
      },
      "source": [
        "Por fora, uma `Function` parece uma função comum escrita usando operações do TensorFlow. Porém, [por dentro](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/eager/def_function.py), é *bem diferente*. Uma `Function` **encapsula vários`tf.Graph`s por trás de uma API** (saiba mais na seção *Polimorfismo*). É assim que uma `Function` consegue proporcionar os benefícios da execução de grafo, como velocidade e capacidade de implantação (confira a seção *Benefícios dos grafos* acima)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MT7U8ozok0gV"
      },
      "source": [
        "`tf.function` aplica-se a uma função *e a todas as outras funções que chama*:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rpz08iLplm9F"
      },
      "outputs": [],
      "source": [
        "def inner_function(x, y, b):\n",
        "  x = tf.matmul(x, y)\n",
        "  x = x + b\n",
        "  return x\n",
        "\n",
        "# Use the decorator to make `outer_function` a `Function`.\n",
        "@tf.function\n",
        "def outer_function(x):\n",
        "  y = tf.constant([[2.0], [3.0]])\n",
        "  b = tf.constant(4.0)\n",
        "\n",
        "  return inner_function(x, y, b)\n",
        "\n",
        "# Note that the callable will create a graph that\n",
        "# includes `inner_function` as well as `outer_function`.\n",
        "outer_function(tf.constant([[1.0, 2.0]])).numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P88fOr88qgCj"
      },
      "source": [
        "Se você já tiver usado o TensorFlow 1.x, observará que em momento nenhum precisou definir um `Placeholder` ou `tf.Session`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfeKf0Nr1OEK"
      },
      "source": [
        "### Como converter funções do Python em grafos\n",
        "\n",
        "Toda função que você escreve com o TensorFlow conterá uma combinação de operações integradas do TF e lógica do Python, como declarações `if-then`, loops, `break`, `return`, `continue` e muito mais. Embora as operações do TensorFlow sejam facilmente capturadas por um `tf.Graph`, lógicas específicas do Python precisam passar por um passo extra para se tornarem parte do grafo. `tf.function` usa uma biblioteca chamada AutoGraph (`tf.autograph`) para converter código Python em código gerador de grafo.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PFObpff1BMEb"
      },
      "outputs": [],
      "source": [
        "def simple_relu(x):\n",
        "  if tf.greater(x, 0):\n",
        "    return x\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "# `tf_simple_relu` is a TensorFlow `Function` that wraps `simple_relu`.\n",
        "tf_simple_relu = tf.function(simple_relu)\n",
        "\n",
        "print(\"First branch, with graph:\", tf_simple_relu(tf.constant(1)).numpy())\n",
        "print(\"Second branch, with graph:\", tf_simple_relu(tf.constant(-1)).numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hO4DBUNZBMwQ"
      },
      "source": [
        "Embora seja improvável que você precise ver grafos diretamente, pode analisar as saídas para verificar os resultados exatos, que não são fáceis de ler, então não precisa analisar detalhadamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lAKaat3w0gnn"
      },
      "outputs": [],
      "source": [
        "# This is the graph-generating output of AutoGraph.\n",
        "print(tf.autograph.to_code(simple_relu))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8x6RAqza1UWf"
      },
      "outputs": [],
      "source": [
        "# This is the graph itself.\n",
        "print(tf_simple_relu.get_concrete_function(tf.constant(1)).graph.as_graph_def())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZ4Ieg6tBE6l"
      },
      "source": [
        "Na maioria do tempo, `tf.function` funcionará sem considerações especiais. Porém, há algumas ressalvas, e o  <a href=\"./function.ipynb\" data-md-type=\"link\">guia sobre `tf.function`</a> pode ajudar, bem como a [referência completa do AutoGraph](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/g3doc/reference/index.md)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIpc_jfjEZEg"
      },
      "source": [
        "### Polimorfismo: uma `Function`, vários grafos\n",
        "\n",
        "Um `tf.Graph` é especializado para um tipo de entradas (por exemplo, tensores com um [`dtype`](https://www.tensorflow.org/api_docs/python/tf/dtypes/DType) – tipo de dados – específico ou objetos com o mesmo [`id()`](https://docs.python.org/3/library/functions.html#id%5D)).\n",
        "\n",
        "Cada vez que você chama uma `Function` com um conjunto de argumentos que não podem ser tratados por nenhum dos grafos existentes (como argumentos com novos `dtypes` ou formatos incompatíveis), `Function` cria um novo `tf.Graph` especializado para esses novos argumentos. A especificação de tipo das entradas de um `tf.Graph` é conhecida como **assinatura da entrada** ou simplesmente **assinatura**. Para saber mais sobre quando um novo `tf.Graph` é gerado e como pode ser controlado, confira a seção *Regras de tracing* do guia [Desempenho melhor com `tf.function`](./function.ipynb).\n",
        "\n",
        "A `Function` armazena o `tf.Graph` que corresponde à assinatura em uma `ConcreteFunction`. <strong data-md-type=\"double_emphasis\">Uma `ConcreteFunction` é um encapsulador de `tf.Graph`.</strong>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LOASwhbvIv_T"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def my_relu(x):\n",
        "  return tf.maximum(0., x)\n",
        "\n",
        "# `my_relu` creates new graphs as it observes more signatures.\n",
        "print(my_relu(tf.constant(5.5)))\n",
        "print(my_relu([1, -1]))\n",
        "print(my_relu(tf.constant([3., -3.])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qRtw7R4KL9X"
      },
      "source": [
        "Se a `Function` já tiver sido chamada com essa assinatura, a `Function` não criará um novo `tf.Graph`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TjjbnL5OKNDP"
      },
      "outputs": [],
      "source": [
        "# These two calls do *not* create new graphs.\n",
        "print(my_relu(tf.constant(-2.5))) # Signature matches `tf.constant(5.5)`.\n",
        "print(my_relu(tf.constant([-1., 1.]))) # Signature matches `tf.constant([3., -3.])`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UohRmexhIpvQ"
      },
      "source": [
        "Como uma `Function` tem muitos grafos por trás, ela é **polimorfa**, o que permite receber mais tipos de entrada do que um único `tf.Graph` poderia representar e permite também otimizar cada `tf.Graph` a fim de melhorar o desempenho."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dxzqebDYFmLy"
      },
      "outputs": [],
      "source": [
        "# There are three `ConcreteFunction`s (one for each graph) in `my_relu`.\n",
        "# The `ConcreteFunction` also knows the return type and shape!\n",
        "print(my_relu.pretty_printed_concrete_signatures())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V11zkxU22XeD"
      },
      "source": [
        "## Usando `tf.function`\n",
        "\n",
        "Até o momento, você aprendeu a converter uma função do Python em um grafo apenas usando `tf.function` como decorador ou encapsulador. Porém, na prática, pode ser complicado fazer `tf.function` funcionar corretamente. Nas próximas seções, você verá como fazer seu código funcionar conforme o esperado ao usar `tf.function`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yp_n0B5-P0RU"
      },
      "source": [
        "### Execução de grafo versus execução adiantada (eager)\n",
        "\n",
        "O código em uma `Function` pode ser executado tanto no modo grafo quanto adiantado. Por padrão, `Function` executa o código como um grafo:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_R0BOvBFxqVZ"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def get_MSE(y_true, y_pred):\n",
        "  sq_diff = tf.pow(y_true - y_pred, 2)\n",
        "  return tf.reduce_mean(sq_diff)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zikMVPGhmDET"
      },
      "outputs": [],
      "source": [
        "y_true = tf.random.uniform([5], maxval=10, dtype=tf.int32)\n",
        "y_pred = tf.random.uniform([5], maxval=10, dtype=tf.int32)\n",
        "print(y_true)\n",
        "print(y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "07r08Dh158ft"
      },
      "outputs": [],
      "source": [
        "get_MSE(y_true, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyZNCRcQorGO"
      },
      "source": [
        "Para verificar que o grafo da sua `Function` esteja fazendo a mesma computação que a função equivalente do Python, você pode fazer a execução adiantada usando `tf.config.run_functions_eagerly(True)`, que é um controle que <strong data-md-type=\"double_emphasis\">desativa a capacidade de `Function`criar e executar grafos</strong>, que passa então a executar o código normalmente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lKoF6NjPoI8w"
      },
      "outputs": [],
      "source": [
        "tf.config.run_functions_eagerly(True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ZLqTyn0oKeM"
      },
      "outputs": [],
      "source": [
        "get_MSE(y_true, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cV7daQW9odn-"
      },
      "outputs": [],
      "source": [
        "# Don't forget to set it back when you are done.\n",
        "tf.config.run_functions_eagerly(False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKT3YBsqy0x4"
      },
      "source": [
        "Porém, `Function` pode se comportar de maneira diferente no modo grafo e no modo adiantado (eager). A função [`print`](https://docs.python.org/3/library/functions.html#print) do Python é um exemplo de como esses dois modos diferem. Vamos conferir o que acontece ao inserir uma declaração `print` em sua função e chamá-la repetidamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BEJeVeBEoGjV"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def get_MSE(y_true, y_pred):\n",
        "  print(\"Calculating MSE!\")\n",
        "  sq_diff = tf.pow(y_true - y_pred, 2)\n",
        "  return tf.reduce_mean(sq_diff)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3sWTGwX3BzP1"
      },
      "source": [
        "Observe a saída:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3rJIeBg72T9n"
      },
      "outputs": [],
      "source": [
        "error = get_MSE(y_true, y_pred)\n",
        "error = get_MSE(y_true, y_pred)\n",
        "error = get_MSE(y_true, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLMXk1uxKQ44"
      },
      "source": [
        "A saída é surpreendente? **`get_MSE` só foi exibido uma vez via print, embora tenha sido chamado *três* vezes**.\n",
        "\n",
        "A explicação é que a declaração `print` é executada quando a `Function` executa o código original para criar o grafo em um processo conhecido como \"tracing\" (confira a seção *Tracing* do [guia sobre `tf.function`](./function.ipynb)). <strong data-md-type=\"double_emphasis\">O tracing captura as operações do TensorFlow em um grafo, e `print` não é capturado no grafo. </strong> Então, esse grafo é executado para todas as três chamadas **sem executar o código Python novamente**.\n",
        "\n",
        "Para testar, vamos desativar a execução de grafo a fim de fazer uma comparação:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oFSxRtcptYpe"
      },
      "outputs": [],
      "source": [
        "# Now, globally set everything to run eagerly to force eager execution.\n",
        "tf.config.run_functions_eagerly(True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qYxrAtvzNgHR"
      },
      "outputs": [],
      "source": [
        "# Observe what is printed below.\n",
        "error = get_MSE(y_true, y_pred)\n",
        "error = get_MSE(y_true, y_pred)\n",
        "error = get_MSE(y_true, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Df6ynXcAaup"
      },
      "outputs": [],
      "source": [
        "tf.config.run_functions_eagerly(False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUR7qC_bquCn"
      },
      "source": [
        "`print` é um *efeito colateral do Python*, e você precisa estar ciente de outras diferenças ao converter uma função em uma `Function`. Saiba mais na seção *Limitações* do guia [Desempenho melhor com `tf.function`](./function.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTZJfV_tccVp"
      },
      "source": [
        "Observação: se você quiser exibir valores via print tanto na execução adiantada (eager) quanto de grafo, utilize `tf.print`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMT_Xf5yKn9o"
      },
      "source": [
        "### Execução não estrita\n",
        "\n",
        "<a id=\"non-strict\"></a>\n",
        "\n",
        "O modo grafo executa somente as operações necessárias para gerar os efeitos observáveis, o que inclui:\n",
        "\n",
        "- O valor de retorno da função.\n",
        "- Efeitos colaterais conhecidos e documentados, como:\n",
        "    - Operações de entrada/saída, como `tf.print`.\n",
        "    - Operações de depuração, como as funções de asserção em `tf.debugging`.\n",
        "    - Mutações de `tf.Variable`.\n",
        "\n",
        "Esse comportamento é conhecido como \"Execução não estrita\", e difere da execução adiantada (eager), que passa por todas as operações do programa, sejam necessárias ou não.\n",
        "\n",
        "Especificamente, a verificação de erro do runtime não conta como um efeito observável. Se uma operação for ignorada porque é desnecessária, não pode gerar erros de runtime.\n",
        "\n",
        "No exemplo abaixo, a operação \"desnecessária\" `tf.gather` é ignorada durante a execução de grafo, então o erro do runtime `InvalidArgumentError` não é gerado como seria na execução adiantada (eager). Não conte com a geração de erros ao executar um grafo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OdN0nKlUwj7M"
      },
      "outputs": [],
      "source": [
        "def unused_return_eager(x):\n",
        "  # Get index 1 will fail when `len(x) == 1`\n",
        "  tf.gather(x, [1]) # unused \n",
        "  return x\n",
        "\n",
        "try:\n",
        "  print(unused_return_eager(tf.constant([0.0])))\n",
        "except tf.errors.InvalidArgumentError as e:\n",
        "  # All operations are run during eager execution so an error is raised.\n",
        "  print(f'{type(e).__name__}: {e}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d80Fob4MwhTs"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def unused_return_graph(x):\n",
        "  tf.gather(x, [1]) # unused\n",
        "  return x\n",
        "\n",
        "# Only needed operations are run during graph execution. The error is not raised.\n",
        "print(unused_return_graph(tf.constant([0.0])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "def6MupG9R0O"
      },
      "source": [
        "### Práticas recomendadas ao usar `tf.function`\n",
        "\n",
        "Pode demorar um tempo para se acostumar com o comportamento de `Function`. Para começar a usá-la rapidamente, usuários iniciantes podem decorar funções usando `@tf.function` para adquirirem experiência com a mudança de execução no modo adiantado (eager) para o modo grafo.\n",
        "\n",
        "*Utilizar `tf.function`* poderá ser a melhor opção para escrever programas do TensorFlow compatíveis com grafos. Veja algumas dicas:\n",
        "\n",
        "- Alterne entre execução no modo adiantado e grafo já no começo com `tf.config.run_functions_eagerly` para identificar se/quando os dois modos divergem.\n",
        "- Crie `tf.Variable`s fora da função do Python e modifique-as dentro dele. O mesmo vale para objetos que usam `tf.Variable`, como `tf.keras.layers`, `tf.keras.Model` e `tf.keras.optimizers`.\n",
        "- Evite escrever funções que dependam das variáveis externas do Python, exceto `tf.Variable`s e objetos do Keras. Saiba mais na seção *Dependência de variáveis globais e livres do Python * do guia sobre [`tf.function`](./function.ipynb).\n",
        "- Opte por escrever funções que recebam tensores e outros tipos do TensorFlow como entrada. Você pode passar outros tipos de objeto, mas tenha cuidado. Saiba mais na seção *Dependência de objetos do Python* do guia sobre [`tf.function`](./function.ipynb).\n",
        "- Inclua o máximo de computação possível usando `tf.function` para maximizar os ganhos de desempenho. Por exemplo, decore um passo de treinamento inteiro ou todo o loop de treinamento.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ViM3oBJVJrDx"
      },
      "source": [
        "## Como verificar a aceleração"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6NHDp7vAKcJ"
      },
      "source": [
        "Geralmente, `tf.function` melhora o desempenho do código, mas o nível de aceleração depende do tipo de computação executada. Pequenas computações podem acarretar sobrecargas ao chamar um grafo. Você pode mensurar a diferença de desempenho da seguinte forma:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jr7p1BBjauPK"
      },
      "outputs": [],
      "source": [
        "x = tf.random.uniform(shape=[10, 10], minval=-1, maxval=2, dtype=tf.dtypes.int32)\n",
        "\n",
        "def power(x, y):\n",
        "  result = tf.eye(10, dtype=tf.dtypes.int32)\n",
        "  for _ in range(y):\n",
        "    result = tf.matmul(x, result)\n",
        "  return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ms2yJyAnUYxK"
      },
      "outputs": [],
      "source": [
        "print(\"Eager execution:\", timeit.timeit(lambda: power(x, 100), number=1000), \"seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gUB2mTyRYRAe"
      },
      "outputs": [],
      "source": [
        "power_as_graph = tf.function(power)\n",
        "print(\"Graph execution:\", timeit.timeit(lambda: power_as_graph(x, 100), number=1000), \"seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1Pfo5YwwILi"
      },
      "source": [
        "`tf.function` é usada com frequência para acelerar os loops de treinamento. Saiba mais na seção <em data-md-type=\"emphasis\">Como acelerar o passo de treinamento com `tf.function`</em> do guia do Keras [Como escrever um loop de treinamento do zero](https://www.tensorflow.org/guide/keras/writing_a_training_loop_from_scratch).\n",
        "\n",
        "Observação: você também pode tentar usar `tf.function(jit_compile=True)` para conseguir um aumento maior do desempenho, especialmente se o seu código tiver muito fluxo de controle do TensorFlow e usar vários tensores pequenos. Saiba mais na seção <em data-md-type=\"emphasis\">Execução explícita com `tf.function(jit_compile=True)`</em> da [Visão geral do XLA](https://www.tensorflow.org/xla)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sm0bNFp8PX53"
      },
      "source": [
        "### Desempenho e contrapartidas\n",
        "\n",
        "Os grafos podem acelerar seu código, mas o processo de criá-los tem uma certa sobrecarga. Para algumas funções, a criação do grafo leva mais tempo do que a execução. **Geralmente, esse investimento é pago rapidamente com o aumento de desempenho das execuções subsequentes, mas é importante ter em mente que os primeiros passos de treinamento de um modelo grande podem ser mais lentos devido ao tracing.**\n",
        "\n",
        "Não importa o tamanho do seu modelo, deve-se evitar fazer o tracing com frequência. O [guia sobre `tf.function`](./function.ipynb) demonstra como definir especificações de entrada e usar argumentos de tensores para evitar o retracing na seção *Como controlar o retracing*. Se você observar um desempenho baixo, é uma boa ideia verificar se está fazendo retracing acidentalmente"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4InDaTjwmBA"
      },
      "source": [
        "## Quando uma `Function` faz tracing?\n",
        "\n",
        "Para descobrir quando sua `Function` está fazendo tracing, adicione uma declaração `print` ao código. Por via de regra, uma `Function` executará a declaração `print` toda vez que fizer o tracing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hXtwlbpofLgW"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def a_function_with_python_side_effect(x):\n",
        "  print(\"Tracing!\") # An eager-only side effect.\n",
        "  return x * x + tf.constant(2)\n",
        "\n",
        "# This is traced the first time.\n",
        "print(a_function_with_python_side_effect(tf.constant(2)))\n",
        "# The second time through, you won't see the side effect.\n",
        "print(a_function_with_python_side_effect(tf.constant(3)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "inzSg8yzfNjl"
      },
      "outputs": [],
      "source": [
        "# This retraces each time the Python argument changes,\n",
        "# as a Python argument could be an epoch count or other\n",
        "# hyperparameter.\n",
        "print(a_function_with_python_side_effect(2))\n",
        "print(a_function_with_python_side_effect(3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtN8NW6AfKye"
      },
      "source": [
        "Novos argumentos do Python sempre acionam a criação de um novo grafo, e é daí que vem o tracing extra.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1kbr5ocpS6R"
      },
      "source": [
        "## Próximos passos\n",
        "\n",
        "Saiba mais sobre `tf.function` na página de referência da API e no guia <a href=\"./function.ipynb\" data-md-type=\"link\">Desempenho melhor com `tf.function`</a>."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "intro_to_graphs.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
