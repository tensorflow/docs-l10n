{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FhGuhbZ6M5tl"
      },
      "source": [
        "##### Copyright 2022 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "AwOEIRJC6Une"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIdT9iu_Z4Rb"
      },
      "source": [
        "# Aproximação de matrizes com as APIs principais (Core)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBIlTPscrIT9"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>     <a target=\"_blank\" href=\"https://www.tensorflow.org/guide/core/matrix_core\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver no TensorFlow.org</a> </td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/pt-br/guide/core/matrix_core.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Executar no Google Colab</a> </td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/pt-br/guide/core/matrix_core.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver fonte no GitHub</a> </td>\n",
        "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/pt-br/guide/core/matrix_core.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Baixar notebook</a> </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGw8TF2vtzru"
      },
      "source": [
        "## Introdução\n",
        "\n",
        "Este notebook usa as [APIs de baixo nível do TensorFlow Core](https://www.tensorflow.org/guide/core) para mostrar os recursos do TensorFlow como uma plataforma de computação científica de alto desempenho. Veja a [Visão geral das APIs Core](https://www.tensorflow.org/guide/core) para saber mais sobre o TensorFlow Core e seus casos de uso pretendidos.\n",
        "\n",
        "Este tutorial explora a técnica de [decomposição em valores singulares](https://developers.google.com/machine-learning/recommendation/collaborative/matrix) (SVD) e suas aplicações para problemas de aproximação de posto baixo. O SVD é usado para fatorar matrizes reais ou complexas e tem uma variedade de casos de uso em ciência de dados, como compactação de imagens. As imagens para este tutorial vêm do projeto [Imagen](https://imagen.research.google/) do Google Brain. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_FdwaovEkCC"
      },
      "source": [
        "> ![svd_intro](http://tensorflow.org/images/core/svd_intro.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nchsZfwEVtVs"
      },
      "source": [
        "## Configuração"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1rRo8oNqZ-Rj"
      },
      "outputs": [],
      "source": [
        "import matplotlib\n",
        "from matplotlib.image import imread\n",
        "from matplotlib import pyplot as plt\n",
        "import requests\n",
        "# Preset Matplotlib figure sizes.\n",
        "matplotlib.rcParams['figure.figsize'] = [16, 9]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9xQKvCJ85kCQ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "so_ewq3gAoEI"
      },
      "source": [
        "## Fundamentos do SVD\n",
        "\n",
        "A decomposição em valores singulares de uma matriz, ${\\mathrm{A}}$, é determinada pela seguinte fatoração:\n",
        "\n",
        "$${\\mathrm{A}} = {\\mathrm{U}} \\Sigma {\\mathrm{V}}^T$$\n",
        "\n",
        "onde\n",
        "\n",
        "- $\\underset{m \\times n}{\\mathrm{A}}$: matriz de entrada onde $m \\geq n$\n",
        "- $\\underset{m \\times n}{\\mathrm{U}}$: matriz ortogonal, ${\\mathrm{U}}^T{\\mathrm{U}} = {\\mathrm{I}}$, com cada coluna, $u_i$, denotando um vetor singular esquerdo de ${\\mathrm{A}}$\n",
        "- $\\underset{n \\times n}{\\Sigma}$: matriz diagonal com cada entrada diagonal, $\\sigma_i$, denotando um valor singular de ${\\mathrm{A}}$\n",
        "- $\\underset{n \\times n}{{\\mathrm{V}}^T}$: matriz ortogonal, ${\\mathrm{V}}^T{\\mathrm{V}} = {\\mathrm{I}}$, com cada linha, $v_i$, denotando um vetor singular direito de ${\\mathrm{A}}$\n",
        "\n",
        "Quando $m <n$, ${\\mathrm{U}}$ e $\\Sigma$  ambos têm dimensão $(m \\times m)$, e ${\\mathrm{V}}^T$ tem dimensão $(m \\vezes n)$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enGGGXCQKNv8"
      },
      "source": [
        "> ![svd_full](http://tensorflow.org/images/core/svd_full.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NlP-cBdSKLtc"
      },
      "source": [
        "O pacote de álgebra linear do TensorFlow tem uma função, `tf.linalg.svd` , que pode ser usada para calcular a decomposição em valores singulares de uma ou mais matrizes. Comece definindo uma matriz simples e calculando sua fatoração SVD.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C3QAcgyoeIpv"
      },
      "outputs": [],
      "source": [
        "A = tf.random.uniform(shape=[40,30])\n",
        "# Compute the SVD factorization\n",
        "s, U, V = tf.linalg.svd(A)\n",
        "# Define Sigma and V Transpose\n",
        "S = tf.linalg.diag(s)\n",
        "V_T = tf.transpose(V)\n",
        "# Reconstruct the original matrix\n",
        "A_svd = U@S@V_T\n",
        "# Visualize \n",
        "plt.bar(range(len(s)), s);\n",
        "plt.xlabel(\"Singular value rank\")\n",
        "plt.ylabel(\"Singular value\")\n",
        "plt.title(\"Bar graph of singular values\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6H_C9WhFACm4"
      },
      "source": [
        "A função `tf.einsum` pode ser usada para calcular diretamente a reconstrução da matriz das saídas de `tf.linalg.svd` ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TPE6QeMtADUn"
      },
      "outputs": [],
      "source": [
        "A_svd = tf.einsum('s,us,vs -> uv',s,U,V)\n",
        "print('\\nReconstructed Matrix, A_svd', A_svd)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1m6JIsM9DLP"
      },
      "source": [
        "## Aproximação de posto baixo com o SVD\n",
        "\n",
        "O posto de uma matriz, ${\\mathrm{A}}$, é determinado pela dimensão do espaço vetorial representado por suas colunas. O SVD pode ser usado para aproximar uma matriz com posto inferior, o que acaba diminuindo a dimensionalidade dos dados necessários para armazenar as informações representadas pela matriz.\n",
        "\n",
        "A aproximação de posto r de ${\\mathrm{A}}$ em termos de SVD é definida pela fórmula:\n",
        "\n",
        "$${\\mathrm{A_r}} = {\\mathrm{U_r}} \\Sigma_r {\\mathrm{V_r}}^T$$\n",
        "\n",
        "onde\n",
        "\n",
        "- $\\underset{m \\times r}{\\mathrm{U_r}}$: matriz composta pelas primeiras $r$ colunas de ${\\mathrm{U}}$\n",
        "- $\\underset{r \\times r}{\\Sigma_r}$: matriz diagonal composta pelos primeiros $r$ valores singulares em $\\Sigma$\n",
        "- $\\underset{r \\times n}{\\mathrm{V_r}}^T$: matriz composta pelas primeiras $r$ linhas de ${\\mathrm{V}}^T$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJWMJu36QyUV"
      },
      "source": [
        "> ![svd_approx](http://tensorflow.org/images/core/svd_approx.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkiVUxeaQybq"
      },
      "source": [
        "Comece escrevendo uma função para calcular a aproximação de posto r de uma determinada matriz. Este procedimento de aproximação de baixo posto é usado para compressão de imagens; portanto, também é útil calcular os tamanhos de dados físicos para cada aproximação. Para simplificar, suponha que o tamanho dos dados para uma matriz aproximada de posto r seja igual ao número total de elementos necessários para calcular a aproximação. Em seguida, escreva uma função para visualizar a matriz original, $\\mathrm{A}$ sua aproximação de posto r, $\\mathrm{A}_r$ e a matriz de erro, $|\\mathrm{A} - \\mathrm{A} _r|$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2oY3pMPagJrO"
      },
      "outputs": [],
      "source": [
        "def rank_r_approx(s, U, V, r, verbose=False):\n",
        "  # Compute the matrices necessary for a rank-r approximation\n",
        "  s_r, U_r, V_r = s[..., :r], U[..., :, :r], V[..., :, :r] # ... implies any number of extra batch axes\n",
        "  # Compute the low-rank approximation and its size\n",
        "  A_r = tf.einsum('...s,...us,...vs->...uv',s_r,U_r,V_r)\n",
        "  A_r_size = tf.size(U_r) + tf.size(s_r) + tf.size(V_r)\n",
        "  if verbose:\n",
        "    print(f\"Approximation Size: {A_r_size}\")\n",
        "  return A_r, A_r_size\n",
        "\n",
        "def viz_approx(A, A_r):\n",
        "  # Plot A, A_r, and A - A_r\n",
        "  vmin, vmax = 0, tf.reduce_max(A)\n",
        "  fig, ax = plt.subplots(1,3)\n",
        "  mats = [A, A_r, abs(A - A_r)]\n",
        "  titles = ['Original A', 'Approximated A_r', 'Error |A - A_r|']\n",
        "  for i, (mat, title) in enumerate(zip(mats, titles)):\n",
        "    ax[i].pcolormesh(mat, vmin=vmin, vmax=vmax)\n",
        "    ax[i].set_title(title)\n",
        "    ax[i].axis('off')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O3ZRkYCkX2FQ"
      },
      "outputs": [],
      "source": [
        "print(f\"Original Size of A: {tf.size(A)}\")\n",
        "s, U, V = tf.linalg.svd(A)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S1DR83VMX4cM"
      },
      "outputs": [],
      "source": [
        "# Rank-15 approximation\n",
        "A_15, A_15_size = rank_r_approx(s, U, V, 15, verbose = True)\n",
        "viz_approx(A, A_15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KgFT70XFX57E"
      },
      "outputs": [],
      "source": [
        "# Rank-3 approximation\n",
        "A_3, A_3_size = rank_r_approx(s, U, V, 3, verbose = True)\n",
        "viz_approx(A, A_3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DS4XoSlTJgX0"
      },
      "source": [
        "Como esperado, usar postos mais baixos resulta em aproximações menos precisas. No entanto, a qualidade dessas aproximações de baixo posto costuma ser boa o suficiente em cenários do mundo real. Observe também que o principal objetivo da aproximação de baixo posto com SVD é reduzir a dimensionalidade dos dados, mas não reduzir o espaço em disco ocupado pelos próprios dados. No entanto, à medida em que são usadas matrizes de entrada de dimensões superiores, muitas aproximações de baixo posto também acabam se beneficiando do tamanho reduzido dos dados. Esse benefício de redução é o motivo pelo qual o processo é aplicável para problemas de compactação de imagem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IhsaiOnnZs6M"
      },
      "source": [
        "## Carregamento de imagens\n",
        "\n",
        "A imagem a seguir está disponível na página inicial [do Imagen](https://imagen.research.google/). Imagen é um modelo de difusão de texto para imagem desenvolvido pela equipe Brain do Google Research. Uma IA criou esta imagem com base no prompt a seguir: \"Uma foto de um cachorro Corgi andando de bicicleta na Times Square. Ele está usando óculos escuros e um chapéu de praia\". Não é legal? Você também pode alterar a URL abaixo para qualquer link .jpg para carregar qualquer imagem personalizada de sua escolha.\n",
        "\n",
        "Comece lendo e visualizando a imagem. Depois de ler um arquivo JPEG, o Matplotlib gera uma matriz, ${\\mathrm{I}}$, de formato $(m \\times n \\times 3)$ que representa uma imagem bidimensional com 3 canais de cores para vermelho, verde e azul respectivamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OVsZOQUAZ2C7"
      },
      "outputs": [],
      "source": [
        "img_link = \"https://imagen.research.google/main_gallery_images/a-photo-of-a-corgi-dog-riding-a-bike-in-times-square.jpg\"\n",
        "img_path = requests.get(img_link, stream=True).raw\n",
        "I = imread(img_path, 0)\n",
        "print(\"Input Image Shape:\", I.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qvs7uftcZ54x"
      },
      "outputs": [],
      "source": [
        "def show_img(I):\n",
        "  # Display the image in matplotlib\n",
        "  img = plt.imshow(I)\n",
        "  plt.axis('off')\n",
        "  return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZbesXO3HZ6Qs"
      },
      "outputs": [],
      "source": [
        "show_img(I)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdnUBVg_JoOa"
      },
      "source": [
        "## O algoritmo de compressão de imagem\n",
        "\n",
        "Agora, use o SVD para calcular aproximações de posto baixo da imagem de exemplo. Lembre-se de que a imagem tem o formato $(1024 \\times 1024 \\times 3)$ e que a teoria SVD só se aplica a matrizes bidimensionais. Isto significa que a imagem de exemplo deve ser loteada em 3 matrizes de tamanho igual que correspondem a cada um dos 3 canais de cores. Isto pode ser feito transpondo a matriz para o formato $(3 \\times 1024 \\times 1024)$. Para visualizar claramente o erro de aproximação, redimensione os valores RGB da imagem de $[0,255]$ para $[0,1]$. Lembre-se de truncar os valores aproximados para que fiquem dentro desse intervalo antes de visualizá-los. A função `tf.clip_by_value` é útil para isso."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i7DDp0h7oSIk"
      },
      "outputs": [],
      "source": [
        "def compress_image(I, r, verbose=False):\n",
        "  # Compress an image with the SVD given a rank \n",
        "  I_size = tf.size(I)\n",
        "  print(f\"Original size of image: {I_size}\")\n",
        "  # Compute SVD of image\n",
        "  I = tf.convert_to_tensor(I)/255\n",
        "  I_batched = tf.transpose(I, [2, 0, 1]) # einops.rearrange(I, 'h w c -> c h w')\n",
        "  s, U, V = tf.linalg.svd(I_batched)\n",
        "  # Compute low-rank approximation of image across each RGB channel\n",
        "  I_r, I_r_size = rank_r_approx(s, U, V, r)\n",
        "  I_r = tf.transpose(I_r, [1, 2, 0]) # einops.rearrange(I_r, 'c h w -> h w c')\n",
        "  I_r_prop = (I_r_size / I_size)\n",
        "  if verbose:\n",
        "    # Display compressed image and attributes\n",
        "    print(f\"Number of singular values used in compression: {r}\")\n",
        "    print(f\"Compressed image size: {I_r_size}\")\n",
        "    print(f\"Proportion of original size: {I_r_prop:.3f}\")\n",
        "    ax_1 = plt.subplot(1,2,1)\n",
        "    show_img(tf.clip_by_value(I_r,0.,1.))\n",
        "    ax_1.set_title(\"Approximated image\")\n",
        "    ax_2 = plt.subplot(1,2,2)\n",
        "    show_img(tf.clip_by_value(0.5+abs(I-I_r),0.,1.))\n",
        "    ax_2.set_title(\"Error\")\n",
        "  return I_r, I_r_prop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGQ_rTyKDX9F"
      },
      "source": [
        "Agora, compute aproximações de posto r para os seguintes postos: 100, 50, 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7GlKkVLGDjre"
      },
      "outputs": [],
      "source": [
        "I_100, I_100_prop = compress_image(I, 100, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XdvUkF5_E75D"
      },
      "outputs": [],
      "source": [
        "I_50, I_50_prop = compress_image(I, 50, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MsCNZ8416Sbk"
      },
      "outputs": [],
      "source": [
        "I_10, I_10_prop = compress_image(I, 10, verbose=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfYYBhcuNkvH"
      },
      "source": [
        "## Computando aproximações\n",
        "\n",
        "Há uma variedade de métodos interessantes para medir a eficácia e ter mais controle sobre as aproximações matriciais."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2Lotde9Zg7v"
      },
      "source": [
        "### Fator de compressão vs posto\n",
        "\n",
        "Para cada uma das aproximações acima, observe como os tamanhos dos dados mudam com o posto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O1ariNQe6Wbl"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(11,6))\n",
        "plt.plot([100, 50, 10], [I_100_prop, I_50_prop, I_10_prop])\n",
        "plt.xlabel(\"Rank\")\n",
        "plt.ylabel(\"Proportion of original image size\")\n",
        "plt.title(\"Compression factor vs rank\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvHcLRj2QoDg"
      },
      "source": [
        "Com base nesse gráfico, há uma relação linear entre o fator de compressão de uma imagem aproximada e seu posto. Para explorar isso ainda mais, lembre-se de que o tamanho dos dados de uma matriz aproximada, ${\\mathrm{A}}_r$, é definido como o número total de elementos necessários para sua computação. As seguintes equações podem ser usadas para encontrar a relação entre o fator de compressão e o posto:\n",
        "\n",
        "$$x = (m \\times r) + r + (r \\times n) = r \\times (m + n + 1)$$\n",
        "\n",
        "$$c = \\large \\frac{x}{y} = \\frac{r \\times (m + n + 1)}{m \\times n}$$\n",
        "\n",
        "onde\n",
        "\n",
        "- $x$: tamanho de ${\\mathrm{A_r}}$\n",
        "- $y$: tamanho de ${\\mathrm{A}}$\n",
        "- $c = \\frac{x}{y}$: fator de compressão\n",
        "- $r$: posto da aproximação\n",
        "- $m$ e $n$: dimensões de linha e coluna de ${\\mathrm{A}}$\n",
        "\n",
        "Para encontrar o posto, $r$, que é necessário para comprimir uma imagem para um fator desejado, $c$, a equação acima pode ser reorganizada para a solução de $r$:\n",
        "\n",
        "$$r = ⌊{\\large\\frac{c \\times m \\times n}{m + n + 1}}⌋$$\n",
        "\n",
        "Observe que esta fórmula independe da dimensão do canal de cores, pois cada uma das aproximações RGB não afeta uma à outra. Agora, escreva uma função para comprimir uma imagem de entrada dado um fator de compressão desejado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "viVO-I60QynI"
      },
      "outputs": [],
      "source": [
        "def compress_image_with_factor(I, compression_factor, verbose=False):\n",
        "  # Returns a compressed image based on a desired compression factor\n",
        "  m,n,o = I.shape\n",
        "  r = int((compression_factor * m * n)/(m + n + 1))\n",
        "  I_r, I_r_prop = compress_image(I, r, verbose=verbose)\n",
        "  return I_r"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWSv58J6LSRQ"
      },
      "source": [
        "Comprima uma imagem em 15% de seu tamanho original."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HVeeloIwQ1b6"
      },
      "outputs": [],
      "source": [
        "compression_factor = 0.15\n",
        "I_r_img = compress_image_with_factor(I, compression_factor, verbose=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LkeRyms7jZMd"
      },
      "source": [
        "### Soma cumulativa de valores singulares\n",
        "\n",
        "A soma cumulativa de valores singulares pode ser um indicador útil para a quantidade de energia capturada por uma aproximação de posto r. Visualize a proporção cumulativa de valores singulares de RGB médio na imagem de amostra. A função `tf.cumsum` pode ser útil para esse fim."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CteJ6VbKlndu"
      },
      "outputs": [],
      "source": [
        "def viz_energy(I):\n",
        "  # Visualize the energy captured based on rank\n",
        "  # Computing SVD\n",
        "  I = tf.convert_to_tensor(I)/255\n",
        "  I_batched = tf.transpose(I, [2, 0, 1]) \n",
        "  s, U, V = tf.linalg.svd(I_batched)\n",
        "  # Plotting average proportion across RGB channels \n",
        "  props_rgb = tf.map_fn(lambda x: tf.cumsum(x)/tf.reduce_sum(x), s)\n",
        "  props_rgb_mean = tf.reduce_mean(props_rgb, axis=0)\n",
        "  plt.figure(figsize=(11,6))\n",
        "  plt.plot(range(len(I)), props_rgb_mean, color='k')\n",
        "  plt.xlabel(\"Rank / singular value number\")\n",
        "  plt.ylabel(\"Cumulative proportion of singular values\")\n",
        "  plt.title(\"RGB-averaged proportion of energy captured by the first 'r' singular values\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vl9PKow-GgCp"
      },
      "outputs": [],
      "source": [
        "viz_energy(I)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQtwimKuQP19"
      },
      "source": [
        "Parece que mais de 90% da energia desta imagem foi capturada nos primeiros 100 valores singulares. Agora, escreva uma função para comprimir uma imagem de entrada dado um fator de retenção de energia desejado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fum5Cvm7R5vH"
      },
      "outputs": [],
      "source": [
        "def compress_image_with_energy(I, energy_factor, verbose=False):\n",
        "  # Returns a compressed image based on a desired energy factor\n",
        "  # Computing SVD\n",
        "  I_rescaled = tf.convert_to_tensor(I)/255\n",
        "  I_batched = tf.transpose(I_rescaled, [2, 0, 1]) \n",
        "  s, U, V = tf.linalg.svd(I_batched)\n",
        "  # Extracting singular values\n",
        "  props_rgb = tf.map_fn(lambda x: tf.cumsum(x)/tf.reduce_sum(x), s)\n",
        "  props_rgb_mean = tf.reduce_mean(props_rgb, axis=0)\n",
        "  # Find closest r that corresponds to the energy factor\n",
        "  r = tf.argmin(tf.abs(props_rgb_mean - energy_factor)) + 1\n",
        "  actual_ef = props_rgb_mean[r]\n",
        "  I_r, I_r_prop = compress_image(I, r, verbose=verbose)\n",
        "  print(f\"Proportion of energy captured by the first {r} singular values: {actual_ef:.3f}\")\n",
        "  return I_r"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_rChG0OLby1"
      },
      "source": [
        "Comprima uma imagem para reter 75% de sua energia."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xDXBaZQ4c5jF"
      },
      "outputs": [],
      "source": [
        "energy_factor = 0.75\n",
        "I_r_img = compress_image_with_energy(I, energy_factor, verbose=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tmqTW0CYX-v"
      },
      "source": [
        "### Erro e valores singulares\n",
        "\n",
        "Existe também um relacionamento interessante entre o erro de aproximação e os valores singulares. Acontece que o quadrado da norma de Frobenius da aproximação é igual à soma dos quadrados de seus valores singulares que foram deixados de fora:\n",
        "\n",
        "$${||A - A_r||}^2 = \\sum_{i=r+1}^{R}σ_i^2$$\n",
        "\n",
        "Teste esse relacionamento com uma aproximação de posto 10 da matriz de exemplo no início deste tutorial."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hctOvN8BckiS"
      },
      "outputs": [],
      "source": [
        "s, U, V = tf.linalg.svd(A)\n",
        "A_10, A_10_size = rank_r_approx(s, U, V, 10)\n",
        "squared_norm = tf.norm(A - A_10)**2\n",
        "s_squared_sum = tf.reduce_sum(s[10:]**2)\n",
        "print(f\"Squared Frobenius norm: {squared_norm:.3f}\")\n",
        "print(f\"Sum of squared singular values left out: {s_squared_sum:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgGQuV-yqYZH"
      },
      "source": [
        "## Conclusão\n",
        "\n",
        "Este notebook apresentou o processo de implementação da decomposição em valores singulares com o TensorFlow e sua aplicação para escrever um algoritmo de compactação de imagens. Aqui estão mais algumas dicas que podem ser úteis:\n",
        "\n",
        "- As [APIs Core do TensorFlow](https://www.tensorflow.org/guide/core) podem ser utilizadas para uma variedade de casos de uso de computação científica de alto desempenho.\n",
        "- Para saber mais sobre as funcionalidades de álgebra linear do TensorFlow, veja os documentos do [módulo linalg](https://www.tensorflow.org/api_docs/python/tf/linalg) .\n",
        "- O SVD também pode ser aplicado para construir [sistemas de recomendação](https://developers.google.com/machine-learning/recommendation/labs/movie-rec-programming-exercise) .\n",
        "\n",
        "Para obter mais exemplos de uso das APIs Core do TensorFlow, confira o [guia](https://www.tensorflow.org/guide/core) . Se você quiser saber mais sobre como carregar e preparar dados, consulte os tutoriais sobre [carregamento de dados de imagem](https://www.tensorflow.org/tutorials/load_data/images) ou [carregamento de dados CSV](https://www.tensorflow.org/tutorials/load_data/csv)."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "matrix_core.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
