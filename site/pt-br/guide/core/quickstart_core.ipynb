{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rX8mhOLljYeM"
      },
      "source": [
        "##### Copyright 2022 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "BZSlp3DAjdYf"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wF5wszaj97Y"
      },
      "source": [
        "# Guia de início rápido para as APIs Core do TensorFlow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUNzJc4jTj6G"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>     <a target=\"_blank\" href=\"https://www.tensorflow.org/guide/core/quickstart_core\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Veja em TensorFlow.org</a> </td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/pt-br/guide/core/quickstart_core.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Executar no Google Colab</a> </td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/pt-br/guide/core/quickstart_core.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver fonte em GitHub</a> </td>\n",
        "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/pt-br/guide/core/quickstart_core.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Baixar notebook</a> </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04QgGZc9bF5D"
      },
      "source": [
        "Este tutorial de início rápido demonstra como você pode usar as [APIs de baixo nível do TensorFlow Core](https://www.tensorflow.org/guide/core) para criar e treinar um modelo de regressão linear múltipla que prevê a eficiência de combustível. Ele usa o dataset [Auto MPG](https://archive.ics.uci.edu/ml/datasets/auto+mpg) {:.external} que contém dados de eficiência de combustível para automóveis do final dos anos 1970 e início dos anos 1980.\n",
        "\n",
        "Você seguirá as etapas típicas de um processo de aprendizado de máquina:\n",
        "\n",
        "1. Carregar o dataset.\n",
        "2. Construir um [pipeline de entrada](../data.ipynb) .\n",
        "3. Construir um modelo de [regressão linear](https://developers.google.com/machine-learning/glossary#linear-regression) múltipla {:.external}.\n",
        "4. Avaliar o desempenho do modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnrWf3PCEzXL"
      },
      "source": [
        "## Configuração\n",
        "\n",
        "Importe o TensorFlow e outras bibliotecas necessárias para começar:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0trJmd6DjqBZ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import matplotlib\n",
        "from matplotlib import pyplot as plt\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "# Set a random seed for reproducible results \n",
        "tf.random.set_seed(22)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NAbSZiaoJ4z"
      },
      "source": [
        "## Carga e pré-processamento do dataset\n",
        "\n",
        "Em seguida, você precisa carregar e pré-processar o [dataset Auto MPG](https://archive.ics.uci.edu/ml/datasets/auto+mpg) {:.external} do [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/) {:.external}. Este dataset usa uma variedade de recursos quantitativos e categóricos, como cilindros, deslocamento, potência e peso para prever a eficiência de combustível dos automóveis no final dos anos 1970 e início dos anos 1980.\n",
        "\n",
        "O dataset contém alguns valores desconhecidos. Certifique-se de descartar todos os valores ausentes com o `pandas.DataFrame.dropna` e converter o dataset num tipo de tensor `tf.float32` com as funções `tf.convert_to_tensor` e `tf.cast` ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HglhDsUfrJ98"
      },
      "outputs": [],
      "source": [
        "url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data'\n",
        "column_names = ['MPG', 'Cylinders', 'Displacement', 'Horsepower', 'Weight',\n",
        "                'Acceleration', 'Model Year', 'Origin']\n",
        "\n",
        "dataset = pd.read_csv(url, names=column_names, na_values='?', comment='\\t',\n",
        "                          sep=' ', skipinitialspace=True)\n",
        "\n",
        "dataset = dataset.dropna()\n",
        "dataset_tf = tf.convert_to_tensor(dataset, dtype=tf.float32)\n",
        "dataset.tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vgoDL3hYesB"
      },
      "source": [
        "Em seguida, divida o dataset em conjuntos de treinamento e teste. Certifique-se de embaralhar o dataset com `tf.random.shuffle` para evitar divisões com viés."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0mJU4kt6YiAp"
      },
      "outputs": [],
      "source": [
        "dataset_shuffled = tf.random.shuffle(dataset_tf, seed=22)\n",
        "train_data, test_data = dataset_shuffled[100:], dataset_shuffled[:100]\n",
        "x_train, y_train = train_data[:, 1:], train_data[:, 0]\n",
        "x_test, y_test = test_data[:, 1:], test_data[:, 0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bscb2Vsbi3TE"
      },
      "source": [
        "Faça a engenharia de recursos básicos através da transformação one-hot-encoding do recurso `\"Origin\"` . A função `tf.one_hot` é útil para transformar esta coluna categórica em 3 colunas binárias independentes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_B8N9IV1i6IV"
      },
      "outputs": [],
      "source": [
        "def onehot_origin(x):\n",
        "  origin = tf.cast(x[:, -1], tf.int32)\n",
        "  # Use `origin - 1` to account for 1-indexed feature\n",
        "  origin_oh = tf.one_hot(origin - 1, 3)\n",
        "  x_ohe = tf.concat([x[:, :-1], origin_oh], axis = 1)\n",
        "  return x_ohe\n",
        "\n",
        "x_train_ohe, x_test_ohe = onehot_origin(x_train), onehot_origin(x_test)\n",
        "x_train_ohe.numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnoCDzzedite"
      },
      "source": [
        "Este exemplo mostra um problema de regressão múltipla com preditores ou recursos em escalas bastante diferentes. Portanto, é vantajoso padronizar os dados para que cada característica tenha média zero e variância unitária. Use as funções `tf.reduce_mean` e `tf.math.reduce_std` para fazer a padronização. Você pode depois desnormalizar a previsão do modelo de regressão para obter seu valor em termos das unidades originais."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dJJFdvqydhyp"
      },
      "outputs": [],
      "source": [
        "class Normalize(tf.Module):\n",
        "  def __init__(self, x):\n",
        "    # Initialize the mean and standard deviation for normalization\n",
        "    self.mean = tf.math.reduce_mean(x, axis=0)\n",
        "    self.std = tf.math.reduce_std(x, axis=0)\n",
        "\n",
        "  def norm(self, x):\n",
        "    # Normalize the input\n",
        "    return (x - self.mean)/self.std\n",
        "\n",
        "  def unnorm(self, x):\n",
        "    # Unnormalize the input\n",
        "    return (x * self.std) + self.mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5BONV6fYYwZb"
      },
      "outputs": [],
      "source": [
        "norm_x = Normalize(x_train_ohe)\n",
        "norm_y = Normalize(y_train)\n",
        "x_train_norm, y_train_norm = norm_x.norm(x_train_ohe), norm_y.norm(y_train)\n",
        "x_test_norm, y_test_norm = norm_x.norm(x_test_ohe), norm_y.norm(y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPZ68wASog_I"
      },
      "source": [
        "## Construção de um modelo de aprendizado de máquina\n",
        "\n",
        "Crie um modelo de regressão linear com as APIs Core do TensorFlow. A equação para regressão linear múltipla é a seguinte:\n",
        "\n",
        "```\n",
        "onde\n",
        "```\n",
        "\n",
        "Usando o decorador `@tf.function`, o código Python correspondente será rastreado para gerar um gráfico do TensorFlow que possa ser chamado. Essa abordagem é útil para salvar e carregar o modelo após o treinamento. Ela também pode fornecer um aumento de desempenho para modelos com muitas camadas e operações complexas.\n",
        "\n",
        "- $\\underset{m\\times 1}{\\mathrm{Y}}$: vetor alvo\n",
        "- $\\underset{m\\times n}{\\mathrm{X}}$: matriz de atributos\n",
        "- $\\underset{m\\times 1}{\\mathrm{Y}}$: vetor de peso\n",
        "- $b$: bias\n",
        "\n",
        "Usando o decorador `@tf.function`, o código Python correspondente será rastreado para gerar um gráfico do TensorFlow que possa ser chamado. Essa abordagem é útil para salvar e carregar o modelo após o treinamento. Ela também pode fornecer um aumento de desempenho para modelos com muitas camadas e operações complexas. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h3IKyzTCDNGo"
      },
      "outputs": [],
      "source": [
        "class LinearRegression(tf.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    self.built = False\n",
        "\n",
        "  @tf.function\n",
        "  def __call__(self, x):\n",
        "    # Initialize the model parameters on the first call\n",
        "    if not self.built:\n",
        "      # Randomly generate the weight vector and bias term\n",
        "      rand_w = tf.random.uniform(shape=[x.shape[-1], 1])\n",
        "      rand_b = tf.random.uniform(shape=[])\n",
        "      self.w = tf.Variable(rand_w)\n",
        "      self.b = tf.Variable(rand_b)\n",
        "      self.built = True\n",
        "    y = tf.add(tf.matmul(x, self.w), self.b)\n",
        "    return tf.squeeze(y, axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2hiez2eIUz8"
      },
      "source": [
        "Para cada exemplo, o modelo retorna uma previsão para o MPG do automóvel de entrada, calculando a soma ponderada de seus recursos mais um termo de bias. Essa previsão pode depois ter a padronização revertida para obter seu valor em termos das unidades originais."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OeOrNdnkEEcR"
      },
      "outputs": [],
      "source": [
        "lin_reg = LinearRegression()\n",
        "prediction = lin_reg(x_train_norm[:1])\n",
        "prediction_unnorm = norm_y.unnorm(prediction)\n",
        "prediction_unnorm.numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIHANxNSvWr9"
      },
      "source": [
        "## Definição de uma função de perda\n",
        "\n",
        "Agora, defina uma função de perda para avaliar o desempenho do modelo durante o processo de treinamento.\n",
        "\n",
        "Como os problemas de regressão lidam com saídas contínuas, o erro quadrático médio (MSE) é uma escolha ideal para a função de perda. O MSE é definido pela seguinte equação:\n",
        "\n",
        "```\n",
        "onde\n",
        "```\n",
        "\n",
        "O objetivo deste problema de regressão é encontrar o vetor de peso ideal, $w$, e bias, $b$, que minimiza a função de perda do MSE.\n",
        "\n",
        "- $\\hat{y}$: vetor de previsões\n",
        "- $y$: vetor de alvos verdadeiros\n",
        "\n",
        "O objetivo deste problema de regressão é encontrar o vetor de peso ideal, $w$, e bias, $b$, que minimiza a função de perda do MSE. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8tYNVUkmw35s"
      },
      "outputs": [],
      "source": [
        "def mse_loss(y_pred, y):\n",
        "  return tf.reduce_mean(tf.square(y_pred - y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htI-7aJPqclK"
      },
      "source": [
        "## Treinamento e avaliação do seu modelo\n",
        "\n",
        "O uso de minilotes para treinamento garante eficiência de memória e convergência mais rápida. A API `tf.data.Dataset` tem funções úteis para lotes e embaralhamento. A API permite que você crie pipelines de entrada complexos a partir de peças simples e reutilizáveis. Saiba mais sobre como criar pipelines de entrada do TensorFlow [neste guia](https://www.tensorflow.org/guide/data) ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kxST2w_Nq0C5"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train_norm, y_train_norm))\n",
        "train_dataset = train_dataset.shuffle(buffer_size=x_train.shape[0]).batch(batch_size)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((x_test_norm, y_test_norm))\n",
        "test_dataset = test_dataset.shuffle(buffer_size=x_test.shape[0]).batch(batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9haUW8Yq3xD"
      },
      "source": [
        "Em seguida, escreva um loop de treinamento para atualizar iterativamente os parâmetros do seu modelo, fazendo uso da função de perda MSE e seus gradientes em relação aos parâmetros de entrada.\n",
        "\n",
        "Esse método iterativo é conhecido como [método do gradiente descendente](https://developers.google.com/machine-learning/glossary#gradient-descent) {:.external}. A cada iteração, os parâmetros do modelo são atualizados dando um passo na direção oposta de seus gradientes calculados. O tamanho dessa etapa é determinado pela taxa de aprendizado, que é um hiperparâmetro configurável. Lembre-se de que o gradiente de uma função indica a direção de sua maior subida; portanto, dar um passo na direção oposta indica a direção da descida mais íngreme, o que ajuda a minimizar a função de perda do MSE."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y7suUbJXVLqP"
      },
      "outputs": [],
      "source": [
        "# Set training parameters\n",
        "epochs = 100\n",
        "learning_rate = 0.01\n",
        "train_losses, test_losses = [], []\n",
        "\n",
        "# Format training loop\n",
        "for epoch in range(epochs):\n",
        "  batch_losses_train, batch_losses_test = [], []\n",
        "\n",
        "  # Iterate through the training data\n",
        "  for x_batch, y_batch in train_dataset:\n",
        "    with tf.GradientTape() as tape:\n",
        "      y_pred_batch = lin_reg(x_batch)\n",
        "      batch_loss = mse_loss(y_pred_batch, y_batch)\n",
        "    # Update parameters with respect to the gradient calculations\n",
        "    grads = tape.gradient(batch_loss, lin_reg.variables)\n",
        "    for g,v in zip(grads, lin_reg.variables):\n",
        "      v.assign_sub(learning_rate * g)\n",
        "    # Keep track of batch-level training performance \n",
        "    batch_losses_train.append(batch_loss)\n",
        "  \n",
        "  # Iterate through the testing data\n",
        "  for x_batch, y_batch in test_dataset:\n",
        "    y_pred_batch = lin_reg(x_batch)\n",
        "    batch_loss = mse_loss(y_pred_batch, y_batch)\n",
        "    # Keep track of batch-level testing performance \n",
        "    batch_losses_test.append(batch_loss)\n",
        "\n",
        "  # Keep track of epoch-level model performance\n",
        "  train_loss = tf.reduce_mean(batch_losses_train)\n",
        "  test_loss = tf.reduce_mean(batch_losses_test)\n",
        "  train_losses.append(train_loss)\n",
        "  test_losses.append(test_loss)\n",
        "  if epoch % 10 == 0:\n",
        "    print(f'Mean squared error for step {epoch}: {train_loss.numpy():0.3f}')\n",
        "\n",
        "# Output final losses\n",
        "print(f\"\\nFinal train loss: {train_loss:0.3f}\")\n",
        "print(f\"Final test loss: {test_loss:0.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mDAAPFqVVgn"
      },
      "source": [
        "Desenhe as mudanças na perda de MSE ao longo do tempo. Calcular métricas de desempenho em um [conjunto de validação](https://developers.google.com/machine-learning/glossary#validation-set) designado {:.external} ou [conjunto de teste](https://developers.google.com/machine-learning/glossary#test-set) {:.external} garante que não ocorra o overfit excessivo do modelo em relação ao dataset de treinamento e possa generalizar bem para dados não vistos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F7dTAzgHDUh7"
      },
      "outputs": [],
      "source": [
        "matplotlib.rcParams['figure.figsize'] = [9, 6]\n",
        "\n",
        "plt.plot(range(epochs), train_losses, label = \"Training loss\")\n",
        "plt.plot(range(epochs), test_losses, label = \"Testing loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Mean squared error loss\")\n",
        "plt.legend()\n",
        "plt.title(\"MSE loss vs training iterations\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aj8NrlzlJqDG"
      },
      "source": [
        "Parece que o modelo faz um bom trabalho ao ajustar os dados de treinamento e, ao mesmo tempo, generalizar bem os dados de teste não vistos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUNIPubuPYDR"
      },
      "source": [
        "## Salve e carregue o modelo\n",
        "\n",
        "Comece criando um módulo de exportação que receba dados brutos e execute as seguintes operações:\n",
        "\n",
        "- Extração de recursos\n",
        "- Normalização\n",
        "- Predição\n",
        "- Desnormalização"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g-uOrGa9ZehG"
      },
      "outputs": [],
      "source": [
        "class ExportModule(tf.Module):\n",
        "  def __init__(self, model, extract_features, norm_x, norm_y):\n",
        "    # Initialize pre and postprocessing functions\n",
        "    self.model = model\n",
        "    self.extract_features = extract_features\n",
        "    self.norm_x = norm_x\n",
        "    self.norm_y = norm_y\n",
        "\n",
        "  @tf.function(input_signature=[tf.TensorSpec(shape=[None, None], dtype=tf.float32)]) \n",
        "  def __call__(self, x):\n",
        "    # Run the ExportModule for new data points\n",
        "    x = self.extract_features(x)\n",
        "    x = self.norm_x.norm(x)\n",
        "    y = self.model(x)\n",
        "    y = self.norm_y.unnorm(y)\n",
        "    return y "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YPYYLQ8EZiU8"
      },
      "outputs": [],
      "source": [
        "lin_reg_export = ExportModule(model=lin_reg,\n",
        "                              extract_features=onehot_origin,\n",
        "                              norm_x=norm_x,\n",
        "                              norm_y=norm_y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6v8xi06XZWiC"
      },
      "source": [
        "Se você deseja salvar o modelo em seu estado atual, use a função `tf.saved_model.save`. Para carregar um modelo salvo para fazer previsões, use a função `tf.saved_model.load` ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K1IvMoHbptht"
      },
      "outputs": [],
      "source": [
        "import tempfile\n",
        "import os\n",
        "\n",
        "models = tempfile.mkdtemp()\n",
        "save_path = os.path.join(models, 'lin_reg_export')\n",
        "tf.saved_model.save(lin_reg_export, save_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rYb6DrEH0GMv"
      },
      "outputs": [],
      "source": [
        "lin_reg_loaded = tf.saved_model.load(save_path)\n",
        "test_preds = lin_reg_loaded(x_test)\n",
        "test_preds[:10].numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-47O6_GLdRuT"
      },
      "source": [
        "## Conclusão\n",
        "\n",
        "Parabéns! Você treinou um modelo de regressão usando as APIs de baixo nível do TensorFlow Core.\n",
        "\n",
        "Para mais exemplos de uso das APIs do TensorFlow Core, confira os seguintes guias:\n",
        "\n",
        "- [Regressão logística](./logistic_regression_core.ipynb) para classificação binária\n",
        "- [Perceptrons multicamadas](./mlp_core.ipynb) para reconhecimento de dígitos escritos à mão\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "rX8mhOLljYeM"
      ],
      "name": "quickstart_core.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
