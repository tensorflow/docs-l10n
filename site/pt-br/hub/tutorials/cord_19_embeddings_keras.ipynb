{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wFF5JFyD2Ki"
      },
      "source": [
        "#### Copyright 2019 The TensorFlow Hub Authors.\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uf6NouXxDqGk"
      },
      "outputs": [],
      "source": [
        "# Copyright 2019 The TensorFlow Hub Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# =============================================================================="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORy-KvWXGXBo"
      },
      "source": [
        "# Explorando os embeddings Swivel CORD-19 do TF Hub\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfBg1C5NB3X0"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>     <a target=\"_blank\" href=\"https://www.tensorflow.org/hub/tutorials/cord_19_embeddings_keras\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver em TensorFlow.org</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/hub/tutorials/cord_19_embeddings_keras.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Executar no Google Colab</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/cord_19_embeddings_keras.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver no GitHub</a>\n",
        "</td>\n",
        "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/hub/tutorials/cord_19_embeddings_keras.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Baixar notebook</a>\n",
        "</td>\n",
        "  <td>     <a href=\"https://tfhub.dev/tensorflow/cord-19/swivel-128d/3\"><img src=\"https://www.tensorflow.org/images/hub_logo_32px.png\">Ver modelo do TF Hub</a>\n",
        "</td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yI6Mh3-P0_Pk"
      },
      "source": [
        "O módulo de embeddings de texto Swivel CORD-19 do TF Hub (https://tfhub.dev/tensorflow/cord-19/swivel-128d/1) foi criado para ajudar pesquisadores a analisar texto de linguagens naturais relacionado à COVID-19. Esses embeddings foram treinados com títulos, autores, resumos, corpo de textos e títulos de referência de artigos disponíveis no [dataset CORD-19](https://api.semanticscholar.org/CorpusID:216056360).\n",
        "\n",
        "Neste Colab, vamos:\n",
        "\n",
        "- Analisar palavras semanticamente similares no espaço de embeddings\n",
        "- Treinar um classificador com o dataset SciCite usando os embeddings do CORD-19\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVWOrccw0_Pl"
      },
      "source": [
        "## Configuração\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ym2nXOPuPV__"
      },
      "outputs": [],
      "source": [
        "import functools\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "from tqdm import trange"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_VgRRf2I7tER"
      },
      "source": [
        "# Analise os embeddings\n",
        "\n",
        "Vamos começar analisando o embedding por meio do cálculo e da plotagem de uma matriz de correlação entre os diferentes termos. Se o embedding tiver aprendido a capturar o significado de palavras diferentes com êxito, os vetores de embeddings de palavras semanticamente similares devem estar próximos. Vamos dar uma olhada em alguns termos relacionados à COVID-19."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HNN_9bBKSLHU"
      },
      "outputs": [],
      "source": [
        "# Use the inner product between two embedding vectors as the similarity measure\n",
        "def plot_correlation(labels, features):\n",
        "  corr = np.inner(features, features)\n",
        "  corr /= np.max(corr)\n",
        "  sns.heatmap(corr, xticklabels=labels, yticklabels=labels)\n",
        "\n",
        "# Generate embeddings for some terms\n",
        "queries = [\n",
        "  # Related viruses\n",
        "  'coronavirus', 'SARS', 'MERS',\n",
        "  # Regions\n",
        "  'Italy', 'Spain', 'Europe',\n",
        "  # Symptoms\n",
        "  'cough', 'fever', 'throat'\n",
        "]\n",
        "\n",
        "module = hub.load('https://tfhub.dev/tensorflow/cord-19/swivel-128d/3')\n",
        "embeddings = module(queries)\n",
        "\n",
        "plot_correlation(queries, embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bg-PGqtm8B7K"
      },
      "source": [
        "Podemos ver que o embedding conseguiu capturar com êxito o significado de diferentes termos. Cada palavra é similar a outras palavras de seu cluster (isto é, \"coronavírus\" tem alta correlação com \"SARS\" e \"MERS\"), embora seja diferente de termos de outros clusters (isto é, a similaridade entre \"SARS\" e \"Spain\" – Espanha – é próxima de 0).\n",
        "\n",
        "Agora, vamos ver como podemos usar esses embeddings para resolver uma tarefa específica."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idJ1jFmH7xMa"
      },
      "source": [
        "## SciCite – Classificação da intenção de citação\n",
        "\n",
        "Esta seção mostra como usar o embedding para tarefas downstream, como classificação de texto. Usaremos o [dataset SciCite](https://www.tensorflow.org/datasets/catalog/scicite) do TensorFlow Datasets para classificar as intenções de citações em artigos acadêmicos. Dada uma frase com uma citação de um artigo acadêmico, vamos classificar se a intenção principal da citação é informação histórica, uso de métodos ou comparação de resultados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ghc-CzT8DDaZ"
      },
      "outputs": [],
      "source": [
        "builder = tfds.builder(name='scicite')\n",
        "builder.download_and_prepare()\n",
        "train_data, validation_data, test_data = builder.as_dataset(\n",
        "    split=('train', 'validation', 'test'),\n",
        "    as_supervised=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CVjyBD0ZPh4Z"
      },
      "outputs": [],
      "source": [
        "#@title Let's take a look at a few labeled examples from the training set\n",
        "NUM_EXAMPLES =   10#@param {type:\"integer\"}\n",
        "\n",
        "TEXT_FEATURE_NAME = builder.info.supervised_keys[0]\n",
        "LABEL_NAME = builder.info.supervised_keys[1]\n",
        "\n",
        "def label2str(numeric_label):\n",
        "  m = builder.info.features[LABEL_NAME].names\n",
        "  return m[numeric_label]\n",
        "\n",
        "data = next(iter(train_data.batch(NUM_EXAMPLES)))\n",
        "\n",
        "\n",
        "pd.DataFrame({\n",
        "    TEXT_FEATURE_NAME: [ex.numpy().decode('utf8') for ex in data[0]],\n",
        "    LABEL_NAME: [label2str(x) for x in data[1]]\n",
        "})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65s9UpYJ_1ct"
      },
      "source": [
        "## Treinamento de um classificador de intenção de citação\n",
        "\n",
        "Vamos treinar um classificador com o [dataset SciCite](https://www.tensorflow.org/datasets/catalog/scicite) usando o Keras. Vamos criar um modelo que use os embeddings do CORD-19 com uma camada de classificação por cima."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yZUclu8xBYlj"
      },
      "outputs": [],
      "source": [
        "#@title Hyperparameters { run: \"auto\" }\n",
        "\n",
        "EMBEDDING = 'https://tfhub.dev/tensorflow/cord-19/swivel-128d/3'  #@param {type: \"string\"}\n",
        "TRAINABLE_MODULE = False  #@param {type: \"boolean\"}\n",
        "\n",
        "hub_layer = hub.KerasLayer(EMBEDDING, input_shape=[], \n",
        "                           dtype=tf.string, trainable=TRAINABLE_MODULE)\n",
        "\n",
        "model = tf.keras.Sequential()\n",
        "model.add(hub_layer)\n",
        "model.add(tf.keras.layers.Dense(3))\n",
        "model.summary()\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "weZKWK-pLBll"
      },
      "source": [
        "## Treinamento e avaliação do modelo\n",
        "\n",
        "Vamos treinar e avaliar o modelo para ver o desempenho da tarefa SciCite."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cO1FWkZW2WS9"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 35#@param {type: \"integer\"}\n",
        "BATCH_SIZE = 32#@param {type: \"integer\"}\n",
        "\n",
        "history = model.fit(train_data.shuffle(10000).batch(BATCH_SIZE),\n",
        "                    epochs=EPOCHS,\n",
        "                    validation_data=validation_data.batch(BATCH_SIZE),\n",
        "                    verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2sKE7kEyLJQZ"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "def display_training_curves(training, validation, title, subplot):\n",
        "  if subplot%10==1: # set up the subplots on the first call\n",
        "    plt.subplots(figsize=(10,10), facecolor='#F0F0F0')\n",
        "    plt.tight_layout()\n",
        "  ax = plt.subplot(subplot)\n",
        "  ax.set_facecolor('#F8F8F8')\n",
        "  ax.plot(training)\n",
        "  ax.plot(validation)\n",
        "  ax.set_title('model '+ title)\n",
        "  ax.set_ylabel(title)\n",
        "  ax.set_xlabel('epoch')\n",
        "  ax.legend(['train', 'valid.'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nnQfxevhLKld"
      },
      "outputs": [],
      "source": [
        "display_training_curves(history.history['accuracy'], history.history['val_accuracy'], 'accuracy', 211)\n",
        "display_training_curves(history.history['loss'], history.history['val_loss'], 'loss', 212)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjvtOw72Lpyw"
      },
      "source": [
        "## Avalie o modelo\n",
        "\n",
        "Vamos conferir o desempenho do modelo. Serão retornados dois valores: perda (um número que representa o erro; quanto menor, melhor) e exatidão."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y0ExC8D0LX8m"
      },
      "outputs": [],
      "source": [
        "results = model.evaluate(test_data.batch(512), verbose=2)\n",
        "\n",
        "for name, value in zip(model.metrics_names, results):\n",
        "  print('%s: %.3f' % (name, value))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWp5OWeTL2EW"
      },
      "source": [
        "Podemos ver que a perda diminui rapidamente e que a exatidão aumenta rapidamente. Vamos plotar alguns exemplos para verificar como a previsão está relacionada aos rótulos verdadeiros:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VzHzAOaaOVC0"
      },
      "outputs": [],
      "source": [
        "prediction_dataset = next(iter(test_data.batch(20)))\n",
        "\n",
        "prediction_texts = [ex.numpy().decode('utf8') for ex in prediction_dataset[0]]\n",
        "prediction_labels = [label2str(x) for x in prediction_dataset[1]]\n",
        "\n",
        "predictions = [\n",
        "    label2str(x) for x in np.argmax(model.predict(prediction_texts), axis=-1)]\n",
        "\n",
        "\n",
        "pd.DataFrame({\n",
        "    TEXT_FEATURE_NAME: prediction_texts,\n",
        "    LABEL_NAME: prediction_labels,\n",
        "    'prediction': predictions\n",
        "})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSGcrkE069_Q"
      },
      "source": [
        "Podemos ver que, para essa amostra aleatória, o modelo prevê o rótulo correto na maioria das vezes, o que indica que ele consegue fazer o embedding de frases científicas muito bem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLE0kCfO5CIA"
      },
      "source": [
        "# Quais são os próximos passos?\n",
        "\n",
        "Agora que você conheceu um pouco mais sobre os embeddings Swivel CORD-19 do TF Hub, sugerimos que participe da competição CORD-19 do Kaggle para contribuir com o desenvolvimento de informações científicas a partir de textos acadêmicos relacionados à COVID-19.\n",
        "\n",
        "- Participe do [Desafio CORD-19 do Kaggle](https://www.kaggle.com/allen-institute-for-ai/CORD-19-research-challenge)\n",
        "- Saiba mais sobre o [COVID-19 Open Research Dataset (CORD-19)](https://api.semanticscholar.org/CorpusID:216056360)\n",
        "- Confira a documentação e mais detalhes sobre os embeddings do TF Hub em https://tfhub.dev/tensorflow/cord-19/swivel-128d/1\n",
        "- Explore o espaço de embeddings do CORD-19 com o [TensorFlow Embedding Projector](http://projector.tensorflow.org/?config=https://storage.googleapis.com/tfhub-examples/tensorflow/cord-19/swivel-128d/3/tensorboard/projector_config.json) (projetos de embeddings do TF)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "cord_19_embeddings_keras.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
