{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2q27gKz1H20"
      },
      "source": [
        "##### Copyright 2022 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "TUfAcER1oUS6"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gb7qyhNL1yWt"
      },
      "source": [
        "# Pesquisador de texto com o TensorFlow Lite Model Maker"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fw5Y7snSuG51"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>     <a target=\"_blank\" href=\"https://www.tensorflow.org/lite/models/modify/model_maker/text_searcher\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver em TensorFlow.org</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/pt-br/lite/models/modify/model_maker/text_searcher.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Executar no Google Colab</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/pt-br/lite/models/modify/model_maker/text_searcher.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver fonte no GitHub</a>\n",
        "</td>\n",
        "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/pt-br/lite/models/modify/model_maker/text_searcher.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Baixar notebook</a>\n",
        "</td>\n",
        "  <td>     <a href=\"https://tfhub.dev/google/universal-sentence-encoder-lite/2\"><img src=\"https://www.tensorflow.org/images/hub_logo_32px.png\">Ver modelo do TF Hub</a>\n",
        "</td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2sdIlXEVPZR"
      },
      "source": [
        "Neste notebook do Colab, você aprenderá a usar a biblioteca [TensorFlow Lite Model Maker](https://www.tensorflow.org/lite/models/modify/model_maker) (criador de modelos do TensorFlow Lite) para criar um modelo de pesquisador do TF Lite. Você pode usar um modelo de pesquisador de texto para criar uma pesquisa semântica ou resposta inteligente para seu aplicativo. Esse tipo de modelo permite receber uma consulta de texto e pesquisar as entradas mais relacionadas em um dataset de texto, como um banco de dados de páginas web. O modelo retorna uma lista das entradas de pontuação com a menor distância no dataset, incluindo os metadados que você especificar, como URL, título da página ou outros identificadores de entrada de texto. Após compilar o modelo, você pode implantá-lo em dispositivos (como Android) usando a [API Task Library Searcher](https://www.tensorflow.org/lite/inference_with_metadata/task_library/text_searcher) para executar a inferência com apenas algumas linhas de código.\n",
        "\n",
        "Este tutorial usa o dataset CNN/DailyMail como uma instância para criar o modelo de pesquisador do TF Lite. Você pode usar seu próprio dataset no formato de valor separado por vírgula (CSV)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_aZYF85VaVK"
      },
      "source": [
        "## Pesquisa de texto usando Scalable Nearest Neighbor (vizinho mais próximo escalável)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sr3q-gvm3cI8"
      },
      "source": [
        "Este tutorial usa o dataset de resumo não anonimizado CNN/DailyMail, disponível publicamente, que foi gerado pelo [repositório do GitHub](https://github.com/abisee/cnn-dailymail). Esse dataset contém mais de 300 mil notícias e, portanto, é um bom dataset para criar o modelo de pesquisador, além de retornar diversas notícias relacionadas durante a inferência do modelo dada uma consulta de texto.\n",
        "\n",
        "O modelo de pesquisador de texto deste exemplo usa um arquivo de índice de [ScaNN](https://github.com/google-research/google-research/tree/master/scann) (Scalable Nearest Neighbors) que pode pesquisar itens similares em um banco de dados predefinido. O ScaNN alcança um desempenho excepcional em pesquisa eficiente de similaridade de vetores em grande escala.\n",
        "\n",
        "Os destaques e as URLs nesse dataset são usados neste Colab para criar o modelo:\n",
        "\n",
        "1. Os destaques são os textos para gerar os vetores de características de embedding, e depois são usados para fazer a pesquisa.\n",
        "2. As URLs são os resultados retornados exibidos para os usuários após procurar os destaques relacionados.\n",
        "\n",
        "Este tutorial salva esses dados no arquivo CSV e depois usa esse arquivo para compilar o modelo. Veja diversos exemplos do dataset.\n",
        "\n",
        "Destaques | URLs\n",
        "--- | ---\n",
        "Hawaiian Airlines again lands at No. 1 in on-time performance. The Airline Quality Rankings Report looks at the 14 largest U.S. airlines. ExpressJet <br> and American Airlines had the worst on-time performance. Virgin America had the best baggage  handling; Southwest had lowest complaint rate. (A Hawaiian Airlines figura novamente em 1º lugar em pontualidade. O Relatório de Classificação de Qualidade das Linhas Aéreas avalia as 14 maiores linhas aéreas dos EUA. A ExpressJet e a American Airlines tiveram a pior pontualidade. A Virgin America teve o melhor manuseio de bagagens; a Southwest teve a taxa de reclamações mais baixa.) | http://www.cnn.com/2013/04/08/travel/airline-quality-report\n",
        "European football's governing body reveals list of countries bidding to host 2020 finals. The 60th anniversary edition of the finals will be hosted by 13 <br> countries. Thirty-two countries are considering bids to host 2020 matches. UEFA will announce host cities on September 25. (A agência reguladora de futebol europeia revela a lista de países dando lances para sediar as finais de 2020. A edição de 60º aniversário das finais será realizada por 13 países. Trinta e dois países consideram dar lances para sediar as partidas de 2020. A UEFA anunciará as cidades-sede em 25 de setembro.) | http://edition.cnn.com:80/2013/09/20/sport/football/football-euro-2020-bid-countries/index.html?\n",
        "Once octopus-hunter Dylan Mayer has now also signed a petition of 5,000 divers banning their hunt at Seacrest Park. Decision by Washington <br> Department of Fish and Wildlife could take months. (O ex-caçador de polvos Dylan Mayer assinou uma petição de 5.000 mergulhadores banindo a caçada em Seacrest Park. A decisão do Departamento de Pesca e Vida Selvagem de Washington poderá demorar meses.) | http://www.dailymail.co.uk:80/news/article-2238423/Dylan-Mayer-Washington-considers-ban-Octopus-hunting-diver-caught-ate-Puget-Sound.html?\n",
        "Galaxy was observed 420 million years after the Big Bang. found by NASA’s Hubble Space Telescope, Spitzer Space Telescope, and one of nature’s <br> own natural 'zoom lenses' in space. (A galáxia foi observada 420 milhões de anos após o Big Bang. Foi encontrada pelo telescópio espacial Hubble da NASA, pelo telescópio espacial Spitzer e por uma das \"lentes de zoom\" naturais da natureza no espaço.) | http://www.dailymail.co.uk/sciencetech/article-2233883/The-furthest-object-seen-Record-breaking-image-shows-galaxy-13-3-BILLION-light-years-Earth.html\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcLF2PKkSbV3"
      },
      "source": [
        "## Configuração\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vvAObmTqglq"
      },
      "source": [
        "Comece instalando os pacotes obrigatórios, incluindo o pacote do Model Maker disponível no [repositório do GitHub](https://github.com/tensorflow/examples/tree/master/tensorflow_examples/lite/model_maker)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qhl8lqVamEty"
      },
      "outputs": [],
      "source": [
        "!sudo apt -y install libportaudio2\n",
        "!pip install -q tflite-model-maker\n",
        "!pip install gdown"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6lRhVK9Q_0U"
      },
      "source": [
        "Importe os pacotes necessários."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XtxiUeZEiXpt"
      },
      "outputs": [],
      "source": [
        "from tflite_model_maker import searcher"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "veelLw_VT6uQ"
      },
      "source": [
        "### Prepare o dataset\n",
        "\n",
        "Este tutorial usa o dataset de resumo CNN/DailyMail do [repositório do GitHub](https://github.com/abisee/cnn-dailymail).\n",
        "\n",
        "Primeiro baixe os textos e URLs da CNN e DailyMail e descompacte-os. Se houver falha ao baixar do Google Drive, aguarde alguns minutos para tentar novamente ou baixe-os manualmente e carregue-os no Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-P3zxue1T6Iy"
      },
      "outputs": [],
      "source": [
        "!gdown https://drive.google.com/uc?id=0BwmD_VLjROrfTHk4NFg2SndKcjQ\n",
        "!gdown https://drive.google.com/uc?id=0BwmD_VLjROrfM1BxdkxVaTY2bWs\n",
        "\n",
        "!wget -O all_train.txt https://raw.githubusercontent.com/abisee/cnn-dailymail/master/url_lists/all_train.txt\n",
        "!tar xzf cnn_stories.tgz\n",
        "!tar xzf dailymail_stories.tgz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aoOWzTU7ViPM"
      },
      "source": [
        "Em seguida, salve os dados no arquivo CSV, que pode ser carregado na biblioteca `tflite_model_maker`. O código baseia-se na lógica usada para carregar esses dados em [`tensorflow_datasets`](https://github.com/tensorflow/datasets/blob/master/tensorflow_datasets/summarization/cnn_dailymail.py). Não podemos usar `tensorflow_dataset` diretamente, já que ele não contém as URLs que são usadas neste Colab.\n",
        "\n",
        "Como demora um longo tempo para processar os dados em vetores de características de embedding para todo o dataset, somente os primeiros 5% das histórias do dataset CNN/DailyMail são selecionados por padrão para fins de demonstração. Você também pode ajustar a porcentagem ou usar o [modelo](https://storage.googleapis.com/download.tensorflow.org/models/tflite_support/searcher/text_to_image_blogpost/cnn_daily_text_searcher.tflite) pré-compilado do TF Lite com 50% das histórias do dataset CNN/DailyMail para fazer a pesquisa."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "bA4PsR6NVU69"
      },
      "outputs": [],
      "source": [
        "#@title Save the highlights and urls to the CSV file\n",
        "#@markdown Load the highlights from the stories of CNN / Daily Mail, map urls with highlights, and save them to the CSV file.\n",
        "\n",
        "CNN_FRACTION = 0.05 #@param {type:\"number\"}\n",
        "DAILYMAIL_FRACTION = 0.05 #@param {type:\"number\"}\n",
        "\n",
        "import csv\n",
        "import hashlib\n",
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "dm_single_close_quote = u\"\\u2019\"  # unicode\n",
        "dm_double_close_quote = u\"\\u201d\"\n",
        "END_TOKENS = [\n",
        "    \".\", \"!\", \"?\", \"...\", \"'\", \"`\", '\"', dm_single_close_quote,\n",
        "    dm_double_close_quote, \")\"\n",
        "]  # acceptable ways to end a sentence\n",
        "\n",
        "\n",
        "def read_file(file_path):\n",
        "  \"\"\"Reads lines in the file.\"\"\"\n",
        "  lines = []\n",
        "  with tf.io.gfile.GFile(file_path, \"r\") as f:\n",
        "    for line in f:\n",
        "      lines.append(line.strip())\n",
        "  return lines\n",
        "\n",
        "\n",
        "def url_hash(url):\n",
        "  \"\"\"Gets the hash value of the url.\"\"\"\n",
        "  h = hashlib.sha1()\n",
        "  url = url.encode(\"utf-8\")\n",
        "  h.update(url)\n",
        "  return h.hexdigest()\n",
        "\n",
        "\n",
        "def get_url_hashes_dict(urls_path):\n",
        "  \"\"\"Gets hashes dict that maps the hash value to the original url in file.\"\"\"\n",
        "  urls = read_file(urls_path)\n",
        "  return {url_hash(url): url[url.find(\"id_/\") + 4:] for url in urls}\n",
        "\n",
        "\n",
        "def find_files(folder, url_dict):\n",
        "  \"\"\"Finds files corresponding to the urls in the folder.\"\"\"\n",
        "  all_files = tf.io.gfile.listdir(folder)\n",
        "  ret_files = []\n",
        "  for file in all_files:\n",
        "    # Gets the file name without extension.\n",
        "    filename = os.path.splitext(os.path.basename(file))[0]\n",
        "    if filename in url_dict:\n",
        "      ret_files.append(os.path.join(folder, file))\n",
        "  return ret_files\n",
        "\n",
        "\n",
        "def fix_missing_period(line):\n",
        "  \"\"\"Adds a period to a line that is missing a period.\"\"\"\n",
        "  if \"@highlight\" in line:\n",
        "    return line\n",
        "  if not line:\n",
        "    return line\n",
        "  if line[-1] in END_TOKENS:\n",
        "    return line\n",
        "  return line + \".\"\n",
        "\n",
        "\n",
        "def get_highlights(story_file):\n",
        "  \"\"\"Gets highlights from a story file path.\"\"\"\n",
        "  lines = read_file(story_file)\n",
        "\n",
        "  # Put periods on the ends of lines that are missing them\n",
        "  # (this is a problem in the dataset because many image captions don't end in\n",
        "  # periods; consequently they end up in the body of the article as run-on\n",
        "  # sentences)\n",
        "  lines = [fix_missing_period(line) for line in lines]\n",
        "\n",
        "  # Separate out article and abstract sentences\n",
        "  highlight_list = []\n",
        "  next_is_highlight = False\n",
        "  for line in lines:\n",
        "    if not line:\n",
        "      continue  # empty line\n",
        "    elif line.startswith(\"@highlight\"):\n",
        "      next_is_highlight = True\n",
        "    elif next_is_highlight:\n",
        "      highlight_list.append(line)\n",
        "\n",
        "  # Make highlights into a single string.\n",
        "  highlights = \"\\n\".join(highlight_list)\n",
        "\n",
        "  return highlights\n",
        "\n",
        "url_hashes_dict = get_url_hashes_dict(\"all_train.txt\")\n",
        "cnn_files = find_files(\"cnn/stories\", url_hashes_dict)\n",
        "dailymail_files = find_files(\"dailymail/stories\", url_hashes_dict)\n",
        "\n",
        "# The size to be selected.\n",
        "cnn_size = int(CNN_FRACTION * len(cnn_files))\n",
        "dailymail_size = int(DAILYMAIL_FRACTION * len(dailymail_files))\n",
        "print(\"CNN size: %d\"%cnn_size)\n",
        "print(\"Daily Mail size: %d\"%dailymail_size)\n",
        "\n",
        "with open(\"cnn_dailymail.csv\", \"w\") as csvfile:\n",
        "  writer = csv.DictWriter(csvfile, fieldnames=[\"highlights\", \"urls\"])\n",
        "  writer.writeheader()\n",
        "\n",
        "  for file in cnn_files[:cnn_size] + dailymail_files[:dailymail_size]:\n",
        "    highlights = get_highlights(file)\n",
        "    # Gets the filename which is the hash value of the url.\n",
        "    filename = os.path.splitext(os.path.basename(file))[0]\n",
        "    url = url_hashes_dict[filename]\n",
        "    writer.writerow({\"highlights\": highlights, \"urls\": url})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xushUyZXqP59"
      },
      "source": [
        "## Compile o modelo de pesquisador de texto"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vn61LJ9QbOPi"
      },
      "source": [
        "Para criar um modelo de pesquisador de texto, carregue um dataset, crie um modelo com os dados e exporte o modelo do TF Lite.\n",
        "\n",
        "### Etapa 1 – Carregue o dataset\n",
        "\n",
        "O Model Maker recebe o dataset de texto e os metadados correspondentes de cada string de texto (como URLs, neste exemplo) no formato CSV. Ele incorpora as strings de texto aos vetores de características usando o modelo de incorporador especificado pelo usuário.\n",
        "\n",
        "Nesta demonstração, criamos o modelo de pesquisador usando o [Universal Sentence Encoder](https://tfhub.dev/google/universal-sentence-encoder-lite/2) (encoder de frases universal), um modelo moderno de embedding de frases que já foi retreinado no [Colab](https://github.com/tensorflow/tflite-support/blob/master/tensorflow_lite_support/examples/colab/on_device_text_to_image_search_tflite.ipynb). O modelo é otimizado para ter alto desempenho de inferência em dispositivos e demora somente 6 ms para incorporar uma string de consulta (essa medida foi feita no Pixel 6). Outra opção é usar [esta](https://tfhub.dev/google/lite-model/universal-sentence-encoder-qa-ondevice/1?lite-format=tflite) versão quantizada, que é menor, mas demora 38 ms para cada embedding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ymHbk0wjHHZ"
      },
      "outputs": [],
      "source": [
        "!wget -O universal_sentence_encoder.tflite https://storage.googleapis.com/download.tensorflow.org/models/tflite_support/searcher/text_to_image_blogpost/text_embedder.tflite"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knJwmJHxkFbx"
      },
      "source": [
        "Crie uma instância de `searcher.TextDataLoader` e use o método `data_loader.load_from_csv` para carregar o dataset. Esta etapa demora cerca de 10 minutos, pois é gerado o vetor de características de embedding para cada texto, um por um. Você também pode enviar seu próprio arquivo CSV e carregá-lo para compilar o modelo personalizado.\n",
        "\n",
        "Especifique o nome da coluna de texto e a coluna de metadados no arquivo CSV.\n",
        "\n",
        "- O texto é usado para gerar os vetores de características de embedding.\n",
        "- Os metadados são o contexto a ser exibido ao pesquisar um determinado texto.\n",
        "\n",
        "Veja as primeiras quatro linhas do arquivo CSV CNN-DailyMail gerado acima.\n",
        "\n",
        "Destaques | URLs\n",
        "--- | ---\n",
        "Syrian official: Obama climbed to the top of the tree, doesn't know how to get down. Obama sends a letter to the heads of the House and Senate. Obama <br> to seek congressional approval on military action against Syria. Aim is to determine whether CW were used, not by whom, says U.N. spokesman. (Representante da Síria: Obama subiu no topo da árvore e não sabe como descer. Obama envia uma carta aos presidentes da Câmara e do Senado. Obama busca aprovação do Congresso para ação militar contra a Síria. O objetivo é determinar se armas químicas foram usadas, não por quem, diz porta-voz da ONU.) | http://www.cnn.com/2013/08/31/world/meast/syria-civil-war/\n",
        "Usain Bolt wins third gold of world championship. Anchors Jamaica to 4x100m relay victory. Eighth gold at the championships for Bolt. Jamaica double <br> up in women's 4x100m relay. (Usain Bolt ganha o terceiro ouro no campeonato mundial. Leva a Jamaica à vitória do revezamento 4 x 100 metros. Oitavo ouro em campeonatos para Bolt. Dobradinha da Jamaica com vitória do revezamento 4 x 100 metros feminino.) | http://edition.cnn.com/2013/08/18/sport/athletics-bolt-jamaica-gold\n",
        "The employee in agency's Kansas City office is among hundreds of \"virtual\" workers. The employee's travel to and from the mainland U.S. last year cost <br> more than $24,000. The telecommuting program, like all GSA practices, is under review. (O funcionário no gabinete da agência em Kansas City está entre centenas de trabalhadores \"virtuais\". O deslocamento do funcionário para os EUA continentais e dos EUA continentais custou mais de US$ 24 mil no ano passado. O programa de teletrabalho, assim como todas as práticas da GSA, estão sob análise.) | http://www.cnn.com:80/2012/08/23/politics/gsa-hawaii-teleworking\n",
        "NEW: A Canadian doctor says she was part of a team examining Harry Burkhart in 2010. NEW: Diagnosis: \"autism, severe anxiety, post-traumatic stress <br> disorder and depression\" Burkhart is also suspected in a German arson probe, officials say. Prosecutors believe the German national set a string of fires <br> in Los Angeles. (NOVIDADE: Uma médica canadense disse que participou da equipe que examinou Harry Burkhart em 2010. NOVIDADE: Diagnóstico: \"autismo, ansiedade grave, transtorno de estresse pós-traumático e depressão\". Burkhart também é suspeito em uma investigação alemã de incêndio criminoso, segundo os oficiais. Promotores acreditam que o cidadão alemão causou diversos incêndios em Los Angeles.) | http://edition.cnn.com:80/2012/01/05/justice/california-arson/index.html?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CtdZ-JDwMimd"
      },
      "outputs": [],
      "source": [
        "data_loader = searcher.TextDataLoader.create(\"universal_sentence_encoder.tflite\", l2_normalize=True)\n",
        "data_loader.load_from_csv(\"cnn_dailymail.csv\", text_column=\"highlights\", metadata_column=\"urls\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVN5bkSFiZdV"
      },
      "source": [
        "Para casos de uso com imagens, você pode criar uma instância de `searcher.ImageDataLoader` e depois usar `data_loader.load_from_folder` para carregar imagens a partir da pasta. A instância de `searcher.ImageDataLoader` precisa ser criada por um modelo de incorporador do TF Lite, pois ele será usado para codificar consultas em vetores de características e será exportado com o modelo de pesquisador do TF Lite. Por exemplo:\n",
        "\n",
        "```python\n",
        "data_loader = searcher.ImageDataLoader.create(\"mobilenet_v2_035_96_embedder_with_metadata.tflite\")\n",
        "data_loader.load_from_folder(\"food/\")\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2uZkLR6N6gDR"
      },
      "source": [
        "Etapa 2 – Crie o modelo de pesquisador\n",
        "\n",
        "- Configure as opções do ScaNN. Confira mais detalhes na [documentação da API](https://www.tensorflow.org/lite/api_docs/python/tflite_model_maker/searcher/ScaNNOptions).\n",
        "- Crie o modelo de pesquisador a partir dos dados e opções do ScaNN. Confira a [análise detalhada](https://ai.googleblog.com/2020/07/announcing-scann-efficient-vector.html) para saber mais sobre o algoritmo do ScaNN."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kwlYdTcg63xy"
      },
      "outputs": [],
      "source": [
        "scann_options = searcher.ScaNNOptions(\n",
        "      distance_measure=\"dot_product\",\n",
        "      tree=searcher.Tree(num_leaves=140, num_leaves_to_search=4),\n",
        "      score_ah=searcher.ScoreAH(dimensions_per_block=1, anisotropic_quantization_threshold=0.2))\n",
        "model = searcher.Searcher.create_from_data(data_loader, scann_options)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lluAWms3soFm"
      },
      "source": [
        "No exemplo acima, definimos as seguintes opções:\n",
        "\n",
        "- `distance_measure`: usamos o produto escalar para mensurar a distância entre dois vetores de embedding. Observação: nós computamos o valor do produto escalar **negativo** para preservar a noção de que \"menor é mais próximo\".\n",
        "\n",
        "- `tree`: o dataset é dividido em 140 partições (aproximadamente, a raiz quadrada do tamanho dos dados), e 4 delas são pesquisadas durante a recuperação, o que corresponde a cerca de 3% do dataset.\n",
        "\n",
        "- `score_ah`: quantizamos os embeddings float em valores int8 com a mesma dimensão para economizar espaço."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CgCDMe0e6jlT"
      },
      "source": [
        "Etapa 3 – Exporte o modelo do TF Lite\n",
        "\n",
        "Em seguida, você pode exportar o modelo de pesquisador do TF Lite."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hm_UULdW7A9T"
      },
      "outputs": [],
      "source": [
        "model.export(\n",
        "      export_filename=\"searcher.tflite\",\n",
        "      userinfo=\"\",\n",
        "      export_format=searcher.ExportFormat.TFLITE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "me6_RwPZqNhX"
      },
      "source": [
        "## Teste o modelo do TF Lite com sua pesquisa\n",
        "\n",
        "Você pode testar o modelo do TF Lite exportado com um texto de consulta personalizado. Para consultar o texto usando o modelo de pesquisador, inicialize o modelo e execute uma pesquisa com a frase da seguinte forma:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GkXtipXKqXp4"
      },
      "outputs": [],
      "source": [
        "from tflite_support.task import text\n",
        "\n",
        "# Initializes a TextSearcher object.\n",
        "searcher = text.TextSearcher.create_from_file(\"searcher.tflite\")\n",
        "\n",
        "# Searches the input query.\n",
        "results = searcher.search(\"The Airline Quality Rankings Report looks at the 14 largest U.S. airlines.\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GzI0tPM2rFlc"
      },
      "source": [
        "Confira mais informações sobre como integrar o modelo a diversas plataformas na [documentação da Task Library](https://www.tensorflow.org/lite/inference_with_metadata/task_library/text_searcher)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HS4u77W5gnzQ"
      },
      "source": [
        "# Saiba mais\n",
        "\n",
        "Confira mais informações em:\n",
        "\n",
        "- [Guia](https://www.tensorflow.org/lite/models/modify/model_maker) e [referência da API](https://www.tensorflow.org/lite/api_docs/python/tflite_model_maker) do TensorFlow Lite Model Maker.\n",
        "\n",
        "- Task Library: [TextSearcher](https://www.tensorflow.org/lite/inference_with_metadata/task_library/text_searcher) para implantação.\n",
        "\n",
        "- Aplicativos de referência completos para [Android](https://github.com/tensorflow/examples/tree/master/lite/examples/text_searcher/android).\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "text_searcher.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
