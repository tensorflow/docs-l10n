{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2q27gKz1H20"
      },
      "source": [
        "##### Copyright 2019 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "TUfAcER1oUS6"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gb7qyhNL1yWt"
      },
      "source": [
        "# Classificação de texto com o TensorFlow Lite Model Maker"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fw5Y7snSuG51"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>     <a target=\"_blank\" href=\"https://www.tensorflow.org/lite/models/modify/model_maker/text_classification\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Veja em TensorFlow.org</a>   </td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/pt-br/lite/models/modify/model_maker/text_classification.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Executar no Google Colab</a>   </td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/pt-br/lite/models/modify/model_maker/text_classification.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver fonte em GitHub</a>   </td>\n",
        "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/pt-br/lite/models/modify/model_maker/text_classification.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Baixar notebook</a>\n",
        "</td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sr3q-gvm3cI8"
      },
      "source": [
        "A [biblioteca TensorFlow Lite Model Maker](https://www.tensorflow.org/lite/models/modify/model_maker) (criador de modelos do TF Lite) simplifica o processo de adaptar e converter um modelo do TensorFlow para dados de entrada específicos ao implantar esse modelo em aplicativos de aprendizado de máquina em dispositivos.\n",
        "\n",
        "Este notebook apresenta um exemplo completo que utiliza a biblioteca Model Maker para ilustrar a adaptação e conversão de um modelo de classificação de texto usado com frequência para classificar avaliações de filmes em um dispositivo móvel. O modelo classifica textos em categorias predefinidas. As entradas devem ser texto pré-processado, e as saídas são as probabilidades das categorias. O dataset usado neste tutorial é composto por avaliações de filmes positivas e negativas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcLF2PKkSbV3"
      },
      "source": [
        "## Pré-requisitos\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vvAObmTqglq"
      },
      "source": [
        "### Instale os pacotes obrigatórios\n",
        "\n",
        "Para executar este exemplo, instale os pacotes exigidos, incluindo o pacote do Model Maker no [repositório do GitHub](https://github.com/tensorflow/examples/tree/master/tensorflow_examples/lite/model_maker)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qhl8lqVamEty"
      },
      "outputs": [],
      "source": [
        "!sudo apt -y install libportaudio2\n",
        "!pip install -q tflite-model-maker\n",
        "!pip uninstall tflite_support_nightly\n",
        "!pip install tflite_support_nightly"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6lRhVK9Q_0U"
      },
      "source": [
        "Importe os pacotes necessários."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XtxiUeZEiXpt"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "\n",
        "from tflite_model_maker import model_spec\n",
        "from tflite_model_maker import text_classifier\n",
        "from tflite_model_maker.config import ExportFormat\n",
        "from tflite_model_maker.text_classifier import AverageWordVecSpec\n",
        "from tflite_model_maker.text_classifier import DataLoader\n",
        "\n",
        "from tflite_support.task import core\n",
        "from tflite_support.task import processor\n",
        "from tflite_support.task import text\n",
        "\n",
        "import tensorflow as tf\n",
        "assert tf.__version__.startswith('2')\n",
        "tf.get_logger().setLevel('ERROR')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRd13bfetO7B"
      },
      "source": [
        "### Baixe os dados de treinamento de amostra\n",
        "\n",
        "Neste tutorial, usaremos o [SST-2](https://nlp.stanford.edu/sentiment/index.html) (Stanford Sentiment Treebank), uma das tarefas no referencial [GLUE](https://gluebenchmark.com/). Ele contém 67.349 avaliações de filme para treinamento e 872 avaliações de filmes para teste. O dataset tem duas classes: avaliações de filmes positivas e negativas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R2BSkxWg6Rhx"
      },
      "outputs": [],
      "source": [
        "data_dir = tf.keras.utils.get_file(\n",
        "      fname='SST-2.zip',\n",
        "      origin='https://dl.fbaipublicfiles.com/glue/data/SST-2.zip',\n",
        "      extract=True)\n",
        "data_dir = os.path.join(os.path.dirname(data_dir), 'SST-2')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPYTbGrizcTC"
      },
      "source": [
        "O dataset SST-2 é armazenado no formato TSV. A única diferença entre TSV e CSV é que o TSV usa o caractere de tabulação `\\t` como delimitador em vez da vírgula `,` usada no formato CSV.\n",
        "\n",
        "Veja abaixo as 5 primeiras linhas do dataset de treinamento. label=0 significa negativo, e label=1 significa positivo.\n",
        "\n",
        "Frase | label |  |  |\n",
        "--- | --- | --- | --- | ---\n",
        "hide new secretions from the parental units (oculta novas secreções das unidades parentais) | 0 |  |  |\n",
        "contains no wit , only labored gags (não contém sabedoria, só piadas cansativas) | 0 |  |  |\n",
        "that loves its characters and communicates something rather beautiful about human nature (que ama seus personagens e comunica algo lindo sobre a natureza humana) | 1 |  |  |\n",
        "remains utterly satisfied to remain the same throughout (permanece totalmente satisfeito para permanecer igual o filme todo) | 0 |  |  |\n",
        "on the worst revenge-of-the-nerds clichés the filmmakers could dredge up (nos piores clichês de vingança dos nerds que os cineastas puderam criar) | 0 |  |  |\n",
        "\n",
        "Agora, vamos carregar o dataset em um dataframe do Pandas e alterar os nomes de rótulos atuais (`0` e `1`) para rótulos mais legíveis por humanos (`negative` – negativa e `positive` – positiva) e usá-los para o treinamento do modelo.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iLNaOXnl3JQB"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def replace_label(original_file, new_file):\n",
        "  # Load the original file to pandas. We need to specify the separator as\n",
        "  # '\\t' as the training data is stored in TSV format\n",
        "  df = pd.read_csv(original_file, sep='\\t')\n",
        "\n",
        "  # Define how we want to change the label name\n",
        "  label_map = {0: 'negative', 1: 'positive'}\n",
        "\n",
        "  # Excute the label change\n",
        "  df.replace({'label': label_map}, inplace=True)\n",
        "\n",
        "  # Write the updated dataset to a new file\n",
        "  df.to_csv(new_file)\n",
        "\n",
        "# Replace the label name for both the training and test dataset. Then write the\n",
        "# updated CSV dataset to the current folder.\n",
        "replace_label(os.path.join(os.path.join(data_dir, 'train.tsv')), 'train.csv')\n",
        "replace_label(os.path.join(os.path.join(data_dir, 'dev.tsv')), 'dev.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xushUyZXqP59"
      },
      "source": [
        "## Início rápido\n",
        "\n",
        "Existem cinco etapas para treinar um modelo de classificação de texto:\n",
        "\n",
        "**Etapa 1 – Escolha uma arquitetura de modelo de classificação de texto**\n",
        "\n",
        "Usaremos a arquitetura de modelo de média de embedding de palavra, que vai gerar um modelo pequeno e rápido, com uma exatidão razoável."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CtdZ-JDwMimd"
      },
      "outputs": [],
      "source": [
        "spec = model_spec.get('average_word_vec')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yug6gR9qyHui"
      },
      "source": [
        "O Model Maker também oferece suporte a outras arquiteturas de modelo, como [BERT](https://arxiv.org/abs/1810.04805). Se você tiver interesse em aprender outras arquiteturas, confira a seção [Escolha uma arquitetura de modelo para classificador de texto](#scrollTo=kJ_B8fMDOhMR) abaixo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5U-A3tw6Y27"
      },
      "source": [
        "**Etapa 2 – Carregue os dados de treinamento e teste, depois pré-processe-os de acordo com um `model_spec` específico.**\n",
        "\n",
        "O Model Maker recebe dados de entrada no formato CSV. Vamos carregar o dataset de treinamento e teste com o nome de rótulos legível por humanos que criamos anteriormente.\n",
        "\n",
        "Cada arquitetura de modelo requer que os dados de entrada sejam processados de uma forma específica. `DataLoader` lê os requisitos em `model_spec` e executa o pré-processamento necessário automaticamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HD5BvzWe6YKa"
      },
      "outputs": [],
      "source": [
        "train_data = DataLoader.from_csv(\n",
        "      filename='train.csv',\n",
        "      text_column='sentence',\n",
        "      label_column='label',\n",
        "      model_spec=spec,\n",
        "      is_training=True)\n",
        "test_data = DataLoader.from_csv(\n",
        "      filename='dev.csv',\n",
        "      text_column='sentence',\n",
        "      label_column='label',\n",
        "      model_spec=spec,\n",
        "      is_training=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2uZkLR6N6gDR"
      },
      "source": [
        "**Etapa 3 – Treine o modelo do TensorFlow com os dados de treinamento**\n",
        "\n",
        "O modelo de média de embedding de palavra usa `batch_size = 32` por padrão. Portanto, você verá que ele leva 2.104 passos para percorrer as 67.349 frases do dataset de treinamento. Vamos treinar o modelo com 10 épocas, ou seja, percorrer todo o dataset de treinamento 10 vezes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kwlYdTcg63xy"
      },
      "outputs": [],
      "source": [
        "model = text_classifier.create(train_data, model_spec=spec, epochs=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BzCHLWJ6h7q"
      },
      "source": [
        "**Etapa 4 – Avalie o modelo com os dados de teste**\n",
        "\n",
        "Após treinar o modelo de classificação de texto usando as frases do dataset de treinamento, usaremos as 872 frases restantes no dataset de teste para avaliar o desempenho do modelo com os novos dados que ele nunca viu.\n",
        "\n",
        "Como o tamanho padrão do lote é 32, vai demorar 28 passos para percorrer as 872 frases do dataset de teste."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8xmnl6Yy7ARn"
      },
      "outputs": [],
      "source": [
        "loss, acc = model.evaluate(test_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CgCDMe0e6jlT"
      },
      "source": [
        "**Etapa 5 – Exporte para um modelo do TensorFlow Lite**\n",
        "\n",
        "Vamos exportar o classificador de texto que treinamos para o formato do TensorFlow Lite. Especificaremos para qual pasta o modelo deverá ser exportado. Por padrão, o modelo float do TF Lite é exportado para a arquitetura de modelo de média de embedding de palavra."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hm_UULdW7A9T"
      },
      "outputs": [],
      "source": [
        "model.export(export_dir='average_word_vec')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVxaf3x_7OfB"
      },
      "source": [
        "Você pode baixar o arquivo do modelo do TensorFlow Lite pela barra lateral esquerda do Colab. Acesse a pasta `average_word_vec` que especificamos no parâmetro `export_dir` acima, clique com o botão direito no arquivo `model.tflite` e selecione `Download` (Baixar) para baixá-lo para seu computador local.\n",
        "\n",
        "Este modelo pode ser integrado a um aplicativo para Android ou iOS usando a [API NLClassifier](https://www.tensorflow.org/lite/inference_with_metadata/task_library/nl_classifier) da [biblioteca Task do TensorFlow Lite](https://www.tensorflow.org/lite/inference_with_metadata/task_library/overview).\n",
        "\n",
        "Confira mais detalhes de como o modelo é usado em um aplicativo funcional no [exemplo de aplicativo para classificação de texto do TF Lite](https://github.com/tensorflow/examples/blob/master/lite/examples/text_classification/android/lib_task_api/src/main/java/org/tensorflow/lite/examples/textclassification/client/TextClassificationClient.java#L54).\n",
        "\n",
        "*Observação: o Android Studio Model Binding ainda não oferece suporte à classificação de texto, então use a TensorFlow Lite Task Library.*\n",
        "\n",
        "*Observação 2: há um arquivo `model.json` na mesma pasta que do modelo do TF Lite. Ele contém a representação em JSON dos [metadados](https://www.tensorflow.org/lite/models/convert/metadata) empacotados dentro do modelo do TensorFlow Lite. Os metadados do modelo ajudam a TF Lite Task Library a saber o que o modelo faz e como pré/pós-processar os dados para o modelo. Você não precisa baixar o arquivo `model.json`, pois ele tem apenas fins informativos, e seu conteúdo já está dentro do arquivo do TF Lite.*\n",
        "\n",
        "*Observação 3: se você treinar um modelo de classificação de texto usando a arquitetura MobileBERT ou BERT-Base, precisará usar a [API BertNLClassifier](https://www.tensorflow.org/lite/inference_with_metadata/task_library/bert_nl_classifier) para integrar o modelo treinado a um aplicativo para dispositivos móveis.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l65ctmtW7_FF"
      },
      "source": [
        "As próximas seções explicam o exemplo passo a passo para mostrar mais detalhes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izO7NU7unYot"
      },
      "source": [
        "**Etapa 6 – Use a `TFLite Task Library` para demonstrar como utilizar os modelos treinados**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDov6P4wppHO"
      },
      "source": [
        "Leia o arquivo dev.csv nos dados de frase para fazer previsões com o modelo treinado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XWwvHmIltQC2"
      },
      "outputs": [],
      "source": [
        "sentence_data = pd.read_csv('/content/dev.csv', index_col=0)\n",
        "sentence_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_-bejm5vRBf"
      },
      "source": [
        "Parâmetro de configuração do modelo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IAEEs3_3vPz5"
      },
      "outputs": [],
      "source": [
        "# Name of the TFLite text classification model.\n",
        "_MODEL = '/content/average_word_vec/model.tflite'\n",
        "# Whether to run the model on EdgeTPU.\n",
        "_ENABLE_EDGETPU = False\n",
        "# Number of CPU threads to run the model.\n",
        "_NUM_THREADS = 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bInGjRcOtQbn"
      },
      "source": [
        "Inicialize o modelo\n",
        "\n",
        "Também podemos alterar parâmetros como `file_name`, `use_coral` e `num_threads`, o que pode afetar os resultados do modelo. Veja quais parâmetros podem ser ajustados.\n",
        "\n",
        "- `file_name`: nome do modelo de classificação de texto do TF Lite.\n",
        "- `use_coral`: se for true (verdadeiro), a inferência será delegada a um dispositivo Coral Edge TPU conectado.\n",
        "- `num_threads`: número de threads de CPU que executarão o modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Haham4qT8hmV"
      },
      "outputs": [],
      "source": [
        "# Initialize the text classification model.\n",
        "base_options = core.BaseOptions(file_name=_MODEL, use_coral=_ENABLE_EDGETPU, num_threads=_NUM_THREADS)\n",
        "options = text.NLClassifierOptions(base_options)\n",
        "\n",
        "# Create NLClassifier from options.\n",
        "classifier = text.NLClassifier.create_from_options(options)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HLl9LC9oA3G"
      },
      "source": [
        "Faça a previsão usando a `TF Lite Task Library`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pAQDHFs5tTxZ"
      },
      "outputs": [],
      "source": [
        "for idx in range(20):\n",
        "  sentence = sentence_data['sentence'].iloc[idx]\n",
        "  label = sentence_data['label'].iloc[idx]\n",
        "  text_classification_result = classifier.classify(sentence)\n",
        "  classification_list = text_classification_result.classifications[0].categories\n",
        "\n",
        "  # Sort output by probability descending.\n",
        "  predict_label = sorted(\n",
        "      classification_list, key=lambda item: item.score, reverse=True)[0]\n",
        "\n",
        "  print('truth_label: {} -----> predict_label: {}'.format(label, predict_label.category_name))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJ_B8fMDOhMR"
      },
      "source": [
        "## Escolha uma arquitetura de modelo para classificador de texto\n",
        "\n",
        "Cada objeto `model_spec` representa um modelo específico de classificador de texto.. Atualmente, o TensorFlow Lite Model Maker tem suporte a modelos [MobileBERT](https://arxiv.org/pdf/2004.02984.pdf), média de embedding de palavra e modelos [BERT-Base](https://arxiv.org/pdf/1810.04805.pdf).\n",
        "\n",
        "Modelo com suporte | Nome de model_spec | Descrição do modelo | Tamanho do modelo\n",
        "--- | --- | --- | ---\n",
        "Média de embedding de palavra | 'average_word_vec' | Média de embedding de palavra de texto com ativação RELU. | &lt; 1 MB\n",
        "<a>MobileBERT</a> | 'mobilebert_classifier' | 4,3 vezes menor e 5,5 vezes mais rápido do que o BERT-Base, alcançando resultados competitivos, adequados para aplicativos em dispositivos. | 25 MB com quantização <br> 100 MB sem quantização\n",
        "<a>BERT-Base</a> | 'bert_classifier' | Modelo BERT padrão amplamente usado em tarefas de NLP. | 300 MB\n",
        "\n",
        "No início rápido, usamos o modelo de média de embedding de palavras. Vamos alterar para [MobileBERT](https://arxiv.org/pdf/2004.02984.pdf) para treinar um modelo com exatidão maior."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vEAWuZQ1PFiX"
      },
      "outputs": [],
      "source": [
        "mb_spec = model_spec.get('mobilebert_classifier')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygEncJxtl-nQ"
      },
      "source": [
        "## Carregue os dados de treinamento\n",
        "\n",
        "Você pode carregar seu próprio dataset neste tutorial. Para carregá-lo, use a barra lateral esquerda no Colab.\n",
        "\n",
        "<img src=\"https://storage.googleapis.com/download.tensorflow.org/models/tflite/screenshots/model_maker_text_classification.png\" width=\"800\" hspace=\"100\" alt=\"Subir arquivo\">\n",
        "\n",
        "Se você preferir não carregar o dataset na nuvem, pode executar a biblioteca localmente de acordo com este [guia](https://github.com/tensorflow/examples/tree/master/tensorflow_examples/lite/model_maker)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWAusqz-WD5i"
      },
      "source": [
        "Para simplificar, vamos reutilizar o dataset SST-2 baixado anteriormente. Vamos usar o método `DataLoader.from_csv` para carregar os dados.\n",
        "\n",
        "Observação: como alteramos a arquitetura do modelo, vamos precisar recarregar o dataset de treinamento e de teste para aplicar a nova lógica de pré-processamento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I_fOlZsklmlL"
      },
      "outputs": [],
      "source": [
        "train_data = DataLoader.from_csv(\n",
        "      filename='train.csv',\n",
        "      text_column='sentence',\n",
        "      label_column='label',\n",
        "      model_spec=mb_spec,\n",
        "      is_training=True)\n",
        "test_data = DataLoader.from_csv(\n",
        "      filename='dev.csv',\n",
        "      text_column='sentence',\n",
        "      label_column='label',\n",
        "      model_spec=mb_spec,\n",
        "      is_training=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlHvVvv2hw4H"
      },
      "source": [
        "A biblioteca Model Maker também oferece suporte ao método `from_folder()` para carregar dados. Ele pressupõe que os dados de texto da mesma classe estejam no mesmo subdiretório e que o nome da subpasta seja o nome da classe. Cada arquivo de texto contém uma amostra de avaliação de filme. O parâmetro `class_labels` é usado para especificar quais são as subpastas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWuoensX4vDA"
      },
      "source": [
        "## Treine um modelo do TensorFlow\n",
        "\n",
        "Treine um modelo de classificação de texto usando os dados de treinamento.\n",
        "\n",
        "*Observação: como o MobileBERT é um modelo complexo, cada época de treinamento demora cerca de 10 minutos em uma GPU do Colab. Você deve usar um runtime de GPU.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TvYSUuJY3QxR"
      },
      "outputs": [],
      "source": [
        "model = text_classifier.create(train_data, model_spec=mb_spec, epochs=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JKI-pNc8idH"
      },
      "source": [
        "Confira a estrutura detalhada do modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gd7Hs8TF8n3H"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LP5FPk_tOxoZ"
      },
      "source": [
        "## Avaliar o modelo\n",
        "\n",
        "Avalie o modelo que acabamos de treinar usando os dados de teste e mensure os valores de perda e precisão."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A8c2ZQ0J3Riy"
      },
      "outputs": [],
      "source": [
        "loss, acc = model.evaluate(test_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esBGwHE2QxE8"
      },
      "source": [
        "## Exporte para um modelo do TensorFlow Lite\n",
        "\n",
        "Converta o modelo treinado para o formato de modelos do TensorFlow Lite com [metadados](https://www.tensorflow.org/lite/models/convert/metadata) para poder usá-lo posteriormente em um aplicativo de aprendizado de máquina em dispositivos. O arquivo de rótulos e o arquivo de vocabulário são incorporados aos metadados. O nome de arquivo padrão do TF Lite é `model.tflite`.\n",
        "\n",
        "Em diversos aplicativos de aprendizado de máquina em dispositivos, o tamanho do modelo é um fator importante. Portanto, recomendamos aplicar quantização no modelo para deixá-lo menor e possivelmente mais rápido. Para modelos BERT e MobileBERT, a técnica padrão de quantização pós-treinamento é a quantização de intervalo dinâmico."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Im6wA9lK3TQB"
      },
      "outputs": [],
      "source": [
        "model.export(export_dir='mobilebert/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w12kvDdHJIGH"
      },
      "source": [
        "O arquivo do modelo do TensorFlow Lite pode ser integrado a um aplicativo para dispositivos móveis usando a [API BertNLClassifier](https://www.tensorflow.org/lite/inference_with_metadata/task_library/bert_nl_classifier) na [TensorFlow Lite Task Library](https://www.tensorflow.org/lite/inference_with_metadata/task_library/overview). Observação: isso é **diferente** da API `NLClassifier` usada para integrar um classificador de texto treinado com a arquitetura de modelo de média do vetor de palavras."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVy0ormoMZwL"
      },
      "source": [
        "Confira abaixo os formatos de exportação permitidos:\n",
        "\n",
        "- `ExportFormat.TFLITE`\n",
        "- `ExportFormat.LABEL`\n",
        "- `ExportFormat.VOCAB`\n",
        "- `ExportFormat.SAVED_MODEL`\n",
        "\n",
        "Por padrão, ele exporta somente o modelo do TensorFlow Lite contendo os metadados do modelo. Você também pode optar por exportar outros arquivos relacionados ao modelo para avaliá-los melhor. Por exemplo, é possível exportar somente o arquivo de rótulos e o arquivo de vocabulário da seguinte forma:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nbK7nzK_Mfx4"
      },
      "outputs": [],
      "source": [
        "model.export(export_dir='mobilebert/', export_format=[ExportFormat.LABEL, ExportFormat.VOCAB])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZKYthlVrTos"
      },
      "source": [
        "Você pode avaliar o modelo do TF Lite com o método `evaluate_tflite` para mensurar a exatidão. Ao converter o modelo do TensorFlow treinado para o formato do TF Lite e aplicar quantização, a exatidão pode ser afetada, então é recomendável avaliar a exatidão do modelo do TF Lite antes da implantação."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ochbq95ZrVFX"
      },
      "outputs": [],
      "source": [
        "accuracy = model.evaluate_tflite('mobilebert/model.tflite', test_data)\n",
        "print('TFLite model accuracy: ', accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EoWiA_zX8rxE"
      },
      "source": [
        "## Uso avançado\n",
        "\n",
        "A função `create` é a função que a biblioteca Model Maker usa para criar modelos. O parâmetro `model_spec` define a especificação do modelo. No momento, há suporte às classes `AverageWordVecSpec` e `BertClassifierSpec`. A função `create` consiste nas seguintes etapas:\n",
        "\n",
        "1. Cria o modelo de classificação de texto de acordo com `model_spec`.\n",
        "2. Treina o modelo de classificador. As épocas padrão e o tamanho de lote padrão são definidos pelas duas variáveis `default_training_epochs` e `default_batch_size` no objeto `model_spec`.\n",
        "\n",
        "Esta seção abrange tópicos de uso avançado, como ajustar o modelo e os hiperparâmetros de treinamento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8VxPiOLy4Gv"
      },
      "source": [
        "### Personalize os hiperparâmetros do modelo MobileBERT\n",
        "\n",
        "Os parâmetros do modelo que podem ser ajustados são:\n",
        "\n",
        "- `seq_len`: tamanho da sequência a ser alimentada no modelo.\n",
        "- `initializer_range`: desvio padrão do `truncated_normal_initializer` para inicializar as matrizes de pesos.\n",
        "- `trainable`: booleano que especifica se a camada pré-treinada é treinável.\n",
        "\n",
        "Os parâmetros do pipeline de treinamento que podem ser ajustados são:\n",
        "\n",
        "- `model_dir`: local dos arquivos de checkpoint do modelo. Caso não seja definido, será usado um diretório temporário.\n",
        "- `dropout_rate`: taxa de dropout.\n",
        "- `learning_rate`: taxa de aprendizado inicial para o otimizador Adam.\n",
        "- `tpu`: endereço da TPU à qual se conectar.\n",
        "\n",
        "Por exemplo: você pode definir `seq_len=256` (o padrão é 128), o que permite ao modelo classificar textos maiores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4tr9BLcjy4Sh"
      },
      "outputs": [],
      "source": [
        "new_model_spec = model_spec.get('mobilebert_classifier')\n",
        "new_model_spec.seq_len = 256"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwtiksguDfhl"
      },
      "source": [
        "### Personalize os hiperparâmetros do modelo de média de embedding de palavra\n",
        "\n",
        "Você pode ajustar a infraestrutura do modelo, como as variáveis `wordvec_dim` e `seq_len` na classe  `AverageWordVecSpec`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cAOd5_bzH9AQ"
      },
      "source": [
        "Por exemplo: você pode treinar o modelo com um valor maior de `wordvec_dim`. Observação: você precisa construir um novo `model_spec` se modificar o modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e9WBN0UTQoMN"
      },
      "outputs": [],
      "source": [
        "new_model_spec = AverageWordVecSpec(wordvec_dim=32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LSTdghTP0Cv"
      },
      "source": [
        "Obtenha os dados pré-processados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DVZurFBORG3J"
      },
      "outputs": [],
      "source": [
        "new_train_data = DataLoader.from_csv(\n",
        "      filename='train.csv',\n",
        "      text_column='sentence',\n",
        "      label_column='label',\n",
        "      model_spec=new_model_spec,\n",
        "      is_training=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tD7QVVHeRZoM"
      },
      "source": [
        "Treine o novo modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PzpV246_JGEu"
      },
      "outputs": [],
      "source": [
        "model = text_classifier.create(new_train_data, model_spec=new_model_spec)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvQuy7RSDir3"
      },
      "source": [
        "### Ajuste os hiperparâmetros de treinamento\n",
        "\n",
        "Você também pode ajustar os hiperparâmetros de treinamento, como `epochs` e `batch_size`, o que impacta a exatidão do modelo. Por exemplo:\n",
        "\n",
        "- `epochs`: mais épocas podem levar a uma exatidão melhor, mas podem causar overfitting.\n",
        "- `batch_size`: número de amostras a serem usadas em um passo de treinamento.\n",
        "\n",
        "Por exemplo: você pode treinar com mais épocas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rnWFaYZBG6NW"
      },
      "outputs": [],
      "source": [
        "model = text_classifier.create(new_train_data, model_spec=new_model_spec, epochs=20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUaKQZBQHBQR"
      },
      "source": [
        "Avalie o modelo retreinado recentemente com 20 épocas de treinamento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BMPi1xflHDSY"
      },
      "outputs": [],
      "source": [
        "new_test_data = DataLoader.from_csv(\n",
        "      filename='dev.csv',\n",
        "      text_column='sentence',\n",
        "      label_column='label',\n",
        "      model_spec=new_model_spec,\n",
        "      is_training=False)\n",
        "\n",
        "loss, accuracy = model.evaluate(new_test_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eq6B9lKMfhS6"
      },
      "source": [
        "### Altere a arquitetura do modelo\n",
        "\n",
        "É possível alterar o modelo mudando `model_spec`. O exemplo abaixo mostra como alterar para o modelo BERT-Base.\n",
        "\n",
        "Altere `model_spec` para o modelo BERT-Base para o classificador de texto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QfFCWrwyggrT"
      },
      "outputs": [],
      "source": [
        "spec = model_spec.get('bert_classifier')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2d7yycrgu6L"
      },
      "source": [
        "As outras etapas são as mesmas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgiD_tkyQn7l"
      },
      "source": [
        "### Personalize a quantização pós-treinamento em um modelo do TensorFlow Lite\n",
        "\n",
        "A [quantização pós-treinamento](https://www.tensorflow.org/lite/performance/post_training_quantization) é uma técnica de conversão que pode reduzir o tamanho do modelo e a latência de inferência, além de aumentar a velocidade de inferência da CPU e do acelerador de hardware com uma pequena redução da exatidão do modelo. A quantização é amplamente utilizada para otimizar o modelo.\n",
        "\n",
        "A biblioteca Model Maker aplica uma técnica padrão de quantização pós-treinamento ao exportar o modelo. Se você quiser personalizar a quantização pós-treinamento, o Model Maker oferece suporte a diversas opções usando [QuantizationConfig](https://www.tensorflow.org/lite/api_docs/python/tflite_model_maker/config/QuantizationConfig). Vejamos a quantização de float 16 como exemplo. Primeiro, definimos a configuração de quantização.\n",
        "\n",
        "```python\n",
        "config = QuantizationConfig.for_float16()\n",
        "```\n",
        "\n",
        "Em seguida, exportamos o modelo do TensorFlow Lite com essa configuração.\n",
        "\n",
        "```python\n",
        "model.export(export_dir='.', tflite_filename='model_fp16.tflite', quantization_config=config)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkJGvMEx6VD-"
      },
      "source": [
        "# Saiba mais\n",
        "\n",
        "Leia o exemplo de [classificação de texto](https://www.tensorflow.org/lite/examples/text_classification/overview) para aprender os detalhes técnicos. Confira mais informações em:\n",
        "\n",
        "- [Guia](https://www.tensorflow.org/lite/models/modify/model_maker) e [referência da API](https://www.tensorflow.org/lite/api_docs/python/tflite_model_maker) do TensorFlow Lite Model Maker.\n",
        "- Task Library: [NLClassifier](https://www.tensorflow.org/lite/inference_with_metadata/task_library/nl_classifier) e [BertNLClassifier](https://www.tensorflow.org/lite/inference_with_metadata/task_library/bert_nl_classifier) para implantação.\n",
        "- Aplicativos de referência completos para [Android](https://github.com/tensorflow/examples/tree/master/lite/examples/text_classification/android) e [iOS](https://github.com/tensorflow/examples/tree/master/lite/examples/text_classification/ios)."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "text_classification.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
