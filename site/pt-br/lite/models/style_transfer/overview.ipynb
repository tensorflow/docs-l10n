{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_nWetWWd_ns"
      },
      "source": [
        "##### Copyright 2019 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "2pHVBk_seED1"
      },
      "outputs": [

      ],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7vSdG6sAIQn"
      },
      "source": [
        "# Transferência de estilo artístico com o TensorFlow Lite"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwc5GKHBASdc"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>     <a target=\"_blank\" href=\"https://www.tensorflow.org/lite/examples/style_transfer/overview\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver em TensorFlow.org</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/examples/style_transfer/overview.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Executar no Google Colab</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/examples/style_transfer/overview.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver fonte no GitHub</a>\n",
        "</td>\n",
        "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/tensorflow/tensorflow/lite/g3doc/examples/style_transfer/overview.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Baixar notebook</a>\n",
        "</td>\n",
        "  <td>     <a href=\"https://tfhub.dev/google/magenta/arbitrary-image-stylization-v1-256/2\"><img src=\"https://www.tensorflow.org/images/hub_logo_32px.png\">Ver modelo do TF Hub</a>\n",
        "</td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31O0iaROAw8z"
      },
      "source": [
        "Um dos desenvolvimentos mais animadores no aprendizado profundo que ocorreu recentemente foi a [transferência de estilo artístico](https://arxiv.org/abs/1508.06576), ou seja, a capacidade de criar uma nova imagem, conhecida como [pastiche](https://en.wikipedia.org/wiki/Pastiche), baseada em duas imagens de entrada: uma que representa o estilo artístico e outra que representa o conteúdo.\n",
        "\n",
        "![Style transfer example](https://storage.googleapis.com/download.tensorflow.org/models/tflite/arbitrary_style_transfer/formula.png)\n",
        "\n",
        "Usando essa técnica, podemos gerar novas obras de artes lindas em diversos estilos.\n",
        "\n",
        "![Style transfer example](https://storage.googleapis.com/download.tensorflow.org/models/tflite/arbitrary_style_transfer/table.png)\n",
        "\n",
        "Se você estiver apenas começando a usar o TensorFlow Lite e estiver trabalhando com Android, recomendamos conferir os exemplos de aplicativo abaixo que podem te ajudar a começar.\n",
        "\n",
        "<a class=\"button button-primary\" href=\"https://github.com/tensorflow/examples/tree/master/lite/examples/style_transfer/android\">Exemplo do Android</a> <a class=\"button button-primary\" href=\"https://github.com/tensorflow/examples/tree/master/lite/examples/style_transfer/ios\">Exemplo do iOS</a>\n",
        "\n",
        "Se você estiver usando outra plataforma que não o Android ou iOS ou se já conhecer bem as <a href=\"https://www.tensorflow.org/api_docs/python/tf/lite\">APIs do TensorFlow Lite</a>, pode acompanhar este tutorial para aprender como aplicar a transferência de estilo a qualquer par de imagem de conteúdo/imagem de estilo com um modelo pré-treinado do TensorFlow. Você pode usar o modelo para adicionar transferência aos seus próprios aplicativos móveis.\n",
        "\n",
        "O código do modelo está aberto no [GitHub](https://github.com/tensorflow/magenta/tree/master/magenta/models/arbitrary_image_stylization#train-a-model-on-a-large-dataset-with-data-augmentation-to-run-on-mobile). Você pode treinar novamente o modelo com parâmetros diferentes (por exemplo, aumentar os pesos das camadas de conteúdo para deixar a imagem de saída mais parecida com a imagem do conteúdo)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ak0S4gkOCSxs"
      },
      "source": [
        "## Compreendendo a arquitetura do modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oee6G_bBCgAM"
      },
      "source": [
        "![Model Architecture](https://storage.googleapis.com/download.tensorflow.org/models/tflite/arbitrary_style_transfer/architecture.png)\n",
        "\n",
        "O modelo de transferência de estilo artístico é composto por dois submodelos:\n",
        "\n",
        "1. **Modelo de previsão de estilo**: rede neural baseada no MobilenetV2 que recebe uma imagem de estilo como entrada em um vetor de gargalo de estilo com 100 dimensões.\n",
        "2. **Modelo de transformação de estilo**: rede neural que recebe e aplica um vetor de gargalo de estilo a uma imagem de conteúdo e cria uma imagem estilizada.\n",
        "\n",
        "Caso o seu aplicativo precise oferecer somente um conjunto fixo de imagens de estilo, você pode computar os vetores de gargalo de estilo antecipadamente e excluir o modelo de previsão de estilo do binário do aplicativo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7ZETsRVNMo7"
      },
      "source": [
        "## Configuração"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3n8oObKZN4c8"
      },
      "source": [
        "Importe as dependências:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xz62Lb1oNm97"
      },
      "outputs": [

      ],
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Ua5FpcJNrIj"
      },
      "outputs": [

      ],
      "source": [
        "import IPython.display as display\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "mpl.rcParams['figure.figsize'] = (12,12)\n",
        "mpl.rcParams['axes.grid'] = False\n",
        "\n",
        "import numpy as np\n",
        "import time\n",
        "import functools"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1b988wrrQnVF"
      },
      "source": [
        "Baixe as imagens de conteúdo, de estilo e os modelos pré-treinados do TensorFlow Lite."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "16g57cIMQnen"
      },
      "outputs": [

      ],
      "source": [
        "content_path = tf.keras.utils.get_file('belfry.jpg','https://storage.googleapis.com/khanhlvg-public.appspot.com/arbitrary-style-transfer/belfry-2611573_1280.jpg')\n",
        "style_path = tf.keras.utils.get_file('style23.jpg','https://storage.googleapis.com/khanhlvg-public.appspot.com/arbitrary-style-transfer/style23.jpg')\n",
        "\n",
        "style_predict_path = tf.keras.utils.get_file('style_predict.tflite', 'https://tfhub.dev/google/lite-model/magenta/arbitrary-image-stylization-v1-256/int8/prediction/1?lite-format=tflite')\n",
        "style_transform_path = tf.keras.utils.get_file('style_transform.tflite', 'https://tfhub.dev/google/lite-model/magenta/arbitrary-image-stylization-v1-256/int8/transfer/1?lite-format=tflite')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQZXL7kON-gM"
      },
      "source": [
        "## Pré-processe as entradas\n",
        "\n",
        "- A imagem de conteúdo e a imagem de estilo devem ser imagens RGB com valores de pixels como números float32 entre [0-1].\n",
        "- O tamanho da imagem de estilo deve ser (1, 256, 256, 3). Fazemos o recorte central da imagem e a redimensionamos.\n",
        "- A imagem de conteúdo deve ser (1, 384, 384, 3). Fazemos o recorte central da imagem e a redimensionamos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cg0Vi-rXRUFl"
      },
      "outputs": [

      ],
      "source": [
        "# Function to load an image from a file, and add a batch dimension.\n",
        "def load_img(path_to_img):\n",
        "  img = tf.io.read_file(path_to_img)\n",
        "  img = tf.io.decode_image(img, channels=3)\n",
        "  img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "  img = img[tf.newaxis, :]\n",
        "\n",
        "  return img\n",
        "\n",
        "# Function to pre-process by resizing an central cropping it.\n",
        "def preprocess_image(image, target_dim):\n",
        "  # Resize the image so that the shorter dimension becomes 256px.\n",
        "  shape = tf.cast(tf.shape(image)[1:-1], tf.float32)\n",
        "  short_dim = min(shape)\n",
        "  scale = target_dim / short_dim\n",
        "  new_shape = tf.cast(shape * scale, tf.int32)\n",
        "  image = tf.image.resize(image, new_shape)\n",
        "\n",
        "  # Central crop the image.\n",
        "  image = tf.image.resize_with_crop_or_pad(image, target_dim, target_dim)\n",
        "\n",
        "  return image\n",
        "\n",
        "# Load the input images.\n",
        "content_image = load_img(content_path)\n",
        "style_image = load_img(style_path)\n",
        "\n",
        "# Preprocess the input images.\n",
        "preprocessed_content_image = preprocess_image(content_image, 384)\n",
        "preprocessed_style_image = preprocess_image(style_image, 256)\n",
        "\n",
        "print('Style Image Shape:', preprocessed_style_image.shape)\n",
        "print('Content Image Shape:', preprocessed_content_image.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xE4Yt8nArTeR"
      },
      "source": [
        "## Visualize as entradas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ncPA4esJRcEu"
      },
      "outputs": [

      ],
      "source": [
        "def imshow(image, title=None):\n",
        "  if len(image.shape) > 3:\n",
        "    image = tf.squeeze(image, axis=0)\n",
        "\n",
        "  plt.imshow(image)\n",
        "  if title:\n",
        "    plt.title(title)\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "imshow(preprocessed_content_image, 'Content Image')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "imshow(preprocessed_style_image, 'Style Image')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJ7R-CHbjC3s"
      },
      "source": [
        "## Execute a transferência de estilo com o TensorFlow Lite"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euu00ldHjKwD"
      },
      "source": [
        "### Previsão do estilo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o3zd9cTFRiS_"
      },
      "outputs": [

      ],
      "source": [
        "# Function to run style prediction on preprocessed style image.\n",
        "def run_style_predict(preprocessed_style_image):\n",
        "  # Load the model.\n",
        "  interpreter = tf.lite.Interpreter(model_path=style_predict_path)\n",
        "\n",
        "  # Set model input.\n",
        "  interpreter.allocate_tensors()\n",
        "  input_details = interpreter.get_input_details()\n",
        "  interpreter.set_tensor(input_details[0][\"index\"], preprocessed_style_image)\n",
        "\n",
        "  # Calculate style bottleneck.\n",
        "  interpreter.invoke()\n",
        "  style_bottleneck = interpreter.tensor(\n",
        "      interpreter.get_output_details()[0][\"index\"]\n",
        "      )()\n",
        "\n",
        "  return style_bottleneck\n",
        "\n",
        "# Calculate style bottleneck for the preprocessed style image.\n",
        "style_bottleneck = run_style_predict(preprocessed_style_image)\n",
        "print('Style Bottleneck Shape:', style_bottleneck.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00t8S2PekIyW"
      },
      "source": [
        "### Transformação do estilo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cZp5bCj8SX1w"
      },
      "outputs": [

      ],
      "source": [
        "# Run style transform on preprocessed style image\n",
        "def run_style_transform(style_bottleneck, preprocessed_content_image):\n",
        "  # Load the model.\n",
        "  interpreter = tf.lite.Interpreter(model_path=style_transform_path)\n",
        "\n",
        "  # Set model input.\n",
        "  input_details = interpreter.get_input_details()\n",
        "  interpreter.allocate_tensors()\n",
        "\n",
        "  # Set model inputs.\n",
        "  interpreter.set_tensor(input_details[0][\"index\"], preprocessed_content_image)\n",
        "  interpreter.set_tensor(input_details[1][\"index\"], style_bottleneck)\n",
        "  interpreter.invoke()\n",
        "\n",
        "  # Transform content image.\n",
        "  stylized_image = interpreter.tensor(\n",
        "      interpreter.get_output_details()[0][\"index\"]\n",
        "      )()\n",
        "\n",
        "  return stylized_image\n",
        "\n",
        "# Stylize the content image using the style bottleneck.\n",
        "stylized_image = run_style_transform(style_bottleneck, preprocessed_content_image)\n",
        "\n",
        "# Visualize the output.\n",
        "imshow(stylized_image, 'Stylized Image')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vv_71Td-QtrW"
      },
      "source": [
        "### Mesclagem do estilo\n",
        "\n",
        "Podemos mesclar o estilo da imagem de conteúdo à saída estilizada, o que deixa a saída mais parecida com a imagem de conteúdo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eJcAURXQQtJ7"
      },
      "outputs": [

      ],
      "source": [
        "# Calculate style bottleneck of the content image.\n",
        "style_bottleneck_content = run_style_predict(\n",
        "    preprocess_image(content_image, 256)\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4S3yg2MgkmRD"
      },
      "outputs": [

      ],
      "source": [
        "# Define content blending ratio between [0..1].\n",
        "# 0.0: 0% style extracts from content image.\n",
        "# 1.0: 100% style extracted from content image.\n",
        "content_blending_ratio = 0.5 #@param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "\n",
        "# Blend the style bottleneck of style image and content image\n",
        "style_bottleneck_blended = content_blending_ratio * style_bottleneck_content \\\n",
        "                           + (1 - content_blending_ratio) * style_bottleneck\n",
        "\n",
        "# Stylize the content image using the style bottleneck.\n",
        "stylized_image_blended = run_style_transform(style_bottleneck_blended,\n",
        "                                             preprocessed_content_image)\n",
        "\n",
        "# Visualize the output.\n",
        "imshow(stylized_image_blended, 'Blended Stylized Image')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9k9jGIep8p1c"
      },
      "source": [
        "## Referenciais de desempenho\n",
        "\n",
        "Os referenciais de desempenho são gerados com a ferramenta [descrita aqui](https://www.tensorflow.org/lite/performance/benchmarks).\n",
        "\n",
        "<table>\n",
        "<thead>\n",
        "<tr>\n",
        "<th>Nome do modelo</th> <th>Tamanho do modelo</th>  <th>Dispositivo</th> <th>NNAPI</th> <th>CPU</th> <th>GPU</th>\n",
        "</tr> </thead>\n",
        "<tr> <td rowspan=\"3\"> <a href=\"https://tfhub.dev/google/lite-model/magenta/arbitrary-image-stylization-v1-256/int8/prediction/1?lite-format=tflite\">Modelo de previsão de estilo (int8)</a>\n",
        "</td>\n",
        "<td rowspan=\"3\">2,8 MB</td>\n",
        "<td>Pixel 3 (Android 10)</td> <td>142 ms</td>\n",
        "<td>14 ms*</td>\n",
        "<td></td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>Pixel 4 (Android 10)</td> <td>5,2 ms</td>\n",
        "<td>6,7 ms*</td>\n",
        "<td></td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>iPhone XS (iOS 12.4.1)</td> <td></td>\n",
        "<td>10,7 ms**</td>\n",
        "<td></td>\n",
        "</tr>\n",
        "<tr> <td rowspan=\"3\"> <a href=\"https://tfhub.dev/google/lite-model/magenta/arbitrary-image-stylization-v1-256/int8/transfer/1?lite-format=tflite\">Modelo de transformação de estilo (int8)</a>\n",
        "</td>\n",
        "<td rowspan=\"3\">0,2 MB</td>\n",
        "<td>Pixel 3 (Android 10)</td> <td></td>\n",
        "<td>540 ms*</td>\n",
        "<td></td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>Pixel 4 (Android 10)</td> <td></td>\n",
        "<td>405 ms*</td>\n",
        "<td></td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>iPhone XS (iOS 12.4.1)</td> <td></td>\n",
        "<td>251 ms**</td>\n",
        "<td></td>\n",
        "</tr>\n",
        "<tr> <td rowspan=\"2\"> <a href=\"https://tfhub.dev/google/lite-model/magenta/arbitrary-image-stylization-v1-256/fp16/prediction/1?lite-format=tflite\">Modelo de previsão de estilo (float16)</a>\n",
        "</td>\n",
        "<td rowspan=\"2\">4,7 MB</td>\n",
        "<td>Pixel 3 (Android 10)</td> <td>86 ms</td>\n",
        "<td>28 ms*</td>\n",
        "<td>9,1 ms</td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>Pixel 4 (Android 10)</td>\n",
        "<td>32 ms</td>\n",
        "<td>12 ms*</td>\n",
        "<td>10 ms</td>\n",
        "</tr>\n",
        "<tr> <td rowspan=\"2\"> <a href=\"https://tfhub.dev/google/lite-model/magenta/arbitrary-image-stylization-v1-256/fp16/transfer/1?lite-format=tflite\">Modelo de transferência de estilo (float16)</a>\n",
        "</td>\n",
        "<td rowspan=\"2\">0,4 MB</td>\n",
        "<td>Pixel 3 (Android 10)</td> <td>1.095 ms</td>\n",
        "<td>545 ms*</td>\n",
        "<td>42 ms</td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>Pixel 4 (Android 10)</td>\n",
        "<td>603 ms</td>\n",
        "<td>377 ms*</td>\n",
        "<td>42 ms</td>\n",
        "</tr>\n",
        "</table>\n",
        "\n",
        "** 4 threads usados. <br>*\n",
        "*** 2 threads usados no iPhone para o melhor desempenho.*\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [

      ],
      "name": "overview.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
