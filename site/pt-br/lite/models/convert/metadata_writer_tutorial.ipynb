{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mq-riZs-TJGt"
      },
      "source": [
        "##### Copyright 2021 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "LEvnopDoTC4M"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSRG6qmtTRSk"
      },
      "source": [
        "# API TensorFlow Lite Metadata Writer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlzjEt4Txr0x"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>     <a target=\"_blank\" href=\"https://www.tensorflow.org/lite/models/convert/metadata_writer_tutorial\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver em TensorFlow.org</a> </td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/pt-br/lite/models/convert/metadata_writer_tutorial.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Executar no Google Colab</a> </td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/pt-br/lite/models/convert/metadata_writer_tutorial.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver fonte no GitHub</a> </td>\n",
        "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/pt-br/lite/models/convert/metadata_writer_tutorial.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Baixar notebook</a> </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0gwEhfRYat6"
      },
      "source": [
        "Os [metadados de modelos do TensorFlow Lite](https://www.tensorflow.org/lite/models/convert/metadata) são um formato padrão de descrição de modelos. Eles contêm uma semântica rica para informações gerais do modelo, entradas/saídas e arquivos associados, o que deixa o modelo mais autodescritivo e intercambiável.\n",
        "\n",
        "Atualmente, os metadados de modelos são usados nestes dois casos de uso principais:\n",
        "\n",
        "1. **Permitir fácil inferência do modelo usando a [biblioteca Task](https://www.tensorflow.org/lite/inference_with_metadata/task_library/overview) do TensorFlow Lite e as [ferramentas de geração de código](https://www.tensorflow.org/lite/inference_with_metadata/codegen)**. Os metadados do modelo contêm as informações obrigatórias exigidas durante a inferência, como os arquivos de rótulos em classificação de imagens, a taxa de amostragem de entrada de áudio em classificação de áudio e o tipo de tokenizador para processar a string de entrada em modelos de linguagem natural.\n",
        "\n",
        "2. **Permitir que os criadores de modelos incluam documentações**, como a descrição das entradas/saídas do modelo ou como usar o modelo. Os usuários podem ver essas documentações usando ferramentas de visualização, como o [Netron](https://netron.app/).\n",
        "\n",
        "A API de gravação de metadados do TensorFlow Lite conta com uma API fácil de usar para criar metadados de modelos para tarefas populares de aprendizado de máquina compatíveis com a biblioteca Task do TF Lite. Este notebook mostra exemplos de como os metadados devem ser preenchidos para as seguintes tarefas:\n",
        "\n",
        "- [Classificadores de imagem](#image_classifiers)\n",
        "- [Detectores de objeto](#object_detectors)\n",
        "- [Segmentadores de imagem](#image_segmenters)\n",
        "- [Classificadores de linguagem natural](#nl_classifiers)\n",
        "- [Classificadores de áudio](#audio_classifiers)\n",
        "\n",
        "Os gravadores de metadados para classificadores de linguagem natural BERT e para modelos de resposta a perguntas BERT serão disponibilizados em breve.\n",
        "\n",
        "Se você quiser adicionar metadados para casos de uso ainda não disponíveis, use a [API Flatbuffers do Python](https://www.tensorflow.org/lite/models/convert/metadata#adding_metadata). Confira os tutoriais [aqui](https://www.tensorflow.org/lite/models/convert/metadata#adding_metadata).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVRIGdA4T6tO"
      },
      "source": [
        "## Pré-requisitos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVTD2KSyotBK"
      },
      "source": [
        "Instale o pacote Pypi do TensorFlow Lite Support."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m-8xSrSvUg-6"
      },
      "outputs": [],
      "source": [
        "!pip install tflite-support-nightly"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyYS87Odpxef"
      },
      "source": [
        "## Crie metadados do modelo para a biblioteca Task e o gerador de código"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLxv541TqTim"
      },
      "source": [
        "<a name=\"image_classifiers\"></a>\n",
        "\n",
        "### Classificadores de imagem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s41TjCGlsyEF"
      },
      "source": [
        "Confira mais detalhes sobre o formato de modelo permitido nos [requisitos de compatibilidade de modelos de classificador de imagem](https://www.tensorflow.org/lite/inference_with_metadata/task_library/image_classifier#model_compatibility_requirements)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KsPKmg8T9-8"
      },
      "source": [
        "Etapa 1 – Importe os pacotes obrigatórios."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hhgNqEtWrwB3"
      },
      "outputs": [],
      "source": [
        "from tflite_support.metadata_writers import image_classifier\n",
        "from tflite_support.metadata_writers import writer_utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9WBgiFdsiIQ"
      },
      "source": [
        "Etapa 2 – Baixe o exemplo de classificador de imagem, [mobilenet_v2_1.0_224.tflite](https://github.com/tensorflow/tflite-support/raw/master/tensorflow_lite_support/metadata/python/tests/testdata/image_classifier/mobilenet_v2_1.0_224.tflite) e o [arquivo de rótulos](https://github.com/tensorflow/tflite-support/raw/master/tensorflow_lite_support/metadata/python/tests/testdata/image_classifier/labels.txt)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6WgSBbNet-Tt"
      },
      "outputs": [],
      "source": [
        "!curl -L https://github.com/tensorflow/tflite-support/raw/master/tensorflow_lite_support/metadata/python/tests/testdata/image_classifier/mobilenet_v2_1.0_224.tflite -o mobilenet_v2_1.0_224.tflite\n",
        "!curl -L https://github.com/tensorflow/tflite-support/raw/master/tensorflow_lite_support/metadata/python/tests/testdata/image_classifier/labels.txt -o mobilenet_labels.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALtlz7woweHe"
      },
      "source": [
        "Etapa 3 – Crie o gravador de metadados e preencha os metadados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_SMEBBt2r-W6"
      },
      "outputs": [],
      "source": [
        "ImageClassifierWriter = image_classifier.MetadataWriter\n",
        "_MODEL_PATH = \"mobilenet_v2_1.0_224.tflite\"\n",
        "# Task Library expects label files that are in the same format as the one below.\n",
        "_LABEL_FILE = \"mobilenet_labels.txt\"\n",
        "_SAVE_TO_PATH = \"mobilenet_v2_1.0_224_metadata.tflite\"\n",
        "# Normalization parameters is required when reprocessing the image. It is\n",
        "# optional if the image pixel values are in range of [0, 255] and the input\n",
        "# tensor is quantized to uint8. See the introduction for normalization and\n",
        "# quantization parameters below for more details.\n",
        "# https://www.tensorflow.org/lite/models/convert/metadata#normalization_and_quantization_parameters)\n",
        "_INPUT_NORM_MEAN = 127.5\n",
        "_INPUT_NORM_STD = 127.5\n",
        "\n",
        "# Create the metadata writer.\n",
        "writer = ImageClassifierWriter.create_for_inference(\n",
        "    writer_utils.load_file(_MODEL_PATH), [_INPUT_NORM_MEAN], [_INPUT_NORM_STD],\n",
        "    [_LABEL_FILE])\n",
        "\n",
        "# Verify the metadata generated by metadata writer.\n",
        "print(writer.get_metadata_json())\n",
        "\n",
        "# Populate the metadata into the model.\n",
        "writer_utils.save_file(writer.populate(), _SAVE_TO_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GhhTDkr-uf0n"
      },
      "source": [
        "<a name=\"object_detectors\"></a>\n",
        "\n",
        "### Detectores de objeto"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EL9GssnTuf0n"
      },
      "source": [
        "Confira mais detalhes sobre o formato de modelo permitido nos [requisitos de compatibilidade de modelos de detector de objeto](https://www.tensorflow.org/lite/inference_with_metadata/task_library/object_detector#model_compatibility_requirements)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-HUTEtHuf0n"
      },
      "source": [
        "Etapa 1 – Importe os pacotes obrigatórios."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2_NIROeouf0o"
      },
      "outputs": [],
      "source": [
        "from tflite_support.metadata_writers import object_detector\n",
        "from tflite_support.metadata_writers import writer_utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UM6jijiUuf0o"
      },
      "source": [
        "Etapa 2 – Baixe o exemplo de detector de objeto, [ssd_mobilenet_v1.tflite](https://github.com/tensorflow/tflite-support/blob/master/tensorflow_lite_support/metadata/python/tests/testdata/object_detector/ssd_mobilenet_v1.tflite) e o [arquivo de rótulos](https://github.com/tensorflow/tflite-support/blob/master/tensorflow_lite_support/metadata/python/tests/testdata/object_detector/labelmap.txt)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4i_BBfGzuf0o"
      },
      "outputs": [],
      "source": [
        "!curl -L https://github.com/tensorflow/tflite-support/raw/master/tensorflow_lite_support/metadata/python/tests/testdata/object_detector/ssd_mobilenet_v1.tflite -o ssd_mobilenet_v1.tflite\n",
        "!curl -L https://github.com/tensorflow/tflite-support/raw/master/tensorflow_lite_support/metadata/python/tests/testdata/object_detector/labelmap.txt -o ssd_mobilenet_labels.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DG9T3eSDwsnd"
      },
      "source": [
        "Etapa 3 – Crie o gravador de metadados e preencha os metadados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vMGGeJfCuf0p"
      },
      "outputs": [],
      "source": [
        "ObjectDetectorWriter = object_detector.MetadataWriter\n",
        "_MODEL_PATH = \"ssd_mobilenet_v1.tflite\"\n",
        "# Task Library expects label files that are in the same format as the one below.\n",
        "_LABEL_FILE = \"ssd_mobilenet_labels.txt\"\n",
        "_SAVE_TO_PATH = \"ssd_mobilenet_v1_metadata.tflite\"\n",
        "# Normalization parameters is required when reprocessing the image. It is\n",
        "# optional if the image pixel values are in range of [0, 255] and the input\n",
        "# tensor is quantized to uint8. See the introduction for normalization and\n",
        "# quantization parameters below for more details.\n",
        "# https://www.tensorflow.org/lite/models/convert/metadata#normalization_and_quantization_parameters)\n",
        "_INPUT_NORM_MEAN = 127.5\n",
        "_INPUT_NORM_STD = 127.5\n",
        "\n",
        "# Create the metadata writer.\n",
        "writer = ObjectDetectorWriter.create_for_inference(\n",
        "    writer_utils.load_file(_MODEL_PATH), [_INPUT_NORM_MEAN], [_INPUT_NORM_STD],\n",
        "    [_LABEL_FILE])\n",
        "\n",
        "# Verify the metadata generated by metadata writer.\n",
        "print(writer.get_metadata_json())\n",
        "\n",
        "# Populate the metadata into the model.\n",
        "writer_utils.save_file(writer.populate(), _SAVE_TO_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QT0Oa0SU6uGS"
      },
      "source": [
        "<a name=\"image_segmenters\"></a>\n",
        "\n",
        "### Segmentadores de imagem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaFQmg-S6uGW"
      },
      "source": [
        "Confira mais detalhes sobre o formato de modelo permitido nos [requisitos de compatibilidade de modelos de segmentador de imagem](https://www.tensorflow.org/lite/inference_with_metadata/task_library/image_segmenter#model_compatibility_requirements)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DiktANhj6uGX"
      },
      "source": [
        "Etapa 1 – Importe os pacotes obrigatórios."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H6Lrw3op6uGX"
      },
      "outputs": [],
      "source": [
        "from tflite_support.metadata_writers import image_segmenter\n",
        "from tflite_support.metadata_writers import writer_utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EFs8Oyi6uGX"
      },
      "source": [
        "Etapa 2 – Baixe o exemplo de segmentador de imagem, [deeplabv3.tflite](https://github.com/tensorflow/tflite-support/blob/master/tensorflow_lite_support/metadata/python/tests/testdata/image_segmenter/deeplabv3.tflite) e o [arquivo de rótulos](https://github.com/tensorflow/tflite-support/blob/master/tensorflow_lite_support/metadata/python/tests/testdata/image_segmenter/labelmap.txt)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "feQDH0bN6uGY"
      },
      "outputs": [],
      "source": [
        "!curl -L https://github.com/tensorflow/tflite-support/raw/master/tensorflow_lite_support/metadata/python/tests/testdata/image_segmenter/deeplabv3.tflite -o deeplabv3.tflite\n",
        "!curl -L https://github.com/tensorflow/tflite-support/raw/master/tensorflow_lite_support/metadata/python/tests/testdata/image_segmenter/labelmap.txt -o deeplabv3_labels.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LhiAbJM6uGY"
      },
      "source": [
        "Etapa 3 – Crie o gravador de metadados e preencha os metadados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yot8xLI46uGY"
      },
      "outputs": [],
      "source": [
        "ImageSegmenterWriter = image_segmenter.MetadataWriter\n",
        "_MODEL_PATH = \"deeplabv3.tflite\"\n",
        "# Task Library expects label files that are in the same format as the one below.\n",
        "_LABEL_FILE = \"deeplabv3_labels.txt\"\n",
        "_SAVE_TO_PATH = \"deeplabv3_metadata.tflite\"\n",
        "# Normalization parameters is required when reprocessing the image. It is\n",
        "# optional if the image pixel values are in range of [0, 255] and the input\n",
        "# tensor is quantized to uint8. See the introduction for normalization and\n",
        "# quantization parameters below for more details.\n",
        "# https://www.tensorflow.org/lite/models/convert/metadata#normalization_and_quantization_parameters)\n",
        "_INPUT_NORM_MEAN = 127.5\n",
        "_INPUT_NORM_STD = 127.5\n",
        "\n",
        "# Create the metadata writer.\n",
        "writer = ImageSegmenterWriter.create_for_inference(\n",
        "    writer_utils.load_file(_MODEL_PATH), [_INPUT_NORM_MEAN], [_INPUT_NORM_STD],\n",
        "    [_LABEL_FILE])\n",
        "\n",
        "# Verify the metadata generated by metadata writer.\n",
        "print(writer.get_metadata_json())\n",
        "\n",
        "# Populate the metadata into the model.\n",
        "writer_utils.save_file(writer.populate(), _SAVE_TO_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NnvM80e7AG-h"
      },
      "source": [
        "<a name=\"nl_classifiers\"></a> ###Classificadores de linguagem natural"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfOPhFwOAG-k"
      },
      "source": [
        "Confira mais detalhes sobre o formato de modelo permitido nos [requisitos de compatibilidade de modelos de classificador de linguagem natural](https://www.tensorflow.org/lite/inference_with_metadata/task_library/nl_classifier#model_compatibility_requirements)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMJ7tvuwAG-k"
      },
      "source": [
        "Etapa 1 – Importe os pacotes obrigatórios."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_FGVyb2iAG-k"
      },
      "outputs": [],
      "source": [
        "from tflite_support.metadata_writers import nl_classifier\n",
        "from tflite_support.metadata_writers import metadata_info\n",
        "from tflite_support.metadata_writers import writer_utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIg7rATpAG-l"
      },
      "source": [
        "Etapa 2 – Baixe o exemplo de classificador de linguagem natural, [movie_review.tflite](https://github.com/tensorflow/tflite-support/blob/master/tensorflow_lite_support/metadata/python/tests/testdata/nl_classifier/movie_review.tflite), o [arquivo de rótulos](https://github.com/tensorflow/tflite-support/blob/master/tensorflow_lite_support/metadata/python/tests/testdata/nl_classifier/labels.txt) e o [arquivo de vocabulário](https://storage.googleapis.com/download.tensorflow.org/models/tflite_support/nl_classifier/vocab.txt)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TzuQcti2AG-l"
      },
      "outputs": [],
      "source": [
        "!curl -L https://github.com/tensorflow/tflite-support/raw/master/tensorflow_lite_support/metadata/python/tests/testdata/nl_classifier/movie_review.tflite -o movie_review.tflite\n",
        "!curl -L https://github.com/tensorflow/tflite-support/raw/master/tensorflow_lite_support/metadata/python/tests/testdata/nl_classifier/labels.txt -o movie_review_labels.txt\n",
        "!curl -L https://storage.googleapis.com/download.tensorflow.org/models/tflite_support/nl_classifier/vocab.txt -o movie_review_vocab.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWxUtHdeAG-m"
      },
      "source": [
        "Etapa 3 – Crie o gravador de metadados e preencha os metadados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NGPWzRuHAG-m"
      },
      "outputs": [],
      "source": [
        "NLClassifierWriter = nl_classifier.MetadataWriter\n",
        "_MODEL_PATH = \"movie_review.tflite\"\n",
        "# Task Library expects label files and vocab files that are in the same formats\n",
        "# as the ones below.\n",
        "_LABEL_FILE = \"movie_review_labels.txt\"\n",
        "_VOCAB_FILE = \"movie_review_vocab.txt\"\n",
        "# NLClassifier supports tokenize input string using the regex tokenizer. See\n",
        "# more details about how to set up RegexTokenizer below:\n",
        "# https://github.com/tensorflow/tflite-support/blob/master/tensorflow_lite_support/metadata/python/metadata_writers/metadata_info.py#L130\n",
        "_DELIM_REGEX_PATTERN = r\"[^\\w\\']+\"\n",
        "_SAVE_TO_PATH = \"moview_review_metadata.tflite\"\n",
        "\n",
        "# Create the metadata writer.\n",
        "writer = nl_classifier.MetadataWriter.create_for_inference(\n",
        "    writer_utils.load_file(_MODEL_PATH),\n",
        "    metadata_info.RegexTokenizerMd(_DELIM_REGEX_PATTERN, _VOCAB_FILE),\n",
        "    [_LABEL_FILE])\n",
        "\n",
        "# Verify the metadata generated by metadata writer.\n",
        "print(writer.get_metadata_json())\n",
        "\n",
        "# Populate the metadata into the model.\n",
        "writer_utils.save_file(writer.populate(), _SAVE_TO_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qv0WDnzW711f"
      },
      "source": [
        "<a name=\"audio_classifiers\"></a>\n",
        "\n",
        "### Classificadores de áudio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqP7X8jww8pL"
      },
      "source": [
        "Confira mais detalhes sobre o formato de modelo permitido nos [requisitos de compatibilidade de modelos de classificador de áudio](https://www.tensorflow.org/lite/inference_with_metadata/task_library/audio_classifier#model_compatibility_requirements)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RToKepxw8pL"
      },
      "source": [
        "Etapa 1 – Importe os pacotes obrigatórios."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JjddvTXKw8pL"
      },
      "outputs": [],
      "source": [
        "from tflite_support.metadata_writers import audio_classifier\n",
        "from tflite_support.metadata_writers import metadata_info\n",
        "from tflite_support.metadata_writers import writer_utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ar418rH6w8pL"
      },
      "source": [
        "Etapa 2 – Baixe o exemplo de classificador de áudio, [yamnet.tflite](https://github.com/tensorflow/tflite-support/blob/master/tensorflow_lite_support/metadata/python/tests/testdata/audio_classifier/yamnet_wavin_quantized_mel_relu6.tflite) e o [arquivo de rótulos](https://github.com/tensorflow/tflite-support/blob/master/tensorflow_lite_support/metadata/python/tests/testdata/audio_classifier/yamnet_521_labels.txt)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5eQY6znmw8pM"
      },
      "outputs": [],
      "source": [
        "!curl -L https://github.com/tensorflow/tflite-support/raw/master/tensorflow_lite_support/metadata/python/tests/testdata/audio_classifier/yamnet_wavin_quantized_mel_relu6.tflite -o yamnet.tflite\n",
        "!curl -L https://github.com/tensorflow/tflite-support/raw/master/tensorflow_lite_support/metadata/python/tests/testdata/audio_classifier/yamnet_521_labels.txt -o yamnet_labels.txt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TYP5w0Ew8pM"
      },
      "source": [
        "Etapa 3 – Crie o gravador de metadados e preencha os metadados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MDlSczBQw8pM"
      },
      "outputs": [],
      "source": [
        "AudioClassifierWriter = audio_classifier.MetadataWriter\n",
        "_MODEL_PATH = \"yamnet.tflite\"\n",
        "# Task Library expects label files that are in the same format as the one below.\n",
        "_LABEL_FILE = \"yamnet_labels.txt\"\n",
        "# Expected sampling rate of the input audio buffer.\n",
        "_SAMPLE_RATE = 16000\n",
        "# Expected number of channels of the input audio buffer. Note, Task library only\n",
        "# support single channel so far.\n",
        "_CHANNELS = 1\n",
        "_SAVE_TO_PATH = \"yamnet_metadata.tflite\"\n",
        "\n",
        "# Create the metadata writer.\n",
        "writer = AudioClassifierWriter.create_for_inference(\n",
        "    writer_utils.load_file(_MODEL_PATH), _SAMPLE_RATE, _CHANNELS, [_LABEL_FILE])\n",
        "\n",
        "# Verify the metadata generated by metadata writer.\n",
        "print(writer.get_metadata_json())\n",
        "\n",
        "# Populate the metadata into the model.\n",
        "writer_utils.save_file(writer.populate(), _SAVE_TO_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YoRLs84yNAJR"
      },
      "source": [
        "## Crie os metadados do modelo com informações semânticas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxXsOBknOGJ2"
      },
      "source": [
        "Você pode preencher informações mais descritivas sobre o modelo e cada tensor por meio da API Metadata Writer (gravação de metadados) para ajudar a melhorar a compreensão do modelo. Isso pode ser feito pelo método 'create_from_metadata_info' em cada gravador de metadados. De forma geral, você pode preencher os dados por meio dos parâmetros de 'create_from_metadata_info', por exemplo: `general_md`, `input_md` e `output_md`. Confira o exemplo abaixo para criar metadados completos de modelos de classificadores de imagem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-LW6nrcQ9lv"
      },
      "source": [
        "Etapa 1 – Importe os pacotes obrigatórios."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KsL_egYcRGw3"
      },
      "outputs": [],
      "source": [
        "from tflite_support.metadata_writers import image_classifier\n",
        "from tflite_support.metadata_writers import metadata_info\n",
        "from tflite_support.metadata_writers import writer_utils\n",
        "from tflite_support import metadata_schema_py_generated as _metadata_fb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UWck_8uRboF"
      },
      "source": [
        "Etapa 2 – Baixe o exemplo de classificador de imagem, [mobilenet_v2_1.0_224.tflite](https://github.com/tensorflow/tflite-support/raw/master/tensorflow_lite_support/metadata/python/tests/testdata/image_classifier/mobilenet_v2_1.0_224.tflite) e o [arquivo de rótulos](https://github.com/tensorflow/tflite-support/raw/master/tensorflow_lite_support/metadata/python/tests/testdata/image_classifier/labels.txt)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TqJ-jh-PRVdk"
      },
      "outputs": [],
      "source": [
        "!curl -L https://github.com/tensorflow/tflite-support/raw/master/tensorflow_lite_support/metadata/python/tests/testdata/image_classifier/mobilenet_v2_1.0_224.tflite -o mobilenet_v2_1.0_224.tflite\n",
        "!curl -L https://github.com/tensorflow/tflite-support/raw/master/tensorflow_lite_support/metadata/python/tests/testdata/image_classifier/labels.txt -o mobilenet_labels.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4I5wJMQRxzb"
      },
      "source": [
        "Etapa 3 – Crie as informações do modelo e dos tensores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "urd7HDuaR_HC"
      },
      "outputs": [],
      "source": [
        "model_buffer = writer_utils.load_file(\"mobilenet_v2_1.0_224.tflite\")\n",
        "\n",
        "# Create general model information.\n",
        "general_md = metadata_info.GeneralMd(\n",
        "    name=\"ImageClassifier\",\n",
        "    version=\"v1\",\n",
        "    description=(\"Identify the most prominent object in the image from a \"\n",
        "                 \"known set of categories.\"),\n",
        "    author=\"TensorFlow Lite\",\n",
        "    licenses=\"Apache License. Version 2.0\")\n",
        "\n",
        "# Create input tensor information.\n",
        "input_md = metadata_info.InputImageTensorMd(\n",
        "    name=\"input image\",\n",
        "    description=(\"Input image to be classified. The expected image is \"\n",
        "                 \"128 x 128, with three channels (red, blue, and green) per \"\n",
        "                 \"pixel. Each element in the tensor is a value between min and \"\n",
        "                 \"max, where (per-channel) min is [0] and max is [255].\"),\n",
        "    norm_mean=[127.5],\n",
        "    norm_std=[127.5],\n",
        "    color_space_type=_metadata_fb.ColorSpaceType.RGB,\n",
        "    tensor_type=writer_utils.get_input_tensor_types(model_buffer)[0])\n",
        "\n",
        "# Create output tensor information.\n",
        "output_md = metadata_info.ClassificationTensorMd(\n",
        "    name=\"probability\",\n",
        "    description=\"Probabilities of the 1001 labels respectively.\",\n",
        "    label_files=[\n",
        "        metadata_info.LabelFileMd(file_path=\"mobilenet_labels.txt\",\n",
        "                                  locale=\"en\")\n",
        "    ],\n",
        "    tensor_type=writer_utils.get_output_tensor_types(model_buffer)[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5aL5Uxkf4aO"
      },
      "source": [
        "Etapa 4 – Crie o gravador de metadados e preencha os metadados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_iWIwdqEf_mr"
      },
      "outputs": [],
      "source": [
        "ImageClassifierWriter = image_classifier.MetadataWriter\n",
        "# Create the metadata writer.\n",
        "writer = ImageClassifierWriter.create_from_metadata_info(\n",
        "    model_buffer, general_md, input_md, output_md)\n",
        "\n",
        "# Verify the metadata generated by metadata writer.\n",
        "print(writer.get_metadata_json())\n",
        "\n",
        "# Populate the metadata into the model.\n",
        "writer_utils.save_file(writer.populate(), _SAVE_TO_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z78vuu6np5sb"
      },
      "source": [
        "## Leia os metadados preenchidos em seu modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DnWt-4oOselo"
      },
      "source": [
        "É possível exibir os metadados e arquivos associados em um modelo do TF Lite por meio do seguinte código:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5D13YPUsp5VT"
      },
      "outputs": [],
      "source": [
        "from tflite_support import metadata\n",
        "\n",
        "displayer = metadata.MetadataDisplayer.with_model_file(\"mobilenet_v2_1.0_224_metadata.tflite\")\n",
        "print(\"Metadata populated:\")\n",
        "print(displayer.get_metadata_json())\n",
        "\n",
        "print(\"Associated file(s) populated:\")\n",
        "for file_name in displayer.get_packed_associated_file_list():\n",
        "  print(\"file name: \", file_name)\n",
        "  print(\"file content:\")\n",
        "  print(displayer.get_associated_file_buffer(file_name))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Mq-riZs-TJGt"
      ],
      "name": "metadata_writer_tutorial.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
