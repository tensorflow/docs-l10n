{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3puWgvKeyWu"
      },
      "source": [
        "# Auto-Batched Joint Distributions: A Gentle Tutorial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrwVQsM9TiUw"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow Authors.\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "CpDUTVKYTowI"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\"); { display-mode: \"form\" }\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltPJCG6pAUoc"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>     <a target=\"_blank\" href=\"https://www.tensorflow.org/probability/examples/JointDistributionAutoBatched_A_Gentle_Tutorial\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver em TensorFlow.org</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/pt-br/probability/examples/JointDistributionAutoBatched_A_Gentle_Tutorial.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Executar no Google Colab</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/pt-br/probability/examples/JointDistributionAutoBatched_A_Gentle_Tutorial.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver fonte no GitHub</a>\n",
        "</td>\n",
        "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/pt-br/probability/examples/JointDistributionAutoBatched_A_Gentle_Tutorial.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Baixar notebook</a>\n",
        "</td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzaOJSXagzMY"
      },
      "source": [
        "### Introdução"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cIvB2CSBe49Z"
      },
      "source": [
        "O TensorFlow Probability (TFP) conta com diversas abstrações de `JointDistribution` que facilitam a inferência probabilística ao permitir que o usuário expresse com facilidade um modelo gráfico probabilístico de uma forma quase matemática. A abstração gera métodos para fazer a amostragem do modelo e avaliar a probabilidade logarítmica das amostras. Neste tutorial, vamos avaliar as variantes com \"divisão automática em lotes\", que foram desenvolvidas depois das abstrações de `JointDistribution` originais. Com relação às originais, as abstrações sem divisão automática em lotes, as versões com divisão automática em lotes são mais simples de usar e mais ergonômicas, permitindo que diversos modelos sejam expressados com menos código boilerplate. Neste Colab, veremos um modelo simples com muitos detalhes (talvez tediosos), esclarecendo os problemas que a divisão automática em lotes resolve e ensinando mais sobre os conceitos de formato do TFP para os leitores.\n",
        "\n",
        "Antes do lançamento da divisão automática em lotes, havia algumas variantes diferentes de `JointDistribution`, correspondentes a estilos sintáticos diferentes para expressar modelos probabilísticos: `JointDistributionSequential`, `JointDistributionNamed` e `JointDistributionCoroutine`. A divisão automática em lotes existe como mixin, então agora temos variantes `AutoBatched` de todas essas distribuições. Neste tutorial, veremos as diferenças entre `JointDistributionSequential` e `JointDistributionSequentialAutoBatched`. Porém, tudo o que fizermos aqui pode ser aplicado às outras variantes basicamente sem alterações.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uiR4-VOt9NFX"
      },
      "source": [
        "### Dependências e pré-requisitos\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "coUnDhkpT5_6"
      },
      "outputs": [],
      "source": [
        "#@title Import and set ups{ display-mode: \"form\" }\n",
        "\n",
        "import functools\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow.compat.v2 as tf\n",
        "tf.enable_v2_behavior()\n",
        "\n",
        "import tensorflow_probability as tfp\n",
        "\n",
        "tfd = tfp.distributions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KohBmaTn5W7I"
      },
      "source": [
        "### Pré-requisito: problema de regressão bayesiana"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vChyK0vr9XD8"
      },
      "source": [
        "Vamos considerar um cenário bem simples de regressão bayesiana:\n",
        "\n",
        "$$\n",
        "\\begin{align*}\n",
        "m & \\sim \\text{Normal}(0, 1) \\\\\n",
        "b & \\sim \\text{Normal}(0, 1) \\\\\n",
        "Y & \\sim \\text{Normal}(mX + b, 1)\n",
        "\\end{align*}\n",
        "$$\n",
        "\n",
        "Nesse modelo, `m` e `b` são obtidos a partir das distribuições normais padrão, e as observações `Y` são obtidas a partir de uma distribuição normal cuja média depende das variáveis aleatórias `m` e `b` e de algumas covariáveis (conhecidas, não aleatórias) `X` (por questões de simplicidade, neste exemplo, pressupomos que a escala de todas as variáveis aleatórias seja conhecida).\n",
        "\n",
        "Para fazer a inferência nesse modelo, precisaríamos saber tanto as covariáveis `X` quanto as observações `Y`, mas, para a finalidade deste tutorial, precisaremos somente de `X` e, portanto, definimos um `X` simples:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UIpJ_cXUVabB"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4, 5, 6])"
            ]
          },
          "execution_count": 0,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X = np.arange(7)\n",
        "X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CIBpupyt9GTT"
      },
      "source": [
        "### Dados desejados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2uzL_uI9tqO"
      },
      "source": [
        "Na inferência probabilística, geralmente queremos realizar duas operações básicas:\n",
        "\n",
        "- `sample`: obtenção de amostras do modelo.\n",
        "- `log_prob`: computação da probabilidade logarítmica de uma amostra do modelo.\n",
        "\n",
        "A principal contribuição das abstrações de `JointDistribution` do TFP (bem como de diversas outras estratégias de programação probabilística) é permitir que os usuários escrevam um modelo *uma vez* e tenham acesso tanto a computações de `sample` quanto de `log_prob`.\n",
        "\n",
        "Observando que temos sete pontos em nosso dataset (`X.shape = (7,)`), agora podemos declarar os dados desejados para uma `JointDistribution` excelente:\n",
        "\n",
        "- `sample()` deve gerar uma lista de `Tensors` com formato `[(), (), (7,)]`, correspondente ao declive escalar, ao bias escalar e às observações do vetor, respectivamente.\n",
        "- `log_prob(sample())` deve gerar um escalar: a probabilidade logarítmica de um declive, bias e observações específicos.\n",
        "- `sample([5, 3])` deve gerar uma lista de `Tensors` com formato `[(5, 3), (5, 3), (5, 3, 7)]`, representando um *lote* `(5, 3)` de amostras do modelo.\n",
        "- `log_prob(sample([5, 3]))` deve gerar um `Tensor` com formato (5, 3).\n",
        "\n",
        "Agora vamos conferir uma sequência de modelos de `JointDistribution`, ver como alcançar os dados desejados acima e quem sabe aprender um pouco mais sobre os formatos do TFP.\n",
        "\n",
        "Spoiler: a estratégia que satisfaz os dados desejados acima sem código boilerplate adicional é a [divisão automática em lotes](#scrollTo=_h7sJ2bkfOS7). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QiII0ypZcyTY"
      },
      "source": [
        "### Primeira tentativa: `JointDistributionSequential`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kY501q-QVR9g"
      },
      "outputs": [],
      "source": [
        "jds = tfd.JointDistributionSequential([\n",
        "    tfd.Normal(loc=0., scale=1.),   # m\n",
        "    tfd.Normal(loc=0., scale=1.),   # b\n",
        "    lambda b, m: tfd.Normal(loc=m*X + b, scale=1.) # Y\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzNPPqJ-BwA-"
      },
      "source": [
        "Isso é basicamente uma tradução direta do modelo em código. O declive `m` e o bias `b` são diretos. `Y` é definido usando-se uma função `lambda`: o padrão geral é que uma função `lambda` de $k$ argumentos em uma distribuição `JointDistributionSequential` (JDS, na sigla em inglês) use as $k$ distribuições anteriores do modelo. Agora, a ordem \"reversa\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jIvsQSOD81N"
      },
      "source": [
        "Vamos chamar `sample_distributions`, que retorna tanto uma amostra *quanto* as \"subdistribuições\" subjacentes que foram usadas para gerar a amostra (poderíamos ter gerado somente a amostra chamando `sample`; posteriormente neste tutorial, também será conveniente ter as distribuições). A amostra que geramos é boa:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y05IrsfiaxCh"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<tf.Tensor: shape=(), dtype=float32, numpy=-1.668757>,\n",
              " <tf.Tensor: shape=(), dtype=float32, numpy=0.6585061>,\n",
              " <tf.Tensor: shape=(7,), dtype=float32, numpy=\n",
              " array([ 0.18573815, -1.79962   , -1.8106272 , -3.5971394 , -6.6625295 ,\n",
              "        -7.308844  , -9.832693  ], dtype=float32)>]"
            ]
          },
          "execution_count": 0,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dists, sample = jds.sample_distributions()\n",
        "sample"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7E1WkoCEB12"
      },
      "source": [
        "Mas `log_prob` gera um resultado com formato indesejado:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xR0lbgjNay4X"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(7,), dtype=float32, numpy=\n",
              "array([-4.4777603, -4.6775575, -4.7430477, -4.647725 , -4.5746684,\n",
              "       -4.4368567, -4.480562 ], dtype=float32)>"
            ]
          },
          "execution_count": 0,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "jds.log_prob(sample)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mMIs28LEJqN"
      },
      "source": [
        "E a amostragem múltipla não funciona:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LbfRiIsfc9Hf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Incompatible shapes: [5,3] vs. [7] [Op:Mul]\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "  jds.sample([5, 3])\n",
        "except tf.errors.InvalidArgumentError as e:\n",
        "  print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rnvtz3SQHrVL"
      },
      "source": [
        "Vamos tentar entender o que está dando errado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dp30JPCmHyuz"
      },
      "source": [
        "### Breve revisão: formato de lote e evento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w24fZn3kH2uF"
      },
      "source": [
        "No TFP, uma distribuição de probabilidades comum (não uma `JointDistribution`) tem um *formato de evento* e um *formato de lote*, e compreender a diferença entre eles é essencial para usar o TFP com eficácia:\n",
        "\n",
        "- Cada formato descreve o formato de uma única obtenção de dado da distribuição; a obtenção pode ser dependente entre as dimensões. Para distribuições escalares, o formato de evento é []. Para uma distribuição normal multivariada de 5 dimensões, o formato de evento é [5].\n",
        "- O formato de lote descreve obtenções de dados independentes, não distribuídas identicamente, ou seja, um \"lote\" de distribuições. Representar um lote de distribuições em um único objeto do Python é uma das principais formas de o TFP alcançar eficiência em grande escala.\n",
        "\n",
        "Para nossos propósitos, um fato crítico que deve ser lembrando é que, se chamarmos `log_prob` em uma única amostra de uma distribuição, o resultado sempre terá um formato que coincide (ou seja, tem as dimensões da extremidade direita) com o formato de *lote*.\n",
        "\n",
        "Confira mais detalhes sobre formatos no [tutorial \"Noções básicas sobre os formatos de distribuições do TensorFlow\"](https://www.tensorflow.org/probability/examples/Understanding_TensorFlow_Distributions_Shapes).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nONZMjl-KtTz"
      },
      "source": [
        "### Por que `log_prob(sample())` não gera um escalar? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUKyGzkOJiuD"
      },
      "source": [
        "Vamos usar nossos conhecimentos sofre formato de lote e evento para ver o que está acontecendo com `log_prob(sample())`. Veja a amostra novamente:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ijRGAnSBJwCG"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<tf.Tensor: shape=(), dtype=float32, numpy=-1.668757>,\n",
              " <tf.Tensor: shape=(), dtype=float32, numpy=0.6585061>,\n",
              " <tf.Tensor: shape=(7,), dtype=float32, numpy=\n",
              " array([ 0.18573815, -1.79962   , -1.8106272 , -3.5971394 , -6.6625295 ,\n",
              "        -7.308844  , -9.832693  ], dtype=float32)>]"
            ]
          },
          "execution_count": 0,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sample"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NAzBAsu3OoLv"
      },
      "source": [
        "E aqui estão as distribuições:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_xtIUKf8Nq3G"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<tfp.distributions.Normal 'Normal' batch_shape=[] event_shape=[] dtype=float32>,\n",
              " <tfp.distributions.Normal 'Normal' batch_shape=[] event_shape=[] dtype=float32>,\n",
              " <tfp.distributions.Normal 'JointDistributionSequential_sample_distributions_Normal' batch_shape=[7] event_shape=[] dtype=float32>]"
            ]
          },
          "execution_count": 0,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dists"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzkLnoZyFeU_"
      },
      "source": [
        "A probabilidade logarítmica é computada somando os probabilidades logarítmicas das subdistribuições nos elementos (coincidentes) das partes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5XTDKVMPO5qg"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<tf.Tensor: shape=(), dtype=float32, numpy=-2.3113134>,\n",
              " <tf.Tensor: shape=(), dtype=float32, numpy=-1.1357536>,\n",
              " <tf.Tensor: shape=(7,), dtype=float32, numpy=\n",
              " array([-1.0306933, -1.2304904, -1.2959809, -1.200658 , -1.1276014,\n",
              "        -0.9897899, -1.0334952], dtype=float32)>]"
            ]
          },
          "execution_count": 0,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "log_prob_parts = [dist.log_prob(s) for (dist, s) in zip(dists, sample)]\n",
        "log_prob_parts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QoWsVGx8N1IJ"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(7,), dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0.], dtype=float32)>"
            ]
          },
          "execution_count": 0,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sum(log_prob_parts) - jds.log_prob(sample)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJFvR4ZNFngd"
      },
      "source": [
        "Portanto, a primeira explicação é que o cálculo da probabilidade logarítmica está retornando um Tensor de dimensão 7 porque o terceiro subcomponente de `log_prob_parts` é um Tensor dimensão 7. Mas por quê?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdpKnguOPOrr"
      },
      "source": [
        "Podemos ver que o último elemento de `dists`, que corresponde à nossa distribuição para `Y` na formulação matemática, tem um `batch_shape` igual a `[7]`. Em outras palavras, a distribuição para `Y` é um lote de 7 distribuições normais independentes (com médias diferentes e, neste caso, a mesma escala)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WXzlR_diTuZ"
      },
      "source": [
        "Agora entendemos o que está errado: na JDS, a distribuição para `Y` tem `batch_shape=[7]`, uma amostra da JDS representa escalares para `m` e `b` e um \"lote\" de 7 distribuições normais independentes. Além disso, `log_prob` computa 7 probabilidades logarítmicas separadas, cada uma representando a probabilidade logarítmica de obter `m` e `b` e uma única observação `Y[i]` em algum `X[i]`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9RI0oxCi_En"
      },
      "source": [
        "### Corrigindo `log_prob(sample())` com `Independent`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOL1hllzjDcF"
      },
      "source": [
        "Lembre-se de que `dists[2]` tem `event_shape=[]` e `batch_shape=[7]`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TA05J9VwjCLu"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tfp.distributions.Normal 'JointDistributionSequential_sample_distributions_Normal' batch_shape=[7] event_shape=[] dtype=float32>"
            ]
          },
          "execution_count": 0,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dists[2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xQ5ORIqjPAz"
      },
      "source": [
        "Usando a metadistribuição `Independent` do TFP, que converte dimensões de lote em dimensões de evento, podemos convertê-la em uma distribuição com `event_shape=[7]` e `batch_shape=[]` (vamos renomear para `y_dist_i`, pois é uma distribuição para `Y`, com `_i` indicando nosso encapsulamento `Independent`): "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aa_SPItTjLBO"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tfp.distributions.Independent 'IndependentJointDistributionSequential_sample_distributions_Normal' batch_shape=[] event_shape=[7] dtype=float32>"
            ]
          },
          "execution_count": 0,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_dist_i = tfd.Independent(dists[2], reinterpreted_batch_ndims=1)\n",
        "y_dist_i"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrRjuDhhmBEr"
      },
      "source": [
        "Agora, a `log_prob` de um vetor de dimensão 7 é um escalar:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y9yZs-kwdLGa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=-7.9087086>"
            ]
          },
          "execution_count": 0,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_dist_i.log_prob(sample[2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqNEen4Ujkhh"
      },
      "source": [
        "Nos bastidores, `Independent` soma ao longo do lote:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SxYr1McJkWFx"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.0>"
            ]
          },
          "execution_count": 0,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_dist_i.log_prob(sample[2]) - tf.reduce_sum(dists[2].log_prob(sample[2]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00lD003YkojA"
      },
      "source": [
        "E podemos usá-la para construir uma nova `jds_i` (novamente, `i` significa `Independent`), em que `log_prob` retorna um escalar:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1jwoSeNWkhT6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=-11.355776>"
            ]
          },
          "execution_count": 0,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "jds_i = tfd.JointDistributionSequential([\n",
        "    tfd.Normal(loc=0., scale=1.),   # m\n",
        "    tfd.Normal(loc=0., scale=1.),   # b\n",
        "    lambda b, m: tfd.Independent(   # Y\n",
        "        tfd.Normal(loc=m*X + b, scale=1.),\n",
        "        reinterpreted_batch_ndims=1)\n",
        "])\n",
        "\n",
        "jds_i.log_prob(sample)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hYY3CNBXlAIZ"
      },
      "source": [
        "Algumas observações:\n",
        "\n",
        "- `jds_i.log_prob(s)` *não* é a mesma que `tf.reduce_sum(jds.log_prob(s))`. A primeira gera a probabilidade logarítmica \"correta\" da distribuição conjunta. A segunda faz a soma para um Tensor de dimensão 7, em que cada elemento é a soma da probabilidade logarítmica de `m`, `b` e um único elemento da probabilidade logarítmica de `Y`, então `m` e `b` são contabilizados acima do que deveriam ser. (`log_prob(m) + log_prob(b) + log_prob(Y)` retorna um resultado em vez de gerar uma exceção porque o TFP segue as regras de broadcast do TF e do NumPy – adicionar um escalar a um vetor gera um resultado com tamanho do vetor).\n",
        "- Neste caso específico, poderíamos ter resolvido o problema e conseguido o mesmo resultado usando `MultivariateNormalDiag` em vez de `Independent(Normal(...))`. `MultivariateNormalDiag` é uma distribuição com valor de vetor (ou seja, já tem formato de evento como vetor). De fato, `MultivariateNormalDiag` poderia ser (mas não é) implementada como uma composição de `Independent` e `Normal`. É importante lembrar que, dado um vetor `V`, as amostras de `n1 = Normal(loc=V)` e `n2 = MultivariateNormalDiag(loc=V)` são indistinguíveis. A diferença entre essas distribuições é que `n1.log_prob(n1.sample())` é um vetor, e `n2.log_prob(n2.sample())` é um escalar."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-iFi65ZmvpB"
      },
      "source": [
        "### Múltiplas amostras?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZcEBJS_nAhA"
      },
      "source": [
        "Obter múltiplas amostras não funciona também:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PkvYmB3jm2sI"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Incompatible shapes: [5,3] vs. [7] [Op:Mul]\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "  jds_i.sample([5, 3])\n",
        "except tf.errors.InvalidArgumentError as e:\n",
        "  print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9Jh0MTCn0Mr"
      },
      "source": [
        "Vamos pensar no motivo. Quando chamamos `jds_i.sample([5, 3])`, primeiro obtemos amostras para `m` e `b`, cada uma com formato `(5, 3)`. Em seguida, tentamos construir uma distribuição `Normal` via:\n",
        "\n",
        "```\n",
        "tfd.Normal(loc=m*X + b, scale=1.)\n",
        "```\n",
        "\n",
        "Mas, se `m` tem formato `(5, 3)`, e `X` tem formato `7`, não podemos multiplicá-los e, de fato, é esse erro que estamos obtendo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ei9Z2Nozp8Dy"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Incompatible shapes: [5,3] vs. [7] [Op:Mul]\n"
          ]
        }
      ],
      "source": [
        "m = tfd.Normal(0., 1.).sample([5, 3])\n",
        "try:\n",
        "  m * X\n",
        "except tf.errors.InvalidArgumentError as e:\n",
        "  print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1uqaIx2LlaeP"
      },
      "source": [
        "Para resolver esse problema, vamos pensar em que propriedades a distribuição para `Y` precisa ter. Se chamarmos `jds_i.sample([5, 3])`, então sabemos que tanto `m` quanto `b` terão formato igual a `(5, 3)`. Que formato uma chamada a `sample` na distribuição `Y` gera? A resposta óbvia é `(5, 3, 7)`: para cada ponto do lote, queremos uma amostra com o mesmo tamanho que o de `X`. Podemos conseguir isso usando as funcionalidades de broadcast do TensorFlow, acrescentando dimensões extras:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-22Bg8Yfr6tg"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TensorShape([5, 3, 1])"
            ]
          },
          "execution_count": 0,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "m[..., tf.newaxis].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7k21MOvlsHGe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TensorShape([5, 3, 7])"
            ]
          },
          "execution_count": 0,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(m[..., tf.newaxis] * X).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5AEBbcjVsXQR"
      },
      "source": [
        "Acrescentando um eixo tanto a `m` quanto a `b`, podemos definir uma nova JDS com suporte a múltiplas amostras:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9rJ9WCVQsW0S"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<tf.Tensor: shape=(5, 3), dtype=float32, numpy=\n",
              " array([[-1.1133379 ,  0.16390413, -0.24177533],\n",
              "        [-1.1312429 , -0.6224666 , -1.8182136 ],\n",
              "        [-0.31343174, -0.32932565,  0.5164407 ],\n",
              "        [-0.0119963 , -0.9079621 ,  2.3655841 ],\n",
              "        [-0.26293617,  0.8229698 ,  0.31098196]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(5, 3), dtype=float32, numpy=\n",
              " array([[-0.02876974,  1.0872147 ,  1.0138507 ],\n",
              "        [ 0.27367726, -1.331534  , -0.09084719],\n",
              "        [ 1.3349475 , -0.68765205,  1.680652  ],\n",
              "        [ 0.75436825,  1.3050154 , -0.9415123 ],\n",
              "        [-1.2502679 , -0.25730947,  0.74611956]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(5, 3, 7), dtype=float32, numpy=\n",
              " array([[[-1.8258233e+00, -3.0641669e-01, -2.7595463e+00, -1.6952467e+00,\n",
              "          -4.8197951e+00, -5.2986512e+00, -6.6931367e+00],\n",
              "         [ 3.6438566e-01,  1.0067395e+00,  1.4542470e+00,  8.1155670e-01,\n",
              "           1.8868095e+00,  2.3877139e+00,  1.0195159e+00],\n",
              "         [-8.3624744e-01,  1.2518480e+00,  1.0943471e+00,  1.3052304e+00,\n",
              "          -4.5756745e-01, -1.0668410e-01, -7.0669651e-02]],\n",
              " \n",
              "        [[-3.1788960e-01,  9.2615485e-03, -3.0963073e+00, -2.2846246e+00,\n",
              "          -3.2269263e+00, -6.0213070e+00, -7.4806519e+00],\n",
              "         [-3.9149747e+00, -3.5155020e+00, -1.5669601e+00, -5.0759468e+00,\n",
              "          -4.5065498e+00, -5.6719379e+00, -4.8012795e+00],\n",
              "         [ 1.3053948e-01, -8.0493152e-01, -4.7845001e+00, -4.9721808e+00,\n",
              "          -7.1365709e+00, -9.6198196e+00, -9.7951422e+00]],\n",
              " \n",
              "        [[ 2.0621397e+00,  3.4639853e-01,  7.0252883e-01, -1.4311566e+00,\n",
              "           3.3790007e+00,  1.1619035e+00, -8.9105040e-01],\n",
              "         [-7.8956139e-01, -8.5023916e-01, -9.7148323e-01, -2.6229355e+00,\n",
              "          -2.7150445e+00, -2.4633870e+00, -2.1841538e+00],\n",
              "         [ 7.7627432e-01,  2.2401071e+00,  3.7601702e+00,  2.4245868e+00,\n",
              "           4.0690269e+00,  4.0605016e+00,  5.1753912e+00]],\n",
              " \n",
              "        [[ 1.4275590e+00,  3.3346462e+00,  1.5374103e+00, -2.2849756e-01,\n",
              "           9.1219616e-01, -3.1220305e-01, -3.2643962e-01],\n",
              "         [-3.1910419e-02, -3.8848895e-01,  9.9946201e-02, -2.3619974e+00,\n",
              "          -1.8507402e+00, -3.6830821e+00, -5.4907336e+00],\n",
              "         [-7.1941972e-02,  2.1602919e+00,  4.9575748e+00,  4.2317696e+00,\n",
              "           9.3528280e+00,  1.0526063e+01,  1.5262107e+01]],\n",
              " \n",
              "        [[-2.3257759e+00, -2.5343289e+00, -3.5342445e+00, -4.0423255e+00,\n",
              "          -3.2361765e+00, -3.3434000e+00, -2.6849220e+00],\n",
              "         [ 1.5006512e-02, -1.9866472e-01,  7.6781356e-01,  1.6228745e+00,\n",
              "           1.4191239e+00,  2.6655579e+00,  4.4663467e+00],\n",
              "         [ 2.6599693e+00,  1.2663836e+00,  1.7162113e+00,  1.4839669e+00,\n",
              "           2.0559487e+00,  2.5976877e+00,  2.5977583e+00]]], dtype=float32)>]"
            ]
          },
          "execution_count": 0,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "jds_ia = tfd.JointDistributionSequential([\n",
        "    tfd.Normal(loc=0., scale=1.),   # m\n",
        "    tfd.Normal(loc=0., scale=1.),   # b\n",
        "    lambda b, m: tfd.Independent(   # Y\n",
        "        tfd.Normal(loc=m[..., tf.newaxis]*X + b[..., tf.newaxis], scale=1.),\n",
        "        reinterpreted_batch_ndims=1)\n",
        "])\n",
        "\n",
        "shaped_sample = jds_ia.sample([5, 3])\n",
        "shaped_sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8fsYEy6Fla0o"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5, 3), dtype=float32, numpy=\n",
              "array([[-12.483114 , -10.139662 , -11.514159 ],\n",
              "       [-11.656767 , -17.201958 , -12.132455 ],\n",
              "       [-17.838818 ,  -9.474525 , -11.24898  ],\n",
              "       [-13.95219  , -12.490049 , -17.123957 ],\n",
              "       [-14.487818 , -11.3755455, -10.576363 ]], dtype=float32)>"
            ]
          },
          "execution_count": 0,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "jds_ia.log_prob(shaped_sample)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ArLyKqJtY3Z"
      },
      "source": [
        "Como checagem extra, vamos verificar se a probabilidade logarítmica para um único ponto do lote coincide com a que obtivemos antes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9_2lIJyJtpyW"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.0>"
            ]
          },
          "execution_count": 0,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(jds_ia.log_prob(shaped_sample)[3, 1] -\n",
        " jds_i.log_prob([shaped_sample[0][3, 1],\n",
        "                 shaped_sample[1][3, 1],\n",
        "                 shaped_sample[2][3, 1, :]]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_h7sJ2bkfOS7"
      },
      "source": [
        "<a id=\"AutoBatching-For-The-Win\"></a>\n",
        "\n",
        "### Divisão automática em lotes é a melhor opção\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7nqIUMxuKzw"
      },
      "source": [
        "Excelente! Agora temos uma versão da JointDistribution que trata todo os nossos dados desejados: `log_prob` retorna um escalar graças ao uso de `tfd.Independent`, e agora múltiplas amostras funcionam porque fixamos o broadcast ao adicionar eixos extras.\n",
        "\n",
        "E se dissermos que existe uma forma melhor e mais fácil? Ela é chamada `JointDistributionSequentialAutoBatched` (JDSAB, na sigla em inglês):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LZtVljb0fRx2"
      },
      "outputs": [],
      "source": [
        "jds_ab = tfd.JointDistributionSequentialAutoBatched([\n",
        "    tfd.Normal(loc=0., scale=1.),   # m\n",
        "    tfd.Normal(loc=0., scale=1.),   # b\n",
        "    lambda b, m: tfd.Normal(loc=m*X + b, scale=1.) # Y\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gpvjnvXqu2Mk"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=-12.954952>"
            ]
          },
          "execution_count": 0,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "jds_ab.log_prob(jds.sample())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Js3luiUfns_R"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5, 3), dtype=float32, numpy=\n",
              "array([[-12.191533 , -10.43885  , -16.371655 ],\n",
              "       [-13.292994 , -11.97949  , -16.788685 ],\n",
              "       [-15.987699 , -13.435732 , -10.6029   ],\n",
              "       [-10.184758 , -11.969714 , -14.275676 ],\n",
              "       [-12.740775 , -11.5654125, -12.990162 ]], dtype=float32)>"
            ]
          },
          "execution_count": 0,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "shaped_sample = jds_ab.sample([5, 3])\n",
        "jds_ab.log_prob(shaped_sample)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v1ppa6F6bdkv"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5, 3), dtype=float32, numpy=\n",
              "array([[0., 0., 0.],\n",
              "       [0., 0., 0.],\n",
              "       [0., 0., 0.],\n",
              "       [0., 0., 0.],\n",
              "       [0., 0., 0.]], dtype=float32)>"
            ]
          },
          "execution_count": 0,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "jds_ab.log_prob(shaped_sample) - jds_ia.log_prob(shaped_sample)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xy-kuUbYwFB3"
      },
      "source": [
        "Como funciona? Você pode [avaliar o código](https://github.com/tensorflow/probability/blob/main/tensorflow_probability/python/distributions/joint_distribution_auto_batched.py#L426) para entender melhor, mas vamos apresentar uma visão geral breve que é suficiente para a maioria dos casos de uso:\n",
        "\n",
        "- Lembre-se de que o primeiro problema era que a distribuição para `Y` tinha `batch_shape=[7]` e `event_shape=[]`, e usamos `Independent` para converter a dimensão de lote em dimensão de evento. A JDSAB ignora os formatos de lote das distribuições componentes; em vez disso, ela trata o formato de lote como uma propriedade geral do modelo, que é presumido como `[]` (a menos que seja especificado de outra forma definindo `batch_ndims > 0`). O efeito é equivalente a usar tfd.Independent para converter *todas* as dimensões de lote das distribuições componentes em dimensões de evento, conforme fizemos manualmente acima.\n",
        "- O segundo problema era a necessidade de alterar os formatos de `m` e `b` para que pudessem fazer o broadcast corretamente com `X` ao criar múltiplas amostras. Com a JDSAB, escrevemos um modelo para gerar uma única amostra e fazemos o modelo inteiro gerar múltiplas amostras usando [vectorized_map](https://www.tensorflow.org/api_docs/python/tf/vectorized_map) do TensorFlow (essa funcionalidade é análoga a [vmap](https://jax.readthedocs.io/en/latest/notebooks/quickstart.html#Auto-vectorization-with-vmap) do JAX)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUsWfVGqJiph"
      },
      "source": [
        "Explorando o problema do formato de lote com mais detalhes, podemos comparar os formatos de lote da distribuição conjunta original \"ruim\" `jds`, das distribuições com lote fixo `jds_i` e `jds_ia`, e da `jds_ab` com divisão automática em lotes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "298I732fJDk5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[TensorShape([]), TensorShape([]), TensorShape([7])]"
            ]
          },
          "execution_count": 0,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "jds.batch_shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SBmdWrUuJGx0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[TensorShape([]), TensorShape([]), TensorShape([])]"
            ]
          },
          "execution_count": 0,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "jds_i.batch_shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vD71eqN2JMhx"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[TensorShape([]), TensorShape([]), TensorShape([])]"
            ]
          },
          "execution_count": 0,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "jds_ia.batch_shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qHmvRcxBJOAZ"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TensorShape([])"
            ]
          },
          "execution_count": 0,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "jds_ab.batch_shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozegq0diJuOL"
      },
      "source": [
        "Podemos ver que a `jds` original tem subdistribuições com formatos de lote diferentes. `jds_i` e `jds_ia` corrigem esse problema criando subdistribuições com o mesmo formato de lote (vazio). `jds_ab` tem somente um único formato de lote (vazio)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMm55xqV1dz6"
      },
      "source": [
        "É importante salientar que `JointDistributionSequentialAutoBatched` oferece uma generalização adicional gratuitamente. Vamos supor que tornemos as covariáveis `X` (e, implicitamente, as observações `Y`) bidimensionais:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1WfK-XbR1tXU"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 0,  1,  2,  3,  4,  5,  6],\n",
              "       [ 7,  8,  9, 10, 11, 12, 13]])"
            ]
          },
          "execution_count": 0,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X = np.arange(14).reshape((2, 7))\n",
        "X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOnnkZooSj2C"
      },
      "source": [
        "A `JointDistributionSequentialAutoBatched` funciona sem alterações (precisamos redefinir o modelo porque é feito cache do formato de `X` por `jds_ab.log_prob`):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6WwMvoY71qph"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<tf.Tensor: shape=(5, 3), dtype=float32, numpy=\n",
              " array([[ 0.1813647 , -0.85994506,  0.27593774],\n",
              "        [-0.73323774,  1.1153806 ,  0.8841938 ],\n",
              "        [ 0.5127983 , -0.29271227,  0.63733214],\n",
              "        [ 0.2362284 , -0.919168  ,  1.6648189 ],\n",
              "        [ 0.26317367,  0.73077047,  2.5395133 ]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(5, 3), dtype=float32, numpy=\n",
              " array([[ 0.09636458,  2.0138032 , -0.5054413 ],\n",
              "        [ 0.63941646, -1.0785882 , -0.6442188 ],\n",
              "        [ 1.2310615 , -0.3293852 ,  0.77637213],\n",
              "        [ 1.2115169 , -0.98906034, -0.07816773],\n",
              "        [-1.1318136 ,  0.510014  ,  1.036522  ]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(5, 3, 2, 7), dtype=float32, numpy=\n",
              " array([[[[-1.9685398e+00, -1.6832136e+00, -6.9127172e-01,\n",
              "            8.5992378e-01, -5.3123581e-01,  3.1584005e+00,\n",
              "            2.9044402e+00],\n",
              "          [-2.5645006e-01,  3.1554163e-01,  3.1186538e+00,\n",
              "            1.4272424e+00,  1.2843871e+00,  1.2266440e+00,\n",
              "            1.2798605e+00]],\n",
              " \n",
              "         [[ 1.5973477e+00, -5.3631151e-01,  6.8143606e-03,\n",
              "           -1.4910895e+00, -2.1568544e+00, -2.0513713e+00,\n",
              "           -3.1663666e+00],\n",
              "          [-4.9448099e+00, -2.8385928e+00, -6.9027486e+00,\n",
              "           -5.6543546e+00, -7.2378774e+00, -8.1577444e+00,\n",
              "           -9.3582869e+00]],\n",
              " \n",
              "         [[-2.1233239e+00,  5.8853775e-02,  1.2024102e+00,\n",
              "            1.6622503e+00, -1.9197327e-01,  1.8647723e+00,\n",
              "            6.4322817e-01],\n",
              "          [ 3.7549341e-01,  1.5853541e+00,  2.4594500e+00,\n",
              "            2.1952972e+00,  1.7517658e+00,  2.9666045e+00,\n",
              "            2.5468128e+00]]],\n",
              " \n",
              " \n",
              "        [[[ 8.9906776e-01,  6.7375046e-01,  7.3354661e-01,\n",
              "           -9.9894643e-01, -3.4606690e+00, -3.4810467e+00,\n",
              "           -4.4315586e+00],\n",
              "          [-3.0670738e+00, -6.3628020e+00, -6.2538433e+00,\n",
              "           -6.8091092e+00, -7.7134805e+00, -8.6319380e+00,\n",
              "           -8.6904278e+00]],\n",
              " \n",
              "         [[-2.2462025e+00, -3.3060855e-01,  1.8974400e-01,\n",
              "            3.1422038e+00,  4.1483402e+00,  3.5642972e+00,\n",
              "            4.8709240e+00],\n",
              "          [ 4.7880130e+00,  5.8790064e+00,  9.6695948e+00,\n",
              "            7.8112822e+00,  1.2022618e+01,  1.2411858e+01,\n",
              "            1.4323385e+01]],\n",
              " \n",
              "         [[-1.0189297e+00, -7.8115642e-01,  1.6466728e+00,\n",
              "            8.2378983e-01,  3.0765080e+00,  3.0170646e+00,\n",
              "            5.1899948e+00],\n",
              "          [ 6.5285158e+00,  7.8038850e+00,  6.4155884e+00,\n",
              "            9.0899811e+00,  1.0040427e+01,  9.1404457e+00,\n",
              "            1.0411951e+01]]],\n",
              " \n",
              " \n",
              "        [[[ 4.5557004e-01,  1.4905317e+00,  1.4904103e+00,\n",
              "            2.9777462e+00,  2.8620450e+00,  3.4745665e+00,\n",
              "            3.8295493e+00],\n",
              "          [ 3.9977460e+00,  5.7173767e+00,  7.8421035e+00,\n",
              "            6.3180594e+00,  6.0838981e+00,  8.2257290e+00,\n",
              "            9.6548376e+00]],\n",
              " \n",
              "         [[-7.0750320e-01, -3.5972297e-01,  4.3136525e-01,\n",
              "           -2.3301599e+00, -5.0374687e-01, -2.8338656e+00,\n",
              "           -3.4453444e+00],\n",
              "          [-3.1258626e+00, -3.4687450e+00, -1.2045374e+00,\n",
              "           -4.0196013e+00, -5.8831010e+00, -4.2965469e+00,\n",
              "           -4.1388311e+00]],\n",
              " \n",
              "         [[ 2.1969774e+00,  2.4614549e+00,  2.2314475e+00,\n",
              "            1.8392437e+00,  2.8367062e+00,  4.8600502e+00,\n",
              "            4.2273531e+00],\n",
              "          [ 6.1879644e+00,  5.1792760e+00,  6.1141996e+00,\n",
              "            5.6517797e+00,  8.9979610e+00,  7.5938139e+00,\n",
              "            9.7918644e+00]]],\n",
              " \n",
              " \n",
              "        [[[ 1.5249090e+00,  1.1388919e+00,  8.6903995e-01,\n",
              "            3.0762129e+00,  1.5128503e+00,  3.5204377e+00,\n",
              "            2.4760864e+00],\n",
              "          [ 3.4166217e+00,  3.5930209e+00,  3.1694956e+00,\n",
              "            4.5797420e+00,  4.5271711e+00,  2.8774328e+00,\n",
              "            4.7288942e+00]],\n",
              " \n",
              "         [[-2.3095846e+00, -2.0595703e+00, -3.0093951e+00,\n",
              "           -3.8594103e+00, -4.9681158e+00, -6.4256043e+00,\n",
              "           -5.5345035e+00],\n",
              "          [-6.4306297e+00, -7.0924540e+00, -8.4075985e+00,\n",
              "           -1.0417805e+01, -1.1727266e+01, -1.1196255e+01,\n",
              "           -1.1333830e+01]],\n",
              " \n",
              "         [[-7.0419472e-01,  1.4568675e+00,  3.7946482e+00,\n",
              "            4.8489718e+00,  6.6498446e+00,  9.0224218e+00,\n",
              "            1.1153137e+01],\n",
              "          [ 1.0060651e+01,  1.1998097e+01,  1.5326431e+01,\n",
              "            1.7957514e+01,  1.8323889e+01,  2.0160881e+01,\n",
              "            2.1269085e+01]]],\n",
              " \n",
              " \n",
              "        [[[-2.2360647e-01, -1.3632748e+00, -7.2704530e-01,\n",
              "            2.3558271e-01, -1.0381399e+00,  1.9387857e+00,\n",
              "           -3.3694571e-01],\n",
              "          [ 1.6015106e-01,  1.5284677e+00, -4.8567140e-01,\n",
              "           -1.7770648e-01,  2.1919653e+00,  1.3015286e+00,\n",
              "            1.3877077e+00]],\n",
              " \n",
              "         [[ 1.3688663e+00,  2.6602898e+00,  6.6657305e-01,\n",
              "            4.6554832e+00,  5.7781887e+00,  4.9115267e+00,\n",
              "            4.8446012e+00],\n",
              "          [ 5.1983776e+00,  6.2297459e+00,  6.3848300e+00,\n",
              "            8.4291229e+00,  7.1309576e+00,  1.0395646e+01,\n",
              "            8.5736713e+00]],\n",
              " \n",
              "         [[ 1.2675294e+00,  5.2844582e+00,  5.1331611e+00,\n",
              "            8.9993315e+00,  1.0794343e+01,  1.4039831e+01,\n",
              "            1.5731170e+01],\n",
              "          [ 1.9084715e+01,  2.2191265e+01,  2.3481146e+01,\n",
              "            2.5803375e+01,  2.8632090e+01,  3.0234968e+01,\n",
              "            3.1886738e+01]]]], dtype=float32)>]"
            ]
          },
          "execution_count": 0,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "jds_ab = tfd.JointDistributionSequentialAutoBatched([\n",
        "    tfd.Normal(loc=0., scale=1.),   # m\n",
        "    tfd.Normal(loc=0., scale=1.),   # b\n",
        "    lambda b, m: tfd.Normal(loc=m*X + b, scale=1.) # Y\n",
        "])\n",
        "\n",
        "shaped_sample = jds_ab.sample([5, 3])\n",
        "shaped_sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GLvHMTpnSyvH"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5, 3), dtype=float32, numpy=\n",
              "array([[-28.90071 , -23.052422, -19.851362],\n",
              "       [-19.775568, -25.894997, -20.302256],\n",
              "       [-21.10754 , -23.667885, -20.973007],\n",
              "       [-19.249458, -20.87892 , -20.573763],\n",
              "       [-22.351208, -25.457762, -24.648403]], dtype=float32)>"
            ]
          },
          "execution_count": 0,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "jds_ab.log_prob(shaped_sample)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AI40r2oETnVP"
      },
      "source": [
        "Por outro lado, a `JointDistributionSequential` criada cuidadosamente deixa de funcionar:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tfYkdBIi0wJl"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Incompatible shapes: [5,3,1] vs. [2,7] [Op:Mul]\n"
          ]
        }
      ],
      "source": [
        "jds_ia = tfd.JointDistributionSequential([\n",
        "    tfd.Normal(loc=0., scale=1.),   # m\n",
        "    tfd.Normal(loc=0., scale=1.),   # b\n",
        "    lambda b, m: tfd.Independent(   # Y\n",
        "        tfd.Normal(loc=m[..., tf.newaxis]*X + b[..., tf.newaxis], scale=1.),\n",
        "        reinterpreted_batch_ndims=1)\n",
        "])\n",
        "\n",
        "try:\n",
        "  jds_ia.sample([5, 3])\n",
        "except tf.errors.InvalidArgumentError as e:\n",
        "  print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLERQvFNTwQJ"
      },
      "source": [
        "Para corrigir esse problema, precisamos adicionar um segundo `tf.newaxis` tanto a `m` quanto a `b` para deixar o formato igual, e aumentar `reinterpreted_batch_ndims` para 2 na chamada a `Independent`. Neste caso, deixar o mecanismo de divisão automática em lotes tratar os problemas de formato é mais rápido, fácil e ergonômico."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIgCF6yJXpHE"
      },
      "source": [
        "Novamente, observe que, embora este notebook tenha explorado `JointDistributionSequentialAutoBatched`, as outras variantes de `JointDistribution` têm `AutoBatched` equivalente (para usuários de `JointDistributionCoroutine`, `JointDistributionCoroutineAutoBatched` tem o benefício adicional de não precisar mais especificar nós `Root`; se você nunca tiver usado `JointDistributionCoroutine`, pode ignorar esta afirmação sem problema nenhum)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHacIM0iUW09"
      },
      "source": [
        "### Consideração final"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXAC7GDWUaaY"
      },
      "source": [
        "Neste notebook, apresentamos `JointDistributionSequentialAutoBatched` e detalhamos um exemplo simples. Esperamos que você tenha aprendido alguma coisa sobre os formatos do TFP e a divisão automática em lotes!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "JointDistributionAutoBatched_A_Gentle_Tutorial.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
