{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_nWetWWd_ns"
      },
      "source": [
        "##### Copyright 2023 The TensorFlow Datasets Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "2pHVBk_seED1"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7vSdG6sAIQn"
      },
      "source": [
        "# TFDS para Jax e PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwc5GKHBASdc"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>     <a target=\"_blank\" href=\"https://www.tensorflow.org/datasets/tfless_tfds\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver em TensorFlow.org</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/pt-br/datasets/tfless_tfds.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Executar no Google Colab</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/pt-br/datasets/tfless_tfds.ipynb\"> <img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\"> Ver fonte no GitHub</a>\n",
        "</td>\n",
        "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/pt-br/datasets/tfless_tfds.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Baixar notebook</a>\n",
        "</td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ee074e4"
      },
      "source": [
        "O TFDS sempre foi independente de framework. Por exemplo, você pode carregar facilmente datasets no [formato NumPy](https://www.tensorflow.org/datasets/api_docs/python/tfds/as_numpy) para uso em Jax e PyTorch.\n",
        "\n",
        "O TensorFlow e sua solução de carregamento de dados ([`tf.data`](https://www.tensorflow.org/guide/data)) são cidadãos de primeira classe em nossa API por design.\n",
        "\n",
        "Estendemos o TFDS para oferecer suporte ao carregamento de dados em NumPy puro sem TensorFlow. Isto pode ser conveniente para uso em estruturas de aprendizado de máquina, como Jax e PyTorch. Na verdade, para esses últimos usuários, o TensorFlow pode:\n",
        "\n",
        "- reservar memória GPU/TPU;\n",
        "- aumentar o tempo de construção em CI/CD;\n",
        "- levar um tempo para importar em tempo de execução.\n",
        "\n",
        "O TensorFlow não é mais uma dependência para a leitura de datasets.\n",
        "\n",
        "Os pipelines de aprendizado de máquina precisam de um carregador de dados para carregar exemplos, decodificá-los e apresentá-los ao modelo. Os carregadores de dados usam o paradigma \"fonte/amostrador/carregador\":\n",
        "\n",
        "```\n",
        " TFDS dataset       ┌────────────────┐\n",
        "   on disk          │                │\n",
        "        ┌──────────►│      Data      │\n",
        "|..|... │     |     │     source     ├─┐\n",
        "├──┼────┴─────┤     │                │ │\n",
        "│12│image12   │     └────────────────┘ │    ┌────────────────┐\n",
        "├──┼──────────┤                        │    │                │\n",
        "│13│image13   │                        ├───►│      Data      ├───► ML pipeline\n",
        "├──┼──────────┤                        │    │     loader     │\n",
        "│14│image14   │     ┌────────────────┐ │    │                │\n",
        "├──┼──────────┤     │                │ │    └────────────────┘\n",
        "|..|...       |     │     Index      ├─┘\n",
        "                    │    sampler     │\n",
        "                    │                │\n",
        "                    └────────────────┘\n",
        "```\n",
        "\n",
        "- A fonte de dados é responsável por acessar e decodificar exemplos de um dataset TFDS em tempo real.\n",
        "- O amostrador de índice é responsável por determinar a ordem em que os registros são processados. Isto é importante para implementar transformações globais (por exemplo, embaralhamento global, fragmentação, repetição para múltiplas épocas) antes de ler quaisquer registros.\n",
        "- O carregador de dados orquestra o carregamento aproveitando a fonte de dados e o amostrador de índice. Permite otimização de desempenho (por exemplo, pré-busca, multiprocessamento ou multithreading).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UaWdLA3fQDK2"
      },
      "source": [
        "## Resumo\n",
        "\n",
        "`tfds.data_source` é uma API para criar fontes de dados:\n",
        "\n",
        "1. para prototipagem rápida em pipelines de Python puro;\n",
        "2. para gerenciar pipelines de aprendizagem de máquina com uso intensivo de dados em escala."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLho3l_Vd0a5"
      },
      "source": [
        "## Configuração\n",
        "\n",
        "Vamos instalar e importar as dependências necessárias:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c4COEsqIdvYH"
      },
      "outputs": [],
      "source": [
        "!pip install array_record\n",
        "!pip install tfds-nightly\n",
        "\n",
        "import os\n",
        "os.environ.pop('TFDS_DATA_DIR', None)\n",
        "\n",
        "import tensorflow_datasets as tfds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjEJeF1Id_JM"
      },
      "source": [
        "## Fontes de dados\n",
        "\n",
        "Fontes de dados são basicamente sequências Python. Portanto, elas precisam implementar o seguinte protocolo:\n",
        "\n",
        "```python\n",
        "class RandomAccessDataSource(Protocol):\n",
        "  \"\"\"Interface for datasources where storage supports efficient random access.\"\"\"\n",
        "\n",
        "  def __len__(self) -> int:\n",
        "    \"\"\"Number of records in the dataset.\"\"\"\n",
        "\n",
        "  def __getitem__(self, record_key: int) -> Sequence[Any]:\n",
        "    \"\"\"Retrieves records for the given record_keys.\"\"\"\n",
        "```\n",
        "\n",
        "**Aviso**: a API ainda está em desenvolvimento. Neste ponto em particular, `__getitem__` deve suportar `int` e `list[int]` em entradas. No futuro, provavelmente só suportará `int` conforme[o padrão](https://docs.python.org/3/reference/datamodel.html#object.__getitem__).\n",
        "\n",
        "O formato de arquivo subjacente precisa suportar acesso aleatório eficiente. No momento, o TFDS depende de [`array_record`](https://github.com/google/array_record).\n",
        "\n",
        "[`array_record`](https://github.com/google/array_record) é um novo formato de arquivo derivado de [Riegeli](https://github.com/google/riegeli), atingindo uma nova fronteira de eficiência em entrada e saída. O ArrayRecord suporta leitura paralela, gravação e acesso aleatório por índice de registros. ArrayRecord é baseado em Riegeli e oferece suporte aos mesmos algoritmos de compactação.\n",
        "\n",
        "[`fashion_mnist`](https://www.tensorflow.org/datasets/catalog/fashion_mnist) é um dataset comum para visão computacional. Para recuperar uma fonte de dados baseada em ArrayRecord com TFDS, basta usar:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Tslzx0_eEWx"
      },
      "outputs": [],
      "source": [
        "ds = tfds.data_source('fashion_mnist')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlaRrD_SeHLY"
      },
      "source": [
        "`tfds.data_source` é um wrapper conveniente. É equivalente a:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "duHDKzXReIKB"
      },
      "outputs": [],
      "source": [
        "builder = tfds.builder('fashion_mnist', file_format='array_record')\n",
        "builder.download_and_prepare()\n",
        "ds = builder.as_data_source()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlyIsd0ueKjQ"
      },
      "source": [
        "Isso gera como saída um dicionário de fontes de dados:\n",
        "\n",
        "```\n",
        "{\n",
        "  'train': DataSource(name=fashion_mnist, split='train', decoders=None),\n",
        "  'test': DataSource(name=fashion_mnist, split='test', decoders=None),\n",
        "}\n",
        "```\n",
        "\n",
        "Depois que `download_and_prepare` for executado e você gerar os arquivos de registro, não precisaremos mais do TensorFlow. Tudo acontecerá em Python/NumPy!\n",
        "\n",
        "Vamos verificar isso desinstalando o TensorFlow e recarregando a fonte de dados em outro subprocesso:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mTfSzvaQkSd9"
      },
      "outputs": [],
      "source": [
        "!pip uninstall -y tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3sT5AN7neNT9"
      },
      "outputs": [],
      "source": [
        "%%writefile no_tensorflow.py\n",
        "import os\n",
        "os.environ.pop('TFDS_DATA_DIR', None)\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "try:\n",
        "  import tensorflow as tf\n",
        "except ImportError:\n",
        "  print('No TensorFlow found...')\n",
        "\n",
        "ds = tfds.data_source('fashion_mnist')\n",
        "print('...but the data source could still be loaded...')\n",
        "ds['train'][0]\n",
        "print('...and the records can be decoded.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FxohFdb3kSxh"
      },
      "outputs": [],
      "source": [
        "!python no_tensorflow.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1o8n-BhhePYY"
      },
      "source": [
        "Em versões futuras, também faremos com que a preparação do dataset seja independente do TensorFlow.\n",
        "\n",
        "Uma fonte de dados tem um comprimento:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qtfl17SQeQ7F"
      },
      "outputs": [],
      "source": [
        "len(ds['train'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-UFBu8leSMp"
      },
      "source": [
        "Acessar o primeiro elemento do dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFvT2Sx2eToh"
      },
      "outputs": [],
      "source": [
        "%%timeit\n",
        "ds['train'][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTgZskyZeU_D"
      },
      "source": [
        "...é tão barato quanto acessar qualquer outro elemento. Esta é a definição de [acesso aleatório](https://en.wikipedia.org/wiki/Random_access):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cPJFa6aIeWcY"
      },
      "outputs": [],
      "source": [
        "%%timeit\n",
        "ds['train'][1000]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fs3kafYheX6N"
      },
      "source": [
        "Características agora usam o NumPy DTypes (em vez de TensorFlow DTypes). Você pode inspecionar as características com:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q7x5AEEaeZja"
      },
      "outputs": [],
      "source": [
        "features = tfds.builder('fashion_mnist').info.features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOnLqAZOeiBi"
      },
      "source": [
        "Você encontrará mais informações sobre [as características na nossa documentação](https://www.tensorflow.org/datasets/api_docs/python/tfds/features). Aqui podemos recuperar a forma das imagens e o número de classes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xk8Vc-y0edlb"
      },
      "outputs": [],
      "source": [
        "shape = features['image'].shape\n",
        "num_classes = features['label'].num_classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFh8pytVemsu"
      },
      "source": [
        "## Uso em Python puro\n",
        "\n",
        "Você pode consumir fontes de dados em Python iterando sobre elas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ULjO-JDVefNf"
      },
      "outputs": [],
      "source": [
        "for example in ds['train']:\n",
        "  print(example)\n",
        "  break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZRHZNOkenPb"
      },
      "source": [
        "Se você inspecionar elementos, também perceberá que todas as características já estão decodificadas usando NumPy. Nos bastidores, usamos [OpenCV](https://opencv.org) por padrão porque é rápido. Se você não tiver o OpenCV instalado, usaremos como padrão o [Pillow](python-pillow.org) para obter decodificação de imagem leve e rápida.\n",
        "\n",
        "```\n",
        "{\n",
        "  'image': array([[[0], [0], ..., [0]],\n",
        "                  [[0], [0], ..., [0]]], dtype=uint8),\n",
        "  'label': 2,\n",
        "}\n",
        "```\n",
        "\n",
        "**Observação**: Atualmente, o recurso está disponível apenas para características de `Tensor`, `Image` e `Scalar`. As características de `Audio` e `Video` chegarão em breve. Fique atento!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8kLyK5j1enhc"
      },
      "source": [
        "## Uso com PyTorch\n",
        "\n",
        "O PyTorch usa o paradigma fonte/amostrador/carregador. No Torch, as \"fontes de dados\" são chamadas de \"datasets\". [`torch.utils.data`](https://pytorch.org/docs/stable/data.html) contém todos os detalhes que você precisa saber para construir pipelines de entrada eficientes no Torch.\n",
        "\n",
        "As fontes de dados TFDS podem ser usadas como [datasets em estilo de mapa](https://pytorch.org/docs/stable/data.html#map-style-datasets) comuns.\n",
        "\n",
        "Primeiro instalamos e importamos o Torch:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3aKol1fDeyoK"
      },
      "outputs": [],
      "source": [
        "!pip install torch\n",
        "\n",
        "from tqdm import tqdm\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKdJvYywe0YC"
      },
      "source": [
        "Já definimos fontes de dados para treinamento e teste (respectivamente, `ds['train']` e `ds['test']`). Agora podemos definir o amostrador e os carregadores:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_4P2JIrie23f"
      },
      "outputs": [],
      "source": [
        "batch_size = 128\n",
        "train_sampler = torch.utils.data.RandomSampler(ds['train'], num_samples=5_000)\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    ds['train'],\n",
        "    sampler=train_sampler,\n",
        "    batch_size=batch_size,\n",
        ")\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    ds['test'],\n",
        "    sampler=None,\n",
        "    batch_size=batch_size,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVhofOm4e53O"
      },
      "source": [
        "Usando o PyTorch, treinamos e avaliamos uma regressão logística simples nos primeiros exemplos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HcAmvMa-e42p"
      },
      "outputs": [],
      "source": [
        "class LinearClassifier(torch.nn.Module):\n",
        "  def __init__(self, shape, num_classes):\n",
        "    super(LinearClassifier, self).__init__()\n",
        "    height, width, channels = shape\n",
        "    self.classifier = torch.nn.Linear(height * width * channels, num_classes)\n",
        "\n",
        "  def forward(self, image):\n",
        "    image = image.view(image.size()[0], -1).to(torch.float32)\n",
        "    return self.classifier(image)\n",
        "\n",
        "\n",
        "model = LinearClassifier(shape, num_classes)\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "print('Training...')\n",
        "model.train()\n",
        "for example in tqdm(train_loader):\n",
        "  image, label = example['image'], example['label']\n",
        "  prediction = model(image)\n",
        "  loss = loss_function(prediction, label)\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "print('Testing...')\n",
        "model.eval()\n",
        "num_examples = 0\n",
        "true_positives = 0\n",
        "for example in tqdm(test_loader):\n",
        "  image, label = example['image'], example['label']\n",
        "  prediction = model(image)\n",
        "  num_examples += image.shape[0]\n",
        "  predicted_label = prediction.argmax(dim=1)\n",
        "  true_positives += (predicted_label == label).sum().item()\n",
        "print(f'\\nAccuracy: {true_positives/num_examples * 100:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewKJQpwZe6Ik"
      },
      "source": [
        "## Em breve: uso com JAX\n",
        "\n",
        "Estamos trabalhando em estreita colaboração com o [Grain](https://github.com/google/grain). O Grain é um carregador de dados de código aberto, rápido e determinístico para Python. Então fique ligado!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvLEtCWRvvy8"
      },
      "source": [
        "## Saiba mais\n",
        "\n",
        "Para mais informações, consulte o documento da API [`tfds.data_source`](https://www.tensorflow.org/datasets/api_docs/python/tfds/data_source)."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "tfless_tfds.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
