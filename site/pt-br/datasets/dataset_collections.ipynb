{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIMvgrGMe7ZF"
      },
      "source": [
        "##### Copyright 2022 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "n25wrPRbfCGc"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZyGUj_q7IdfQ"
      },
      "source": [
        "# Coleções de datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LpO0um1nez_q"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>     <a target=\"_blank\" href=\"https://www.tensorflow.org/datasets/dataset_collections\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver em TensorFlow.org</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/pt-br/datasets/dataset_collections.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Executar no Google Colab</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/pt-br/datasets/dataset_collections.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver no GitHub</a>\n",
        "</td>\n",
        "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/pt-br/datasets/dataset_collections.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Baixar notebook</a>\n",
        "</td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p8AFT7CpSzBG"
      },
      "source": [
        "## Visão geral\n",
        "\n",
        "As coleções de datasets fornecem uma maneira simples de agrupar um número arbitrário de datasets TFDS existentes e de realizar operações simples sobre eles.\n",
        "\n",
        "Podem ser úteis, por exemplo, para agrupar diferentes datasets relacionados com a mesma tarefa ou para facilitar o [benchmarking](https://ruder.io/nlp-benchmarking/) de modelos sobre um número fixo de tarefas diferentes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZjxBV9E79Fl"
      },
      "source": [
        "## Configuração\n",
        "\n",
        "Para começar, instale alguns pacotes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1AnxnW65I_FC"
      },
      "outputs": [],
      "source": [
        "# Use tfds-nightly to ensure access to the latest features.\n",
        "!pip install -q tfds-nightly tensorflow\n",
        "!pip install -U conllu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81CCGS5R8GeV"
      },
      "source": [
        "Importe o TensorFlow e o pacote Tensorflow Datasets para seu ambiente de desenvolvimento:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-hxMPT0wIu3f"
      },
      "outputs": [],
      "source": [
        "import pprint\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "at0bMS_jIdjt"
      },
      "source": [
        "As coleções de datasets fornecem uma maneira simples de agrupar um número arbitrário de datasets existentes de do Tensorflow Datasets (TFDS) e de realizar operações simples sobre eles.\n",
        "\n",
        "Podem ser úteis, por exemplo, para agrupar diferentes datasets relacionados com a mesma tarefa ou para facilitar o [benchmarking](https://ruder.io/nlp-benchmarking/) de modelos sobre um número fixo de tarefas diferentes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLvkZBKwIdmL"
      },
      "source": [
        "## Encontre coleções de datasets disponíveis\n",
        "\n",
        "Todos os construtores de coleções de datasets são uma subclasse de `tfds.core.dataset_collection_builder.DatasetCollection`.\n",
        "\n",
        "Para obter a lista de construtores disponíveis, use `tfds.list_dataset_collections()`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R14uGGzKItDz"
      },
      "outputs": [],
      "source": [
        "tfds.list_dataset_collections()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jpcq2AMvI5K1"
      },
      "source": [
        "## Carregue e inspecione uma coleção de datasets\n",
        "\n",
        "A maneira mais fácil de carregar uma coleção de datasets é instanciando um objeto `DatasetCollectionLoader` com o comando [`tfds.dataset_collection`](https://www.tensorflow.org/datasets/api_docs/python/tfds/dataset_collection).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "leIwyl9aI3WA"
      },
      "outputs": [],
      "source": [
        "collection_loader = tfds.dataset_collection('xtreme')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgjomybjY7qI"
      },
      "source": [
        "Versões específicas da coleção de datasets podem ser carregadas seguindo a mesma sintaxe dos datasets TFDS:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pyILkuYJY6ts"
      },
      "outputs": [],
      "source": [
        "collection_loader = tfds.dataset_collection('xtreme:1.0.0')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKOJ6CNQKG9S"
      },
      "source": [
        "Um carregador de coleção de datasets pode exibir informações sobre a coleção:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kwk4PVDoKEAC"
      },
      "outputs": [],
      "source": [
        "collection_loader.print_info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FlLLbwuLLTu"
      },
      "source": [
        "O carregador de datasets também pode exibir informações sobre os datasets contidos na coleção:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IxNJEie6K55T"
      },
      "outputs": [],
      "source": [
        "collection_loader.print_datasets()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGxorc3kLwRj"
      },
      "source": [
        "### Carregando datasets de uma coleção de datasets\n",
        "\n",
        "A maneira mais fácil de carregar um dataset de uma coleção é usar o método `load_dataset` do objeto `DatasetCollectionLoader`, que carrega o dataset necessário chamando [`tfds.load`](https://www.tensorflow.org/datasets/api_docs/python/tfds/load).\n",
        "\n",
        "Esta chamada retorna um dicionário de nomes de divisões e os `tf.data.Dataset` correspondentes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UP1nRj4ILwb6"
      },
      "outputs": [],
      "source": [
        "splits = collection_loader.load_dataset(\"ner\")\n",
        "\n",
        "pprint.pprint(splits)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2spLEgN1Lwmm"
      },
      "source": [
        "`load_dataset` aceita os seguintes parâmetros opcionais:\n",
        "\n",
        "- `split`: qual(is) divisão(ões) carregar. Aceita uma única divisão `(split=\"test\")` ou uma lista de divisões: `(split=[\"train\", \"test\"])`. Se não for especificado, carregará todas as divisões do dataset fornecido.\n",
        "- `loader_kwargs`: argumentos de palavra-chave a serem passados ​​para a função `tfds.load`. Consulte a documentação [`tfds.load`](https://www.tensorflow.org/datasets/api_docs/python/tfds/load) para uma visão geral abrangente das diferentes opções de carregamento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aClLU4eAh2oC"
      },
      "source": [
        "### Carregando múltiplos datasets de uma coleção de datasets\n",
        "\n",
        "A maneira mais fácil de carregar múltiplos datasets de uma coleção é usar o método `load_datasets` do objeto `DatasetCollectionLoader`, que carrega os datasets necessários chamando [`tfds.load`](https://www.tensorflow.org/datasets/api_docs/python/tfds/load).\n",
        "\n",
        "Ele retorna um dicionário de nomes de dataset, cada um deles associado a um dicionário de nomes de divisões e os `tf.data.Dataset` correspondentes, como no exemplo a seguir:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sEG5744Oh2vQ"
      },
      "outputs": [],
      "source": [
        "datasets = collection_loader.load_datasets(['xnli', 'bucc'])\n",
        "\n",
        "pprint.pprint(datasets)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WF0kNqwsiN1Y"
      },
      "source": [
        "O método `load_all_datasets` carrega *todos os* datasets disponíveis para uma determinada coleção:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QX-M3xcjiM35"
      },
      "outputs": [],
      "source": [
        "all_datasets = collection_loader.load_all_datasets()\n",
        "\n",
        "pprint.pprint(all_datasets)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXxVztK5kAHh"
      },
      "source": [
        "O método `load_datasets` aceita os seguintes parâmetros opcionais:\n",
        "\n",
        "- `split`: qual(is) divisão(ões) carregar. Aceita uma única divisão `(split=\"test\")` ou uma lista de divisões: `(split=[\"train\", \"test\"])`. Se não for especificado, carregará todas as divisões do dataset fornecido.\n",
        "- `loader_kwargs`: argumentos de palavra-chave a serem passados ​​para a função `tfds.load`. Consulte a documentação [`tfds.load`](https://www.tensorflow.org/datasets/api_docs/python/tfds/load) para uma visão geral abrangente das diferentes opções de carregamento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4JoreSHfcKZ"
      },
      "source": [
        "### Especificando `loader_kwargs`\n",
        "\n",
        "Os `loader_kwargs` são argumentos de palavra-chave opcionais a serem passados ​​para a função [`tfds.load`](https://www.tensorflow.org/datasets/api_docs/python/tfds/load). Eles podem ser especificados de três maneiras:\n",
        "\n",
        "1. Ao inicializar a classe `DatasetCollectionLoader`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TjgZSIlvfcSP"
      },
      "outputs": [],
      "source": [
        "collection_loader = tfds.dataset_collection('xtreme', loader_kwargs=dict(split='train', batch_size=10, try_gcs=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJcEZl97Xj6Y"
      },
      "source": [
        "1. Usando o método `set_loader_kwargs` de `DatasetCollectioLoader`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zrysflp-k1d3"
      },
      "outputs": [],
      "source": [
        "collection_loader.set_loader_kwargs(dict(split='train', batch_size=10, try_gcs=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ra-ZonhfXkLD"
      },
      "source": [
        "1. Como parâmetros opcionais para os métodos `load_dataset`, `load_datasets` e `load_all_datasets`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rHSu-8GnlGTk"
      },
      "outputs": [],
      "source": [
        "dataset = collection_loader.load_dataset('ner', loader_kwargs=dict(split='train', batch_size=10, try_gcs=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJDGoeAqmJAQ"
      },
      "source": [
        "### Feedback\n",
        "\n",
        "Nos esforçamos continuamente para melhorar o fluxo de trabalho de criação de datasets, mas só poderemos fazê-lo se estivermos cientes dos problemas. Quais problemas ou erros você encontrou ao criar a coleção de datasets? Alguma parte ficou confusa, clichê ou não funcionou de primeira? Compartilhe seu feedback no [GitHub](https://github.com/tensorflow/datasets/issues)."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "dataset_collections.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
