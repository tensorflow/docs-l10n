{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7765UFHoyGx6"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "KsOkK8O69PyT"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZS8z-_KeywY9"
      },
      "source": [
        "# Estimadores predefinidos do TF Lattice"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r61fkA2i9Y3_"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>     <a target=\"_blank\" href=\"https://www.tensorflow.org/lattice/tutorials/canned_estimators\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver em TensorFlow.org</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/pt-br/lattice/tutorials/canned_estimators.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Executar no Google Colab</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/pt-br/lattice/tutorials/canned_estimators.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver fonte no GitHub</a>\n",
        "</td>\n",
        "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/pt-br/lattice/tutorials/canned_estimators.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Baixar notebook</a>\n",
        "</td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQRNKVzRR9pa"
      },
      "source": [
        "> Aviso: os Estimadores não são recomendados para novos códigos. Os Estimadores executam código `v1.Session`, que é mais difícil de escrever corretamente e pode se comportar de forma inesperada, ainda mais quando usado em conjunto com código do TF 2. Os Estimadores são abarcados pelas [garantias de compatibilidade](https://tensorflow.org/guide/versions), mas não recebem mais correções, exceto para vulnerabilidades de segurança. Confira mais detalhes no [guia de migração](https://tensorflow.org/guide/migrate)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCpl-9WDVq9d"
      },
      "source": [
        "## Visão geral\n",
        "\n",
        "Os estimadores predefinidos são maneiras rápidas e fáceis de treinar modelos do TFL para casos de uso típicos. Este guia descreve as etapas necessárias para criar um estimador predefinido do TFL."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x769lI12IZXB"
      },
      "source": [
        "## Configuração"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbBVAR6UeRN5"
      },
      "source": [
        "Instale o pacote do TF Lattice:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bpXjJKpSd3j4"
      },
      "outputs": [],
      "source": [
        "#@test {\"skip\": true}\n",
        "!pip install tensorflow-lattice"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSVl9SHTeSGX"
      },
      "source": [
        "Importe os pacotes necessários:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "both",
        "id": "FbZDk8bIx8ig"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import copy\n",
        "import logging\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sys\n",
        "import tensorflow_lattice as tfl\n",
        "from tensorflow import feature_column as fc\n",
        "logging.disable(sys.maxsize)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svPuM6QNxlrH"
      },
      "source": [
        "Baixe o dataset UCI Statlog (Heart):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "both",
        "id": "j-k1qTR_yvBl"
      },
      "outputs": [],
      "source": [
        "csv_file = tf.keras.utils.get_file(\n",
        "    'heart.csv', 'http://storage.googleapis.com/download.tensorflow.org/data/heart.csv')\n",
        "df = pd.read_csv(csv_file)\n",
        "target = df.pop('target')\n",
        "train_size = int(len(df) * 0.8)\n",
        "train_x = df[:train_size]\n",
        "train_y = target[:train_size]\n",
        "test_x = df[train_size:]\n",
        "test_y = target[train_size:]\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKkAw12SxvGG"
      },
      "source": [
        "Configure os valores padrão usados para treinamento neste guia:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "both",
        "id": "1T6GFI9F6mcG"
      },
      "outputs": [],
      "source": [
        "LEARNING_RATE = 0.01\n",
        "BATCH_SIZE = 128\n",
        "NUM_EPOCHS = 500\n",
        "PREFITTING_NUM_EPOCHS = 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0TGfzhPHzpix"
      },
      "source": [
        "## Colunas de características\n",
        "\n",
        "Como qualquer outro estimador do TF, os dados precisam ser passados para o estimador, o que geralmente ocorre por uma input_fn, e processados usando [FeatureColumns](https://www.tensorflow.org/guide/feature_columns)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DCIUz8apzs0l"
      },
      "outputs": [],
      "source": [
        "# Feature columns.\n",
        "# - age\n",
        "# - sex\n",
        "# - cp        chest pain type (4 values)\n",
        "# - trestbps  resting blood pressure\n",
        "# - chol      serum cholestoral in mg/dl\n",
        "# - fbs       fasting blood sugar > 120 mg/dl\n",
        "# - restecg   resting electrocardiographic results (values 0,1,2)\n",
        "# - thalach   maximum heart rate achieved\n",
        "# - exang     exercise induced angina\n",
        "# - oldpeak   ST depression induced by exercise relative to rest\n",
        "# - slope     the slope of the peak exercise ST segment\n",
        "# - ca        number of major vessels (0-3) colored by flourosopy\n",
        "# - thal      3 = normal; 6 = fixed defect; 7 = reversable defect\n",
        "feature_columns = [\n",
        "    fc.numeric_column('age', default_value=-1),\n",
        "    fc.categorical_column_with_vocabulary_list('sex', [0, 1]),\n",
        "    fc.numeric_column('cp'),\n",
        "    fc.numeric_column('trestbps', default_value=-1),\n",
        "    fc.numeric_column('chol'),\n",
        "    fc.categorical_column_with_vocabulary_list('fbs', [0, 1]),\n",
        "    fc.categorical_column_with_vocabulary_list('restecg', [0, 1, 2]),\n",
        "    fc.numeric_column('thalach'),\n",
        "    fc.categorical_column_with_vocabulary_list('exang', [0, 1]),\n",
        "    fc.numeric_column('oldpeak'),\n",
        "    fc.categorical_column_with_vocabulary_list('slope', [0, 1, 2]),\n",
        "    fc.numeric_column('ca'),\n",
        "    fc.categorical_column_with_vocabulary_list(\n",
        "        'thal', ['normal', 'fixed', 'reversible']),\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hEZstmtT2CA3"
      },
      "source": [
        "Os estimadores predefinidos do TFL usam o tipo de coluna de característica para decidir o tipo de camada de calibração que deve ser utilizado. Usamos uma camada `tfl.layers.PWLCalibration` para colunas de características numéricas e uma camada `tfl.layers.CategoricalCalibration` para colunas de características categóricas.\n",
        "\n",
        "Observe que as colunas de características categóricas não são envolvidas por uma coluna de característica de embedding. Elas são alimentadas diretamente ao estimador."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_LoW_9m5OFL"
      },
      "source": [
        "## Criação da input_fn\n",
        "\n",
        "Como qualquer outro estimador, você pode usar uma input_fn para alimentar os dados no modelo para treinamento e avaliação. Os estimadores do TFL podem calcular automaticamente os quantis das características e usá-los como keypoints de entrada para a camada de calibração PWL. Para isso, eles precisam passar uma `feature_analysis_input_fn`, que é semelhante a input_fn de treinamento, mas com uma única época ou uma subamostra dos dados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lFVy1Efy5NKD"
      },
      "outputs": [],
      "source": [
        "train_input_fn = tf.compat.v1.estimator.inputs.pandas_input_fn(\n",
        "    x=train_x,\n",
        "    y=train_y,\n",
        "    shuffle=False,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    num_epochs=NUM_EPOCHS,\n",
        "    num_threads=1)\n",
        "\n",
        "# feature_analysis_input_fn is used to collect statistics about the input.\n",
        "feature_analysis_input_fn = tf.compat.v1.estimator.inputs.pandas_input_fn(\n",
        "    x=train_x,\n",
        "    y=train_y,\n",
        "    shuffle=False,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    # Note that we only need one pass over the data.\n",
        "    num_epochs=1,\n",
        "    num_threads=1)\n",
        "\n",
        "test_input_fn = tf.compat.v1.estimator.inputs.pandas_input_fn(\n",
        "    x=test_x,\n",
        "    y=test_y,\n",
        "    shuffle=False,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    num_epochs=1,\n",
        "    num_threads=1)\n",
        "\n",
        "# Serving input fn is used to create saved models.\n",
        "serving_input_fn = (\n",
        "    tf.estimator.export.build_parsing_serving_input_receiver_fn(\n",
        "        feature_spec=fc.make_parse_example_spec(feature_columns)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQlzREcm2Wbj"
      },
      "source": [
        "## Configurações de características\n",
        "\n",
        "A calibração de características e as configurações por característica são definidas usando `tfl.configs.FeatureConfig`. As configurações de características incluem restrições de monotonicidade, regularização por recurso (ver `tfl.configs.RegularizerConfig`) e tamanhos de lattice para modelos lattice.\n",
        "\n",
        "Se nenhuma configuração for definida para uma característica de entrada, será usada a configuração padrão em `tfl.config.FeatureConfig`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vD0tNpiO3p9c"
      },
      "outputs": [],
      "source": [
        "# Feature configs are used to specify how each feature is calibrated and used.\n",
        "feature_configs = [\n",
        "    tfl.configs.FeatureConfig(\n",
        "        name='age',\n",
        "        lattice_size=3,\n",
        "        # By default, input keypoints of pwl are quantiles of the feature.\n",
        "        pwl_calibration_num_keypoints=5,\n",
        "        monotonicity='increasing',\n",
        "        pwl_calibration_clip_max=100,\n",
        "        # Per feature regularization.\n",
        "        regularizer_configs=[\n",
        "            tfl.configs.RegularizerConfig(name='calib_wrinkle', l2=0.1),\n",
        "        ],\n",
        "    ),\n",
        "    tfl.configs.FeatureConfig(\n",
        "        name='cp',\n",
        "        pwl_calibration_num_keypoints=4,\n",
        "        # Keypoints can be uniformly spaced.\n",
        "        pwl_calibration_input_keypoints='uniform',\n",
        "        monotonicity='increasing',\n",
        "    ),\n",
        "    tfl.configs.FeatureConfig(\n",
        "        name='chol',\n",
        "        # Explicit input keypoint initialization.\n",
        "        pwl_calibration_input_keypoints=[126.0, 210.0, 247.0, 286.0, 564.0],\n",
        "        monotonicity='increasing',\n",
        "        # Calibration can be forced to span the full output range by clamping.\n",
        "        pwl_calibration_clamp_min=True,\n",
        "        pwl_calibration_clamp_max=True,\n",
        "        # Per feature regularization.\n",
        "        regularizer_configs=[\n",
        "            tfl.configs.RegularizerConfig(name='calib_hessian', l2=1e-4),\n",
        "        ],\n",
        "    ),\n",
        "    tfl.configs.FeatureConfig(\n",
        "        name='fbs',\n",
        "        # Partial monotonicity: output(0) <= output(1)\n",
        "        monotonicity=[(0, 1)],\n",
        "    ),\n",
        "    tfl.configs.FeatureConfig(\n",
        "        name='trestbps',\n",
        "        pwl_calibration_num_keypoints=5,\n",
        "        monotonicity='decreasing',\n",
        "    ),\n",
        "    tfl.configs.FeatureConfig(\n",
        "        name='thalach',\n",
        "        pwl_calibration_num_keypoints=5,\n",
        "        monotonicity='decreasing',\n",
        "    ),\n",
        "    tfl.configs.FeatureConfig(\n",
        "        name='restecg',\n",
        "        # Partial monotonicity: output(0) <= output(1), output(0) <= output(2)\n",
        "        monotonicity=[(0, 1), (0, 2)],\n",
        "    ),\n",
        "    tfl.configs.FeatureConfig(\n",
        "        name='exang',\n",
        "        # Partial monotonicity: output(0) <= output(1)\n",
        "        monotonicity=[(0, 1)],\n",
        "    ),\n",
        "    tfl.configs.FeatureConfig(\n",
        "        name='oldpeak',\n",
        "        pwl_calibration_num_keypoints=5,\n",
        "        monotonicity='increasing',\n",
        "    ),\n",
        "    tfl.configs.FeatureConfig(\n",
        "        name='slope',\n",
        "        # Partial monotonicity: output(0) <= output(1), output(1) <= output(2)\n",
        "        monotonicity=[(0, 1), (1, 2)],\n",
        "    ),\n",
        "    tfl.configs.FeatureConfig(\n",
        "        name='ca',\n",
        "        pwl_calibration_num_keypoints=4,\n",
        "        monotonicity='increasing',\n",
        "    ),\n",
        "    tfl.configs.FeatureConfig(\n",
        "        name='thal',\n",
        "        # Partial monotonicity:\n",
        "        # output(normal) <= output(fixed)\n",
        "        # output(normal) <= output(reversible)        \n",
        "        monotonicity=[('normal', 'fixed'), ('normal', 'reversible')],\n",
        "    ),\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKBULveZ4mr3"
      },
      "source": [
        "## Modelo linear calibrado\n",
        "\n",
        "Para criar um estimador predefinido do TFL, primeiro construa uma configuração de modelo a partir de `tfl.configs`. Um modelo linear calibrado é criado usando a `tfl.configs.CalibratedLinearConfig`. Ela aplica a calibração categórica e por partes nas características de entrada e, em seguida, uma combinação linear e uma calibração linear por partes de saída opcional. Ao usar a calibração de saída ou especificar limites de saída, a camada linear aplicará a média ponderada nas saídas calibradas.\n",
        "\n",
        "Este exemplo cria um modelo linear calibrado nas primeiras 5 características. Usamos `tfl.visualization` para plotar o grafo do modelo com os plots do calibrador."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "diRRozio4sAL"
      },
      "outputs": [],
      "source": [
        "# Model config defines the model structure for the estimator.\n",
        "model_config = tfl.configs.CalibratedLinearConfig(\n",
        "    feature_configs=feature_configs,\n",
        "    use_bias=True,\n",
        "    output_calibration=True,\n",
        "    regularizer_configs=[\n",
        "        # Regularizer for the output calibrator.\n",
        "        tfl.configs.RegularizerConfig(name='output_calib_hessian', l2=1e-4),\n",
        "    ])\n",
        "# A CannedClassifier is constructed from the given model config.\n",
        "estimator = tfl.estimators.CannedClassifier(\n",
        "    feature_columns=feature_columns[:5],\n",
        "    model_config=model_config,\n",
        "    feature_analysis_input_fn=feature_analysis_input_fn,\n",
        "    optimizer=tf.keras.optimizers.legacy.Adam(LEARNING_RATE),\n",
        "    config=tf.estimator.RunConfig(tf_random_seed=42))\n",
        "estimator.train(input_fn=train_input_fn)\n",
        "results = estimator.evaluate(input_fn=test_input_fn)\n",
        "print('Calibrated linear test AUC: {}'.format(results['auc']))\n",
        "saved_model_path = estimator.export_saved_model(estimator.model_dir,\n",
        "                                                serving_input_fn)\n",
        "model_graph = tfl.estimators.get_model_graph(saved_model_path)\n",
        "tfl.visualization.draw_model_graph(model_graph)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWzPM2_p977t"
      },
      "source": [
        "## Modelo lattice calibrado\n",
        "\n",
        "Um modelo lattice calibrado é criado usando <a>tfl.configs.CalibratedLatticeConfig</a>. Esse tipo de modelo aplica calibração linear por partes e categórica nas características de entrada e, em seguida, um modelo lattice e uma calibração linear por partes de saída opcional.\n",
        "\n",
        "Este exemplo cria um modelo lattice calibrado nas primeiras 5 características.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C6EvVpKW4BbC"
      },
      "outputs": [],
      "source": [
        "# This is calibrated lattice model: Inputs are calibrated, then combined\n",
        "# non-linearly using a lattice layer.\n",
        "model_config = tfl.configs.CalibratedLatticeConfig(\n",
        "    feature_configs=feature_configs,\n",
        "    regularizer_configs=[\n",
        "        # Torsion regularizer applied to the lattice to make it more linear.\n",
        "        tfl.configs.RegularizerConfig(name='torsion', l2=1e-4),\n",
        "        # Globally defined calibration regularizer is applied to all features.\n",
        "        tfl.configs.RegularizerConfig(name='calib_hessian', l2=1e-4),\n",
        "    ])\n",
        "# A CannedClassifier is constructed from the given model config.\n",
        "estimator = tfl.estimators.CannedClassifier(\n",
        "    feature_columns=feature_columns[:5],\n",
        "    model_config=model_config,\n",
        "    feature_analysis_input_fn=feature_analysis_input_fn,\n",
        "    optimizer=tf.keras.optimizers.legacy.Adam(LEARNING_RATE),\n",
        "    config=tf.estimator.RunConfig(tf_random_seed=42))\n",
        "estimator.train(input_fn=train_input_fn)\n",
        "results = estimator.evaluate(input_fn=test_input_fn)\n",
        "print('Calibrated lattice test AUC: {}'.format(results['auc']))\n",
        "saved_model_path = estimator.export_saved_model(estimator.model_dir,\n",
        "                                                serving_input_fn)\n",
        "model_graph = tfl.estimators.get_model_graph(saved_model_path)\n",
        "tfl.visualization.draw_model_graph(model_graph)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9494K_ZBKFcm"
      },
      "source": [
        "## Ensemble lattice calibrado\n",
        "\n",
        "Quando o número de características for grande, você pode usar um modelo ensemble, que cria vários lattices menores para subconjuntos de características e calcula a média da saída deles, em vez de só criar um lattice grande. Os modelos lattice ensemble são criados usando <a>tfl.configs.CalibratedLatticeEnsembleConfig</a>. Um modelo ensemble lattice calibrado aplica a calibração linear por partes e categórica na característica de entrada e, em seguida, um ensemble de modelos lattice e uma calibração linear por partes de saída opcional.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjrzziMFKuCB"
      },
      "source": [
        "### Ensemble lattice aleatório\n",
        "\n",
        "A seguinte configuração de modelo usa um subconjunto aleatório de características para cada lattice."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YBSS7dLjKExq"
      },
      "outputs": [],
      "source": [
        "# This is random lattice ensemble model with separate calibration:\n",
        "# model output is the average output of separately calibrated lattices.\n",
        "model_config = tfl.configs.CalibratedLatticeEnsembleConfig(\n",
        "    feature_configs=feature_configs,\n",
        "    num_lattices=5,\n",
        "    lattice_rank=3)\n",
        "# A CannedClassifier is constructed from the given model config.\n",
        "estimator = tfl.estimators.CannedClassifier(\n",
        "    feature_columns=feature_columns,\n",
        "    model_config=model_config,\n",
        "    feature_analysis_input_fn=feature_analysis_input_fn,\n",
        "    optimizer=tf.keras.optimizers.legacy.Adam(LEARNING_RATE),\n",
        "    config=tf.estimator.RunConfig(tf_random_seed=42))\n",
        "estimator.train(input_fn=train_input_fn)\n",
        "results = estimator.evaluate(input_fn=test_input_fn)\n",
        "print('Random ensemble test AUC: {}'.format(results['auc']))\n",
        "saved_model_path = estimator.export_saved_model(estimator.model_dir,\n",
        "                                                serving_input_fn)\n",
        "model_graph = tfl.estimators.get_model_graph(saved_model_path)\n",
        "tfl.visualization.draw_model_graph(model_graph, calibrator_dpi=15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uyO8s97FGJM"
      },
      "source": [
        "### Ensemble lattice aleatório de camada RTL\n",
        "\n",
        "A seguinte configuração de modelo usa uma camada `tfl.layers.RTL` que utiliza um subconjunto aleatório de características para cada lattice. Ressaltamos que `tfl.layers.RTL` só é compatível com as restrições de monotonicidade, precisa apresentar o mesmo tamanho de lattice para todas as características e não pode ter regularização por característica. Observe que o uso de uma camada `tfl.layers.RTL` permite escalar para ensembles muito maiores em comparação com o uso de instâncias `tfl.layers.Lattice`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8v7dKg-FF7iz"
      },
      "outputs": [],
      "source": [
        "# Make sure our feature configs have the same lattice size, no per-feature\n",
        "# regularization, and only monotonicity constraints.\n",
        "rtl_layer_feature_configs = copy.deepcopy(feature_configs)\n",
        "for feature_config in rtl_layer_feature_configs:\n",
        "  feature_config.lattice_size = 2\n",
        "  feature_config.unimodality = 'none'\n",
        "  feature_config.reflects_trust_in = None\n",
        "  feature_config.dominates = None\n",
        "  feature_config.regularizer_configs = None\n",
        "# This is RTL layer ensemble model with separate calibration:\n",
        "# model output is the average output of separately calibrated lattices.\n",
        "model_config = tfl.configs.CalibratedLatticeEnsembleConfig(\n",
        "    lattices='rtl_layer',\n",
        "    feature_configs=rtl_layer_feature_configs,\n",
        "    num_lattices=5,\n",
        "    lattice_rank=3)\n",
        "# A CannedClassifier is constructed from the given model config.\n",
        "estimator = tfl.estimators.CannedClassifier(\n",
        "    feature_columns=feature_columns,\n",
        "    model_config=model_config,\n",
        "    feature_analysis_input_fn=feature_analysis_input_fn,\n",
        "    optimizer=tf.keras.optimizers.legacy.Adam(LEARNING_RATE),\n",
        "    config=tf.estimator.RunConfig(tf_random_seed=42))\n",
        "estimator.train(input_fn=train_input_fn)\n",
        "results = estimator.evaluate(input_fn=test_input_fn)\n",
        "print('Random ensemble test AUC: {}'.format(results['auc']))\n",
        "saved_model_path = estimator.export_saved_model(estimator.model_dir,\n",
        "                                                serving_input_fn)\n",
        "model_graph = tfl.estimators.get_model_graph(saved_model_path)\n",
        "tfl.visualization.draw_model_graph(model_graph, calibrator_dpi=15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSXEaYAULRvf"
      },
      "source": [
        "### Ensemble lattice do Crystals\n",
        "\n",
        "O TFL também fornece um algoritmo de arranjo de características heurístico chamado [Crystals](https://papers.nips.cc/paper/6377-fast-and-flexible-monotonic-functions-with-ensembles-of-lattices). Primeiro, o algoritmo Crystals treina um modelo de *prefitting* que estima as interações de características por partes. Em seguida, ele arranja o ensemble final para que as características com mais interações não lineares fiquem nos mesmos lattices.\n",
        "\n",
        "Para modelos Crystals, você também precisará fornecer uma `prefitting_input_fn` que é usada para treinar o modelo de prefitting, conforme descrito acima. O modelo de prefitting não precisa ser totalmente treinado, então algumas épocas deve ser o suficiente.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FjQKh9saMaFu"
      },
      "outputs": [],
      "source": [
        "prefitting_input_fn = tf.compat.v1.estimator.inputs.pandas_input_fn(\n",
        "    x=train_x,\n",
        "    y=train_y,\n",
        "    shuffle=False,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    num_epochs=PREFITTING_NUM_EPOCHS,\n",
        "    num_threads=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVnZpwX8MtPi"
      },
      "source": [
        "Em seguida, você pode criar um modelo Crystal ao definir `lattice='crystals'` na configuração do modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f4awRMDe-eMv"
      },
      "outputs": [],
      "source": [
        "# This is Crystals ensemble model with separate calibration: model output is\n",
        "# the average output of separately calibrated lattices.\n",
        "model_config = tfl.configs.CalibratedLatticeEnsembleConfig(\n",
        "    feature_configs=feature_configs,\n",
        "    lattices='crystals',\n",
        "    num_lattices=5,\n",
        "    lattice_rank=3)\n",
        "# A CannedClassifier is constructed from the given model config.\n",
        "estimator = tfl.estimators.CannedClassifier(\n",
        "    feature_columns=feature_columns,\n",
        "    model_config=model_config,\n",
        "    feature_analysis_input_fn=feature_analysis_input_fn,\n",
        "    # prefitting_input_fn is required to train the prefitting model.\n",
        "    prefitting_input_fn=prefitting_input_fn,\n",
        "    optimizer=tf.keras.optimizers.legacy.Adam(LEARNING_RATE),\n",
        "    prefitting_optimizer=tf.keras.optimizers.legacy.Adam(LEARNING_RATE),\n",
        "    config=tf.estimator.RunConfig(tf_random_seed=42))\n",
        "estimator.train(input_fn=train_input_fn)\n",
        "results = estimator.evaluate(input_fn=test_input_fn)\n",
        "print('Crystals ensemble test AUC: {}'.format(results['auc']))\n",
        "saved_model_path = estimator.export_saved_model(estimator.model_dir,\n",
        "                                                serving_input_fn)\n",
        "model_graph = tfl.estimators.get_model_graph(saved_model_path)\n",
        "tfl.visualization.draw_model_graph(model_graph, calibrator_dpi=15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Isb2vyLAVBM1"
      },
      "source": [
        "Você pode plotar os calibradores de características com mais detalhes usando o módulo `tfl.visualization`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DJPaREuWS2sg"
      },
      "outputs": [],
      "source": [
        "_ = tfl.visualization.plot_feature_calibrator(model_graph, \"age\")\n",
        "_ = tfl.visualization.plot_feature_calibrator(model_graph, \"restecg\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "canned_estimators.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
