{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdeKOEkv1Fe8"
      },
      "source": [
        "##### Copyright 2021 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "c2jyGuiG1gHr"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLsMb4vqY244"
      },
      "source": [
        "참고: 이 예제는 Jupyter 스타일 노트북에서 바로 실행할 수 있으며 설정이 필요하지 않습니다. \"Google Colab에서 실행\"을 클릭하세요.\n",
        "\n",
        "<div class=\"devsite-table-wrapper\"><table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "<td>     <a target=\"_blank\" href=\"https://www.tensorflow.org/tfx/tutorials/model_analysis/tfma_basic\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">TensorFlow.org에서 보기</a>\n",
        "</td>\n",
        "<td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/ko/tfx/tutorials/model_analysis/tfma_basic.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Google Colab에서 실행</a>\n",
        "</td>\n",
        "<td><a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/ko/tfx/tutorials/model_analysis/tfma_basic.ipynb\"><img width=\"32px\" src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">GitHub에서 소스 보기</a></td>\n",
        "<td><a target=\"_blank\" href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/ko/tfx/tutorials/model_analysis/tfma_basic.ipynb\"> <img width=\"32px\" src=\"https://www.tensorflow.org/images/download_logo_32px.png\">노트북 다운로드</a></td>\n",
        "</table></div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YuSYVbwEYNHw"
      },
      "source": [
        "# TensorFlow 모델 분석\n",
        "\n",
        "***TensorFlow Extended(TFX)의 주요 구성 요소 예***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPt5BHTwy_0F"
      },
      "source": [
        "[TensorFlow Model Analysis(TFMA)](https://www.tensorflow.org/tfx/guide/tfma)는 다양한 데이터 조각에서 모델 평가를 수행하기 위한 라이브러리입니다. TFMA는 [Apache Beam](https://beam.apache.org/documentation/programming-guide/)을 사용하여 대량의 데이터에 대해 분산된 방식으로 계산을 수행합니다.\n",
        "\n",
        "이 예제 colab 노트북은 TFMA를 사용하여 데이터세트의 특성과 관련하여 모델의 성능을 조사하고 시각화하는 방법을 보여줍니다. 이전에 훈련한 모델을 사용하고 이제 결과를 만져볼 수 있습니다! 학습한 모델은 [Chicago Taxi 예제](https://github.com/tensorflow/tfx/tree/master/tfx/examples/chicago_taxi_pipeline)를 위한 것이었고, 이를 위해 시카고 시에서 공개한 [Taxi Trips 데이터세트](https://data.cityofchicago.org/Transportation/Taxi-Trips/wrvz-psew)가 사용됩니다. [BigQuery UI](https://bigquery.cloud.google.com/dataset/bigquery-public-data:chicago_taxi_trips)에서 전체 데이터세트를 살펴보세요.\n",
        "\n",
        "모델러 및 개발자로서 이 데이터가 어떻게 사용되는지, 그리고 모델의 예측이 초래할 수 있는 잠재적인 이점과 피해에 대해 생각해보세요. 이와 같은 모델은 사회적 편견과 불균형을 강화시킬 수 있습니다. 기능이 해결하려는 문제와 관련이 있습니까? 아니면 편견을 유발합니까? 자세한 내용은 <a target=\"_blank\" href=\"https://developers.google.com/machine-learning/fairness-overview/\">ML 공정성</a>에 대해 읽어보세요.\n",
        "\n",
        "참고: TFMA 및 TFMA가 Apache Beam에서 작동하는 방식을 이해하려면 Apache Beam 자체에 대해 조금은 알아야 합니다. <a target=\"_blank\" href=\"https://beam.apache.org/documentation/programming-guide/\">Beam 프로그래밍 가이드</a>는 이를 위한 좋은 출발점입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fnm6Mj3vTGLm"
      },
      "source": [
        "데이터세트의 열은 다음과 같습니다.\n",
        "\n",
        "<table>\n",
        "<tr>\n",
        "<td>pickup_community_area</td>\n",
        "<td>fare</td>\n",
        "<td>trip_start_month</td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>trip_start_hour</td>\n",
        "<td>trip_start_day</td>\n",
        "<td>trip_start_timestamp</td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>pickup_latitude</td>\n",
        "<td>pickup_longitude</td>\n",
        "<td>dropoff_latitude</td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>dropoff_longitude</td>\n",
        "<td>trip_miles</td>\n",
        "<td>pickup_census_tract</td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>dropoff_census_tract</td>\n",
        "<td>payment_type</td>\n",
        "<td>company</td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>trip_seconds</td>\n",
        "<td>dropoff_community_area</td>\n",
        "<td>tips</td>\n",
        "</tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7-ouHFnWAsu"
      },
      "source": [
        "## Jupyter 확장 프로그램 설치하기\n",
        "\n",
        "참고: 로컬 Jupyter 노트북에서 실행 중인 경우 Jupyter를 실행하기 전에 이러한 Jupyter 확장 프로그램을 환경에 설치해야 합니다.\n",
        "\n",
        "```bash\n",
        "jupyter nbextension enable --py widgetsnbextension --sys-prefix\n",
        "jupyter nbextension install --py --symlink tensorflow_model_analysis --sys-prefix\n",
        "jupyter nbextension enable --py tensorflow_model_analysis --sys-prefix\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZj-impiAD_l"
      },
      "source": [
        "## TensorFlow Model Analysis(TFMA) 설치하기\n",
        "\n",
        "이것은 모든 종속성을 가져오고 1분 정도 걸립니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8X32Q_lIKYxH"
      },
      "outputs": [],
      "source": [
        "# Upgrade pip to the latest, and install TFMA.\n",
        "!pip install -U pip\n",
        "!pip install tensorflow-model-analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7121_u1LO5W"
      },
      "source": [
        "**이제 아래 셀을 실행하기 전에 런타임을 다시 시작해야 합니다.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SA2E343NAMRF"
      },
      "outputs": [],
      "source": [
        "# This setup was tested with TF 2.5 and TFMA 0.31 (using colab), but it should\n",
        "# also work with the latest release.\n",
        "import sys\n",
        "\n",
        "# Confirm that we're using Python 3\n",
        "assert sys.version_info.major==3, 'This notebook must be run using Python 3.'\n",
        "\n",
        "import tensorflow as tf\n",
        "print('TF version: {}'.format(tf.__version__))\n",
        "import apache_beam as beam\n",
        "print('Beam version: {}'.format(beam.__version__))\n",
        "import tensorflow_model_analysis as tfma\n",
        "print('TFMA version: {}'.format(tfma.__version__))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_aD7n5eECydb"
      },
      "source": [
        "**참고: 계속하기 전에 위의 출력에 오류가 없어야 합니다. 여전히 오류가 보이면 설치를 다시 실행하세요. 또한 다음 단계로 이동하기 전에 런타임/커널을 다시 시작해야 합니다.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RptgLn2RYuK3"
      },
      "source": [
        "## 파일 로드하기\n",
        "\n",
        "필요한 모든 것이 포함된 tar 파일을 다운로드합니다. 여기에는 다음이 포함됩니다.\n",
        "\n",
        "- 훈련 및 평가 데이터세트\n",
        "- 데이터 스키마\n",
        "- 저장된 모델(keras 및 estimator) 및 eval 저장된 모델(estimator) 훈련 및 제공"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K4QXVIM7iglN"
      },
      "outputs": [],
      "source": [
        "# Download the tar file from GCP and extract it\n",
        "import io, os, tempfile\n",
        "TAR_NAME = 'saved_models-2.2'\n",
        "BASE_DIR = tempfile.mkdtemp()\n",
        "DATA_DIR = os.path.join(BASE_DIR, TAR_NAME, 'data')\n",
        "MODELS_DIR = os.path.join(BASE_DIR, TAR_NAME, 'models')\n",
        "SCHEMA = os.path.join(BASE_DIR, TAR_NAME, 'schema.pbtxt')\n",
        "OUTPUT_DIR = os.path.join(BASE_DIR, 'output')\n",
        "\n",
        "!curl -O https://storage.googleapis.com/artifacts.tfx-oss-public.appspot.com/datasets/{TAR_NAME}.tar\n",
        "!tar xf {TAR_NAME}.tar\n",
        "!mv {TAR_NAME} {BASE_DIR}\n",
        "!rm {TAR_NAME}.tar\n",
        "\n",
        "print(\"Here's what we downloaded:\")\n",
        "!ls -R {BASE_DIR}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xa7ZDV1MycO"
      },
      "source": [
        "## 스키마 구문 분석하기\n",
        "\n",
        "다운로드한 항목 중에는 [TensorFlow Data Validation](https://www.tensorflow.org/tfx/data_validation/)에서 생성한 데이터 스키마가 있습니다. 이제 TFMA와 함께 사용할 수 있도록 이 스키마 구문을 분석해 보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uW5eB4TPcwFw"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from google.protobuf import text_format\n",
        "from tensorflow.python.lib.io import file_io\n",
        "from tensorflow_metadata.proto.v0 import schema_pb2\n",
        "from tensorflow.core.example import example_pb2\n",
        "\n",
        "schema = schema_pb2.Schema()\n",
        "contents = file_io.read_file_to_string(SCHEMA)\n",
        "schema = text_format.Parse(contents, schema)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UP3yuJxfNXRL"
      },
      "source": [
        "## 스키마를 사용하여 TFRecord 생성하기\n",
        "\n",
        "TFMA에 데이터세트에 대한 액세스 권한을 부여해야 하므로 TFRecords 파일을 생성하겠습니다. 스키마를 사용하여 이 파일을 생성할 수 있는데, 각 특성에 대한 올바른 유형을 제공하기 때문입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8-wud3fPczl6"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "\n",
        "datafile = os.path.join(DATA_DIR, 'eval', 'data.csv')\n",
        "reader = csv.DictReader(open(datafile, 'r'))\n",
        "examples = []\n",
        "for line in reader:\n",
        "  example = example_pb2.Example()\n",
        "  for feature in schema.feature:\n",
        "    key = feature.name\n",
        "    if feature.type == schema_pb2.FLOAT:\n",
        "      example.features.feature[key].float_list.value[:] = (\n",
        "          [float(line[key])] if len(line[key]) > 0 else [])\n",
        "    elif feature.type == schema_pb2.INT:\n",
        "      example.features.feature[key].int64_list.value[:] = (\n",
        "          [int(line[key])] if len(line[key]) > 0 else [])\n",
        "    elif feature.type == schema_pb2.BYTES:\n",
        "      example.features.feature[key].bytes_list.value[:] = (\n",
        "          [line[key].encode('utf8')] if len(line[key]) > 0 else [])\n",
        "  # Add a new column 'big_tipper' that indicates if tips was > 20% of the fare. \n",
        "  # TODO(b/157064428): Remove after label transformation is supported for Keras.\n",
        "  big_tipper = float(line['tips']) > float(line['fare']) * 0.2\n",
        "  example.features.feature['big_tipper'].float_list.value[:] = [big_tipper]\n",
        "  examples.append(example)\n",
        "\n",
        "tfrecord_file = os.path.join(BASE_DIR, 'train_data.rio')\n",
        "with tf.io.TFRecordWriter(tfrecord_file) as writer:\n",
        "  for example in examples:\n",
        "    writer.write(example.SerializeToString())\n",
        "\n",
        "!ls {tfrecord_file}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fp8Ub7GTXH3j"
      },
      "source": [
        "## TFMA 설정 및 실행하기\n",
        "\n",
        "TFMA는 TF keras 모델, 일반 TF2 서명 API 기반 모델, TF estimator 기반 모델을 비롯한 다양한 모델 유형을 지원합니다. [get_started](https://www.tensorflow.org/tfx/model_analysis/get_started) 가이드에 지원되는 모델 유형의 전체 목록과 제한 사항이 나와 있습니다. 이 예제에서는 [`EvalSavedModel`](https://www.tensorflow.org/tfx/model_analysis/eval_saved_model)로 저장된 estimator 기반 모델뿐만 아니라 keras 기반 모델을 구성하는 방법을 보여줄 것입니다. 다른 구성 예는 [FAQ](https://www.tensorflow.org/tfx/model_analysis/faq)를 참조하세요.\n",
        "\n",
        "TFMA는 훈련 시간에 사용된 메트릭(예: 내장 메트릭)뿐만 아니라 모델이 TFMA 구성 설정의 일부로 저장된 후 정의된 메트릭의 계산도 지원합니다. keras [설정](https://www.tensorflow.org/tfx/model_analysis/setup)의 경우, 구성의 일부로 메트릭 및 플롯을 수동으로 추가하는 방법을 보여줄 것입니다(지원되는 메트릭 및 플롯에 대한 정보는 [메트릭 가이드](https://www.tensorflow.org/tfx/model_analysis/metrics) 참조). Estimator 설정을 위해 모델과 함께 저장된 내장 메트릭을 사용합니다. 또한 설정에는 다음 섹션에서 자세히 설명하는 여러 슬라이싱 사양도 포함되어 있습니다.\n",
        "\n",
        "[`tfma.EvalConfig`](https://www.tensorflow.org/tfx/model_analysis/api_docs/python/tfma/EvalConfig) 및 [`tfma.EvalSharedModel`](https://www.tensorflow.org/tfx/model_analysis/api_docs/python/tfma/EvalSharedModel)을 만든 후, [`tfma.run_model_analysis`](https://www.tensorflow.org/tfx/model_analysis/api_docs/python/tfma/run_model_analysis)를 사용하여 TFMA를 실행할 수 있습니다. 그러면 나중에 메트릭과 플롯을 렌더링하는 데 사용할 수 있는 [`tfma.EvalResult`](https://www.tensorflow.org/tfx/model_analysis/api_docs/python/tfma/EvalResult)가 생성됩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgC7NdCatT8y"
      },
      "source": [
        "### Keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PLJxcjpjfwkx"
      },
      "outputs": [],
      "source": [
        "import tensorflow_model_analysis as tfma\n",
        "\n",
        "# Setup tfma.EvalConfig settings\n",
        "keras_eval_config = text_format.Parse(\"\"\"\n",
        "  ## Model information\n",
        "  model_specs {\n",
        "    # For keras (and serving models) we need to add a `label_key`.\n",
        "    label_key: \"big_tipper\"\n",
        "  }\n",
        "\n",
        "  ## Post training metric information. These will be merged with any built-in\n",
        "  ## metrics from training.\n",
        "  metrics_specs {\n",
        "    metrics { class_name: \"ExampleCount\" }\n",
        "    metrics { class_name: \"BinaryAccuracy\" }\n",
        "    metrics { class_name: \"BinaryCrossentropy\" }\n",
        "    metrics { class_name: \"AUC\" }\n",
        "    metrics { class_name: \"AUCPrecisionRecall\" }\n",
        "    metrics { class_name: \"Precision\" }\n",
        "    metrics { class_name: \"Recall\" }\n",
        "    metrics { class_name: \"MeanLabel\" }\n",
        "    metrics { class_name: \"MeanPrediction\" }\n",
        "    metrics { class_name: \"Calibration\" }\n",
        "    metrics { class_name: \"CalibrationPlot\" }\n",
        "    metrics { class_name: \"ConfusionMatrixPlot\" }\n",
        "    # ... add additional metrics and plots ...\n",
        "  }\n",
        "\n",
        "  ## Slicing information\n",
        "  slicing_specs {}  # overall slice\n",
        "  slicing_specs {\n",
        "    feature_keys: [\"trip_start_hour\"]\n",
        "  }\n",
        "  slicing_specs {\n",
        "    feature_keys: [\"trip_start_day\"]\n",
        "  }\n",
        "  slicing_specs {\n",
        "    feature_values: {\n",
        "      key: \"trip_start_month\"\n",
        "      value: \"1\"\n",
        "    }\n",
        "  }\n",
        "  slicing_specs {\n",
        "    feature_keys: [\"trip_start_hour\", \"trip_start_day\"]\n",
        "  }\n",
        "\"\"\", tfma.EvalConfig())\n",
        "\n",
        "# Create a tfma.EvalSharedModel that points at our keras model.\n",
        "keras_model_path = os.path.join(MODELS_DIR, 'keras', '2')\n",
        "keras_eval_shared_model = tfma.default_eval_shared_model(\n",
        "    eval_saved_model_path=keras_model_path,\n",
        "    eval_config=keras_eval_config)\n",
        "\n",
        "keras_output_path = os.path.join(OUTPUT_DIR, 'keras')\n",
        "\n",
        "# Run TFMA\n",
        "keras_eval_result = tfma.run_model_analysis(\n",
        "    eval_shared_model=keras_eval_shared_model,\n",
        "    eval_config=keras_eval_config,\n",
        "    data_location=tfrecord_file,\n",
        "    output_path=keras_output_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMtoi_FpthQL"
      },
      "source": [
        "### Estimator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6MJg42JVtjjj"
      },
      "outputs": [],
      "source": [
        "import tensorflow_model_analysis as tfma\n",
        "\n",
        "# Setup tfma.EvalConfig settings\n",
        "estimator_eval_config = text_format.Parse(\"\"\"\n",
        "  ## Model information\n",
        "  model_specs {\n",
        "    # To use EvalSavedModel set `signature_name` to \"eval\".\n",
        "    signature_name: \"eval\"\n",
        "  }\n",
        "\n",
        "  ## Post training metric information. These will be merged with any built-in\n",
        "  ## metrics from training.\n",
        "  metrics_specs {\n",
        "    metrics { class_name: \"ConfusionMatrixPlot\" }\n",
        "    # ... add additional metrics and plots ...\n",
        "  }\n",
        "\n",
        "  ## Slicing information\n",
        "  slicing_specs {}  # overall slice\n",
        "  slicing_specs {\n",
        "    feature_keys: [\"trip_start_hour\"]\n",
        "  }\n",
        "  slicing_specs {\n",
        "    feature_keys: [\"trip_start_day\"]\n",
        "  }\n",
        "  slicing_specs {\n",
        "    feature_values: {\n",
        "      key: \"trip_start_month\"\n",
        "      value: \"1\"\n",
        "    }\n",
        "  }\n",
        "  slicing_specs {\n",
        "    feature_keys: [\"trip_start_hour\", \"trip_start_day\"]\n",
        "  }\n",
        "\"\"\", tfma.EvalConfig())\n",
        "\n",
        "# Create a tfma.EvalSharedModel that points at our eval saved model.\n",
        "estimator_base_model_path = os.path.join(\n",
        "    MODELS_DIR, 'estimator', 'eval_model_dir')\n",
        "estimator_model_path = os.path.join(\n",
        "    estimator_base_model_path, os.listdir(estimator_base_model_path)[0])\n",
        "estimator_eval_shared_model = tfma.default_eval_shared_model(\n",
        "    eval_saved_model_path=estimator_model_path,\n",
        "    eval_config=estimator_eval_config)\n",
        "\n",
        "estimator_output_path = os.path.join(OUTPUT_DIR, 'estimator')\n",
        "\n",
        "# Run TFMA\n",
        "estimator_eval_result = tfma.run_model_analysis(\n",
        "    eval_shared_model=estimator_eval_shared_model,\n",
        "    eval_config=estimator_eval_config,\n",
        "    data_location=tfrecord_file,\n",
        "    output_path=estimator_output_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0khNBC9FlEO"
      },
      "source": [
        "## 메트릭 및 플롯 시각화하기\n",
        "\n",
        "이제 평가를 실행했으므로 TFMA를 사용하여 시각화를 살펴보겠습니다. 다음 예제에서는 keras 모델에서 평가를 실행한 결과를 시각화합니다. Estimator 기반 모델을 보려면 `estimator_eval_result` 변수를 가리키도록 `eval_result`를 업데이트합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XFY0BqGtGkJ0"
      },
      "outputs": [],
      "source": [
        "eval_result = keras_eval_result\n",
        "# eval_result = estimator_eval_result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSl9qyTCbBKR"
      },
      "source": [
        "### 메트릭 렌더링하기\n",
        "\n",
        "메트릭을 보려면 [`tfma.view.render_slicing_metrics`](https://www.tensorflow.org/tfx/model_analysis/api_docs/python/tfma/view/render_slicing_metrics)를 사용합니다.\n",
        "\n",
        "기본적으로, 보기는 `Overall` 조각을 표시합니다. 특정 조각을 보려면 열 이름을 사용하거나(`slicing_column`을 설정하여) [`tfma.SlicingSpec`](https://www.tensorflow.org/tfx/model_analysis/api_docs/python/tfma/SlicingSpec)를 제공할 수 있습니다.\n",
        "\n",
        "메트릭 시각화는 다음 상호 작용을 지원합니다.\n",
        "\n",
        "- 클릭하고 끌어서 이동\n",
        "- 스크롤하여 확대/축소\n",
        "- 마우스 오른쪽 버튼을 클릭하여 보기 재설정\n",
        "- 원하는 데이터 포인트 위로 마우스를 가져가 자세한 정보 표시\n",
        "- 하단의 선택 항목을 사용하여 네 가지 유형의 보기 중에서 선택\n",
        "\n",
        "예를 들어, 이전 `slicing_specs`의 `trip_start_hour` 특성을 살펴보도록 `slicing_column`을 설정합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hJ5_UMnWYmaE"
      },
      "outputs": [],
      "source": [
        "tfma.view.render_slicing_metrics(eval_result, slicing_column='trip_start_hour')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJuxvGCpn4yF"
      },
      "source": [
        "### 조각 개요\n",
        "\n",
        "기본 시각화는 조각 수가 적을 때 **조각 개요**이며, 각 조각에 대한 메트릭 값을 보여줍니다. 위에서 `trip_start_hour`를 선택했기 때문에 각 시간에 대한 정확도 및 AUC와 같은 메트릭을 보여주며, 이를 통해 다른 시간이 아닌 특정 시간에 관련된 문제를 찾을 수 있습니다.\n",
        "\n",
        "위의 시각화에서:\n",
        "\n",
        "- 열 머리글을 클릭하여 `trip_start_hours` 특성인 특성 열을 정렬해봅니다.\n",
        "- 정밀도를 기준으로 정렬해보고 **예제에서 일부 시간의 정밀도가 0인 것에 주목하세요. 이것은 문제를 나타낼 수 있습니다.**\n",
        "\n",
        "차트를 사용하여 조각에서 여러 메트릭을 선택하고 표시할 수도 있습니다.\n",
        "\n",
        "- \"표시\" 메뉴에서 여러 메트릭을 선택해봅니다.\n",
        "- \"표시\" 메뉴에서 리콜을 선택해봅니다. **예제에서 일부 시간에 대한 리콜이 0인 것에 주목하세요. 이것은 문제를 나타낼 수 있습니다.**\n",
        "\n",
        "더 적은 수의 예제 또는 \"가중치\"를 사용하여 조각을 필터링하도록 임계값을 설정할 수도 있습니다. 최소한의 예를 입력하거나 조각을 사용할 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQT-1Ckcnd_7"
      },
      "source": [
        "### 메트릭 히스토그램\n",
        "\n",
        "이 보기는 또한 조각 수가 많을 때 기본 보기인 대체 시각화로 **메트릭 히스토그램**을 지원합니다. 결과는 버킷으로 나뉘며 조각 수/총 가중치/둘 모두를 시각화할 수 있습니다. 열 머리글을 클릭하여 열을 정렬할 수 있습니다. 가중치가 작은 조각은 임계값을 설정하여 필터링할 수 있습니다. 회색 밴드를 끌어서 추가 필터링을 적용할 수 있습니다. 범위를 재설정하려면 밴드를 두 번 클릭합니다. 필터링을 사용하여 시각화 및 메트릭 테이블에서 이상 값을 제거할 수도 있습니다. 기어 아이콘을 클릭하여 선형 스케일 대신 로그 스케일로 전환합니다.\n",
        "\n",
        "- 시각화 메뉴에서 \"메트릭 히스토그램\"을 선택해봅니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSnqI6Esb1XM"
      },
      "source": [
        "### 더 많은 조각\n",
        "\n",
        "처음의 `tfma.EvalConfig`는 `slicing_specs`의 전체 목록을 생성했으며 `tfma.view.render_slicing_metrics`로 전달된 조각 정보를 업데이트하여 이를 시각화할 수 있습니다. 여기에서는 `trip_start_day` 조각(요일)을 선택합니다. <strong data-md-type=\"double_emphasis\">`trip_start_day`를 <code data-md-type=\"codespan\">trip_start_month</code>로 변경하고 다시 렌더링하여 다른 조각을 살펴봅니다.</strong>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "355wqvY3yBod"
      },
      "outputs": [],
      "source": [
        "tfma.view.render_slicing_metrics(eval_result, slicing_column='trip_start_day')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PsXM0NYGeajg"
      },
      "source": [
        "TFMA는 또한 특성의 조합을 분석하기 위한 특성 교차 생성도 지원합니다. 원래 설정에서는 교차 `trip_start_hour` 및 `trip_start_day`를 생성했습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k7vbFS1Me1SH"
      },
      "outputs": [],
      "source": [
        "tfma.view.render_slicing_metrics(\n",
        "    eval_result,\n",
        "    slicing_spec=tfma.SlicingSpec(\n",
        "        feature_keys=['trip_start_hour', 'trip_start_day']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmeODqrUfJw2"
      },
      "source": [
        "두 열을 교차하면 많은 조합이 생성됩니다! **정오에 시작하는 이동**만 살펴보도록 교차를 좁혀 보겠습니다. 그런 다음 시각화에서 `binary_accuracy`를 선택합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kdvBNfcHfRWg"
      },
      "outputs": [],
      "source": [
        "tfma.view.render_slicing_metrics(\n",
        "    eval_result,\n",
        "    slicing_spec=tfma.SlicingSpec(\n",
        "        feature_keys=['trip_start_day'], feature_values={'trip_start_hour': '12'}))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8acksU33KMm"
      },
      "source": [
        "### 플롯 렌더링하기\n",
        "\n",
        "사후 훈련 `metric_specs`로 `tfma.EvalConfig`에 추가된 플롯은 [`tfma.view.render_plot`](https://www.tensorflow.org/tfx/model_analysis/api_docs/python/tfma/view/render_plot)을 사용하여 표시할 수 있습니다.\n",
        "\n",
        "메트릭과 마찬가지로 플롯을 조각별로 볼 수 있습니다. 메트릭과 달리 특정 조각 값에 대한 플롯만 표시할 수 있으므로 `tfma.SlicingSpec`을 사용해야 하며 조각 특성 이름과 값을 모두 지정해야 합니다. 조각이 제공되지 않으면 `Overall` 조각에 대한 플롯이 사용됩니다.\n",
        "\n",
        "아래 예에서는 `trip_start_hour:1` 조각에 대해 계산된 `CalibrationPlot` 및 `ConfusionMatrixPlot` 플롯을 표시합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X4TCKjGw3S-a"
      },
      "outputs": [],
      "source": [
        "tfma.view.render_plot(\n",
        "    eval_result,\n",
        "    tfma.SlicingSpec(feature_values={'trip_start_hour': '1'}))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "meRvFkKcPbux"
      },
      "source": [
        "## 시간 경과에 따른 모델 성능 추적하기\n",
        "\n",
        "훈련 데이터세트는 모델 훈련에 사용되며, 바라건데 테스트 데이터세트와 프로덕션에서 모델로 전송될 데이터를 대표할 것입니다. 그러나 추론 요청의 데이터는 훈련 데이터와 동일하게 유지될 수 있지만 많은 경우 모델의 성능이 변경될 정도로 충분히 변하기 시작합니다.\n",
        "\n",
        "즉, 변화를 인식하고 이에 대응할 수 있도록 지속적으로 모델의 성능을 모니터링하고 측정해야 합니다. TFMA가 어떤 도움을 주는지 살펴보겠습니다.\n",
        "\n",
        "3개의 다른 모델 실행을 로드하고 TFMA를 사용하여 [`render_time_series`](https://www.tensorflow.org/tfx/model_analysis/api_docs/python/tfma/view/render_time_series)에서 어떻게 비교되는지 살펴보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zJYUOjmFfuPy"
      },
      "outputs": [],
      "source": [
        "# Note this re-uses the EvalConfig from the keras setup.\n",
        "\n",
        "# Run eval on each saved model\n",
        "output_paths = []\n",
        "for i in range(3):\n",
        "  # Create a tfma.EvalSharedModel that points at our saved model.\n",
        "  eval_shared_model = tfma.default_eval_shared_model(\n",
        "      eval_saved_model_path=os.path.join(MODELS_DIR, 'keras', str(i)),\n",
        "      eval_config=keras_eval_config)\n",
        "\n",
        "  output_path = os.path.join(OUTPUT_DIR, 'time_series', str(i))\n",
        "  output_paths.append(output_path)\n",
        "\n",
        "  # Run TFMA\n",
        "  tfma.run_model_analysis(eval_shared_model=eval_shared_model,\n",
        "                          eval_config=keras_eval_config,\n",
        "                          data_location=tfrecord_file,\n",
        "                          output_path=output_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsO-gqCRK0ar"
      },
      "source": [
        "먼저, 어제 모델을 훈련하고 배포했다고 가정하고 이제는 오늘 들어오는 새 데이터에 대해 모델이 어떻게 작동하는지 보려고 합니다. 시각화는 AUC를 표시하는 것으로 시작됩니다. UI에서 다음을 수행할 수 있습니다.\n",
        "\n",
        "- \"메트릭 시리즈 추가\" 메뉴를 사용하여 다른 메트릭을 추가합니다.\n",
        "- x를 클릭하여 원하지 않는 그래프를 닫습니다.\n",
        "- 자세한 내용을 보려면 데이터 포인트(그래프의 선분 끝) 위로 마우스를 가져갑니다.\n",
        "\n",
        "참고: 메트릭 시리즈 차트에서 X축은 검사 중인 모델 실행의 모델 디렉터리 이름입니다. 이러한 이름 자체는 의미가 없습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KjEws8T0cDm9"
      },
      "outputs": [],
      "source": [
        "eval_results_from_disk = tfma.load_eval_results(output_paths[:2])\n",
        "\n",
        "tfma.view.render_time_series(eval_results_from_disk)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQ7kZxESN9Bx"
      },
      "source": [
        "이제 또 하루가 지나갔다고 가정하고 이전 이틀과 비교하여 오늘 들어오는 새로운 데이터에서 어떻게 작동하는지 보려고합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjQmlXMmLwHf"
      },
      "outputs": [],
      "source": [
        "eval_results_from_disk = tfma.load_eval_results(output_paths)\n",
        "\n",
        "tfma.view.render_time_series(eval_results_from_disk)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1jpShgQxlVL"
      },
      "source": [
        "## 모델 검증\n",
        "\n",
        "TFMA는 동시에 여러 모델을 평가하도록 구성할 수 있습니다. 일반적으로, 이것은 새로운 모델을 기준선(예: 현재 제공되는 모델)과 비교하여 메트릭(예: AUC 등)의 어떤 성능 차이가 기준선과 관련이 있는지 확인하기 위해 수행됩니다. [임계값](https://www.tensorflow.org/tfx/model_analysis/api_docs/python/tfma/MetricThreshold)이 구성되면 TFMA는 성능이 기대와 일치하는지 여부를 나타내는 [`tfma.ValidationResult`](https://www.tensorflow.org/tfx/model_analysis/api_docs/python/tfma/ValidationResult) 레코드를 생성합니다.\n",
        "\n",
        "keras 평가를 다시 구성하여 후보와 기준선의 두 모델을 비교해 보겠습니다. 또한 AUC 메트릭에서 [`tmfa.MetricThreshold`](https://www.tensorflow.org/tfx/model_analysis/api_docs/python/tfma/MetricThreshold)를 설정하여 기준선에 대비한 후보의 성능을 검증합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kkatdR6Y1-4G"
      },
      "outputs": [],
      "source": [
        "# Setup tfma.EvalConfig setting\n",
        "eval_config_with_thresholds = text_format.Parse(\"\"\"\n",
        "  ## Model information\n",
        "  model_specs {\n",
        "    name: \"candidate\"\n",
        "    # For keras we need to add a `label_key`.\n",
        "    label_key: \"big_tipper\"\n",
        "  }\n",
        "  model_specs {\n",
        "    name: \"baseline\"\n",
        "    # For keras we need to add a `label_key`.\n",
        "    label_key: \"big_tipper\"\n",
        "    is_baseline: true\n",
        "  }\n",
        "\n",
        "  ## Post training metric information\n",
        "  metrics_specs {\n",
        "    metrics { class_name: \"ExampleCount\" }\n",
        "    metrics { class_name: \"BinaryAccuracy\" }\n",
        "    metrics { class_name: \"BinaryCrossentropy\" }\n",
        "    metrics {\n",
        "      class_name: \"AUC\"\n",
        "      threshold {\n",
        "        # Ensure that AUC is always > 0.9\n",
        "        value_threshold {\n",
        "          lower_bound { value: 0.9 }\n",
        "        }\n",
        "        # Ensure that AUC does not drop by more than a small epsilon\n",
        "        # e.g. (candidate - baseline) > -1e-10 or candidate > baseline - 1e-10\n",
        "        change_threshold {\n",
        "          direction: HIGHER_IS_BETTER\n",
        "          absolute { value: -1e-10 }\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "    metrics { class_name: \"AUCPrecisionRecall\" }\n",
        "    metrics { class_name: \"Precision\" }\n",
        "    metrics { class_name: \"Recall\" }\n",
        "    metrics { class_name: \"MeanLabel\" }\n",
        "    metrics { class_name: \"MeanPrediction\" }\n",
        "    metrics { class_name: \"Calibration\" }\n",
        "    metrics { class_name: \"CalibrationPlot\" }\n",
        "    metrics { class_name: \"ConfusionMatrixPlot\" }\n",
        "    # ... add additional metrics and plots ...\n",
        "  }\n",
        "\n",
        "  ## Slicing information\n",
        "  slicing_specs {}  # overall slice\n",
        "  slicing_specs {\n",
        "    feature_keys: [\"trip_start_hour\"]\n",
        "  }\n",
        "  slicing_specs {\n",
        "    feature_keys: [\"trip_start_day\"]\n",
        "  }\n",
        "  slicing_specs {\n",
        "    feature_keys: [\"trip_start_month\"]\n",
        "  }\n",
        "  slicing_specs {\n",
        "    feature_keys: [\"trip_start_hour\", \"trip_start_day\"]\n",
        "  }\n",
        "\"\"\", tfma.EvalConfig())\n",
        "\n",
        "# Create tfma.EvalSharedModels that point at our keras models.\n",
        "candidate_model_path = os.path.join(MODELS_DIR, 'keras', '2')\n",
        "baseline_model_path = os.path.join(MODELS_DIR, 'keras', '1')\n",
        "eval_shared_models = [\n",
        "  tfma.default_eval_shared_model(\n",
        "      model_name=tfma.CANDIDATE_KEY,\n",
        "      eval_saved_model_path=candidate_model_path,\n",
        "      eval_config=eval_config_with_thresholds),\n",
        "  tfma.default_eval_shared_model(\n",
        "      model_name=tfma.BASELINE_KEY,\n",
        "      eval_saved_model_path=baseline_model_path,\n",
        "      eval_config=eval_config_with_thresholds),\n",
        "]\n",
        "\n",
        "validation_output_path = os.path.join(OUTPUT_DIR, 'validation')\n",
        "\n",
        "# Run TFMA\n",
        "eval_result_with_validation = tfma.run_model_analysis(\n",
        "    eval_shared_models,\n",
        "    eval_config=eval_config_with_thresholds,\n",
        "    data_location=tfrecord_file,\n",
        "    output_path=validation_output_path,\n",
        "    schema=schema)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "siF6npd3IfJq"
      },
      "source": [
        "기준선에 대비해 하나 이상의 모델로 평가를 실행할 때 TFMA는 평가 중에 계산된 모든 메트릭에 대해 diff 메트릭을 자동으로 추가합니다. 이러한 메트릭은 해당 메트릭의 이름을 따서 명명되지만 메트릭 이름에 `_diff`가 붙습니다.\n",
        "\n",
        "실행으로 생성된 메트릭을 살펴보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yGIw9TDuJ7wn"
      },
      "outputs": [],
      "source": [
        "tfma.view.render_time_series(eval_result_with_validation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIsehm_V4oKU"
      },
      "source": [
        "이제 검증 검사의 출력을 살펴보겠습니다. 검증 결과를 보려면 [`tfma.load_validator_result`](https://www.tensorflow.org/tfx/model_analysis/api_docs/python/tfma/load_validation_result)를 사용합니다. 이 예의 경우 AUC가 임계값 미만이므로 검사에 실패합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "48EdSTUW5eE1"
      },
      "outputs": [],
      "source": [
        "validation_result = tfma.load_validation_result(validation_output_path)\n",
        "print(validation_result.validation_ok)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tghWegsjhpkt"
      },
      "source": [
        "# Copyright © 2020 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "rSGJWC5biBiG"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvsmelXGasty"
      },
      "source": [
        "참고: 이 사이트는 원 출처인 시카고 시의 공식 웹 사이트 www.cityofchicago.org를 바탕으로 수정된 데이터를 사용하는 애플리케이션을 제공합니다. 시카고 시는 이 사이트에서 제공되는 데이터의 내용, 정확성, 적시성 또는 완전성에 대해 어떠한 주장도하지 않습니다. 이 사이트에서 제공되는 데이터는 언제든지 변경될 수 있습니다. 이 사이트에서 제공하는 데이터는 자신의 책임 하에 사용되는 것으로 이해됩니다."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "tfma_basic.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
