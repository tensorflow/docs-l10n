{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdeKOEkv1Fe8"
      },
      "source": [
        "##### Copyright 2021 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "c2jyGuiG1gHr"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23R0Z9RojXYW"
      },
      "source": [
        "# TFX 에스티 메이터 컴포넌트 튜토리얼\n",
        "\n",
        "***TensorFlow Extended (TFX)에 대한 구성 요소 별 소개***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LidV2qsXm4XC"
      },
      "source": [
        "참고 : 설정이 필요하지 않은 Colab 노트북에서이 가이드를 실행하는 것이 좋습니다. \"Google Colab에서 실행\"을 클릭하십시오.\n",
        "\n",
        "<div class=\"devsite-table-wrapper\"><table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "<td><a target=\"_blank\" href=\"https://www.tensorflow.org/tfx/tutorials/tfx/components\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">TensorFlow.org에서보기</a></td>\n",
        "<td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/ko/tfx/tutorials/tfx/components.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Google Colab에서 실행</a></td>\n",
        "<td><a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/ko/tfx/tutorials/tfx/components.ipynb\"><img width=\"32px\" src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">GitHub에서 소스보기</a></td>\n",
        "<td><a target=\"_blank\" href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/ko/tfx/tutorials/tfx/components.ipynb\"><img width=\"32px\" src=\"https://www.tensorflow.org/images/download_logo_32px.png\">노트북 다운로드</a></td>\n",
        "</table></div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBbTLeWmWs8q"
      },
      "source": [
        "> 경고: Estimator는 새 코드에 권장되지 않습니다. Estimator는 `v1.Session` 스타일 코드를 실행하며, 이 코드는 올바르게 작성하기가 좀 더 어렵고 특히 TF 2 코드와 결합할 경우 예기치 않게 작동할 수 있습니다. Estimator는 [호환성 보장](https://tensorflow.org/guide/versions)이 적용되지만 보안 취약점 외에는 수정 사항이 제공되지 않습니다. 자세한 내용은 [마이그레이션 가이드](https://tensorflow.org/guide/migrate)를 참조하세요."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAD1tLoTm_QS"
      },
      "source": [
        "이 Colab 기반 자습서는 TensorFlow Extended (TFX)의 각 기본 제공 구성 요소를 대화식으로 안내합니다.\n",
        "\n",
        "데이터 수집에서 모델 푸시, 제공에 이르기까지 엔드 투 엔드 머신 러닝 파이프 라인의 모든 단계를 다룹니다.\n",
        "\n",
        "완료되면이 노트북의 콘텐츠를 TFX 파이프 라인 소스 코드로 자동으로 내보낼 수 있으며 Apache Airflow 및 Apache Beam으로 조정할 수 있습니다.\n",
        "\n",
        "참고 :이 노트북 및 관련 API는 **실험적** 이며 현재 개발 중입니다. 기능, 동작 및 표현의 주요 변경이 예상됩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfSQ-kX-MLEr"
      },
      "source": [
        "## 배경 설명\n",
        "\n",
        "이 노트북은 Jupyter / Colab 환경에서 TFX를 사용하는 방법을 보여줍니다. 여기에서는 대화 형 노트북에서 Chicago Taxi 예제를 살펴 봅니다.\n",
        "\n",
        "대화 형 노트북에서 작업하는 것은 TFX 파이프 라인의 구조에 익숙해지는 데 유용한 방법입니다. 경량 개발 환경으로 자체 파이프 라인을 개발할 때도 유용하지만 대화 형 노트북이 오케스트레이션되는 방식과 메타 데이터 아티팩트에 액세스하는 방식에 차이가 있다는 점을 알고 있어야합니다.\n",
        "\n",
        "### 관현악법\n",
        "\n",
        "TFX의 프로덕션 배포에서는 Apache Airflow, Kubeflow Pipelines 또는 Apache Beam과 같은 오케 스트레이터를 사용하여 TFX 구성 요소의 사전 정의 된 파이프 라인 그래프를 오케스트레이션합니다. 대화 형 노트북에서 노트북 자체는 노트북 셀을 실행할 때 각 TFX 구성 요소를 실행하는 오케 스트레이터입니다.\n",
        "\n",
        "### 메타 데이터\n",
        "\n",
        "TFX의 프로덕션 배포에서 ML Metadata (MLMD) API를 통해 메타 데이터에 액세스합니다. MLMD는 MySQL 또는 SQLite와 같은 데이터베이스에 메타 데이터 속성을 저장하고 파일 시스템과 같은 영구 저장소에 메타 데이터 페이로드를 저장합니다. 대화 형 노트북에서 속성과 페이로드는 모두 Jupyter 노트북 또는 Colab 서버 `/tmp`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GivNBNYjb3b"
      },
      "source": [
        "## Setup\n",
        "\n",
        "먼저 필요한 패키지를 설치 및 가져오고 경로를 설정하고 데이터를 다운로드합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDl_6DkqJ-pG"
      },
      "source": [
        "### Pip 업그레이드\n",
        "\n",
        "로컬에서 실행할 때 시스템에서 Pip을 업그레이드하지 않으려면 Colab에서 실행 중인지 확인하십시오. 물론 로컬 시스템은 별도로 업그레이드 할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFhBChv4J_PD"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  import colab\n",
        "  !pip install --upgrade pip\n",
        "except:\n",
        "  pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZOYTt1RW4TK"
      },
      "source": [
        "### TFX 설치\n",
        "\n",
        "**참고 : Google Colab에서는 패키지 업데이트로 인해이 셀을 처음 실행할 때 런타임을 다시 시작해야합니다 (런타임&gt; 런타임 다시 시작 ...).**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S4SQA7Q5nej3"
      },
      "outputs": [],
      "source": [
        "!pip install tfx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szPQ2MDYPZ5j"
      },
      "source": [
        "## 런타임을 다시 시작 했습니까?\n",
        "\n",
        "Google Colab을 사용하는 경우 위의 셀을 처음 실행할 때 런타임을 다시 시작해야합니다 (런타임&gt; 런타임 다시 시작 ...). 이는 Colab이 패키지를로드하는 방식 때문입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-ePgV0Lj68Q"
      },
      "source": [
        "### 패키지 가져오기\n",
        "\n",
        "표준 TFX 컴포넌트 클래스를 포함하여 필요한 패키지를 가져옵니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YIqpWK9efviJ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pprint\n",
        "import tempfile\n",
        "import urllib\n",
        "\n",
        "import absl\n",
        "import tensorflow as tf\n",
        "import tensorflow_model_analysis as tfma\n",
        "tf.get_logger().propagate = False\n",
        "pp = pprint.PrettyPrinter()\n",
        "\n",
        "from tfx import v1 as tfx\n",
        "from tfx.orchestration.experimental.interactive.interactive_context import InteractiveContext\n",
        "\n",
        "%load_ext tfx.orchestration.experimental.interactive.notebook_extensions.skip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCZTHRy0N1D6"
      },
      "source": [
        "라이브러리 버전을 확인해 봅시다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eZ4K18_DN2D8"
      },
      "outputs": [],
      "source": [
        "print('TensorFlow version: {}'.format(tf.__version__))\n",
        "print('TFX version: {}'.format(tfx.__version__))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufJKQ6OvkJlY"
      },
      "source": [
        "### 파이프 라인 경로 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ad5JLpKbf6sN"
      },
      "outputs": [],
      "source": [
        "# This is the root directory for your TFX pip package installation.\n",
        "_tfx_root = tfx.__path__[0]\n",
        "\n",
        "# This is the directory containing the TFX Chicago Taxi Pipeline example.\n",
        "_taxi_root = os.path.join(_tfx_root, 'examples/chicago_taxi_pipeline')\n",
        "\n",
        "# This is the path where your model will be pushed for serving.\n",
        "_serving_model_dir = os.path.join(\n",
        "    tempfile.mkdtemp(), 'serving_model/taxi_simple')\n",
        "\n",
        "# Set up logging.\n",
        "absl.logging.set_verbosity(absl.logging.INFO)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2cMMAbSkGfX"
      },
      "source": [
        "### 예제 데이터 다운로드\n",
        "\n",
        "TFX 파이프 라인에서 사용할 예제 데이터 세트를 다운로드합니다.\n",
        "\n",
        "우리가 사용하는 데이터 세트는 시카고시에서 발표 한 [Taxi Trips 데이터 세트입니다.](https://data.cityofchicago.org/Transportation/Taxi-Trips/wrvz-psew) 이 데이터 세트의 열은 다음과 같습니다.\n",
        "\n",
        "<table>\n",
        "<tr>\n",
        "<td>pickup_community_area</td>\n",
        "<td>요금</td>\n",
        "<td>trip_start_month</td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>trip_start_hour</td>\n",
        "<td>trip_start_day</td>\n",
        "<td>trip_start_timestamp</td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>픽업 _ 위도</td>\n",
        "<td>픽업 _ 경도</td>\n",
        "<td>dropoff_latitude</td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>dropoff_longitude</td>\n",
        "<td>trip_miles</td>\n",
        "<td>Pickup_census_tract</td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>dropoff_census_tract</td>\n",
        "<td>지불 _ 유형</td>\n",
        "<td>회사</td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>trip_seconds</td>\n",
        "<td>dropoff_community_area</td>\n",
        "<td>팁</td>\n",
        "</tr>\n",
        "</table>\n",
        "\n",
        "이 데이터 세트를 사용하여 여행 `tips` 을 예측하는 모델을 구축합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BywX6OUEhAqn"
      },
      "outputs": [],
      "source": [
        "_data_root = tempfile.mkdtemp(prefix='tfx-data')\n",
        "DATA_PATH = 'https://raw.githubusercontent.com/tensorflow/tfx/master/tfx/examples/chicago_taxi_pipeline/data/simple/data.csv'\n",
        "_data_filepath = os.path.join(_data_root, \"data.csv\")\n",
        "urllib.request.urlretrieve(DATA_PATH, _data_filepath)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blZC1sIQOWfH"
      },
      "source": [
        "CSV 파일을 빠르게 살펴보십시오."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c5YPeLPFOXaD"
      },
      "outputs": [],
      "source": [
        "!head {_data_filepath}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QioyhunCImwE"
      },
      "source": [
        "*면책 조항 :이 사이트는 시카고시의 공식 웹 사이트 인 www.cityofchicago.org의 원본 소스에서 사용하기 위해 수정 된 데이터를 사용하는 애플리케이션을 제공합니다. 시카고시는이 사이트에서 제공되는 데이터의 내용, 정확성, 적시성 또는 완전성에 대해 어떠한 주장도하지 않습니다. 이 사이트에서 제공되는 데이터는 언제든지 변경 될 수 있습니다. 이 사이트에서 제공하는 데이터는 자신의 책임하에 사용되는 것으로 이해됩니다.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ONIE_hdkPS4"
      },
      "source": [
        "### InteractiveContext 만들기\n",
        "\n",
        "마지막으로이 노트북에서 TFX 구성 요소를 대화식으로 실행할 수있는 InteractiveContext를 만듭니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Rh6K5sUf9dd"
      },
      "outputs": [],
      "source": [
        "# Here, we create an InteractiveContext using default parameters. This will\n",
        "# use a temporary directory with an ephemeral ML Metadata database instance.\n",
        "# To use your own pipeline root or database, the optional properties\n",
        "# `pipeline_root` and `metadata_connection_config` may be passed to\n",
        "# InteractiveContext. Calls to InteractiveContext are no-ops outside of the\n",
        "# notebook.\n",
        "context = InteractiveContext()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdQWxfsVkzdJ"
      },
      "source": [
        "## 대화식으로 TFX 구성 요소 실행\n",
        "\n",
        "다음 셀에서는 TFX 구성 요소를 하나씩 만들고 각 구성 요소를 실행하고 출력 아티팩트를 시각화합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9fwt9gQk3BR"
      },
      "source": [
        "### ExampleGen\n",
        "\n",
        "`ExampleGen` 구성 요소는 일반적으로 TFX 파이프 라인의 시작 부분에 있습니다. 그것은 :\n",
        "\n",
        "1. 데이터를 훈련 및 평가 세트로 분할 (기본적으로 2/3 훈련 + 1/3 평가)\n",
        "2. 데이터를 `tf.Example` 형식으로 변환합니다([여기](https://www.tensorflow.org/tutorials/load_data/tfrecord)에서 자세히 알아보기).\n",
        "3. 다른 구성 요소가 액세스 할 수 있도록 `_tfx_root` 디렉토리에 복사하십시오.\n",
        "\n",
        "`ExampleGen` 은 데이터 소스에 대한 경로를 입력으로 사용합니다. 이 경우 다운로드 된 CSV가 포함 된 `_data_root`\n",
        "\n",
        "참고 :이 노트북에서는 구성 요소를 하나씩 인스턴스화하고 `InteractiveContext.run()` 실행할 수 있습니다. `Pipeline` 모든 구성 요소를 사전에 지정하여 오케 스트레이터에 전달할 것입니다 ( [TFX 파이프 라인 구축 가이드 참조](https://www.tensorflow.org/tfx/guide/build_tfx_pipeline) )."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PyXjuMt8f-9u"
      },
      "outputs": [],
      "source": [
        "example_gen = tfx.components.CsvExampleGen(input_base=_data_root)\n",
        "context.run(example_gen)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OqCoZh7KPUm9"
      },
      "source": [
        "`ExampleGen` 의 출력 결과물을 살펴 보겠습니다. 이 구성 요소는 두 가지 아티팩트, 교육 예제 및 평가 예제를 생성합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "880KkTAkPeUg"
      },
      "outputs": [],
      "source": [
        "artifact = example_gen.outputs['examples'].get()[0]\n",
        "print(artifact.split_names, artifact.uri)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6vcbW_wPqvl"
      },
      "source": [
        "처음 세 가지 교육 예제도 살펴볼 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H4XIXjiCPwzQ"
      },
      "outputs": [],
      "source": [
        "# Get the URI of the output artifact representing the training examples, which is a directory\n",
        "train_uri = os.path.join(example_gen.outputs['examples'].get()[0].uri, 'Split-train')\n",
        "\n",
        "# Get the list of files in this directory (all compressed TFRecord files)\n",
        "tfrecord_filenames = [os.path.join(train_uri, name)\n",
        "                      for name in os.listdir(train_uri)]\n",
        "\n",
        "# Create a `TFRecordDataset` to read these files\n",
        "dataset = tf.data.TFRecordDataset(tfrecord_filenames, compression_type=\"GZIP\")\n",
        "\n",
        "# Iterate over the first 3 records and decode them.\n",
        "for tfrecord in dataset.take(3):\n",
        "  serialized_example = tfrecord.numpy()\n",
        "  example = tf.train.Example()\n",
        "  example.ParseFromString(serialized_example)\n",
        "  pp.pprint(example)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2gluYjccf-IP"
      },
      "source": [
        "`ExampleGen` 이 데이터 수집을 완료 했으므로 이제 다음 단계는 데이터 분석입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csM6BFhtk5Aa"
      },
      "source": [
        "### StatisticsGen\n",
        "\n",
        "`StatisticsGen` 구성 요소는 데이터 분석 및 다운 스트림 구성 요소에서 사용하기 위해 데이터 세트에 대한 통계를 계산합니다. [TensorFlow Data Validation](https://www.tensorflow.org/tfx/data_validation/get_started) 라이브러리를 사용합니다.\n",
        "\n",
        "`StatisticsGen` `ExampleGen` 사용하여 방금 수집 한 데이터 세트를 입력으로받습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MAscCCYWgA-9"
      },
      "outputs": [],
      "source": [
        "statistics_gen = tfx.components.StatisticsGen(examples=example_gen.outputs['examples'])\n",
        "context.run(statistics_gen)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLI6cb_5WugZ"
      },
      "source": [
        "`StatisticsGen` 실행이 끝나면 출력 된 통계를 시각화 할 수 있습니다. 다른 플롯으로 놀아보세요!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tLjXy7K6Tp_G"
      },
      "outputs": [],
      "source": [
        "context.show(statistics_gen.outputs['statistics'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLKLTO9Nk60p"
      },
      "source": [
        "### SchemaGen\n",
        "\n",
        "`SchemaGen` 구성 요소는 데이터 통계를 기반으로 스키마를 생성합니다. (스키마는 데이터 세트에있는 기능의 예상 경계, 유형 및 속성을 정의합니다.) 또한 [TensorFlow Data Validation](https://www.tensorflow.org/tfx/data_validation/get_started) 라이브러리를 사용합니다.\n",
        "\n",
        "`SchemaGen` `StatisticsGen` 생성 한 통계를 입력으로 받아 기본적으로 훈련 분할을 살펴 봅니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ygQvZ6hsiQ_J"
      },
      "outputs": [],
      "source": [
        "schema_gen = tfx.components.SchemaGen(\n",
        "    statistics=statistics_gen.outputs['statistics'],\n",
        "    infer_feature_shape=False)\n",
        "context.run(schema_gen)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zi6TxTUKXM6b"
      },
      "source": [
        "`SchemaGen` 실행이 끝나면 생성 된 스키마를 테이블로 시각화 할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ec9vqDXpXeMb"
      },
      "outputs": [],
      "source": [
        "context.show(schema_gen.outputs['schema'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZWWdbA-m7zp"
      },
      "source": [
        "데이터 세트의 각 특성은 속성과 함께 스키마 테이블에 행으로 표시됩니다. 또한 스키마는 도메인으로 표시되는 범주 형 기능이 취하는 모든 값을 캡처합니다.\n",
        "\n",
        "스키마에 대한 자세한 내용 [은 SchemaGen 문서를](https://www.tensorflow.org/tfx/guide/schemagen) 참조하십시오."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1qcUuO9k9f8"
      },
      "source": [
        "### ExampleValidator\n",
        "\n",
        "`ExampleValidator` 구성 요소는 스키마에 정의 된 기대치를 기반으로 데이터의 이상을 감지합니다. [또한 TensorFlow Data Validation](https://www.tensorflow.org/tfx/data_validation/get_started) 라이브러리를 사용합니다.\n",
        "\n",
        "`ExampleValidator` 는 `StatisticsGen` `SchemaGen` 의 스키마를 입력으로받습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XRlRUuGgiXks"
      },
      "outputs": [],
      "source": [
        "example_validator = tfx.components.ExampleValidator(\n",
        "    statistics=statistics_gen.outputs['statistics'],\n",
        "    schema=schema_gen.outputs['schema'])\n",
        "context.run(example_validator)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "855mrHgJcoer"
      },
      "source": [
        "`ExampleValidator` 가 실행을 마치면 이상을 테이블로 시각화 할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TDyAAozQcrk3"
      },
      "outputs": [],
      "source": [
        "context.show(example_validator.outputs['anomalies'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znMoJj60ybZx"
      },
      "source": [
        "anomalies 테이블에서 이상이 없음을 확인할 수 있습니다. 이것이 우리가 분석 한 첫 번째 데이터 세트이고 스키마가 이에 맞게 조정 되었기 때문에 이것이 우리가 기대하는 것입니다. 이 스키마를 검토해야합니다. 예상치 못한 것은 데이터의 이상을 의미합니다. 검토가 완료되면 스키마를 사용하여 향후 데이터를 보호 할 수 있으며 여기에서 생성 된 이상 항목을 사용하여 모델 성능을 디버깅하고 시간이 지남에 따라 데이터가 어떻게 진화하는지 이해하며 데이터 오류를 식별 할 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPViEz5RlA36"
      },
      "source": [
        "### 변환\n",
        "\n",
        "`Transform` 구성 요소는 학습 및 제공 모두를위한 기능 엔지니어링을 수행합니다. [TensorFlow Transform](https://www.tensorflow.org/tfx/transform/get_started) 라이브러리를 사용합니다.\n",
        "\n",
        "`Transform` `ExampleGen` 의 데이터 `SchemaGen` 의 스키마 및 사용자 정의 Transform 코드를 포함하는 모듈을 입력으로받습니다.\n",
        "\n",
        "아래에서 사용자 정의 Transform 코드의 예를 살펴 보겠습니다 (TensorFlow Transform API에 대한 소개 [는 자습서 참조](https://www.tensorflow.org/tfx/tutorials/transform/simple) ). 먼저 기능 엔지니어링을위한 몇 가지 상수를 정의합니다.\n",
        "\n",
        "참고 : `%%writefile` 셀 매직은 셀의 내용을 디스크에 `.py` 이렇게하면 `Transform` 구성 요소가 코드를 모듈로로드 할 수 있습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PuNSiUKb4YJf"
      },
      "outputs": [],
      "source": [
        "_taxi_constants_module_file = 'taxi_constants.py'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HPjhXuIF4YJh"
      },
      "outputs": [],
      "source": [
        "%%writefile {_taxi_constants_module_file}\n",
        "\n",
        "# Categorical features are assumed to each have a maximum value in the dataset.\n",
        "MAX_CATEGORICAL_FEATURE_VALUES = [24, 31, 12]\n",
        "\n",
        "CATEGORICAL_FEATURE_KEYS = [\n",
        "    'trip_start_hour', 'trip_start_day', 'trip_start_month',\n",
        "    'pickup_census_tract', 'dropoff_census_tract', 'pickup_community_area',\n",
        "    'dropoff_community_area'\n",
        "]\n",
        "\n",
        "DENSE_FLOAT_FEATURE_KEYS = ['trip_miles', 'fare', 'trip_seconds']\n",
        "\n",
        "# Number of buckets used by tf.transform for encoding each feature.\n",
        "FEATURE_BUCKET_COUNT = 10\n",
        "\n",
        "BUCKET_FEATURE_KEYS = [\n",
        "    'pickup_latitude', 'pickup_longitude', 'dropoff_latitude',\n",
        "    'dropoff_longitude'\n",
        "]\n",
        "\n",
        "# Number of vocabulary terms used for encoding VOCAB_FEATURES by tf.transform\n",
        "VOCAB_SIZE = 1000\n",
        "\n",
        "# Count of out-of-vocab buckets in which unrecognized VOCAB_FEATURES are hashed.\n",
        "OOV_SIZE = 10\n",
        "\n",
        "VOCAB_FEATURE_KEYS = [\n",
        "    'payment_type',\n",
        "    'company',\n",
        "]\n",
        "\n",
        "# Keys\n",
        "LABEL_KEY = 'tips'\n",
        "FARE_KEY = 'fare'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Duj2Ax5z4YJl"
      },
      "source": [
        "다음으로 원시 데이터를 입력으로 받아들이고 모델이 학습 할 수있는 변환 된 기능을 반환 `preprocessing_fn` 을 작성합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4AJ9hBs94YJm"
      },
      "outputs": [],
      "source": [
        "_taxi_transform_module_file = 'taxi_transform.py'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MYmxxx9A4YJn"
      },
      "outputs": [],
      "source": [
        "%%writefile {_taxi_transform_module_file}\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_transform as tft\n",
        "\n",
        "import taxi_constants\n",
        "\n",
        "_DENSE_FLOAT_FEATURE_KEYS = taxi_constants.DENSE_FLOAT_FEATURE_KEYS\n",
        "_VOCAB_FEATURE_KEYS = taxi_constants.VOCAB_FEATURE_KEYS\n",
        "_VOCAB_SIZE = taxi_constants.VOCAB_SIZE\n",
        "_OOV_SIZE = taxi_constants.OOV_SIZE\n",
        "_FEATURE_BUCKET_COUNT = taxi_constants.FEATURE_BUCKET_COUNT\n",
        "_BUCKET_FEATURE_KEYS = taxi_constants.BUCKET_FEATURE_KEYS\n",
        "_CATEGORICAL_FEATURE_KEYS = taxi_constants.CATEGORICAL_FEATURE_KEYS\n",
        "_FARE_KEY = taxi_constants.FARE_KEY\n",
        "_LABEL_KEY = taxi_constants.LABEL_KEY\n",
        "\n",
        "\n",
        "def preprocessing_fn(inputs):\n",
        "  \"\"\"tf.transform's callback function for preprocessing inputs.\n",
        "  Args:\n",
        "    inputs: map from feature keys to raw not-yet-transformed features.\n",
        "  Returns:\n",
        "    Map from string feature key to transformed feature operations.\n",
        "  \"\"\"\n",
        "  outputs = {}\n",
        "  for key in _DENSE_FLOAT_FEATURE_KEYS:\n",
        "    # If sparse make it dense, setting nan's to 0 or '', and apply zscore.\n",
        "    outputs[key] = tft.scale_to_z_score(\n",
        "        _fill_in_missing(inputs[key]))\n",
        "\n",
        "  for key in _VOCAB_FEATURE_KEYS:\n",
        "    # Build a vocabulary for this feature.\n",
        "    outputs[key] = tft.compute_and_apply_vocabulary(\n",
        "        _fill_in_missing(inputs[key]),\n",
        "        top_k=_VOCAB_SIZE,\n",
        "        num_oov_buckets=_OOV_SIZE)\n",
        "\n",
        "  for key in _BUCKET_FEATURE_KEYS:\n",
        "    outputs[key] = tft.bucketize(\n",
        "        _fill_in_missing(inputs[key]), _FEATURE_BUCKET_COUNT)\n",
        "\n",
        "  for key in _CATEGORICAL_FEATURE_KEYS:\n",
        "    outputs[key] = _fill_in_missing(inputs[key])\n",
        "\n",
        "  # Was this passenger a big tipper?\n",
        "  taxi_fare = _fill_in_missing(inputs[_FARE_KEY])\n",
        "  tips = _fill_in_missing(inputs[_LABEL_KEY])\n",
        "  outputs[_LABEL_KEY] = tf.where(\n",
        "      tf.math.is_nan(taxi_fare),\n",
        "      tf.cast(tf.zeros_like(taxi_fare), tf.int64),\n",
        "      # Test if the tip was > 20% of the fare.\n",
        "      tf.cast(\n",
        "          tf.greater(tips, tf.multiply(taxi_fare, tf.constant(0.2))), tf.int64))\n",
        "\n",
        "  return outputs\n",
        "\n",
        "\n",
        "def _fill_in_missing(x):\n",
        "  \"\"\"Replace missing values in a SparseTensor.\n",
        "  Fills in missing values of `x` with '' or 0, and converts to a dense tensor.\n",
        "  Args:\n",
        "    x: A `SparseTensor` of rank 2.  Its dense shape should have size at most 1\n",
        "      in the second dimension.\n",
        "  Returns:\n",
        "    A rank 1 tensor where missing values of `x` have been filled in.\n",
        "  \"\"\"\n",
        "  if not isinstance(x, tf.sparse.SparseTensor):\n",
        "    return x\n",
        "\n",
        "  default_value = '' if x.dtype == tf.string else 0\n",
        "  return tf.squeeze(\n",
        "      tf.sparse.to_dense(\n",
        "          tf.SparseTensor(x.indices, x.values, [x.dense_shape[0], 1]),\n",
        "          default_value),\n",
        "      axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgbmZr3sgbWW"
      },
      "source": [
        "이제이 기능 엔지니어링 코드를 `Transform` 구성 요소에 전달하고이를 실행하여 데이터를 변환합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jHfhth_GiZI9"
      },
      "outputs": [],
      "source": [
        "transform = tfx.components.Transform(\n",
        "    examples=example_gen.outputs['examples'],\n",
        "    schema=schema_gen.outputs['schema'],\n",
        "    module_file=os.path.abspath(_taxi_transform_module_file))\n",
        "context.run(transform)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwAwb4rARRQ2"
      },
      "source": [
        "`Transform` 의 출력 결과물을 살펴 보겠습니다. 이 구성 요소는 두 가지 유형의 출력을 생성합니다.\n",
        "\n",
        "- `transform_graph` 는 전처리 작업을 수행 할 수있는 그래프입니다 (이 그래프는 제공 및 평가 모델에 포함됨).\n",
        "- `transformed_examples` 는 전처리 된 훈련 및 평가 데이터를 나타냅니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SClrAaEGR1O5"
      },
      "outputs": [],
      "source": [
        "transform.outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyFkBd9AR1sy"
      },
      "source": [
        "`transform_graph` 아티팩트를 살펴보십시오. 세 개의 하위 디렉터리를 포함하는 디렉터리를 가리 킵니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5tRw4DneR3i7"
      },
      "outputs": [],
      "source": [
        "train_uri = transform.outputs['transform_graph'].get()[0].uri\n",
        "os.listdir(train_uri)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fqV54CIR6Pu"
      },
      "source": [
        "`transformed_metadata` 하위 디렉토리에는 전처리 된 데이터의 스키마가 포함됩니다. `transform_fn` 하위 디렉토리에는 실제 전처리 그래프가 포함되어 있습니다. `metadata` 하위 디렉토리에는 원본 데이터의 스키마가 포함됩니다.\n",
        "\n",
        "처음 세 가지 변형 된 예를 살펴볼 수도 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pwbW2zPKR_S4"
      },
      "outputs": [],
      "source": [
        "# Get the URI of the output artifact representing the transformed examples, which is a directory\n",
        "train_uri = os.path.join(transform.outputs['transformed_examples'].get()[0].uri, 'Split-train')\n",
        "\n",
        "# Get the list of files in this directory (all compressed TFRecord files)\n",
        "tfrecord_filenames = [os.path.join(train_uri, name)\n",
        "                      for name in os.listdir(train_uri)]\n",
        "\n",
        "# Create a `TFRecordDataset` to read these files\n",
        "dataset = tf.data.TFRecordDataset(tfrecord_filenames, compression_type=\"GZIP\")\n",
        "\n",
        "# Iterate over the first 3 records and decode them.\n",
        "for tfrecord in dataset.take(3):\n",
        "  serialized_example = tfrecord.numpy()\n",
        "  example = tf.train.Example()\n",
        "  example.ParseFromString(serialized_example)\n",
        "  pp.pprint(example)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_b_V6eN4f69"
      },
      "source": [
        "`Transform` 구성 요소가 데이터를 특성으로 변환 한 후 다음 단계는 모델을 학습하는 것입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBJFtnl6lCg9"
      },
      "source": [
        "### Trainer\n",
        "\n",
        "`Trainer` 구성 요소는 TensorFlow에서 정의한 모델을 학습시킵니다 (Estimator API 또는 [`model_to_estimator`](https://www.tensorflow.org/api_docs/python/tf/keras/estimator/model_to_estimator) ).\n",
        "\n",
        "`Trainer` `SchemaGen` 의 스키마 `Transform` 의 변환 된 데이터 및 그래프, 학습 매개 변수, 사용자 정의 모델 코드가 포함 된 모듈을 입력으로받습니다.\n",
        "\n",
        "아래에서 사용자 정의 모델 코드의 예를 살펴 보겠습니다 (TensorFlow Estimator API에 대한 소개 [는 튜토리얼 참조](https://www.tensorflow.org/tutorials/estimator/premade) )."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N1376oq04YJt"
      },
      "outputs": [],
      "source": [
        "_taxi_trainer_module_file = 'taxi_trainer.py'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nf9UuNng4YJu"
      },
      "outputs": [],
      "source": [
        "%%writefile {_taxi_trainer_module_file}\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_model_analysis as tfma\n",
        "import tensorflow_transform as tft\n",
        "from tensorflow_transform.tf_metadata import schema_utils\n",
        "from tfx_bsl.tfxio import dataset_options\n",
        "\n",
        "import taxi_constants\n",
        "\n",
        "_DENSE_FLOAT_FEATURE_KEYS = taxi_constants.DENSE_FLOAT_FEATURE_KEYS\n",
        "_VOCAB_FEATURE_KEYS = taxi_constants.VOCAB_FEATURE_KEYS\n",
        "_VOCAB_SIZE = taxi_constants.VOCAB_SIZE\n",
        "_OOV_SIZE = taxi_constants.OOV_SIZE\n",
        "_FEATURE_BUCKET_COUNT = taxi_constants.FEATURE_BUCKET_COUNT\n",
        "_BUCKET_FEATURE_KEYS = taxi_constants.BUCKET_FEATURE_KEYS\n",
        "_CATEGORICAL_FEATURE_KEYS = taxi_constants.CATEGORICAL_FEATURE_KEYS\n",
        "_MAX_CATEGORICAL_FEATURE_VALUES = taxi_constants.MAX_CATEGORICAL_FEATURE_VALUES\n",
        "_LABEL_KEY = taxi_constants.LABEL_KEY\n",
        "\n",
        "\n",
        "# Tf.Transform considers these features as \"raw\"\n",
        "def _get_raw_feature_spec(schema):\n",
        "  return schema_utils.schema_as_feature_spec(schema).feature_spec\n",
        "\n",
        "\n",
        "def _build_estimator(config, hidden_units=None, warm_start_from=None):\n",
        "  \"\"\"Build an estimator for predicting the tipping behavior of taxi riders.\n",
        "  Args:\n",
        "    config: tf.estimator.RunConfig defining the runtime environment for the\n",
        "      estimator (including model_dir).\n",
        "    hidden_units: [int], the layer sizes of the DNN (input layer first)\n",
        "    warm_start_from: Optional directory to warm start from.\n",
        "  Returns:\n",
        "    A dict of the following:\n",
        "      - estimator: The estimator that will be used for training and eval.\n",
        "      - train_spec: Spec for training.\n",
        "      - eval_spec: Spec for eval.\n",
        "      - eval_input_receiver_fn: Input function for eval.\n",
        "  \"\"\"\n",
        "  real_valued_columns = [\n",
        "      tf.feature_column.numeric_column(key, shape=())\n",
        "      for key in _DENSE_FLOAT_FEATURE_KEYS\n",
        "  ]\n",
        "  categorical_columns = [\n",
        "      tf.feature_column.categorical_column_with_identity(\n",
        "          key, num_buckets=_VOCAB_SIZE + _OOV_SIZE, default_value=0)\n",
        "      for key in _VOCAB_FEATURE_KEYS\n",
        "  ]\n",
        "  categorical_columns += [\n",
        "      tf.feature_column.categorical_column_with_identity(\n",
        "          key, num_buckets=_FEATURE_BUCKET_COUNT, default_value=0)\n",
        "      for key in _BUCKET_FEATURE_KEYS\n",
        "  ]\n",
        "  categorical_columns += [\n",
        "      tf.feature_column.categorical_column_with_identity(  # pylint: disable=g-complex-comprehension\n",
        "          key,\n",
        "          num_buckets=num_buckets,\n",
        "          default_value=0) for key, num_buckets in zip(\n",
        "              _CATEGORICAL_FEATURE_KEYS,\n",
        "              _MAX_CATEGORICAL_FEATURE_VALUES)\n",
        "  ]\n",
        "  return tf.estimator.DNNLinearCombinedClassifier(\n",
        "      config=config,\n",
        "      linear_feature_columns=categorical_columns,\n",
        "      dnn_feature_columns=real_valued_columns,\n",
        "      dnn_hidden_units=hidden_units or [100, 70, 50, 25],\n",
        "      warm_start_from=warm_start_from)\n",
        "\n",
        "\n",
        "def _example_serving_receiver_fn(tf_transform_graph, schema):\n",
        "  \"\"\"Build the serving in inputs.\n",
        "  Args:\n",
        "    tf_transform_graph: A TFTransformOutput.\n",
        "    schema: the schema of the input data.\n",
        "  Returns:\n",
        "    Tensorflow graph which parses examples, applying tf-transform to them.\n",
        "  \"\"\"\n",
        "  raw_feature_spec = _get_raw_feature_spec(schema)\n",
        "  raw_feature_spec.pop(_LABEL_KEY)\n",
        "\n",
        "  raw_input_fn = tf.estimator.export.build_parsing_serving_input_receiver_fn(\n",
        "      raw_feature_spec, default_batch_size=None)\n",
        "  serving_input_receiver = raw_input_fn()\n",
        "\n",
        "  transformed_features = tf_transform_graph.transform_raw_features(\n",
        "      serving_input_receiver.features)\n",
        "\n",
        "  return tf.estimator.export.ServingInputReceiver(\n",
        "      transformed_features, serving_input_receiver.receiver_tensors)\n",
        "\n",
        "\n",
        "def _eval_input_receiver_fn(tf_transform_graph, schema):\n",
        "  \"\"\"Build everything needed for the tf-model-analysis to run the model.\n",
        "  Args:\n",
        "    tf_transform_graph: A TFTransformOutput.\n",
        "    schema: the schema of the input data.\n",
        "  Returns:\n",
        "    EvalInputReceiver function, which contains:\n",
        "      - Tensorflow graph which parses raw untransformed features, applies the\n",
        "        tf-transform preprocessing operators.\n",
        "      - Set of raw, untransformed features.\n",
        "      - Label against which predictions will be compared.\n",
        "  \"\"\"\n",
        "  # Notice that the inputs are raw features, not transformed features here.\n",
        "  raw_feature_spec = _get_raw_feature_spec(schema)\n",
        "\n",
        "  serialized_tf_example = tf.compat.v1.placeholder(\n",
        "      dtype=tf.string, shape=[None], name='input_example_tensor')\n",
        "\n",
        "  # Add a parse_example operator to the tensorflow graph, which will parse\n",
        "  # raw, untransformed, tf examples.\n",
        "  features = tf.io.parse_example(serialized_tf_example, raw_feature_spec)\n",
        "\n",
        "  # Now that we have our raw examples, process them through the tf-transform\n",
        "  # function computed during the preprocessing step.\n",
        "  transformed_features = tf_transform_graph.transform_raw_features(\n",
        "      features)\n",
        "\n",
        "  # The key name MUST be 'examples'.\n",
        "  receiver_tensors = {'examples': serialized_tf_example}\n",
        "\n",
        "  # NOTE: Model is driven by transformed features (since training works on the\n",
        "  # materialized output of TFT, but slicing will happen on raw features.\n",
        "  features.update(transformed_features)\n",
        "\n",
        "  return tfma.export.EvalInputReceiver(\n",
        "      features=features,\n",
        "      receiver_tensors=receiver_tensors,\n",
        "      labels=transformed_features[_LABEL_KEY])\n",
        "\n",
        "\n",
        "def _input_fn(file_pattern, data_accessor, tf_transform_output, batch_size=200):\n",
        "  \"\"\"Generates features and label for tuning/training.\n",
        "\n",
        "  Args:\n",
        "    file_pattern: List of paths or patterns of input tfrecord files.\n",
        "    data_accessor: DataAccessor for converting input to RecordBatch.\n",
        "    tf_transform_output: A TFTransformOutput.\n",
        "    batch_size: representing the number of consecutive elements of returned\n",
        "      dataset to combine in a single batch\n",
        "\n",
        "  Returns:\n",
        "    A dataset that contains (features, indices) tuple where features is a\n",
        "      dictionary of Tensors, and indices is a single Tensor of label indices.\n",
        "  \"\"\"\n",
        "  return data_accessor.tf_dataset_factory(\n",
        "      file_pattern,\n",
        "      dataset_options.TensorFlowDatasetOptions(\n",
        "          batch_size=batch_size, label_key=_LABEL_KEY),\n",
        "      tf_transform_output.transformed_metadata.schema)\n",
        "\n",
        "\n",
        "# TFX will call this function\n",
        "def trainer_fn(trainer_fn_args, schema):\n",
        "  \"\"\"Build the estimator using the high level API.\n",
        "  Args:\n",
        "    trainer_fn_args: Holds args used to train the model as name/value pairs.\n",
        "    schema: Holds the schema of the training examples.\n",
        "  Returns:\n",
        "    A dict of the following:\n",
        "      - estimator: The estimator that will be used for training and eval.\n",
        "      - train_spec: Spec for training.\n",
        "      - eval_spec: Spec for eval.\n",
        "      - eval_input_receiver_fn: Input function for eval.\n",
        "  \"\"\"\n",
        "  # Number of nodes in the first layer of the DNN\n",
        "  first_dnn_layer_size = 100\n",
        "  num_dnn_layers = 4\n",
        "  dnn_decay_factor = 0.7\n",
        "\n",
        "  train_batch_size = 40\n",
        "  eval_batch_size = 40\n",
        "\n",
        "  tf_transform_graph = tft.TFTransformOutput(trainer_fn_args.transform_output)\n",
        "\n",
        "  train_input_fn = lambda: _input_fn(  # pylint: disable=g-long-lambda\n",
        "      trainer_fn_args.train_files,\n",
        "      trainer_fn_args.data_accessor,\n",
        "      tf_transform_graph,\n",
        "      batch_size=train_batch_size)\n",
        "\n",
        "  eval_input_fn = lambda: _input_fn(  # pylint: disable=g-long-lambda\n",
        "      trainer_fn_args.eval_files,\n",
        "      trainer_fn_args.data_accessor,\n",
        "      tf_transform_graph,\n",
        "      batch_size=eval_batch_size)\n",
        "\n",
        "  train_spec = tf.estimator.TrainSpec(  # pylint: disable=g-long-lambda\n",
        "      train_input_fn,\n",
        "      max_steps=trainer_fn_args.train_steps)\n",
        "\n",
        "  serving_receiver_fn = lambda: _example_serving_receiver_fn(  # pylint: disable=g-long-lambda\n",
        "      tf_transform_graph, schema)\n",
        "\n",
        "  exporter = tf.estimator.FinalExporter('chicago-taxi', serving_receiver_fn)\n",
        "  eval_spec = tf.estimator.EvalSpec(\n",
        "      eval_input_fn,\n",
        "      steps=trainer_fn_args.eval_steps,\n",
        "      exporters=[exporter],\n",
        "      name='chicago-taxi-eval')\n",
        "\n",
        "  run_config = tf.estimator.RunConfig(\n",
        "      save_checkpoints_steps=999, keep_checkpoint_max=1)\n",
        "\n",
        "  run_config = run_config.replace(model_dir=trainer_fn_args.serving_model_dir)\n",
        "\n",
        "  estimator = _build_estimator(\n",
        "      # Construct layers sizes with exponetial decay\n",
        "      hidden_units=[\n",
        "          max(2, int(first_dnn_layer_size * dnn_decay_factor**i))\n",
        "          for i in range(num_dnn_layers)\n",
        "      ],\n",
        "      config=run_config,\n",
        "      warm_start_from=trainer_fn_args.base_model)\n",
        "\n",
        "  # Create an input receiver for TFMA processing\n",
        "  receiver_fn = lambda: _eval_input_receiver_fn(  # pylint: disable=g-long-lambda\n",
        "      tf_transform_graph, schema)\n",
        "\n",
        "  return {\n",
        "      'estimator': estimator,\n",
        "      'train_spec': train_spec,\n",
        "      'eval_spec': eval_spec,\n",
        "      'eval_input_receiver_fn': receiver_fn\n",
        "  }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GY4yTRaX4YJx"
      },
      "source": [
        "이제이 모델 코드를 `Trainer` 구성 요소에 전달하고 실행하여 모델을 교육합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "429-vvCWibO0"
      },
      "outputs": [],
      "source": [
        "from tfx.components.trainer.executor import Executor\n",
        "from tfx.dsl.components.base import executor_spec\n",
        "\n",
        "trainer = tfx.components.Trainer(\n",
        "    module_file=os.path.abspath(_taxi_trainer_module_file),\n",
        "    custom_executor_spec=executor_spec.ExecutorClassSpec(Executor),\n",
        "    examples=transform.outputs['transformed_examples'],\n",
        "    schema=schema_gen.outputs['schema'],\n",
        "    transform_graph=transform.outputs['transform_graph'],\n",
        "    train_args=tfx.proto.TrainArgs(num_steps=10000),\n",
        "    eval_args=tfx.proto.EvalArgs(num_steps=5000))\n",
        "context.run(trainer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Cql1G35StJp"
      },
      "source": [
        "#### TensorBoard로 훈련 분석\n",
        "\n",
        "선택적으로 TensorBoard를 Trainer에 연결하여 모델의 훈련 곡선을 분석 할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bXe62WE0S0Ek"
      },
      "outputs": [],
      "source": [
        "# Get the URI of the output artifact representing the training logs, which is a directory\n",
        "model_run_dir = trainer.outputs['model_run'].get()[0].uri\n",
        "\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir {model_run_dir}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmPftrv0lEQy"
      },
      "source": [
        "### 평가자\n",
        "\n",
        "`Evaluator` 구성 요소는 평가 세트에 대한 모델 성능 메트릭을 계산합니다. [TensorFlow Model Analysis](https://www.tensorflow.org/tfx/model_analysis/get_started) 라이브러리를 사용합니다. 또한 `Evaluator` 는 새로 훈련 된 모델이 이전 모델보다 나은지 선택적으로 검증 할 수도 있습니다. 이는 매일 모델을 자동으로 학습하고 검증 할 수있는 프로덕션 파이프 라인 설정에서 유용합니다. 이 노트북에서는 하나의 모델 만 학습하므로 `Evaluator` 자동으로 모델을 \"양호\"로 표시합니다.\n",
        "\n",
        "`Evaluator` `ExampleGen` `Trainer` 의 학습 된 모델 및 슬라이싱 구성의 데이터를 입력으로받습니다. 슬라이싱 구성을 사용하면 특성 값에 대한 메트릭을 분할 할 수 있습니다 (예 : 오전 8시 대 오후 8시에 시작하는 택시 여행에서 모델의 성능이 어떻습니까?). 아래에서이 구성의 예를 참조하십시오."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fVhfzzh9PDEx"
      },
      "outputs": [],
      "source": [
        "eval_config = tfma.EvalConfig(\n",
        "    model_specs=[\n",
        "        # Using signature 'eval' implies the use of an EvalSavedModel. To use\n",
        "        # a serving model remove the signature to defaults to 'serving_default'\n",
        "        # and add a label_key.\n",
        "        tfma.ModelSpec(signature_name='eval')\n",
        "    ],\n",
        "    metrics_specs=[\n",
        "        tfma.MetricsSpec(\n",
        "            # The metrics added here are in addition to those saved with the\n",
        "            # model (assuming either a keras model or EvalSavedModel is used).\n",
        "            # Any metrics added into the saved model (for example using\n",
        "            # model.compile(..., metrics=[...]), etc) will be computed\n",
        "            # automatically.\n",
        "            metrics=[\n",
        "                tfma.MetricConfig(class_name='ExampleCount')\n",
        "            ],\n",
        "            # To add validation thresholds for metrics saved with the model,\n",
        "            # add them keyed by metric name to the thresholds map.\n",
        "            thresholds = {\n",
        "                'accuracy': tfma.MetricThreshold(\n",
        "                    value_threshold=tfma.GenericValueThreshold(\n",
        "                        lower_bound={'value': 0.5}),\n",
        "                    # Change threshold will be ignored if there is no\n",
        "                    # baseline model resolved from MLMD (first run).\n",
        "                    change_threshold=tfma.GenericChangeThreshold(\n",
        "                       direction=tfma.MetricDirection.HIGHER_IS_BETTER,\n",
        "                       absolute={'value': -1e-10}))\n",
        "            }\n",
        "        )\n",
        "    ],\n",
        "    slicing_specs=[\n",
        "        # An empty slice spec means the overall slice, i.e. the whole dataset.\n",
        "        tfma.SlicingSpec(),\n",
        "        # Data can be sliced along a feature column. In this case, data is\n",
        "        # sliced along feature column trip_start_hour.\n",
        "        tfma.SlicingSpec(feature_keys=['trip_start_hour'])\n",
        "    ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mBdKH1F8JuT"
      },
      "source": [
        "다음으로이 구성을 `Evaluator` 하고 실행합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zjcx8g6mihSt"
      },
      "outputs": [],
      "source": [
        "# Use TFMA to compute a evaluation statistics over features of a model and\n",
        "# validate them against a baseline.\n",
        "\n",
        "# The model resolver is only required if performing model validation in addition\n",
        "# to evaluation. In this case we validate against the latest blessed model. If\n",
        "# no model has been blessed before (as in this case) the evaluator will make our\n",
        "# candidate the first blessed model.\n",
        "model_resolver = tfx.dsl.Resolver(\n",
        "      strategy_class=tfx.dsl.experimental.LatestBlessedModelStrategy,\n",
        "      model=tfx.dsl.Channel(type=tfx.types.standard_artifacts.Model),\n",
        "      model_blessing=tfx.dsl.Channel(\n",
        "          type=tfx.types.standard_artifacts.ModelBlessing)).with_id(\n",
        "              'latest_blessed_model_resolver')\n",
        "context.run(model_resolver)\n",
        "\n",
        "evaluator = tfx.components.Evaluator(\n",
        "    examples=example_gen.outputs['examples'],\n",
        "    model=trainer.outputs['model'],\n",
        "    eval_config=eval_config)\n",
        "context.run(evaluator)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AeCVkBusS_8g"
      },
      "source": [
        "`Evaluator` 의 출력 결과물을 살펴 보겠습니다. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k4GghePOTJxL"
      },
      "outputs": [],
      "source": [
        "evaluator.outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5TMskWe9LL0"
      },
      "source": [
        "`evaluation` 출력을 사용하여 전체 평가 세트에 대한 글로벌 메트릭의 기본 시각화를 표시 할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U729j5X5QQUQ"
      },
      "outputs": [],
      "source": [
        "context.show(evaluator.outputs['evaluation'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-tI4p6m-OAn"
      },
      "source": [
        "슬라이스 된 평가 측정 항목의 시각화를 보려면 TensorFlow 모델 분석 라이브러리를 직접 호출 할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pyis6iy0HLdi"
      },
      "outputs": [],
      "source": [
        "import tensorflow_model_analysis as tfma\n",
        "\n",
        "# Get the TFMA output result path and load the result.\n",
        "PATH_TO_RESULT = evaluator.outputs['evaluation'].get()[0].uri\n",
        "tfma_result = tfma.load_eval_result(PATH_TO_RESULT)\n",
        "\n",
        "# Show data sliced along feature column trip_start_hour.\n",
        "tfma.view.render_slicing_metrics(\n",
        "    tfma_result, slicing_column='trip_start_hour')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uvYrUf2-r_6"
      },
      "source": [
        "이 시각화는 동일한 측정 항목을 보여 주지만 전체 평가 세트 대신 `trip_start_hour`\n",
        "\n",
        "TensorFlow 모델 분석은 공정성 지표 및 모델 성능의 시계열 플로팅과 같은 다른 많은 시각화를 지원합니다. 자세한 내용 [은 튜토리얼을](https://www.tensorflow.org/tfx/tutorials/model_analysis/tfma_basic) 참조하십시오."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEotnkxEswUb"
      },
      "source": [
        "구성에 임계 값을 추가 했으므로 유효성 검사 출력도 사용할 수 있습니다. `blessing` 아티팩트의 우선 순위는 모델이 유효성 검사를 통과했음을 나타냅니다. 이것이 수행되는 첫 번째 검증이기 때문에 후보자는 자동으로 축복을받습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FZmiRtg6TKtR"
      },
      "outputs": [],
      "source": [
        "blessing_uri = evaluator.outputs['blessing'].get()[0].uri\n",
        "!ls -l {blessing_uri}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hM1tFkOVSBa0"
      },
      "source": [
        "이제 유효성 검사 결과 레코드를로드하여 성공 여부를 확인할 수도 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lxa5G08bSJ8a"
      },
      "outputs": [],
      "source": [
        "PATH_TO_RESULT = evaluator.outputs['evaluation'].get()[0].uri\n",
        "print(tfma.load_validation_result(PATH_TO_RESULT))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8DYekCZlHfj"
      },
      "source": [
        "### 미는 사람\n",
        "\n",
        "`Pusher` 구성 요소는 일반적으로 TFX 파이프 라인의 끝에 있습니다. 모델이 유효성 검사를 통과했는지 확인하고, 그렇다면 모델을 `_serving_model_dir` 내 보냅니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r45nQ69eikc9"
      },
      "outputs": [],
      "source": [
        "pusher = tfx.components.Pusher(\n",
        "    model=trainer.outputs['model'],\n",
        "    model_blessing=evaluator.outputs['blessing'],\n",
        "    push_destination=tfx.proto.PushDestination(\n",
        "        filesystem=tfx.proto.PushDestination.Filesystem(\n",
        "            base_directory=_serving_model_dir)))\n",
        "context.run(pusher)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctUErBYoTO9I"
      },
      "source": [
        "`Pusher` 의 출력 결과물을 살펴 보겠습니다. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pRkWo-MzTSss"
      },
      "outputs": [],
      "source": [
        "pusher.outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peH2PPS3VgkL"
      },
      "source": [
        "특히 Pusher는 다음과 같은 SavedModel 형식으로 모델을 내 보냅니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4zyIqWl9TSdG"
      },
      "outputs": [],
      "source": [
        "push_uri = pusher.outputs['pushed_model'].get()[0].uri\n",
        "model = tf.saved_model.load(push_uri)\n",
        "\n",
        "for item in model.signatures.items():\n",
        "  pp.pprint(item)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-YPNUuHANtj"
      },
      "source": [
        "내장 TFX 컴포넌트 둘러보기를 마쳤습니다!"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "wdeKOEkv1Fe8"
      ],
      "name": "components.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
