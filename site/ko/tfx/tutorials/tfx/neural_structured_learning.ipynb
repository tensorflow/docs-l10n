{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24gYiJcWNlpA"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ioaprt5q5US7"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ItXfxkxvosLH"
      },
      "source": [
        "# TFX에서 그래프 기반 신경 구조화 학습\n",
        "\n",
        "이 튜토리얼에서는 [신경 구조화 학습(Neural Structured Learning)](https://www.tensorflow.org/neural_structured_learning/) 프레임워크의 그래프 정규화에 대해 설명하고 TFX 파이프라인에서 감정 분류를 위한 전체 워크플로를 보여줍니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyAF26z9IDoq"
      },
      "source": [
        "참고: 설정이 필요하지 않은 Colab 노트북에서 이 튜토리얼을 실행하는 것이 좋습니다! \"Google Colab에서 실행\"을 클릭하기만 하면 됩니다.\n",
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>TensorFlow.org에서 보기</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/ko/tfx/tutorials/tfx/neural_structured_learning.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Google Colab에서 실행하기</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/ko/tfx/tutorials/tfx/neural_structured_learning.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">GitHub에서 소스 보기</a>\n",
        "</td>\n",
        "  <td><a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/ko/tfx/tutorials/tfx/neural_structured_learning.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">노트북 다운론드하기</a></td>\n",
        "  <td>TF Hub 모델 보기</td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3otbdCMmJiJ"
      },
      "source": [
        "## 개요"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApxPtg2DiTtd"
      },
      "source": [
        "이 노트북은 리뷰 텍스트를 사용하여 영화 리뷰를 *긍정적* 또는 *부정적*으로 분류합니다. 중요하고도 널리 적용 가능한 머신러닝 문제인 *이진* 분류의 예입니다.\n",
        "\n",
        "주어진 입력으로부터 그래프를 빌드하여 이 노트북에서 그래프 정규화를 사용하는 방법을 보여줄 것입니다. 입력에 명시적 그래프가 포함되어 있지 않을 때 Neural Structured Learning(NSL) 프레임워크를 사용하여 그래프 정규화 모델을 빌드하는 일반적인 방법은 다음과 같습니다.\n",
        "\n",
        "1. 입력에서 각 텍스트 샘플에 대한 임베딩을 만듭니다. [word2vec](https://arxiv.org/pdf/1310.4546.pdf), [Swivel](https://arxiv.org/abs/1602.02215), [BERT](https://arxiv.org/abs/1810.04805) 등과 같은 사전 훈련된 모델을 사용하여 수행할 수 있습니다.\n",
        "2. 'L2' 거리, 'cosine' 거리 등과 같은 유사성 메트릭을 사용하여 이러한 임베딩을 기반으로 그래프를 빌드합니다. 그래프에서 노드는 샘플에 해당하고, 그래프에서 간선은 샘플 쌍 간의 유사성에 해당합니다.\n",
        "3. 위의 합성 그래프와 샘플 특성에서 훈련 데이터를 생성합니다. 결과적인 훈련 데이터에는 원래 노드 특성 외에도 이웃 특성이 포함됩니다.\n",
        "4. Estimator를 사용하여 기본 모델로 신경망을 만듭니다.\n",
        "5. NSL 프레임워크에서 제공하는 `add_graph_regularization` 래퍼 함수로 기본 모델을 래핑하여 새 그래프 Estimator 모델을 만듭니다. 이 새로운 모델은 훈련 목표에서 그래프 정규화 손실을 정규화 항으로 포함합니다.\n",
        "6. 그래프 Estimator 모델을 훈련하고 평가합니다.\n",
        "\n",
        "이 튜토리얼에서는 여러 사용자 지정 TFX 구성 요소와 사용자 지정 그래프 정규화 트레이너 구성 요소를 사용하여 위의 워크플로를 TFX 파이프라인에 통합합니다.\n",
        "\n",
        "다음은 TFX 파이프라인의 개략도입니다. 주황색 상자는 기성 TFX 구성 요소를 나타내고 분홍색 상자는 사용자 지정 TFX 구성 요소를 나타냅니다.\n",
        "\n",
        "![TFX 파이프라인](images/nsl/nsl-tfx.svg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIx0r9-TeVQQ"
      },
      "source": [
        "## Pip 업그레이드\n",
        "\n",
        "로컬에서 실행할 때 시스템에서 Pip을 업그레이드하지 않으려면 Colab에서 실행 중인지 확인하세요. 물론 로컬 시스템은 별도로 업그레이드할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-UmVrHUfkUA2"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "if 'google.colab' in sys.modules:\n",
        "  !pip install --upgrade pip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDOFbB34KY1R"
      },
      "source": [
        "## 필요한 패키지 설치하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yDUe7gk_ztZ-"
      },
      "outputs": [],
      "source": [
        "!pip install -q \\\n",
        "  tfx \\\n",
        "  neural-structured-learning \\\n",
        "  tensorflow-hub \\\n",
        "  tensorflow-datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CeGS8G_eueJ"
      },
      "source": [
        "## 런타임을 다시 시작했습니까?\n",
        "\n",
        "Google Colab을 사용하는 경우, 위의 셀을 처음 실행할 때 런타임을 다시 시작해야 합니다(런타임 &gt; 런타임 다시 시작...). 이는 Colab이 패키지를 로드하는 방식 때문입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6FJ64qMNLez"
      },
      "source": [
        "## 종속성 및 가져오기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ew7HTbPpCJH"
      },
      "outputs": [],
      "source": [
        "import apache_beam as beam\n",
        "import gzip as gzip_lib\n",
        "import numpy as np\n",
        "import os\n",
        "import pprint\n",
        "import shutil\n",
        "import tempfile\n",
        "import urllib\n",
        "import uuid\n",
        "pp = pprint.PrettyPrinter()\n",
        "\n",
        "import tensorflow as tf\n",
        "import neural_structured_learning as nsl\n",
        "\n",
        "import tfx\n",
        "from tfx.components.evaluator.component import Evaluator\n",
        "from tfx.components.example_gen.import_example_gen.component import ImportExampleGen\n",
        "from tfx.components.example_validator.component import ExampleValidator\n",
        "from tfx.components.model_validator.component import ModelValidator\n",
        "from tfx.components.pusher.component import Pusher\n",
        "from tfx.components.schema_gen.component import SchemaGen\n",
        "from tfx.components.statistics_gen.component import StatisticsGen\n",
        "from tfx.components.trainer import executor as trainer_executor\n",
        "from tfx.components.trainer.component import Trainer\n",
        "from tfx.components.transform.component import Transform\n",
        "from tfx.dsl.components.base import executor_spec\n",
        "from tfx.orchestration.experimental.interactive.interactive_context import InteractiveContext\n",
        "from tfx.proto import evaluator_pb2\n",
        "from tfx.proto import example_gen_pb2\n",
        "from tfx.proto import pusher_pb2\n",
        "from tfx.proto import trainer_pb2\n",
        "\n",
        "from tfx.types import artifact\n",
        "from tfx.types import artifact_utils\n",
        "from tfx.types import channel\n",
        "from tfx.types import standard_artifacts\n",
        "from tfx.types.standard_artifacts import Examples\n",
        "\n",
        "from tfx.dsl.component.experimental.annotations import InputArtifact\n",
        "from tfx.dsl.component.experimental.annotations import OutputArtifact\n",
        "from tfx.dsl.component.experimental.annotations import Parameter\n",
        "from tfx.dsl.component.experimental.decorators import component\n",
        "\n",
        "from tensorflow_metadata.proto.v0 import anomalies_pb2\n",
        "from tensorflow_metadata.proto.v0 import schema_pb2\n",
        "from tensorflow_metadata.proto.v0 import statistics_pb2\n",
        "\n",
        "import tensorflow_data_validation as tfdv\n",
        "import tensorflow_transform as tft\n",
        "import tensorflow_model_analysis as tfma\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "print(\"TF Version: \", tf.__version__)\n",
        "print(\"Eager mode: \", tf.executing_eagerly())\n",
        "print(\n",
        "    \"GPU is\",\n",
        "    \"available\" if tf.config.list_physical_devices(\"GPU\") else \"NOT AVAILABLE\")\n",
        "print(\"NSL Version: \", nsl.__version__)\n",
        "print(\"TFX Version: \", tfx.__version__)\n",
        "print(\"TFDV version: \", tfdv.__version__)\n",
        "print(\"TFT version: \", tft.__version__)\n",
        "print(\"TFMA version: \", tfma.__version__)\n",
        "print(\"Hub version: \", hub.__version__)\n",
        "print(\"Beam version: \", beam.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGwwFd99n42P"
      },
      "source": [
        "## IMDB 데이터세트\n",
        "\n",
        "[IMDB 데이터세트](https://www.tensorflow.org/datasets/catalog/imdb_reviews)에는 [인터넷 영화 데이터베이스](https://www.imdb.com/)에서 가져온 50,000개의 영화 리뷰 텍스트가 포함되어 있습니다. 훈련용 리뷰 25,000개와 테스트용 리뷰 25,000개로 나뉩니다. 훈련 및 테스트 세트는 *균형을 이룹니다*. 즉, 동일한 수의 긍정적인 리뷰와 부정적인 리뷰가 포함되어 있습니다. 또한 레이블이 지정되지 않은 50,000개의 추가 영화 리뷰도 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAsKG535pHep"
      },
      "source": [
        "### 전처리된 IMDB 데이터세트 다운로드하기\n",
        "\n",
        "다음 코드는 TFDS를 사용하여 IMDB 데이터세트를 다운로드합니다(또는 이미 다운로드된 경우 캐시된 복사본 사용). 이 노트북의 속도를 높이기 위해 레이블이 지정된 리뷰 10,000개와 레이블이 지정되지 않은 리뷰 10,000개만 훈련에 사용하고 테스트 리뷰 10,000개를 평가에 사용합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "__cZi2Ic48KL"
      },
      "outputs": [],
      "source": [
        "train_set, eval_set = tfds.load(\n",
        "    \"imdb_reviews:1.0.0\",\n",
        "    split=[\"train[:10000]+unsupervised[:10000]\", \"test[:10000]\"],\n",
        "    shuffle_files=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nE9tNh-67Y3W"
      },
      "source": [
        "훈련 세트의 몇 가지 리뷰를 살펴보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LsnHde8T67Jz"
      },
      "outputs": [],
      "source": [
        "for tfrecord in train_set.take(4):\n",
        "  print(\"Review: {}\".format(tfrecord[\"text\"].numpy().decode(\"utf-8\")[:300]))\n",
        "  print(\"Label: {}\\n\".format(tfrecord[\"label\"].numpy()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0wG7v3rk-Cwo"
      },
      "outputs": [],
      "source": [
        "def _dict_to_example(instance):\n",
        "  \"\"\"Decoded CSV to tf example.\"\"\"\n",
        "  feature = {}\n",
        "  for key, value in instance.items():\n",
        "    if value is None:\n",
        "      feature[key] = tf.train.Feature()\n",
        "    elif value.dtype == np.integer:\n",
        "      feature[key] = tf.train.Feature(\n",
        "          int64_list=tf.train.Int64List(value=value.tolist()))\n",
        "    elif value.dtype == np.float32:\n",
        "      feature[key] = tf.train.Feature(\n",
        "          float_list=tf.train.FloatList(value=value.tolist()))\n",
        "    else:\n",
        "      feature[key] = tf.train.Feature(\n",
        "          bytes_list=tf.train.BytesList(value=value.tolist()))\n",
        "  return tf.train.Example(features=tf.train.Features(feature=feature))\n",
        "\n",
        "\n",
        "examples_path = tempfile.mkdtemp(prefix=\"tfx-data\")\n",
        "train_path = os.path.join(examples_path, \"train.tfrecord\")\n",
        "eval_path = os.path.join(examples_path, \"eval.tfrecord\")\n",
        "\n",
        "for path, dataset in [(train_path, train_set), (eval_path, eval_set)]:\n",
        "  with tf.io.TFRecordWriter(path) as writer:\n",
        "    for example in dataset:\n",
        "      writer.write(\n",
        "          _dict_to_example({\n",
        "              \"label\": np.array([example[\"label\"].numpy()]),\n",
        "              \"text\": np.array([example[\"text\"].numpy()]),\n",
        "          }).SerializeToString())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdQWxfsVkzdJ"
      },
      "source": [
        "## 대화식으로 TFX 구성 요소 실행\n",
        "\n",
        "다음 셀에서 TFX 구성 요소를 구성하고 InteractiveContext 내에서 각 구성 요소를 대화식으로 실행하여 `ExecutionResult` 개체를 얻습니다. 이는 각 구성 요소에 대한 종속성이 충족되는 시기를 기반으로 TFX DAG에서 구성 요소를 실행하는 오케스트레이터의 프로세스를 미러링합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4aVuXUil7hil"
      },
      "outputs": [],
      "source": [
        "context = InteractiveContext()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9fwt9gQk3BR"
      },
      "source": [
        "### ExampleGen 구성 요소\n",
        "\n",
        "모든 ML 개발 프로세스에서 코드 개발을 시작할 때의 첫 단계는 훈련 및 테스트 데이터세트를 수집하는 것입니다. `ExampleGen` 구성 요소는 데이터를 TFX 파이프라인으로 가져옵니다.\n",
        "\n",
        "ExampleGen 구성 요소를 만들고 실행합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WdH4ql3Y7pT4"
      },
      "outputs": [],
      "source": [
        "input_config = example_gen_pb2.Input(splits=[\n",
        "    example_gen_pb2.Input.Split(name='train', pattern='train.tfrecord'),\n",
        "    example_gen_pb2.Input.Split(name='eval', pattern='eval.tfrecord')\n",
        "])\n",
        "\n",
        "example_gen = ImportExampleGen(input_base=examples_path, input_config=input_config)\n",
        "\n",
        "context.run(example_gen, enable_cache=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IeUp6xCCrxsS"
      },
      "outputs": [],
      "source": [
        "for artifact in example_gen.outputs['examples'].get():\n",
        "  print(artifact)\n",
        "\n",
        "print('\\nexample_gen.outputs is a {}'.format(type(example_gen.outputs)))\n",
        "print(example_gen.outputs)\n",
        "\n",
        "print(example_gen.outputs['examples'].get()[0].split_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0SXc2OGnDWz5"
      },
      "source": [
        "구성 요소의 출력에는 2개의 아티팩트가 포함됩니다.\n",
        "\n",
        "- 훈련 예제(10,000개의 레이블이 지정된 리뷰 + 10,000개의 레이블이 없는 리뷰)\n",
        "- 평가 예(10,000개의 레이블이 지정된 리뷰)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pcPppPASQzFa"
      },
      "source": [
        "### IdentExamples 사용자 지정 구성 요소\n",
        "\n",
        "NSL을 사용하려면 각 인스턴스에 고유 ID가 있어야 합니다. 모든 분할의 모든 인스턴스에 이러한 고유 ID를 추가하는 사용자 지정 구성 요소를 만듭니다. 필요한 경우 대규모 데이터세트로 쉽게 확장할 수 있도록 [Apache Beam](https://beam.apache.org)을 활용합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XHCUzXA5qeWe"
      },
      "outputs": [],
      "source": [
        "def make_example_with_unique_id(example, id_feature_name):\n",
        "  \"\"\"Adds a unique ID to the given `tf.train.Example` proto.\n",
        "\n",
        "  This function uses Python's 'uuid' module to generate a universally unique\n",
        "  identifier for each example.\n",
        "\n",
        "  Args:\n",
        "    example: An instance of a `tf.train.Example` proto.\n",
        "    id_feature_name: The name of the feature in the resulting `tf.train.Example`\n",
        "      that will contain the unique identifier.\n",
        "\n",
        "  Returns:\n",
        "    A new `tf.train.Example` proto that includes a unique identifier as an\n",
        "    additional feature.\n",
        "  \"\"\"\n",
        "  result = tf.train.Example()\n",
        "  result.CopyFrom(example)\n",
        "  unique_id = uuid.uuid4()\n",
        "  result.features.feature.get_or_create(\n",
        "      id_feature_name).bytes_list.MergeFrom(\n",
        "          tf.train.BytesList(value=[str(unique_id).encode('utf-8')]))\n",
        "  return result\n",
        "\n",
        "\n",
        "@component\n",
        "def IdentifyExamples(orig_examples: InputArtifact[Examples],\n",
        "                     identified_examples: OutputArtifact[Examples],\n",
        "                     id_feature_name: Parameter[str],\n",
        "                     component_name: Parameter[str]) -> None:\n",
        "\n",
        "  # Get a list of the splits in input_data\n",
        "  splits_list = artifact_utils.decode_split_names(\n",
        "      split_names=orig_examples.split_names)\n",
        "  # For completeness, encode the splits names and payload_format.\n",
        "  # We could also just use input_data.split_names.\n",
        "  identified_examples.split_names = artifact_utils.encode_split_names(\n",
        "      splits=splits_list)\n",
        "  # TODO(b/168616829): Remove populating payload_format after tfx 0.25.0.\n",
        "  identified_examples.set_string_custom_property(\n",
        "      \"payload_format\",\n",
        "      orig_examples.get_string_custom_property(\"payload_format\"))\n",
        "\n",
        "\n",
        "  for split in splits_list:\n",
        "    input_dir = artifact_utils.get_split_uri([orig_examples], split)\n",
        "    output_dir = artifact_utils.get_split_uri([identified_examples], split)\n",
        "    os.mkdir(output_dir)\n",
        "    with beam.Pipeline() as pipeline:\n",
        "      (pipeline\n",
        "       | 'ReadExamples' >> beam.io.ReadFromTFRecord(\n",
        "           os.path.join(input_dir, '*'),\n",
        "           coder=beam.coders.coders.ProtoCoder(tf.train.Example))\n",
        "       | 'AddUniqueId' >> beam.Map(make_example_with_unique_id, id_feature_name)\n",
        "       | 'WriteIdentifiedExamples' >> beam.io.WriteToTFRecord(\n",
        "           file_path_prefix=os.path.join(output_dir, 'data_tfrecord'),\n",
        "           coder=beam.coders.coders.ProtoCoder(tf.train.Example),\n",
        "           file_name_suffix='.gz'))\n",
        "\n",
        "  return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZtLxNWHPO0je"
      },
      "outputs": [],
      "source": [
        "identify_examples = IdentifyExamples(\n",
        "    orig_examples=example_gen.outputs['examples'],\n",
        "    component_name=u'IdentifyExamples',\n",
        "    id_feature_name=u'id')\n",
        "context.run(identify_examples, enable_cache=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csM6BFhtk5Aa"
      },
      "source": [
        "### StatisticsGen 구성 요소\n",
        "\n",
        "`StatisticsGen` 구성 요소는 데이터세트에 대한 설명적 통계를 계산합니다. 생성된 통계는 검토를 위해 시각화할 수 있으며, 예제 검증과 스키마 추론에 사용됩니다.\n",
        "\n",
        "StatisticsGen 구성 요소를 생성하고 실행합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MAscCCYWgA-9"
      },
      "outputs": [],
      "source": [
        "# Computes statistics over data for visualization and example validation.\n",
        "statistics_gen = StatisticsGen(\n",
        "    examples=identify_examples.outputs[\"identified_examples\"])\n",
        "context.run(statistics_gen, enable_cache=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLKLTO9Nk60p"
      },
      "source": [
        "### SchemaGen 구성 요소\n",
        "\n",
        "`SchemaGen` 구성 요소는 StatisticsGen의 통계를 기반으로 데이터에 대한 스키마를 생성합니다. 이는 각 특성의 데이터 유형과 범주형 특성의 합법적 값 범위를 추론하려고 합니다.\n",
        "\n",
        "SchemaGen 구성 요소를 만들고 실행합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ygQvZ6hsiQ_J"
      },
      "outputs": [],
      "source": [
        "# Generates schema based on statistics files.\n",
        "schema_gen = SchemaGen(\n",
        "    statistics=statistics_gen.outputs['statistics'], infer_feature_shape=False)\n",
        "context.run(schema_gen, enable_cache=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdtU3u01FR-2"
      },
      "source": [
        "생성된 아티팩트는 단순히 `schema_pb2.Schema` protobuf의 텍스트 표현을 포함하는 `schema.pbtxt`입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L6-tgKi6A_gK"
      },
      "outputs": [],
      "source": [
        "train_uri = schema_gen.outputs['schema'].get()[0].uri\n",
        "schema_filename = os.path.join(train_uri, 'schema.pbtxt')\n",
        "schema = tfx.utils.io_utils.parse_pbtxt_file(\n",
        "    file_name=schema_filename, message=schema_pb2.Schema())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FaSgx5qIFelw"
      },
      "source": [
        "`tfdv.display_schema()`를 사용하여 시각화할 수 있습니다(이에 대해서는 이후 실습에서 자세히 살펴볼 예정임)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gycOsJIQFhi3"
      },
      "outputs": [],
      "source": [
        "tfdv.display_schema(schema)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1qcUuO9k9f8"
      },
      "source": [
        "### ExampleValidator 구성 요소\n",
        "\n",
        "`ExampleValidator`는 StatisticsGen의 통계와 SchemaGen의 스키마를 기반으로 이상 감지를 수행합니다. 누락된 값, 잘못된 유형의 값 또는 허용 가능한 값의 범위를 벗어난 범주형 값과 같은 문제를 찾습니다.\n",
        "\n",
        "ExampleValidator 구성 요소를 만들고 실행합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XRlRUuGgiXks"
      },
      "outputs": [],
      "source": [
        "# Performs anomaly detection based on statistics and data schema.\n",
        "validate_stats = ExampleValidator(\n",
        "    statistics=statistics_gen.outputs['statistics'],\n",
        "    schema=schema_gen.outputs['schema'])\n",
        "context.run(validate_stats, enable_cache=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3f2vmrF_e9b"
      },
      "source": [
        "### SynthesizeGraph 구성 요소"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3oCuXo4BPfGr"
      },
      "source": [
        "그래프 구성에는 텍스트 샘플에 대한 임베딩을 만든 다음 유사성 함수를 사용하여 임베딩을 비교하는 것이 포함됩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gf8B3KxcinZ0"
      },
      "source": [
        "사전 훈련된 Swivel 임베딩을 사용하여 입력의 각 샘플에 대해 `tf.train.Example` 형식으로 임베딩을 생성합니다. 샘플 ID와 함께 `TFRecord`에서 결과적인 임베딩을 저장합니다. 이것은 중요하며 나중에 그래프의 해당 노드와 샘플 임베딩을 일치시킬 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hSzZNdbPa4X"
      },
      "source": [
        "이제 샘플 임베딩이 있으므로 이를 사용하여 유사성 그래프를 빌드합니다. 즉, 이 그래프에서 노드는 샘플에 해당하고, 이 그래프에서 간선은 노드 쌍 간의 유사성에 해당합니다.\n",
        "\n",
        "Neural Structured Learning은 샘플 임베딩을 기반으로 그래프를 빌드하기 위한 그래프 빌드 라이브러리를 제공합니다. **코사인 유사성**을 유사성 척도로 사용하여 임베딩을 비교하고 그 사이에서 간선을 빌드합니다. 또한 최종 그래프에서 유사하지 않은 간선을 버리는 데 사용할 수 있는 유사성 임계값도 지정할 수 있습니다. 다음 예에서는 유사성 임계값으로 0.99를 사용하여 111,066개의 양방향 간선을 가진 그래프를 만듭니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nERXNfSWPa4Z"
      },
      "source": [
        "**참고:** 그래프 품질과 더 나아가 임베딩 품질은 그래프 정규화에 매우 중요합니다. 이 노트북에서는 Swivel 임베딩을 사용했지만, 예를 들어 BERT 임베딩을 사용하면 리뷰 의미 체계를 더 정확하게 파악할 수 있습니다. 사용자가 원하는 임베딩을 필요에 따라 사용할 것을 권장합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2bAttbhgPa4V"
      },
      "outputs": [],
      "source": [
        "swivel_url = 'https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1'\n",
        "hub_layer = hub.KerasLayer(swivel_url, input_shape=[], dtype=tf.string)\n",
        "\n",
        "\n",
        "def _bytes_feature(value):\n",
        "  \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
        "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=value))\n",
        "\n",
        "\n",
        "def _float_feature(value):\n",
        "  \"\"\"Returns a float_list from a float / double.\"\"\"\n",
        "  return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n",
        "\n",
        "\n",
        "def create_embedding_example(example):\n",
        "  \"\"\"Create tf.Example containing the sample's embedding and its ID.\"\"\"\n",
        "  sentence_embedding = hub_layer(tf.sparse.to_dense(example['text']))\n",
        "\n",
        "  # Flatten the sentence embedding back to 1-D.\n",
        "  sentence_embedding = tf.reshape(sentence_embedding, shape=[-1])\n",
        "\n",
        "  feature_dict = {\n",
        "      'id': _bytes_feature(tf.sparse.to_dense(example['id']).numpy()),\n",
        "      'embedding': _float_feature(sentence_embedding.numpy().tolist())\n",
        "  }\n",
        "\n",
        "  return tf.train.Example(features=tf.train.Features(feature=feature_dict))\n",
        "\n",
        "\n",
        "def create_dataset(uri):\n",
        "  tfrecord_filenames = [os.path.join(uri, name) for name in os.listdir(uri)]\n",
        "  return tf.data.TFRecordDataset(tfrecord_filenames, compression_type='GZIP')\n",
        "\n",
        "\n",
        "def create_embeddings(train_path, output_path):\n",
        "  dataset = create_dataset(train_path)\n",
        "  embeddings_path = os.path.join(output_path, 'embeddings.tfr')\n",
        "\n",
        "  feature_map = {\n",
        "      'label': tf.io.FixedLenFeature([], tf.int64),\n",
        "      'id': tf.io.VarLenFeature(tf.string),\n",
        "      'text': tf.io.VarLenFeature(tf.string)\n",
        "  }\n",
        "\n",
        "  with tf.io.TFRecordWriter(embeddings_path) as writer:\n",
        "    for tfrecord in dataset:\n",
        "      tensor_dict = tf.io.parse_single_example(tfrecord, feature_map)\n",
        "      embedding_example = create_embedding_example(tensor_dict)\n",
        "      writer.write(embedding_example.SerializeToString())\n",
        "\n",
        "\n",
        "def build_graph(output_path, similarity_threshold):\n",
        "  embeddings_path = os.path.join(output_path, 'embeddings.tfr')\n",
        "  graph_path = os.path.join(output_path, 'graph.tsv')\n",
        "  graph_builder_config = nsl.configs.GraphBuilderConfig(\n",
        "      similarity_threshold=similarity_threshold,\n",
        "      lsh_splits=32,\n",
        "      lsh_rounds=15,\n",
        "      random_seed=12345)\n",
        "  nsl.tools.build_graph_from_config([embeddings_path], graph_path,\n",
        "                                    graph_builder_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ITkf2SLg1TG7"
      },
      "outputs": [],
      "source": [
        "\"\"\"Custom Artifact type\"\"\"\n",
        "\n",
        "\n",
        "class SynthesizedGraph(tfx.types.artifact.Artifact):\n",
        "  \"\"\"Output artifact of the SynthesizeGraph component\"\"\"\n",
        "  TYPE_NAME = 'SynthesizedGraphPath'\n",
        "  PROPERTIES = {\n",
        "      'span': standard_artifacts.SPAN_PROPERTY,\n",
        "      'split_names': standard_artifacts.SPLIT_NAMES_PROPERTY,\n",
        "  }\n",
        "\n",
        "\n",
        "@component\n",
        "def SynthesizeGraph(identified_examples: InputArtifact[Examples],\n",
        "                    synthesized_graph: OutputArtifact[SynthesizedGraph],\n",
        "                    similarity_threshold: Parameter[float],\n",
        "                    component_name: Parameter[str]) -> None:\n",
        "\n",
        "  # Get a list of the splits in input_data\n",
        "  splits_list = artifact_utils.decode_split_names(\n",
        "      split_names=identified_examples.split_names)\n",
        "\n",
        "  # We build a graph only based on the 'Split-train' split which includes both\n",
        "  # labeled and unlabeled examples.\n",
        "  train_input_examples_uri = os.path.join(identified_examples.uri,\n",
        "                                          'Split-train')\n",
        "  output_graph_uri = os.path.join(synthesized_graph.uri, 'Split-train')\n",
        "  os.mkdir(output_graph_uri)\n",
        "\n",
        "  print('Creating embeddings...')\n",
        "  create_embeddings(train_input_examples_uri, output_graph_uri)\n",
        "\n",
        "  print('Synthesizing graph...')\n",
        "  build_graph(output_graph_uri, similarity_threshold)\n",
        "\n",
        "  synthesized_graph.split_names = artifact_utils.encode_split_names(\n",
        "      splits=['Split-train'])\n",
        "\n",
        "  return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H0ZkHvJMA-0G"
      },
      "outputs": [],
      "source": [
        "synthesize_graph = SynthesizeGraph(\n",
        "    identified_examples=identify_examples.outputs['identified_examples'],\n",
        "    component_name=u'SynthesizeGraph',\n",
        "    similarity_threshold=0.99)\n",
        "context.run(synthesize_graph, enable_cache=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o54M-0Q11FcS"
      },
      "outputs": [],
      "source": [
        "train_uri = synthesize_graph.outputs[\"synthesized_graph\"].get()[0].uri\n",
        "os.listdir(train_uri)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IRK_rS_q1UcZ"
      },
      "outputs": [],
      "source": [
        "graph_path = os.path.join(train_uri, \"Split-train\", \"graph.tsv\")\n",
        "print(\"node 1\\t\\t\\t\\t\\tnode 2\\t\\t\\t\\t\\tsimilarity\")\n",
        "!head {graph_path}\n",
        "print(\"...\")\n",
        "!tail {graph_path}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uybqyWztvCGm"
      },
      "outputs": [],
      "source": [
        "!wc -l {graph_path}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPViEz5RlA36"
      },
      "source": [
        "### Transform 구성 요소\n",
        "\n",
        "`Transform` 구성 요소는 데이터 변환 및 특성 엔지니어링을 수행합니다. 결과에는 훈련 또는 추론 전에 데이터를 사전 처리하기 위해 훈련 및 제공 중에 사용되는 입력 TensorFlow 그래프가 포함됩니다. 이 그래프는 모델 훈련의 결과인 SavedModel의 일부가 됩니다. 훈련과 제공 모두에 동일한 입력 그래프가 사용되기 때문에 전처리는 항상 동일하며 한 번만 작성하면 됩니다.\n",
        "\n",
        "Transform 구성 요소에는 작업 중인 데이터 및/또는 모델에 필요할 수도 있는 특성 엔지니어링의 임의적 복잡성 때문에 다른 많은 구성 요소보다 더 많은 코드가 필요합니다. 필요한 처리를 정의하는 코드 파일을 사용할 수 있어야 합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_USkfut69gNW"
      },
      "source": [
        "각 샘플에는 다음 세 가지 특성이 포함됩니다.\n",
        "\n",
        "1. **id**: 샘플의 노드 ID입니다.\n",
        "2. **text_xf**: 단어 ID를 포함하는 int64 목록입니다.\n",
        "3. **label_xf**: 리뷰의 대상 클래스를 식별하는 싱글톤 int64: 0=부정적, 1=긍정적."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUYeCayFG7kH"
      },
      "source": [
        "`Transform` 구성 요소에 전달할 `preprocessing_fn()` 함수를 포함하는 모듈을 정의해 보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7uuWiQbOG9ki"
      },
      "outputs": [],
      "source": [
        "_transform_module_file = 'imdb_transform.py'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v3EIuVQnBfH7"
      },
      "outputs": [],
      "source": [
        "%%writefile {_transform_module_file}\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import tensorflow_transform as tft\n",
        "\n",
        "SEQUENCE_LENGTH = 100\n",
        "VOCAB_SIZE = 10000\n",
        "OOV_SIZE = 100\n",
        "\n",
        "def tokenize_reviews(reviews, sequence_length=SEQUENCE_LENGTH):\n",
        "  reviews = tf.strings.lower(reviews)\n",
        "  reviews = tf.strings.regex_replace(reviews, r\" '| '|^'|'$\", \" \")\n",
        "  reviews = tf.strings.regex_replace(reviews, \"[^a-z' ]\", \" \")\n",
        "  tokens = tf.strings.split(reviews)[:, :sequence_length]\n",
        "  start_tokens = tf.fill([tf.shape(reviews)[0], 1], \"<START>\")\n",
        "  end_tokens = tf.fill([tf.shape(reviews)[0], 1], \"<END>\")\n",
        "  tokens = tf.concat([start_tokens, tokens, end_tokens], axis=1)\n",
        "  tokens = tokens[:, :sequence_length]\n",
        "  tokens = tokens.to_tensor(default_value=\"<PAD>\")\n",
        "  pad = sequence_length - tf.shape(tokens)[1]\n",
        "  tokens = tf.pad(tokens, [[0, 0], [0, pad]], constant_values=\"<PAD>\")\n",
        "  return tf.reshape(tokens, [-1, sequence_length])\n",
        "\n",
        "def preprocessing_fn(inputs):\n",
        "  \"\"\"tf.transform's callback function for preprocessing inputs.\n",
        "\n",
        "  Args:\n",
        "    inputs: map from feature keys to raw not-yet-transformed features.\n",
        "\n",
        "  Returns:\n",
        "    Map from string feature key to transformed feature operations.\n",
        "  \"\"\"\n",
        "  outputs = {}\n",
        "  outputs[\"id\"] = inputs[\"id\"]\n",
        "  tokens = tokenize_reviews(_fill_in_missing(inputs[\"text\"], ''))\n",
        "  outputs[\"text_xf\"] = tft.compute_and_apply_vocabulary(\n",
        "      tokens,\n",
        "      top_k=VOCAB_SIZE,\n",
        "      num_oov_buckets=OOV_SIZE)\n",
        "  outputs[\"label_xf\"] = _fill_in_missing(inputs[\"label\"], -1)\n",
        "  return outputs\n",
        "\n",
        "def _fill_in_missing(x, default_value):\n",
        "  \"\"\"Replace missing values in a SparseTensor.\n",
        "\n",
        "  Fills in missing values of `x` with the default_value.\n",
        "\n",
        "  Args:\n",
        "    x: A `SparseTensor` of rank 2.  Its dense shape should have size at most 1\n",
        "      in the second dimension.\n",
        "    default_value: the value with which to replace the missing values.\n",
        "\n",
        "  Returns:\n",
        "    A rank 1 tensor where missing values of `x` have been filled in.\n",
        "  \"\"\"\n",
        "  if not isinstance(x, tf.sparse.SparseTensor):\n",
        "    return x\n",
        "  return tf.squeeze(\n",
        "      tf.sparse.to_dense(\n",
        "          tf.SparseTensor(x.indices, x.values, [x.dense_shape[0], 1]),\n",
        "          default_value),\n",
        "      axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eeMVMafpHHX1"
      },
      "source": [
        "위에서 만든 파일을 참조하여 `Transform` 구성 요소를 만들고 실행합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jHfhth_GiZI9"
      },
      "outputs": [],
      "source": [
        "# Performs transformations and feature engineering in training and serving.\n",
        "transform = Transform(\n",
        "    examples=identify_examples.outputs['identified_examples'],\n",
        "    schema=schema_gen.outputs['schema'],\n",
        "    module_file=_transform_module_file)\n",
        "context.run(transform, enable_cache=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jbZO1ykHOeG"
      },
      "source": [
        "`Transform` 구성 요소에는 두 가지 유형의 출력이 있습니다.\n",
        "\n",
        "- `transform_graph`는 전처리 작업을 수행할 수 있는 그래프입니다(이 그래프는 제공 및 평가 모델에 포함됩니다).\n",
        "- `transformed_examples`는 전처리된 훈련 및 평가 데이터를 나타냅니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j4UjersvAC7p"
      },
      "outputs": [],
      "source": [
        "transform.outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRFMlRcdHlQy"
      },
      "source": [
        "`transform_graph` 아티팩트를 살펴보세요. 3개의 하위 디렉터리가 포함된 디렉터리를 가리킵니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E4I-cqfQQvaW"
      },
      "outputs": [],
      "source": [
        "train_uri = transform.outputs['transform_graph'].get()[0].uri\n",
        "os.listdir(train_uri)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9374B4RpHzor"
      },
      "source": [
        "`transform_fn` 하위 디렉터리에는 실제 전처리 그래프가 포함되어 있습니다. `metadata` 하위 디렉터리에는 원본 데이터의 스키마가 포함됩니다. `transformed_metadata` 하위 디렉터리에는 전처리된 데이터의 스키마가 포함됩니다.\n",
        "\n",
        "변환된 예제 중 일부를 살펴보고 의도한 대로 실제로 처리되었는지 확인하세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-QPONyzDTswf"
      },
      "outputs": [],
      "source": [
        "def pprint_examples(artifact, n_examples=3):\n",
        "  print(\"artifact:\", artifact)\n",
        "  uri = os.path.join(artifact.uri, \"Split-train\")\n",
        "  print(\"uri:\", uri)\n",
        "  tfrecord_filenames = [os.path.join(uri, name) for name in os.listdir(uri)]\n",
        "  print(\"tfrecord_filenames:\", tfrecord_filenames)\n",
        "  dataset = tf.data.TFRecordDataset(tfrecord_filenames, compression_type=\"GZIP\")\n",
        "  for tfrecord in dataset.take(n_examples):\n",
        "    serialized_example = tfrecord.numpy()\n",
        "    example = tf.train.Example.FromString(serialized_example)\n",
        "    pp.pprint(example)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2zIepQhSQoPa"
      },
      "outputs": [],
      "source": [
        "pprint_examples(transform.outputs['transformed_examples'].get()[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpGvPKielIvI"
      },
      "source": [
        "### GraphAugmentation 구성 요소\n",
        "\n",
        "샘플 특성과 합성된 그래프가 있으므로 Neural Structured Learning을 위한 증강 훈련 데이터를 생성할 수 있습니다. NSL 프레임워크는 그래프 정규화를 위한 최종 훈련 데이터를 생성하기 위해 그래프와 샘플 특성을 결합하는 라이브러리를 제공합니다. 결과적인 훈련 데이터에는 원본 샘플 특성과 해당 이웃의 특성이 포함됩니다.\n",
        "\n",
        "이 튜토리얼에서는 방향 없는 간선을 고려하고 샘플당 최대 3개의 이웃을 사용하여 그래프 이웃으로 훈련 데이터를 보강합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gI6P_-AXGm04"
      },
      "outputs": [],
      "source": [
        "def split_train_and_unsup(input_uri):\n",
        "  'Separate the labeled and unlabeled instances.'\n",
        "\n",
        "  tmp_dir = tempfile.mkdtemp(prefix='tfx-data')\n",
        "  tfrecord_filenames = [\n",
        "      os.path.join(input_uri, filename) for filename in os.listdir(input_uri)\n",
        "  ]\n",
        "  train_path = os.path.join(tmp_dir, 'train.tfrecord')\n",
        "  unsup_path = os.path.join(tmp_dir, 'unsup.tfrecord')\n",
        "  with tf.io.TFRecordWriter(train_path) as train_writer, \\\n",
        "       tf.io.TFRecordWriter(unsup_path) as unsup_writer:\n",
        "    for tfrecord in tf.data.TFRecordDataset(\n",
        "        tfrecord_filenames, compression_type='GZIP'):\n",
        "      example = tf.train.Example()\n",
        "      example.ParseFromString(tfrecord.numpy())\n",
        "      if ('label_xf' not in example.features.feature or\n",
        "          example.features.feature['label_xf'].int64_list.value[0] == -1):\n",
        "        writer = unsup_writer\n",
        "      else:\n",
        "        writer = train_writer\n",
        "      writer.write(tfrecord.numpy())\n",
        "  return train_path, unsup_path\n",
        "\n",
        "\n",
        "def gzip(filepath):\n",
        "  with open(filepath, 'rb') as f_in:\n",
        "    with gzip_lib.open(filepath + '.gz', 'wb') as f_out:\n",
        "      shutil.copyfileobj(f_in, f_out)\n",
        "  os.remove(filepath)\n",
        "\n",
        "\n",
        "def copy_tfrecords(input_uri, output_uri):\n",
        "  for filename in os.listdir(input_uri):\n",
        "    input_filename = os.path.join(input_uri, filename)\n",
        "    output_filename = os.path.join(output_uri, filename)\n",
        "    shutil.copyfile(input_filename, output_filename)\n",
        "\n",
        "\n",
        "@component\n",
        "def GraphAugmentation(identified_examples: InputArtifact[Examples],\n",
        "                      synthesized_graph: InputArtifact[SynthesizedGraph],\n",
        "                      augmented_examples: OutputArtifact[Examples],\n",
        "                      num_neighbors: Parameter[int],\n",
        "                      component_name: Parameter[str]) -> None:\n",
        "\n",
        "  # Get a list of the splits in input_data\n",
        "  splits_list = artifact_utils.decode_split_names(\n",
        "      split_names=identified_examples.split_names)\n",
        "\n",
        "  train_input_uri = os.path.join(identified_examples.uri, 'Split-train')\n",
        "  eval_input_uri = os.path.join(identified_examples.uri, 'Split-eval')\n",
        "  train_graph_uri = os.path.join(synthesized_graph.uri, 'Split-train')\n",
        "  train_output_uri = os.path.join(augmented_examples.uri, 'Split-train')\n",
        "  eval_output_uri = os.path.join(augmented_examples.uri, 'Split-eval')\n",
        "\n",
        "  os.mkdir(train_output_uri)\n",
        "  os.mkdir(eval_output_uri)\n",
        "\n",
        "  # Separate the labeled and unlabeled examples from the 'Split-train' split.\n",
        "  train_path, unsup_path = split_train_and_unsup(train_input_uri)\n",
        "\n",
        "  output_path = os.path.join(train_output_uri, 'nsl_train_data.tfr')\n",
        "  pack_nbrs_args = dict(\n",
        "      labeled_examples_path=train_path,\n",
        "      unlabeled_examples_path=unsup_path,\n",
        "      graph_path=os.path.join(train_graph_uri, 'graph.tsv'),\n",
        "      output_training_data_path=output_path,\n",
        "      add_undirected_edges=True,\n",
        "      max_nbrs=num_neighbors)\n",
        "  print('nsl.tools.pack_nbrs arguments:', pack_nbrs_args)\n",
        "  nsl.tools.pack_nbrs(**pack_nbrs_args)\n",
        "\n",
        "  # Downstream components expect gzip'ed TFRecords.\n",
        "  gzip(output_path)\n",
        "\n",
        "  # The test examples are left untouched and are simply copied over.\n",
        "  copy_tfrecords(eval_input_uri, eval_output_uri)\n",
        "\n",
        "  augmented_examples.split_names = identified_examples.split_names\n",
        "\n",
        "  return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r9MIEVDiOANe"
      },
      "outputs": [],
      "source": [
        "# Augments training data with graph neighbors.\n",
        "graph_augmentation = GraphAugmentation(\n",
        "    identified_examples=transform.outputs['transformed_examples'],\n",
        "    synthesized_graph=synthesize_graph.outputs['synthesized_graph'],\n",
        "    component_name=u'GraphAugmentation',\n",
        "    num_neighbors=3)\n",
        "context.run(graph_augmentation, enable_cache=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gpSLs3Hx8viI"
      },
      "outputs": [],
      "source": [
        "pprint_examples(graph_augmentation.outputs['augmented_examples'].get()[0], 6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBJFtnl6lCg9"
      },
      "source": [
        "### Trainer 구성 요소\n",
        "\n",
        "`Trainer` 구성 요소는 TensorFlow를 사용하여 모델을 훈련합니다.\n",
        "\n",
        "Estimator를 반환해야 하는 `trainer_fn` 함수가 포함된 Python 모듈을 만듭니다. Keras 모델 생성하려는 경우 `keras.model_to_estimator()`를 사용하여 이를 Estimator로 변환할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ajvClE6b2pd"
      },
      "outputs": [],
      "source": [
        "# Setup paths.\n",
        "_trainer_module_file = 'imdb_trainer.py'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_dh6AejVk2Oq"
      },
      "outputs": [],
      "source": [
        "%%writefile {_trainer_module_file}\n",
        "\n",
        "import neural_structured_learning as nsl\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import tensorflow_model_analysis as tfma\n",
        "import tensorflow_transform as tft\n",
        "from tensorflow_transform.tf_metadata import schema_utils\n",
        "\n",
        "\n",
        "NBR_FEATURE_PREFIX = 'NL_nbr_'\n",
        "NBR_WEIGHT_SUFFIX = '_weight'\n",
        "LABEL_KEY = 'label'\n",
        "ID_FEATURE_KEY = 'id'\n",
        "\n",
        "def _transformed_name(key):\n",
        "  return key + '_xf'\n",
        "\n",
        "\n",
        "def _transformed_names(keys):\n",
        "  return [_transformed_name(key) for key in keys]\n",
        "\n",
        "\n",
        "# Hyperparameters:\n",
        "#\n",
        "# We will use an instance of `HParams` to inclue various hyperparameters and\n",
        "# constants used for training and evaluation. We briefly describe each of them\n",
        "# below:\n",
        "#\n",
        "# -   max_seq_length: This is the maximum number of words considered from each\n",
        "#                     movie review in this example.\n",
        "# -   vocab_size: This is the size of the vocabulary considered for this\n",
        "#                 example.\n",
        "# -   oov_size: This is the out-of-vocabulary size considered for this example.\n",
        "# -   distance_type: This is the distance metric used to regularize the sample\n",
        "#                    with its neighbors.\n",
        "# -   graph_regularization_multiplier: This controls the relative weight of the\n",
        "#                                      graph regularization term in the overall\n",
        "#                                      loss function.\n",
        "# -   num_neighbors: The number of neighbors used for graph regularization. This\n",
        "#                    value has to be less than or equal to the `num_neighbors`\n",
        "#                    argument used above in the GraphAugmentation component when\n",
        "#                    invoking `nsl.tools.pack_nbrs`.\n",
        "# -   num_fc_units: The number of units in the fully connected layer of the\n",
        "#                   neural network.\n",
        "class HParams(object):\n",
        "  \"\"\"Hyperparameters used for training.\"\"\"\n",
        "  def __init__(self):\n",
        "    ### dataset parameters\n",
        "    # The following 3 values should match those defined in the Transform\n",
        "    # Component.\n",
        "    self.max_seq_length = 100\n",
        "    self.vocab_size = 10000\n",
        "    self.oov_size = 100\n",
        "    ### Neural Graph Learning parameters\n",
        "    self.distance_type = nsl.configs.DistanceType.L2\n",
        "    self.graph_regularization_multiplier = 0.1\n",
        "    # The following value has to be at most the value of 'num_neighbors' used\n",
        "    # in the GraphAugmentation component.\n",
        "    self.num_neighbors = 1\n",
        "    ### Model Architecture\n",
        "    self.num_embedding_dims = 16\n",
        "    self.num_fc_units = 64\n",
        "\n",
        "HPARAMS = HParams()\n",
        "\n",
        "\n",
        "def optimizer_fn():\n",
        "  \"\"\"Returns an instance of `tf.Optimizer`.\"\"\"\n",
        "  return tf.compat.v1.train.RMSPropOptimizer(\n",
        "    learning_rate=0.0001, decay=1e-6)\n",
        "\n",
        "\n",
        "def build_train_op(loss, global_step):\n",
        "  \"\"\"Builds a train op to optimize the given loss using gradient descent.\"\"\"\n",
        "  with tf.name_scope('train'):\n",
        "    optimizer = optimizer_fn()\n",
        "    train_op = optimizer.minimize(loss=loss, global_step=global_step)\n",
        "  return train_op\n",
        "\n",
        "\n",
        "# Building the model:\n",
        "#\n",
        "# A neural network is created by stacking layers—this requires two main\n",
        "# architectural decisions:\n",
        "# * How many layers to use in the model?\n",
        "# * How many *hidden units* to use for each layer?\n",
        "#\n",
        "# In this example, the input data consists of an array of word-indices. The\n",
        "# labels to predict are either 0 or 1. We will use a feed-forward neural network\n",
        "# as our base model in this tutorial.\n",
        "def feed_forward_model(features, is_training, reuse=tf.compat.v1.AUTO_REUSE):\n",
        "  \"\"\"Builds a simple 2 layer feed forward neural network.\n",
        "\n",
        "  The layers are effectively stacked sequentially to build the classifier. The\n",
        "  first layer is an Embedding layer, which takes the integer-encoded vocabulary\n",
        "  and looks up the embedding vector for each word-index. These vectors are\n",
        "  learned as the model trains. The vectors add a dimension to the output array.\n",
        "  The resulting dimensions are: (batch, sequence, embedding). Next is a global\n",
        "  average pooling 1D layer, which reduces the dimensionality of its inputs from\n",
        "  3D to 2D. This fixed-length output vector is piped through a fully-connected\n",
        "  (Dense) layer with 16 hidden units. The last layer is densely connected with a\n",
        "  single output node. Using the sigmoid activation function, this value is a\n",
        "  float between 0 and 1, representing a probability, or confidence level.\n",
        "\n",
        "  Args:\n",
        "    features: A dictionary containing batch features returned from the\n",
        "      `input_fn`, that include sample features, corresponding neighbor features,\n",
        "      and neighbor weights.\n",
        "    is_training: a Python Boolean value or a Boolean scalar Tensor, indicating\n",
        "      whether to apply dropout.\n",
        "    reuse: a Python Boolean value for reusing variable scope.\n",
        "\n",
        "  Returns:\n",
        "    logits: Tensor of shape [batch_size, 1].\n",
        "    representations: Tensor of shape [batch_size, _] for graph regularization.\n",
        "      This is the representation of each example at the graph regularization\n",
        "      layer.\n",
        "  \"\"\"\n",
        "\n",
        "  with tf.compat.v1.variable_scope('ff', reuse=reuse):\n",
        "    inputs = features[_transformed_name('text')]\n",
        "    embeddings = tf.compat.v1.get_variable(\n",
        "        'embeddings',\n",
        "        shape=[\n",
        "            HPARAMS.vocab_size + HPARAMS.oov_size, HPARAMS.num_embedding_dims\n",
        "        ])\n",
        "    embedding_layer = tf.nn.embedding_lookup(embeddings, inputs)\n",
        "\n",
        "    pooling_layer = tf.compat.v1.layers.AveragePooling1D(\n",
        "        pool_size=HPARAMS.max_seq_length, strides=HPARAMS.max_seq_length)(\n",
        "            embedding_layer)\n",
        "    # Shape of pooling_layer is now [batch_size, 1, HPARAMS.num_embedding_dims]\n",
        "    pooling_layer = tf.reshape(pooling_layer, [-1, HPARAMS.num_embedding_dims])\n",
        "\n",
        "    dense_layer = tf.compat.v1.layers.Dense(\n",
        "        16, activation='relu')(\n",
        "            pooling_layer)\n",
        "\n",
        "    output_layer = tf.compat.v1.layers.Dense(\n",
        "        1, activation='sigmoid')(\n",
        "            dense_layer)\n",
        "\n",
        "    # Graph regularization will be done on the penultimate (dense) layer\n",
        "    # because the output layer is a single floating point number.\n",
        "    return output_layer, dense_layer\n",
        "\n",
        "\n",
        "# A note on hidden units:\n",
        "#\n",
        "# The above model has two intermediate or \"hidden\" layers, between the input and\n",
        "# output, and excluding the Embedding layer. The number of outputs (units,\n",
        "# nodes, or neurons) is the dimension of the representational space for the\n",
        "# layer. In other words, the amount of freedom the network is allowed when\n",
        "# learning an internal representation. If a model has more hidden units\n",
        "# (a higher-dimensional representation space), and/or more layers, then the\n",
        "# network can learn more complex representations. However, it makes the network\n",
        "# more computationally expensive and may lead to learning unwanted\n",
        "# patterns—patterns that improve performance on training data but not on the\n",
        "# test data. This is called overfitting.\n",
        "\n",
        "\n",
        "# This function will be used to generate the embeddings for samples and their\n",
        "# corresponding neighbors, which will then be used for graph regularization.\n",
        "def embedding_fn(features, mode, **params):\n",
        "  \"\"\"Returns the embedding corresponding to the given features.\n",
        "\n",
        "  Args:\n",
        "    features: A dictionary containing batch features returned from the\n",
        "      `input_fn`, that include sample features, corresponding neighbor features,\n",
        "      and neighbor weights.\n",
        "    mode: Specifies if this is training, evaluation, or prediction. See\n",
        "      tf.estimator.ModeKeys.\n",
        "\n",
        "  Returns:\n",
        "    The embedding that will be used for graph regularization.\n",
        "  \"\"\"\n",
        "  is_training = (mode == tf.estimator.ModeKeys.TRAIN)\n",
        "  _, embedding = feed_forward_model(features, is_training)\n",
        "  return embedding\n",
        "\n",
        "\n",
        "def feed_forward_model_fn(features, labels, mode, params, config):\n",
        "  \"\"\"Implementation of the model_fn for the base feed-forward model.\n",
        "\n",
        "  Args:\n",
        "    features: This is the first item returned from the `input_fn` passed to\n",
        "      `train`, `evaluate`, and `predict`. This should be a single `Tensor` or\n",
        "      `dict` of same.\n",
        "    labels: This is the second item returned from the `input_fn` passed to\n",
        "      `train`, `evaluate`, and `predict`. This should be a single `Tensor` or\n",
        "      `dict` of same (for multi-head models). If mode is `ModeKeys.PREDICT`,\n",
        "      `labels=None` will be passed. If the `model_fn`'s signature does not\n",
        "      accept `mode`, the `model_fn` must still be able to handle `labels=None`.\n",
        "    mode: Optional. Specifies if this training, evaluation or prediction. See\n",
        "      `ModeKeys`.\n",
        "    params: An HParams instance as returned by get_hyper_parameters().\n",
        "    config: Optional configuration object. Will receive what is passed to\n",
        "      Estimator in `config` parameter, or the default `config`. Allows updating\n",
        "      things in your model_fn based on configuration such as `num_ps_replicas`,\n",
        "      or `model_dir`. Unused currently.\n",
        "\n",
        "  Returns:\n",
        "     A `tf.estimator.EstimatorSpec` for the base feed-forward model. This does\n",
        "     not include graph-based regularization.\n",
        "  \"\"\"\n",
        "\n",
        "  is_training = mode == tf.estimator.ModeKeys.TRAIN\n",
        "\n",
        "  # Build the computation graph.\n",
        "  probabilities, _ = feed_forward_model(features, is_training)\n",
        "  predictions = tf.round(probabilities)\n",
        "\n",
        "  if mode == tf.estimator.ModeKeys.PREDICT:\n",
        "    # labels will be None, and no loss to compute.\n",
        "    cross_entropy_loss = None\n",
        "    eval_metric_ops = None\n",
        "  else:\n",
        "    # Loss is required in train and eval modes.\n",
        "    # Flatten 'probabilities' to 1-D.\n",
        "    probabilities = tf.reshape(probabilities, shape=[-1])\n",
        "    cross_entropy_loss = tf.compat.v1.keras.losses.binary_crossentropy(\n",
        "        labels, probabilities)\n",
        "    eval_metric_ops = {\n",
        "        'accuracy': tf.compat.v1.metrics.accuracy(labels, predictions)\n",
        "    }\n",
        "\n",
        "  if is_training:\n",
        "    global_step = tf.compat.v1.train.get_or_create_global_step()\n",
        "    train_op = build_train_op(cross_entropy_loss, global_step)\n",
        "  else:\n",
        "    train_op = None\n",
        "\n",
        "  return tf.estimator.EstimatorSpec(\n",
        "      mode=mode,\n",
        "      predictions={\n",
        "          'probabilities': probabilities,\n",
        "          'predictions': predictions\n",
        "      },\n",
        "      loss=cross_entropy_loss,\n",
        "      train_op=train_op,\n",
        "      eval_metric_ops=eval_metric_ops)\n",
        "\n",
        "\n",
        "# Tf.Transform considers these features as \"raw\"\n",
        "def _get_raw_feature_spec(schema):\n",
        "  return schema_utils.schema_as_feature_spec(schema).feature_spec\n",
        "\n",
        "\n",
        "def _gzip_reader_fn(filenames):\n",
        "  \"\"\"Small utility returning a record reader that can read gzip'ed files.\"\"\"\n",
        "  return tf.data.TFRecordDataset(\n",
        "      filenames,\n",
        "      compression_type='GZIP')\n",
        "\n",
        "\n",
        "def _example_serving_receiver_fn(tf_transform_output, schema):\n",
        "  \"\"\"Build the serving in inputs.\n",
        "\n",
        "  Args:\n",
        "    tf_transform_output: A TFTransformOutput.\n",
        "    schema: the schema of the input data.\n",
        "\n",
        "  Returns:\n",
        "    Tensorflow graph which parses examples, applying tf-transform to them.\n",
        "  \"\"\"\n",
        "  raw_feature_spec = _get_raw_feature_spec(schema)\n",
        "  raw_feature_spec.pop(LABEL_KEY)\n",
        "\n",
        "  # We don't need the ID feature for serving.\n",
        "  raw_feature_spec.pop(ID_FEATURE_KEY)\n",
        "\n",
        "  raw_input_fn = tf.estimator.export.build_parsing_serving_input_receiver_fn(\n",
        "      raw_feature_spec, default_batch_size=None)\n",
        "  serving_input_receiver = raw_input_fn()\n",
        "\n",
        "  transformed_features = tf_transform_output.transform_raw_features(\n",
        "      serving_input_receiver.features)\n",
        "\n",
        "  # Even though, LABEL_KEY was removed from 'raw_feature_spec', the transform\n",
        "  # operation would have injected the transformed LABEL_KEY feature with a\n",
        "  # default value.\n",
        "  transformed_features.pop(_transformed_name(LABEL_KEY))\n",
        "  return tf.estimator.export.ServingInputReceiver(\n",
        "      transformed_features, serving_input_receiver.receiver_tensors)\n",
        "\n",
        "\n",
        "def _eval_input_receiver_fn(tf_transform_output, schema):\n",
        "  \"\"\"Build everything needed for the tf-model-analysis to run the model.\n",
        "\n",
        "  Args:\n",
        "    tf_transform_output: A TFTransformOutput.\n",
        "    schema: the schema of the input data.\n",
        "\n",
        "  Returns:\n",
        "    EvalInputReceiver function, which contains:\n",
        "      - Tensorflow graph which parses raw untransformed features, applies the\n",
        "        tf-transform preprocessing operators.\n",
        "      - Set of raw, untransformed features.\n",
        "      - Label against which predictions will be compared.\n",
        "  \"\"\"\n",
        "  # Notice that the inputs are raw features, not transformed features here.\n",
        "  raw_feature_spec = _get_raw_feature_spec(schema)\n",
        "\n",
        "  # We don't need the ID feature for TFMA.\n",
        "  raw_feature_spec.pop(ID_FEATURE_KEY)\n",
        "\n",
        "  raw_input_fn = tf.estimator.export.build_parsing_serving_input_receiver_fn(\n",
        "      raw_feature_spec, default_batch_size=None)\n",
        "  serving_input_receiver = raw_input_fn()\n",
        "\n",
        "  transformed_features = tf_transform_output.transform_raw_features(\n",
        "      serving_input_receiver.features)\n",
        "\n",
        "  labels = transformed_features.pop(_transformed_name(LABEL_KEY))\n",
        "  return tfma.export.EvalInputReceiver(\n",
        "      features=transformed_features,\n",
        "      receiver_tensors=serving_input_receiver.receiver_tensors,\n",
        "      labels=labels)\n",
        "\n",
        "\n",
        "def _augment_feature_spec(feature_spec, num_neighbors):\n",
        "  \"\"\"Augments `feature_spec` to include neighbor features.\n",
        "    Args:\n",
        "      feature_spec: Dictionary of feature keys mapping to TF feature types.\n",
        "      num_neighbors: Number of neighbors to use for feature key augmentation.\n",
        "    Returns:\n",
        "      An augmented `feature_spec` that includes neighbor feature keys.\n",
        "  \"\"\"\n",
        "  for i in range(num_neighbors):\n",
        "    feature_spec['{}{}_{}'.format(NBR_FEATURE_PREFIX, i, 'id')] = \\\n",
        "        tf.io.VarLenFeature(dtype=tf.string)\n",
        "    # We don't care about the neighbor features corresponding to\n",
        "    # _transformed_name(LABEL_KEY) because the LABEL_KEY feature will be\n",
        "    # removed from the feature spec during training/evaluation.\n",
        "    feature_spec['{}{}_{}'.format(NBR_FEATURE_PREFIX, i, 'text_xf')] = \\\n",
        "        tf.io.FixedLenFeature(shape=[HPARAMS.max_seq_length], dtype=tf.int64,\n",
        "                              default_value=tf.constant(0, dtype=tf.int64,\n",
        "                                                        shape=[HPARAMS.max_seq_length]))\n",
        "    # The 'NL_num_nbrs' features is currently not used.\n",
        "\n",
        "  # Set the neighbor weight feature keys.\n",
        "  for i in range(num_neighbors):\n",
        "    feature_spec['{}{}{}'.format(NBR_FEATURE_PREFIX, i, NBR_WEIGHT_SUFFIX)] = \\\n",
        "        tf.io.FixedLenFeature(shape=[1], dtype=tf.float32, default_value=[0.0])\n",
        "\n",
        "  return feature_spec\n",
        "\n",
        "\n",
        "def _input_fn(filenames, tf_transform_output, is_training, batch_size=200):\n",
        "  \"\"\"Generates features and labels for training or evaluation.\n",
        "\n",
        "  Args:\n",
        "    filenames: [str] list of CSV files to read data from.\n",
        "    tf_transform_output: A TFTransformOutput.\n",
        "    is_training: Boolean indicating if we are in training mode.\n",
        "    batch_size: int First dimension size of the Tensors returned by input_fn\n",
        "\n",
        "  Returns:\n",
        "    A (features, indices) tuple where features is a dictionary of\n",
        "      Tensors, and indices is a single Tensor of label indices.\n",
        "  \"\"\"\n",
        "  transformed_feature_spec = (\n",
        "      tf_transform_output.transformed_feature_spec().copy())\n",
        "\n",
        "  # During training, NSL uses augmented training data (which includes features\n",
        "  # from graph neighbors). So, update the feature spec accordingly. This needs\n",
        "  # to be done because we are using different schemas for NSL training and eval,\n",
        "  # but the Trainer Component only accepts a single schema.\n",
        "  if is_training:\n",
        "    transformed_feature_spec =_augment_feature_spec(transformed_feature_spec,\n",
        "                                                    HPARAMS.num_neighbors)\n",
        "\n",
        "  dataset = tf.data.experimental.make_batched_features_dataset(\n",
        "      filenames, batch_size, transformed_feature_spec, reader=_gzip_reader_fn)\n",
        "\n",
        "  transformed_features = tf.compat.v1.data.make_one_shot_iterator(\n",
        "      dataset).get_next()\n",
        "  # We pop the label because we do not want to use it as a feature while we're\n",
        "  # training.\n",
        "  return transformed_features, transformed_features.pop(\n",
        "      _transformed_name(LABEL_KEY))\n",
        "\n",
        "\n",
        "# TFX will call this function\n",
        "def trainer_fn(hparams, schema):\n",
        "  \"\"\"Build the estimator using the high level API.\n",
        "  Args:\n",
        "    hparams: Holds hyperparameters used to train the model as name/value pairs.\n",
        "    schema: Holds the schema of the training examples.\n",
        "  Returns:\n",
        "    A dict of the following:\n",
        "      - estimator: The estimator that will be used for training and eval.\n",
        "      - train_spec: Spec for training.\n",
        "      - eval_spec: Spec for eval.\n",
        "      - eval_input_receiver_fn: Input function for eval.\n",
        "  \"\"\"\n",
        "  train_batch_size = 40\n",
        "  eval_batch_size = 40\n",
        "\n",
        "  tf_transform_output = tft.TFTransformOutput(hparams.transform_output)\n",
        "\n",
        "  train_input_fn = lambda: _input_fn(\n",
        "      hparams.train_files,\n",
        "      tf_transform_output,\n",
        "      is_training=True,\n",
        "      batch_size=train_batch_size)\n",
        "\n",
        "  eval_input_fn = lambda: _input_fn(\n",
        "      hparams.eval_files,\n",
        "      tf_transform_output,\n",
        "      is_training=False,\n",
        "      batch_size=eval_batch_size)\n",
        "\n",
        "  train_spec = tf.estimator.TrainSpec(\n",
        "      train_input_fn,\n",
        "      max_steps=hparams.train_steps)\n",
        "\n",
        "  serving_receiver_fn = lambda: _example_serving_receiver_fn(\n",
        "      tf_transform_output, schema)\n",
        "\n",
        "  exporter = tf.estimator.FinalExporter('imdb', serving_receiver_fn)\n",
        "  eval_spec = tf.estimator.EvalSpec(\n",
        "      eval_input_fn,\n",
        "      steps=hparams.eval_steps,\n",
        "      exporters=[exporter],\n",
        "      name='imdb-eval')\n",
        "\n",
        "  run_config = tf.estimator.RunConfig(\n",
        "      save_checkpoints_steps=999, keep_checkpoint_max=1)\n",
        "\n",
        "  run_config = run_config.replace(model_dir=hparams.serving_model_dir)\n",
        "\n",
        "  estimator = tf.estimator.Estimator(\n",
        "      model_fn=feed_forward_model_fn, config=run_config, params=HPARAMS)\n",
        "\n",
        "  # Create a graph regularization config.\n",
        "  graph_reg_config = nsl.configs.make_graph_reg_config(\n",
        "      max_neighbors=HPARAMS.num_neighbors,\n",
        "      multiplier=HPARAMS.graph_regularization_multiplier,\n",
        "      distance_type=HPARAMS.distance_type,\n",
        "      sum_over_axis=-1)\n",
        "\n",
        "  # Invoke the Graph Regularization Estimator wrapper to incorporate\n",
        "  # graph-based regularization for training.\n",
        "  graph_nsl_estimator = nsl.estimator.add_graph_regularization(\n",
        "      estimator,\n",
        "      embedding_fn,\n",
        "      optimizer_fn=optimizer_fn,\n",
        "      graph_reg_config=graph_reg_config)\n",
        "\n",
        "  # Create an input receiver for TFMA processing\n",
        "  receiver_fn = lambda: _eval_input_receiver_fn(\n",
        "      tf_transform_output, schema)\n",
        "\n",
        "  return {\n",
        "      'estimator': graph_nsl_estimator,\n",
        "      'train_spec': train_spec,\n",
        "      'eval_spec': eval_spec,\n",
        "      'eval_input_receiver_fn': receiver_fn\n",
        "  }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnLjStUJIoos"
      },
      "source": [
        "`Trainer` 구성 요소를 만들고 실행하여 위에서 만든 파일을 전달합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MWLQI6t0b2pg"
      },
      "outputs": [],
      "source": [
        "# Uses user-provided Python function that implements a model using TensorFlow's\n",
        "# Estimators API.\n",
        "trainer = Trainer(\n",
        "    module_file=_trainer_module_file,\n",
        "    custom_executor_spec=executor_spec.ExecutorClassSpec(\n",
        "        trainer_executor.Executor),\n",
        "    transformed_examples=graph_augmentation.outputs['augmented_examples'],\n",
        "    schema=schema_gen.outputs['schema'],\n",
        "    transform_graph=transform.outputs['transform_graph'],\n",
        "    train_args=trainer_pb2.TrainArgs(num_steps=10000),\n",
        "    eval_args=trainer_pb2.EvalArgs(num_steps=5000))\n",
        "context.run(trainer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDiZvYbFb2ph"
      },
      "source": [
        "`Trainer`에서 내보낸 훈련된 모델을 살펴보세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qDBZG9Oso-BD"
      },
      "outputs": [],
      "source": [
        "train_uri = trainer.outputs['model'].get()[0].uri\n",
        "serving_model_path = os.path.join(train_uri, 'Format-Serving')\n",
        "exported_model = tf.saved_model.load(serving_model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KyT3ZVGCZWsj"
      },
      "outputs": [],
      "source": [
        "exported_model.graph.get_operations()[:10] + [\"...\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIsspBf5GjKm"
      },
      "source": [
        "Tensorboard를 사용하여 모델의 메트릭을 시각화해 보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rnKeqLmcGqHH"
      },
      "outputs": [],
      "source": [
        "#docs_infra: no_execute\n",
        "\n",
        "# Get the URI of the output artifact representing the training logs,\n",
        "# which is a directory\n",
        "model_run_dir = trainer.outputs['model_run'].get()[0].uri\n",
        "\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir {model_run_dir}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgZXZJBsGzHm"
      },
      "source": [
        "## 모델 제공\n",
        "\n",
        "그래프 정규화는 손실 함수에 정규화 항을 추가하여 훈련 워크플로에만 영향을 미칩니다. 결과적으로 모델 평가 및 제공 워크플로는 변경되지 않은 상태로 유지됩니다. *Evaluator*, *Pusher* 등과 같은 *Trainer* 구성 요소 뒤에 일반적으로 오는 다운스트림 TFX 구성 요소를 생략한 것도 같은 이유입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOh5FjbWiP-b"
      },
      "source": [
        "## 결론\n",
        "\n",
        "입력에 명시적 그래프가 포함되지 않은 경우에도 TFX 파이프라인에서 Neural Structured Learning(NSL) 프레임워크를 사용하여 그래프 정규화를 사용하는 방법을 시연했습니다. 리뷰 임베딩을 기반으로 유사성 그래프를 합성한 IMDB 영화 리뷰의 감정 분류 작업을 고려했습니다. 그래프 구성에 다양한 임베딩을 사용하고, 하이퍼 매개변수를 변경하고, 감독의 양을 변경하고, 다양한 모델 아키텍처를 정의하여 더 많은 실험을 해볼 것을 권장합니다."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "24gYiJcWNlpA"
      ],
      "name": "neural_structured_learning.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
