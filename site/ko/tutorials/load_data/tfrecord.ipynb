{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pL--_KGdYoBz"
      },
      "source": [
        "##### Copyright 2019 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "uBDvXpYzYnGj"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQzaEQuJiW_d"
      },
      "source": [
        "# TFRecord 및 tf.Example\n",
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td><a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/load_data/tfrecord\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\"> TensorFlow.org에서 보기</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/load_data/tfrecord.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Google Colab에서 실행</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/tfrecord.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\"> GitHub에서 소스 보기</a></td>\n",
        "  <td><a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/tutorials/load_data/tfrecord.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">노트북 다운로드</a></td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3pkUd_9IZCFO"
      },
      "source": [
        "데이터를 효율적으로 읽으려면 데이터를 직렬화하여 각각을 선형적으로 읽을 수 있는 파일 세트(각각 100~200MB)에 저장하면 도움이 될 수 있습니다. 데이터가 네트워크를 통해 스트리밍되는 경우에는 특히 그렇습니다. 또한 데이터 전처리를 캐싱하는 데도 유용할 수 있습니다.\n",
        "\n",
        "TFRecord 형식은 일련의 이진 레코드를 저장하기 위한 단순한 형식입니다.\n",
        "\n",
        "[프로토콜 버퍼](https://developers.google.com/protocol-buffers/)는 구조화된 데이터의 효율적인 직렬화를 위한 플랫폼 및 언어 간 라이브러리입니다.\n",
        "\n",
        "프로토콜 메시지는 `.proto` 파일로 정의되며 메시지 유형을 이해하는 가장 쉬운 방법인 경우가 많습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ac83J0QxjhFt"
      },
      "source": [
        "이 노트북은 `tf.Example` 메시지를 생성 및 구문 분석하고 사용한 다음 `tf.Example` 메시지를 `.tfrecord` 파일 사이에서 직렬화하고 쓰기 및 읽기를 수행하는 방법을 보여줍니다.\n",
        "\n",
        "참고: 유용하기는 하지만 이러한 구조는 선택적입니다. [`tf.data`](https://www.tensorflow.org/guide/data)를 사용하면서 데이터 읽기가 훈련에 계속 병목 현상을 일으키는 경우가 아니라면 TFRecords를 사용하도록 기존 코드를 변환할 필요는 없습니다. 데이터세트 성능에 대한 유용한 정보는 [데이터 입력 파이프라인 성능](https://www.tensorflow.org/guide/performance/datasets)을 참조하세요.\n",
        "\n",
        "참고: 일반적으로, I/O를 병렬화할 수 있도록 여러 파일에 데이터를 분할해야 합니다(단일 호스트 내에서, 또는 여러 호스트에서). 경험상 데이터를 읽는 호스트 수보다 파일 수가 최소 10배 이상 되어야 합니다. 이와 동시에 I/O 프리페치의 이점을 누릴 수 있으려면 각 파일이 충분히 커야 합니다(최소 10MB 이상, 이상적으로는 100MB 이상). 예를 들어, `X` GB의 데이터가 있고 최대 `N`개의 호스트에서 훈련할 계획이라고 가정해 보겠습니다. 이상적으로, ~ `X/(10*N)`가 10MB 이상(이상적으로는 100MB 이상)이면 데이터를 ~ `10*N` 파일로 분할해야 합니다. 이보다 적으면 병렬 처리의 이점과 I/O 프리페치의 이점을 절충하기 위해 더 적은 수의 샤드를 만들어야 할 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WkRreBf1eDVc"
      },
      "source": [
        "## !pip install -U tf-hub-nightly<br>import tensorflow_hub as hub<br><br>from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ja7sezsmnXph"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "import IPython.display as display"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5Kq88ccUWQV"
      },
      "source": [
        "## `tf.train.Example`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VrdQHgvNijTi"
      },
      "source": [
        "### `tf.Example`의 데이터 형식"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZw57Qrn4CTE"
      },
      "source": [
        "기본적으로 `tf.Example`은 `{\"string\": tf.train.Feature}` 매핑입니다.\n",
        "\n",
        "`tf.train.Feature` 메시지 유형은 다음 3가지 유형 중 하나를 허용할 수 있습니다([`.proto` 파일](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/example/feature.proto) 참조). 다른 대부분의 일반 형식은 다음 중 하나로 강제 변환할 수 있습니다.\n",
        "\n",
        "1. `tf.train.BytesList`(다음 유형을 강제 변환할 수 있음)\n",
        "\n",
        "- `string`\n",
        "- `byte`\n",
        "\n",
        "1. `tf.train.FloatList`(다음 유형을 강제 변환할 수 있음)\n",
        "\n",
        "- `float` ( `float32` )\n",
        "- `double` ( `float64` )\n",
        "\n",
        "1. `tf.train.Int64List`(다음 유형을 강제 변환할 수 있음)\n",
        "\n",
        "- `bool`\n",
        "- `enum`\n",
        "- `int32`\n",
        "- `uint32`\n",
        "- `int64`\n",
        "- `uint64`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_e3g9ExathXP"
      },
      "source": [
        "표준 TensorFlow 유형을 `tf.Example` 호환 `tf.train.Feature` 로 변환하려면 아래 바로 가기 함수를 사용할 수 있습니다. 각 함수는 스칼라 입력 값을 받아들여 위의 세 가지 `list` 유형 중 하나를 포함하는 `tf.train.Feature`를 반환합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mbsPOUpVtYxA"
      },
      "outputs": [],
      "source": [
        "# The following functions can be used to convert a value to a type compatible\n",
        "# with tf.train.Example.\n",
        "\n",
        "def _bytes_feature(value):\n",
        "  \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
        "  if isinstance(value, type(tf.constant(0))):\n",
        "    value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
        "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
        "\n",
        "def _float_feature(value):\n",
        "  \"\"\"Returns a float_list from a float / double.\"\"\"\n",
        "  return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
        "\n",
        "def _int64_feature(value):\n",
        "  \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
        "  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wst0v9O8hgzy"
      },
      "source": [
        "참고: 단순화를 위해 이 예에서는 스칼라 입력만 사용합니다. 스칼라가 아닌 특성을 처리하는 가장 간단한 방법은 `tf.io.serialize_tensor`를 사용하여 텐서를 이진 문자열로 변환하는 것입니다. 문자열은 tensorflow에서 스칼라입니다. 이진 문자열을 다시 텐서로 변환하려면 `tf.io.parse_tensor`를 사용하세요."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsMbkkC8xxtB"
      },
      "source": [
        "다음은 이러한 함수의 작동 방식을 보여주는 몇 가지 예입니다. 다양한 입력 유형과 표준화된 출력 유형에 주목하세요. 함수의 입력 유형이 위에서 언급 한 강제 변환할 수 있는 유형 중 하나와 일치하지 않으면 함수에서 예외가 발생합니다(예: `1.0`은 부동 소수점이어서 `_int64_feature(1.0)` 오류가 발생하므로 대신 `_float_feature` 함수와 함께 사용해야 함)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hZzyLGr0u73y"
      },
      "outputs": [],
      "source": [
        "print(_bytes_feature(b'test_string'))\n",
        "print(_bytes_feature(u'test_bytes'.encode('utf-8')))\n",
        "\n",
        "print(_float_feature(np.exp(1)))\n",
        "\n",
        "print(_int64_feature(True))\n",
        "print(_int64_feature(1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nj1qpfQU5qmi"
      },
      "source": [
        "`.SerializeToString` 메서드를 사용하여 모든 proto 메시지를 이진 문자열로 직렬화할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5afZkORT5pjm"
      },
      "outputs": [],
      "source": [
        "feature = _float_feature(np.exp(1))\n",
        "\n",
        "feature.SerializeToString()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "laKnw9F3hL-W"
      },
      "source": [
        "### `tf.Example` 메시지 작성하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_MEnhxchQPC"
      },
      "source": [
        "기존 데이터에서 `tf.Example` 메시지를 작성한다고 가정해 보겠습니다. 실제로 데이터세트는 어디서든 올 수 있지만 단일 관측에서 `tf.Example` 메시지를 작성하는 절차는 같습니다.\n",
        "\n",
        "1. 각 관측 내에서 각 값은 위의 함수 중 하나를 사용하여 3가지 호환 유형 중 하나를 포함하는 `tf.train.Feature`로 변환해야 합니다.\n",
        "\n",
        "2. 특성 이름 문자열을 #1에서 생성된 인코딩된 특성 값과 연결하는 맵(사전)을 생성합니다.\n",
        "\n",
        "3. 2단계에서 생성한 맵은 [`Features` 메시지](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/example/feature.proto#L85)로 변환됩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4EgFQ2uHtchc"
      },
      "source": [
        "이 노트북에서는 NumPy를 사용하여 데이터세트를 만듭니다.\n",
        "\n",
        "이 데이터세트에는 4가지 특성이 있습니다.\n",
        "\n",
        "- 확률이 동일한 부울 특성 `False` 또는 `True`\n",
        "- `[0, 5]`에서 균일하게 무작위로 선택된 정수 특성\n",
        "- 정수 특성을 인덱스로 사용하여 문자열 테이블에서 생성된 문자열 특성\n",
        "- 표준 정규 분포의 부동 특성\n",
        "\n",
        "위의 각 분포에서 독립적으로 동일하게 분포된 관측 값 10,000개로 구성된 표본을 고려하겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CnrguFAy3YQv"
      },
      "outputs": [],
      "source": [
        "# The number of observations in the dataset.\n",
        "n_observations = int(1e4)\n",
        "\n",
        "# Boolean feature, encoded as False or True.\n",
        "feature0 = np.random.choice([False, True], n_observations)\n",
        "\n",
        "# Integer feature, random from 0 to 4.\n",
        "feature1 = np.random.randint(0, 5, n_observations)\n",
        "\n",
        "# String feature.\n",
        "strings = np.array([b'cat', b'dog', b'chicken', b'horse', b'goat'])\n",
        "feature2 = strings[feature1]\n",
        "\n",
        "# Float feature, from a standard normal distribution.\n",
        "feature3 = np.random.randn(n_observations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGrscehJr7Jd"
      },
      "source": [
        "이러한 각 특성은 `_bytes_feature` , `_float_feature` , `_int64_feature` 중 하나를 사용하여 `tf.Example` 호환 유형으로 강제 변환할 수 있습니다. 그런 다음, 이러한 인코딩된 특성에서 `tf.Example` 메시지를 작성할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RTCS49Ij_kUw"
      },
      "outputs": [],
      "source": [
        "def serialize_example(feature0, feature1, feature2, feature3):\n",
        "  \"\"\"\n",
        "  Creates a tf.train.Example message ready to be written to a file.\n",
        "  \"\"\"\n",
        "  # Create a dictionary mapping the feature name to the tf.train.Example-compatible\n",
        "  # data type.\n",
        "  feature = {\n",
        "      'feature0': _int64_feature(feature0),\n",
        "      'feature1': _int64_feature(feature1),\n",
        "      'feature2': _bytes_feature(feature2),\n",
        "      'feature3': _float_feature(feature3),\n",
        "  }\n",
        "\n",
        "  # Create a Features message using tf.train.Example.\n",
        "\n",
        "  example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
        "  return example_proto.SerializeToString()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XftzX9CN_uGT"
      },
      "source": [
        "예를 들어, 데이터세트에서 얻은 단일 관측 `[False, 4, bytes('goat'), 0.9876]`이 있다고 하겠습니다. `create_message()`를 사용하여 이 관측에 대한 `tf.Example` 메시지를 작성하고 인쇄할 수 있습니다. 각 단일 관측은 위의 조건에 따라 `Features` 메시지로 작성됩니다. `tf.Example` [메시지](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/example/example.proto#L88)는 `Features` 메시지 주변에서 단지 래퍼로만 작동합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N8BtSx2RjYcb"
      },
      "outputs": [],
      "source": [
        "# This is an example observation from the dataset.\n",
        "\n",
        "example_observation = []\n",
        "\n",
        "serialized_example = serialize_example(False, 4, b'goat', 0.9876)\n",
        "serialized_example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pbGATlG6u-4"
      },
      "source": [
        "메시지를 디코딩하려면 `tf.train.Example.FromString` 메서드를 사용합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dGim-mEm6vit"
      },
      "outputs": [],
      "source": [
        "example_proto = tf.train.Example.FromString(serialized_example)\n",
        "example_proto"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6qxofy89obI"
      },
      "source": [
        "## TF 레코드 형식 세부 사항\n",
        "\n",
        "TFRecord 파일에는 일련의 레코드가 포함됩니다. 파일은 순차적으로만 읽을 수 있습니다.\n",
        "\n",
        "각 레코드에는 데이터 페이로드에 대한 바이트 문자열과 데이터 길이 및 무결성 검사를 위한 CRC32C(Castagnoli 다항식을 사용하는 32비트 CRC) 해시가 포함됩니다.\n",
        "\n",
        "각 레코드는 다음 형식으로 저장됩니다.\n",
        "\n",
        "```\n",
        "uint64 length\n",
        "uint32 masked_crc32_of_length\n",
        "byte   data[length]\n",
        "uint32 masked_crc32_of_data\n",
        "```\n",
        "\n",
        "이 레코드는 함께 연결되어 파일을 생성합니다. CRC는 [여기서 설명](https://en.wikipedia.org/wiki/Cyclic_redundancy_check)하며 CRC 마스크는 다음과 같습니다.\n",
        "\n",
        "```\n",
        "masked_crc = ((crc >> 15) | (crc << 17)) + 0xa282ead8ul\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0iHagLQCJv6"
      },
      "source": [
        "참고: TFRecord 파일에서 `tf.train.Example`을 사용할 필요는 없습니다. `tf.train.Example`은 사전을 바이트 문자열로 직렬화하는 방법일 뿐입니다. TensorFlow에서 디코딩할 수 있는 모든 바이트 문자열은 TFRecord 파일에 저장할 수 있습니다. 텍스트 줄, JSON(`tf.io.decode_json_example` 사용), 인코딩된 이미지 데이터 또는 직렬화된 `tf.Tensors`(`tf.io.serialize_tensor`/`tf.io.parse_tensor` 사용) 등을 예로 들 수 있습니다. 더 많은 옵션은 `tf.io` 모듈을 참조하세요."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-Hjmee-fbLH"
      },
      "source": [
        "## `tf.data`를 사용한 TFRecord 파일"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmehkCCT81Ez"
      },
      "source": [
        "`tf.data` 모듈은 TensorFlow에서 데이터를 읽고 쓰기 위한 도구를 제공합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FISEuz8ubu3"
      },
      "source": [
        "### TFRecord 파일 작성하기\n",
        "\n",
        "데이터를 데이터세트로 가져오는 가장 쉬운 방법은 `from_tensor_slices` 메서드를 사용하는 것입니다.\n",
        "\n",
        "배열에 적용했을 때는 스칼라의 데이터세트를 반환합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mXeaukvwu5_-"
      },
      "outputs": [],
      "source": [
        "tf.data.Dataset.from_tensor_slices(feature1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-q0VKyZvcad"
      },
      "source": [
        "배열의 튜플에 적용하면 튜플의 데이터세트를 반환합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H5sWyu1kxnvg"
      },
      "outputs": [],
      "source": [
        "features_dataset = tf.data.Dataset.from_tensor_slices((feature0, feature1, feature2, feature3))\n",
        "features_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m1C-t71Nywze"
      },
      "outputs": [],
      "source": [
        "# Use `take(1)` to only pull one example from the dataset.\n",
        "for f0,f1,f2,f3 in features_dataset.take(1):\n",
        "  print(f0)\n",
        "  print(f1)\n",
        "  print(f2)\n",
        "  print(f3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhIe63awyZYd"
      },
      "source": [
        "`tf.data.Dataset.map` 메서드를 사용하여 `Dataset` 각 요소에 함수를 적용합니다.\n",
        "\n",
        "매핑된 함수는 TensorFlow 그래프 모드에서 작동해야 합니다(`tf.Tensors`에서 작동하고 이를 반환해야 함). `serialize_example`과 같이 텐서가 아닌 함수는 `tf.py_function`으로 래핑하여 호환되도록 만들 수 있습니다.\n",
        "\n",
        "`tf.py_function` 사용하려면 다른 방식으로는 사용할 수 없는 형상과 유형 정보를 지정해야 합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "apB5KYrJzjPI"
      },
      "outputs": [],
      "source": [
        "def tf_serialize_example(f0,f1,f2,f3):\n",
        "  tf_string = tf.py_function(\n",
        "    serialize_example,\n",
        "    (f0, f1, f2, f3),  # Pass these args to the above function.\n",
        "    tf.string)      # The return type is `tf.string`.\n",
        "  return tf.reshape(tf_string, ()) # The result is a scalar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lHFjW4u4Npz9"
      },
      "outputs": [],
      "source": [
        "tf_serialize_example(f0, f1, f2, f3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrFZ9avE3HUF"
      },
      "source": [
        "이 함수를 데이터세트의 각 요소에 적용합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VDeqYVbW3ww9"
      },
      "outputs": [],
      "source": [
        "serialized_features_dataset = features_dataset.map(tf_serialize_example)\n",
        "serialized_features_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DlDfuh46bRf6"
      },
      "outputs": [],
      "source": [
        "def generator():\n",
        "  for features in features_dataset:\n",
        "    yield serialize_example(*features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iv9oXKrcbhvX"
      },
      "outputs": [],
      "source": [
        "serialized_features_dataset = tf.data.Dataset.from_generator(\n",
        "    generator, output_types=tf.string, output_shapes=())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dqz8C4D5cIj9"
      },
      "outputs": [],
      "source": [
        "serialized_features_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6lw5VYpjZZC"
      },
      "source": [
        "그리고 TFRecord 파일에 이 내용을 작성합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vP1VgTO44UIE"
      },
      "outputs": [],
      "source": [
        "filename = 'test.tfrecord'\n",
        "writer = tf.data.experimental.TFRecordWriter(filename)\n",
        "writer.write(serialized_features_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aV0GQhV8tmp"
      },
      "source": [
        "### TFRecord 파일 읽기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3J5D4gcSy8N"
      },
      "source": [
        "`tf.data.TFRecordDataset` 클래스를 사용하여 TFRecord 파일을 읽을 수도 있습니다.\n",
        "\n",
        "`tf.data`를 사용하여 TFRecord 파일을 소비하기 위한 자세한 내용은 [여기](https://www.tensorflow.org/guide/datasets#consuming_tfrecord_data)에서 확인할 수 있습니다.\n",
        "\n",
        "`TFRecordDataset`를 사용하면 입력 데이터를 표준화하고 성능을 최적화하는 데 유용할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6OjX6UZl-bHC"
      },
      "outputs": [],
      "source": [
        "filenames = [filename]\n",
        "raw_dataset = tf.data.TFRecordDataset(filenames)\n",
        "raw_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_EQ9i2E_-Fz"
      },
      "source": [
        "이 시점에서 데이터세트에는 직렬화된 `tf.train.Example` 메시지가 포함됩니다. 반복 실행하면 메시지가 스칼라 문자열 텐서로 반환됩니다.\n",
        "\n",
        "`.take` 메서드를 사용하여 처음 10개의 레코드만 표시합니다.\n",
        "\n",
        "참고: `tf.data.Dataset`의 반복 실행은 즉시 실행이 활성화된 경우에만 작동합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hxVXpLz_AJlm"
      },
      "outputs": [],
      "source": [
        "for raw_record in raw_dataset.take(10):\n",
        "  print(repr(raw_record))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-6oNzM4luFQ"
      },
      "source": [
        "이러한 텐서는 아래 함수를 이용해 구문 분석할 수 있습니다. 여기서 `feature_description`이 필요한 이유는 데이터세트가 그래프 실행을 사용하고 형상과 유형을 빌드하기 위해 이 설명을 필요로 하기 때문입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zQjbIR1nleiy"
      },
      "outputs": [],
      "source": [
        "# Create a description of the features.\n",
        "feature_description = {\n",
        "    'feature0': tf.io.FixedLenFeature([], tf.int64, default_value=0),\n",
        "    'feature1': tf.io.FixedLenFeature([], tf.int64, default_value=0),\n",
        "    'feature2': tf.io.FixedLenFeature([], tf.string, default_value=''),\n",
        "    'feature3': tf.io.FixedLenFeature([], tf.float32, default_value=0.0),\n",
        "}\n",
        "\n",
        "def _parse_function(example_proto):\n",
        "  # Parse the input `tf.train.Example` proto using the dictionary above.\n",
        "  return tf.io.parse_single_example(example_proto, feature_description)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWETjUqhEQZf"
      },
      "source": [
        "또는, `tf.parse example`를 사용하여 전체 배치를 한 번에 구문 분석합니다. `tf.data.Dataset.map` 메서드를 사용하여 데이터세트의 각 항목에 이 함수를 적용합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Ob7D-zmBm1w"
      },
      "outputs": [],
      "source": [
        "parsed_dataset = raw_dataset.map(_parse_function)\n",
        "parsed_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNV-XclGnOvn"
      },
      "source": [
        "즉시 실행을 사용하여 데이터세트에 관측 값을 표시합니다. 이 데이터세트에는 10,000개의 관측 값이 있지만 처음 10개만 표시됩니다. 데이터는 특성의 사전으로 표시됩니다. 각 항목은 `tf.Tensor`이며 이 텐서의 `numpy` 요소는 특성 값을 표시합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x2LT2JCqhoD_"
      },
      "outputs": [],
      "source": [
        "for parsed_record in parsed_dataset.take(10):\n",
        "  print(repr(parsed_record))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cig9EodTlDmg"
      },
      "source": [
        "여기서 `tf.parse_example` 함수는 `tf.Example` 필드를 표준 텐서로 풀어 넣습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyg1g3gU7DNn"
      },
      "source": [
        "## Python에서 TFRecord 파일"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FXG3miA7Kf1"
      },
      "source": [
        "`tf.io` 모듈에는 TFRecord 파일을 읽고 쓰기 위한 순수 Python 함수도 포함되어 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKn5uql2lAaN"
      },
      "source": [
        "### TFRecord 파일 작성하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNW_FA-GQWXs"
      },
      "source": [
        "다음으로, `test.tfrecord` 파일에 10,000개의 관측 값을 작성합니다. 각 관측 값은 `tf.Example` 메시지로 변환된 다음 파일에 작성됩니다. 그러면 `test.tfrecord` 파일이 생성되었는지 확인할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MKPHzoGv7q44"
      },
      "outputs": [],
      "source": [
        "# Write the `tf.train.Example` observations to the file.\n",
        "with tf.io.TFRecordWriter(filename) as writer:\n",
        "  for i in range(n_observations):\n",
        "    example = serialize_example(feature0[i], feature1[i], feature2[i], feature3[i])\n",
        "    writer.write(example)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EjdFHHJMpUUo"
      },
      "outputs": [],
      "source": [
        "!du -sh {filename}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2osVRnYNni-E"
      },
      "source": [
        "### TFRecord 파일 읽기\n",
        "\n",
        "이 직렬화된 텐서는 `tf.train.Example.ParseFromString`을 사용하여 쉽게 구문 분석할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U3tnd3LerOtV"
      },
      "outputs": [],
      "source": [
        "filenames = [filename]\n",
        "raw_dataset = tf.data.TFRecordDataset(filenames)\n",
        "raw_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nsEAACHcnm3f"
      },
      "outputs": [],
      "source": [
        "for raw_record in raw_dataset.take(1):\n",
        "  example = tf.train.Example()\n",
        "  example.ParseFromString(raw_record.numpy())\n",
        "  print(example)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhnZZmhm1miG"
      },
      "source": [
        "That returns a `tf.train.Example` proto which is dificult to use as is, but it's fundamentally a representation of a:\n",
        "\n",
        "```\n",
        "Dict[str,\n",
        "     Union[List[float],\n",
        "           List[int],\n",
        "           List[str]]]\n",
        "```\n",
        "\n",
        "The following code manually converts the `Example` to a dictionary of NumPy arrays, without using TensorFlow Ops. Refer to [the PROTO file](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/example/feature.proto) for detials."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ziv9tiNE1l6J"
      },
      "outputs": [],
      "source": [
        "result = {}\n",
        "# example.features.feature is the dictionary\n",
        "for key, feature in example.features.feature.items():\n",
        "  # The values are the Feature objects which contain a `kind` which contains:\n",
        "  # one of three fields: bytes_list, float_list, int64_list\n",
        "\n",
        "  kind = feature.WhichOneof('kind')\n",
        "  result[key] = np.array(getattr(feature, kind).value)\n",
        "\n",
        "result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0tFDrwdoj3q"
      },
      "source": [
        "## 연습: 이미지 데이터 읽기 및 쓰기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjN2LFxFpcR9"
      },
      "source": [
        "이번 연습은 TFRecord를 사용하여 이미지 데이터를 읽고 쓰는 방법을 보여주는 엔드 투 엔드 예제입니다. 이미지를 입력 데이터로 사용하여 데이터를 TFRecord 파일로 작성한 다음 파일을 다시 읽고 이미지를 표시합니다.\n",
        "\n",
        "예를 들어, 이 방법은 같은 입력 데이터세트에서 여러 모델을 사용하려는 경우에 유용합니다. 이미지 데이터를 그대로 저장하는 대신 TFRecord 형식으로 사전 처리할 수 있으며 이후의 모든 처리 및 모델링에 사용할 수 있습니다.\n",
        "\n",
        "먼저, 눈 속 고양이를 보여주는 [이 이미지](https://commons.wikimedia.org/wiki/File:Felis_catus-cat_on_snow.jpg)와 건설 중인 NYC의 Williamsburg Bridge를 보여주는 [이 사진](https://upload.wikimedia.org/wikipedia/commons/f/fe/New_East_River_Bridge_from_Brooklyn_det.4a09796u.jpg)을 다운로드하겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Lk2qrKvN0yu"
      },
      "source": [
        "### 이미지 가져오기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3a0fmwg8lHdF"
      },
      "outputs": [],
      "source": [
        "cat_in_snow  = tf.keras.utils.get_file(\n",
        "    '320px-Felis_catus-cat_on_snow.jpg',\n",
        "    'https://storage.googleapis.com/download.tensorflow.org/example_images/320px-Felis_catus-cat_on_snow.jpg')\n",
        "\n",
        "williamsburg_bridge = tf.keras.utils.get_file(\n",
        "    '194px-New_East_River_Bridge_from_Brooklyn_det.4a09796u.jpg',\n",
        "    'https://storage.googleapis.com/download.tensorflow.org/example_images/194px-New_East_River_Bridge_from_Brooklyn_det.4a09796u.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7aJJh7vENeE4"
      },
      "outputs": [],
      "source": [
        "display.display(display.Image(filename=cat_in_snow))\n",
        "display.display(display.HTML('Image cc-by: <a \"href=https://commons.wikimedia.org/wiki/File:Felis_catus-cat_on_snow.jpg\">Von.grzanka</a>'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KkW0uuhcXZqA"
      },
      "outputs": [],
      "source": [
        "display.display(display.Image(filename=williamsburg_bridge))\n",
        "display.display(display.HTML('<a \"href=https://commons.wikimedia.org/wiki/File:New_East_River_Bridge_from_Brooklyn_det.4a09796u.jpg\">From Wikimedia</a>'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VSOgJSwoN5TQ"
      },
      "source": [
        "### TFRecord 파일 작성하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Azx83ryQEU6T"
      },
      "source": [
        "이전과 마찬가지로 특성을 `tf.Example`과 호환되는 유형으로 인코딩합니다. 그러면 원시 이미지 문자열 특성과 높이, 너비, 깊이 및 임의의 `label` 특성이 저장됩니다.  후자는 고양이 이미지와 다리 이미지를 구별하는 파일을 작성할 때 사용됩니다. 고양이 이미지에는 `0`을 사용하고 다리 이미지에는 `1`을 사용합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kC4TS1ZEONHr"
      },
      "outputs": [],
      "source": [
        "image_labels = {\n",
        "    cat_in_snow : 0,\n",
        "    williamsburg_bridge : 1,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c5njMSYNEhNZ"
      },
      "outputs": [],
      "source": [
        "# This is an example, just using the cat image.\n",
        "image_string = open(cat_in_snow, 'rb').read()\n",
        "\n",
        "label = image_labels[cat_in_snow]\n",
        "\n",
        "# Create a dictionary with features that may be relevant.\n",
        "def image_example(image_string, label):\n",
        "  image_shape = tf.io.decode_jpeg(image_string).shape\n",
        "\n",
        "  feature = {\n",
        "      'height': _int64_feature(image_shape[0]),\n",
        "      'width': _int64_feature(image_shape[1]),\n",
        "      'depth': _int64_feature(image_shape[2]),\n",
        "      'label': _int64_feature(label),\n",
        "      'image_raw': _bytes_feature(image_string),\n",
        "  }\n",
        "\n",
        "  return tf.train.Example(features=tf.train.Features(feature=feature))\n",
        "\n",
        "for line in str(image_example(image_string, label)).split('\\n')[:15]:\n",
        "  print(line)\n",
        "print('...')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2G_o3O9MN0Qx"
      },
      "source": [
        "이제 모든 특성이 `tf.Example` 메시지에 저장됩니다. 그 다음, 위의 코드를 함수화하고 예제 메시지를 `images.tfrecords` 이름의 파일에 작성합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qcw06lQCOCZU"
      },
      "outputs": [],
      "source": [
        "# Write the raw image files to `images.tfrecords`.\n",
        "# First, process the two images into `tf.train.Example` messages.\n",
        "# Then, write to a `.tfrecords` file.\n",
        "record_file = 'images.tfrecords'\n",
        "with tf.io.TFRecordWriter(record_file) as writer:\n",
        "  for filename, label in image_labels.items():\n",
        "    image_string = open(filename, 'rb').read()\n",
        "    tf_example = image_example(image_string, label)\n",
        "    writer.write(tf_example.SerializeToString())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yJrTe6tHPCfs"
      },
      "outputs": [],
      "source": [
        "!du -sh {record_file}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJSsCkZLPH6K"
      },
      "source": [
        "### TFRecord 파일 읽기\n",
        "\n",
        "이제 `images.tfrecords` 파일이 얻었으며 여기에 있는 레코드를 반복 실행하여 작성한 내용을 다시 읽을 수 있습니다. 이 예에서는 이미지만 생성하기 때문에 유일하게 필요한 특성은 원시 이미지 문자열입니다. 위에서 설명한 getter, 즉 `example.features.feature['image_raw'].bytes_list.value[0]`를 이용해 이를 추출합니다. 또한 레이블을 이용해 어떤 레코드가 고양이이고 어떤 것이 다리인지 결정할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M6Cnfd3cTKHN"
      },
      "outputs": [],
      "source": [
        "raw_image_dataset = tf.data.TFRecordDataset('images.tfrecords')\n",
        "\n",
        "# Create a dictionary describing the features.\n",
        "image_feature_description = {\n",
        "    'height': tf.io.FixedLenFeature([], tf.int64),\n",
        "    'width': tf.io.FixedLenFeature([], tf.int64),\n",
        "    'depth': tf.io.FixedLenFeature([], tf.int64),\n",
        "    'label': tf.io.FixedLenFeature([], tf.int64),\n",
        "    'image_raw': tf.io.FixedLenFeature([], tf.string),\n",
        "}\n",
        "\n",
        "def _parse_image_function(example_proto):\n",
        "  # Parse the input tf.train.Example proto using the dictionary above.\n",
        "  return tf.io.parse_single_example(example_proto, image_feature_description)\n",
        "\n",
        "parsed_image_dataset = raw_image_dataset.map(_parse_image_function)\n",
        "parsed_image_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0PEEFPk4NEg1"
      },
      "source": [
        "TFRecord 파일에서 이미지를 복구합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yZf8jOyEIjSF"
      },
      "outputs": [],
      "source": [
        "for image_features in parsed_image_dataset:\n",
        "  image_raw = image_features['image_raw'].numpy()\n",
        "  display.display(display.Image(data=image_raw))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "pL--_KGdYoBz"
      ],
      "name": "tfrecord.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
