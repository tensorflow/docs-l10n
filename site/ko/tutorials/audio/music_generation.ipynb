{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0DH9bjZD_Cfi"
      },
      "source": [
        "##### Copyright 2021 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "JO1GUwC1_T2x"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4xOsFiu-1-c"
      },
      "source": [
        "# RNN으로 음악 생성"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OyzAxV7Vu_9Y"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td><a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/audio/music_generation\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">TensorFlow.org에서 보기</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/audio/music_generation.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Google Colab에서 실행</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/audio/music_generation.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">GitHub에서 소스 보기</a></td>\n",
        "  <td><a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/tutorials/audio/music_generation.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">노트북 다운로드</a></td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hr78EkAY-FFg"
      },
      "source": [
        "이 튜토리얼에서는 간단한 RNN을 사용하여 음표를 생성하는 방법을 보여줍니다. [MAESTRO 데이터 세트](https://magenta.tensorflow.org/datasets/maestro) 의 피아노 MIDI 파일 모음을 사용하여 모델을 훈련합니다. 일련의 음표가 주어지면 모델은 순서대로 다음 음표를 예측하는 방법을 학습합니다. 모델을 반복적으로 호출하여 더 긴 노트 시퀀스를 생성할 수 있습니다.\n",
        "\n",
        "이 튜토리얼에는 MIDI 파일을 구문 분석하고 생성하기 위한 완전한 코드가 포함되어 있습니다. [RNN으로 텍스트 생성을](https://www.tensorflow.org/text/tutorials/text_generation) 방문하여 RNN의 작동 방식에 대해 자세히 알아볼 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZniYb7Y_0Ey"
      },
      "source": [
        "## 설정"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ks8__E_WUGt"
      },
      "source": [
        "이 튜토리얼은 사용 [`pretty_midi`](https://github.com/craffel/pretty-midi) 만들고 MIDI 파일 및 구문 분석 라이브러리 [`pyfluidsynth`](https://github.com/nwhitehead/pyfluidsynth) Colab에서 오디오 재생을 생성합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kahm6Z8v_TqC"
      },
      "outputs": [],
      "source": [
        "!sudo apt install -y fluidsynth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M0lAReB7_Vqb"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade pyfluidsynth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G46kKoQZmIa8"
      },
      "outputs": [],
      "source": [
        "!pip install pretty_midi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GsLFq7nsiqcq"
      },
      "outputs": [],
      "source": [
        "import collections\n",
        "import datetime\n",
        "import fluidsynth\n",
        "import glob\n",
        "import numpy as np\n",
        "import pathlib\n",
        "import pandas as pd\n",
        "import pretty_midi\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "\n",
        "from IPython import display\n",
        "from matplotlib import pyplot as plt\n",
        "from typing import Dict, List, Optional, Sequence, Tuple"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Efja_OtJNzAM"
      },
      "outputs": [],
      "source": [
        "seed = 42\n",
        "tf.random.set_seed(seed)\n",
        "np.random.seed(seed)\n",
        "\n",
        "# Sampling rate for audio playback\n",
        "_SAMPLING_RATE = 16000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FzIbfb-Ikgg7"
      },
      "source": [
        "## Maestro 데이터 세트 다운로드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mwja4SWmibrL"
      },
      "outputs": [],
      "source": [
        "data_dir = pathlib.Path('data/maestro-v2.0.0')\n",
        "if not data_dir.exists():\n",
        "  tf.keras.utils.get_file(\n",
        "      'maestro-v2.0.0-midi.zip',\n",
        "      origin='https://storage.googleapis.com/magentadata/datasets/maestro/v2.0.0/maestro-v2.0.0-midi.zip',\n",
        "      extract=True,\n",
        "      cache_dir='.', cache_subdir='data',\n",
        "  )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7UYBSxcINqJ"
      },
      "source": [
        "데이터 세트에는 약 1,200개의 MIDI 파일이 포함되어 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "72iFI1bPB9o1"
      },
      "outputs": [],
      "source": [
        "filenames = glob.glob(str(data_dir/'**/*.mid*'))\n",
        "print('Number of files:', len(filenames))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BlRafYDIRgA"
      },
      "source": [
        "## MIDI 파일 처리"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFsmG87gXSbh"
      },
      "source": [
        "먼저, `pretty_midi` 를 사용하여 단일 MIDI 파일을 구문 분석하고 음표 형식을 검사합니다. 아래 MIDI 파일을 다운로드하여 컴퓨터에서 재생하려면 colab에서 `files.download(sample_file)` 을 작성하여 다운로드할 수 있습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6oSCbHvJNbci"
      },
      "outputs": [],
      "source": [
        "sample_file = filenames[1]\n",
        "print(sample_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A48VdGEpXnLp"
      },
      "source": [
        "샘플 MIDI 파일에 대한 `PrettyMIDI` 개체를 생성합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1YSQ5DjRI2md"
      },
      "outputs": [],
      "source": [
        "pm = pretty_midi.PrettyMIDI(sample_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZNVsZuA_lef"
      },
      "source": [
        "샘플 파일을 재생합니다. 재생 위젯을 로드하는 데 몇 초가 걸릴 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vzoHAaVY_kyY"
      },
      "outputs": [],
      "source": [
        "def display_audio(pm: pretty_midi.PrettyMIDI, seconds=30):\n",
        "  waveform = pm.fluidsynth(fs=_SAMPLING_RATE)\n",
        "  # Take a sample of the generated waveform to mitigate kernel resets\n",
        "  waveform_short = waveform[:seconds*_SAMPLING_RATE]\n",
        "  return display.Audio(waveform_short, rate=_SAMPLING_RATE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GOe-3AAi_sRw"
      },
      "outputs": [],
      "source": [
        "display_audio(pm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Lqe7nOsIyh1"
      },
      "source": [
        "MIDI 파일을 검사하십시오. 어떤 종류의 악기가 사용됩니까?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SIGHYQPZQnRo"
      },
      "outputs": [],
      "source": [
        "print('Number of instruments:', len(pm.instruments))\n",
        "instrument = pm.instruments[0]\n",
        "instrument_name = pretty_midi.program_to_instrument_name(instrument.program)\n",
        "print('Instrument name:', instrument_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVQfV2hVKB28"
      },
      "source": [
        "## 메모 추출"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nYZm_VehYOTZ"
      },
      "outputs": [],
      "source": [
        "for i, note in enumerate(instrument.notes[:10]):\n",
        "  note_name = pretty_midi.note_number_to_name(note.pitch)\n",
        "  duration = note.end - note.start\n",
        "  print(f'{i}: pitch={note.pitch}, note_name={note_name},'\n",
        "        f' duration={duration:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jutzynyqX_GC"
      },
      "source": [
        "모델을 훈련할 때 음표를 나타내기 위해 세 가지 변수( `pitch` , `step` 및 `duration` 합니다. 피치는 MIDI 음표 번호로서의 사운드의 지각적 품질입니다. `step` 는 트랙의 이전 음표 또는 시작 부분에서 경과된 시간입니다. `duration` 은 음표가 재생되는 시간(초)이며 음표 종료 시간과 음표 시작 시간의 차이입니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGn7Juv_PTi6"
      },
      "source": [
        "샘플 MIDI 파일에서 음표를 추출합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wyp_wdcEPWby"
      },
      "outputs": [],
      "source": [
        "def midi_to_notes(midi_file: str) -> pd.DataFrame:\n",
        "  pm = pretty_midi.PrettyMIDI(midi_file)\n",
        "  instrument = pm.instruments[0]\n",
        "  notes = collections.defaultdict(list)\n",
        "\n",
        "  # Sort the notes by start time\n",
        "  sorted_notes = sorted(instrument.notes, key=lambda note: note.start)\n",
        "  prev_start = sorted_notes[0].start\n",
        "\n",
        "  for note in sorted_notes:\n",
        "    start = note.start\n",
        "    end = note.end\n",
        "    notes['pitch'].append(note.pitch)\n",
        "    notes['start'].append(start)\n",
        "    notes['end'].append(end)\n",
        "    notes['step'].append(start - prev_start)\n",
        "    notes['duration'].append(end - start)\n",
        "    prev_start = start\n",
        "\n",
        "  return pd.DataFrame({name: np.array(value) for name, value in notes.items()})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X0kPjLBlcnY6"
      },
      "outputs": [],
      "source": [
        "raw_notes = midi_to_notes(sample_file)\n",
        "raw_notes.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-71LPvjubOSO"
      },
      "source": [
        "음높이보다는 음표 이름을 해석하는 것이 더 쉬울 수 있으므로 아래 기능을 사용하여 숫자 음높이 값에서 음표 이름으로 변환할 수 있습니다. 음표 이름은 음표 유형, 우발적 및 옥타브 번호(예: C#4)를 나타냅니다. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WE9YXrGZbY2X"
      },
      "outputs": [],
      "source": [
        "get_note_names = np.vectorize(pretty_midi.note_number_to_name)\n",
        "sample_note_names = get_note_names(raw_notes['pitch'])\n",
        "sample_note_names[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7sjqbp1e_f-"
      },
      "source": [
        "악곡을 시각화하려면 트랙 길이(즉, 피아노 롤)에 걸쳐 음표 피치, 시작 및 끝을 플롯합니다. 처음 100개의 메모로 시작"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "liD2N7x_WOTp"
      },
      "outputs": [],
      "source": [
        "def plot_piano_roll(notes: pd.DataFrame, count: Optional[int] = None):\n",
        "  if count:\n",
        "    title = f'First {count} notes'\n",
        "  else:\n",
        "    title = f'Whole track'\n",
        "    count = len(notes['pitch'])\n",
        "  plt.figure(figsize=(20, 4))\n",
        "  plot_pitch = np.stack([notes['pitch'], notes['pitch']], axis=0)\n",
        "  plot_start_stop = np.stack([notes['start'], notes['end']], axis=0)\n",
        "  plt.plot(\n",
        "      plot_start_stop[:, :count], plot_pitch[:, :count], color=\"b\", marker=\".\")\n",
        "  plt.xlabel('Time [s]')\n",
        "  plt.ylabel('Pitch')\n",
        "  _ = plt.title(title)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vWeUbqmAXjOs"
      },
      "outputs": [],
      "source": [
        "plot_piano_roll(raw_notes, count=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcUyCXYhXeVA"
      },
      "source": [
        "전체 트랙에 대한 메모를 플로팅합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G7l76hEDZX8Z"
      },
      "outputs": [],
      "source": [
        "plot_piano_roll(raw_notes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GM1bi3aX8rd"
      },
      "source": [
        "각 음표 변수의 분포를 확인하십시오."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pq9C9XBBaK7W"
      },
      "outputs": [],
      "source": [
        "def plot_distributions(notes: pd.DataFrame, drop_percentile=2.5):\n",
        "  plt.figure(figsize=[15, 5])\n",
        "  plt.subplot(1, 3, 1)\n",
        "  sns.histplot(notes, x=\"pitch\", bins=20)\n",
        "\n",
        "  plt.subplot(1, 3, 2)\n",
        "  max_step = np.percentile(notes['step'], 100 - drop_percentile)\n",
        "  sns.histplot(notes, x=\"step\", bins=np.linspace(0, max_step, 21))\n",
        "  \n",
        "  plt.subplot(1, 3, 3)\n",
        "  max_duration = np.percentile(notes['duration'], 100 - drop_percentile)\n",
        "  sns.histplot(notes, x=\"duration\", bins=np.linspace(0, max_duration, 21))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Nu2Pw24acFD"
      },
      "outputs": [],
      "source": [
        "plot_distributions(raw_notes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "poIivompcfS4"
      },
      "source": [
        "## MIDI 파일 생성\n",
        "\n",
        "아래 기능을 사용하여 음표 목록에서 자신만의 MIDI 파일을 생성할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BD5rsMRARYoV"
      },
      "outputs": [],
      "source": [
        "def notes_to_midi(\n",
        "  notes: pd.DataFrame,\n",
        "  out_file: str, \n",
        "  instrument_name: str,\n",
        "  velocity: int = 100,  # note loudness\n",
        ") -> pretty_midi.PrettyMIDI:\n",
        "\n",
        "  pm = pretty_midi.PrettyMIDI()\n",
        "  instrument = pretty_midi.Instrument(\n",
        "      program=pretty_midi.instrument_name_to_program(\n",
        "          instrument_name))\n",
        "\n",
        "  prev_start = 0\n",
        "  for i, note in notes.iterrows():\n",
        "    start = float(prev_start + note['step'])\n",
        "    end = float(start + note['duration'])\n",
        "    note = pretty_midi.Note(\n",
        "        velocity=velocity,\n",
        "        pitch=int(note['pitch']),\n",
        "        start=start,\n",
        "        end=end,\n",
        "    )\n",
        "    instrument.notes.append(note)\n",
        "    prev_start = start\n",
        "\n",
        "  pm.instruments.append(instrument)\n",
        "  pm.write(out_file)\n",
        "  return pm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wTazLbuWPIPF"
      },
      "outputs": [],
      "source": [
        "example_file = 'example.midi'\n",
        "example_pm = notes_to_midi(\n",
        "    raw_notes, out_file=example_file, instrument_name=instrument_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XG0N9zZV_4Gp"
      },
      "source": [
        "생성된 MIDI 파일을 재생하여 차이점이 있는지 확인합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fGRLs-eR_4uK"
      },
      "outputs": [],
      "source": [
        "display_audio(example_pm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLrUscjhBzYc"
      },
      "source": [
        "이전과 마찬가지로 `files.download(example_file)` 를 작성하여 이 파일을 다운로드하고 재생할 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfRNk9tEScuf"
      },
      "source": [
        "## 훈련 데이터 세트 생성\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b77zHR1udDrK"
      },
      "source": [
        "MIDI 파일에서 메모를 추출하여 교육 데이터 세트를 만듭니다. 적은 수의 파일을 사용하여 시작하고 나중에 더 많은 파일로 실험할 수 있습니다. 몇 분 정도 걸릴 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GiaQiTnXSW-T"
      },
      "outputs": [],
      "source": [
        "num_files = 5\n",
        "all_notes = []\n",
        "for f in filenames[:num_files]:\n",
        "  notes = midi_to_notes(f)\n",
        "  all_notes.append(notes)\n",
        "\n",
        "all_notes = pd.concat(all_notes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F4bMDeRvgWqx"
      },
      "outputs": [],
      "source": [
        "n_notes = len(all_notes)\n",
        "print('Number of notes parsed:', n_notes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIBLvj-cODWS"
      },
      "source": [
        "다음으로, 구문 분석된 메모에서 [tf.data.Dataset을 만듭니다.](https://www.tensorflow.org/datasets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mvNHCHZdXG2P"
      },
      "outputs": [],
      "source": [
        "key_order = ['pitch', 'step', 'duration']\n",
        "train_notes = np.stack([all_notes[key] for key in key_order], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PLC_19tshyFk"
      },
      "outputs": [],
      "source": [
        "notes_ds = tf.data.Dataset.from_tensor_slices(train_notes)\n",
        "notes_ds.element_spec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sj9SXRCjt3I7"
      },
      "source": [
        "일련의 노트에 대해 모델을 훈련합니다. 각 예제는 입력 기능으로 일련의 메모와 레이블로 다음 메모로 구성됩니다. 이러한 방식으로 모델은 시퀀스의 다음 음표를 예측하도록 훈련됩니다. [RNN을 사용한 텍스트 분류](https://www.tensorflow.org/text/tutorials/text_generation) 에서 이 프로세스(및 자세한 내용)를 설명하는 다이어그램을 찾을 수 있습니다.\n",
        "\n",
        "크기가 `seq_length` 편리한 [창](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#window) 함수를 사용하여 이 형식으로 기능과 레이블을 만들 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZkEC-5s6wJJV"
      },
      "outputs": [],
      "source": [
        "def create_sequences(\n",
        "    dataset: tf.data.Dataset, \n",
        "    seq_length: int,\n",
        "    vocab_size = 128,\n",
        ") -> tf.data.Dataset:\n",
        "  \"\"\"Returns TF Dataset of sequence and label examples.\"\"\"\n",
        "  seq_length = seq_length+1\n",
        "\n",
        "  # Take 1 extra for the labels\n",
        "  windows = dataset.window(seq_length, shift=1, stride=1,\n",
        "                              drop_remainder=True)\n",
        "\n",
        "  # `flat_map` flattens the\" dataset of datasets\" into a dataset of tensors\n",
        "  flatten = lambda x: x.batch(seq_length, drop_remainder=True)\n",
        "  sequences = windows.flat_map(flatten)\n",
        "  \n",
        "  # Normalize note pitch\n",
        "  def scale_pitch(x):\n",
        "    x = x/[vocab_size,1.0,1.0]\n",
        "    return x\n",
        "\n",
        "  # Split the labels\n",
        "  def split_labels(sequences):\n",
        "    inputs = sequences[:-1]\n",
        "    labels_dense = sequences[-1]\n",
        "    labels = {key:labels_dense[i] for i,key in enumerate(key_order)}\n",
        "\n",
        "    return scale_pitch(inputs), labels\n",
        "\n",
        "  return sequences.map(split_labels, num_parallel_calls=tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xDX5pVkegrv"
      },
      "source": [
        "각 예의 시퀀스 길이를 설정합니다. 다른 길이(예: 50, 100, 150)로 실험하여 어느 것이 데이터에 가장 적합한지 확인하거나 초 [매개변수 조정을](https://www.tensorflow.org/tutorials/keras/keras_tuner) 사용합니다. 어휘 (크기 `vocab_size` )에 의해 지원되는 모든 피치 나타내는 128로 설정 `pretty_midi` ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fGA3VxcFXZ4T"
      },
      "outputs": [],
      "source": [
        "seq_length = 25\n",
        "vocab_size = 128\n",
        "seq_ds = create_sequences(notes_ds, seq_length, vocab_size)\n",
        "seq_ds.element_spec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AX9nKmSYetGo"
      },
      "source": [
        "데이터 세트의 모양은 `(100,1)` . 즉, 모델은 100개의 메모를 입력으로 사용하고 다음 메모를 출력으로 예측하는 방법을 학습합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ESK9cL7__TF3"
      },
      "outputs": [],
      "source": [
        "for seq, target in seq_ds.take(1):\n",
        "  print('sequence shape:', seq.shape)\n",
        "  print('sequence elements (first 10):', seq[0: 10])\n",
        "  print()\n",
        "  print('target:', target)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kR3TVZZGk5Qq"
      },
      "source": [
        "예제를 일괄 처리하고 성능을 위해 데이터 세트를 구성합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fTpFoiM_AV_Y"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "buffer_size = n_notes - seq_length  # the number of items in the dataset\n",
        "train_ds = (seq_ds\n",
        "            .shuffle(buffer_size)\n",
        "            .batch(batch_size, drop_remainder=True)\n",
        "            .cache()\n",
        "            .prefetch(tf.data.experimental.AUTOTUNE))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LySbjV0GzXQu"
      },
      "outputs": [],
      "source": [
        "train_ds.element_spec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWZmfkshqP8G"
      },
      "source": [
        "## 모델 생성 및 학습"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGQn32q-hdK2"
      },
      "source": [
        "모델에는 각 음 변수에 대해 하나씩 3개의 출력이 있습니다. `pitch` 및 `duration` 경우 모델이 음이 아닌 값을 출력하도록 권장하는 평균 제곱 오차를 기반으로 하는 사용자 정의 손실 함수를 사용합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "erxLOif08e8v"
      },
      "outputs": [],
      "source": [
        "def mse_with_positive_pressure(y_true: tf.Tensor, y_pred: tf.Tensor):\n",
        "  mse = (y_true - y_pred) ** 2\n",
        "  positive_pressure = 10 * tf.maximum(-y_pred, 0.0)\n",
        "  return tf.reduce_mean(mse + positive_pressure)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kNaVWcCzAm5V"
      },
      "outputs": [],
      "source": [
        "input_shape = (seq_length, 3)\n",
        "learning_rate = 0.005\n",
        "\n",
        "inputs = tf.keras.Input(input_shape)\n",
        "x = tf.keras.layers.LSTM(128)(inputs)\n",
        "\n",
        "outputs = {\n",
        "  'pitch': tf.keras.layers.Dense(128, name='pitch')(x),\n",
        "  'step': tf.keras.layers.Dense(1, name='step')(x),\n",
        "  'duration': tf.keras.layers.Dense(1, name='duration')(x),\n",
        "}\n",
        "\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "loss = {\n",
        "      'pitch': tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "          from_logits=True),\n",
        "      'step': mse_with_positive_pressure,\n",
        "      'duration': mse_with_positive_pressure,\n",
        "}\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "model.compile(loss=loss, optimizer=optimizer)\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDL0Jypt3eU5"
      },
      "source": [
        "`model.evaluate` 함수를 테스트하면 `pitch` `step` 및 `duration` 손실보다 훨씬 큰 것을 알 수 있습니다. `loss` 은 다른 모든 손실을 합산하여 계산된 총 손실이며 현재 `pitch` 손실이 지배합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BlATt7Rl0XJl"
      },
      "outputs": [],
      "source": [
        "losses = model.evaluate(train_ds, return_dict=True)\n",
        "losses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLvNLvtR3W59"
      },
      "source": [
        "이 균형을 유지하는 한 가지 방법은 `loss_weights` 인수를 사용하여 컴파일하는 것입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9fQB5SiN3ufX"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    loss=loss,\n",
        "    loss_weights={\n",
        "        'pitch': 0.05,\n",
        "        'step': 1.0,\n",
        "        'duration':1.0,\n",
        "    },\n",
        "    optimizer=optimizer,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPMUnIMelHgR"
      },
      "source": [
        "`loss` 후 개별 손실의 가중 합이된다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T7CzWmFR38ut"
      },
      "outputs": [],
      "source": [
        "model.evaluate(train_ds, return_dict=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJbn7HZgfosr"
      },
      "source": [
        "모델을 훈련시킵니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uQA_rwKEgPjp"
      },
      "outputs": [],
      "source": [
        "callbacks = [\n",
        "    tf.keras.callbacks.ModelCheckpoint(\n",
        "        filepath='./training_checkpoints/ckpt_{epoch}',\n",
        "        save_weights_only=True),\n",
        "    tf.keras.callbacks.EarlyStopping(\n",
        "        monitor='loss',\n",
        "        patience=5,\n",
        "        verbose=1,\n",
        "        restore_best_weights=True),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aLoYY8-XaPFN"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "epochs = 50\n",
        "\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    epochs=epochs,\n",
        "    callbacks=callbacks,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PYBSjgDWiUfT"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.epoch, history.history['loss'], label='total loss')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPWI94lQ8uQA"
      },
      "source": [
        "## 메모 생성"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wbaoiy4Hf-n5"
      },
      "source": [
        "모델을 사용하여 메모를 생성하려면 먼저 메모의 시작 순서를 제공해야 합니다. 아래 함수는 일련의 음표에서 하나의 음표를 생성합니다.\n",
        "\n",
        "음높이의 경우 모델에서 생성된 음의 softmax 분포에서 샘플을 추출하며 단순히 가장 높은 확률의 음표를 선택하지 않습니다. 항상 확률이 가장 높은 음표를 선택하면 음표가 반복적으로 생성됩니다.\n",
        "\n",
        "`temperature` 매개변수는 생성된 음표의 무작위성을 제어하는 데 사용할 수 있습니다. [RNN을 사용한 텍스트 생성](https://www.tensorflow.org/text/tutorials/text_generation) 에서 온도에 대한 자세한 내용을 찾을 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1mil8ZyJNe1w"
      },
      "outputs": [],
      "source": [
        "def predict_next_note(\n",
        "    notes: np.ndarray, \n",
        "    keras_model: tf.keras.Model, \n",
        "    temperature: float = 1.0) -> int:\n",
        "  \"\"\"Generates a note IDs using a trained sequence model.\"\"\"\n",
        "\n",
        "  assert temperature > 0\n",
        "\n",
        "  # Add batch dimension\n",
        "  inputs = tf.expand_dims(notes, 0)\n",
        "\n",
        "  predictions = model.predict(inputs)\n",
        "  pitch_logits = predictions['pitch']\n",
        "  step = predictions['step']\n",
        "  duration = predictions['duration']\n",
        " \n",
        "  pitch_logits /= temperature\n",
        "  pitch = tf.random.categorical(pitch_logits, num_samples=1)\n",
        "  pitch = tf.squeeze(pitch, axis=-1)\n",
        "  duration = tf.squeeze(duration, axis=-1)\n",
        "  step = tf.squeeze(step, axis=-1)\n",
        "\n",
        "  # `step` and `duration` values should be non-negative\n",
        "  step = tf.maximum(0, step)\n",
        "  duration = tf.maximum(0, duration)\n",
        "\n",
        "  return int(pitch), float(step), float(duration)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W64K-EX3hxU_"
      },
      "source": [
        "이제 몇 가지 메모를 생성합니다. `next_notes` 에서 온도와 시작 순서를 가지고 놀고 무슨 일이 일어나는지 볼 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "87fPl4auPdR3"
      },
      "outputs": [],
      "source": [
        "temperature = 2.0\n",
        "num_predictions = 120\n",
        "\n",
        "sample_notes = np.stack([raw_notes[key] for key in key_order], axis=1)\n",
        "\n",
        "# The initial sequence of notes; pitch is normalized similar to training\n",
        "# sequences\n",
        "input_notes = (\n",
        "    sample_notes[:seq_length] / np.array([vocab_size, 1, 1]))\n",
        "\n",
        "generated_notes = []\n",
        "prev_start = 0\n",
        "for _ in range(num_predictions):\n",
        "  pitch, step, duration = predict_next_note(input_notes, model, temperature)\n",
        "  start = prev_start + step\n",
        "  end = start + duration\n",
        "  input_note = (pitch, step, duration)\n",
        "  generated_notes.append((*input_note, start, end))\n",
        "  input_notes = np.delete(input_notes, 0, axis=0)\n",
        "  input_notes = np.append(input_notes, np.expand_dims(input_note, 0), axis=0)\n",
        "  prev_start = start\n",
        "\n",
        "generated_notes = pd.DataFrame(\n",
        "    generated_notes, columns=(*key_order, 'start', 'end'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0MK7HmqLuqka"
      },
      "outputs": [],
      "source": [
        "generated_notes.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e9K9KHPaTNnK"
      },
      "outputs": [],
      "source": [
        "out_file = 'output.mid'\n",
        "out_pm = notes_to_midi(\n",
        "    generated_notes, out_file=out_file, instrument_name=instrument_name)\n",
        "display_audio(out_pm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4N9_Y03Kw-3"
      },
      "source": [
        "아래 두 줄을 추가하여 오디오 파일을 다운로드할 수도 있습니다.\n",
        "\n",
        "```\n",
        "from google.colab import files\n",
        "files.download(out_file)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trp82gTqskPR"
      },
      "source": [
        "생성된 메모를 시각화합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NlNsxcnhvbcK"
      },
      "outputs": [],
      "source": [
        "plot_piano_roll(generated_notes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5_yA9lvvitC"
      },
      "source": [
        "`pitch` , `step` , `duration` 의 분포 를 확인 하십시오 ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j5bco2WVRkAa"
      },
      "outputs": [],
      "source": [
        "plot_distributions(generated_notes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAyxR7Itw3Wh"
      },
      "source": [
        "위의 플롯에서 메모 변수의 분포가 변경되었음을 알 수 있습니다. 모델의 출력과 입력 사이에 피드백 루프가 있기 때문에 모델은 손실을 줄이기 위해 유사한 출력 시퀀스를 생성하는 경향이 있습니다. 이것은 특히 MSE 손실을 사용하는 `step` 및 `duration` `pitch` `predict_next_note` `temperature` 를 높여 임의성을 높일 수 있습니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bkfe3GYZEu4l"
      },
      "source": [
        "## 다음 단계\n",
        "\n",
        "이 튜토리얼은 RNN을 사용하여 MIDI 파일 데이터 세트에서 일련의 음표를 생성하는 방법을 보여주었습니다. 자세히 알아보려면 추가 다이어그램과 설명이 포함 [된 RNN 자습서로 밀접하게 관련된 텍스트 생성을 방문하세요.](https://www.tensorflow.org/text/tutorials/text_generation)\n",
        "\n",
        "음악 생성을 위해 RNN을 사용하는 것의 대안은 GAN을 사용하는 것입니다. 오디오를 생성하는 대신 GAN 기반 접근 방식은 전체 시퀀스를 병렬로 생성할 수 있습니다. [Magenta 팀은 GANSynth를 사용](https://magenta.tensorflow.org/gansynth) 하여 이 접근 방식에 대해 인상적인 작업을 수행했습니다. [Magenta 프로젝트 웹사이트](https://magenta.tensorflow.org/) 에서 멋진 음악 및 예술 프로젝트와 오픈 소스 코드를 찾을 수도 있습니다."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "music_generation.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
