{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6ZDpd9XzFeN"
      },
      "source": [
        "##### Copyright 2018 The TensorFlow Hub Authors.\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "KUu4vOt5zI9d"
      },
      "outputs": [],
      "source": [
        "# Copyright 2018 The TensorFlow Hub Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# =============================================================================="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ok9PfyoQ2rH_"
      },
      "source": [
        "# TF-Hub로 Kaggle 문제를 해결하는 방법\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfBg1C5NB3X0"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td><a target=\"_blank\" href=\"https://www.tensorflow.org/hub/tutorials/text_classification_with_tf_hub_on_kaggle\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">TensorFlow.org에서 보기</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/hub/blob/master/examples/colab/text_classification_with_tf_hub_on_kaggle.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Google Colab에서 실행</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://github.com/tensorflow/hub/blob/master/examples/colab/text_classification_with_tf_hub_on_kaggle.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\"> GitHub에서 소스 보기</a></td>\n",
        "  <td><a href=\"https://storage.googleapis.com/tensorflow_docs/hub/examples/colab/text_classification_with_tf_hub_on_kaggle.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">노트북 다운로드</a></td>\n",
        "  <td><a href=\"https://tfhub.dev/google/nnlm-en-dim128/1\"><img src=\"https://www.tensorflow.org/images/hub_logo_32px.png\">TF Hub 모델보기</a></td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "556YQZLUO4Ih"
      },
      "source": [
        "TF-허브는 재사용 가능한 리소스, 특히 사전 훈련된 **모듈** 형태로 머신러닝에 대한 전문 지식을 공유하는 플랫폼입니다. 이 튜토리얼에서는 TF-허브 텍스트 임베딩 모듈을 사용하여 합리적인 기준 정확성으로 간단한 감정 분류자를 훈련합니다. 그런 다음 Kaggle에 예측을 제출합니다.\n",
        "\n",
        "TF-허브를 사용한 텍스트 분류에 대한 자세한 튜토리얼과 정확성 향상을 위한 추가 단계는 [TF-허브를 이용한 텍스트 분류](https://colab.research.google.com/github/tensorflow/hub/blob/master/docs/tutorials/text_classification_with_tf_hub.ipynb)를 살펴보세요."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4DN769E2O_R"
      },
      "source": [
        "## 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9KyLct9rq0lo"
      },
      "outputs": [],
      "source": [
        "!pip install -q kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v7hy0bhngTUp"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import zipfile\n",
        "\n",
        "from sklearn import model_selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvgBdeMsuu_3"
      },
      "source": [
        "이 튜토리얼에서는 Kaggle의 데이터세트를 사용하기 때문에 Kaggle 계정에 대한 [API 토큰을 만들고](https://github.com/Kaggle/kaggle-api) Colab 환경에 토큰을 업로드해야 합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nI7C-Zc4urOH"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pathlib\n",
        "\n",
        "# Upload the API token.\n",
        "def get_kaggle():\n",
        "  try:\n",
        "    import kaggle\n",
        "    return kaggle\n",
        "  except OSError:\n",
        "    pass\n",
        "\n",
        "  token_file = pathlib.Path(\"~/.kaggle/kaggle.json\").expanduser()\n",
        "  token_file.parent.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "  try:\n",
        "    from google.colab import files\n",
        "  except ImportError:\n",
        "    raise ValueError(\"Could not find kaggle token.\")\n",
        "\n",
        "  uploaded = files.upload()\n",
        "  token_content = uploaded.get('kaggle.json', None)\n",
        "  if token_content:\n",
        "    token_file.write_bytes(token_content)\n",
        "    token_file.chmod(0o600)\n",
        "  else:\n",
        "    raise ValueError('Need a file named \"kaggle.json\"')\n",
        "  \n",
        "  import kaggle\n",
        "  return kaggle\n",
        "\n",
        "\n",
        "kaggle = get_kaggle()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OPyVxHuiTEE"
      },
      "source": [
        "# 시작하기\n",
        "\n",
        "## 데이터\n",
        "\n",
        "Kaggle의 [영화 리뷰에 대한 감정 분석](https://www.kaggle.com/c/sentiment-analysis-on-movie-reviews/data) 작업을 해결해 보려고 합니다. 데이터세트는 Rotten Tomatoes 영화 리뷰의 구문론적 하위 문구로 구성됩니다. 여기서 해야 할 작업은 문구에 1에서 5까지의 척도로 **부정적** 또는 **긍정적** 레이블을 지정하는 것입니다.\n",
        "\n",
        "API를 사용하여 데이터를 다운로드하려면 먼저 [경쟁 규칙을 수락](https://www.kaggle.com/c/sentiment-analysis-on-movie-reviews/data)해야 합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "both",
        "id": "rKzc-fOGV72G"
      },
      "outputs": [],
      "source": [
        "SENTIMENT_LABELS = [\n",
        "    \"negative\", \"somewhat negative\", \"neutral\", \"somewhat positive\", \"positive\"\n",
        "]\n",
        "\n",
        "# Add a column with readable values representing the sentiment.\n",
        "def add_readable_labels_column(df, sentiment_value_column):\n",
        "  df[\"SentimentLabel\"] = df[sentiment_value_column].replace(\n",
        "      range(5), SENTIMENT_LABELS)\n",
        "    \n",
        "# Download data from Kaggle and create a DataFrame.\n",
        "def load_data_from_zip(path):\n",
        "  with zipfile.ZipFile(path, \"r\") as zip_ref:\n",
        "    name = zip_ref.namelist()[0]\n",
        "    with zip_ref.open(name) as zf:\n",
        "      return pd.read_csv(zf, sep=\"\\t\", index_col=0)\n",
        "\n",
        "\n",
        "# The data does not come with a validation set so we'll create one from the\n",
        "# training set.\n",
        "def get_data(competition, train_file, test_file, validation_set_ratio=0.1):\n",
        "  data_path = pathlib.Path(\"data\")\n",
        "  kaggle.api.competition_download_files(competition, data_path)\n",
        "  competition_path = (data_path/competition)\n",
        "  competition_path.mkdir(exist_ok=True, parents=True)\n",
        "  competition_zip_path = competition_path.with_suffix(\".zip\")\n",
        "\n",
        "  with zipfile.ZipFile(competition_zip_path, \"r\") as zip_ref:\n",
        "    zip_ref.extractall(competition_path)\n",
        "  \n",
        "  train_df = load_data_from_zip(competition_path/train_file)\n",
        "  test_df = load_data_from_zip(competition_path/test_file)\n",
        "\n",
        "  # Add a human readable label.\n",
        "  add_readable_labels_column(train_df, \"Sentiment\")\n",
        "\n",
        "  # We split by sentence ids, because we don't want to have phrases belonging\n",
        "  # to the same sentence in both training and validation set.\n",
        "  train_indices, validation_indices = model_selection.train_test_split(\n",
        "      np.unique(train_df[\"SentenceId\"]),\n",
        "      test_size=validation_set_ratio,\n",
        "      random_state=0)\n",
        "\n",
        "  validation_df = train_df[train_df[\"SentenceId\"].isin(validation_indices)]\n",
        "  train_df = train_df[train_df[\"SentenceId\"].isin(train_indices)]\n",
        "  print(\"Split the training data into %d training and %d validation examples.\" %\n",
        "        (len(train_df), len(validation_df)))\n",
        "\n",
        "  return train_df, validation_df, test_df\n",
        "\n",
        "\n",
        "train_df, validation_df, test_df = get_data(\n",
        "    \"sentiment-analysis-on-movie-reviews\",\n",
        "    \"train.tsv.zip\", \"test.tsv.zip\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFq_EyS1BEyK"
      },
      "source": [
        "참고: 이 경쟁에서 주어진 과제는 전체 리뷰를 평가하는 것이 아니라 리뷰 내의 개별 문구를 평가하는 것입니다. 이것은 훨씬 더 어려운 작업입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "42hgsiWNq5y9"
      },
      "outputs": [],
      "source": [
        "train_df.head(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPuHgx3BWBOg"
      },
      "source": [
        "## 모델 훈련하기\n",
        "\n",
        "*참고: 이 작업을 회귀로 모델링할 수도 있습니다([TF-허브를 사용한 텍스트 분류](https://colab.research.google.com/github/tensorflow/hub/blob/master/docs/tutorials/text_classification_with_tf_hub.ipynb) 참조).*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23U30yEkVq4w"
      },
      "outputs": [],
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self, hub_url):\n",
        "    super().__init__()\n",
        "    self.hub_url = hub_url\n",
        "    self.embed = hub.load(self.hub_url).signatures['default']\n",
        "    self.sequential = tf.keras.Sequential([\n",
        "      tf.keras.layers.Dense(500),\n",
        "      tf.keras.layers.Dense(100),\n",
        "      tf.keras.layers.Dense(5),\n",
        "    ])\n",
        "\n",
        "  def call(self, inputs):\n",
        "    phrases = inputs['Phrase'][:,0]\n",
        "    embedding = 5*self.embed(phrases)['default']\n",
        "    return self.sequential(embedding)\n",
        "\n",
        "  def get_config(self):\n",
        "    return {\"hub_url\":self.hub_url}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JE--GDMM2tSp"
      },
      "outputs": [],
      "source": [
        "model = MyModel(\"https://tfhub.dev/google/nnlm-en-dim128/1\")\n",
        "model.compile(\n",
        "    loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    optimizer=tf.optimizers.Adam(), \n",
        "    metrics = [tf.keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\")])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SRr-lvhstiNw"
      },
      "outputs": [],
      "source": [
        "history = model.fit(x=dict(train_df), y=train_df['Sentiment'],\n",
        "          validation_data=(dict(validation_df), validation_df['Sentiment']),\n",
        "          epochs = 25)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8j7YTRSe7Pj"
      },
      "source": [
        "# 예측\n",
        "\n",
        "검증 세트 및 훈련 세트에 대한 예측을 실행합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iGqVNSl87bgN"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zbLg5LzGwAfC"
      },
      "outputs": [],
      "source": [
        "train_eval_result = model.evaluate(dict(train_df), train_df['Sentiment'])\n",
        "validation_eval_result = model.evaluate(dict(validation_df), validation_df['Sentiment'])\n",
        "\n",
        "print(f\"Training set accuracy: {train_eval_result[1]}\")\n",
        "print(f\"Validation set accuracy: {validation_eval_result[1]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DR2IsTF5vuAX"
      },
      "source": [
        "## 혼동 행렬\n",
        "\n",
        "특히 다중 클래스 문제에 대한 또 다른 매우 흥미로운 통계는 [혼동 행렬](https://en.wikipedia.org/wiki/Confusion_matrix)입니다. 혼동 행렬을 사용하면 레이블이 올바르게 지정된 예와 그렇지 않은 예의 비율을 시각화할 수 있습니다. 분류자의 편향된 정도와 레이블 분포가 적절한지 여부를 쉽게 확인할 수 있습니다. 예측값의 가장 큰 부분이 대각선을 따라 분포되는 것이 이상적입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yKUnJFYY8bO_"
      },
      "outputs": [],
      "source": [
        "predictions = model.predict(dict(validation_df))\n",
        "predictions = tf.argmax(predictions, axis=-1)\n",
        "predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fjAs8W_Z9BvP"
      },
      "outputs": [],
      "source": [
        "cm = tf.math.confusion_matrix(validation_df['Sentiment'], predictions)\n",
        "cm = cm/cm.numpy().sum(axis=1)[:, tf.newaxis]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nT71CtArpsKz"
      },
      "outputs": [],
      "source": [
        "sns.heatmap(\n",
        "    cm, annot=True,\n",
        "    xticklabels=SENTIMENT_LABELS,\n",
        "    yticklabels=SENTIMENT_LABELS)\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pic7o2m04weY"
      },
      "source": [
        "다음 코드를 코드 셀에 붙여넣고 실행하여 예측을 Kaggle에 쉽게 다시 제출할 수 있습니다.\n",
        "\n",
        "```python\n",
        "test_predictions = model.predict(dict(test_df))\n",
        "test_predictions = np.argmax(test_predictions, axis=-1)\n",
        "\n",
        "result_df = test_df.copy()\n",
        "\n",
        "result_df[\"Predictions\"] = test_predictions\n",
        "\n",
        "result_df.to_csv(\n",
        "    \"predictions.csv\",\n",
        "    columns=[\"Predictions\"],\n",
        "    header=[\"Sentiment\"])\n",
        "kaggle.api.competition_submit(\"predictions.csv\", \"Submitted from Colab\",\n",
        "                              \"sentiment-analysis-on-movie-reviews\")\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50BLu-JX_dlm"
      },
      "source": [
        "제출 후에 [리더보드를 점검](https://www.kaggle.com/c/sentiment-analysis-on-movie-reviews/leaderboard)하여 작업한 내용의 결과를 확인하세요."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "text_classification_with_tf_hub_on_kaggle.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
