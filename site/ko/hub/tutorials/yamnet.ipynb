{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "laa9tRjJ59bl"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow Hub Authors.\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "T4ZHtBpK6Dom"
      },
      "outputs": [],
      "source": [
        "#@title Copyright 2020 The TensorFlow Hub Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# =============================================================================="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hk5u_9KN1m-t"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>     <a target=\"_blank\" href=\"https://www.tensorflow.org/hub/tutorials/yamnet\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">TensorFlow.org에서 보기</a>   </td>\n",
        "  <td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/hub/blob/master/examples/colab/yamnet.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Google Colab에서 실행</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://github.com/tensorflow/hub/blob/master/examples/colab/yamnet.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">GitHub에서 보기</a></td>\n",
        "  <td><a href=\"https://storage.googleapis.com/tensorflow_docs/hub/examples/colab/yamnet.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">노트북 다운로드</a></td>\n",
        "  <td><a href=\"https://tfhub.dev/google/yamnet/1\"><img src=\"https://www.tensorflow.org/images/hub_logo_32px.png\">TF Hub 모델보기</a></td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2ep-q7k_5R-"
      },
      "source": [
        "# YAMNet을 사용한 사운드 분류\n",
        "\n",
        "YAMNet은 훈련된 [AudioSet-YouTube 코퍼스](https://github.com/tensorflow/models/blob/master/research/audioset/yamnet/yamnet_class_map.csv)에서 521개의 오디오 이벤트 [클래스](https://github.com/tensorflow/models/blob/master/research/audioset/yamnet/yamnet_class_map.csv)를 예측하는 딥 넷입니다. 여기에는 [Mobilenet_v1](https://arxiv.org/pdf/1704.04861.pdf) 심도 분리형 컨볼루션 아키텍처가 사용됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bteu7pfkpt_f"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import numpy as np\n",
        "import csv\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Audio\n",
        "from scipy.io import wavfile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSVs3zRrrYmY"
      },
      "source": [
        "TensorFlow 허브에서 모델을 로드합니다.\n",
        "\n",
        "참고: 문서를 읽으려면 모델의 [URL](https://tfhub.dev/google/yamnet/1)을 따르세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VX8Vzs6EpwMo"
      },
      "outputs": [],
      "source": [
        "# Load the model.\n",
        "model = hub.load('https://tfhub.dev/google/yamnet/1')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxWx6tOdtdBP"
      },
      "source": [
        "레이블 파일은 모델 자산에서 로드되며 `model.class_map_path()`에 있습니다. `class_names` 변수에 이를 로드합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EHSToAW--o4U"
      },
      "outputs": [],
      "source": [
        "# Find the name of the class with the top score when mean-aggregated across frames.\n",
        "def class_names_from_csv(class_map_csv_text):\n",
        "  \"\"\"Returns list of class names corresponding to score vector.\"\"\"\n",
        "  class_names = []\n",
        "  with tf.io.gfile.GFile(class_map_csv_text) as csvfile:\n",
        "    reader = csv.DictReader(csvfile)\n",
        "    for row in reader:\n",
        "      class_names.append(row['display_name'])\n",
        "\n",
        "  return class_names\n",
        "\n",
        "class_map_path = model.class_map_path().numpy()\n",
        "class_names = class_names_from_csv(class_map_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSFjRwkZ59lU"
      },
      "source": [
        "로드된 오디오가 적절한 sample_rate(16K)인지 확인하고 변환하는 메서드를 추가합니다. 그렇지 않으면 모델의 결과에 영향을 미칩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LizGwWjc5w6A"
      },
      "outputs": [],
      "source": [
        "def ensure_sample_rate(original_sample_rate, waveform,\n",
        "                       desired_sample_rate=16000):\n",
        "  \"\"\"Resample waveform if required.\"\"\"\n",
        "  if original_sample_rate != desired_sample_rate:\n",
        "    desired_length = int(round(float(len(waveform)) /\n",
        "                               original_sample_rate * desired_sample_rate))\n",
        "    waveform = scipy.signal.resample(waveform, desired_length)\n",
        "  return desired_sample_rate, waveform"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZEgCobA9bWl"
      },
      "source": [
        "## 사운드 파일 다운로드 및 준비하기\n",
        "\n",
        "여기에서 wav 파일을 다운로드하여 들을 수 있습니다. 이미 사용 가능한 파일이 있는 경우, colab에 업로드하고 대신 사용하세요.\n",
        "\n",
        "참고: 예상되는 오디오 파일은 16kHz 샘플링 속도의 모노 wav 파일이어야 합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WzZHvyTtsJrc"
      },
      "outputs": [],
      "source": [
        "!curl -O https://storage.googleapis.com/audioset/speech_whistling2.wav"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D8LKmqvGzZzr"
      },
      "outputs": [],
      "source": [
        "!curl -O https://storage.googleapis.com/audioset/miaow_16k.wav"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wo9KJb-5zuz1"
      },
      "outputs": [],
      "source": [
        "# wav_file_name = 'speech_whistling2.wav'\n",
        "wav_file_name = 'miaow_16k.wav'\n",
        "sample_rate, wav_data = wavfile.read(wav_file_name, 'rb')\n",
        "sample_rate, wav_data = ensure_sample_rate(sample_rate, wav_data)\n",
        "\n",
        "# Show some basic information about the audio.\n",
        "duration = len(wav_data)/sample_rate\n",
        "print(f'Sample rate: {sample_rate} Hz')\n",
        "print(f'Total duration: {duration:.2f}s')\n",
        "print(f'Size of the input: {len(wav_data)}')\n",
        "\n",
        "# Listening to the wav file.\n",
        "Audio(wav_data, rate=sample_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9I290COsMBm"
      },
      "source": [
        "`wav_data`는 `[-1.0, 1.0]`의 값으로 정규화되어야 합니다(모델의 [문서](https://tfhub.dev/google/yamnet/1)에 명시되어 있음)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bKr78aCBsQo3"
      },
      "outputs": [],
      "source": [
        "waveform = wav_data / tf.int16.max"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_Xwd4GPuMsB"
      },
      "source": [
        "## 모델 실행하기\n",
        "\n",
        "이제 쉬운 부분: 이미 준비된 데이터를 사용하여 모델을 호출하고 점수, 임베딩 및 스펙트로그램을 얻습니다.\n",
        "\n",
        "점수는 사용할 주요 결과입니다. 스펙트로그램은 나중에 시각화를 수행하는 데 사용합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJGP6r-At_Jc"
      },
      "outputs": [],
      "source": [
        "# Run the model, check the output.\n",
        "scores, embeddings, spectrogram = model(waveform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vmo7griQprDk"
      },
      "outputs": [],
      "source": [
        "scores_np = scores.numpy()\n",
        "spectrogram_np = spectrogram.numpy()\n",
        "infered_class = class_names[scores_np.mean(axis=0).argmax()]\n",
        "print(f'The main sound is: {infered_class}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uj2xLf-P_ndS"
      },
      "source": [
        "## 시각화\n",
        "\n",
        "YAMNet은 시각화에 사용할 수 있는 몇 가지 추가 정보도 반환합니다. 추론된 파형, 스펙트로그램 및 상위 클래스를 살펴보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_QSTkmv7wr2M"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Plot the waveform.\n",
        "plt.subplot(3, 1, 1)\n",
        "plt.plot(waveform)\n",
        "plt.xlim([0, len(waveform)])\n",
        "\n",
        "# Plot the log-mel spectrogram (returned by the model).\n",
        "plt.subplot(3, 1, 2)\n",
        "plt.imshow(spectrogram_np.T, aspect='auto', interpolation='nearest', origin='lower')\n",
        "\n",
        "# Plot and label the model output scores for the top-scoring classes.\n",
        "mean_scores = np.mean(scores, axis=0)\n",
        "top_n = 10\n",
        "top_class_indices = np.argsort(mean_scores)[::-1][:top_n]\n",
        "plt.subplot(3, 1, 3)\n",
        "plt.imshow(scores_np[:, top_class_indices].T, aspect='auto', interpolation='nearest', cmap='gray_r')\n",
        "\n",
        "# patch_padding = (PATCH_WINDOW_SECONDS / 2) / PATCH_HOP_SECONDS\n",
        "# values from the model documentation\n",
        "patch_padding = (0.025 / 2) / 0.01\n",
        "plt.xlim([-patch_padding-0.5, scores.shape[0] + patch_padding-0.5])\n",
        "# Label the top_N classes.\n",
        "yticks = range(0, top_n, 1)\n",
        "plt.yticks(yticks, [class_names[top_class_indices[x]] for x in yticks])\n",
        "_ = plt.ylim(-0.5 + np.array([top_n, 0]))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "yamnet.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
