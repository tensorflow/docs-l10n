{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wC0PtNm3Sa_T"
      },
      "source": [
        "##### Copyright 2019 The TensorFlow Hub Authors.\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hgOqPjRKSa-7"
      },
      "outputs": [],
      "source": [
        "# Copyright 2019 The TensorFlow Hub Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# =============================================================================="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKAkxAYuONU6"
      },
      "source": [
        "# 3D 컨볼루션을 사용한 비디오 동화 작업\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfBg1C5NB3X0"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/hub/tutorials/tweening_conv3d\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">View on TensorFlow.org</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/hub/blob/master/examples/colab/tweening_conv3d.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/hub/blob/master/examples/colab/tweening_conv3d.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">View on GitHub</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://storage.googleapis.com/tensorflow_docs/hub/examples/colab/tweening_conv3d.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Download notebook</a>\n",
        "  </td>\n",
        "  <td><a href=\"https://tfhub.dev/google/tweening_conv3d_bair/1\"><img src=\"https://www.tensorflow.org/images/hub_logo_32px.png\">TF Hub 모델보기</a></td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvMgkVIBpT-Y"
      },
      "source": [
        "Yunpeng Li, Dominik Roblek, and Marco Tagliasacchi. From Here to There: Video Inbetweening Using Direct 3D Convolutions, 2019.\n",
        "\n",
        "https://arxiv.org/abs/1905.10240\n",
        "\n",
        "현재 Hub의 특징:\n",
        "\n",
        "- BAIR 로봇 푸싱 비디오 및 KTH 액션 비디오 데이터세트에 대한 모델이 있습니다(이 colab에서는 BAIR만 사용).\n",
        "- Hub에서 이미 BAIR 데이터세트를 사용할 수 있습니다. 그러나 KTH 비디오는 사용자가 직접 제공해야 합니다.\n",
        "- 지금은 평가(비디오 생성)만 가능합니다.\n",
        "- 배치 크기와 프레임 크기는 하드 코딩됩니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4DN769E2O_R"
      },
      "source": [
        "## 설정"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EsQFWvxrYrHg"
      },
      "source": [
        "`tfds.load('bair_robot_pushing_small', split='test')`는 훈련 데이터도 포함하는 30GB 아카이브를 다운로드하므로 190MB 테스트 데이터만 포함하는 별도의 아카이브를 다운로드합니다. 사용된 데이터세트는 [이 논문](https://arxiv.org/abs/1710.05268)에 게시되었고 Creative Commons BY 4.0으로 라이선스가 부여되었습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GhIKakhc7JYL"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "from tensorflow_datasets.core import SplitGenerator\n",
        "from tensorflow_datasets.video.bair_robot_pushing import BairRobotPushingSmall\n",
        "\n",
        "import tempfile\n",
        "import pathlib\n",
        "\n",
        "TEST_DIR = pathlib.Path(tempfile.mkdtemp()) / \"bair_robot_pushing_small/softmotion30_44k/test/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zBMz14GmYkwz"
      },
      "outputs": [],
      "source": [
        "# Download the test split to $TEST_DIR\n",
        "!mkdir -p $TEST_DIR\n",
        "!wget -nv https://storage.googleapis.com/download.tensorflow.org/data/bair_test_traj_0_to_255.tfrecords -O $TEST_DIR/traj_0_to_255.tfrecords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "irRJ2Q0iYoW0"
      },
      "outputs": [],
      "source": [
        "# Since the dataset builder expects the train and test split to be downloaded,\n",
        "# patch it so it only expects the test data to be available\n",
        "builder = BairRobotPushingSmall()\n",
        "test_generator = SplitGenerator(name='test', gen_kwargs={\"filedir\": str(TEST_DIR)})\n",
        "builder._split_generators = lambda _: [test_generator]\n",
        "builder.download_and_prepare()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iaGU8hhBPi_6"
      },
      "source": [
        "## BAIR: numpy 배열 입력에 기초한 데모"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "IgWmW8YzEiDo"
      },
      "outputs": [],
      "source": [
        "# @title Load some example data (BAIR).\n",
        "batch_size = 16\n",
        "\n",
        "# If unable to download the dataset automatically due to \"not enough disk space\", please download manually to Google Drive and\n",
        "# load using tf.data.TFRecordDataset.\n",
        "ds = builder.as_dataset(split=\"test\")\n",
        "test_videos = ds.batch(batch_size)\n",
        "first_batch = next(iter(test_videos))\n",
        "input_frames = first_batch['image_aux1'][:, ::15]\n",
        "input_frames = tf.cast(input_frames, tf.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "96Jd5XefGHRr"
      },
      "outputs": [],
      "source": [
        "# @title Visualize loaded videos start and end frames.\n",
        "\n",
        "print('Test videos shape [batch_size, start/end frame, height, width, num_channels]: ', input_frames.shape)\n",
        "sns.set_style('white')\n",
        "plt.figure(figsize=(4, 2*batch_size))\n",
        "\n",
        "for i in range(batch_size)[:4]:\n",
        "  plt.subplot(batch_size, 2, 1 + 2*i)\n",
        "  plt.imshow(input_frames[i, 0] / 255.0)\n",
        "  plt.title('Video {}: First frame'.format(i))\n",
        "  plt.axis('off')\n",
        "  plt.subplot(batch_size, 2, 2 + 2*i)\n",
        "  plt.imshow(input_frames[i, 1] / 255.0)\n",
        "  plt.title('Video {}: Last frame'.format(i))\n",
        "  plt.axis('off')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0FFhkikQABy"
      },
      "source": [
        "### Hub 모듈 로드하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cLAUiWfEQAB5"
      },
      "outputs": [],
      "source": [
        "hub_handle = 'https://tfhub.dev/google/tweening_conv3d_bair/1'\n",
        "module = hub.load(hub_handle).signatures['default']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVHTdXnhbGsK"
      },
      "source": [
        "### 비디오 생성 및 표시하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FHAwBW-zyegP"
      },
      "outputs": [],
      "source": [
        "filled_frames = module(input_frames)['default'] / 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tVesWHTnSW1Z"
      },
      "outputs": [],
      "source": [
        "# Show sequences of generated video frames.\n",
        "\n",
        "# Concatenate start/end frames and the generated filled frames for the new videos.\n",
        "generated_videos = np.concatenate([input_frames[:, :1] / 255.0, filled_frames, input_frames[:, 1:] / 255.0], axis=1)\n",
        "\n",
        "for video_id in range(4):\n",
        "  fig = plt.figure(figsize=(10 * 2, 2))\n",
        "  for frame_id in range(1, 16):\n",
        "    ax = fig.add_axes([frame_id * 1 / 16., 0, (frame_id + 1) * 1 / 16., 1],\n",
        "                      xmargin=0, ymargin=0)\n",
        "    ax.imshow(generated_videos[video_id, frame_id])\n",
        "    ax.axis('off')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Q4DN769E2O_R"
      ],
      "name": "tweening_conv3d.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
