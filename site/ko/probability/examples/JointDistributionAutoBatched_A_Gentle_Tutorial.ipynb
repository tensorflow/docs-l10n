{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3puWgvKeyWu"
      },
      "source": [
        "# Auto-Batched Joint Distributions: A Gentle Tutorial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrwVQsM9TiUw"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow Authors.\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "CpDUTVKYTowI"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\"); { display-mode: \"form\" }\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltPJCG6pAUoc"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>     <a target=\"_blank\" href=\"https://www.tensorflow.org/probability/examples/Modeling_with_JointDistribution\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">TensorFlow.org에서 보기</a>   </td>\n",
        "  <td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/probability/blob/main/tensorflow_probability/examples/jupyter_notebooks/Modeling_with_JointDistribution.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Google Colab에서 실행</a></td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/probability/blob/main/tensorflow_probability/examples/jupyter_notebooks/Modeling_with_JointDistribution.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">GitHub에서 소스 보기</a>\n",
        "</td>\n",
        "  <td><a href=\"https://storage.googleapis.com/tensorflow_docs/probability/tensorflow_probability/examples/jupyter_notebooks/Modeling_with_JointDistribution.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">노트북 다운로드</a></td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzaOJSXagzMY"
      },
      "source": [
        "### 시작하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cIvB2CSBe49Z"
      },
      "source": [
        "TensorFlow Probability(TFP)는 여러 `JointDistribution` 추상화를 제공함으로 사용자가 수학적 형식에 가까운 확률적 그래프 모델을 쉽게 표현할 수 있도록 하여 확률적 추론을 더 쉽게 만듭니다. 추상화는 모델에서 샘플링하고 모델에서 샘플의 로그 확률을 평가하는 방법을 생성합니다. 이 튜토리얼에서는 원본 `JointDistribution` 추상화 이후 개발된 '자동 일괄 처리된' 변형을 검토합니다. 원래의 자동 일괄 처리되지 않은 추상화에 비해 자동 일괄 처리 버전은 사용이 더 간단하고 인체 공학적이므로 더 적은 상용구로 많은 모델을 표현할 수 있습니다. 이 colab에서는 단순한 모델을 자세히 탐색하여(다소 지루할 수 있음) 자동 일괄 처리로 해결되는 문제를 명확하게 하고, 앞으로 독자에게 TFP 형상 개념을 더 많이 소개할 수 있기를 바랍니다.\n",
        "\n",
        "Prior to the introduction of autobatching, there were a few different variants of `JointDistribution`, corresponding to different syntactic styles for expressing probabilistic models: `JointDistributionSequential`, `JointDistributionNamed`, and`JointDistributionCoroutine`. Auobatching exists as a mixin, so we now have `AutoBatched` variants of all of these. In this tutorial, we explore the differences between `JointDistributionSequential` and `JointDistributionSequentialAutoBatched`; however, everything we do here is applicable to the other variants with essentially no changes.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uiR4-VOt9NFX"
      },
      "source": [
        "### 종속성과 전제 조건\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "coUnDhkpT5_6"
      },
      "outputs": [],
      "source": [
        "#@title Import and set ups{ display-mode: \"form\" }\n",
        "\n",
        "import functools\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow.compat.v2 as tf\n",
        "tf.enable_v2_behavior()\n",
        "\n",
        "import tensorflow_probability as tfp\n",
        "\n",
        "tfd = tfp.distributions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KohBmaTn5W7I"
      },
      "source": [
        "### 전제 조건: 베이지안 회귀 문제"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vChyK0vr9XD8"
      },
      "source": [
        "We'll consider a very simple Bayesian regression scenario:\n",
        "\n",
        "$$ \\begin{align*} m &amp; \\sim \\text{Normal}(0, 1) \\ b &amp; \\sim \\text{Normal}(0, 1) \\ Y &amp; \\sim \\text{Normal}(mX + b, 1) \\end{align*} $$\n",
        "\n",
        "이 모델에서 `m`과 `b`는 표준 정규 분포에서 추출되고 관측치 `Y`는 평균이 확률 변수 `m` 및 `b`에 의존하는 정규 분포와 일부 공변량(무작위가 아닌, 알려진 공변량) `X`에서 추출됩니다(간단함을 위해 이 예에서는 모든 확률 변수의 규모가 알려져 있다고 가정함).\n",
        "\n",
        "이 모델에서 추론을 수행하려면 공변량 `X`와 관측치 `Y`를 모두 알아야 하지만, 이 튜토리얼에서는 `X`만 필요하므로 간단한 더미 `X`를 정의합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UIpJ_cXUVabB"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4, 5, 6])"
            ]
          },
          "execution_count": 0,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X = np.arange(7)\n",
        "X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CIBpupyt9GTT"
      },
      "source": [
        "### 데시데라타(Desiderata)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2uzL_uI9tqO"
      },
      "source": [
        "확률적 추론에서는 종종 두 가지 기본 연산을 수행하려고 합니다.\n",
        "\n",
        "- `sample`: 모델에서 샘플을 추출합니다.\n",
        "- `log_prob`: 모델에서 샘플의 로그 확률을 계산합니다.\n",
        "\n",
        "TFP의 `JointDistribution` 추상화(확률적 프로그래밍에 대한 다른 많은 접근 방식 포함)를 사용할 때의 주요 이점은 사용자가 모델을 *한 번* 작성하고 `sample` 및 `log_prob` 계산에 모두 액세스할 수 있다는 것입니다.\n",
        "\n",
        "데이터세트(`X.shape = (7,)`)에 7개의 지점이 있다는 점에 주목하여 이제 우수한 `JointDistribution`에 대한 데시데라타를 명시할 수 있습니다.\n",
        "\n",
        "- `sample()`은 각각 스칼라 기울기, 스칼라 바이어스 및 벡터 관측치에 해당하는 형상 `[(), (), (7,)`]을 가진 `Tensors` 목록을 생성해야 합니다.\n",
        "- `log_prob(sample())`은 특정 기울기, 바이어스 및 관측치의 로그 확률인 스칼라를 생성해야 합니다.\n",
        "- `sample([5, 3])`은 모델의 샘플 `(5, 3)`-<em>배치</em>를 나타내는 형상 <code>[(5, 3), (5, 3), (5, 3, 7)]</code>을 가진 `Tensors` 목록을 생성해야 합니다.\n",
        "- `log_prob(sample([5, 3]))`은 형상 (5, 3)의 `Tensor`를 생성해야 합니다.\n",
        "\n",
        "We'll now look at a succession of `JointDistribution` models, see how to achieve the above desiderata, and hopefully learn a little more about TFP shapes along the way.\n",
        "\n",
        "스포일러 경고: 상용구를 추가하지 않고 위의 데시데라타를 충족하는 접근 방식은 [자동 일괄 처리](#scrollTo=_h7sJ2bkfOS7)입니다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QiII0ypZcyTY"
      },
      "source": [
        "### 첫 번째 시도: `JointDistributionSequential`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kY501q-QVR9g"
      },
      "outputs": [],
      "source": [
        "jds = tfd.JointDistributionSequential([\n",
        "    tfd.Normal(loc=0., scale=1.),   # m\n",
        "    tfd.Normal(loc=0., scale=1.),   # b\n",
        "    lambda b, m: tfd.Normal(loc=m*X + b, scale=1.) # Y\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzNPPqJ-BwA-"
      },
      "source": [
        "첫 번째 시도는 모델을 코드로 직접 변환하는 것입니다. 기울기 `m`과 바이어스 `b`는 간단합니다. `Y`는 `lambda` 함수를 사용하여 정의됩니다. 일반적인 패턴은 `JointDistributionSequential`(JDS)에서 $k$ 인수의 `lambda` 함수가 모델의 이전 $k$ 분포를 사용한다는 것입니다. '역'순서에 유의하세요."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jIvsQSOD81N"
      },
      "source": [
        "샘플을 생성하는 데 사용된 샘플 *및* 기본 '하위 분포'를 모두 반환하는 `sample_distributions`를 호출합니다(`sample`을 호출하여 샘플만 생성할 수 있습니다. 튜토리얼의 뒷부분에서 이들 분포가 있으면 편리할 것입니다). 적절한 샘플은 다음과 같습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y05IrsfiaxCh"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<tf.Tensor: shape=(), dtype=float32, numpy=-1.668757>,\n",
              " <tf.Tensor: shape=(), dtype=float32, numpy=0.6585061>,\n",
              " <tf.Tensor: shape=(7,), dtype=float32, numpy=\n",
              " array([ 0.18573815, -1.79962   , -1.8106272 , -3.5971394 , -6.6625295 ,\n",
              "        -7.308844  , -9.832693  ], dtype=float32)>]"
            ]
          },
          "execution_count": 0,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dists, sample = jds.sample_distributions()\n",
        "sample"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7E1WkoCEB12"
      },
      "source": [
        "하지만 `log_prob`는 원하지 않는 형상이 있는 결과를 생성합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xR0lbgjNay4X"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(7,), dtype=float32, numpy=\n",
              "array([-4.4777603, -4.6775575, -4.7430477, -4.647725 , -4.5746684,\n",
              "       -4.4368567, -4.480562 ], dtype=float32)>"
            ]
          },
          "execution_count": 0,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "jds.log_prob(sample)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mMIs28LEJqN"
      },
      "source": [
        "여러 샘플 추출하기도 동작하지 않습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LbfRiIsfc9Hf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Incompatible shapes: [5,3] vs. [7] [Op:Mul]\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "  jds.sample([5, 3])\n",
        "except tf.errors.InvalidArgumentError as e:\n",
        "  print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rnvtz3SQHrVL"
      },
      "source": [
        "무엇이 잘못되었는지 이해하려고 해봅시다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dp30JPCmHyuz"
      },
      "source": [
        "### 간략한 검토: 배치 형상 및 이벤트 형상"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w24fZn3kH2uF"
      },
      "source": [
        "In TFP, an ordinary (not a `JointDistribution`) probability distribution has an *event shape* and a *batch shape*, and understanding the difference is crucial to effective use of TFP:\n",
        "\n",
        "- 이벤트 형상은 분포에서 단일 추출의 형상을 설명합니다. 추출은 차원에 따라 달라질 수 있습니다. 스칼라 분포의 경우 이벤트 형상은 []입니다. 5차원 MultivariateNormal의 경우 이벤트 형상은 [5]입니다.\n",
        "- 배치 형상은 동일하게 분포되지 않은 독립적인 추출, 일명 '배치'를 나타냅니다. 단일 Python 객체에서 분포의 배치를 나타내는 것은 TFP가 대규모 효율성을 달성하는 주요 방법 중 하나입니다.\n",
        "\n",
        "For our purposes, a critical fact to keep in mind is that if we call `log_prob` on a single sample from a distribution, the result will always have a shape that matches (i.e., has as rightmost dimensions) the *batch* shape.\n",
        "\n",
        "형상에 대한 자세한 내용은 ['TensorFlow 분포 형상 이해하기' 튜토리얼](https://www.tensorflow.org/probability/examples/Understanding_TensorFlow_Distributions_Shapes)을 참조하세요.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nONZMjl-KtTz"
      },
      "source": [
        "### `log_prob(sample())`이 스칼라를 생성하지 않는 이유는 무엇일까요? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUKyGzkOJiuD"
      },
      "source": [
        "배치 형상 및 이벤트 형상에 대한 지식을 사용하여 `log_prob(sample())`에서 무슨 일이 일어나고 있는지 살펴보겠습니다. 다음의 샘플을 다시 보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ijRGAnSBJwCG"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<tf.Tensor: shape=(), dtype=float32, numpy=-1.668757>,\n",
              " <tf.Tensor: shape=(), dtype=float32, numpy=0.6585061>,\n",
              " <tf.Tensor: shape=(7,), dtype=float32, numpy=\n",
              " array([ 0.18573815, -1.79962   , -1.8106272 , -3.5971394 , -6.6625295 ,\n",
              "        -7.308844  , -9.832693  ], dtype=float32)>]"
            ]
          },
          "execution_count": 0,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sample"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NAzBAsu3OoLv"
      },
      "source": [
        "그리고 분포는 다음과 같습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_xtIUKf8Nq3G"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<tfp.distributions.Normal 'Normal' batch_shape=[] event_shape=[] dtype=float32>,\n",
              " <tfp.distributions.Normal 'Normal' batch_shape=[] event_shape=[] dtype=float32>,\n",
              " <tfp.distributions.Normal 'JointDistributionSequential_sample_distributions_Normal' batch_shape=[7] event_shape=[] dtype=float32>]"
            ]
          },
          "execution_count": 0,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dists"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzkLnoZyFeU_"
      },
      "source": [
        "The log probability is computed by summing the log probabilities of the sub-distributions at the (matched) elements of the parts:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5XTDKVMPO5qg"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<tf.Tensor: shape=(), dtype=float32, numpy=-2.3113134>,\n",
              " <tf.Tensor: shape=(), dtype=float32, numpy=-1.1357536>,\n",
              " <tf.Tensor: shape=(7,), dtype=float32, numpy=\n",
              " array([-1.0306933, -1.2304904, -1.2959809, -1.200658 , -1.1276014,\n",
              "        -0.9897899, -1.0334952], dtype=float32)>]"
            ]
          },
          "execution_count": 0,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "log_prob_parts = [dist.log_prob(s) for (dist, s) in zip(dists, sample)]\n",
        "log_prob_parts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QoWsVGx8N1IJ"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(7,), dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0.], dtype=float32)>"
            ]
          },
          "execution_count": 0,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.sum(log_prob_parts) - jds.log_prob(sample)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJFvR4ZNFngd"
      },
      "source": [
        "따라서 한 가지 설명으로는 `log_prob_parts`의 3번째 서브 구성 요소가 7-텐서이므로 로그 확률 계산이 7-텐서를 반환한다는 것입니다. 이유는 무엇일까요?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdpKnguOPOrr"
      },
      "source": [
        "수학 공식에서 `Y`에 대한 분포에 해당하는 `dists`의 마지막 요소가 `[7]`의 `batch_shape`를 가짐을 확인합니다. 즉, `Y`에 대한 분포는 7개의 독립적인 정규 분포(평균이 다르며 이 경우 규모는 같음)입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WXzlR_diTuZ"
      },
      "source": [
        "We now understand what's wrong: in JDS, the distribution over `Y` has `batch_shape=[7]`, a sample from the JDS represents scalars for `m` and `b` and a \"batch\" of 7 independent normals. and `log_prob` computes 7 separate log-probabilities, each of which represents the log probability of drawing `m` and `b` and a single observation `Y[i]` at some `X[i]`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9RI0oxCi_En"
      },
      "source": [
        "### `Independent`로 `log_prob(sample())` 수정하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOL1hllzjDcF"
      },
      "source": [
        "`dists[2]`에는 `event_shape=[]`과 `batch_shape=[7]`이 있음을 상기하세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TA05J9VwjCLu"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tfp.distributions.Normal 'JointDistributionSequential_sample_distributions_Normal' batch_shape=[7] event_shape=[] dtype=float32>"
            ]
          },
          "execution_count": 0,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dists[2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xQ5ORIqjPAz"
      },
      "source": [
        "배치 차원을 이벤트 차원으로 변환하는 TFP의 `Independent` 메타분포를 사용하여 `event_shape=[7]` 및 `batch_shape=[]`의 분포로 변환할 수 있습니다(`Y`의 분포이므로 `y_dist_i` 이름을 변경하고 `_i`는 `Independent` 래핑을 대신합니다). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aa_SPItTjLBO"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tfp.distributions.Independent 'IndependentJointDistributionSequential_sample_distributions_Normal' batch_shape=[] event_shape=[7] dtype=float32>"
            ]
          },
          "execution_count": 0,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_dist_i = tfd.Independent(dists[2], reinterpreted_batch_ndims=1)\n",
        "y_dist_i"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrRjuDhhmBEr"
      },
      "source": [
        "이제 7-벡터의 `log_prob`는 스칼라입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y9yZs-kwdLGa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=-7.9087086>"
            ]
          },
          "execution_count": 0,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_dist_i.log_prob(sample[2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqNEen4Ujkhh"
      },
      "source": [
        "Under the covers, `Independent` sums over the batch:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SxYr1McJkWFx"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.0>"
            ]
          },
          "execution_count": 0,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_dist_i.log_prob(sample[2]) - tf.reduce_sum(dists[2].log_prob(sample[2]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00lD003YkojA"
      },
      "source": [
        "그리고 실제로 이를 사용하여 `log_prob`가 스칼라를 반환하는 새로운 `jds_i`(`i`는 다시 `Independent` 나타냄)를 생성할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1jwoSeNWkhT6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=-11.355776>"
            ]
          },
          "execution_count": 0,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "jds_i = tfd.JointDistributionSequential([\n",
        "    tfd.Normal(loc=0., scale=1.),   # m\n",
        "    tfd.Normal(loc=0., scale=1.),   # b\n",
        "    lambda b, m: tfd.Independent(   # Y\n",
        "        tfd.Normal(loc=m*X + b, scale=1.),\n",
        "        reinterpreted_batch_ndims=1)\n",
        "])\n",
        "\n",
        "jds_i.log_prob(sample)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hYY3CNBXlAIZ"
      },
      "source": [
        "몇 가지 참고 사항입니다.\n",
        "\n",
        "- `jds_i.log_prob(s)`은 `tf.reduce_sum(jds.log_prob(s))`와 같지 *않*습니다. 전자는 결합 분포의 '올바른' 로그 확률을 생성합니다. 후자는 7-텐서에 대해 합하고, 각 요소는 `m`, `b` 및 `Y` 로그 확률의 단일 요소의 합이므로 `m`과 `b`를 초과합니다(`log_prob(m) + log_prob(b) + log_prob(Y)`는 TFP가 TF 및 NumPy의 브로드캐스팅 규칙을 따르므로 예외로 처리하지 않고 결과를 반환합니다. 벡터에 스칼라를 추가하면 벡터 크기의 결과가 생성됩니다).\n",
        "- 이 특정 경우에는 문제를 해결하고 `Independent(Normal(...))` 대신 `MultivariateNormalDiag`를 사용하여 같은 결과를 얻을 수 있습니다. `MultivariateNormalDiag`는 벡터 값 분포입니다(즉, 이미 벡터 이벤트 형상이 있음). `MultivariateNormalDiag`는 `Independent`와 `Normal`의 구성으로 구현될 수 있지만 실제로 구현되지는 않습니다. 벡터 `V`가 주어지면 `n1 = Normal(loc=V)`와 `n2 = MultivariateNormalDiag(loc=V)`의 샘플은 구별할 수 없음을 기억하는 것이 좋습니다. 이러한 분포의 차이점은 `n1.log_prob(n1.sample())`이 벡터이고 `n2.log_prob(n2.sample())`은 스칼라라는 것입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-iFi65ZmvpB"
      },
      "source": [
        "### 여러 샘플"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZcEBJS_nAhA"
      },
      "source": [
        "여러 샘플 추출하기가 여전히 동작하지 않습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PkvYmB3jm2sI"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Incompatible shapes: [5,3] vs. [7] [Op:Mul]\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "  jds_i.sample([5, 3])\n",
        "except tf.errors.InvalidArgumentError as e:\n",
        "  print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9Jh0MTCn0Mr"
      },
      "source": [
        "그 이유를 생각해봅시다. `jds_i.sample([5, 3])`을 호출할 때 먼저 `m`과 `b` 샘플을 각각 형상 `(5, 3)`으로 추출합니다. 그 후, 다음을 통해 `Normal` 분포를 구성하려고 합니다.\n",
        "\n",
        "```\n",
        "tfd.Normal(loc=m*X + b, scale=1.)\n",
        "```\n",
        "\n",
        "그러나 `m`이 형상 `(5, 3)`이고 `X`가 형상 `7`이면 이 둘을 함께 곱할 수 없으며 실제로 이러한 오류가 발생합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ei9Z2Nozp8Dy"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Incompatible shapes: [5,3] vs. [7] [Op:Mul]\n"
          ]
        }
      ],
      "source": [
        "m = tfd.Normal(0., 1.).sample([5, 3])\n",
        "try:\n",
        "  m * X\n",
        "except tf.errors.InvalidArgumentError as e:\n",
        "  print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1uqaIx2LlaeP"
      },
      "source": [
        "이 문제를 해결하기 위해 `Y`에 대한 분포에 어떤 속성이 있어야 하는지 생각해 보겠습니다. `jds_i.sample([5, 3])`을 호출했다면 `m`과 `b`가 모두 형상`(5, 3)`을 가질 것임을 압니다. `Y` 분포에서 `sample`에 대한 호출은 어떤 형상을 생성해야 할까요? 분명한 대답은 `(5, 3, 7)`입니다. 각 배치 지점에 대해 `X`와 같은 크기의 샘플이 필요합니다. TensorFlow의 브로드캐스팅 기능으로 추가 차원을 더하여 이를 달성할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-22Bg8Yfr6tg"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TensorShape([5, 3, 1])"
            ]
          },
          "execution_count": 0,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "m[..., tf.newaxis].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7k21MOvlsHGe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TensorShape([5, 3, 7])"
            ]
          },
          "execution_count": 0,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(m[..., tf.newaxis] * X).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5AEBbcjVsXQR"
      },
      "source": [
        "`m`과 `b` 모두에 축을 추가하면 여러 샘플을 지원하는 새 JDS를 정의할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9rJ9WCVQsW0S"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<tf.Tensor: shape=(5, 3), dtype=float32, numpy=\n",
              " array([[-1.1133379 ,  0.16390413, -0.24177533],\n",
              "        [-1.1312429 , -0.6224666 , -1.8182136 ],\n",
              "        [-0.31343174, -0.32932565,  0.5164407 ],\n",
              "        [-0.0119963 , -0.9079621 ,  2.3655841 ],\n",
              "        [-0.26293617,  0.8229698 ,  0.31098196]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(5, 3), dtype=float32, numpy=\n",
              " array([[-0.02876974,  1.0872147 ,  1.0138507 ],\n",
              "        [ 0.27367726, -1.331534  , -0.09084719],\n",
              "        [ 1.3349475 , -0.68765205,  1.680652  ],\n",
              "        [ 0.75436825,  1.3050154 , -0.9415123 ],\n",
              "        [-1.2502679 , -0.25730947,  0.74611956]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(5, 3, 7), dtype=float32, numpy=\n",
              " array([[[-1.8258233e+00, -3.0641669e-01, -2.7595463e+00, -1.6952467e+00,\n",
              "          -4.8197951e+00, -5.2986512e+00, -6.6931367e+00],\n",
              "         [ 3.6438566e-01,  1.0067395e+00,  1.4542470e+00,  8.1155670e-01,\n",
              "           1.8868095e+00,  2.3877139e+00,  1.0195159e+00],\n",
              "         [-8.3624744e-01,  1.2518480e+00,  1.0943471e+00,  1.3052304e+00,\n",
              "          -4.5756745e-01, -1.0668410e-01, -7.0669651e-02]],\n",
              " \n",
              "        [[-3.1788960e-01,  9.2615485e-03, -3.0963073e+00, -2.2846246e+00,\n",
              "          -3.2269263e+00, -6.0213070e+00, -7.4806519e+00],\n",
              "         [-3.9149747e+00, -3.5155020e+00, -1.5669601e+00, -5.0759468e+00,\n",
              "          -4.5065498e+00, -5.6719379e+00, -4.8012795e+00],\n",
              "         [ 1.3053948e-01, -8.0493152e-01, -4.7845001e+00, -4.9721808e+00,\n",
              "          -7.1365709e+00, -9.6198196e+00, -9.7951422e+00]],\n",
              " \n",
              "        [[ 2.0621397e+00,  3.4639853e-01,  7.0252883e-01, -1.4311566e+00,\n",
              "           3.3790007e+00,  1.1619035e+00, -8.9105040e-01],\n",
              "         [-7.8956139e-01, -8.5023916e-01, -9.7148323e-01, -2.6229355e+00,\n",
              "          -2.7150445e+00, -2.4633870e+00, -2.1841538e+00],\n",
              "         [ 7.7627432e-01,  2.2401071e+00,  3.7601702e+00,  2.4245868e+00,\n",
              "           4.0690269e+00,  4.0605016e+00,  5.1753912e+00]],\n",
              " \n",
              "        [[ 1.4275590e+00,  3.3346462e+00,  1.5374103e+00, -2.2849756e-01,\n",
              "           9.1219616e-01, -3.1220305e-01, -3.2643962e-01],\n",
              "         [-3.1910419e-02, -3.8848895e-01,  9.9946201e-02, -2.3619974e+00,\n",
              "          -1.8507402e+00, -3.6830821e+00, -5.4907336e+00],\n",
              "         [-7.1941972e-02,  2.1602919e+00,  4.9575748e+00,  4.2317696e+00,\n",
              "           9.3528280e+00,  1.0526063e+01,  1.5262107e+01]],\n",
              " \n",
              "        [[-2.3257759e+00, -2.5343289e+00, -3.5342445e+00, -4.0423255e+00,\n",
              "          -3.2361765e+00, -3.3434000e+00, -2.6849220e+00],\n",
              "         [ 1.5006512e-02, -1.9866472e-01,  7.6781356e-01,  1.6228745e+00,\n",
              "           1.4191239e+00,  2.6655579e+00,  4.4663467e+00],\n",
              "         [ 2.6599693e+00,  1.2663836e+00,  1.7162113e+00,  1.4839669e+00,\n",
              "           2.0559487e+00,  2.5976877e+00,  2.5977583e+00]]], dtype=float32)>]"
            ]
          },
          "execution_count": 0,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "jds_ia = tfd.JointDistributionSequential([\n",
        "    tfd.Normal(loc=0., scale=1.),   # m\n",
        "    tfd.Normal(loc=0., scale=1.),   # b\n",
        "    lambda b, m: tfd.Independent(   # Y\n",
        "        tfd.Normal(loc=m[..., tf.newaxis]*X + b[..., tf.newaxis], scale=1.),\n",
        "        reinterpreted_batch_ndims=1)\n",
        "])\n",
        "\n",
        "shaped_sample = jds_ia.sample([5, 3])\n",
        "shaped_sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8fsYEy6Fla0o"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5, 3), dtype=float32, numpy=\n",
              "array([[-12.483114 , -10.139662 , -11.514159 ],\n",
              "       [-11.656767 , -17.201958 , -12.132455 ],\n",
              "       [-17.838818 ,  -9.474525 , -11.24898  ],\n",
              "       [-13.95219  , -12.490049 , -17.123957 ],\n",
              "       [-14.487818 , -11.3755455, -10.576363 ]], dtype=float32)>"
            ]
          },
          "execution_count": 0,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "jds_ia.log_prob(shaped_sample)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ArLyKqJtY3Z"
      },
      "source": [
        "추가 검사로 단일 배치 지점에 대한 로그 확률이 이전과 일치하는지 확인합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9_2lIJyJtpyW"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.0>"
            ]
          },
          "execution_count": 0,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(jds_ia.log_prob(shaped_sample)[3, 1] -\n",
        " jds_i.log_prob([shaped_sample[0][3, 1],\n",
        "                 shaped_sample[1][3, 1],\n",
        "                 shaped_sample[2][3, 1, :]]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_h7sJ2bkfOS7"
      },
      "source": [
        "<a id=\"AutoBatching-For-The-Win\"></a>\n",
        "\n",
        "### 성공적으로 자동 일괄 처리하기\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7nqIUMxuKzw"
      },
      "source": [
        "아주 좋습니다. 이제 모든 데시데라타를 처리하는 JointDistribution의 버전을 갖추었습니다. `log_prob`는 `tfd.Independent`를 사용하여 스칼라를 반환하며, 추가 축을 더하여 브로드캐스팅을 수정했으므로 이제 여러 샘플이 제대로 동작합니다.\n",
        "\n",
        "더 쉽고 더 좋은 방법이 있다면 어떨까요? 그 방법은 바로 `JointDistributionSequentialAutoBatched`(JDSAB)라고 합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LZtVljb0fRx2"
      },
      "outputs": [],
      "source": [
        "jds_ab = tfd.JointDistributionSequentialAutoBatched([\n",
        "    tfd.Normal(loc=0., scale=1.),   # m\n",
        "    tfd.Normal(loc=0., scale=1.),   # b\n",
        "    lambda b, m: tfd.Normal(loc=m*X + b, scale=1.) # Y\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gpvjnvXqu2Mk"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=-12.954952>"
            ]
          },
          "execution_count": 0,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "jds_ab.log_prob(jds.sample())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Js3luiUfns_R"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5, 3), dtype=float32, numpy=\n",
              "array([[-12.191533 , -10.43885  , -16.371655 ],\n",
              "       [-13.292994 , -11.97949  , -16.788685 ],\n",
              "       [-15.987699 , -13.435732 , -10.6029   ],\n",
              "       [-10.184758 , -11.969714 , -14.275676 ],\n",
              "       [-12.740775 , -11.5654125, -12.990162 ]], dtype=float32)>"
            ]
          },
          "execution_count": 0,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "shaped_sample = jds_ab.sample([5, 3])\n",
        "jds_ab.log_prob(shaped_sample)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v1ppa6F6bdkv"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5, 3), dtype=float32, numpy=\n",
              "array([[0., 0., 0.],\n",
              "       [0., 0., 0.],\n",
              "       [0., 0., 0.],\n",
              "       [0., 0., 0.],\n",
              "       [0., 0., 0.]], dtype=float32)>"
            ]
          },
          "execution_count": 0,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "jds_ab.log_prob(shaped_sample) - jds_ia.log_prob(shaped_sample)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xy-kuUbYwFB3"
      },
      "source": [
        "어떻게 동작하나요? 깊은 이해를 위해 [코드 읽기](https://github.com/tensorflow/probability/blob/main/tensorflow_probability/python/distributions/joint_distribution_auto_batched.py#L426)를 시도할 수 있지만 대부분의 사용 사례에 대해 충분한, 간략한 개요를 제공합니다.\n",
        "\n",
        "- 첫 번째 문제는 `Y`에 `batch_shape=[7]`와 `event_shape=[]`가 있고`Independent`를 사용하여 배치 차원을 이벤트 차원으로 변환했다는 점을 기억하세요. JDSAB는 구성 요소 분포의 배치 형상을 무시합니다. 대신 `batch_ndims > 0`을 설정하여 달리 지정하지 않는 한, 배치 형상을 모델의 전체 속성으로 처리하며 `[]`로 간주합니다. 이 효과는 위에서 수동으로 수행한 것처럼 tfd.Independent를 사용하여 구성 요소 분포의 <em>모든</em> 배치 차원을 이벤트 차원으로 변환하는 것과 같습니다.\n",
        "- 두 번째 문제는 여러 샘플을 만들 때 `X`로 적절하게 브로드캐스팅할 수 있도록 `m`과 `b`의 형상을 조정해야 한다는 것이었습니다. JDSAB를 사용하면 모델을 작성하여 단일 샘플을 생성하고 전체 모델을 '리프트(lift)'하여 TensorFlow의 [vectorized_map](https://www.tensorflow.org/api_docs/python/tf/vectorized_map)으로 여러 샘플을 생성합니다(이 특성은 JAX의 [vmap](https://jax.readthedocs.io/en/latest/notebooks/quickstart.html#Auto-vectorization-with-vmap)과 유사합니다)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUsWfVGqJiph"
      },
      "source": [
        "배치 형상 문제를 더 자세히 살펴보면, 원래의 '불량' 결합 분포 `jds`, 배치 고정 분포 `jds_i`, ` jds_ia` 및 자동 일괄 처리된 `jds_ab`의 배치 형상을 비교할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "298I732fJDk5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[TensorShape([]), TensorShape([]), TensorShape([7])]"
            ]
          },
          "execution_count": 0,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "jds.batch_shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SBmdWrUuJGx0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[TensorShape([]), TensorShape([]), TensorShape([])]"
            ]
          },
          "execution_count": 0,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "jds_i.batch_shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vD71eqN2JMhx"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[TensorShape([]), TensorShape([]), TensorShape([])]"
            ]
          },
          "execution_count": 0,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "jds_ia.batch_shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qHmvRcxBJOAZ"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TensorShape([])"
            ]
          },
          "execution_count": 0,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "jds_ab.batch_shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozegq0diJuOL"
      },
      "source": [
        "We see that the original `jds` has subdistributions with different batch shapes. `jds_i` and `jds_ia` fix this by creating subdistributions with the same (empty) batch shape. `jds_ab` has only a single (empty) batch shape."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMm55xqV1dz6"
      },
      "source": [
        "It's worth noting that `JointDistributionSequentialAutoBatched` offers some additional generality for free. Suppose we make the covariates `X` (and, implicitly, the observations `Y`) two-dimensional:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1WfK-XbR1tXU"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 0,  1,  2,  3,  4,  5,  6],\n",
              "       [ 7,  8,  9, 10, 11, 12, 13]])"
            ]
          },
          "execution_count": 0,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X = np.arange(14).reshape((2, 7))\n",
        "X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOnnkZooSj2C"
      },
      "source": [
        "Our `JointDistributionSequentialAutoBatched` works with no changes (we need to redefine the model because the shape of `X` is cached by `jds_ab.log_prob`):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6WwMvoY71qph"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<tf.Tensor: shape=(5, 3), dtype=float32, numpy=\n",
              " array([[ 0.1813647 , -0.85994506,  0.27593774],\n",
              "        [-0.73323774,  1.1153806 ,  0.8841938 ],\n",
              "        [ 0.5127983 , -0.29271227,  0.63733214],\n",
              "        [ 0.2362284 , -0.919168  ,  1.6648189 ],\n",
              "        [ 0.26317367,  0.73077047,  2.5395133 ]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(5, 3), dtype=float32, numpy=\n",
              " array([[ 0.09636458,  2.0138032 , -0.5054413 ],\n",
              "        [ 0.63941646, -1.0785882 , -0.6442188 ],\n",
              "        [ 1.2310615 , -0.3293852 ,  0.77637213],\n",
              "        [ 1.2115169 , -0.98906034, -0.07816773],\n",
              "        [-1.1318136 ,  0.510014  ,  1.036522  ]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(5, 3, 2, 7), dtype=float32, numpy=\n",
              " array([[[[-1.9685398e+00, -1.6832136e+00, -6.9127172e-01,\n",
              "            8.5992378e-01, -5.3123581e-01,  3.1584005e+00,\n",
              "            2.9044402e+00],\n",
              "          [-2.5645006e-01,  3.1554163e-01,  3.1186538e+00,\n",
              "            1.4272424e+00,  1.2843871e+00,  1.2266440e+00,\n",
              "            1.2798605e+00]],\n",
              " \n",
              "         [[ 1.5973477e+00, -5.3631151e-01,  6.8143606e-03,\n",
              "           -1.4910895e+00, -2.1568544e+00, -2.0513713e+00,\n",
              "           -3.1663666e+00],\n",
              "          [-4.9448099e+00, -2.8385928e+00, -6.9027486e+00,\n",
              "           -5.6543546e+00, -7.2378774e+00, -8.1577444e+00,\n",
              "           -9.3582869e+00]],\n",
              " \n",
              "         [[-2.1233239e+00,  5.8853775e-02,  1.2024102e+00,\n",
              "            1.6622503e+00, -1.9197327e-01,  1.8647723e+00,\n",
              "            6.4322817e-01],\n",
              "          [ 3.7549341e-01,  1.5853541e+00,  2.4594500e+00,\n",
              "            2.1952972e+00,  1.7517658e+00,  2.9666045e+00,\n",
              "            2.5468128e+00]]],\n",
              " \n",
              " \n",
              "        [[[ 8.9906776e-01,  6.7375046e-01,  7.3354661e-01,\n",
              "           -9.9894643e-01, -3.4606690e+00, -3.4810467e+00,\n",
              "           -4.4315586e+00],\n",
              "          [-3.0670738e+00, -6.3628020e+00, -6.2538433e+00,\n",
              "           -6.8091092e+00, -7.7134805e+00, -8.6319380e+00,\n",
              "           -8.6904278e+00]],\n",
              " \n",
              "         [[-2.2462025e+00, -3.3060855e-01,  1.8974400e-01,\n",
              "            3.1422038e+00,  4.1483402e+00,  3.5642972e+00,\n",
              "            4.8709240e+00],\n",
              "          [ 4.7880130e+00,  5.8790064e+00,  9.6695948e+00,\n",
              "            7.8112822e+00,  1.2022618e+01,  1.2411858e+01,\n",
              "            1.4323385e+01]],\n",
              " \n",
              "         [[-1.0189297e+00, -7.8115642e-01,  1.6466728e+00,\n",
              "            8.2378983e-01,  3.0765080e+00,  3.0170646e+00,\n",
              "            5.1899948e+00],\n",
              "          [ 6.5285158e+00,  7.8038850e+00,  6.4155884e+00,\n",
              "            9.0899811e+00,  1.0040427e+01,  9.1404457e+00,\n",
              "            1.0411951e+01]]],\n",
              " \n",
              " \n",
              "        [[[ 4.5557004e-01,  1.4905317e+00,  1.4904103e+00,\n",
              "            2.9777462e+00,  2.8620450e+00,  3.4745665e+00,\n",
              "            3.8295493e+00],\n",
              "          [ 3.9977460e+00,  5.7173767e+00,  7.8421035e+00,\n",
              "            6.3180594e+00,  6.0838981e+00,  8.2257290e+00,\n",
              "            9.6548376e+00]],\n",
              " \n",
              "         [[-7.0750320e-01, -3.5972297e-01,  4.3136525e-01,\n",
              "           -2.3301599e+00, -5.0374687e-01, -2.8338656e+00,\n",
              "           -3.4453444e+00],\n",
              "          [-3.1258626e+00, -3.4687450e+00, -1.2045374e+00,\n",
              "           -4.0196013e+00, -5.8831010e+00, -4.2965469e+00,\n",
              "           -4.1388311e+00]],\n",
              " \n",
              "         [[ 2.1969774e+00,  2.4614549e+00,  2.2314475e+00,\n",
              "            1.8392437e+00,  2.8367062e+00,  4.8600502e+00,\n",
              "            4.2273531e+00],\n",
              "          [ 6.1879644e+00,  5.1792760e+00,  6.1141996e+00,\n",
              "            5.6517797e+00,  8.9979610e+00,  7.5938139e+00,\n",
              "            9.7918644e+00]]],\n",
              " \n",
              " \n",
              "        [[[ 1.5249090e+00,  1.1388919e+00,  8.6903995e-01,\n",
              "            3.0762129e+00,  1.5128503e+00,  3.5204377e+00,\n",
              "            2.4760864e+00],\n",
              "          [ 3.4166217e+00,  3.5930209e+00,  3.1694956e+00,\n",
              "            4.5797420e+00,  4.5271711e+00,  2.8774328e+00,\n",
              "            4.7288942e+00]],\n",
              " \n",
              "         [[-2.3095846e+00, -2.0595703e+00, -3.0093951e+00,\n",
              "           -3.8594103e+00, -4.9681158e+00, -6.4256043e+00,\n",
              "           -5.5345035e+00],\n",
              "          [-6.4306297e+00, -7.0924540e+00, -8.4075985e+00,\n",
              "           -1.0417805e+01, -1.1727266e+01, -1.1196255e+01,\n",
              "           -1.1333830e+01]],\n",
              " \n",
              "         [[-7.0419472e-01,  1.4568675e+00,  3.7946482e+00,\n",
              "            4.8489718e+00,  6.6498446e+00,  9.0224218e+00,\n",
              "            1.1153137e+01],\n",
              "          [ 1.0060651e+01,  1.1998097e+01,  1.5326431e+01,\n",
              "            1.7957514e+01,  1.8323889e+01,  2.0160881e+01,\n",
              "            2.1269085e+01]]],\n",
              " \n",
              " \n",
              "        [[[-2.2360647e-01, -1.3632748e+00, -7.2704530e-01,\n",
              "            2.3558271e-01, -1.0381399e+00,  1.9387857e+00,\n",
              "           -3.3694571e-01],\n",
              "          [ 1.6015106e-01,  1.5284677e+00, -4.8567140e-01,\n",
              "           -1.7770648e-01,  2.1919653e+00,  1.3015286e+00,\n",
              "            1.3877077e+00]],\n",
              " \n",
              "         [[ 1.3688663e+00,  2.6602898e+00,  6.6657305e-01,\n",
              "            4.6554832e+00,  5.7781887e+00,  4.9115267e+00,\n",
              "            4.8446012e+00],\n",
              "          [ 5.1983776e+00,  6.2297459e+00,  6.3848300e+00,\n",
              "            8.4291229e+00,  7.1309576e+00,  1.0395646e+01,\n",
              "            8.5736713e+00]],\n",
              " \n",
              "         [[ 1.2675294e+00,  5.2844582e+00,  5.1331611e+00,\n",
              "            8.9993315e+00,  1.0794343e+01,  1.4039831e+01,\n",
              "            1.5731170e+01],\n",
              "          [ 1.9084715e+01,  2.2191265e+01,  2.3481146e+01,\n",
              "            2.5803375e+01,  2.8632090e+01,  3.0234968e+01,\n",
              "            3.1886738e+01]]]], dtype=float32)>]"
            ]
          },
          "execution_count": 0,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "jds_ab = tfd.JointDistributionSequentialAutoBatched([\n",
        "    tfd.Normal(loc=0., scale=1.),   # m\n",
        "    tfd.Normal(loc=0., scale=1.),   # b\n",
        "    lambda b, m: tfd.Normal(loc=m*X + b, scale=1.) # Y\n",
        "])\n",
        "\n",
        "shaped_sample = jds_ab.sample([5, 3])\n",
        "shaped_sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GLvHMTpnSyvH"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5, 3), dtype=float32, numpy=\n",
              "array([[-28.90071 , -23.052422, -19.851362],\n",
              "       [-19.775568, -25.894997, -20.302256],\n",
              "       [-21.10754 , -23.667885, -20.973007],\n",
              "       [-19.249458, -20.87892 , -20.573763],\n",
              "       [-22.351208, -25.457762, -24.648403]], dtype=float32)>"
            ]
          },
          "execution_count": 0,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "jds_ab.log_prob(shaped_sample)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AI40r2oETnVP"
      },
      "source": [
        "반면에 신중하게 만들어진 `JointDistributionSequential`은 더 이상 동작하지 않습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tfYkdBIi0wJl"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Incompatible shapes: [5,3,1] vs. [2,7] [Op:Mul]\n"
          ]
        }
      ],
      "source": [
        "jds_ia = tfd.JointDistributionSequential([\n",
        "    tfd.Normal(loc=0., scale=1.),   # m\n",
        "    tfd.Normal(loc=0., scale=1.),   # b\n",
        "    lambda b, m: tfd.Independent(   # Y\n",
        "        tfd.Normal(loc=m[..., tf.newaxis]*X + b[..., tf.newaxis], scale=1.),\n",
        "        reinterpreted_batch_ndims=1)\n",
        "])\n",
        "\n",
        "try:\n",
        "  jds_ia.sample([5, 3])\n",
        "except tf.errors.InvalidArgumentError as e:\n",
        "  print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLERQvFNTwQJ"
      },
      "source": [
        "이 문제를 해결하려면 두 번째 `tf.newaxis`를 `m`과 `b`가 형상과 일치하도록 추가하고 `reinterpreted_batch_ndims`를 `Independent`에 대한 호출에서 2로 늘려야 합니다. 이 경우 자동 일괄 처리 기계가 형상 문제를 처리하도록 하는 것이 더 짧고 더 쉽고 인체 공학적입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIgCF6yJXpHE"
      },
      "source": [
        "다시 한 번 말하자면, 이 노트북에서 `JointDistributionSequentialAutoBatched`를 탐색하는 동안 `JointDistribution`의 다른 변형에는 동등한 `AutoBatched`가 있습니다(`JointDistributionCoroutine` 사용자에게는 `JointDistributionCoroutineAutoBatched`에 더는 `Root` 노드를 지정할 필요가 없다는 추가 이점이 있습니다. `JointDistributionCoroutine`을 사용한 적이 없으면 이 설명은 생략해도 됩니다)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHacIM0iUW09"
      },
      "source": [
        "### 결론"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXAC7GDWUaaY"
      },
      "source": [
        "이 노트북에서는 `JointDistributionSequentialAutoBatched`를 소개하고 간단한 예제를 자세히 살펴보았습니다. TFP 형상과 자동 일괄 처리에 대해 배웠기를 바랍니다."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "JointDistributionAutoBatched_A_Gentle_Tutorial.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
