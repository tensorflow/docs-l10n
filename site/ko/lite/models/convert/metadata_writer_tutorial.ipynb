{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mq-riZs-TJGt"
      },
      "source": [
        "##### Copyright 2021 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "LEvnopDoTC4M"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSRG6qmtTRSk"
      },
      "source": [
        "# TensorFlow Lite Metadata Writer API\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlzjEt4Txr0x"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td><a target=\"_blank\" href=\"https://www.tensorflow.org/lite/models/convert/metadata_writer_tutorial\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">TensorFlow.org에서 보기</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/ko/lite/models/convert/metadata_writer_tutorial.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Google Colab에서 실행</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/ko/lite/models/convert/metadata_writer_tutorial.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">GitHub에서 소스 보기</a></td>\n",
        "  <td><a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/ko/lite/models/convert/metadata_writer_tutorial.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">노트북 다운로드</a></td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0gwEhfRYat6"
      },
      "source": [
        "[TensorFlow Lite 모델 메타데이터](https://www.tensorflow.org/lite/models/convert/metadata)는 표준 모델 설명 형식입니다. 여기에는 일반 모델 정보, 입력/출력 및 관련 파일에 대한 풍부한 의미 체계가 포함되어 있어 모델을 이해하기 쉽고 교환 가능하게 만들 수 있습니다.\n",
        "\n",
        "모델 메타데이터는 현재 다음 두 가지 주요 사용 사례에서 이용됩니다.\n",
        "\n",
        "1. **TensorFlow Lite [작업 라이브러리](https://www.tensorflow.org/lite/inference_with_metadata/task_library/overview) 및 [codegen 도구](https://www.tensorflow.org/lite/inference_with_metadata/codegen)를 사용하여 손쉬운 모델 추론이 가능합니다**. 모델 메타데이터는 이미지 분류의 레이블 파일, 오디오 분류의 오디오 입력 샘플링 비율, 자연어 모델의 입력 문자열 처리를 위한 토크나이저 유형 등 추론 시 필요한 필수 정보를 포함합니다.\n",
        "\n",
        "2. **모델 작성자가 모델 입력/출력에 대한 설명 또는 모델 사용 방법과 같은 문서를 포함**할 수 있습니다. 모델 사용자는 [Netron](https://netron.app/)과 같은 시각화 도구를 통해 이러한 문서를 볼 수 있습니다.\n",
        "\n",
        "TensorFlow Lite Metadata Writer API는 사용하기 쉬운 API를 제공하여 TFLite 작업 라이브러리에서 지원하는 주된 ML 작업에 대한 모델 메타데이터를 생성합니다. 이 노트북은 아래의 다음 작업에 대해 메타데이터를 채우는 방법에 대한 예를 보여줍니다.\n",
        "\n",
        "- [이미지 분류기](#image_classifiers)\n",
        "- [물체 감지기](#object_detectors)\n",
        "- [이미지 분할기](#image_segmenters)\n",
        "- [자연어 분류기](#nl_classifiers)\n",
        "- [오디오 분류기](#audio_classifiers)\n",
        "\n",
        "BERT 자연어 분류기 및 BERT 질문 답변자를 위한 메타데이터 작성자가 곧 제공될 예정입니다.\n",
        "\n",
        "지원되지 않는 사용 사례에 대한 메타데이터를 추가하려면 [Flatbuffers Python API](https://www.tensorflow.org/lite/models/convert/metadata#adding_metadata)를 사용하세요. [여기](https://www.tensorflow.org/lite/models/convert/metadata#adding_metadata)에서 튜토리얼을 참조하세요.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVRIGdA4T6tO"
      },
      "source": [
        "## 전제 조건"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVTD2KSyotBK"
      },
      "source": [
        "TensorFlow Lite 지원 Pypi 패키지를 설치합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m-8xSrSvUg-6"
      },
      "outputs": [],
      "source": [
        "!pip install tflite-support-nightly"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyYS87Odpxef"
      },
      "source": [
        "## 작업 라이브러리 및 Codegen에 대한 모델 메타데이터 만들기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLxv541TqTim"
      },
      "source": [
        "<a name=\"image_classifiers\"></a>\n",
        "\n",
        "### <a>이미지 분류기</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s41TjCGlsyEF"
      },
      "source": [
        "지원되는 모델 형식에 대한 자세한 내용은 [이미지 분류기 모델 호환성 요구 사항](https://www.tensorflow.org/lite/inference_with_metadata/task_library/image_classifier#model_compatibility_requirements)을 참조하세요."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KsPKmg8T9-8"
      },
      "source": [
        "1단계: 필요한 패키지를 가져옵니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hhgNqEtWrwB3"
      },
      "outputs": [],
      "source": [
        "from tflite_support.metadata_writers import image_classifier\n",
        "from tflite_support.metadata_writers import writer_utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9WBgiFdsiIQ"
      },
      "source": [
        "2단계: 예제 이미지 분류기 [mobilenet_v2_1.0_224.tflite](https://github.com/tensorflow/tflite-support/raw/master/tensorflow_lite_support/metadata/python/tests/testdata/image_classifier/mobilenet_v2_1.0_224.tflite) 및 [레이블 파일](https://github.com/tensorflow/tflite-support/raw/master/tensorflow_lite_support/metadata/python/tests/testdata/image_classifier/labels.txt)을 다운로드합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6WgSBbNet-Tt"
      },
      "outputs": [],
      "source": [
        "!curl -L https://github.com/tensorflow/tflite-support/raw/master/tensorflow_lite_support/metadata/python/tests/testdata/image_classifier/mobilenet_v2_1.0_224.tflite -o mobilenet_v2_1.0_224.tflite\n",
        "!curl -L https://github.com/tensorflow/tflite-support/raw/master/tensorflow_lite_support/metadata/python/tests/testdata/image_classifier/labels.txt -o mobilenet_labels.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALtlz7woweHe"
      },
      "source": [
        "3단계: 메타데이터 작성기를 만들고 채웁니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_SMEBBt2r-W6"
      },
      "outputs": [],
      "source": [
        "ImageClassifierWriter = image_classifier.MetadataWriter\n",
        "_MODEL_PATH = \"mobilenet_v2_1.0_224.tflite\"\n",
        "# Task Library expects label files that are in the same format as the one below.\n",
        "_LABEL_FILE = \"mobilenet_labels.txt\"\n",
        "_SAVE_TO_PATH = \"mobilenet_v2_1.0_224_metadata.tflite\"\n",
        "# Normalization parameters is required when reprocessing the image. It is\n",
        "# optional if the image pixel values are in range of [0, 255] and the input\n",
        "# tensor is quantized to uint8. See the introduction for normalization and\n",
        "# quantization parameters below for more details.\n",
        "# https://www.tensorflow.org/lite/models/convert/metadata#normalization_and_quantization_parameters)\n",
        "_INPUT_NORM_MEAN = 127.5\n",
        "_INPUT_NORM_STD = 127.5\n",
        "\n",
        "# Create the metadata writer.\n",
        "writer = ImageClassifierWriter.create_for_inference(\n",
        "    writer_utils.load_file(_MODEL_PATH), [_INPUT_NORM_MEAN], [_INPUT_NORM_STD],\n",
        "    [_LABEL_FILE])\n",
        "\n",
        "# Verify the metadata generated by metadata writer.\n",
        "print(writer.get_metadata_json())\n",
        "\n",
        "# Populate the metadata into the model.\n",
        "writer_utils.save_file(writer.populate(), _SAVE_TO_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GhhTDkr-uf0n"
      },
      "source": [
        "<a name=\"object_detectors\"></a>\n",
        "\n",
        "### <a>물체 감지기</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EL9GssnTuf0n"
      },
      "source": [
        "지원되는 모델 형식에 대한 자세한 내용은 [물체 감지기 모델 호환성 요구 사항](https://www.tensorflow.org/lite/inference_with_metadata/task_library/object_detector#model_compatibility_requirements)을 참조하세요."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-HUTEtHuf0n"
      },
      "source": [
        "1단계: 필요한 패키지를 가져옵니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2_NIROeouf0o"
      },
      "outputs": [],
      "source": [
        "from tflite_support.metadata_writers import object_detector\n",
        "from tflite_support.metadata_writers import writer_utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UM6jijiUuf0o"
      },
      "source": [
        "2단계: 예제 물체 감지기 [ssd_mobilenet_v1.tflite](https://github.com/tensorflow/tflite-support/blob/master/tensorflow_lite_support/metadata/python/tests/testdata/object_detector/ssd_mobilenet_v1.tflite) 및 [레이블 파일](https://github.com/tensorflow/tflite-support/blob/master/tensorflow_lite_support/metadata/python/tests/testdata/object_detector/labelmap.txt)을 다운로드합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4i_BBfGzuf0o"
      },
      "outputs": [],
      "source": [
        "!curl -L https://github.com/tensorflow/tflite-support/raw/master/tensorflow_lite_support/metadata/python/tests/testdata/object_detector/ssd_mobilenet_v1.tflite -o ssd_mobilenet_v1.tflite\n",
        "!curl -L https://github.com/tensorflow/tflite-support/raw/master/tensorflow_lite_support/metadata/python/tests/testdata/object_detector/labelmap.txt -o ssd_mobilenet_labels.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DG9T3eSDwsnd"
      },
      "source": [
        "3단계: 메타데이터 작성기를 만들고 채웁니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vMGGeJfCuf0p"
      },
      "outputs": [],
      "source": [
        "ObjectDetectorWriter = object_detector.MetadataWriter\n",
        "_MODEL_PATH = \"ssd_mobilenet_v1.tflite\"\n",
        "# Task Library expects label files that are in the same format as the one below.\n",
        "_LABEL_FILE = \"ssd_mobilenet_labels.txt\"\n",
        "_SAVE_TO_PATH = \"ssd_mobilenet_v1_metadata.tflite\"\n",
        "# Normalization parameters is required when reprocessing the image. It is\n",
        "# optional if the image pixel values are in range of [0, 255] and the input\n",
        "# tensor is quantized to uint8. See the introduction for normalization and\n",
        "# quantization parameters below for more details.\n",
        "# https://www.tensorflow.org/lite/models/convert/metadata#normalization_and_quantization_parameters)\n",
        "_INPUT_NORM_MEAN = 127.5\n",
        "_INPUT_NORM_STD = 127.5\n",
        "\n",
        "# Create the metadata writer.\n",
        "writer = ObjectDetectorWriter.create_for_inference(\n",
        "    writer_utils.load_file(_MODEL_PATH), [_INPUT_NORM_MEAN], [_INPUT_NORM_STD],\n",
        "    [_LABEL_FILE])\n",
        "\n",
        "# Verify the metadata generated by metadata writer.\n",
        "print(writer.get_metadata_json())\n",
        "\n",
        "# Populate the metadata into the model.\n",
        "writer_utils.save_file(writer.populate(), _SAVE_TO_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QT0Oa0SU6uGS"
      },
      "source": [
        "<a name=\"image_segmenters\"></a>\n",
        "\n",
        "### <a>이미지 분할기</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaFQmg-S6uGW"
      },
      "source": [
        "지원되는 모델 형식에 대한 자세한 내용은 [이미지 분할기 모델 호환성 요구 사항](https://www.tensorflow.org/lite/inference_with_metadata/task_library/image_segmenter#model_compatibility_requirements)을 참조하세요."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DiktANhj6uGX"
      },
      "source": [
        "1단계: 필요한 패키지를 가져옵니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H6Lrw3op6uGX"
      },
      "outputs": [],
      "source": [
        "from tflite_support.metadata_writers import image_segmenter\n",
        "from tflite_support.metadata_writers import writer_utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EFs8Oyi6uGX"
      },
      "source": [
        "2단계: 예제 이미지 분할기 [deeplabv3.tflite](https://github.com/tensorflow/tflite-support/blob/master/tensorflow_lite_support/metadata/python/tests/testdata/image_segmenter/deeplabv3.tflite) 및 [레이블 파일](https://github.com/tensorflow/tflite-support/blob/master/tensorflow_lite_support/metadata/python/tests/testdata/image_segmenter/labelmap.txt)을 다운로드합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "feQDH0bN6uGY"
      },
      "outputs": [],
      "source": [
        "!curl -L https://github.com/tensorflow/tflite-support/raw/master/tensorflow_lite_support/metadata/python/tests/testdata/image_segmenter/deeplabv3.tflite -o deeplabv3.tflite\n",
        "!curl -L https://github.com/tensorflow/tflite-support/raw/master/tensorflow_lite_support/metadata/python/tests/testdata/image_segmenter/labelmap.txt -o deeplabv3_labels.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LhiAbJM6uGY"
      },
      "source": [
        "3단계: 메타데이터 작성기를 만들고 채웁니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yot8xLI46uGY"
      },
      "outputs": [],
      "source": [
        "ImageSegmenterWriter = image_segmenter.MetadataWriter\n",
        "_MODEL_PATH = \"deeplabv3.tflite\"\n",
        "# Task Library expects label files that are in the same format as the one below.\n",
        "_LABEL_FILE = \"deeplabv3_labels.txt\"\n",
        "_SAVE_TO_PATH = \"deeplabv3_metadata.tflite\"\n",
        "# Normalization parameters is required when reprocessing the image. It is\n",
        "# optional if the image pixel values are in range of [0, 255] and the input\n",
        "# tensor is quantized to uint8. See the introduction for normalization and\n",
        "# quantization parameters below for more details.\n",
        "# https://www.tensorflow.org/lite/models/convert/metadata#normalization_and_quantization_parameters)\n",
        "_INPUT_NORM_MEAN = 127.5\n",
        "_INPUT_NORM_STD = 127.5\n",
        "\n",
        "# Create the metadata writer.\n",
        "writer = ImageSegmenterWriter.create_for_inference(\n",
        "    writer_utils.load_file(_MODEL_PATH), [_INPUT_NORM_MEAN], [_INPUT_NORM_STD],\n",
        "    [_LABEL_FILE])\n",
        "\n",
        "# Verify the metadata generated by metadata writer.\n",
        "print(writer.get_metadata_json())\n",
        "\n",
        "# Populate the metadata into the model.\n",
        "writer_utils.save_file(writer.populate(), _SAVE_TO_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NnvM80e7AG-h"
      },
      "source": [
        "<a name=\"nl_classifiers\"></a>###자연어 분류기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfOPhFwOAG-k"
      },
      "source": [
        "지원되는 모델 형식에 대한 자세한 내용은 [자연어 분류기 모델 호환성 요구 사항](https://www.tensorflow.org/lite/inference_with_metadata/task_library/nl_classifier#model_compatibility_requirements)을 참조하세요."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMJ7tvuwAG-k"
      },
      "source": [
        "1단계: 필요한 패키지를 가져옵니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_FGVyb2iAG-k"
      },
      "outputs": [],
      "source": [
        "from tflite_support.metadata_writers import nl_classifier\n",
        "from tflite_support.metadata_writers import metadata_info\n",
        "from tflite_support.metadata_writers import writer_utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIg7rATpAG-l"
      },
      "source": [
        "2단계: 예제 자연어 분류기 [movie_review.tflite](https://github.com/tensorflow/tflite-support/blob/master/tensorflow_lite_support/metadata/python/tests/testdata/nl_classifier/movie_review.tflite), [레이블 파일](https://github.com/tensorflow/tflite-support/blob/master/tensorflow_lite_support/metadata/python/tests/testdata/nl_classifier/labels.txt) 및 [어휘 파일](https://storage.googleapis.com/download.tensorflow.org/models/tflite_support/nl_classifier/vocab.txt)을 다운로드합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TzuQcti2AG-l"
      },
      "outputs": [],
      "source": [
        "!curl -L https://github.com/tensorflow/tflite-support/raw/master/tensorflow_lite_support/metadata/python/tests/testdata/nl_classifier/movie_review.tflite -o movie_review.tflite\n",
        "!curl -L https://github.com/tensorflow/tflite-support/raw/master/tensorflow_lite_support/metadata/python/tests/testdata/nl_classifier/labels.txt -o movie_review_labels.txt\n",
        "!curl -L https://storage.googleapis.com/download.tensorflow.org/models/tflite_support/nl_classifier/vocab.txt -o movie_review_vocab.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWxUtHdeAG-m"
      },
      "source": [
        "3단계: 메타데이터 작성기를 만들고 채웁니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NGPWzRuHAG-m"
      },
      "outputs": [],
      "source": [
        "NLClassifierWriter = nl_classifier.MetadataWriter\n",
        "_MODEL_PATH = \"movie_review.tflite\"\n",
        "# Task Library expects label files and vocab files that are in the same formats\n",
        "# as the ones below.\n",
        "_LABEL_FILE = \"movie_review_labels.txt\"\n",
        "_VOCAB_FILE = \"movie_review_vocab.txt\"\n",
        "# NLClassifier supports tokenize input string using the regex tokenizer. See\n",
        "# more details about how to set up RegexTokenizer below:\n",
        "# https://github.com/tensorflow/tflite-support/blob/master/tensorflow_lite_support/metadata/python/metadata_writers/metadata_info.py#L130\n",
        "_DELIM_REGEX_PATTERN = r\"[^\\w\\']+\"\n",
        "_SAVE_TO_PATH = \"moview_review_metadata.tflite\"\n",
        "\n",
        "# Create the metadata writer.\n",
        "writer = nl_classifier.MetadataWriter.create_for_inference(\n",
        "    writer_utils.load_file(_MODEL_PATH),\n",
        "    metadata_info.RegexTokenizerMd(_DELIM_REGEX_PATTERN, _VOCAB_FILE),\n",
        "    [_LABEL_FILE])\n",
        "\n",
        "# Verify the metadata generated by metadata writer.\n",
        "print(writer.get_metadata_json())\n",
        "\n",
        "# Populate the metadata into the model.\n",
        "writer_utils.save_file(writer.populate(), _SAVE_TO_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qv0WDnzW711f"
      },
      "source": [
        "<a name=\"audio_classifiers\"></a>\n",
        "\n",
        "### <a>오디오 분류기</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqP7X8jww8pL"
      },
      "source": [
        "지원되는 모델 형식에 대한 자세한 내용은 [오디오 분류기 모델 호환성 요구 사항](https://www.tensorflow.org/lite/inference_with_metadata/task_library/audio_classifier#model_compatibility_requirements)을 참조하세요."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RToKepxw8pL"
      },
      "source": [
        "1단계: 필요한 패키지를 가져옵니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JjddvTXKw8pL"
      },
      "outputs": [],
      "source": [
        "from tflite_support.metadata_writers import audio_classifier\n",
        "from tflite_support.metadata_writers import metadata_info\n",
        "from tflite_support.metadata_writers import writer_utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ar418rH6w8pL"
      },
      "source": [
        "2단계: 예제 오디오 분류기 [yamnet.tflite](https://github.com/tensorflow/tflite-support/blob/master/tensorflow_lite_support/metadata/python/tests/testdata/audio_classifier/yamnet_wavin_quantized_mel_relu6.tflite) 및 [레이블 파일](https://github.com/tensorflow/tflite-support/blob/master/tensorflow_lite_support/metadata/python/tests/testdata/audio_classifier/yamnet_521_labels.txt)을 다운로드합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5eQY6znmw8pM"
      },
      "outputs": [],
      "source": [
        "!curl -L https://github.com/tensorflow/tflite-support/raw/master/tensorflow_lite_support/metadata/python/tests/testdata/audio_classifier/yamnet_wavin_quantized_mel_relu6.tflite -o yamnet.tflite\n",
        "!curl -L https://github.com/tensorflow/tflite-support/raw/master/tensorflow_lite_support/metadata/python/tests/testdata/audio_classifier/yamnet_521_labels.txt -o yamnet_labels.txt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TYP5w0Ew8pM"
      },
      "source": [
        "3단계: 메타데이터 작성기를 만들고 채웁니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MDlSczBQw8pM"
      },
      "outputs": [],
      "source": [
        "AudioClassifierWriter = audio_classifier.MetadataWriter\n",
        "_MODEL_PATH = \"yamnet.tflite\"\n",
        "# Task Library expects label files that are in the same format as the one below.\n",
        "_LABEL_FILE = \"yamnet_labels.txt\"\n",
        "# Expected sampling rate of the input audio buffer.\n",
        "_SAMPLE_RATE = 16000\n",
        "# Expected number of channels of the input audio buffer. Note, Task library only\n",
        "# support single channel so far.\n",
        "_CHANNELS = 1\n",
        "_SAVE_TO_PATH = \"yamnet_metadata.tflite\"\n",
        "\n",
        "# Create the metadata writer.\n",
        "writer = AudioClassifierWriter.create_for_inference(\n",
        "    writer_utils.load_file(_MODEL_PATH), _SAMPLE_RATE, _CHANNELS, [_LABEL_FILE])\n",
        "\n",
        "# Verify the metadata generated by metadata writer.\n",
        "print(writer.get_metadata_json())\n",
        "\n",
        "# Populate the metadata into the model.\n",
        "writer_utils.save_file(writer.populate(), _SAVE_TO_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YoRLs84yNAJR"
      },
      "source": [
        "## 시맨틱 정보로 모델 메타데이터 생성하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxXsOBknOGJ2"
      },
      "source": [
        "Metadata Writer API를 통해 모델 및 각 텐서에 대한 보다 자세한 설명 정보를 입력하여 모델 이해도를 높일 수 있습니다. 이를 위해 각 메타데이터 작성자의 'create_from_metadata_info' 메서드를 이용할 수 있습니다. 일반적으로 'create_from_metadata_info' 매개변수(예: `general_md`, `input_md` 및 `output_md`)를 통해 데이터를 채울 수 있습니다. 이미지 분류기를 위한 풍부한 모델 메타데이터를 생성하려면 아래 예를 참조하세요."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-LW6nrcQ9lv"
      },
      "source": [
        "1단계: 필요한 패키지를 가져옵니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KsL_egYcRGw3"
      },
      "outputs": [],
      "source": [
        "from tflite_support.metadata_writers import image_classifier\n",
        "from tflite_support.metadata_writers import metadata_info\n",
        "from tflite_support.metadata_writers import writer_utils\n",
        "from tflite_support import metadata_schema_py_generated as _metadata_fb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UWck_8uRboF"
      },
      "source": [
        "2단계: 예제 이미지 분류기 [mobilenet_v2_1.0_224.tflite](https://github.com/tensorflow/tflite-support/raw/master/tensorflow_lite_support/metadata/python/tests/testdata/image_classifier/mobilenet_v2_1.0_224.tflite) 및 [레이블 파일](https://github.com/tensorflow/tflite-support/raw/master/tensorflow_lite_support/metadata/python/tests/testdata/image_classifier/labels.txt)을 다운로드합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TqJ-jh-PRVdk"
      },
      "outputs": [],
      "source": [
        "!curl -L https://github.com/tensorflow/tflite-support/raw/master/tensorflow_lite_support/metadata/python/tests/testdata/image_classifier/mobilenet_v2_1.0_224.tflite -o mobilenet_v2_1.0_224.tflite\n",
        "!curl -L https://github.com/tensorflow/tflite-support/raw/master/tensorflow_lite_support/metadata/python/tests/testdata/image_classifier/labels.txt -o mobilenet_labels.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4I5wJMQRxzb"
      },
      "source": [
        "3단계: 모델 및 텐서 정보를 생성합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "urd7HDuaR_HC"
      },
      "outputs": [],
      "source": [
        "model_buffer = writer_utils.load_file(\"mobilenet_v2_1.0_224.tflite\")\n",
        "\n",
        "# Create general model information.\n",
        "general_md = metadata_info.GeneralMd(\n",
        "    name=\"ImageClassifier\",\n",
        "    version=\"v1\",\n",
        "    description=(\"Identify the most prominent object in the image from a \"\n",
        "                 \"known set of categories.\"),\n",
        "    author=\"TensorFlow Lite\",\n",
        "    licenses=\"Apache License. Version 2.0\")\n",
        "\n",
        "# Create input tensor information.\n",
        "input_md = metadata_info.InputImageTensorMd(\n",
        "    name=\"input image\",\n",
        "    description=(\"Input image to be classified. The expected image is \"\n",
        "                 \"128 x 128, with three channels (red, blue, and green) per \"\n",
        "                 \"pixel. Each element in the tensor is a value between min and \"\n",
        "                 \"max, where (per-channel) min is [0] and max is [255].\"),\n",
        "    norm_mean=[127.5],\n",
        "    norm_std=[127.5],\n",
        "    color_space_type=_metadata_fb.ColorSpaceType.RGB,\n",
        "    tensor_type=writer_utils.get_input_tensor_types(model_buffer)[0])\n",
        "\n",
        "# Create output tensor information.\n",
        "output_md = metadata_info.ClassificationTensorMd(\n",
        "    name=\"probability\",\n",
        "    description=\"Probabilities of the 1001 labels respectively.\",\n",
        "    label_files=[\n",
        "        metadata_info.LabelFileMd(file_path=\"mobilenet_labels.txt\",\n",
        "                                  locale=\"en\")\n",
        "    ],\n",
        "    tensor_type=writer_utils.get_output_tensor_types(model_buffer)[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5aL5Uxkf4aO"
      },
      "source": [
        "4단계: 메타데이터 작성기를 만들고 채웁니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_iWIwdqEf_mr"
      },
      "outputs": [],
      "source": [
        "ImageClassifierWriter = image_classifier.MetadataWriter\n",
        "# Create the metadata writer.\n",
        "writer = ImageClassifierWriter.create_from_metadata_info(\n",
        "    model_buffer, general_md, input_md, output_md)\n",
        "\n",
        "# Verify the metadata generated by metadata writer.\n",
        "print(writer.get_metadata_json())\n",
        "\n",
        "# Populate the metadata into the model.\n",
        "writer_utils.save_file(writer.populate(), _SAVE_TO_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z78vuu6np5sb"
      },
      "source": [
        "## 모델에 채워진 메타데이터를 읽습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DnWt-4oOselo"
      },
      "source": [
        "다음 코드를 통해 TFLite 모델의 메타데이터 및 관련 파일을 표시할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5D13YPUsp5VT"
      },
      "outputs": [],
      "source": [
        "from tflite_support import metadata\n",
        "\n",
        "displayer = metadata.MetadataDisplayer.with_model_file(\"mobilenet_v2_1.0_224_metadata.tflite\")\n",
        "print(\"Metadata populated:\")\n",
        "print(displayer.get_metadata_json())\n",
        "\n",
        "print(\"Associated file(s) populated:\")\n",
        "for file_name in displayer.get_packed_associated_file_list():\n",
        "  print(\"file name: \", file_name)\n",
        "  print(\"file content:\")\n",
        "  print(displayer.get_associated_file_buffer(file_name))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Mq-riZs-TJGt"
      ],
      "name": "metadata_writer_tutorial.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
