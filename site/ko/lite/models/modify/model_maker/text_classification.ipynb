{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2q27gKz1H20"
      },
      "source": [
        "##### Copyright 2019 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "TUfAcER1oUS6"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gb7qyhNL1yWt"
      },
      "source": [
        "# TensorFlow Lite Model Maker를 사용한 텍스트 분류"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fw5Y7snSuG51"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/lite/models/modify/model_maker/text_classification\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/models/modify/model_maker/text_classification.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/models/modify/model_maker/text_classification.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://storage.googleapis.com/tensorflow_docs/tensorflow/tensorflow/lite/g3doc/models/modify/model_maker/text_classification.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sr3q-gvm3cI8"
      },
      "source": [
        "The [TensorFlow Lite Model Maker library](https://www.tensorflow.org/lite/models/modify/model_maker) simplifies the process of adapting and converting a TensorFlow model to particular input data when deploying this model for on-device ML applications.\n",
        "\n",
        "This notebook shows an end-to-end example that utilizes the Model Maker library to illustrate the adaptation and conversion of a commonly-used text classification model to classify movie reviews on a mobile device. The text classification model classifies text into predefined categories. The inputs should be preprocessed text and the outputs are the probabilities of the categories. The dataset used in this tutorial are positive and negative movie reviews."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcLF2PKkSbV3"
      },
      "source": [
        "## 전제 조건\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vvAObmTqglq"
      },
      "source": [
        "### 필수 패키지 설치하기\n",
        "\n",
        "이 예제를 실행하려면 [GitHub 리포지토리](https://github.com/tensorflow/examples/tree/master/tensorflow_examples/lite/model_maker)의 Model Maker 패키지를 포함하여 필요한 패키지를 설치합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qhl8lqVamEty"
      },
      "outputs": [],
      "source": [
        "!sudo apt -y install libportaudio2\n",
        "!pip install -q tflite-model-maker-nightly"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6lRhVK9Q_0U"
      },
      "source": [
        "필요한 패키지를 가져옵니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XtxiUeZEiXpt"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "\n",
        "from tflite_model_maker import model_spec\n",
        "from tflite_model_maker import text_classifier\n",
        "from tflite_model_maker.config import ExportFormat\n",
        "from tflite_model_maker.text_classifier import AverageWordVecSpec\n",
        "from tflite_model_maker.text_classifier import DataLoader\n",
        "\n",
        "import tensorflow as tf\n",
        "assert tf.__version__.startswith('2')\n",
        "tf.get_logger().setLevel('ERROR')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRd13bfetO7B"
      },
      "source": [
        "### Download the sample training data.\n",
        "\n",
        "In this tutorial, we will use the [SST-2](https://nlp.stanford.edu/sentiment/index.html) (Stanford Sentiment Treebank) which is one of the tasks in the [GLUE](https://gluebenchmark.com/) benchmark. It contains 67,349 movie reviews for training and 872 movie reviews for testing. The dataset has two classes: positive and negative movie reviews."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R2BSkxWg6Rhx"
      },
      "outputs": [],
      "source": [
        "data_dir = tf.keras.utils.get_file(\n",
        "      fname='SST-2.zip',\n",
        "      origin='https://dl.fbaipublicfiles.com/glue/data/SST-2.zip',\n",
        "      extract=True)\n",
        "data_dir = os.path.join(os.path.dirname(data_dir), 'SST-2')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPYTbGrizcTC"
      },
      "source": [
        "The SST-2 dataset is stored in TSV format. The only difference between TSV and CSV is that TSV uses a tab `\\t` character as its delimiter instead of a comma `,` in the CSV format.\n",
        "\n",
        "Here are the first 5 lines of the training dataset. label=0 means negative, label=1 means positive.\n",
        "\n",
        "| sentence                                                                                  | label |   |   |   |\n",
        "|-------------------------------------------------------------------------------------------|-------|---|---|---|\n",
        "| hide new secretions from the parental units                                               | 0     |   |   |   |\n",
        "| contains no wit , only labored gags                                                       | 0     |   |   |   |\n",
        "| that loves its characters and communicates something rather beautiful about human nature  | 1     |   |   |   |\n",
        "| remains utterly satisfied to remain the same throughout                                   | 0     |   |   |   |\n",
        "| on the worst revenge-of-the-nerds clichés the filmmakers could dredge up                  | 0     |   |   |   |\n",
        "\n",
        "Next, we will load the dataset into a Pandas dataframe and change the current label names (`0` and `1`) to a more human-readable ones (`negative` and `positive`) and use them for model training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iLNaOXnl3JQB"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def replace_label(original_file, new_file):\n",
        "  # Load the original file to pandas. We need to specify the separator as\n",
        "  # '\\t' as the training data is stored in TSV format\n",
        "  df = pd.read_csv(original_file, sep='\\t')\n",
        "\n",
        "  # Define how we want to change the label name\n",
        "  label_map = {0: 'negative', 1: 'positive'}\n",
        "\n",
        "  # Excute the label change\n",
        "  df.replace({'label': label_map}, inplace=True)\n",
        "\n",
        "  # Write the updated dataset to a new file\n",
        "  df.to_csv(new_file)\n",
        "\n",
        "# Replace the label name for both the training and test dataset. Then write the\n",
        "# updated CSV dataset to the current folder.\n",
        "replace_label(os.path.join(os.path.join(data_dir, 'train.tsv')), 'train.csv')\n",
        "replace_label(os.path.join(os.path.join(data_dir, 'dev.tsv')), 'dev.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xushUyZXqP59"
      },
      "source": [
        "## Quickstart\n",
        "\n",
        "There are five steps to train a text classification model:\n",
        "\n",
        "**Step 1. Choose a text classification model architecture.**\n",
        "\n",
        "Here we use the average word embedding model architecture, which will produce a small and fast model with decent accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CtdZ-JDwMimd"
      },
      "outputs": [],
      "source": [
        "spec = model_spec.get('average_word_vec')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yug6gR9qyHui"
      },
      "source": [
        "Model Maker also supports other model architectures such as [BERT](https://arxiv.org/abs/1810.04805). If you are interested to learn about other architecture, see the [Choose a model architecture for Text Classifier](#scrollTo=kJ_B8fMDOhMR) section below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5U-A3tw6Y27"
      },
      "source": [
        "**Step 2.   Load the training and test data, then preprocess them according to a specific `model_spec`.**\n",
        "\n",
        "Model Maker can take input data in the CSV format. We will load the training and test dataset with the human-readable label name that were created earlier.\n",
        "\n",
        "Each model architecture requires input data to be processed in a particular way. `DataLoader` reads the requirement from `model_spec` and automatically executes the necessary preprocessing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HD5BvzWe6YKa"
      },
      "outputs": [],
      "source": [
        "train_data = DataLoader.from_csv(\n",
        "      filename='train.csv',\n",
        "      text_column='sentence',\n",
        "      label_column='label',\n",
        "      model_spec=spec,\n",
        "      is_training=True)\n",
        "test_data = DataLoader.from_csv(\n",
        "      filename='dev.csv',\n",
        "      text_column='sentence',\n",
        "      label_column='label',\n",
        "      model_spec=spec,\n",
        "      is_training=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2uZkLR6N6gDR"
      },
      "source": [
        "**Step 3. Train the TensorFlow model with the training data.**\n",
        "\n",
        "The average word embedding model use `batch_size = 32` by default. Therefore you will see that it takes 2104 steps to go through the 67,349 sentences in the training dataset. We will train the model for 10 epochs, which means going through the training dataset 10 times."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kwlYdTcg63xy"
      },
      "outputs": [],
      "source": [
        "model = text_classifier.create(train_data, model_spec=spec, epochs=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BzCHLWJ6h7q"
      },
      "source": [
        "**Step 4. Evaluate the model with the test data.**\n",
        "\n",
        "After training the text classification model using the sentences in the training dataset, we will use the remaining 872 sentences in the test dataset to evaluate how the model performs against new data it has never seen before.\n",
        "\n",
        "As the default batch size is 32, it will take 28 steps to go through the 872 sentences in the test dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8xmnl6Yy7ARn"
      },
      "outputs": [],
      "source": [
        "loss, acc = model.evaluate(test_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CgCDMe0e6jlT"
      },
      "source": [
        "**Step 5.  Export as a TensorFlow Lite model.**\n",
        "\n",
        "Let's export the text classification that we have trained in the TensorFlow Lite format. We will specify which folder to export the model.\n",
        "By default, the float TFLite model is exported for the average word embedding model architecture."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hm_UULdW7A9T"
      },
      "outputs": [],
      "source": [
        "model.export(export_dir='average_word_vec')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVxaf3x_7OfB"
      },
      "source": [
        "You can download the TensorFlow Lite model file using the left sidebar of Colab. Go into the `average_word_vec` folder as we specified in `export_dir` parameter above, right-click on the `model.tflite` file and choose `Download` to download it to your local computer.\n",
        "\n",
        "This model can be integrated into an Android or an iOS app using the [NLClassifier API](https://www.tensorflow.org/lite/inference_with_metadata/task_library/nl_classifier) of the [TensorFlow Lite Task Library](https://www.tensorflow.org/lite/inference_with_metadata/task_library/overview).\n",
        "\n",
        "See the [TFLite Text Classification sample app](https://github.com/tensorflow/examples/blob/master/lite/examples/text_classification/android/lib_task_api/src/main/java/org/tensorflow/lite/examples/textclassification/client/TextClassificationClient.java#L54) for more details on how the model is used in a working app.\n",
        "\n",
        "*Note 1: Android Studio Model Binding does not support text classification yet so please use the TensorFlow Lite Task Library.*\n",
        "\n",
        "*Note 2: There is a `model.json` file in the same folder with the TFLite model. It contains the JSON representation of the [metadata](https://www.tensorflow.org/lite/models/convert/metadata) bundled inside the TensorFlow Lite model. Model metadata helps the TFLite Task Library know what the model does and how to pre-process/post-process data for the model. You don't need to download the `model.json` file as it is only for informational purpose and its content is already inside the TFLite file.*\n",
        "\n",
        "*Note 3: If you train a text classification model using MobileBERT or BERT-Base architecture, you will need to use [BertNLClassifier API](https://www.tensorflow.org/lite/inference_with_metadata/task_library/bert_nl_classifier) instead to integrate the trained model into a mobile app.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l65ctmtW7_FF"
      },
      "source": [
        "The following sections walk through the example step by step to show more details."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJ_B8fMDOhMR"
      },
      "source": [
        "## Choose a model architecture for Text Classifier\n",
        "\n",
        "Each `model_spec` object represents a specific model for the text classifier. TensorFlow Lite Model Maker currently supports [MobileBERT](https://arxiv.org/pdf/2004.02984.pdf), averaging word embeddings and [BERT-Base](https://arxiv.org/pdf/1810.04805.pdf) models.\n",
        "\n",
        "지원 모델 | model_spec의 이름 | 모델 설명 | 모델 크기\n",
        "--- | --- | --- | ---\n",
        "Averaging Word Embedding | 'average_word_vec' | Averaging text word embeddings with RELU activation. | &lt;1MB\n",
        "MobileBERT | 'mobilebert_classifier' | 4.3x smaller and 5.5x faster than BERT-Base while achieving competitive results, suitable for on-device applications. | 25MB w/ quantization <br> 100MB w/o quantization\n",
        "<a>BERT 기반</a> | 'bert_classifier' | Standard BERT model that is widely used in NLP tasks. | 300MB\n",
        "\n",
        "In the quick start, we have used the average word embedding model. Let's switch to [MobileBERT](https://arxiv.org/pdf/2004.02984.pdf) to train a model with higher accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vEAWuZQ1PFiX"
      },
      "outputs": [],
      "source": [
        "mb_spec = model_spec.get('mobilebert_classifier')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygEncJxtl-nQ"
      },
      "source": [
        "## Load training data\n",
        "\n",
        "You can upload your own dataset to work through this tutorial. Upload your dataset by using the left sidebar in Colab.\n",
        "\n",
        "\n",
        "<img src=\"https://storage.googleapis.com/download.tensorflow.org/models/tflite/screenshots/model_maker_text_classification.png\" alt=\"Upload File\" width=\"800\" hspace=\"100\">\n",
        "\n",
        "데이터세트를 클라우드에 업로드하지 않으려면, [가이드](https://github.com/tensorflow/examples/tree/master/tensorflow_examples/lite/model_maker)에 따라 로컬에서 라이브러리를 실행할 수도 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWAusqz-WD5i"
      },
      "source": [
        "To keep it simple, we will reuse the SST-2 dataset downloaded earlier. Let's use the `DataLoader.from_csv` method to load the data.\n",
        "\n",
        "Please be noted that as we have changed the model architecture, we will need to reload the training and test dataset to apply the new preprocessing logic."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I_fOlZsklmlL"
      },
      "outputs": [],
      "source": [
        "train_data = DataLoader.from_csv(\n",
        "      filename='train.csv',\n",
        "      text_column='sentence',\n",
        "      label_column='label',\n",
        "      model_spec=mb_spec,\n",
        "      is_training=True)\n",
        "test_data = DataLoader.from_csv(\n",
        "      filename='dev.csv',\n",
        "      text_column='sentence',\n",
        "      label_column='label',\n",
        "      model_spec=mb_spec,\n",
        "      is_training=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlHvVvv2hw4H"
      },
      "source": [
        "Model Maker 라이브러리는 데이터를 로드하는 `from_folder()` 메서드도 지원합니다. 같은 클래스의 텍스트 데이터가 같은 하위 디렉토리에 있고 하위 폴더 이름이 클래스 이름이라고 가정합니다. 각 텍스트 파일에는 하나의 영화 리뷰 샘플이 포함되어 있습니다. `class_labels` 매개변수는 하위 폴더를 지정하는 데 사용됩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWuoensX4vDA"
      },
      "source": [
        "## Train a TensorFlow Model\n",
        "\n",
        "Train a text classification model using the training data.\n",
        "\n",
        "*Note: As MobileBERT is a complex model, each training epoch will takes about 10 minutes on a Colab GPU. Please make sure that you are using a GPU runtime.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TvYSUuJY3QxR"
      },
      "outputs": [],
      "source": [
        "model = text_classifier.create(train_data, model_spec=mb_spec, epochs=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JKI-pNc8idH"
      },
      "source": [
        "자세한 모델 구조를 조사합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gd7Hs8TF8n3H"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LP5FPk_tOxoZ"
      },
      "source": [
        "## 모델 평가하기\n",
        "\n",
        "Evaluate the model that we have just trained using the test data and measure the loss and accuracy value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A8c2ZQ0J3Riy"
      },
      "outputs": [],
      "source": [
        "loss, acc = model.evaluate(test_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esBGwHE2QxE8"
      },
      "source": [
        "## Export as a TensorFlow Lite model\n",
        "\n",
        "Convert the trained model to TensorFlow Lite model format with [metadata](https://www.tensorflow.org/lite/models/convert/metadata) so that you can later use in an on-device ML application. The label file and the vocab file are embedded in metadata. The default TFLite filename is `model.tflite`.\n",
        "\n",
        "많은 기기 내 ML 애플리케이션에서 모델 크기는 중요한 요소입니다. 따라서 모델을 더 작게 만들고 잠재적으로 더 빠르게 실행하려면 양자화를 적용하는 것이 좋습니다. 기본 훈련 후 양자화 기술은 BERT 및 MobileBERT 모델에 대한 동적 범위 양자화입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Im6wA9lK3TQB"
      },
      "outputs": [],
      "source": [
        "model.export(export_dir='mobilebert/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w12kvDdHJIGH"
      },
      "source": [
        "The TensorFlow Lite model file can be integrated in a mobile app using the [BertNLClassifier API](https://www.tensorflow.org/lite/inference_with_metadata/task_library/bert_nl_classifier) in [TensorFlow Lite Task Library](https://www.tensorflow.org/lite/inference_with_metadata/task_library/overview). Please note that this is **different** from the `NLClassifier` API used to integrate the text classification trained with the average word vector model architecture."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVy0ormoMZwL"
      },
      "source": [
        "The export formats can be one or a list of the following:\n",
        "\n",
        "- `ExportFormat.TFLITE`\n",
        "- `ExportFormat.LABEL`\n",
        "- `ExportFormat.VOCAB`\n",
        "- `ExportFormat.SAVED_MODEL`\n",
        "\n",
        "By default, it exports only the TensorFlow Lite model file containing the model metadata. You can also choose to export other files related to the model for better examination. For instance, exporting only the label file and vocab file as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nbK7nzK_Mfx4"
      },
      "outputs": [],
      "source": [
        "model.export(export_dir='mobilebert/', export_format=[ExportFormat.LABEL, ExportFormat.VOCAB])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZKYthlVrTos"
      },
      "source": [
        "You can evaluate the TFLite model with `evaluate_tflite` method to measure its accuracy. Converting the trained TensorFlow model to TFLite format and apply quantization can affect its accuracy so it is recommended to evaluate the TFLite model accuracy before deployment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ochbq95ZrVFX"
      },
      "outputs": [],
      "source": [
        "accuracy = model.evaluate_tflite('mobilebert/model.tflite', test_data)\n",
        "print('TFLite model accuracy: ', accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EoWiA_zX8rxE"
      },
      "source": [
        "## 고급 사용법\n",
        "\n",
        "The `create` function is the driver function that the Model Maker library uses to create models. The `model_spec` parameter defines the model specification. The `AverageWordVecSpec` and `BertClassifierSpec` classes are currently supported. The `create` function comprises of the following steps:\n",
        "\n",
        "1. `model_spec`에 따라 텍스트 분류자의 모델을 만듭니다.\n",
        "2. 분류자 모델을 훈련합니다 기본 epoch 및 기본 배치 크기는 `model_spec` 객체에서 `default_training_epochs` 및 `default_batch_size` 변수로 설정합니다.\n",
        "\n",
        "이 섹션에서는 모델 조정 및 하이퍼 매개변수 훈련과 같은 고급 사용법 주제를 다룹니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8VxPiOLy4Gv"
      },
      "source": [
        "### Customize the MobileBERT model hyperparameters\n",
        "\n",
        "The model parameters you can adjust are:\n",
        "\n",
        "- `seq_len`: 모델에 공급할 시퀀스의 길이입니다.\n",
        "- `initializer_range`: 모든 가중치 행렬을 초기화하기 위한 truncated_normal_initializer의 표준 편차입니다.\n",
        "- `trainable`: 사전 훈련된 레이어가 훈련 가능한지 여부를 지정하는 boolean입니다.\n",
        "\n",
        "The training pipeline parameters you can adjust are:\n",
        "\n",
        "- `model_dir`: 모델 체크포인트 파일의 위치입니다. 설정하지 않으면 임시 디렉토리가 사용됩니다.\n",
        "- `dropout_rate`: 드롭아웃 비율입니다.\n",
        "- `learning_rate`: Adam 옵티마이저의 초기 학습률입니다.\n",
        "- `tpu`: 연결할 TPU 주소입니다.\n",
        "\n",
        "For instance, you can set the `seq_len=256` (default is 128). This allows the model to classify longer text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4tr9BLcjy4Sh"
      },
      "outputs": [],
      "source": [
        "new_model_spec = model_spec.get('mobilebert_classifier')\n",
        "new_model_spec.seq_len = 256"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwtiksguDfhl"
      },
      "source": [
        "### Customize the average word embedding model hyperparameters\n",
        "\n",
        "You can adjust the model infrastructure like the `wordvec_dim` and the `seq_len` variables in the `AverageWordVecSpec` class.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cAOd5_bzH9AQ"
      },
      "source": [
        "예를 들어, `wordvec_dim`의 더 큰 값을 사용하여 모델을 훈련할 수 있습니다. 모델을 수정하는 경우 새 `model_spec`을 구성해야 합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e9WBN0UTQoMN"
      },
      "outputs": [],
      "source": [
        "new_model_spec = AverageWordVecSpec(wordvec_dim=32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LSTdghTP0Cv"
      },
      "source": [
        "전처리된 데이터를 가져옵니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DVZurFBORG3J"
      },
      "outputs": [],
      "source": [
        "new_train_data = DataLoader.from_csv(\n",
        "      filename='train.csv',\n",
        "      text_column='sentence',\n",
        "      label_column='label',\n",
        "      model_spec=new_model_spec,\n",
        "      is_training=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tD7QVVHeRZoM"
      },
      "source": [
        "새 모델을 훈련합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PzpV246_JGEu"
      },
      "outputs": [],
      "source": [
        "model = text_classifier.create(new_train_data, model_spec=new_model_spec)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvQuy7RSDir3"
      },
      "source": [
        "### 훈련 하이퍼 매개변수 조정하기\n",
        "\n",
        "모델 정확성에 영향을 미치는 `epochs` 및 `batch_size`와 같은 훈련 하이퍼 매개변수를 조정할 수도 있습니다. 예를 들어, 다음과 같습니다.\n",
        "\n",
        "- `epochs`: epoch가 많을수록 정확성이 향상될 수 있지만, 과대적합으로 이어질 수 있습니다.\n",
        "- `batch_size`: 하나의 훈련 단계에서 사용할 샘플의 수입니다.\n",
        "\n",
        "예를 들어, 더 많은 epoch에서 훈련할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rnWFaYZBG6NW"
      },
      "outputs": [],
      "source": [
        "model = text_classifier.create(new_train_data, model_spec=new_model_spec, epochs=20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUaKQZBQHBQR"
      },
      "source": [
        "20개의 훈련 epoch에서 새로 재훈련된 모델을 평가합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BMPi1xflHDSY"
      },
      "outputs": [],
      "source": [
        "new_test_data = DataLoader.from_csv(\n",
        "      filename='dev.csv',\n",
        "      text_column='sentence',\n",
        "      label_column='label',\n",
        "      model_spec=new_model_spec,\n",
        "      is_training=False)\n",
        "\n",
        "loss, accuracy = model.evaluate(new_test_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eq6B9lKMfhS6"
      },
      "source": [
        "### 모델 아키텍처 변경하기\n",
        "\n",
        "`model_spec`을 변경하여 모델을 변경할 수 있습니다. 다음은 BERT-Base 모델로 변경하는 방법을 보여줍니다.\n",
        "\n",
        "`model_spec`을 텍스트 분류자에 대한 BERT-Base 모델로 변경합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QfFCWrwyggrT"
      },
      "outputs": [],
      "source": [
        "spec = model_spec.get('bert_classifier')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2d7yycrgu6L"
      },
      "source": [
        "나머지 단계는 같습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgiD_tkyQn7l"
      },
      "source": [
        "### TensorFlow Lite 모델에서 훈련 후 양자화 사용자 정의하기\n",
        "\n",
        "[훈련 후 양자화](https://www.tensorflow.org/lite/performance/post_training_quantization)는 모델 정확도를 약간만 떨어트리면서 모델 크기와 추론 지연 시간을 줄이는 동시에 CPU 및 하드웨어 가속기의 추론 속도도 개선할 수 있는 변환 기술입니다. 따라서 모델을 최적화하는 데 널리 사용됩니다.\n",
        "\n",
        "Model Maker 라이브러리는 모델을 내보낼 때 기본 훈련 후 양자화 기술을 적용합니다. 훈련 후 양자화를 사용자 지정하려는 경우 Model Maker는 [QuantizationConfig](https://www.tensorflow.org/lite/api_docs/python/tflite_model_maker/config/QuantizationConfig)를 사용하여 여러 훈련 후 양자화 옵션도 지원합니다. float16 양자화를 예로 들어보겠습니다. 먼저 양자화 구성을 정의합니다.\n",
        "\n",
        "```python\n",
        "config = QuantizationConfig.for_float16()\n",
        "```\n",
        "\n",
        "그런 다음 이러한 구성을 가진 TensorFlow Lite 모델을 내보냅니다.\n",
        "\n",
        "```python\n",
        "model.export(export_dir='.', tflite_filename='model_fp16.tflite', quantization_config=config)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkJGvMEx6VD-"
      },
      "source": [
        "# 더 읽어보기\n",
        "\n",
        "You can read our [text classification](https://www.tensorflow.org/lite/examples/text_classification/overview) example to learn technical details. For more information, please refer to:\n",
        "\n",
        "- TensorFlow Lite Model Maker [guide](https://www.tensorflow.org/lite/models/modify/model_maker) and [API reference](https://www.tensorflow.org/lite/api_docs/python/tflite_model_maker).\n",
        "- Task Library: [NLClassifier](https://www.tensorflow.org/lite/inference_with_metadata/task_library/nl_classifier) and [BertNLClassifier](https://www.tensorflow.org/lite/inference_with_metadata/task_library/bert_nl_classifier) for deployment.\n",
        "- 엔드 투 엔드 참조 앱: [Android](https://github.com/tensorflow/examples/tree/master/lite/examples/text_classification/android) 및 [iOS](https://github.com/tensorflow/examples/tree/master/lite/examples/text_classification/ios)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "text_classification.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
