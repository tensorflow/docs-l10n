{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KimMZUVqcJ8_"
      },
      "source": [
        "##### Copyright 2021 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "BRQ6HQ8zcV5v"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlWzg1D9_EhW"
      },
      "source": [
        "# 양자화 디버거로 양자화 오류 검사"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLoHL19yb-a0"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td><a target=\"_blank\" href=\"https://www.tensorflow.org/lite/performance/quantization_debugger\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">TensorFlow.org에서 보기</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/ko/lite/performance/quantization_debugger.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Google Colab에서 실행</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/ko/lite/performance/quantization_debugger.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">GitHub에서 소스 보기</a></td>\n",
        "  <td><a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/ko/lite/performance/quantization_debugger.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">노트북 다운로드</a></td>\n",
        "  <td><a href=\"https://tfhub.dev/google/imagenet/mobilenet_v3_small_100_224/classification/5\"><img src=\"https://www.tensorflow.org/images/hub_logo_32px.png\">TF 허브 모델 보기</a></td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWO_yYDGcGWY"
      },
      "source": [
        "전체 정수 양자화는 향상된 모델 크기와 대기 시간을 제공하지만 양자화된 모델이 항상 예상대로 작동하지는 않습니다. 일반적으로 모델 품질(예: 정확도, mAP, WER)이 원래 float 모델보다 약간 낮을 것으로 예상됩니다. 그러나 모델 품질이 예상보다 낮거나 완전히 잘못된 결과를 생성하는 경우도 있을 수 있습니다.\n",
        "\n",
        "이 문제가 발생하면 양자화 오류의 근본 원인을 찾는 것이 까다롭고 어려우며 양자화 오류를 수정하는 일은 훨씬 더 어렵습니다. 이 모델 검사 프로세스를 지원하는 방법으로, **양자화 디버거**를 사용하여 문제가 있는 레이어를 식별할 수 있고, **선택적 양자화**로는 이러한 문제가 있는 레이어를 부동 상태로 두어 양자화의 이점을 줄이면서 모델 정확도를 회복시킬 수 있습니다.\n",
        "\n",
        "참고: 이 API는 실험적이며 개선 과정에서 API에 주요 변경이 있을 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kD29R1I_Mn6"
      },
      "source": [
        "## 양자화 디버거\n",
        "\n",
        "양자화 디버거를 사용하면 기존 모델에서 양자화 품질 메트릭 분석을 수행할 수 있습니다. 양자화 디버거는 디버그 데이터세트로 모델을 실행하고 각 텐서에 대한 양자화 품질 메트릭을 수집하는 프로세스를 자동화할 수 있습니다.\n",
        "\n",
        "참고: 양자화 디버거 및 선택적 양자화는 현재 int8 활성화가 적용된 전체 정수 양자화에만 작동합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "221Qon7G_PmZ"
      },
      "source": [
        "### 전제 조건\n",
        "\n",
        "모델을 양자화하기 위한 파이프라인이 이미 있는 경우, 양자화 디버거를 실행하는 데 필요한 모든 부분을 갖춘 것입니다!\n",
        "\n",
        "- 양자화할 모델\n",
        "- 대표적 데이터세트\n",
        "\n",
        "모델 및 데이터 외에도 내보낸 결과를 분석하려면 데이터 처리 프레임워크(예: pandas, Google Sheets)를 사용해야 합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTEEzJWo_iZ_"
      },
      "source": [
        "### 설정\n",
        "\n",
        "이 섹션에서는 100개 이미지의 라이브러리, MobileNet v3 모델 및 테스트 데이터세트를 준비합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l7epUDUP_6qo"
      },
      "outputs": [],
      "source": [
        "# Quantization debugger is available from TensorFlow 2.7.0\n",
        "!pip uninstall -y tensorflow\n",
        "!pip install tf-nightly\n",
        "!pip install tensorflow_datasets --upgrade  # imagenet_v2 needs latest checksum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LLsgiUZe_hIa"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_hub as hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "veWjO3u32vzz"
      },
      "outputs": [],
      "source": [
        "#@title Boilerplates and helpers\n",
        "MODEL_URI = 'https://tfhub.dev/google/imagenet/mobilenet_v3_small_100_224/classification/5'\n",
        "\n",
        "\n",
        "def process_image(data):\n",
        "  data['image'] = tf.image.resize(data['image'], (224, 224)) / 255.0\n",
        "  return data\n",
        "\n",
        "\n",
        "# Representative dataset\n",
        "def representative_dataset(dataset):\n",
        "\n",
        "  def _data_gen():\n",
        "    for data in dataset.batch(1):\n",
        "      yield [data['image']]\n",
        "\n",
        "  return _data_gen\n",
        "\n",
        "\n",
        "def eval_tflite(tflite_model, dataset):\n",
        "  \"\"\"Evaluates tensorflow lite classification model with the given dataset.\"\"\"\n",
        "  interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
        "  interpreter.allocate_tensors()\n",
        "\n",
        "  input_idx = interpreter.get_input_details()[0]['index']\n",
        "  output_idx = interpreter.get_output_details()[0]['index']\n",
        "\n",
        "  results = []\n",
        "\n",
        "  for data in representative_dataset(dataset)():\n",
        "    interpreter.set_tensor(input_idx, data[0])\n",
        "    interpreter.invoke()\n",
        "    results.append(interpreter.get_tensor(output_idx).flatten())\n",
        "\n",
        "  results = np.array(results)\n",
        "  gt_labels = np.array(list(dataset.map(lambda data: data['label'] + 1)))\n",
        "  accuracy = (\n",
        "      np.sum(np.argsort(results, axis=1)[:, -5:] == gt_labels.reshape(-1, 1)) /\n",
        "      gt_labels.size)\n",
        "  print(f'Top-5 accuracy (quantized): {accuracy * 100:.2f}%')\n",
        "\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Input(shape=(224, 224, 3), batch_size=1),\n",
        "  hub.KerasLayer(MODEL_URI)\n",
        "])\n",
        "model.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics='sparse_top_k_categorical_accuracy')\n",
        "model.build([1, 224, 224, 3])\n",
        "\n",
        "# Prepare dataset with 100 examples\n",
        "ds = tfds.load('imagenet_v2', split='test[:1%]')\n",
        "ds = ds.map(process_image)\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.representative_dataset = representative_dataset(ds)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "quantized_model = converter.convert()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7mX-R-xK4ADB"
      },
      "outputs": [],
      "source": [
        "test_ds = ds.map(lambda data: (data['image'], data['label'] + 1)).batch(16)\n",
        "loss, acc = model.evaluate(test_ds)\n",
        "print(f'Top-5 accuracy (float): {acc * 100:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mnp6yBnJSCoh"
      },
      "outputs": [],
      "source": [
        "eval_tflite(quantized_model, ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tblkk3cxxpuw"
      },
      "source": [
        "원본 모델이 우리의 작은 데이터세트에 대해 훨씬 더 높은 상위 5개 정확도를 갖는 반면 양자화된 모델은 상당한 정확도 손실을 가지고 있음을 알 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBBcfCQw_Wqd"
      },
      "source": [
        "### 1단계. 디버거 준비\n",
        "\n",
        "양자화 디버거를 사용하는 가장 쉬운 방법은 모델을 양자화하는 데 사용 중인 `tf.lite.TFLiteConverter`를 제공하는 것입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NOByihbD_NZZ"
      },
      "outputs": [],
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.representative_dataset = representative_dataset(ds)\n",
        "\n",
        "# my_debug_dataset should have the same format as my_representative_dataset\n",
        "debugger = tf.lite.experimental.QuantizationDebugger(\n",
        "    converter=converter, debug_dataset=representative_dataset(ds))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vR1IIrmQS9W"
      },
      "source": [
        "### 2단계. 디버거 실행 및 결과 가져오기\n",
        "\n",
        "`QuantizationDebugger.run()`을 호출하면 디버거는 동일한 작업 위치에 대해 부동 텐서와 양자화된 텐서 간의 차이를 기록하고 지정된 메트릭으로 이를 처리합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HsUM54g-_E52"
      },
      "outputs": [],
      "source": [
        "debugger.run()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQpX_SBUQXvr"
      },
      "source": [
        "처리된 메트릭은 `QuantizationDebugger.layer_statistics`를 사용하여 액세스하거나 `QuantizationDebugger.layer_statistics_dump()`를 사용하여 CSV 형식의 텍스트 파일에 덤프할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U-AGYUAbQUmx"
      },
      "outputs": [],
      "source": [
        "RESULTS_FILE = '/tmp/debugger_results.csv'\n",
        "with open(RESULTS_FILE, 'w') as f:\n",
        "  debugger.layer_statistics_dump(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LQzEi6VnQaen"
      },
      "outputs": [],
      "source": [
        "!head /tmp/debugger_results.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4np7VqU-Qfke"
      },
      "source": [
        "덤프의 각 행에 대해 연산 이름과 인덱스가 먼저 오고 양자화 매개변수와 오류 메트릭(있는 경우 [사용자 지정 오류 메트릭](#custom-metrics) 포함)이 뒤따릅니다. 결과적인 CSV 파일은 양자화 오류 메트릭이 큰 문제가 있는 레이어를 골라내는 데 사용할 수 있습니다.\n",
        "\n",
        "팬더 또는 기타 데이터 처리 라이브러리를 사용하여 상세한 레이어별 오류 메트릭을 검사할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XUcSqYFGQb-f"
      },
      "outputs": [],
      "source": [
        "layer_stats = pd.read_csv(RESULTS_FILE)\n",
        "layer_stats.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7C_oHxWFOV6M"
      },
      "source": [
        "### 3단계. 데이터 분석\n",
        "\n",
        "결과를 분석하는 방법은 다양합니다. 먼저 디버거의 출력에서 파생된 몇 가지 유용한 메트릭을 추가해 보겠습니다(`scale`은 각 텐서에 대한 양자화 스케일 팩터를 의미함).\n",
        "\n",
        "- 범위(`256 / scale`)\n",
        "- RMSE / 스케일(`sqrt(mean_squared_error) / scale`)\n",
        "\n",
        "`RMSE / scale`은 양자화된 분포가 원래 float 분포와 유사할 때 `1 / sqrt(12)`(~ 0.289)에 가까우며 이는 양호한 양자화된 모델을 나타냅니다. 값이 클수록 레이어가 잘 양자화되지 않을 가능성이 높습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mwviORyJN6e5"
      },
      "outputs": [],
      "source": [
        "layer_stats['range'] = 255.0 * layer_stats['scale']\n",
        "layer_stats['rmse/scale'] = layer_stats.apply(\n",
        "    lambda row: np.sqrt(row['mean_squared_error']) / row['scale'], axis=1)\n",
        "layer_stats[['op_name', 'range', 'rmse/scale']].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oAAv35CdPvc4"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15, 5))\n",
        "ax1 = plt.subplot(121)\n",
        "ax1.bar(np.arange(len(layer_stats)), layer_stats['range'])\n",
        "ax1.set_ylabel('range')\n",
        "ax2 = plt.subplot(122)\n",
        "ax2.bar(np.arange(len(layer_stats)), layer_stats['rmse/scale'])\n",
        "ax2.set_ylabel('rmse/scale')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pqUQvRUWB3Q"
      },
      "source": [
        "범위가 넓은 레이어가 많고 `RMSE/scale` 값이 높은 레이어도 있습니다. 오류 메트릭이 높은 레이어를 가져오겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UqFsUX4_Q-cE"
      },
      "outputs": [],
      "source": [
        "layer_stats[layer_stats['rmse/scale'] > 0.7][[\n",
        "    'op_name', 'range', 'rmse/scale', 'tensor_name'\n",
        "]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHeALFTGWl_e"
      },
      "source": [
        "이러한 레이어를 사용하여 선택적 양자화를 시도하면 해당 레이어를 양자화하지 않았을 때 모델 품질이 향상되는지 확인할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cvdkjsbwYC6e"
      },
      "outputs": [],
      "source": [
        "suspected_layers = list(\n",
        "    layer_stats[layer_stats['rmse/scale'] > 0.7]['tensor_name'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6RQw9JobOTR"
      },
      "source": [
        "이 외에도 처음 몇 개의 레이어에 대한 양자화를 건너뛰는 것도 양자화된 모델의 품질을 개선하는 데 도움이 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ikF2bp6NZcXN"
      },
      "outputs": [],
      "source": [
        "suspected_layers.extend(list(layer_stats[:5]['tensor_name']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1DfT78w6W6Li"
      },
      "source": [
        "## 선택적 양자화"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pubC-01cGEH"
      },
      "source": [
        "선택적 양자화는 일부 노드에 대한 양자화를 건너뛰므로 원래 float 영역에서 계산이 이루어질 수 있습니다. 올바른 레이어를 건너뛰면 지연 시간과 모델 크기가 증가하는 대신 일부 모델 품질의 회복을 기대할 수 있습니다.\n",
        "\n",
        "그러나 정수 전용 가속기(예: Hexagon DSP, EdgeTPU)에서 양자화된 모델을 실행할 계획이라면 선택적 양자화로 인해 모델이 단편화되고 주로 CPU와 해당 가속기 간의 데이터 전송 비용으로 인해 추론 지연 시간이 더 느려집니다. 이를 방지하기 위해 [양자화 인식 훈련](https://www.tensorflow.org/model_optimization/guide/quantization/training)을 실행하여 모델 정확도를 유지하면서 모든 계층을 정수로 유지하는 방법을 고려할 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQFBfR7YW-oh"
      },
      "source": [
        "양자화 디버거의 옵션은 특정 레이어 또는 특정 작업의 모든 인스턴스에 대한 양자화를 건너뛰기 위한 `denylisted_nodes` 및 `denylisted_ops` 옵션을 허용합니다. 이전 단계에서 준비한 `suspected_layers`를 사용하여 양자화 디버거로 선택적으로 양자화된 모델을 얻을 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K5KD0JAEbpsv"
      },
      "outputs": [],
      "source": [
        "debug_options = tf.lite.experimental.QuantizationDebugOptions(\n",
        "    denylisted_nodes=suspected_layers)\n",
        "debugger = tf.lite.experimental.QuantizationDebugger(\n",
        "    converter=converter,\n",
        "    debug_dataset=representative_dataset(ds),\n",
        "    debug_options=debug_options)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pfj9gzv4b7h4"
      },
      "outputs": [],
      "source": [
        "selective_quantized_model = debugger.get_nondebug_quantized_model()\n",
        "eval_tflite(selective_quantized_model, ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1RkfMYSHdtZy"
      },
      "source": [
        "정확도는 원래 float 모델에 비해 여전히 낮지만 111개 레이어 중 ~10개 레이어에 대한 양자화를 건너뛰어 전체 양자화 모델에서 눈에 띄는 개선 효과를 거두었습니다.\n",
        "\n",
        "같은 클래스의 모든 연산을 양자화하지 않는 방법도 시도할 수 있습니다. 예를 들어, 모든 평균 연산에 대한 양자화를 건너뛰려면 `MEAN`을 `denylisted_ops`에 전달할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ruUoP7SgcLpO"
      },
      "outputs": [],
      "source": [
        "debug_options = tf.lite.experimental.QuantizationDebugOptions(\n",
        "    denylisted_ops=['MEAN'])\n",
        "debugger = tf.lite.experimental.QuantizationDebugger(\n",
        "    converter=converter,\n",
        "    debug_dataset=representative_dataset(ds),\n",
        "    debug_options=debug_options)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oY6kb5g_cO4H"
      },
      "outputs": [],
      "source": [
        "selective_quantized_model = debugger.get_nondebug_quantized_model()\n",
        "eval_tflite(selective_quantized_model, ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xa8488TeAyx-"
      },
      "source": [
        "이러한 기술을 통해 양자화된 MobileNet V3 모델 정확도를 향상시킬 수 있습니다. 다음으로, 모델 정확도를 더욱 향상시키는 고급 기술을 살펴보겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZD75cY9PUb2u"
      },
      "source": [
        "## 고급 사용법\n",
        "\n",
        "다음 기능을 사용하여 디버깅 파이프라인을 추가로 사용자 지정할 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVj9yrQoUfGo"
      },
      "source": [
        "### 사용자 정의 메트릭\n",
        "\n",
        "기본적으로, 양자화 디버거는 각 float-quant 차이에 대해 텐서 크기, 표준 편차, 평균 오차, 최대 절대 오차 및 평균 제곱 오차의 5가지 메트릭을 내보냅니다. 더 많은 사용자 지정 메트릭을 옵션으로 전달하여 이러한 메트릭을 추가할 수 있습니다. 각 메트릭에 대해 결과는 단일 float 값이어야 하며 결과 메트릭은 모든 예제의 메트릭 평균이 됩니다.\n",
        "\n",
        "- `layer_debug_metrics`: float의 각 op 출력과 양자화된 op 출력의 차이를 기반으로 메트릭을 계산합니다.\n",
        "- `layer_direct_compare_metrics`: diff만 가져오는 대신 원시 float 및 양자화된 텐서, 그리고 그 양자화 매개변수(스케일, 영점)를 기반으로 메트릭을 계산합니다.\n",
        "- `model_debug_metrics`: **`float_model_(path|content)`가 디버거에 전달될 때만 사용됩니다**. Op 수준 메트릭 외에도 최종 레이어 출력은 원래 float 모델의 참조 출력과 비교됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WqmRQSxoVVwu"
      },
      "outputs": [],
      "source": [
        "debug_options = tf.lite.experimental.QuantizationDebugOptions(\n",
        "    layer_debug_metrics={\n",
        "        'mean_abs_error': (lambda diff: np.mean(np.abs(diff)))\n",
        "    },\n",
        "    layer_direct_compare_metrics={\n",
        "        'correlation':\n",
        "            lambda f, q, s, zp: (np.corrcoef(f.flatten(),\n",
        "                                             (q.flatten() - zp) / s)[0, 1])\n",
        "    },\n",
        "    model_debug_metrics={\n",
        "        'argmax_accuracy': (lambda f, q: np.mean(np.argmax(f) == np.argmax(q)))\n",
        "    })\n",
        "\n",
        "debugger = tf.lite.experimental.QuantizationDebugger(\n",
        "    converter=converter,\n",
        "    debug_dataset=representative_dataset(ds),\n",
        "    debug_options=debug_options)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PVQ4nEicXz2l"
      },
      "outputs": [],
      "source": [
        "debugger.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dfKA90csX9UL"
      },
      "outputs": [],
      "source": [
        "CUSTOM_RESULTS_FILE = '/tmp/debugger_results.csv'\n",
        "with open(CUSTOM_RESULTS_FILE, 'w') as f:\n",
        "  debugger.layer_statistics_dump(f)\n",
        "\n",
        "custom_layer_stats = pd.read_csv(CUSTOM_RESULTS_FILE)\n",
        "custom_layer_stats[['op_name', 'mean_abs_error', 'correlation']].tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qqq30oWsZF5b"
      },
      "source": [
        "`model_debug_metrics`의 결과는 `debugger.model_statistics`에서 별도로 볼 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wrXlmzEHYhQ5"
      },
      "outputs": [],
      "source": [
        "debugger.model_statistics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqJBLIsoUyIg"
      },
      "source": [
        "### (내부) mlir_quantize API를 사용하여 심층 기능에 액세스\n",
        "\n",
        "참고: 다음 섹션의 일부 기능인 `TFLiteConverter._experimental_calibrate_only` 및 `converter.mlir_quantize`는 실험적인 내부 API이며 이전 버전과 호환되지 않는 방식으로 변경될 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VJm66Cz-XpeF"
      },
      "outputs": [],
      "source": [
        "from tensorflow.lite.python import convert"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2krUVzpiUp3u"
      },
      "source": [
        "#### 전체 모델 검증 모드\n",
        "\n",
        "디버그 모델 생성의 기본 동작은 레이어별 검증입니다. 이 모드에서 float 및 quantize 연산 쌍에 대한 입력은 동일한 소스(이전 양자화 연산)에서 가져옵니다. 또 다른 모드는 float 및 quantize 모델이 분리되는 전체 모델 검증입니다. 이 모드는 오류가 모델 후단으로 전파되는 방식을 관찰하는 데 유용합니다. 이를 위해 디버그 모델을 수동으로 생성하는 동안 `enable_whole_model_verify=True`를 `convert.mlir_quantize`로 설정합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5zykINDlVLSg"
      },
      "outputs": [],
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.representative_dataset = representative_dataset(ds)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter._experimental_calibrate_only = True\n",
        "calibrated_model = converter.convert()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eqvXlEiFXfSu"
      },
      "outputs": [],
      "source": [
        "# Note that enable_numeric_verify and enable_whole_model_verify are set.\n",
        "quantized_model = convert.mlir_quantize(\n",
        "    calibrated_model,\n",
        "    enable_numeric_verify=True,\n",
        "    enable_whole_model_verify=True)\n",
        "debugger = tf.lite.experimental.QuantizationDebugger(\n",
        "    quant_debug_model_content=quantized_model,\n",
        "    debug_dataset=representative_dataset(ds))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQ6TFsXQVHMe"
      },
      "source": [
        "#### 이미 보정된 모델에서 선택적 양자화\n",
        "\n",
        "`convert.mlir_quantize`를 직접 호출하여 이미 보정된 모델에서 선택적 양자화된 모델을 가져올 수 있습니다. 이는 모델을 한 번 보정하고 다양한 거부 목록 조합을 실험하려는 경우에 특히 유용합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZCS-Fa9lbdc0"
      },
      "outputs": [],
      "source": [
        "selective_quantized_model = convert.mlir_quantize(\n",
        "    calibrated_model, denylisted_nodes=suspected_layers)\n",
        "eval_tflite(selective_quantized_model, ds)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Eq_8T2oauIED"
      ],
      "name": "quantization_debugger.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
