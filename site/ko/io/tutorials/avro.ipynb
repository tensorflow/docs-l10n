{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tce3stUlHN0L"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow IO Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tuOe1ymfHZPu"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFdPvlXBOdUN"
      },
      "source": [
        "# Avro 데이터세트 API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfBg1C5NB3X0"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>     <a target=\"_blank\" href=\"https://www.tensorflow.org/io/tutorials/avro\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\"> TensorFlow.org에서 보기</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/ko/io/tutorials/avro.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Google Colab에서 실행하기</a>\n",
        "</td>\n",
        "  <td><a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/ko/io/tutorials/avro.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">GitHub에서소스 보기</a></td>\n",
        "      <td><a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/ko/io/tutorials/avro.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">노트북 다운론드하기</a></td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHxb-dlhMIzW"
      },
      "source": [
        "## 개요\n",
        "\n",
        "Avro 데이터세트 API의 목적은 Avro 형식의 데이터를 <a target=\"_blank\" href=\"https://www.tensorflow.org/api_docs/python/tf/data/Dataset\">TensorFlow 데이터세트</a>로 TensorFlow에 기본적으로 로드하는 것입니다. Avro는 프로토콜 버퍼와 유사한 데이터 직렬화 시스템입니다. 영구 데이터를 위한 직렬화 형식과 Hadoop 노드 간의 통신을 위한 와이어 형식을 모두 제공할 수 있는 Apache Hadoop에서 널리 사용됩니다. Avro 데이터는 행 지향의 압축된 바이너리 데이터 형식으로, 별도의 JSON 파일로 저장된 스키마에 의존합니다. Avro 형식 및 스키마 선언의 사양은 <a target=\"_blank\" href=\"https://avro.apache.org/docs/current/spec.html\">공식 매뉴얼</a>을 참조하세요.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUXex9ctTuDB"
      },
      "source": [
        "## 설치 패키지\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upgCc3gXybsA"
      },
      "source": [
        "### 필요한 tensorflow-io 패키지 설치하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uUDYyMZRfkX4"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow-io"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjrZNJQRJP-U"
      },
      "source": [
        "### 패키지 가져오기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m6KXZuTBWgRm"
      },
      "outputs": [],
      "source": [
        "model.fit(x=dataset, epochs=1, steps_per_epoch=1, verbose=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCgO11GTJaTj"
      },
      "source": [
        "### tf 및 tfio 가져오기 검증하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dX74RKfZ_TdF"
      },
      "outputs": [],
      "source": [
        "print(\"tensorflow-io version: {}\".format(tfio.__version__))\n",
        "print(\"tensorflow version: {}\".format(tf.__version__))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0ZKhA6s0Pjp"
      },
      "source": [
        "## 사용법"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CfKVmCvwcL7"
      },
      "source": [
        "### 데이터세트 살펴보기\n",
        "\n",
        "이 튜토리얼의 목적을 위해 샘플 Avro 데이터세트를 다운로드하겠습니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGnbXuVnSo8T"
      },
      "source": [
        "샘플 Avro 파일 다운로드:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tu01THzWcE-J"
      },
      "outputs": [],
      "source": [
        "!curl -OL https://github.com/tensorflow/io/raw/master/docs/tutorials/avro/train.avro\n",
        "!ls -l train.avro"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJzE6lMwhY7l"
      },
      "source": [
        "샘플 Avro 파일의 해당 스키마 파일을 다운로드합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cpxa6yhLhY7l"
      },
      "outputs": [],
      "source": [
        "!curl -OL https://github.com/tensorflow/io/raw/master/docs/tutorials/avro/train.avsc\n",
        "!ls -l train.avsc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9GCyPWNuOm7"
      },
      "source": [
        "위의 예에서 테스트용 Avro 데이터세트는 mnist 데이터세트를 기반으로 생성되었습니다. TFRecord 형식의 원래 mnist 데이터세트는 <a target=\"_blank\" href=\"https://www.tensorflow.org/datasets/api_docs/python/tfds/load\">TF라는 데이터세트</a>에서 생성됩니다. 그러나 mnist 데이터세트는 데모 데이터세트로 사용하기엔 너무 큽니다. 단순화하기 위해 대부분을 잘라내고 처음 몇 개의 레코드만 보관했습니다. 또한 원래 mnist 데이터세트의 `image` 필드에 대해 추가 잘라내기가 수행되고 Avro의 `features` 필드에 매핑되었습니다. 따라서 `dataType` 파일 `train.avro`에는 4개의 레코드가 있으며, 그 각각에는 int 배열인 `features`, int 또는 null인 `label`, enum인 `dataType` 등 세 가지 필드가 있습니다. 디코딩된 `train.avro`를 보려면 다음과 같이 합니다(avro는 압축된 형식이므로 <a target=\"_blank\" href=\"https://github.com/tensorflow/io/raw/master/docs/tutorials/avro/train.avro\">원본 avro 데이터 파일</a>은 사람이 읽을 수 없음).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upgCc3gXybsB"
      },
      "source": [
        "Avro 파일을 읽는 데 필요한 패키지를 설치합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nS3eTBvjt-O4"
      },
      "outputs": [],
      "source": [
        "!pip install avro\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7XR0agdhY7n"
      },
      "source": [
        "사람이 읽을 수 있는 형식으로 Avro 파일을 읽고 인쇄하는 방법:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nS3eTBvjt-O5"
      },
      "outputs": [],
      "source": [
        "dataset = tfio.experimental.columnar.make_avro_record_dataset(file_pattern=['train.avro'],\n",
        "                                                              reader_schema=schema,\n",
        "                                                              features=features,\n",
        "                                                              shuffle=False,\n",
        "                                                              num_parallel_reads=16,\n",
        "                                                              batch_size=3,\n",
        "                                                              drop_final_batch=True,\n",
        "                                                              num_epochs=1)\n",
        "\n",
        "for record in dataset:\n",
        "    print(record)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKgUPm6JhY7n"
      },
      "source": [
        "그리고 `train.avro`가 나타내는 `train.avsc`의 스키마는 JSON 형식 파일입니다. `train.avsc`를 보려면 다음과 같이 합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D-95aom1hY7o"
      },
      "outputs": [],
      "source": [
        "def print_schema(avro_schema_file):\n",
        "    with open(avro_schema_file, 'r') as handle:\n",
        "        parsed = json.load(handle)\n",
        "    print(json.dumps(parsed, indent=4, sort_keys=True))\n",
        "\n",
        "print_schema('train.avsc')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21szKFY1hY7o"
      },
      "source": [
        "### 데이터세트 준비하기\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNeBO9m-hY7o"
      },
      "source": [
        "Avro dataset API를 사용하여 `train.avro`를 TensorFlow 데이터세트로 로드합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v-nbLZHKhY7o"
      },
      "outputs": [],
      "source": [
        "features = {\n",
        "    'features[*]': tfio.experimental.columnar.VarLenFeatureWithRank(dtype=tf.int32),\n",
        "    'label': tf.io.FixedLenFeature(shape=[], dtype=tf.int32, default_value=-100),\n",
        "    'dataType': tf.io.FixedLenFeature(shape=[], dtype=tf.string)\n",
        "}\n",
        "\n",
        "schema = tf.io.gfile.GFile('train.avsc').read()\n",
        "\n",
        "dataset = tfio.experimental.columnar.make_avro_record_dataset(file_pattern=['train.avro'],\n",
        "                                                              reader_schema=schema,\n",
        "                                                              features=features,\n",
        "                                                              shuffle=False,\n",
        "                                                              batch_size=3,\n",
        "                                                              num_epochs=1)\n",
        "\n",
        "for record in dataset:\n",
        "    print(record['features[*]'])\n",
        "    print(record['label'])\n",
        "    print(record['dataType'])\n",
        "    print(\"--------------------\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IF_kYz_o2DH4"
      },
      "source": [
        "위의 예는 `train.avro`를 tensorflow 데이터세트로 변환합니다. 데이터세트의 각 요소는 키가 기능 이름이고 값이 변환된 희소 또는 밀집 텐서인 사전입니다. 예를 들어, `features`, `label`, `dataType` 필드를 각각 VarLenFeature(SparseTensor), FixedLenFeature(DenseTensor) 및 FixedLenFeature(DenseTensor)로 변환합니다. batch_size가 3이므로 `train.avro`의 3개 레코드가 결과 데이터세트에서 하나의 요소로 강제 변환됩니다. 레이블이 null인 `train.avro`의 첫 번째 레코드에 대해 avro reader는 이를 지정된 기본값(-100)으로 바꿉니다. 이 예에서 `train.avro`에는 총 4개의 레코드가 있습니다. 배치 크기가 3이므로 결과 데이터세트에는 3개의 요소가 포함되며 마지막 배치 크기는 1입니다. 그러나 사용자는 `drop_final_batch`를 활성화하여 크기가 배치 크기보다 작은 경우 마지막 배치를 삭제할 수도 있습니다. 예를 들면 다음과 같습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bc9vDHyghY7p"
      },
      "outputs": [],
      "source": [
        "dataset = tfio.experimental.columnar.make_avro_record_dataset(file_pattern=['train.avro'],\n",
        "                                                              reader_schema=schema,\n",
        "                                                              features=features,\n",
        "                                                              shuffle=False,\n",
        "                                                              batch_size=3,\n",
        "                                                              drop_final_batch=True,\n",
        "                                                              num_epochs=1)\n",
        "\n",
        "for record in dataset:\n",
        "    print(record)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x45KolnDhY7p"
      },
      "source": [
        "또한 num_parallel_reads를 늘려 avro 구문 분석/읽기 병렬 처리를 높임으로써 Avro 데이터를 원활하게 처리할 수 있습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z2x-gPj_hY7p"
      },
      "outputs": [],
      "source": [
        "dataset = tfio.experimental.columnar.make_avro_record_dataset(file_pattern=['train.avro'],\n",
        "                                                              reader_schema=schema,\n",
        "                                                              features=features,\n",
        "                                                              shuffle=False,\n",
        "                                                              num_parallel_reads=16,\n",
        "                                                              batch_size=3,\n",
        "                                                              drop_final_batch=True,\n",
        "                                                              num_epochs=1)\n",
        "\n",
        "for record in dataset:\n",
        "    print(record)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6V-nwDJGhY7p"
      },
      "source": [
        "`make_avro_record_dataset`의 자세한 사용법은 <a target=\"_blank\" href=\"https://www.tensorflow.org/io/api_docs/python/tfio/experimental/columnar/make_avro_record_dataset\">API 문서</a>를 참조하세요.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIOijGlAhY7p"
      },
      "source": [
        "### Avro 데이터세트로 tf.keras 모델 훈련하기\n",
        "\n",
        "이제 mnist 데이터세트를 기반으로 하는 Avro 데이터세트를 사용하여 tf.keras 모델 훈련의 엔드 투 엔드 예제를 살펴보겠습니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7K85D53hY7q"
      },
      "source": [
        "Avro dataset API를 사용하여 `train.avro`를 TensorFlow 데이터세트로 로드합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VFoeLwIOhY7q"
      },
      "outputs": [],
      "source": [
        "features = {\n",
        "    'features[*]': tfio.experimental.columnar.VarLenFeatureWithRank(dtype=tf.int32),\n",
        "    'label': tf.io.FixedLenFeature(shape=[], dtype=tf.int32, default_value=-100),\n",
        "}\n",
        "\n",
        "\n",
        "schema = tf.io.gfile.GFile('train.avsc').read()\n",
        "\n",
        "dataset = tfio.experimental.columnar.make_avro_record_dataset(file_pattern=['train.avro'],\n",
        "                                                              reader_schema=schema,\n",
        "                                                              features=features,\n",
        "                                                              shuffle=False,\n",
        "                                                              batch_size=1,\n",
        "                                                              num_epochs=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hR2FnIIMhY7q"
      },
      "source": [
        "간단한 keras 모델 정의:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hGV5rHfJhY7q"
      },
      "outputs": [],
      "source": [
        "def build_and_compile_cnn_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.compile(optimizer='sgd', loss='mse')\n",
        "    return model\n",
        "\n",
        "model = build_and_compile_cnn_model()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tuv9n6HshY7q"
      },
      "source": [
        "### Avro 데이터세트를 사용하여 keras 모델 훈련하기\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lb44cUuWhY7r"
      },
      "outputs": [],
      "source": [
        "def extract_label(feature):\n",
        "  label = feature.pop('label')\n",
        "  return tf.sparse.to_dense(feature['features[*]']), label\n",
        "\n",
        "model.fit(x=dataset.map(extract_label), epochs=1, steps_per_epoch=1, verbose=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7K6qAv5rhY7r"
      },
      "source": [
        "Avro 데이터세트는 레코드, 맵, 배열, 분기 및 열거의 레코드를 포함하여 모든 avro 데이터를 구문 분석하고 TensorFlow 텐서로 강제 변환할 수 있습니다. 구문 분석 정보는 키가 데이터 값을 구문 분석하는 방법을 인코딩하는 맵으로 데이터를 TensorFlow 텐서로 강제 변환하는 방법을 인코딩하는 맵으로 전달됩니다. 이것으로 기본 유형(예: bool, int, long, float, double, string)뿐만 아니라 텐서 유형(예: 희소 또는 밀집)도 결정됩니다. TensorFlow의 파서 유형 목록(표 1 참조)과 기본 유형의 강제 변환(표 2)이 제공됩니다.\n",
        "\n",
        "표 1 지원되는 TensorFlow 파서 유형:\n",
        "\n",
        "TensorFlow 파서 유형 | TensorFlow 텐서 | 설명\n",
        "--- | --- | ---\n",
        "tf.FixedLenFeature([], tf.int32) | 밀집 텐서 | 고정 길이 특성을 구문 분석합니다. 즉, 모든 행은 동일한 일정 요소 수를 갖습니다. 단 하나의 요소 또는 각 행에 대해 항상 동일한 수의 요소를 갖는 배열을 예로 들 수 있습니다.\n",
        "tf.SparseFeature(index_key=['key_1st_index', 'key_2nd_index'], value_key='key_value', dtype=tf.int64, size=[20, 50]) | 희소 텐서 | 각 행에 인덱스 및 값의 가변 길이 목록이 있는 희소 특성을 구문 분석합니다. 'index_key'는 인덱스를 식별합니다. 'value_key'는 값을 식별합니다. 'dtype'은 데이터 유형입니다. 'size'는 각 인덱스 항목에 대해 예상되는 최대 인덱스 값입니다.\n",
        "tfio.experimental.columnar.VarLenFeatureWithRank([],tf.int64) | 희소 텐서 | 가변 길이 특성을 구문 분석합니다. 이는 각 데이터 행이 가변적 수의 요소를 가질 수 있음을 의미합니다. 예를 들어, 첫 번째 행에는 5개의 요소가 있고 두 번째 행에는 7개의 요소가 있습니다.\n",
        "\n",
        "표 2 Avro 유형에서 TensorFlow 유형으로 지원되는 변환:\n",
        "\n",
        "Avro 기본 유형 | TensorFlow 기본 유형\n",
        "--- | ---\n",
        "boolean: 바이너리 값 | tf.bool\n",
        "바이트: 부호 없는 8비트 바이트 시퀀스 | tf.string\n",
        "double: 배정밀도 64비트 IEEE 부동 소수점 숫자 | tf.float64\n",
        "enum: 열거 유형 | 기호 이름을 사용하는 tf.string\n",
        "float: 단정밀도 32비트 IEEE 부동 소수점 숫자 | tf.float32\n",
        "int: 부호 있는 32비트 정수 | tf.int32\n",
        "long: 부호 있는 64비트 정수 | tf.int64\n",
        "null: 값 없음 | 기본값 사용\n",
        "string: 유니코드 문자 시퀀스 | tf.string\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PFQPuy5hY7r"
      },
      "source": [
        "Avro dataset API의 전체 예제는 <a target=\"_blank\" href=\"https://github.com/tensorflow/io/blob/master/tests/test_parse_avro.py#L437\">테스트</a> 내에서 제공됩니다.\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "Tce3stUlHN0L"
      ],
      "name": "avro.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
