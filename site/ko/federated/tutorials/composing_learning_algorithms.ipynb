{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkdnLiKk71g-"
      },
      "source": [
        "##### Copyright 2022 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "0asMuNro71hA"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXslvcRocA-0"
      },
      "source": [
        "# 학습 알고리즘 작성하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XBJJIqwcXKd"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td><a target=\"_blank\" href=\"https://www.tensorflow.org/federated/tutorials/composing_learning_algorithms\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">TensorFlow.org에서 보기</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/federated/blob/v0.36.0/docs/tutorials/composing_learning_algorithms.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Google Colab에서 실행</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://github.com/tensorflow/federated/blob/v0.36.0/docs/tutorials/composing_learning_algorithms.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">GitHub에서 소스 보기</a></td>\n",
        "  <td><a href=\"https://storage.googleapis.com/tensorflow_docs/federated/docs/tutorials/composing_learning_algorithms.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">노트북 다운로드</a></td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnUwFbCAKB2r"
      },
      "source": [
        "## 시작하기 전에\n",
        "\n",
        "시작하기 전에 다음을 실행하여 환경이 올바르게 설정되었는지 확인하세요. 인사말이 표시되지 않으면 [설치](../install.md) 가이드에서 지침을 참조하세요. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZrGitA_KnRO0"
      },
      "outputs": [],
      "source": [
        "#@test {\"skip\": true}\n",
        "!pip install --quiet --upgrade tensorflow-federated\n",
        "!pip install --quiet --upgrade nest-asyncio\n",
        "\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HGTM6tWOLo8M"
      },
      "outputs": [],
      "source": [
        "from typing import Callable\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_federated as tff"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yr3ztf28fa1F"
      },
      "source": [
        "**참고**: 이 Colab은 <code>tensorflow_federated</code> pip 패키지의 <a>최신 릴리즈 버전</a>에서 동작하는 것으로 확인되었지만 Tensorflow Federated 프로젝트는 아직 시험판 개발 중이며 `main`에서 동작하지 않을 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFlTaHe0jV2S"
      },
      "source": [
        "# 학습 알고리즘 작성"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zQlyijofSzI"
      },
      "source": [
        "[고유한 페더레이션 학습 알고리즘 구축 튜토리얼](https://github.com/tensorflow/federated/blob/v0.36.0/docs/tutorials/building_your_own_federated_learning_algorithm.ipynb)에서는 TFF의 페더레이션 코어를 사용하여 페더레이션 평균화(FedAvg) 알고리즘 버전을 직접 구현했습니다.\n",
        "\n",
        "이 튜토리얼에서는 TFF API의 페더레이션 학습 구성 요소를 사용하여 모든 것을 처음부터 다시 구현할 필요 없이 모듈 방식으로 페더레이션 학습 알고리즘을 구축합니다.\n",
        "\n",
        "이 튜토리얼의 목적을 위해 로컬 학습을 통해 그래디언트 클리핑을 사용하는 FedAvg의 변형을 구현합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHwcFnLAjqcG"
      },
      "source": [
        "## 학습 알고리즘 빌딩 블록\n",
        "\n",
        "고차원적 수준에서 많은 학습 알고리즘은 **빌딩 블록**이라고 하는 4개의 개별 구성 요소로 분리될 수 있으며, 다음과 같습니다.\n",
        "\n",
        "1. 배포자(즉, 서버-클라이언트 통신)\n",
        "2. 클라이언트 작업(예: 로컬 클라이언트 계산)\n",
        "3. 집계자(예: 클라이언트-서버 통신)\n",
        "4. 종결자(즉, 집계된 클라이언트 출력을 사용하는 서버 계산)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwhOtjlvjboB"
      },
      "source": [
        "[고유한 페더레이션 학습 알고리즘 구축 튜토리얼](https://github.com/tensorflow/federated/blob/v0.36.0/docs/tutorials/building_your_own_federated_learning_algorithm.ipynb)이 이러한 모든 구성 요소를 처음부터 구현했지만 그럴 필요가 없는 경우가 종종 있습니다. 대신 유사한 알고리즘의 빌딩 블록을 재사용할 수 있습니다.\n",
        "\n",
        "이 경우 그래디언트 클리핑으로 FedAvg를 구현하려면 **클라이언트 작업** 빌딩 블록만 수정하면 됩니다. 나머지 블록은 \"바닐라\" FedAvg에 사용된 것과 동일할 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMnd0RvGlGjK"
      },
      "source": [
        "# 클라이언트 작업 구현하기\n",
        "\n",
        "먼저, 그래디언트 클리핑으로 로컬 모델 훈련을 수행하는 TF 로직을 작성해 보겠습니다. 단순하게 하기 위해 그래디언트는 최대 1의 표준을 가집니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lqZ-c4MphTU"
      },
      "source": [
        "## TF 로직"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pIw7QQCqltdV"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def client_update(model: tff.learning.Model,\n",
        "                  dataset: tf.data.Dataset,\n",
        "                  server_weights: tff.learning.ModelWeights,\n",
        "                  client_optimizer: tf.keras.optimizers.Optimizer):\n",
        "  \"\"\"Performs training (using the server model weights) on the client's dataset.\"\"\"\n",
        "  # Initialize the client model with the current server weights.\n",
        "  client_weights = tff.learning.ModelWeights.from_model(model)\n",
        "  tf.nest.map_structure(lambda x, y: x.assign(y),\n",
        "                        client_weights, server_weights)\n",
        "\n",
        "  # Use the client_optimizer to update the local model.\n",
        "  # Keep track of the number of examples as well.\n",
        "  num_examples = 0.0\n",
        "  for batch in dataset:\n",
        "    with tf.GradientTape() as tape:\n",
        "      # Compute a forward pass on the batch of data\n",
        "      outputs = model.forward_pass(batch)\n",
        "      num_examples += tf.cast(outputs.num_examples, tf.float32)\n",
        "\n",
        "    # Compute the corresponding gradient\n",
        "    grads = tape.gradient(outputs.loss, client_weights.trainable)\n",
        "\n",
        "    # Compute the gradient norm and clip\n",
        "    gradient_norm = tf.linalg.global_norm(grads)\n",
        "    if gradient_norm > 1:\n",
        "      grads = tf.nest.map_structure(lambda x: x/gradient_norm, grads)\n",
        "\n",
        "    grads_and_vars = zip(grads, client_weights.trainable)\n",
        "\n",
        "    # Apply the gradient using a client optimizer.\n",
        "    client_optimizer.apply_gradients(grads_and_vars)\n",
        "\n",
        "  # Compute the difference between the server weights and the client weights\n",
        "  client_update = tf.nest.map_structure(tf.subtract,\n",
        "                                        client_weights.trainable,\n",
        "                                        server_weights.trainable)\n",
        "\n",
        "  return tff.learning.templates.ClientResult(\n",
        "      update=client_update, update_weight=num_examples)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fe_emK8LpQe0"
      },
      "source": [
        "위의 코드에는 몇 가지 주목할 부분들이 있습니다. 첫째, 클라이언트 업데이트의 *가중치*를 구성할 것이므로 본 예제의 수를 추적합니다(클라이언트 전체의 평균을 계산할 때).\n",
        "\n",
        "둘째, [`tff.learning.templates.ClientResult`](https://www.tensorflow.org/federated/api_docs/python/tff/learning/templates/ClientResult)를 사용하여 출력을 패키징합니다. 이 반환 유형은 `tff.learning`에서 클라이언트 작업의 빌딩 블록을 표준화하는 데 사용됩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5aKjB1Vpiv3"
      },
      "source": [
        "## ClientWorkProcess 만들기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6IvXUJAzm8ab"
      },
      "source": [
        "위의 TF 로직은 클리핑을 사용하여 로컬 훈련을 수행하지만 필요한 빌딩 블록을 생성하려면 여전히 TFF 코드로 래핑해야 합니다.\n",
        "\n",
        "구체적으로, 4개의 빌딩 블록이 [`tff.templates.MeasuredProcess`](https://www.tensorflow.org/federated/api_docs/python/tff/templates/MeasuredProcess)로 표시됩니다. 이것은 4개의 블록 모두가 계산을 인스턴스화하고 실행하는 데 사용되는 `initialize` 및 `next` 함수를 모두 가지고 있음을 의미합니다.\n",
        "\n",
        "이를 통해 각 빌딩 블록은 작업을 수행하는 데 필요한 자체 **상태**(서버에 저장됨)를 추적할 수 있습니다. 이 튜토리얼에서는 사용되지 않지만, 얼마나 많은 반복이 이루어졌는지 추적하거나 옵티마이저 상태를 추적하는 등에 이를 사용할 수 있습니다.\n",
        "\n",
        "클라이언트 작업 TF 로직은 일반적으로 [`tff.learning.templates.ClientWorkProcess`](https://www.tensorflow.org/federated/api_docs/python/tff/learning/templates/ClientWorkProcess)로 래핑되어야 하며, 이는 클라이언트의 로컬 훈련에 들어오고 나가는 예상 유형을 코드화합니다. 이는 아래와 같이 모델과 옵티마이저에 의해 매개변수화될 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X-I-jPsZmmMy"
      },
      "outputs": [],
      "source": [
        "def build_gradient_clipping_client_work(\n",
        "    model_fn: Callable[[], tff.learning.Model],\n",
        "    optimizer_fn: Callable[[], tf.keras.optimizers.Optimizer],\n",
        ") -> tff.learning.templates.ClientWorkProcess:\n",
        "  \"\"\"Creates a client work process that uses gradient clipping.\"\"\"\n",
        "\n",
        "  with tf.Graph().as_default():\n",
        "    # Wrap model construction in a graph to avoid polluting the global context\n",
        "    # with variables created for this model.\n",
        "    model = model_fn()\n",
        "  data_type = tff.SequenceType(model.input_spec)\n",
        "  model_weights_type = tff.learning.framework.weights_type_from_model(model)\n",
        "\n",
        "  @tff.federated_computation\n",
        "  def initialize_fn():\n",
        "    return tff.federated_value((), tff.SERVER)\n",
        "\n",
        "  @tff.tf_computation(model_weights_type, data_type)\n",
        "  def client_update_computation(model_weights, dataset):\n",
        "    model = model_fn()\n",
        "    optimizer = optimizer_fn()\n",
        "    return client_update(model, dataset, model_weights, optimizer)\n",
        "\n",
        "  @tff.federated_computation(\n",
        "      initialize_fn.type_signature.result,\n",
        "      tff.type_at_clients(model_weights_type),\n",
        "      tff.type_at_clients(data_type)\n",
        "  )\n",
        "  def next_fn(state, model_weights, client_dataset):\n",
        "    client_result = tff.federated_map(\n",
        "        client_update_computation, (model_weights, client_dataset))\n",
        "    # Return empty measurements, though a more complete algorithm might\n",
        "    # measure something here.\n",
        "    measurements = tff.federated_value((), tff.SERVER)\n",
        "    return tff.templates.MeasuredProcessOutput(state, client_result,\n",
        "                                               measurements)\n",
        "  return tff.learning.templates.ClientWorkProcess(\n",
        "      initialize_fn, next_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMUX0d0Sx1Gq"
      },
      "source": [
        "# 학습 알고리즘 작성\n",
        "\n",
        "위의 클라이언트 작업을 본격적인 알고리즘에 넣어 보겠습니다. 먼저 데이터와 모델을 설정하겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQ_N9XbULo8P"
      },
      "source": [
        "## 입력 데이터 준비하기\n",
        "\n",
        "TFF에 포함된 EMNIST 데이터세트를 로드하고 전처리합니다. 자세한 내용은 [이미지 분류](federated_learning_for_image_classification.ipynb) 튜토리얼을 참조하세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-WdnFluLLo8P"
      },
      "outputs": [],
      "source": [
        "emnist_train, emnist_test = tff.simulation.datasets.emnist.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kq8893GogB8E"
      },
      "source": [
        "데이터세트를 모델에 제공하기 위해 데이터가 병합되고 `(flattened_image_vector, label)` 형식의 튜플로 변환됩니다.\n",
        "\n",
        "소수의 클라이언트를 선택하고 위의 전처리를 해당 데이터세트에 적용해 보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Blrh8zJgLo8R"
      },
      "outputs": [],
      "source": [
        "NUM_CLIENTS = 10\n",
        "BATCH_SIZE = 20\n",
        "\n",
        "def preprocess(dataset):\n",
        "\n",
        "  def batch_format_fn(element):\n",
        "    \"\"\"Flatten a batch of EMNIST data and return a (features, label) tuple.\"\"\"\n",
        "    return (tf.reshape(element['pixels'], [-1, 784]), \n",
        "            tf.reshape(element['label'], [-1, 1]))\n",
        "\n",
        "  return dataset.batch(BATCH_SIZE).map(batch_format_fn)\n",
        "\n",
        "client_ids = sorted(emnist_train.client_ids)[:NUM_CLIENTS]\n",
        "federated_train_data = [preprocess(emnist_train.create_tf_dataset_for_client(x))\n",
        "  for x in client_ids\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNO_Y9j_Lo8X"
      },
      "source": [
        "## 모델 준비하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJ0I89ixz8yV"
      },
      "source": [
        "여기서는 [이미지 분류](federated_learning_for_image_classification.ipynb) 튜토리얼에서와 동일한 모델이 사용됩니다. 이 모델(`tf.keras`를 통해 구현됨)에는 하나의 숨겨진 레이어, 그 다음 소프트맥스 레이어가 있습니다. TFF에서 이 모델을 사용하기 위해 Keras 모델은 [`tff.learning.Model`](https://www.tensorflow.org/federated/api_docs/python/tff/learning/Model)로 래핑됩니다. 이를 통해 TFF 내에서 모델의 [정방향 전달](https://www.tensorflow.org/federated/api_docs/python/tff/learning/Model#forward_pass)을 수행하고 [모델 출력을 추출](https://www.tensorflow.org/federated/api_docs/python/tff/learning/Model#report_local_unfinalized_metrics)할 수 있습니다. 자세한 내용은 [이미지 분류](federated_learning_for_image_classification.ipynb) 튜토리얼을 참조하세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yfld4oFNLo8Y"
      },
      "outputs": [],
      "source": [
        "def create_keras_model():\n",
        "  initializer = tf.keras.initializers.GlorotNormal(seed=0)\n",
        "  return tf.keras.models.Sequential([\n",
        "      tf.keras.layers.Input(shape=(784,)),\n",
        "      tf.keras.layers.Dense(10, kernel_initializer=initializer),\n",
        "      tf.keras.layers.Softmax(),\n",
        "  ])\n",
        "\n",
        "def model_fn():\n",
        "  keras_model = create_keras_model()\n",
        "  return tff.learning.from_keras_model(\n",
        "      keras_model,\n",
        "      input_spec=federated_train_data[0].element_spec,\n",
        "      loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7BPxQoGH0bEl"
      },
      "source": [
        "## 옵티마이저 준비하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRw9zwdh0dnL"
      },
      "source": [
        "[`tff.learning.algorithms.build_weighted_fed_avg`](https://www.tensorflow.org/federated/api_docs/python/tff/learning/algorithms/build_weighted_fed_avg)에서와 마찬가지로 여기에는 클라이언트 옵티마이저와 서버 옵티마이저라는 두 가지 옵티마이저가 있습니다. 단순화를 위해 옵티마이저는 학습률이 다른 SGD가 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kOO1ObqJ0cmX"
      },
      "outputs": [],
      "source": [
        "client_optimizer_fn = lambda: tf.keras.optimizers.SGD(learning_rate=0.01)\n",
        "server_optimizer_fn = lambda: tf.keras.optimizers.SGD(learning_rate=1.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R64okB7k06sc"
      },
      "source": [
        "## 빌딩 블록 정의하기\n",
        "\n",
        "이제 클라이언트 작업 빌딩 블록, 데이터, 모델 및 옵티마이저가 설정되었으므로 배포자, 집계자 및 종결자를 위한 빌딩 블록을 만드는 일만 남았습니다. 이를 수행하기 위해 TFF에서 사용할 수 있고 FedAvg에서 사용하는 일부 기본값을 차용할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iwXOTPeIx2nx"
      },
      "outputs": [],
      "source": [
        "@tff.tf_computation()\n",
        "def initial_model_weights_fn():\n",
        "  return tff.learning.ModelWeights.from_model(model_fn())\n",
        "\n",
        "model_weights_type = initial_model_weights_fn.type_signature.result\n",
        "\n",
        "distributor = tff.learning.templates.build_broadcast_process(model_weights_type)\n",
        "client_work = build_gradient_clipping_client_work(model_fn, client_optimizer_fn)\n",
        "\n",
        "# TFF aggregators use a factory pattern, which create an aggregator\n",
        "# based on the output type of the client work. This also uses a float (the number\n",
        "# of examples) to govern the weight in the average being computed.)\n",
        "aggregator_factory = tff.aggregators.MeanFactory()\n",
        "aggregator = aggregator_factory.create(model_weights_type.trainable,\n",
        "                                       tff.TensorType(tf.float32))\n",
        "finalizer = tff.learning.templates.build_apply_optimizer_finalizer(\n",
        "    server_optimizer_fn, model_weights_type)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEYYNHqI1Jif"
      },
      "source": [
        "## 빌딩 블록 구성하기\n",
        "\n",
        "마지막으로, 빌딩 블록을 결합하기 위해 TFF의 내장 **작성기**를 사용할 수 있습니다. 이것은 위의 4가지 빌딩 블록을 사용하고 그 유형을 함께 연결하는 비교적 간단한 작성기입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z_86iNeM0IBm"
      },
      "outputs": [],
      "source": [
        "fed_avg_with_clipping = tff.learning.templates.compose_learning_process(\n",
        "    initial_model_weights_fn,\n",
        "    distributor,\n",
        "    client_work,\n",
        "    aggregator,\n",
        "    finalizer\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcK69pCG16-E"
      },
      "source": [
        "# 알고리즘 실행하기\n",
        "\n",
        "이제 알고리즘이 완료되었으므로 실행해 보겠습니다. 먼저, 알고리즘을 **초기화**합니다. 이 알고리즘의 **상태**에는 *전역 모델 가중치*에 대한 구성 요소와 함께 각 빌딩 블록에 대한 구성 요소가 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jg22oFx11YKK"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "()"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "state = fed_avg_with_clipping.initialize()\n",
        "\n",
        "state.client_work"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmCiEdoq2doJ"
      },
      "source": [
        "예상대로 클라이언트 작업은 비어 있는 상태입니다(위의 클라이언트 작업 코드를 상기할 것!). 그러나 다른 빌딩 블록은 비어 있지 않은 상태를 가질 수 있습니다. 예를 들어 종결자는 얼마나 많은 반복이 이루어졌는지 추적합니다. `next`는 아직 실행되지 않았으므로 상태는 `0`입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kEuB-8Z71-bd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0]"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "state.finalizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2N9XObhZ2zSQ"
      },
      "source": [
        "이제 훈련 라운드를 실행합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tKhPuBgW1-3c"
      },
      "outputs": [],
      "source": [
        "learning_process_output = fed_avg_with_clipping.next(state, federated_train_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7L0jKEe29bk"
      },
      "source": [
        "이 출력(`tff.learning.templates.LearningProcessOutput`)에는 `.state` 및 `.metrics` 출력이 모두 있습니다. 둘 다 살펴보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AMsBmmQz28AZ"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[1]"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "learning_process_output.state.finalizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwcfhAbP3VkH"
      },
      "source": [
        "분명히 종결자 상태는 `.next` 한 라운드가 실행됨에 따라 1씩 증가했습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0K91G_Ob3E05"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "OrderedDict([('distributor', ()),\n",
              "             ('client_work', ()),\n",
              "             ('aggregator',\n",
              "              OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "             ('finalizer', ())])"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "learning_process_output.metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sDyO9uz3Jaz"
      },
      "source": [
        "메트릭은 비어 있지만 더 복잡하고 실용적인 알고리즘의 경우 일반적으로 유용한 정보로 가득 차게 됩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPpxe7Ie3gLJ"
      },
      "source": [
        "# 결론"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8uEZw-T3iBB"
      },
      "source": [
        "위의 빌딩 블록/작성기 프레임워크를 사용하면 모든 작업을 처음부터 다시 수행할 필요 없이 완전히 새로운 학습 알고리즘을 만들 수 있습니다. 그러나 이것은 시작일 뿐입니다. 이 프레임워크를 사용하면 알고리즘을 FedAvg의 간단한 변형으로 훨씬 쉽게 표현할 수 있습니다. 더 많은 알고리즘을 보려면 [`tff.learning.algorithms`](https://www.tensorflow.org/federated/api_docs/python/tff/learning/algorithms)를 참조하세요. 여기에는 [FedProx](https://www.tensorflow.org/federated/api_docs/python/tff/learning/algorithms/build_weighted_fed_prox) 및 [클라이언트 학습률 스케줄링이 있는 FedAvg](https://www.tensorflow.org/federated/api_docs/python/tff/learning/algorithms/build_weighted_fed_avg_with_optimizer_schedule)과 같은 알고리즘이 포함되어 있습니다. 이러한 API는 [페더레이션 k-평균 클러스터링](https://www.tensorflow.org/federated/api_docs/python/tff/learning/algorithms/build_fed_kmeans)과 같은 완전히 새로운 알고리즘의 구현을 지원할 수도 있습니다."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "composing_learning_algorithms.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
