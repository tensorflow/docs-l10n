{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tce3stUlHN0L"
      },
      "source": [
        "##### Copyright 2018 The TensorFlow Authors.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tuOe1ymfHZPu"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfBg1C5NB3X0"
      },
      "source": [
        "# TPU 사용하기\n",
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>     <a target=\"_blank\" href=\"https://www.tensorflow.org/guide/tpu\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">TensorFlow.org에서 보기</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/ko/guide/tpu.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Google Colab에서 실행하기</a>\n",
        "</td>\n",
        "  <td><a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/ko/guide/tpu.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">GitHub에서 소스 보기</a></td>\n",
        "  <td><a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/ko/guide/tpu.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\"> 노트북 다운로드하기</a></td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ys81cOhXOWUP"
      },
      "source": [
        "본 가이드는 전용 고속 네트워크 인터페이스로 연결된 TPU 장치 모음인 [TPU(Tensor Processing Unit)](https://cloud.google.com/tpu/) 및 TPU Pod에 대한 기본 훈련을 `tf.keras`와 사용자 정의 훈련 루프를 사용하여 수행하는 방법을 보여줍니다.\n",
        "\n",
        "TPU는 머신러닝 워크로드를 가속화하는 데 사용하기 위해 Google이 특정 용도에 맞도록 제작한 주문형 반도체인 ASIC(Application-Specific Integrated Circuit)입니다. [Google Colab](https://colab.research.google.com/), [TPU 리서치 클라우드](https://sites.research.google/trc/), [클라우드 TPU](https://cloud.google.com/tpu)를 통해 사용할 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ek5Hop74NVKm"
      },
      "source": [
        "## 설정"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebf7f8489bb7"
      },
      "source": [
        "이 Colab 노트북을 실행하기 전에 노트북 설정을 확인하여 하드웨어 가속기가 TPU인지 확인하세요. **런타임** &gt; **런타임 유형 변경** &gt; **하드웨어 가속기** &gt; **TPU**로 들어가면 됩니다.\n",
        "\n",
        "TensorFlow 데이터세트 등 몇 가지 필요한 라이브러리를 가져옵니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cw0WRaChRxTL"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import os\n",
        "import tensorflow_datasets as tfds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDWaRxSpwBN1"
      },
      "source": [
        "## TPU 초기화\n",
        "\n",
        "TPU는 일반적으로 사용자의 Python 프로그램을 실행하는 로컬 프로세스와 다른 Cloud TPU 작업자입니다. 따라서 원격 클러스터에 연결하고 TPU를 초기화하려면 일부 초기화 작업을 수행해야 합니다. <code>tf.distribute.cluster_resolver.TPUClusterResolver</code>에 대한 `tpu` 인수는 Colab 전용 특수 주소입니다. Google Compute Engine(GCE)에서 코드를 실행하는 경우, Cloud TPU의 이름을 대신 전달해야 합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCqWMqvtwOLs"
      },
      "source": [
        "참고: TPU 초기화 코드는 프로그램의 시작 부분에 있어야 합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dKPqF8d1wJCV"
      },
      "outputs": [],
      "source": [
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "# This is the TPU initialization code that has to be at the beginning.\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "print(\"All devices: \", tf.config.list_logical_devices('TPU'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mv7kehTZ1Lq_"
      },
      "source": [
        "## 수동 기기 배치\n",
        "\n",
        "TPU가 초기화된 후 수동 기기 배치를 사용하여 단일 TPU 기기에 계산을 배치할 수 있습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XRZ4kMoxBNND"
      },
      "outputs": [],
      "source": [
        "a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
        "b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
        "\n",
        "with tf.device('/TPU:0'):\n",
        "  c = tf.matmul(a, b)\n",
        "\n",
        "print(\"c device: \", c.device)\n",
        "print(c)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_NJm-kgFO0cC"
      },
      "source": [
        "## 배포 전략\n",
        "\n",
        "일반적으로 데이터 병렬 방식으로 여러 TPU에서 모델을 실행합니다. 모델을 여러 TPU(및 여러 GPU 또는 여러 머신)에 배포하기 위해 TensorFlow는 `tf.distribute.Strategy` API를 제공합니다. 배포 전략은 교체할 수 있으며 모델은 지정한 (TPU) 장치에서 실행됩니다. 자세한 내용은 [TensorFlow를 사용하여 분산 훈련하기](./distributed_training.ipynb) 가이드를 참고하세요."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcDPMZs-9uLJ"
      },
      "source": [
        "`tf.distribute.TPUStrategy` 옵션을 사용하면 동기식 분산 훈련을 구현하게 됩니다. TPU는 `TPUStrategy`에서 사용하는 효율적인 전체 축소 및 기타 집합적 연산의 자체적 구현을 여러 TPU 코어에 제공합니다.\n",
        "\n",
        "이를 시연하기 위해 `tf.distribute.TPUStrategy` 객체를 생성합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7SO23K8oRpjI"
      },
      "outputs": [],
      "source": [
        "strategy = tf.distribute.TPUStrategy(resolver)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlaAmswWPsU6"
      },
      "source": [
        "모든 TPU 코어에서 실행할 수 있도록 계산을 복제하려면 이를 `strategy.run` API에 전달할 수 있습니다. 다음은 모든 코어가 동일한 입력 `(a, b)`를 받고 각 코어에 대해 독립적으로 행렬 곱셈을 수행하는 예입니다. 출력은 모든 복제본의 값이 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-90CL5uFPTOa"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def matmul_fn(x, y):\n",
        "  z = tf.matmul(x, y)\n",
        "  return z\n",
        "\n",
        "z = strategy.run(matmul_fn, args=(a, b))\n",
        "print(z)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxgYl6kGHJLc"
      },
      "source": [
        "## TPU 기반 분류\n",
        "\n",
        "기본 개념을 다뤘으니 좀 더 구체적인 예를 살펴보겠습니다. 이 섹션에서는 배포 전략(`tf.distribute.TPUStrategy`)을 사용하여 Cloud TPU에서 Keras 모델을 훈련하는 방법을 보여줍니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKRALGgt_kCo"
      },
      "source": [
        "### Keras 모델 정의하기\n",
        "\n",
        "MNIST 데이터세트에서 이미지 분류를 위한 [`Sequential` Keras 모델](https://www.tensorflow.org/guide/keras/sequential_model)을 정의하는 것으로 시작합니다. CPU나 GPU에서 훈련할 때 사용하는 것과 다르지 않습니다. Keras 모델 생성은 `Strategy.scope` 안에서 이루어져야 각 TPU 기기에서 변수를 생성할 수 있습니다. 코드의 다른 부분은 `Strategy` 범위 내에 있지 않아도 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DiBiN-Z_R7P7"
      },
      "outputs": [],
      "source": [
        "def create_model():\n",
        "  regularizer = tf.keras.regularizers.L2(1e-5)\n",
        "  return tf.keras.Sequential(\n",
        "      [tf.keras.layers.Conv2D(256, 3, input_shape=(28, 28, 1),\n",
        "                              activation='relu',\n",
        "                              kernel_regularizer=regularizer),\n",
        "       tf.keras.layers.Conv2D(256, 3,\n",
        "                              activation='relu',\n",
        "                              kernel_regularizer=regularizer),\n",
        "       tf.keras.layers.Flatten(),\n",
        "       tf.keras.layers.Dense(256,\n",
        "                             activation='relu',\n",
        "                             kernel_regularizer=regularizer),\n",
        "       tf.keras.layers.Dense(128,\n",
        "                             activation='relu',\n",
        "                             kernel_regularizer=regularizer),\n",
        "       tf.keras.layers.Dense(10,\n",
        "                             kernel_regularizer=regularizer)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-2qaXgfyONQ"
      },
      "source": [
        "이 모델은 각 레이어의 가중치에 L2 정규화 항을 배치하기에 아래의 사용자 정의 훈련 루프가 `Model.losses`에서 이러한 L2 정규화 항을 선택하는 방법을 보여줄 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYOYjYTg_31l"
      },
      "source": [
        "### 데이터세트 로드하기\n",
        "\n",
        "Cloud TPU를 사용할 때는 `tf.data.Dataset` API를 효율적으로 사용하는 것이 중요합니다. [입력 파이프라인 성능 가이드](./data_performance.ipynb)에서 데이터세트 성능에 대해 자세히 알아볼 수 있습니다.\n",
        "\n",
        "[TPU 노드](https://cloud.google.com/tpu/docs/managing-tpus-tpu-vm)를 사용하는 경우 TensorFlow `Dataset`로 읽은 모든 데이터 파일을 [Google Cloud Storage(GCS) 버킷](https://cloud.google.com/tpu/docs/storage-buckets)에 저장해야 합니다. [TPU VM](https://cloud.google.com/tpu/docs/users-guide-tpu-vm)을 사용하는 경우 원하는 위치에 데이터를 저장할 수 있습니다. TPU 노드 및 TPU VM에 대한 자세한 정보는 [TPU 시스템 아키텍처](https://cloud.google.com/tpu/docs/system-architecture-tpu-vm) 문서를 참조합니다.\n",
        "\n",
        "대부분의 사용 사례에서 데이터를 `TFRecord` 형식으로 변환하고 `tf.data.TFRecordDataset`을 사용하여 읽는 것이 좋습니다. 이 작업을 수행하는 방법에 대한 자세한 내용 [TFRecord 및 tf.Example 튜토리얼](../tutorials/load_data/tfrecord.ipynb)을 확인하세요. 이것은 엄격한 요구 사항은 아니며 `tf.data.FixedLengthRecordDataset` 또는 `tf.data.TextLineDataset`와 같은 다른 데이터세트 판독기를 사용할 수 있습니다.\n",
        "\n",
        "`tf.data.Dataset.cache`를 사용하여 전체 작은 데이터세트를 메모리에 로드할 수 있습니다.\n",
        "\n",
        "사용된 데이터 형식에 관계없이 100MB 정도의 큰 파일을 사용하는 것이 좋습니다. 파일을 여는 오버헤드가 상당히 높기 때문에 네트워크 설정에서 특히 중요합니다.\n",
        "\n",
        "아래 코드와 같이 Tensorflow 데이터세트 `tfds.load` 모듈을 사용하여 MNIST 학습 및 테스트 데이터의 복사본을 가져와야 합니다. `try_gcs`는 공개 GCS 버킷에서 사용 가능한 사본을 사용하도록 지정됩니다. 이를 지정하지 않으면 TPU가 다운로드한 데이터에 액세스할 수 없습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "noAd416KSCo7"
      },
      "outputs": [],
      "source": [
        "def get_dataset(batch_size, is_training=True):\n",
        "  split = 'train' if is_training else 'test'\n",
        "  dataset, info = tfds.load(name='mnist', split=split, with_info=True,\n",
        "                            as_supervised=True, try_gcs=True)\n",
        "\n",
        "  # Normalize the input data.\n",
        "  def scale(image, label):\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    image /= 255.0\n",
        "    return image, label\n",
        "\n",
        "  dataset = dataset.map(scale)\n",
        "\n",
        "  # Only shuffle and repeat the dataset in training. The advantage of having an\n",
        "  # infinite dataset for training is to avoid the potential last partial batch\n",
        "  # in each epoch, so that you don't need to think about scaling the gradients\n",
        "  # based on the actual batch size.\n",
        "  if is_training:\n",
        "    dataset = dataset.shuffle(10000)\n",
        "    dataset = dataset.repeat()\n",
        "\n",
        "  dataset = dataset.batch(batch_size)\n",
        "\n",
        "  return dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgUC6A-zCMEr"
      },
      "source": [
        "### Keras 고급 API를 사용하여 모델 훈련하기\n",
        "\n",
        "Keras `Model.fit`과 `Model.compile` API로 모델을 훈련할 수 있습니다. 이 단계에서는 TPU 관련 사항이 없습니다. `TPUStrategy` 대신 여러 GPU와 `MirroredStrategy`를 사용할 때와 마찬가지로 코드를 작성합니다. [Keras를 사용한 분산 훈련](../tutorials/distribute/keras.ipynb) 튜토리얼에서 자세히 알아볼 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ubmDchPqSIx0"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "  model = create_model()\n",
        "  model.compile(optimizer='adam',\n",
        "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                metrics=['sparse_categorical_accuracy'])\n",
        "\n",
        "batch_size = 200\n",
        "steps_per_epoch = 60000 // batch_size\n",
        "validation_steps = 10000 // batch_size\n",
        "\n",
        "train_dataset = get_dataset(batch_size, is_training=True)\n",
        "test_dataset = get_dataset(batch_size, is_training=False)\n",
        "\n",
        "model.fit(train_dataset,\n",
        "          epochs=5,\n",
        "          steps_per_epoch=steps_per_epoch,\n",
        "          validation_data=test_dataset,\n",
        "          validation_steps=validation_steps)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hSGBIYtUugJ"
      },
      "source": [
        "Python 오버헤드를 줄이고 TPU의 성능을 극대화하기 위해 `steps_per_execution` 인수를 Keras `Model.compile`로 전달합니다. 이 예제에서는 처리량이 약 50% 증가합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M6e3aVVLUorL"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "  model = create_model()\n",
        "  model.compile(optimizer='adam',\n",
        "                # Anything between 2 and `steps_per_epoch` could help here.\n",
        "                steps_per_execution = 50,\n",
        "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                metrics=['sparse_categorical_accuracy'])\n",
        "\n",
        "model.fit(train_dataset,\n",
        "          epochs=5,\n",
        "          steps_per_epoch=steps_per_epoch,\n",
        "          validation_data=test_dataset,\n",
        "          validation_steps=validation_steps)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rRALBZNCO4A"
      },
      "source": [
        "### 사용자 지정 훈련 루프를 사용하여 모델 훈련하기\n",
        "\n",
        "`tf.function`과 `tf.distribute` API를 직접 사용하여 모델을 생성하고 훈련할 수도 있습니다. `Strategy.experimental_distribute_datasets_from_function` API를 사용하여 데이터세트 함수가 지정된 `tf.data.Dataset`를 배포할 수 있습니다. 아래 예제에서 `Dataset`에 전달된 배치 크기는 전역 배치 크기가 아닌 복제본당 배치 크기입니다. 자세히 알아보려면 [`tf.distribute.Strategy`를 사용한 사용자 정의 훈련](../tutorials/distribute/custom_training.ipynb) 튜토리얼을 확인합니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxdgXPAL6iFE"
      },
      "source": [
        "먼저 모델, 데이터세트 및 tf.functions를 생성합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9aHhqwao2Fxi"
      },
      "outputs": [],
      "source": [
        "# Create the model, optimizer and metrics inside the `tf.distribute.Strategy`\n",
        "# scope, so that the variables can be mirrored on each device.\n",
        "with strategy.scope():\n",
        "  model = create_model()\n",
        "  optimizer = tf.keras.optimizers.Adam()\n",
        "  training_loss = tf.keras.metrics.Mean('training_loss', dtype=tf.float32)\n",
        "  training_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
        "      'training_accuracy', dtype=tf.float32)\n",
        "\n",
        "# Calculate per replica batch size, and distribute the `tf.data.Dataset`s\n",
        "# on each TPU worker.\n",
        "per_replica_batch_size = batch_size // strategy.num_replicas_in_sync\n",
        "\n",
        "train_dataset = strategy.experimental_distribute_datasets_from_function(\n",
        "    lambda _: get_dataset(per_replica_batch_size, is_training=True))\n",
        "\n",
        "@tf.function\n",
        "def train_step(iterator):\n",
        "  \"\"\"The step function for one training step.\"\"\"\n",
        "\n",
        "  def step_fn(inputs):\n",
        "    \"\"\"The computation to run on each TPU device.\"\"\"\n",
        "    images, labels = inputs\n",
        "    with tf.GradientTape() as tape:\n",
        "      logits = model(images, training=True)\n",
        "      per_example_loss = tf.keras.losses.sparse_categorical_crossentropy(\n",
        "          labels, logits, from_logits=True)\n",
        "      loss = tf.nn.compute_average_loss(per_example_loss)\n",
        "      model_losses = model.losses\n",
        "      if model_losses:\n",
        "        loss += tf.nn.scale_regularization_loss(tf.add_n(model_losses))\n",
        "\n",
        "    grads = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(list(zip(grads, model.trainable_variables)))\n",
        "    training_loss.update_state(loss * strategy.num_replicas_in_sync)\n",
        "    training_accuracy.update_state(labels, logits)\n",
        "\n",
        "  strategy.run(step_fn, args=(next(iterator),))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ibi7Z97V6xsQ"
      },
      "source": [
        "그런 다음 훈련 루프를 실행합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1du5cXWt6Vtw"
      },
      "outputs": [],
      "source": [
        "steps_per_eval = 10000 // batch_size\n",
        "\n",
        "train_iterator = iter(train_dataset)\n",
        "for epoch in range(5):\n",
        "  print('Epoch: {}/5'.format(epoch))\n",
        "\n",
        "  for step in range(steps_per_epoch):\n",
        "    train_step(train_iterator)\n",
        "  print('Current step: {}, training loss: {}, training accuracy: {}%'.format(\n",
        "      optimizer.iterations.numpy(),\n",
        "      round(float(training_loss.result()), 4),\n",
        "      round(float(training_accuracy.result()) * 100, 2)))\n",
        "  training_loss.reset_states()\n",
        "  training_accuracy.reset_states()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnZJUM3qIjKu"
      },
      "source": [
        "### `tf.function` 내부의 여러 단계로 성능 개선하기\n",
        "\n",
        "`tf.function` 내에서 여러 단계를 실행하여 성능을 개선할 수 있습니다. 이는 `tf.function` 내부의 `tf.range`로 `Strategy.run` 호출을 래핑하여 달성할 수 있으며 AutoGraph는 이를  TPU 작업자의 `tf.while_loop`로 전환합니다. <a data-md-type=\"raw_html\" href=\"./function.ipynb\">`tf.function`으로 성능 향상</a> 가이드에서 `tf.function`에 대해 자세히 알아볼 수 있습니다.\n",
        "\n",
        "개선된 성능에도 불구하고 `tf.function` 내에서 단일 단계를 실행하는 것과 비교하여 이 방법에는 손해되는 부분이 생깁니다. `tf.function`에서 여러 단계를 실행하는 것은 유연성이 떨어집니다. 즉, 단계 내에서 어떤 부분을 강제 실행하거나 임의 Python 코드를 실행할 수 없습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2grYvXLzJYkP"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def train_multiple_steps(iterator, steps):\n",
        "  \"\"\"The step function for one training step.\"\"\"\n",
        "\n",
        "  def step_fn(inputs):\n",
        "    \"\"\"The computation to run on each TPU device.\"\"\"\n",
        "    images, labels = inputs\n",
        "    with tf.GradientTape() as tape:\n",
        "      logits = model(images, training=True)\n",
        "      per_example_loss = tf.keras.losses.sparse_categorical_crossentropy(\n",
        "          labels, logits, from_logits=True)\n",
        "      loss = tf.nn.compute_average_loss(per_example_loss)\n",
        "      model_losses = model.losses\n",
        "      if model_losses:\n",
        "        loss += tf.nn.scale_regularization_loss(tf.add_n(model_losses))\n",
        "    grads = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(list(zip(grads, model.trainable_variables)))\n",
        "    training_loss.update_state(loss * strategy.num_replicas_in_sync)\n",
        "    training_accuracy.update_state(labels, logits)\n",
        "\n",
        "  for _ in tf.range(steps):\n",
        "    strategy.run(step_fn, args=(next(iterator),))\n",
        "\n",
        "# Convert `steps_per_epoch` to `tf.Tensor` so the `tf.function` won't get\n",
        "# retraced if the value changes.\n",
        "train_multiple_steps(train_iterator, tf.convert_to_tensor(steps_per_epoch))\n",
        "\n",
        "print('Current step: {}, training loss: {}, training accuracy: {}%'.format(\n",
        "      optimizer.iterations.numpy(),\n",
        "      round(float(training_loss.result()), 4),\n",
        "      round(float(training_accuracy.result()) * 100, 2)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBKVhMvWjibf"
      },
      "source": [
        "## 다음 단계\n",
        "\n",
        "Cloud TPU 및 사용 방법에 대해 자세히 알아보려면 다음 안내를 따릅니다.\n",
        "\n",
        "- [Google Cloud TPU](https://cloud.google.com/tpu): Google Cloud TPU 홈페이지\n",
        "- [Google Cloud TPU 문서](https://cloud.google.com/tpu/docs/): 다음을 포함하는 Google Cloud TPU 문서:\n",
        "    - [Cloud TPU 소개](https://cloud.google.com/tpu/docs/intro-to-tpu): Cloud TPU 작업에 대한 개요\n",
        "    - [Cloud TPU 빠른 시작](https://cloud.google.com/tpu/docs/quick-starts): TensorFlow 및 기타 기본 머신러닝 프레임워크를 사용하는 Cloud TPU VM 작업에 대한 빠른 시작 소개\n",
        "- [Google Cloud TPU Colab 노트북](https://cloud.google.com/tpu/docs/colabs): 엔드 투 엔드 훈련 예시\n",
        "- [Google Cloud TPU 성능 가이드](https://cloud.google.com/tpu/docs/performance-guide): 애플리케이션에 적합하게 Cloud TPU 구성 매개변수를 조정하여 Cloud TPU 성능 강화\n",
        "- [TensorFlow를 사용한 분산 훈련](./distributed_training.ipynb): 모범 사례를 보여주는 예제와 함께 `tf.distribute.TPUStrategy`를 포함한 배포 전략의 사용 방법\n",
        "- TPU 임베딩: TensorFlow에는 `tf.tpu.experimental.embedding`을 통해 TPU에서 임베딩을 훈련하기 위한 특별 지원이 포함되어 있습니다. 또한 [TensorFlow Recommenders](https://www.tensorflow.org/recommenders)에는 `tfrs.layers.embedding.TPUEmbedding`이 있습니다. 임베딩은 기능 사이의 복잡한 유사성과 관계를 캡처하여 효율적이고 밀도 있는 표현을 제공합니다. TensorFlow의 TPU 특화적 임베딩 지원을 통해 단일 TPU 장치의 메모리보다 큰 임베딩을 훈련하고 TPU에서 밀도가 낮은 비정형 입력을 사용할 수 있습니다.\n",
        "- [TPU 리서치 클라우드(TRC)](https://sites.research.google/trc/about/): TRC를 통해 연구원은 1,000개 이상의 클라우드 TPU 장치 클러스터에 대한 액세스를 신청할 수 있습니다.\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [],
      "name": "tpu.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
