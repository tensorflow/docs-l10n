{
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "9xMkm699JzK8"
      ],
      "name": "custom_callback.ipynb",
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "version": "0.3.2"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "597OjogAI3fy"
      },
      "source": [
        "##### Copyright 2018 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "5bSCD8SyJC2g",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "E_ceEiH7g0MY"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/guide/keras/custom_callback\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />TensorFlow.org에서 보기.org</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/ko/guide/keras/custom_callback.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />구글 코랩(Colab)에서 실행하기</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/ko/guide/keras/custom_callback.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />깃허브(GitHub)에서 소스 보기</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/guide/keras/custom_callback.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />노트북에 다운받기</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1OykC-6lI4gv"
      },
      "source": [
        "Note: 이 문서는 텐서플로 커뮤니티에서 번역했습니다. 커뮤니티 번역 활동의 특성상 정확한 번역과 최신 내용을 반영하기 위해 노력함에도 불구하고 [공식 영문 문서](https://github.com/tensorflow/docs/blob/master/site/en/guide/distribute_strategy.ipynb)의 내용과 일치하지 않을 수 있습니다. 이 번역에 개선할 부분이 있다면 [tensorflow/docs](https://github.com/tensorflow/docs) 깃허브 저장소로 풀 리퀘스트를 보내주시기 바랍니다. 문서 번역이나 리뷰에 참여하려면 [docs-ko@tensorflow.org](https://groups.google.com/a/tensorflow.org/forum/#!forum/docs-ko)로 메일을 보내주시기 바랍니다.",
        "\n",
        "# 케라스 사용자 정의 콜백 (callback)\n",
        "사용자 정의 콜백은 케라스 모델을 읽고 변경하는 것을 포함하여 훈련, 평가 또는 추론 중 케라스 모델의 동작을 사용자가 정의할 수 있도록 해주는 강력한 도구 입니다. 예시로는 훈련 과정과 결과를 텐서보드를 통해 표현하고 시각화 하는 `tf.keras.callbacks.TensorBoard`, 또는 모델을 훈련 중 자동으로 저장할 수 있도록 해주는 `tf.keras.callbacks.ModelCheckpoint` 등이 있습니다. 이 안내서는 케라스 콜백이 무엇인지, 언제 불리는지, 무엇을 할 수 있는지, 그리고 어떻게 콜백을 만들 수 있는지에 대해 소개합니다. 안내서의 뒷 부분에는 콜백 애플리케이션을 어떻게 생성하는지 보여주는 데모가 포함되어 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "d5zZ8rZD69VW"
      },
      "source": [
        "## 설치"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "7BazS4qD6-2n"
      },
      "outputs": [],
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version은 코랩에서만 쓸 수 있습니다.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0c_TYhQOUe1j"
      },
      "source": [
        "## 케라스 callbacks 도입\n",
        "케라스에서 'Callback'은 특정한 기능성을 제공하기 위해 하위로 분류되는 피톤 class로 트레이닝의 다양한 단계 (batch/ epoch 시작및 종료를 포함합니다), 시험 및 예측에서 호출되는 일련의 방법을 포함합니다. Callback은 훈련 중에 모델의 내부 상태와 통계를 보기 위해 유용합니다. '테너플로우.케라스.모델.적합()', '텐서플로우.케랏.모델.평가()' 그리고 '텐서플로우.케라스.모델.예상()' 방법으로 callbacks 리스트(callbacks라는 키워드로)를 전달할 수 있습니다. Callback의 방법은 교육/평가/추론의 다른 단계에서 호출됩니다.\n",
        "\n",
        "시작하려면, 텐서플로우를 불러오고 간단한 순차적 케라스 모델을 정의해봅니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Ct0VCSI2dt3a"
      },
      "outputs": [],
      "source": [
        "# callbacks를 추가하기 위한 케라스 정의\n",
        "def get_model():\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(tf.keras.layers.Dense(1, activation = 'linear', input_dim = 784))\n",
        "  model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=0.1), loss='mean_squared_error', metrics=['mae'])\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ySzdG1IqNgah"
      },
      "source": [
        "다음, 케라스 데이터 세트 API에서 훈련 및 평가를 위한 MNIST 데이터셋을 불러옵니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "fwo9LMKGNPWr"
      },
      "outputs": [],
      "source": [
        "# MNIST 데이터를 불러오고 전처리합니다.\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "x_train = x_train.reshape(60000, 784).astype('float32') / 255\n",
        "x_test = x_test.reshape(10000, 784).astype('float32') / 255"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kHVK7kceNqH2"
      },
      "source": [
        "이제 모든 데이터의 batch의 시작과 끝을 추적할 수 있는 간단한 커스텀 callback을 정의하면 됩니다. 그 동안 이것은 현재 batch의 인덱스를 프린트 합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "-dfuGTMINKRR"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "\n",
        "class MyCustomCallback(tf.keras.callbacks.Callback):\n",
        "\n",
        "  def on_train_batch_begin(self, batch, logs=None):\n",
        "    print('Training: batch {} begins at {}'.format(batch, datetime.datetime.now().time()))\n",
        "\n",
        "  def on_train_batch_end(self, batch, logs=None):\n",
        "    print('Training: batch {} ends at {}'.format(batch, datetime.datetime.now().time()))\n",
        "\n",
        "  def on_test_batch_begin(self, batch, logs=None):\n",
        "    print('Evaluating: batch {} begins at {}'.format(batch, datetime.datetime.now().time()))\n",
        "\n",
        "  def on_test_batch_end(self, batch, logs=None):\n",
        "    print('Evaluating: batch {} ends at {}'.format(batch, datetime.datetime.now().time()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Z4FTUUIBN3WG"
      },
      "source": [
        "텐서플로우.케라스.모델.적합()과 같은 모델 메소드를 callback에 제공하는 것은 해당 단계에서 메소드가 호출되도록 보장합니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "NJV6Tj3sNGzg"
      },
      "outputs": [],
      "source": [
        "model = get_model()\n",
        "_ = model.fit(x_train, y_train,\n",
        "          batch_size=64,\n",
        "          epochs=1,\n",
        "          steps_per_epoch=5,\n",
        "          verbose=0,\n",
        "          callbacks=[MyCustomCallback()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fIy5JKMlZNmh"
      },
      "source": [
        "##callbacks을 수행하는 모델 방법\n",
        "사용자는 다음 `tf.keras.Model` 메소드에 콜백 리스트를 인자로 전달할 수 있습니다:\n",
        "#### [`fit()`](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/Model#fit), [`fit_generator()`](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/Model#fit_generator)\n",
        "일정한 수의 epochs(데이터 집합에 대한 반복, 또는 파이썬 생성기에 의한 batch별 데이터 산출)에 대한 모델을 추적합니다..\n",
        "#### [`evaluate()`](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/Model#evaluate), [`evaluate_generator()`](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/Model#evaluate_generator)\n",
        "주어진 데이터 또는 데이터 생성기(data generator)에 대해 모델을 평가합니다. 평가에서 손실 및 메트릭값(metric values)을 출력합니다.\n",
        "#### [`predict()`](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/Model#predict), [`predict_generator()`](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/Model#predict_generator)\n",
        "입력 데이터 또는 데이터 생성기에 대한 예측을 출력합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "J00bXBbqdnJe"
      },
      "outputs": [],
      "source": [
        "_ = model.evaluate(x_test, y_test, batch_size=128, verbose=0, steps=5,\n",
        "          callbacks=[MyCustomCallback()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "13n44LVkYQsV"
      },
      "source": [
        "## callback 방법의 개요\n",
        "\n",
        "\n",
        "### 훈련/테스트/예측 시 사용되는 일반적인 메소드\n",
        "훈련, 테스트 및 예측을 위해 재정의할 수 있는 메소드들은 다음과 같습니다.\n",
        "#### `on_(train|test|predict)_begin(self, logs=None)`\n",
        "`fit`/`evaluate`/`predict`의 시작 시 호출됩니다.\n",
        "#### `on_(train|test|predict)_end(self, logs=None)`\n",
        "`fit`/`evaluate`/`predict`의 종료 시 호출됩니다.\n",
        "#### `on_(train|test|predict)_batch_begin(self, batch, logs=None)`\n",
        "트레이닝/시험/예측이 진행되는 동안 batch의 진행 직전에 호출됩니다. 이 메소드 내에서, 일지는 batch의 현재 수와 사이즈를 나타내는 자유로운 크기의 키로 받아 써집니다.\n",
        "#### `on_(train|test|predict)_batch_end(self, batch, logs=None)`\n",
        "batch의 트레이닝/시험/예측의 끝에서 호출됩니다. 이 메소드에서, 로그는 상태 저장 메트릭 결과를 포함하는 받아쓰기입니다..\n",
        "\n",
        "### 훈련에만 존재하는 메소드\n",
        "훈련 단계에 한해서는 다음과 같은 메소드들이 정의되어있습니다.\n",
        "#### on_epoch_begin(self, epoch, logs=None)\n",
        "트레이닝 동안의 epoch의 시작에서 호출됩니다.\n",
        "#### on_epoch_end(self, epoch, logs=None)\n",
        "트레이닝 동안의 epoch의 끝에서 호출됩니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SWf3mXYoceCz"
      },
      "source": [
        "### `log` 딕셔너리의 사용 설명\n",
        "로그는 손실값과 batch 또는 epoch의 끝에 모든 메트릭스를 포함합니다. 예제에는 손실과 과실을 의미하는 것을 포함합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "u4wIdcF9BjJH"
      },
      "outputs": [],
      "source": [
        "class LossAndErrorPrintingCallback(tf.keras.callbacks.Callback):\n",
        "\n",
        "  def on_train_batch_end(self, batch, logs=None):\n",
        "    print('For batch {}, loss is {:7.2f}.'.format(batch, logs['loss']))\n",
        "\n",
        "  def on_test_batch_end(self, batch, logs=None):\n",
        "    print('For batch {}, loss is {:7.2f}.'.format(batch, logs['loss']))\n",
        "\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    print('The average loss for epoch {} is {:7.2f} and mean absolute error is {:7.2f}.'.format(epoch, logs['loss'], logs['mae']))\n",
        "\n",
        "model = get_model()\n",
        "_ = model.fit(x_train, y_train,\n",
        "          batch_size=64,\n",
        "          steps_per_epoch=5,\n",
        "          epochs=3,\n",
        "          verbose=0,\n",
        "          callbacks=[LossAndErrorPrintingCallback()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LbXqvC8FHqeu"
      },
      "source": [
        "유사하게 평가()의 호출에서 callbacks를 제공할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "jzTKYPQHwcxF"
      },
      "outputs": [],
      "source": [
        "_ = model.evaluate(x_test, y_test, batch_size=128, verbose=0, steps=20,\n",
        "          callbacks=[LossAndErrorPrintingCallback()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HnSljqtsXKfb"
      },
      "source": [
        "## 케라스 callback 어플리케이션의 예시\n",
        "다음 분야에서는 간단한 callback 어플리케이션을 생성하는 방법을 안내합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kptNF0--Lznv"
      },
      "source": [
        "### 최소 손실 시 훈련 조기 정지하기\n",
        "첫 번째 예는 `model.stop_training` (불리언 자료형) 속성을 변경하여 최소 손실에 도달했을 때 훈련을 중지하는 콜백의 생성 방법을 보여줍니다. 선택 사항으로, 사용자는 `patience` 인자를 정의하여 훈련이 중지되기까지 기다려야하는 에폭의 수를 지정할 수 있습니다.\n",
        "\n",
        "`tf.keras.callbacks.EarlyStopping`은 좀 더 완성적이고 일반적인 구현을 제공합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "BM31gfAV4mks"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "class EarlyStoppingAtMinLoss(tf.keras.callbacks.Callback):\n",
        "  \"\"\"손실이 최소 수준일 때 훈련을 중지합니다. 즉, 손실이 더 이상 감소하지 않을때 멈춥니다.\n",
        "\n",
        "  인자:\n",
        "      patience: 손실이 최소화 되었을 때 기다릴 추가 에폭의 수.\n",
        "      기다렸음에도 진전이 없으면 훈련이 중지됩니다..\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, patience=0):\n",
        "    super(EarlyStoppingAtMinLoss, self).__init__()\n",
        "\n",
        "    self.patience = patience\n",
        "\n",
        "    # 손실이 최소화 되었을때 저장할 최적의 모델 가중치.\n",
        "    self.best_weights = None\n",
        "\n",
        "  def on_train_begin(self, logs=None):\n",
        "    # 손실이 더 이상 최소가 아닐 때 기다려온 epoch의 수.\n",
        "    self.wait = 0\n",
        "    # 트레이닝이 멈춘 시점의 epoch.\n",
        "    self.stopped_epoch = 0\n",
        "    #  값을 무한으로 초기화.\n",
        "    self.best = np.Inf\n",
        "\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    current = logs.get('loss')\n",
        "    if np.less(current, self.best):\n",
        "      self.best = current\n",
        "      self.wait = 0\n",
        "      # 현재 결과가 더 나은 경우 (낮은 경우) 최적의 가중치를 기록합니다.\n",
        "      self.best_weights = self.model.get_weights()\n",
        "    else:\n",
        "      self.wait += 1\n",
        "      if self.wait >= self.patience:\n",
        "        self.stopped_epoch = epoch\n",
        "        self.model.stop_training = True\n",
        "        print('Restoring model weights from the end of the best epoch.')\n",
        "        self.model.set_weights(self.best_weights)\n",
        "\n",
        "  def on_train_end(self, logs=None):\n",
        "    if self.stopped_epoch > 0:\n",
        "      print('Epoch %05d: early stopping' % (self.stopped_epoch + 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "xS4fa-7PFzzc"
      },
      "outputs": [],
      "source": [
        "model = get_model()\n",
        "_ = model.fit(x_train, y_train,\n",
        "          batch_size=64,\n",
        "          steps_per_epoch=5,\n",
        "          epochs=30,\n",
        "          verbose=0,\n",
        "          callbacks=[LossAndErrorPrintingCallback(), EarlyStoppingAtMinLoss()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SpVDjs_Dkkdh"
      },
      "source": [
        "### 학습률 스케줄링 (scheduling)\n",
        "\n",
        "모델 훈련에서 흔히 행해지는 한 가지 일은 더 많은 epochs가 지나감에 따라 학습 속도를 바꾸는 것입니다. 케라스 백엔드는 변수를 설정하는데 사용할 수 있는 겟_벨류 API를 노출합니다. 이 예에서 사용자 지정 콜백을 사용하여 학습 속도를 동적으로 변경하는 방법을 보여드리고 있습니다.\n",
        "\n",
        "노트: 이것은 더 일반적인 실행을 위한 callbacks러닝레이드스케쥴러와 케라스옵티마이져스케쥴러를 보는 한 예시입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "PGowEUC8klSz"
      },
      "outputs": [],
      "source": [
        "class LearningRateScheduler(tf.keras.callbacks.Callback):\n",
        "  \"\"\"스케쥴에 따라 학습 속도를 조정하는 학습률 스케줄러.\n",
        "\n",
        "  논쟁:\n",
        "      스케쥴러: epoch의 인덱스를 가져오는 함수\n",
        "          와 현재 학습률을 입력으로 받아서\n",
        "          새로운 학습률(플로트 자료형)을 출력하는 함수.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, schedule):\n",
        "    super(LearningRateScheduler, self).__init__()\n",
        "    self.schedule = schedule\n",
        "\n",
        "  def on_epoch_begin(self, epoch, logs=None):\n",
        "    if not hasattr(self.model.optimizer, 'lr'):\n",
        "      raise ValueError('Optimizer must have a \"lr\" attribute.')\n",
        "    # 모델 옵티마이저에서 현재 학습률을 확인합니다.\n",
        "    lr = float(tf.keras.backend.get_value(self.model.optimizer.lr))\n",
        "    # 예정된 학습률을 받기 위해 스케줄 함수를 호출합니다.\n",
        "    scheduled_lr = self.schedule(epoch, lr)\n",
        "    # epoch 시작 전의 값으로 돌린 후 옵티마이져에 설정\n",
        "    tf.keras.backend.set_value(self.model.optimizer.lr, scheduled_lr)\n",
        "    print('\\nEpoch %05d: Learning rate is %6.4f.' % (epoch, scheduled_lr))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "1jL3pI5Ep5F8"
      },
      "outputs": [],
      "source": [
        "LR_SCHEDULE = [\n",
        "    # (epoch의 시작, 학습 비율) 투플\n",
        "    (3, 0.05), (6, 0.01), (9, 0.005), (12, 0.001)\n",
        "]\n",
        "\n",
        "def lr_schedule(epoch, lr):\n",
        "  \"\"\"epoch을 기반으로 한 스케쥴 학습 비율을 검색하는 도우미 함수.\"\"\"\n",
        "  if epoch < LR_SCHEDULE[0][0] or epoch > LR_SCHEDULE[-1][0]:\n",
        "    return lr\n",
        "  for i in range(len(LR_SCHEDULE)):\n",
        "    if epoch == LR_SCHEDULE[i][0]:\n",
        "      return LR_SCHEDULE[i][1]\n",
        "  return lr\n",
        "\n",
        "model = get_model()\n",
        "_ = model.fit(x_train, y_train,\n",
        "          batch_size=64,\n",
        "          steps_per_epoch=5,\n",
        "          epochs=15,\n",
        "          verbose=0,\n",
        "          callbacks=[LossAndErrorPrintingCallback(), LearningRateScheduler(lr_schedule)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9xMkm699JzK8"
      },
      "source": [
        "### 케라스 callbacks 표준\n",
        "[API 공식 문서](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/callbacks)를 참조하면 보다 더 다양한 기존의 케라스 콜백 어플리케이션에 대해 알아볼 수 있습니다. CSV 로깅, 모델 저장, 텐서보드에서의 시각화 등의 다양한 기능을 포함한 어플리케이션들이 있습니다."
      ]
    }
  ]
}
