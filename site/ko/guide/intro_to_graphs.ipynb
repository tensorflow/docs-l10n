{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7ITxKLUkX0v"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "yOYx6tzSnWQ3"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xgB0Oz5eGSQ"
      },
      "source": [
        "# 그래프 및 tf.function 소개"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4zzZVZtQb1w"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>     <a target=\"_blank\" href=\"https://www.tensorflow.org/guide/intro_to_graphs\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">TensorFlow.org에서 보기</a>   </td>\n",
        "  <td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/ko/guide/intro_to_graphs.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Google Colab에서 실행</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/ko/guide/intro_to_graphs.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">GitHub에서 소스 보기</a></td>\n",
        "  <td><a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/ko/guide/intro_to_graphs.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">노트북 다운로드</a></td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBKqnXI9GOax"
      },
      "source": [
        "## 개요\n",
        "\n",
        "이 가이드는 TensorFlow의 TensorFlow 및 Keras의 내부를 살펴봄으로써 TensorFlow의 동작 방식을 설명합니다. 대신 Keras를 바로 시작하려면 [Keras 가이드 모음](https://www.tensorflow.org/guide/keras/)을 확인하세요.\n",
        "\n",
        "이 가이드에서는 TensorFlow를 사용하여 코드를 간단하게 변경하고 그래프를 가져오는 방법, 그래프를 저장하고 표시하는 방법, 그리고 이를 사용하여 모델을 가속화하는 방법을 배웁니다.\n",
        "\n",
        "참고: TensorFlow 1.x에만 익숙한 사용자를 위해 이 가이드는 매우 다른 그래프 뷰를 보여줍니다.\n",
        "\n",
        "**본 내용은 `tf.function`을 사용하여 즉시 실행에서 그래프 실행으로 전환하는 방법을 개괄적으로 설명합니다.** `tf.function`의 전반적인 사용에 대한 내용은 <a href=\"function.ipynb\" data-md-type=\"link\">`tf.function` 가이드</a>를 참조하세요.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0DdlfacAdTZ"
      },
      "source": [
        "### 그래프란 무엇인가요?\n",
        "\n",
        "In the previous three guides, you ran TensorFlow **eagerly**. This means TensorFlow operations are executed by Python, operation by operation, and returning results back to Python.\n",
        "\n",
        "즉시 실행에는 몇 가지 고유한 장점이 있지만 그래프 실행은 Python 외부에서 이식성을 가능하게 하며 성능이 더 우수한 경향이 있습니다. **그래프 실행**은 텐서 계산이 `tf.Graph` 또는 간단히 \"그래프\"라고도 하는 *TensorFlow 그래프*로 실행됨을 의미합니다.\n",
        "\n",
        "**그래프는 계산의 단위를 나타내는 `tf.Operation` 객체와 연산 간에 흐르는 데이터의 단위를 나타내는 `tf.Tensor` 객체의 세트를 포함합니다.** 데이터 구조는 `tf.Graph` 컨텍스트에서 정의됩니다. 그래프는 데이터 구조이므로 원래 Python 코드 없이 모두 저장, 실행 및 복원할 수 있습니다.\n",
        "\n",
        "이것은 TensorBoard에서 시각화했을 때 2계층 신경망을 나타내는 TensorFlow 그래프의 모습입니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FvQ5aBuRGT1o"
      },
      "source": [
        "<img alt=\"A simple TensorFlow graph\" src=\"https://github.com/tensorflow/docs/blob/master/site/en/guide/images/intro_to_graphs/two-layer-network.png?raw=1\" class=\"\"> "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHpY3avXGITP"
      },
      "source": [
        "### 그래프의 이점\n",
        "\n",
        "그래프를 사용하면 유연성이 크게 향상됩니다. 모바일 애플리케이션, 임베디드 기기 및 백엔드 서버와 같은 Python 인터프리터가 없는 환경에서 TensorFlow 그래프를 사용할 수 있습니다. TensorFlow는 그래프를 Python에서 내보낼 때 저장된 모델의 형식으로 그래프를 사용합니다.\n",
        "\n",
        "그래프는 쉽게 최적화되어 컴파일러가 다음과 같은 변환을 수행할 수 있습니다.\n",
        "\n",
        "- 계산에서 상수 노드를 접어 텐서의 값을 정적으로 추론합니다*(\"일정한 접기\")*.\n",
        "- 독립적인 계산의 하위 부분을 분리하여 스레드 또는 기기 간에 분할합니다.\n",
        "- 공통 하위 표현식을 제거하여 산술 연산을 단순화합니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1x1EOD9GjnB"
      },
      "source": [
        "위와 같은 변환 및 기타 속도 향상을 수행하기 위한 전체 최적화 시스템으로 [Grappler](./graph_optimization.ipynb)가 있습니다.\n",
        "\n",
        "요약하면, 그래프는 TensorFlow가 **빠르게**, **병렬로**, 그리고 효율적으로 **여러 기기에서** 실행할 때 아주 유용합니다.\n",
        "\n",
        "그러나 편의를 위해 Python에서 머신러닝 모델(또는 기타 계산)을 정의한 다음 필요할 때 자동으로 그래프를 구성하려고 합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-6Qi0thw2i9"
      },
      "source": [
        "## 설정하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "goZwOXp_xyQj"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import timeit\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSZebVuWxDXu"
      },
      "source": [
        "## 그래프 이용하기\n",
        "\n",
        "`tf.function`을 직접 호출 또는 데코레이터로 사용하여 TensorFlow에서 그래프를 만들고 실행합니다. `tf.function`은 일반 함수를 입력으로 받아 `Function`을 반환합니다. <strong data-md-type=\"raw_html\">`Function`은 Python 함수로부터 TensorFlow 그래프를 빌드하는 Python callable입니다. Python의 경우와 동일한 방식으로 `Function`를 사용합니다.</strong>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HKbLeJ1y0Umi"
      },
      "outputs": [],
      "source": [
        "# Define a Python function.\n",
        "def a_regular_function(x, y, b):\n",
        "  x = tf.matmul(x, y)\n",
        "  x = x + b\n",
        "  return x\n",
        "\n",
        "# `a_function_that_uses_a_graph` is a TensorFlow `Function`.\n",
        "a_function_that_uses_a_graph = tf.function(a_regular_function)\n",
        "\n",
        "# Make some tensors.\n",
        "x1 = tf.constant([[1.0, 2.0]])\n",
        "y1 = tf.constant([[2.0], [3.0]])\n",
        "b1 = tf.constant(4.0)\n",
        "\n",
        "orig_value = a_regular_function(x1, y1, b1).numpy()\n",
        "# Call a `Function` like a Python function.\n",
        "tf_function_value = a_function_that_uses_a_graph(x1, y1, b1).numpy()\n",
        "assert(orig_value == tf_function_value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNvuAYpdrTOf"
      },
      "source": [
        "겉보기에 `Function`은 TensorFlow 연산을 사용하여 작성하는 일반 함수처럼 보입니다. 그러나 [그 안을 들여다 보면](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/eager/def_function.py) *매우 다릅니다*. `Function`**는 [하나의 API 뒤에서 여러 `tf.Graph`](#polymorphism_one_function_many_graphs)를 캡슐화합니다.** 바로 이런 이유로 `Function`이 속도 및 배포 가능성과 같은 [그래프 실행의 이점](#the_benefits_of_graphs)을 제공하는 것입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MT7U8ozok0gV"
      },
      "source": [
        "`tf.function`은 함수 및 *이 함수가 호출하는 다른 모든 함수*에 적용됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rpz08iLplm9F"
      },
      "outputs": [],
      "source": [
        "def inner_function(x, y, b):\n",
        "  x = tf.matmul(x, y)\n",
        "  x = x + b\n",
        "  return x\n",
        "\n",
        "# Use the decorator to make `outer_function` a `Function`.\n",
        "@tf.function\n",
        "def outer_function(x):\n",
        "  y = tf.constant([[2.0], [3.0]])\n",
        "  b = tf.constant(4.0)\n",
        "\n",
        "  return inner_function(x, y, b)\n",
        "\n",
        "# Note that the callable will create a graph that\n",
        "# includes `inner_function` as well as `outer_function`.\n",
        "outer_function(tf.constant([[1.0, 2.0]])).numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P88fOr88qgCj"
      },
      "source": [
        "TensorFlow 1.x를 사용한 경우 `Placeholder` 또는 `tf.Sesssion`을 정의할 필요가 없었음을 알 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfeKf0Nr1OEK"
      },
      "source": [
        "### Python 함수를 그래프로 변환하기\n",
        "\n",
        "TensorFlow를 사용하여 작성하는 모든 함수에는 `if-then` 절, 루프, `break`, `return`, `continue` 등과 같은 내장된 TF 연산과 Python 논리가 혼합되어 있습니다. TensorFlow 연산은 `tf.Graph`에 의해 쉽게 캡처되지만 Python 관련 논리는 그래프의 일부가 되기 위해 추가 단계를 거쳐야 합니다. `tf.function`은 AutoGraph(`tf.autograph`)라는 라이브러리를 사용하여 Python 코드를 그래프 생성 코드로 변환합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PFObpff1BMEb"
      },
      "outputs": [],
      "source": [
        "def simple_relu(x):\n",
        "  if tf.greater(x, 0):\n",
        "    return x\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "# `tf_simple_relu` is a TensorFlow `Function` that wraps `simple_relu`.\n",
        "tf_simple_relu = tf.function(simple_relu)\n",
        "\n",
        "print(\"First branch, with graph:\", tf_simple_relu(tf.constant(1)).numpy())\n",
        "print(\"Second branch, with graph:\", tf_simple_relu(tf.constant(-1)).numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hO4DBUNZBMwQ"
      },
      "source": [
        "그래프를 직접 볼 필요는 없겠지만 결과를 검사하여 정확한 결과를 확인할 수 있습니다. 읽기가 쉽지 않으므로 너무 주의 깊게 볼 필요는 없습니다!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lAKaat3w0gnn"
      },
      "outputs": [],
      "source": [
        "# This is the graph-generating output of AutoGraph.\n",
        "print(tf.autograph.to_code(simple_relu))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8x6RAqza1UWf"
      },
      "outputs": [],
      "source": [
        "# This is the graph itself.\n",
        "print(tf_simple_relu.get_concrete_function(tf.constant(1)).graph.as_graph_def())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZ4Ieg6tBE6l"
      },
      "source": [
        "대부분의 경우, `tf.function`은 특별한 고려없이 작동합니다. 그러나 몇 가지 주의 사항이 있으며 <a>tf.function 안내서</a>와 [전체 AutoGraph 참조서](./function.ipynb)가 도움이 될 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIpc_jfjEZEg"
      },
      "source": [
        "### 다형성: 하나의 `Function`, 다수의 그래프\n",
        "\n",
        "`tf.Graph`는 특정 유형의 입력에 특화되어 있습니다(예: 특정 [`dtype`](https://www.tensorflow.org/api_docs/python/tf/dtypes/DType)을 가진 텐서 또는 동일한 [`id()`](https://docs.python.org/3/library/functions.html#id%5D)를 가진 객체).\n",
        "\n",
        "기존 그래프에서 처리할 수 없는 인수 세트로 `Function`을 호출할 때마다(예: 새로운 `dtypes` 또는 호환되지 않는 형상의 인수) `Function`은 이러한 새 인수에 특화된 새 `tf.Graph`를 만듭니다. `tf.Graph` 입력의 유형 사양을 **입력 서명** 또는 그냥 **서명**이라고 합니다. 새 `tf.Graph`가 생성되는 시기와 이를 제어하는 방법에 대한 자세한 내용은 [재트레이싱 규칙](https://www.tensorflow.org/guide/function#rules_of_tracing)을 참조하세요.\n",
        "\n",
        "`Function`은 해당 서명에 대응하는 `tf.Graph`를 `ConcreteFunction`에 저장합니다. <strong data-md-type=\"raw_html\">`ConcreteFunction`은 `tf.Graph`를 감싸는 래퍼입니다.</strong>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LOASwhbvIv_T"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def my_relu(x):\n",
        "  return tf.maximum(0., x)\n",
        "\n",
        "# `my_relu` creates new graphs as it observes more signatures.\n",
        "print(my_relu(tf.constant(5.5)))\n",
        "print(my_relu([1, -1]))\n",
        "print(my_relu(tf.constant([3., -3.])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qRtw7R4KL9X"
      },
      "source": [
        "`Function`이 이 서명으로 이미 호출된 경우, `Function`은 새 `tf.Graph`를 생성하지 않습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TjjbnL5OKNDP"
      },
      "outputs": [],
      "source": [
        "# These two calls do *not* create new graphs.\n",
        "print(my_relu(tf.constant(-2.5))) # Signature matches `tf.constant(5.5)`.\n",
        "print(my_relu(tf.constant([-1., 1.]))) # Signature matches `tf.constant([3., -3.])`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UohRmexhIpvQ"
      },
      "source": [
        "여러 그래프로 뒷받침된다는 점에서 `Function`는 **다형성**입니다. 그 결과, 단일 `tf.Graph`로 나타낼 수 있는 것보다 더 많은 입력 유형을 지원할 수 있을뿐만 아니라 `tf.Graph`가 더 우수한 성능을 갖도록 최적화할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dxzqebDYFmLy"
      },
      "outputs": [],
      "source": [
        "# There are three `ConcreteFunction`s (one for each graph) in `my_relu`.\n",
        "# The `ConcreteFunction` also knows the return type and shape!\n",
        "print(my_relu.pretty_printed_concrete_signatures())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V11zkxU22XeD"
      },
      "source": [
        "## `tf.function` 사용하기\n",
        "\n",
        "지금까지 `tf.function`을 데코레이터 또는 래퍼로 사용하여 Python 함수를 간단히 그래프로 변환하는 방법을 살펴보았습니다. 그러나 실제로 `tf.function`이 올바르게 작동하도록 만드는 일은 까다로울 수 있습니다! 다음 섹션에서는 `tf.function`을 사용하여 코드가 예상대로 작동하도록 만드는 방법을 알아봅니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yp_n0B5-P0RU"
      },
      "source": [
        "### 그래프 실행 vs 즉시 실행\n",
        "\n",
        "`Function`의 코드는 즉시 실행 또는 그래프 실행이 가능합니다. 기본적으로 `Function`은 코드를 그래프로 실행합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_R0BOvBFxqVZ"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def get_MSE(y_true, y_pred):\n",
        "  sq_diff = tf.pow(y_true - y_pred, 2)\n",
        "  return tf.reduce_mean(sq_diff)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zikMVPGhmDET"
      },
      "outputs": [],
      "source": [
        "y_true = tf.random.uniform([5], maxval=10, dtype=tf.int32)\n",
        "y_pred = tf.random.uniform([5], maxval=10, dtype=tf.int32)\n",
        "print(y_true)\n",
        "print(y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "07r08Dh158ft"
      },
      "outputs": [],
      "source": [
        "get_MSE(y_true, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyZNCRcQorGO"
      },
      "source": [
        "`Function`의 그래프가 동등한 Python 함수와 같은 계산을 수행하는지 확인하기 위해 `tf.config.run_functions_eagerly(True)`를 이용해 즉시 실행하도록 할 수 있습니다. <strong data-md-type=\"raw_html\">코드를 정상적으로 실행하는 대신 그래프를 생성하고 실행하는 `Function`의 역할을 해제</strong>시킬 때 스위치와 같이 이용되는 코드입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lKoF6NjPoI8w"
      },
      "outputs": [],
      "source": [
        "tf.config.run_functions_eagerly(True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ZLqTyn0oKeM"
      },
      "outputs": [],
      "source": [
        "get_MSE(y_true, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cV7daQW9odn-"
      },
      "outputs": [],
      "source": [
        "# Don't forget to set it back when you are done.\n",
        "tf.config.run_functions_eagerly(False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKT3YBsqy0x4"
      },
      "source": [
        "그러나 `Function`은 그래프 및 즉시 실행에서 서로 다르게 동작할 수 있습니다. Python [`print`](https://docs.python.org/3/library/functions.html#print) 함수는 이 두 모드가 어떻게 다른지 보여주는 한 가지 예제입니다. `print` 문을 삽입하고 이를 반복적으로 호출할 때 어떤 일이 발생하는지 살펴보겠습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BEJeVeBEoGjV"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def get_MSE(y_true, y_pred):\n",
        "  print(\"Calculating MSE!\")\n",
        "  sq_diff = tf.pow(y_true - y_pred, 2)\n",
        "  return tf.reduce_mean(sq_diff)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3sWTGwX3BzP1"
      },
      "source": [
        "인쇄된 내용을 잘 살펴봅니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3rJIeBg72T9n"
      },
      "outputs": [],
      "source": [
        "error = get_MSE(y_true, y_pred)\n",
        "error = get_MSE(y_true, y_pred)\n",
        "error = get_MSE(y_true, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLMXk1uxKQ44"
      },
      "source": [
        "출력 결과가 놀랍지 않나요? **`get_MSE`는 *세 번* 호출되었지만 한 번만 인쇄되었습니다.**\n",
        "\n",
        "설명하자면, `print` 문은 `Function`이 원래 코드를 실행할 때 실행되며 이 때 [\"트레이싱\"](function.ipynb#tracing)이라는 프로세스를 통해 그래프가 생성됩니다. <strong data-md-type=\"raw_html\">트레이싱은 TensorFlow 연산을 그래프로 캡처하고 `print`는 그래프에서 캡처되지 않습니다.</strong> 이 그래프는 세 번의 모든 호출시 실행되지만 **Python 코드를 다시 실행하지는 않습니다.**\n",
        "\n",
        "실제로 그런지 검사하기 위해 그래프 실행을 해제하고 비교해 보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oFSxRtcptYpe"
      },
      "outputs": [],
      "source": [
        "# Now, globally set everything to run eagerly to force eager execution.\n",
        "tf.config.run_functions_eagerly(True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qYxrAtvzNgHR"
      },
      "outputs": [],
      "source": [
        "# Observe what is printed below.\n",
        "error = get_MSE(y_true, y_pred)\n",
        "error = get_MSE(y_true, y_pred)\n",
        "error = get_MSE(y_true, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Df6ynXcAaup"
      },
      "outputs": [],
      "source": [
        "tf.config.run_functions_eagerly(False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUR7qC_bquCn"
      },
      "source": [
        "`print`는 *Python의 부작용*이며 함수를 `Function`으로 변환할 때 알고 있어야 하는 <a>다른 차이점들</a>이 있습니다. [tf.function으로 성능 향상하기](./function.ipynb#limitations) 가이드의 *한계* 섹션에서 자세히 알아보세요."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTZJfV_tccVp"
      },
      "source": [
        "참고: 즉시 및 그래프 실행 모두에서 값을 인쇄하려면 `tf.print`를 대신 사용하세요."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMT_Xf5yKn9o"
      },
      "source": [
        "### 비평가(Non-strict) 실행\n",
        "\n",
        "<a id=\"non-strict\"></a>\n",
        "\n",
        "그래프 실행은 다음을 포함하여 관찰 가능한 효과를 생성하는 데 필요한 작업만 실행합니다.\n",
        "\n",
        "- 함수의 반환 값\n",
        "- 다음과 같은 문서화된 잘 알려진 부작용:\n",
        "    - `tf.print`와 같은 입력/출력 작업\n",
        "    - `tf.debugging`의 어설션 기능과 같은 디버깅 작업\n",
        "    - `tf.Variable`의 변형\n",
        "\n",
        "이 동작은 일반적으로 \"비평가 실행\"으로 알려져 있으며 필요하거나 필요하지 않은 모든 프로그램 작업을 단계별로 실행하는 즉시 실행과 구분됩니다.\n",
        "\n",
        "특히 런타임 오류 검사는 관찰 가능한 효과로 간주되지 않습니다. 작업이 불필요하다는 이유로 건너뛰면 런타임 오류가 발생할 수 없습니다.\n",
        "\n",
        "다음 예제에서는 그래프 실행 중에 \"불필요한\" 작업인 `tf.gather`을 건너뛰므로 즉시 실행에서와 마찬가지로 런타임 오류 `InvalidArgumentError`가 발생하지 않습니다. 그래프를 실행하는 동안 발생하는 오류에 의존하지 마세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OdN0nKlUwj7M"
      },
      "outputs": [],
      "source": [
        "def unused_return_eager(x):\n",
        "  # Get index 1 will fail when `len(x) == 1`\n",
        "  tf.gather(x, [1]) # unused \n",
        "  return x\n",
        "\n",
        "try:\n",
        "  print(unused_return_eager(tf.constant([0.0])))\n",
        "except tf.errors.InvalidArgumentError as e:\n",
        "  # All operations are run during eager execution so an error is raised.\n",
        "  print(f'{type(e).__name__}: {e}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d80Fob4MwhTs"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def unused_return_graph(x):\n",
        "  tf.gather(x, [1]) # unused\n",
        "  return x\n",
        "\n",
        "# Only needed operations are run during graph exection. The error is not raised.\n",
        "print(unused_return_graph(tf.constant([0.0])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "def6MupG9R0O"
      },
      "source": [
        "###`tf.function` 모범 사례\n",
        "\n",
        "`Function`의 동작에 익숙해지려면 시간이 걸릴 수 있습니다. 빠르게 시작하려는 처음 사용자는 `@tf.function`으로 시험용 함수를 사용해 보면서 즉시 실행에서 그래프 실행으로 이동하는 과정을 체험할 수 있습니다.\n",
        "\n",
        "*`tf.function`을 위한 디자인*은 그래프 호환 TensorFlow 프로그램을 작성하는 가장 좋은 방법일 수 있습니다. 다음은 몇 가지 팁입니다.\n",
        "\n",
        "- `tf.config.run_functions_eagerly`로 즉시 실행과 그래프 실행 사이를 조기에 자주 전환하여 두 모드가 서로 달라지는지, 언제 달라지는지 정확하게 파악합니다.\n",
        "- Python 함수 외부에서 `tf.Variable`을 실행하고 내부에서 수정합니다. `keras.layers`, `keras.Model` 및 `tf.optimizers`와 같이 `tf.Variable`을 사용하는 객체의 경우도 마찬가지입니다.\n",
        "- `tf.Variables` 및 Keras 객체를 제외하고 [외부 Python 변수에 종속되는](function#depending_on_python_global_and_free_variables) 함수 작성을 피합니다.\n",
        "- 텐서 및 기타 TensorFlow 유형을 입력으로 사용하는 함수를 작성하는 것이 좋습니다. 다른 객체 유형을 전달할 수 있지만 [주의해야 합니다](function#depending_on_python_objects)!\n",
        "- 성능 이점을 극대화하기 위해 `tf.function` 하에서 계산이 가능한 한 많이 포함되도록 합니다. 예를 들어 전체 훈룬 스텝 또는 전체 훈룬 루프를 데코레이션합니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ViM3oBJVJrDx"
      },
      "source": [
        "## 속도 향상 확인하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6NHDp7vAKcJ"
      },
      "source": [
        "`tf.function`은 일반적으로 코드의 성능을 향상시키지만 속도 향상의 정도는 실행하는 계산의 종류에 따라 다릅니다. 작은 계산의 경우 그래프를 호출하는 오버헤드에 의해 지배될 수 있습니다. 다음과 같이 성능 차이를 측정할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jr7p1BBjauPK"
      },
      "outputs": [],
      "source": [
        "x = tf.random.uniform(shape=[10, 10], minval=-1, maxval=2, dtype=tf.dtypes.int32)\n",
        "\n",
        "def power(x, y):\n",
        "  result = tf.eye(10, dtype=tf.dtypes.int32)\n",
        "  for _ in range(y):\n",
        "    result = tf.matmul(x, result)\n",
        "  return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ms2yJyAnUYxK"
      },
      "outputs": [],
      "source": [
        "print(\"Eager execution:\", timeit.timeit(lambda: power(x, 100), number=1000))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gUB2mTyRYRAe"
      },
      "outputs": [],
      "source": [
        "power_as_graph = tf.function(power)\n",
        "print(\"Graph execution:\", timeit.timeit(lambda: power_as_graph(x, 100), number=1000))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1Pfo5YwwILi"
      },
      "source": [
        "`tf.function`은 일반적으로 훈련 루프의 속도를 높이는 데 사용되며, Keras를 사용하여 [처음부터 훈련 루프 작성하기](https://www.tensorflow.org/guide/keras/writing_a_training_loop_from_scratch#speeding-up_your_training_step_with_tffunction)에서 자세히 알아볼 수 있습니다.\n",
        "\n",
        "참고: 특히 코드가 TF 제어 흐름에서 과중하고 작은 텐서를 많이 사용하는 경우, 성능 개선의 효과를 높이기 위해 [`tf.function(jit_compile=True)`](https://www.tensorflow.org/xla#explicit_compilation_with_tffunctionjit_compiletrue)를 시도해볼 수도 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sm0bNFp8PX53"
      },
      "source": [
        "### 성능과 상충 관계\n",
        "\n",
        "그래프는 코드의 속도를 높일 수 있지만 이를 생성하는 프로세스에는 약간의 오버헤드가 있습니다. 일부 함수의 경우 그래프를 생성하는 데 그래프를 실행하는 것보다 더 많은 시간이 걸립니다. **이러한 투자를 할 경우 후속 실행에서 성능이 향상되는 보상이 빠르게 뒤따르지만 대규모 모델 훈련의 처음 몇 단계에서는 트레이싱으로 인해 느려질 수 있다는 점을 알고 있어야 합니다**.\n",
        "\n",
        "모델 크기에 관계없이, 빈번한 트레이싱은 피해야 합니다. `tf.function` 가이드에 [리트레이싱을 피하기 위해 입력 사양을 설정하고 텐서 인수를 사용하는 방법](function#controlling_retracing)에 관한 설명이 나와 있습니다. 비정상적으로 성능이 저하되는 것으로 판단되면 실수로 리트레이싱하고 있지 않은지 확인하는 것이 좋습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4InDaTjwmBA"
      },
      "source": [
        "## `Function`은 언제 트레이싱합니까?\n",
        "\n",
        "`Function`이 트레이싱을 수행하는 경우를 알아보려면 코드에 `print` 문을 추가합니다. 대략적인 규칙으로, `Function`은 트레이싱할 때마다 `print` 문을 실행합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hXtwlbpofLgW"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def a_function_with_python_side_effect(x):\n",
        "  print(\"Tracing!\") # An eager-only side effect.\n",
        "  return x * x + tf.constant(2)\n",
        "\n",
        "# This is traced the first time.\n",
        "print(a_function_with_python_side_effect(tf.constant(2)))\n",
        "# The second time through, you won't see the side effect.\n",
        "print(a_function_with_python_side_effect(tf.constant(3)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "inzSg8yzfNjl"
      },
      "outputs": [],
      "source": [
        "# This retraces each time the Python argument changes,\n",
        "# as a Python argument could be an epoch count or other\n",
        "# hyperparameter.\n",
        "print(a_function_with_python_side_effect(2))\n",
        "print(a_function_with_python_side_effect(3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtN8NW6AfKye"
      },
      "source": [
        "새 Python 인수는 항상 새 그래프 생성을 트리거하므로 추가 트레이싱이 발생합니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1kbr5ocpS6R"
      },
      "source": [
        "## 다음 단계\n",
        "\n",
        "API 참조 페이지와 [`tf.function`으로 성능 향상하기](function.ipynb) 가이드에서 `tf.function`에 대한 자세한 내용을 확인할 수 있습니다."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "intro_to_graphs.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
