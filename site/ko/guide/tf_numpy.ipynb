{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjN_IJ8mhJ-4"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "sY3Ffd83hK3b"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03Pw58e6mTHI"
      },
      "source": [
        "# TensorFlow 기반의 NumPy API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WpGysDJmZsg"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>     <a target=\"_blank\" href=\"https://www.tensorflow.org/guide/tf_numpy\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">TensorFlow.org에서 보기</a>   </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/guide/tf_numpy.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/guide/tf_numpy.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">GitHub에서 소스 보기</a>   </td>\n",
        "  <td>\n",
        "    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/guide/tf_numpy.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Download notebook</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2enCDi_FvCR"
      },
      "source": [
        "## 개요\n",
        "\n",
        "TensorFlow는 `tf.experimental.numpy`로 사용할 수 있는 [NumPy API](https://numpy.org/doc/1.16)의 하위 집합을 구현합니다. 이를 통해 TensorFlow에서 NumPy 코드를 빠르게 실행할 수 있으며 TensorFlow의 모든 API에 액세스할 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ob1HNwUmYR5b"
      },
      "source": [
        "## 설정\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AJR558zjAZQu"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow.experimental.numpy as tnp\n",
        "import timeit\n",
        "\n",
        "print(\"Using TensorFlow version %s\" % tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6tacoy0DU6e"
      },
      "source": [
        "### NumPy 동작 사용\n",
        "\n",
        "`tnp`를 NumPy로 사용하려면 TensorFlow에 대해 NumPy 동작을 활성화합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TfCyofpFDQxm"
      },
      "outputs": [],
      "source": [
        "tnp.experimental_enable_numpy_behavior()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "et9D5wq0D1H2"
      },
      "source": [
        "이 호출은 TensorFlow에서 유형 승격을 활성화하고, 리터럴을 텐서로 변환할 때 유형 추론을 변경하여 NumPy 표준을 보다 엄격하게 따릅니다.\n",
        "\n",
        "참고: 이 호출은 `tf.experimental.numpy` 모듈뿐만 아니라 전체 TensorFlow의 동작을 변경합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yh2BwqUzH3C3"
      },
      "source": [
        "## TensorFlow NumPy ND 배열\n",
        "\n",
        "**ND 배열**이라는 `tf.experimental.numpy.ndarray`의 인스턴스는 특정 기기에 배치된 주어진 `dtype`의 다차원 고밀도 배열을 나타냅니다. 이것은 `tf.Tensor`에 대한 별칭입니다. `ndarray.T`, `ndarray.reshape`, `ndarray.ravel` 등과 같은 유용한 메서드를 위한 ND 배열 클래스를 확인해 보세요.\n",
        "\n",
        "먼저 ND 배열 객체를 만든 다음, 다양한 메서드를 호출합니다. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-BHJjxigJ2H1"
      },
      "outputs": [],
      "source": [
        "# Create an ND array and check out different attributes.\n",
        "ones = tnp.ones([5, 3], dtype=tnp.float32)\n",
        "print(\"Created ND array with shape = %s, rank = %s, \"\n",
        "      \"dtype = %s on device = %s\\n\" % (\n",
        "          ones.shape, ones.ndim, ones.dtype, ones.device))\n",
        "\n",
        "# `ndarray` is just an alias to `tf.Tensor`.\n",
        "print(\"Is `ones` an instance of tf.Tensor: %s\\n\" % isinstance(ones, tf.Tensor))\n",
        "\n",
        "# Try commonly used member functions.\n",
        "print(\"ndarray.T has shape %s\" % str(ones.T.shape))\n",
        "print(\"narray.reshape(-1) has shape %s\" % ones.reshape(-1).shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mub8-dvJMUr4"
      },
      "source": [
        "### 형식 승격\n",
        "\n",
        "TensorFlow NumPy API에는 리터럴을 ND 배열로 변환하고 ND 배열 입력에 대해 형식 승격을 수행하기 위한 잘 정의된 의미 체계가 있습니다. 자세한 내용은 [`np.result_type`](https://numpy.org/doc/1.16/reference/generated/numpy.result_type.html)을 참조하세요."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcRznNaMj27J"
      },
      "source": [
        "TensorFlow API는 `tf.Tensor` 입력을 변경하지 않고 유형 승격을 수행하지 않는 반면, TensorFlow NumPy API는 NumPy 유형 승격 규칙에 따라 모든 입력을 승격합니다. 다음 예에서는 유형 승격을 수행합니다. 먼저, 서로 다른 유형의 ND 배열 입력에 추가를 실행하고 출력 유형을 기록합니다. 이러한 유형의 승격은 TensorFlow API에서 허용되지 않습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uHmBi4KZI2t1"
      },
      "outputs": [],
      "source": [
        "print(\"Type promotion for operations\")\n",
        "values = [tnp.asarray(1, dtype=d) for d in\n",
        "          (tnp.int32, tnp.int64, tnp.float32, tnp.float64)]\n",
        "for i, v1 in enumerate(values):\n",
        "  for v2 in values[i + 1:]:\n",
        "    print(\"%s + %s => %s\" % \n",
        "          (v1.dtype.name, v2.dtype.name, (v1 + v2).dtype.name))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrpIoOc7oqox"
      },
      "source": [
        "마지막으로, `ndarray.asarray`를 사용하여 리터럴을 ND 배열로 변환하고 결과 유형을 확인합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1m1cp8_VooNk"
      },
      "outputs": [],
      "source": [
        "print(\"Type inference during array creation\")\n",
        "print(\"tnp.asarray(1).dtype == tnp.%s\" % tnp.asarray(1).dtype.name)\n",
        "print(\"tnp.asarray(1.).dtype == tnp.%s\\n\" % tnp.asarray(1.).dtype.name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kd-_iccXoRL8"
      },
      "source": [
        "리터럴을 ND 배열로 변환할 때 NumPy는 `tnp.int64` 및 `tnp.float64`와 같은 넓은 유형을 선호합니다. 반대로 `tf.convert_to_tensor`는 상수를 `tf.Tensor`로 변환하기 위해 `tf.int32` 및 `tf.float32` 유형을 선호합니다. TensorFlow NumPy API는 정수에 대한 NumPy 동작을 준수합니다. 부동 소수점의 경우, `experimental_enable_numpy_behavior`의 `prefer_float32` 인수를 사용하여 `tf.float64`에 비해 `tf.float32`를 선호할지 여부를 제어할 수 있습니다(기본적으로 `False`). 예를 들면 다음과 같습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4gKasnH0j84C"
      },
      "outputs": [],
      "source": [
        "tnp.experimental_enable_numpy_behavior(prefer_float32=True)\n",
        "print(\"When prefer_float32 is True:\")\n",
        "print(\"tnp.asarray(1.).dtype == tnp.%s\" % tnp.asarray(1.).dtype.name)\n",
        "print(\"tnp.add(1., 2.).dtype == tnp.%s\" % tnp.add(1., 2.).dtype.name)\n",
        "\n",
        "tnp.experimental_enable_numpy_behavior(prefer_float32=False)\n",
        "print(\"When prefer_float32 is False:\")\n",
        "print(\"tnp.asarray(1.).dtype == tnp.%s\" % tnp.asarray(1.).dtype.name)\n",
        "print(\"tnp.add(1., 2.).dtype == tnp.%s\" % tnp.add(1., 2.).dtype.name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwCCDxSZOfA1"
      },
      "source": [
        "### 브로드캐스팅\n",
        "\n",
        "TensorFlow와 유사하게 NumPy는 \"브로드캐스팅\" 값에 대한 풍부한 의미 체계를 정의합니다. 자세한 내용은 [NumPy 브로드캐스팅 가이드](https://numpy.org/doc/stable/user/basics.broadcasting.html)를 확인하고 [TensorFlow 브로드캐스팅 의미 체계](https://www.tensorflow.org/guide/tensor#broadcasting)와 비교할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qlyOShxIO0s2"
      },
      "outputs": [],
      "source": [
        "x = tnp.ones([2, 3])\n",
        "y = tnp.ones([3])\n",
        "z = tnp.ones([1, 2, 1])\n",
        "print(\"Broadcasting shapes %s, %s and %s gives shape %s\" % (\n",
        "    x.shape, y.shape, z.shape, (x + y + z).shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEVr4ctRPrqR"
      },
      "source": [
        "### 인덱싱\n",
        "\n",
        "NumPy는 매우 정교한 인덱싱 규칙을 정의합니다. [NumPy 인덱싱 가이드](https://numpy.org/doc/stable/reference/arrays.indexing.html)를 참조하세요. 아래 인덱스로 ND 배열을 사용합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lRsrtnd3YyMj"
      },
      "outputs": [],
      "source": [
        "x = tnp.arange(24).reshape(2, 3, 4)\n",
        "\n",
        "print(\"Basic indexing\")\n",
        "print(x[1, tnp.newaxis, 1:3, ...], \"\\n\")\n",
        "\n",
        "print(\"Boolean indexing\")\n",
        "print(x[:, (True, False, True)], \"\\n\")\n",
        "\n",
        "print(\"Advanced indexing\")\n",
        "print(x[1, (0, 0, 1), tnp.asarray([0, 1, 1])])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yRAaiGhlaNw7"
      },
      "outputs": [],
      "source": [
        "# Mutation is currently not supported\n",
        "try:\n",
        "  tnp.arange(6)[1] = -1\n",
        "except TypeError:\n",
        "  print(\"Currently, TensorFlow NumPy does not support mutation.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XfJ602j-GVD"
      },
      "source": [
        "### 예시 모델\n",
        "\n",
        "다음으로, 모델을 만들고 추론을 실행하는 방법을 볼 수 있습니다. 이 간단한 모델은 relu 레이어와 직선 투영법(linear projection)을 적용합니다. 이후 섹션에서는 TensorFlow의 `GradientTape`를 사용하여 모델의 그래디언트를 계산하는 방법을 보여줍니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kR_KCh4kYEhm"
      },
      "outputs": [],
      "source": [
        "class Model(object):\n",
        "  \"\"\"Model with a dense and a linear layer.\"\"\"\n",
        "\n",
        "  def __init__(self):\n",
        "    self.weights = None\n",
        "\n",
        "  def predict(self, inputs):\n",
        "    if self.weights is None:\n",
        "      size = inputs.shape[1]\n",
        "      # Note that type `tnp.float32` is used for performance.\n",
        "      stddev = tnp.sqrt(size).astype(tnp.float32)\n",
        "      w1 = tnp.random.randn(size, 64).astype(tnp.float32) / stddev\n",
        "      bias = tnp.random.randn(64).astype(tnp.float32)\n",
        "      w2 = tnp.random.randn(64, 2).astype(tnp.float32) / 8\n",
        "      self.weights = (w1, bias, w2)\n",
        "    else:\n",
        "      w1, bias, w2 = self.weights\n",
        "    y = tnp.matmul(inputs, w1) + bias\n",
        "    y = tnp.maximum(y, 0)  # Relu\n",
        "    return tnp.matmul(y, w2)  # Linear projection\n",
        "\n",
        "model = Model()\n",
        "# Create input data and compute predictions.\n",
        "print(model.predict(tnp.ones([2, 32], dtype=tnp.float32)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSR7Ou5YcS38"
      },
      "source": [
        "## TensorFlow NumPy 및 NumPy\n",
        "\n",
        "TensorFlow NumPy는 전체 NumPy 사양의 하위 집합을 구현합니다. 시간이 지남에 따라 더 많은 기호가 추가되지만, 가까운 장래에 지원되지 않는 체계적인 기능이 있습니다. 여기에는 NumPy C API 지원, Swig 통합, Fortran 저장 순서, 뷰 및 `stride_tricks` 및 일부 `dtype`(예: `np.recarray` 및 `np.object`)이 포함됩니다. 자세한 내용은 [TensorFlow NumPy API 설명서](https://www.tensorflow.org/api_docs/python/tf/experimental/numpy)를 참조하세요.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jb1KXak2YlNN"
      },
      "source": [
        "### NumPy 상호 운용성\n",
        "\n",
        "TensorFlow ND 배열은 NumPy 함수와 상호 운용될 수 있습니다. 이러한 객체는 `__array__` 인터페이스를 구현합니다. NumPy는 이 인터페이스를 사용하여 함수 인수를 처리하기 전에 `np.ndarray` 값으로 변환합니다.\n",
        "\n",
        "마찬가지로, TensorFlow NumPy 함수는 `np.ndarray`를 포함하여 다양한 형식의 입력을 받을 수 있습니다. 이러한 입력은 `ndarray.asarray`를 호출하여 ND 배열로 변환됩니다.\n",
        "\n",
        "ND 배열과 `np.ndarray` 간의 변환은 실제 데이터 복사를 트리거할 수 있습니다. 자세한 내용은 [버퍼 복사본](#Buffer-copies) 섹션을 참조하세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cMOCgzQmeXRU"
      },
      "outputs": [],
      "source": [
        "# ND array passed into NumPy function.\n",
        "np_sum = np.sum(tnp.ones([2, 3]))\n",
        "print(\"sum = %s. Class: %s\" % (float(np_sum), np_sum.__class__))\n",
        "\n",
        "# `np.ndarray` passed into TensorFlow NumPy function.\n",
        "tnp_sum = tnp.sum(np.ones([2, 3]))\n",
        "print(\"sum = %s. Class: %s\" % (float(tnp_sum), tnp_sum.__class__))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZaLPjzxft780"
      },
      "outputs": [],
      "source": [
        "# It is easy to plot ND arrays, given the __array__ interface.\n",
        "labels = 15 + 2 * tnp.random.randn(1, 1000)\n",
        "_ = plt.hist(labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kF-Xyw3XWKqJ"
      },
      "source": [
        "### 버퍼 복사본\n",
        "\n",
        "TensorFlow NumPy와 NumPy 코드를 혼합하면 데이터 복사가 트리거될 수 있습니다. 이는 TensorFlow NumPy가 NumPy보다 메모리 정렬에 대한 요구 사항이 더 엄격하기 때문입니다.\n",
        "\n",
        "When a `np.ndarray` is passed to TensorFlow NumPy, it will check for alignment requirements and trigger a copy if needed. When passing an ND array CPU buffer to NumPy, generally the buffer will satisfy alignment requirements and NumPy will not need to create a copy.\n",
        "\n",
        "ND 배열은 로컬 CPU 메모리가 아닌 기기에 배치된 버퍼를 참조할 수 있습니다. 이러한 경우, NumPy 함수를 호출하면 필요에 따라 네트워크 또는 기기에서 복사본이 트리거됩니다.\n",
        "\n",
        "Given this, intermixing with NumPy API calls should generally be done with caution and the user should watch out for overheads of copying data. Interleaving TensorFlow NumPy calls with TensorFlow calls is generally safe and avoids copying data. See the section on [TensorFlow interoperability](#tensorflow-interoperability) for more details."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RwljbqkBc7Ro"
      },
      "source": [
        "### 연산자 우선 순위\n",
        "\n",
        "TensorFlow NumPy는 NumPy보다 높은 `__array_priority__`를 정의합니다. 즉, ND 배열과 `np.ndarray`를 둘 다 포함하는 연산자의 경우, 전자가 우선합니다. 즉, `np.ndarray` 입력이 ND 배열로 변환되고 연산자의 TensorFlow NumPy 구현이 호출됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cbw8a3G_WUO7"
      },
      "outputs": [],
      "source": [
        "x = tnp.ones([2]) + np.ones([2])\n",
        "print(\"x = %s\\nclass = %s\" % (x, x.__class__))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNEab_Ctky83"
      },
      "source": [
        "## TF NumPy 및 TensorFlow\n",
        "\n",
        "TensorFlow NumPy는 TensorFlow를 기반으로 하므로 TensorFlow와 원활하게 상호 운용됩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fCcfgrlOnAhQ"
      },
      "source": [
        "### `tf.Tensor` 및 ND 배열\n",
        "\n",
        "ND 배열은 `tf.Tensor`에 대한 별칭이므로 실제 데이터 복사를 트리거하지 않고 서로 혼합될 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BkHVauKwnky_"
      },
      "outputs": [],
      "source": [
        "x = tf.constant([1, 2])\n",
        "print(x)\n",
        "\n",
        "# `asarray` and `convert_to_tensor` here are no-ops.\n",
        "tnp_x = tnp.asarray(x)\n",
        "print(tnp_x)\n",
        "print(tf.convert_to_tensor(tnp_x))\n",
        "\n",
        "# Note that tf.Tensor.numpy() will continue to return `np.ndarray`.\n",
        "print(x.numpy(), x.numpy().__class__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_151HQVBooxG"
      },
      "source": [
        "### TensorFlow 상호 운용성\n",
        "\n",
        "ND 배열은 단지 `tf.Tensor`에 대한 별칭이기 때문에 ND 배열을 TensorFlow API에 전달할 수 있습니다. 앞서 언급했듯이, 이러한 상호 연산은 가속기 또는 원격 기기에 있는 데이터의 경우에도 실제로 데이터 복사를 수행하지 않습니다.\n",
        "\n",
        "반대로, `tf.Tensor` 객체는 데이터 복사를 수행하지 않고 `tf.experimental.numpy` API로 전달할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-QvxNhrFoz09"
      },
      "outputs": [],
      "source": [
        "# ND array passed into TensorFlow function.\n",
        "tf_sum = tf.reduce_sum(tnp.ones([2, 3], tnp.float32))\n",
        "print(\"Output = %s\" % tf_sum)\n",
        "\n",
        "# `tf.Tensor` passed into TensorFlow NumPy function.\n",
        "tnp_sum = tnp.sum(tf.ones([2, 3]))\n",
        "print(\"Output = %s\" % tnp_sum)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1b4HeAkhprF_"
      },
      "source": [
        "### 그래디언트 및 야고비 행렬식: tf.GradientTape\n",
        "\n",
        "TensorFlow의 GradientTape는 TensorFlow 및 TensorFlow NumPy 코드를 통한 역전파에 사용할 수 있습니다.\n",
        "\n",
        "[예시 모델](#example-model) 섹션에서 생성된 모델을 사용하고 그래디언트와 야고비 행렬식을 계산합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T47C9KS8pbsP"
      },
      "outputs": [],
      "source": [
        "def create_batch(batch_size=32):\n",
        "  \"\"\"Creates a batch of input and labels.\"\"\"\n",
        "  return (tnp.random.randn(batch_size, 32).astype(tnp.float32),\n",
        "          tnp.random.randn(batch_size, 2).astype(tnp.float32))\n",
        "\n",
        "def compute_gradients(model, inputs, labels):\n",
        "  \"\"\"Computes gradients of squared loss between model prediction and labels.\"\"\"\n",
        "  with tf.GradientTape() as tape:\n",
        "    assert model.weights is not None\n",
        "    # Note that `model.weights` need to be explicitly watched since they\n",
        "    # are not tf.Variables.\n",
        "    tape.watch(model.weights)\n",
        "    # Compute prediction and loss\n",
        "    prediction = model.predict(inputs)\n",
        "    loss = tnp.sum(tnp.square(prediction - labels))\n",
        "  # This call computes the gradient through the computation above.\n",
        "  return tape.gradient(loss, model.weights)\n",
        "\n",
        "inputs, labels = create_batch()\n",
        "gradients = compute_gradients(model, inputs, labels)\n",
        "\n",
        "# Inspect the shapes of returned gradients to verify they match the\n",
        "# parameter shapes.\n",
        "print(\"Parameter shapes:\", [w.shape for w in model.weights])\n",
        "print(\"Gradient shapes:\", [g.shape for g in gradients])\n",
        "# Verify that gradients are of type ND array.\n",
        "assert isinstance(gradients[0], tnp.ndarray)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TujVPDFwrdqp"
      },
      "outputs": [],
      "source": [
        "# Computes a batch of jacobians. Each row is the jacobian of an element in the\n",
        "# batch of outputs w.r.t. the corresponding input batch element.\n",
        "def prediction_batch_jacobian(inputs):\n",
        "  with tf.GradientTape() as tape:\n",
        "    tape.watch(inputs)\n",
        "    prediction = model.predict(inputs)\n",
        "  return prediction, tape.batch_jacobian(prediction, inputs)\n",
        "\n",
        "inp_batch = tnp.ones([16, 32], tnp.float32)\n",
        "output, batch_jacobian = prediction_batch_jacobian(inp_batch)\n",
        "# Note how the batch jacobian shape relates to the input and output shapes.\n",
        "print(\"Output shape: %s, input shape: %s\" % (output.shape, inp_batch.shape))\n",
        "print(\"Batch jacobian shape:\", batch_jacobian.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYq9wxfc1Dv_"
      },
      "source": [
        "### 추적 컴파일: tf.function\n",
        "\n",
        "TensorFlow's `tf.function` works by \"trace compiling\" the code and then optimizing these traces for much faster performance. See the [Introduction to Graphs and Functions](./intro_to_graphs.ipynb).\n",
        "\n",
        "`tf.function`은 TensorFlow NumPy 코드를 최적화하는 데에도 사용할 수 있습니다. 다음은 속도 향상을 보여주는 간단한 예입니다. `tf.function` 코드의 본문에는 TensorFlow NumPy API에 대한 호출이 포함됩니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "05SrUulm1OlL"
      },
      "outputs": [],
      "source": [
        "inputs, labels = create_batch(512)\n",
        "print(\"Eager performance\")\n",
        "compute_gradients(model, inputs, labels)\n",
        "print(timeit.timeit(lambda: compute_gradients(model, inputs, labels),\n",
        "                    number=10) * 100, \"ms\")\n",
        "\n",
        "print(\"\\ntf.function compiled performance\")\n",
        "compiled_compute_gradients = tf.function(compute_gradients)\n",
        "compiled_compute_gradients(model, inputs, labels)  # warmup\n",
        "print(timeit.timeit(lambda: compiled_compute_gradients(model, inputs, labels),\n",
        "                    number=10) * 100, \"ms\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5w8YxR6ELmo1"
      },
      "source": [
        "### 벡터화: tf.vectorized_map\n",
        "\n",
        "TensorFlow는 병렬 루프를 벡터화하는 기능을 내장하여 속도를 1~2배 높일 수 있습니다. 이러한 속도 향상은 `tf.vectorized_map` API를 통해 액세스할 수 있으며 TensorFlow NumPy 코드에도 적용됩니다.\n",
        "\n",
        "해당 입력 배치 요소에 대해 배치에서 각 출력의 그래디언트를 계산하는 것이 때때로 유용합니다. 이러한 계산은 아래와 같이 `tf.vectorized_map` 을 사용하여 효율적으로 수행할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PemSIrs5L-VJ"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def vectorized_per_example_gradients(inputs, labels):\n",
        "  def single_example_gradient(arg):\n",
        "    inp, label = arg\n",
        "    return compute_gradients(model,\n",
        "                             tnp.expand_dims(inp, 0),\n",
        "                             tnp.expand_dims(label, 0))\n",
        "  # Note that a call to `tf.vectorized_map` semantically maps\n",
        "  # `single_example_gradient` over each row of `inputs` and `labels`.\n",
        "  # The interface is similar to `tf.map_fn`.\n",
        "  # The underlying machinery vectorizes away this map loop which gives\n",
        "  # nice speedups.\n",
        "  return tf.vectorized_map(single_example_gradient, (inputs, labels))\n",
        "\n",
        "batch_size = 128\n",
        "inputs, labels = create_batch(batch_size)\n",
        "\n",
        "per_example_gradients = vectorized_per_example_gradients(inputs, labels)\n",
        "for w, p in zip(model.weights, per_example_gradients):\n",
        "  print(\"Weight shape: %s, batch size: %s, per example gradient shape: %s \" % (\n",
        "      w.shape, batch_size, p.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_QZ5BjJmRAlG"
      },
      "outputs": [],
      "source": [
        "# Benchmark the vectorized computation above and compare with\n",
        "# unvectorized sequential computation using `tf.map_fn`.\n",
        "@tf.function\n",
        "def unvectorized_per_example_gradients(inputs, labels):\n",
        "  def single_example_gradient(arg):\n",
        "    inp, label = arg\n",
        "    return compute_gradients(model,\n",
        "                             tnp.expand_dims(inp, 0),\n",
        "                             tnp.expand_dims(label, 0))\n",
        "\n",
        "  return tf.map_fn(single_example_gradient, (inputs, labels),\n",
        "                   fn_output_signature=(tf.float32, tf.float32, tf.float32))\n",
        "\n",
        "print(\"Running vectorized computation\")\n",
        "print(timeit.timeit(lambda: vectorized_per_example_gradients(inputs, labels),\n",
        "                    number=10) * 100, \"ms\")\n",
        "\n",
        "print(\"\\nRunning unvectorized computation\")\n",
        "per_example_gradients = unvectorized_per_example_gradients(inputs, labels)\n",
        "print(timeit.timeit(lambda: unvectorized_per_example_gradients(inputs, labels),\n",
        "                    number=10) * 100, \"ms\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOTh-nkzaJd9"
      },
      "source": [
        "### 기기 배치\n",
        "\n",
        "TensorFlow NumPy는 CPU, GPU, TPU 및 원격 기기에 연산을 배치할 수 있습니다. 기기 배치를 위한 표준 TensorFlow 메커니즘을 사용합니다. 아래의 간단한 예는 모든 기기를 나열한 다음 특정 기기에 계산을 배치하는 방법을 보여줍니다.\n",
        "\n",
        "TensorFlow에는 또한 기기 간에 계산을 복제하고 여기에서 다루지 않을 집단 감소(collective reduction)를 수행하기 위한 API가 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0gHrwYYaTCE"
      },
      "source": [
        "#### 기기 나열하기\n",
        "\n",
        "`tf.config.list_logical_devices` 및 `tf.config.list_physical_devices`를 사용하여 사용할 기기를 찾을 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NDEAd9m9aemS"
      },
      "outputs": [],
      "source": [
        "print(\"All logical devices:\", tf.config.list_logical_devices())\n",
        "print(\"All physical devices:\", tf.config.list_physical_devices())\n",
        "\n",
        "# Try to get the GPU device. If unavailable, fallback to CPU.\n",
        "try:\n",
        "  device = tf.config.list_logical_devices(device_type=\"GPU\")[0]\n",
        "except IndexError:\n",
        "  device = \"/device:CPU:0\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fihgfF_tahVx"
      },
      "source": [
        "#### 연산 배치하기: **`tf.device`**\n",
        "\n",
        "`tf.device` 범위에서 호출하여 기기에 연산을 배치할 수 있습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c7ELvLmnazfV"
      },
      "outputs": [],
      "source": [
        "print(\"Using device: %s\" % str(device))\n",
        "# Run operations in the `tf.device` scope.\n",
        "# If a GPU is available, these operations execute on the GPU and outputs are\n",
        "# placed on the GPU memory.\n",
        "with tf.device(device):\n",
        "  prediction = model.predict(create_batch(5)[0])\n",
        "\n",
        "print(\"prediction is placed on %s\" % prediction.device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-LK6wsHbBiM"
      },
      "source": [
        "#### 기기 간에 ND 배열 복사하기: **`tnp.copy`**\n",
        "\n",
        "특정 기기 범위에 배치된 `tnp.copy`를 호출하면 데이터가 해당 기기에 이미 있는 경우를 제외하고 해당 기기에 데이터를 복사합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CCesyidaa-UT"
      },
      "outputs": [],
      "source": [
        "with tf.device(\"/device:CPU:0\"):\n",
        "  prediction_cpu = tnp.copy(prediction)\n",
        "print(prediction.device)\n",
        "print(prediction_cpu.device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AiYzRDOtKzAH"
      },
      "source": [
        "## 성능 비교\n",
        "\n",
        "TensorFlow NumPy는 CPU, GPU, TPU에서 디스패치될 수 있는 고도로 최적화된 TensorFlow 커널을 사용합니다. TensorFlow는 또한 연산 융합과 같은 많은 컴파일러 최적화를 수행하며, 이는 성능 및 메모리 개선으로 이어집니다. 자세한 내용은 [Gradler를 사용한 TensorFlow 그래프 최적화](./graph_optimization.ipynb)를 참조하세요.\n",
        "\n",
        "그러나 TensorFlow는 NumPy와 비교하여 디스패치 연산에 대한 오버헤드가 더 높습니다. 소규모 연산(약 10마이크로초 미만)으로 구성된 워크로드의 경우 이러한 오버헤드가 런타임에서 우세할 수 있으며 NumPy가 더 나은 성능을 제공할 수 있습니다. 다른 경우에는 일반적으로 TensorFlow가 더 나은 성능을 제공합니다.\n",
        "\n",
        "아래 벤치마크를 실행하여 다양한 입력 크기에서 NumPy와 TensorFlow Numpy의 성능을 비교해 보세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "code",
        "id": "RExwjI9_pJG0"
      },
      "outputs": [],
      "source": [
        "def benchmark(f, inputs, number=30, force_gpu_sync=False):\n",
        "  \"\"\"Utility to benchmark `f` on each value in `inputs`.\"\"\"\n",
        "  times = []\n",
        "  for inp in inputs:\n",
        "    def _g():\n",
        "      if force_gpu_sync:\n",
        "        one = tnp.asarray(1)\n",
        "      f(inp)\n",
        "      if force_gpu_sync:\n",
        "        with tf.device(\"CPU:0\"):\n",
        "          tnp.copy(one)  # Force a sync for GPU case\n",
        "\n",
        "    _g()  # warmup\n",
        "    t = timeit.timeit(_g, number=number)\n",
        "    times.append(t * 1000. / number)\n",
        "  return times\n",
        "\n",
        "\n",
        "def plot(np_times, tnp_times, compiled_tnp_times, has_gpu, tnp_times_gpu):\n",
        "  \"\"\"Plot the different runtimes.\"\"\"\n",
        "  plt.xlabel(\"size\")\n",
        "  plt.ylabel(\"time (ms)\")\n",
        "  plt.title(\"Sigmoid benchmark: TF NumPy vs NumPy\")\n",
        "  plt.plot(sizes, np_times, label=\"NumPy\")\n",
        "  plt.plot(sizes, tnp_times, label=\"TF NumPy (CPU)\")\n",
        "  plt.plot(sizes, compiled_tnp_times, label=\"Compiled TF NumPy (CPU)\")\n",
        "  if has_gpu:\n",
        "    plt.plot(sizes, tnp_times_gpu, label=\"TF NumPy (GPU)\")\n",
        "  plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p-fs_H1lkLfV"
      },
      "outputs": [],
      "source": [
        "# Define a simple implementation of `sigmoid`, and benchmark it using\n",
        "# NumPy and TensorFlow NumPy for different input sizes.\n",
        "\n",
        "def np_sigmoid(y):\n",
        "  return 1. / (1. + np.exp(-y))\n",
        "\n",
        "def tnp_sigmoid(y):\n",
        "  return 1. / (1. + tnp.exp(-y))\n",
        "\n",
        "@tf.function\n",
        "def compiled_tnp_sigmoid(y):\n",
        "  return tnp_sigmoid(y)\n",
        "\n",
        "sizes = (2 ** 0, 2 ** 5, 2 ** 10, 2 ** 15, 2 ** 20)\n",
        "np_inputs = [np.random.randn(size).astype(np.float32) for size in sizes]\n",
        "np_times = benchmark(np_sigmoid, np_inputs)\n",
        "\n",
        "with tf.device(\"/device:CPU:0\"):\n",
        "  tnp_inputs = [tnp.random.randn(size).astype(np.float32) for size in sizes]\n",
        "  tnp_times = benchmark(tnp_sigmoid, tnp_inputs)\n",
        "  compiled_tnp_times = benchmark(compiled_tnp_sigmoid, tnp_inputs)\n",
        "\n",
        "has_gpu = len(tf.config.list_logical_devices(\"GPU\"))\n",
        "if has_gpu:\n",
        "  with tf.device(\"/device:GPU:0\"):\n",
        "    tnp_inputs = [tnp.random.randn(size).astype(np.float32) for size in sizes]\n",
        "    tnp_times_gpu = benchmark(compiled_tnp_sigmoid, tnp_inputs, 100, True)\n",
        "else:\n",
        "  tnp_times_gpu = None\n",
        "plot(np_times, tnp_times, compiled_tnp_times, has_gpu, tnp_times_gpu)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ReK_9k5D8BZQ"
      },
      "source": [
        "## 추가 자료\n",
        "\n",
        "- [TensorFlow NumPy: Distributed Image Classification Tutorial](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/numpy_ops/g3doc/TensorFlow_Numpy_Distributed_Image_Classification.ipynb)\n",
        "- [TensorFlow NumPy: Keras and Distribution Strategy](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/numpy_ops/g3doc/TensorFlow_NumPy_Keras_and_Distribution_Strategy.ipynb)\n",
        "- [Sentiment Analysis with Trax and TensorFlow NumPy](https://github.com/google/trax/blob/master/trax/tf_numpy_and_keras.ipynb)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "tf_numpy.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
