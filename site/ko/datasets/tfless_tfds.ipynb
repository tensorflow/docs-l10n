{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_nWetWWd_ns"
      },
      "source": [
        "##### Copyright 2023 The TensorFlow Datasets Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "2pHVBk_seED1"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7vSdG6sAIQn"
      },
      "source": [
        "# Jax 및 PyTorch를 위한 TFDS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwc5GKHBASdc"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td><a target=\"_blank\" href=\"https://www.tensorflow.org/datasets/tfless_tfds\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">TensorFlow.org에서 보기</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/ko/datasets/tfless_tfds.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Google Colab에서 실행하기</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/ko/datasets/tfless_tfds.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">GitHub에서 소스 보기</a></td>\n",
        "  <td><a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/ko/datasets/tfless_tfds.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">노트북 다운로드하기</a></td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ee074e4"
      },
      "source": [
        "TFDS는 항상 프레임워크에 구애받지 않았습니다. 예를 들어, Jax 및 PyTorch에서 사용할 데이터세트를 [NumPy 형식](https://www.tensorflow.org/datasets/api_docs/python/tfds/as_numpy)으로 쉽게 로드할 수 있습니다.\n",
        "\n",
        "TensorFlow와 TensorFlow의 데이터 로딩 솔루션([`tf.data`](https://www.tensorflow.org/guide/data))은 설계상 우리 API의 1등 시민입니다.\n",
        "\n",
        "TensorFlow가 없는 NumPy 전용 데이터 로드를 지원하도록 TFDS를 확장했습니다. 그러면 Jax나 PyTorch와 같은 ML 프레임워크에서 사용하기에 편리할 수 있습니다. 실제로 이후의 사용자들을 위해 TensorFlow는 다음을 수행할 수 있습니다.\n",
        "\n",
        "- GPU/TPU 메모리 예약\n",
        "- CI/CD에서 빌드 시간을 연장\n",
        "- 런타임에서 가져오는 시간을 소요\n",
        "\n",
        "TensorFlow는 더 이상 데이터세트 읽기에 종속적이지 않습니다.\n",
        "\n",
        "ML 파이프라인은 예제를 로드하고 디코딩하여 모델에 표시하기 위해 데이터 로더를 필요로 합니다. 데이터 로더는 '소스/샘플러/로더' 패러다임을 사용합니다.\n",
        "\n",
        "```\n",
        " TFDS dataset       ┌────────────────┐\n",
        "   on disk          │                │\n",
        "        ┌──────────►│      Data      │\n",
        "|..|... │     |     │     source     ├─┐\n",
        "├──┼────┴─────┤     │                │ │\n",
        "│12│image12   │     └────────────────┘ │    ┌────────────────┐\n",
        "├──┼──────────┤                        │    │                │\n",
        "│13│image13   │                        ├───►│      Data      ├───► ML pipeline\n",
        "├──┼──────────┤                        │    │     loader     │\n",
        "│14│image14   │     ┌────────────────┐ │    │                │\n",
        "├──┼──────────┤     │                │ │    └────────────────┘\n",
        "|..|...       |     │     Index      ├─┘\n",
        "                    │    sampler     │\n",
        "                    │                │\n",
        "                    └────────────────┘\n",
        "```\n",
        "\n",
        "- 데이터 소스는 TFDS 데이터세트의 예제에 즉시 액세스하고 디코딩하는 역할을 담당합니다.\n",
        "- 인덱스 샘플러는 레코드를 처리하는 순서를 결정합니다. 이는 레코드를 읽기 전에 전역 변환(예: 전역 셔플링, 샤딩, 여러 에포크 반복)을 현하는 데 중요합니다.\n",
        "- 데이터 로더는 데이터 소스와 인덱스 샘플러를 활용하여 로드를 오케스트레이션합니다. 이를 통해 성능 최적화(예: 프리페칭, 멀티 프로세싱 또는 멀티 스레딩)가 가능합니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UaWdLA3fQDK2"
      },
      "source": [
        "## TL;DR\n",
        "\n",
        "`tfds.data_source`는 데이터 소스를 생성하기 위한 API입니다.\n",
        "\n",
        "1. 순수 Python 파이프라인에서 빠른 프로토타이핑이 목적\n",
        "2. 데이터 집약적인 ML 파이프라인을 대규모로 관리"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLho3l_Vd0a5"
      },
      "source": [
        "## 설치하기\n",
        "\n",
        "필요한 종속성을 설치하고 가져오겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c4COEsqIdvYH"
      },
      "outputs": [],
      "source": [
        "!pip install array_record\n",
        "!pip install tfds-nightly\n",
        "\n",
        "import os\n",
        "os.environ.pop('TFDS_DATA_DIR', None)\n",
        "\n",
        "import tensorflow_datasets as tfds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjEJeF1Id_JM"
      },
      "source": [
        "## 데이터 소스\n",
        "\n",
        "데이터 소스는 기본적으로 Python 시퀀스입니다. 따라서 다음 프로토콜을 구현해야 합니다.\n",
        "\n",
        "```python\n",
        "class RandomAccessDataSource(Protocol):\n",
        "  \"\"\"Interface for datasources where storage supports efficient random access.\"\"\"\n",
        "\n",
        "  def __len__(self) -> int:\n",
        "    \"\"\"Number of records in the dataset.\"\"\"\n",
        "\n",
        "  def __getitem__(self, record_key: int) -> Sequence[Any]:\n",
        "    \"\"\"Retrieves records for the given record_keys.\"\"\"\n",
        "```\n",
        "\n",
        "**경고**: 이 API는 아직 개발 중입니다. 특히 이 시점에서 `__getitem__`은 입력으로 `int` 및 `list[int]`를 모두 지원해야 합니다. 앞으로는 [표준](https://docs.python.org/3/reference/datamodel.html#object.__getitem__)에 따라 `int`만 지원할 것입니다.\n",
        "\n",
        "기본 파일 형식은 효율적인 랜덤 액세스를 지원해야 합니다. 현재 TFDS는 [`array_record`](https://github.com/google/array_record)에 의존합니다.\n",
        "\n",
        "[`array_record`](https://github.com/google/array_record)는 [Riegeli](https://github.com/google/riegeli)에서 파생된 새로운 파일 형식으로 IO 효율성의 새로운 지평을 열었습니다. 특히 ArrayRecord는 레코드 인덱스로 병렬 읽기, 쓰기 및 랜덤 액세스를 지원합니다. ArrayRecord는 Riegeli를 기반으로 구축되며 동일한 압축 알고리즘을 지원합니다.\n",
        "\n",
        "[`fashion_mnist`](https://www.tensorflow.org/datasets/catalog/fashion_mnist)는 컴퓨터 비전용 일반 데이터세트입니다. TFDS로 ArrayRecord 기반 데이터 소스를 검색하려면 다음을 사용하면 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Tslzx0_eEWx"
      },
      "outputs": [],
      "source": [
        "ds = tfds.data_source('fashion_mnist')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlaRrD_SeHLY"
      },
      "source": [
        "`tfds.data_source`는 편리한 래퍼입니다. 이는 다음과 같습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "duHDKzXReIKB"
      },
      "outputs": [],
      "source": [
        "builder = tfds.builder('fashion_mnist', file_format='array_record')\n",
        "builder.download_and_prepare()\n",
        "ds = builder.as_data_source()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlyIsd0ueKjQ"
      },
      "source": [
        "이렇게 하면 데이터 소스 사전이 출력됩니다.\n",
        "\n",
        "```\n",
        "{\n",
        "  'train': DataSource(name=fashion_mnist, split='train', decoders=None),\n",
        "  'test': DataSource(name=fashion_mnist, split='test', decoders=None),\n",
        "}\n",
        "```\n",
        "\n",
        "`download_and_prepare`가 실행되고 레코드 파일이 생성되면 더 이상 TensorFlow가 필요하지 않습니다. 모든 것은 Python/NumPy에서 이루어집니다.\n",
        "\n",
        "TensorFlow를 제거하고 다른 하위 프로세스에서 데이터 소스를 다시 로드하여 이를 확인해보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mTfSzvaQkSd9"
      },
      "outputs": [],
      "source": [
        "!pip uninstall -y tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3sT5AN7neNT9"
      },
      "outputs": [],
      "source": [
        "%%writefile no_tensorflow.py\n",
        "import os\n",
        "os.environ.pop('TFDS_DATA_DIR', None)\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "try:\n",
        "  import tensorflow as tf\n",
        "except ImportError:\n",
        "  print('No TensorFlow found...')\n",
        "\n",
        "ds = tfds.data_source('fashion_mnist')\n",
        "print('...but the data source could still be loaded...')\n",
        "ds['train'][0]\n",
        "print('...and the records can be decoded.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FxohFdb3kSxh"
      },
      "outputs": [],
      "source": [
        "!python no_tensorflow.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1o8n-BhhePYY"
      },
      "source": [
        "향후 버전에서는 데이터세트 준비를 TensorFlow 없이 할 수 있게 만들 것입니다.\n",
        "\n",
        "데이터 소스의 길이는 다음과 같습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qtfl17SQeQ7F"
      },
      "outputs": [],
      "source": [
        "len(ds['train'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-UFBu8leSMp"
      },
      "source": [
        "데이터세트의 첫 번째 요소에 액세스합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFvT2Sx2eToh"
      },
      "outputs": [],
      "source": [
        "%%timeit\n",
        "ds['train'][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTgZskyZeU_D"
      },
      "source": [
        "이것은 다른 요소에 액세스하는 것만큼이나 저렴합니다. 이것이 [랜덤 액세스](https://en.wikipedia.org/wiki/Random_access)의 정의입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cPJFa6aIeWcY"
      },
      "outputs": [],
      "source": [
        "%%timeit\n",
        "ds['train'][1000]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fs3kafYheX6N"
      },
      "source": [
        "이제 특성으로 TensorFlow DType 대신 NumPy DTypes를 사용합니다. 다음을 사용하여 특성을 검사할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q7x5AEEaeZja"
      },
      "outputs": [],
      "source": [
        "features = tfds.builder('fashion_mnist').info.features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOnLqAZOeiBi"
      },
      "source": [
        "[문서 자료에서 특성](https://www.tensorflow.org/datasets/api_docs/python/tfds/features)에 대한 자세한 정보를 확인할 수 있습니다. 여기에서 이미지의 모양과 클래스 수를 검색할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xk8Vc-y0edlb"
      },
      "outputs": [],
      "source": [
        "shape = features['image'].shape\n",
        "num_classes = features['label'].num_classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFh8pytVemsu"
      },
      "source": [
        "## 순수 Python에서 사용하기\n",
        "\n",
        "Python에서 데이터 소스를 반복하여 사용할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ULjO-JDVefNf"
      },
      "outputs": [],
      "source": [
        "for example in ds['train']:\n",
        "  print(example)\n",
        "  break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZRHZNOkenPb"
      },
      "source": [
        "요소를 검사하면 모든 특성이 이미 NumPy를 사용하여 디코딩되어 있음을 알 수 있습니다. 애초에 [OpenCV](https://opencv.org)를 기본으로 사용하는데, 이는 속도가 빠르기 때문입니다. OpenCV가 설치되어 있지 않은 경우, 가볍고 빠른 이미지 디코딩을 제공하기 위해 기본값을 [Pillow](python-pillow.org)로 설정합니다.\n",
        "\n",
        "```\n",
        "{\n",
        "  'image': array([[[0], [0], ..., [0]],\n",
        "                  [[0], [0], ..., [0]]], dtype=uint8),\n",
        "  'label': 2,\n",
        "}\n",
        "```\n",
        "\n",
        "**참고**: 현재 이 기능은 `Tensor`, `Image` 및 `Scalar` 특성에서만 사용할 수 있습니다. `Audio` 및 `Video` 특성은 곧 제공될 예정입니다. 계속 지켜봐주세요!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8kLyK5j1enhc"
      },
      "source": [
        "## PyTorch와 함께 사용하기\n",
        "\n",
        "PyTorch는 소스/샘플러/로더 패러다임을 사용합니다. Torch에서는 \"데이터 소스\"를 \"데이터세트\"라고 부릅니다. [`torch.utils.data`](https://pytorch.org/docs/stable/data.html)에는 Torch에서 효율적인 입력 파이프라인을 구축하기 위해 알아야 할 모든 세부 정보가 포함되어 있습니다.\n",
        "\n",
        "TFDS 데이터 소스는 일반 [지도 스타일 데이터세트](https://pytorch.org/docs/stable/data.html#map-style-datasets)로 사용할 수 있습니다.\n",
        "\n",
        "먼저 Torch를 설치하고 가져옵니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3aKol1fDeyoK"
      },
      "outputs": [],
      "source": [
        "!pip install torch\n",
        "\n",
        "from tqdm import tqdm\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKdJvYywe0YC"
      },
      "source": [
        "우리는 이미 훈련 및 테스트용 데이터 소스를 정의했습니다(각각 `ds['train']` 및 `ds['test']`). 이제 샘플러와 로더를 정의할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_4P2JIrie23f"
      },
      "outputs": [],
      "source": [
        "batch_size = 128\n",
        "train_sampler = torch.utils.data.RandomSampler(ds['train'], num_samples=5_000)\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    ds['train'],\n",
        "    sampler=train_sampler,\n",
        "    batch_size=batch_size,\n",
        ")\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    ds['test'],\n",
        "    sampler=None,\n",
        "    batch_size=batch_size,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVhofOm4e53O"
      },
      "source": [
        "PyTorch를 사용하여 첫 번째 예제에 대한 간단한 로지스틱 회귀를 훈련하고 평가합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HcAmvMa-e42p"
      },
      "outputs": [],
      "source": [
        "class LinearClassifier(torch.nn.Module):\n",
        "  def __init__(self, shape, num_classes):\n",
        "    super(LinearClassifier, self).__init__()\n",
        "    height, width, channels = shape\n",
        "    self.classifier = torch.nn.Linear(height * width * channels, num_classes)\n",
        "\n",
        "  def forward(self, image):\n",
        "    image = image.view(image.size()[0], -1).to(torch.float32)\n",
        "    return self.classifier(image)\n",
        "\n",
        "\n",
        "model = LinearClassifier(shape, num_classes)\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "print('Training...')\n",
        "model.train()\n",
        "for example in tqdm(train_loader):\n",
        "  image, label = example['image'], example['label']\n",
        "  prediction = model(image)\n",
        "  loss = loss_function(prediction, label)\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "print('Testing...')\n",
        "model.eval()\n",
        "num_examples = 0\n",
        "true_positives = 0\n",
        "for example in tqdm(test_loader):\n",
        "  image, label = example['image'], example['label']\n",
        "  prediction = model(image)\n",
        "  num_examples += image.shape[0]\n",
        "  predicted_label = prediction.argmax(dim=1)\n",
        "  true_positives += (predicted_label == label).sum().item()\n",
        "print(f'\\nAccuracy: {true_positives/num_examples * 100:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewKJQpwZe6Ik"
      },
      "source": [
        "## 곧 출시 예정: JAX와 함께 사용하기\n",
        "\n",
        "우리는 [Grain](https://github.com/google/grain)과 긴밀히 협력하고 있습니다. Grain은 Python에서 사용할 수 있는 빠르고 결정론적인 오픈 소스 데이터 로더입니다. 계속 지켜봐주세요!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvLEtCWRvvy8"
      },
      "source": [
        "## 더 읽어보기\n",
        "\n",
        "자세한 내용은 [`tfds.data_source`](https://www.tensorflow.org/datasets/api_docs/python/tfds/data_source) API 문서를 참조하세요."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "tfless_tfds.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
