{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7765UFHoyGx6"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "KsOkK8O69PyT"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKQpW0JqQQmY"
      },
      "source": [
        "# Tensorflow Lattice와 형상 제약 조건\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r61fkA2i9Y3_"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td><a target=\"_blank\" href=\"https://www.tensorflow.org/lattice/tutorials/shape_constraints\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">TensorFlow.org에서 보기</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/ko/lattice/tutorials/shape_constraints.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Google Colab에서 실행하기</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/ko/lattice/tutorials/shape_constraints.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">GitHub에서소스 보기</a></td>\n",
        "  <td><a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/ko/lattice/tutorials/shape_constraints.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">노트북 다운로드하기</a></td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2plcL3iTVjsp"
      },
      "source": [
        "## 개요\n",
        "\n",
        "이 튜토리얼은 TensorFlow Lattice(TFL) 라이브러리에서 제공하는 제약 조건 및 regularizer에 대한 개요입니다. 여기서는 합성 데이터세트에 TFL canned estimator를 사용하지만, 해당 튜토리얼의 모든 내용은 TFL Keras 레이어로 구성된 모델로도 수행될 수 있습니다.\n",
        "\n",
        "계속하기 전에 런타임에 필요한 모든 패키지가 아래 코드 셀에서 가져온 대로 설치되어 있는지 먼저 확인하세요."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x769lI12IZXB"
      },
      "source": [
        "## 설정"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbBVAR6UeRN5"
      },
      "source": [
        "TF Lattice 패키지 설치하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bpXjJKpSd3j4"
      },
      "outputs": [],
      "source": [
        "#@test {\"skip\": true}\n",
        "!pip install tensorflow-lattice"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSVl9SHTeSGX"
      },
      "source": [
        "필수 패키지 가져오기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "both",
        "id": "iY6awAl058TV"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from IPython.core.pylabtools import figsize\n",
        "import itertools\n",
        "import logging\n",
        "import matplotlib\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sys\n",
        "import tensorflow_lattice as tfl\n",
        "logging.disable(sys.maxsize)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TmBk_IGgJF0"
      },
      "source": [
        "이 가이드에서 사용되는 기본값"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kQHPyPsPUF92"
      },
      "outputs": [],
      "source": [
        "NUM_EPOCHS = 1000\n",
        "BATCH_SIZE = 64\n",
        "LEARNING_RATE=0.01"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FjR7D8Ag3z0d"
      },
      "source": [
        "## 레스토랑 순위 지정을 위한 훈련 데이터세트"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1YetzbdFOij"
      },
      "source": [
        "사용자가 레스토랑 검색 결과를 클릭할지 여부를 결정하는 단순화된 시나리오를 상상해봅니다. 이 작업은 주어진 입력 특성에 따른 클릭률(CTR)을 예측하는 것입니다.\n",
        "\n",
        "- 평균 평점(`avg_rating`): [1,5] 범위의 값을 가진 숫자 특성입니다.\n",
        "- 리뷰 수(`num_reviews`): 200개로 제한되는 값이 있는 숫자 특성으로, 트렌드를 측정하는 데 사용됩니다.\n",
        "- 달러 등급(`dollar_rating`): { \"D\", \"DD\", \"DDD\", \"DDDD\"} 세트에 문자열 값이 있는 범주형 특성입니다.\n",
        "\n",
        "실제 CTR이 공식으로 제공되는 합성 데이터세트를 만듭니다. $$ CTR = 1 / (1 + exp{\\mbox {b(dollar_rating)}-\\mbox {avg_rating} \\times log(\\mbox {num_reviews}) / 4}) $$ 여기서 $b(\\cdot)$는 각 `dollar_rating`을 기준값으로 변환합니다. $$ \\mbox{D}\\to 3,\\ \\ mbox{DD}\\to 2,\\ \\ mbox{DDD}\\to 4,\\ \\mbox{DDDD}\\to 4.5. $$\n",
        "\n",
        "이 공식은 일반적인 사용자 패턴을 반영합니다. 예를 들어 다른 모든 사항이 수정된 경우 사용자는 별표 평점이 더 높은 식당을 선호하며 '$$'식당은 '$'보다 더 많은 클릭을 받고 '$$$' 및 '$$$'가 이어집니다. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mKovnyv1jATw"
      },
      "outputs": [],
      "source": [
        "def click_through_rate(avg_ratings, num_reviews, dollar_ratings):\n",
        "  dollar_rating_baseline = {\"D\": 3, \"DD\": 2, \"DDD\": 4, \"DDDD\": 4.5}\n",
        "  return 1 / (1 + np.exp(\n",
        "      np.array([dollar_rating_baseline[d] for d in dollar_ratings]) -\n",
        "      avg_ratings * np.log1p(num_reviews) / 4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPlgRdt6jAbP"
      },
      "source": [
        "이 CTR 함수의 등고선도를 살펴보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KC5qX_XKmc7g"
      },
      "outputs": [],
      "source": [
        "def color_bar():\n",
        "  bar = matplotlib.cm.ScalarMappable(\n",
        "      norm=matplotlib.colors.Normalize(0, 1, True),\n",
        "      cmap=\"viridis\",\n",
        "  )\n",
        "  bar.set_array([0, 1])\n",
        "  return bar\n",
        "\n",
        "\n",
        "def plot_fns(fns, split_by_dollar=False, res=25):\n",
        "  \"\"\"Generates contour plots for a list of (name, fn) functions.\"\"\"\n",
        "  num_reviews, avg_ratings = np.meshgrid(\n",
        "      np.linspace(0, 200, num=res),\n",
        "      np.linspace(1, 5, num=res),\n",
        "  )\n",
        "  if split_by_dollar:\n",
        "    dollar_rating_splits = [\"D\", \"DD\", \"DDD\", \"DDDD\"]\n",
        "  else:\n",
        "    dollar_rating_splits = [None]\n",
        "  if len(fns) == 1:\n",
        "    fig, axes = plt.subplots(2, 2, sharey=True, tight_layout=False)\n",
        "  else:\n",
        "    fig, axes = plt.subplots(\n",
        "        len(dollar_rating_splits), len(fns), sharey=True, tight_layout=False)\n",
        "  axes = axes.flatten()\n",
        "  axes_index = 0\n",
        "  for dollar_rating_split in dollar_rating_splits:\n",
        "    for title, fn in fns:\n",
        "      if dollar_rating_split is not None:\n",
        "        dollar_ratings = np.repeat(dollar_rating_split, res**2)\n",
        "        values = fn(avg_ratings.flatten(), num_reviews.flatten(),\n",
        "                    dollar_ratings)\n",
        "        title = \"{}: dollar_rating={}\".format(title, dollar_rating_split)\n",
        "      else:\n",
        "        values = fn(avg_ratings.flatten(), num_reviews.flatten())\n",
        "      subplot = axes[axes_index]\n",
        "      axes_index += 1\n",
        "      subplot.contourf(\n",
        "          avg_ratings,\n",
        "          num_reviews,\n",
        "          np.reshape(values, (res, res)),\n",
        "          vmin=0,\n",
        "          vmax=1)\n",
        "      subplot.title.set_text(title)\n",
        "      subplot.set(xlabel=\"Average Rating\")\n",
        "      subplot.set(ylabel=\"Number of Reviews\")\n",
        "      subplot.set(xlim=(1, 5))\n",
        "\n",
        "  _ = fig.colorbar(color_bar(), cax=fig.add_axes([0.95, 0.2, 0.01, 0.6]))\n",
        "\n",
        "\n",
        "figsize(11, 11)\n",
        "plot_fns([(\"CTR\", click_through_rate)], split_by_dollar=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ol91olp3muNN"
      },
      "source": [
        "### 데이터 준비하기\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8BOshZS9xwn"
      },
      "source": [
        "이제 합성 데이터세트를 만들어야 합니다. 레스토랑과 해당 특징의 시뮬레이션된 데이터세트를 생성하는 것으로 작업을 시작합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MhqcOPdTT_wj"
      },
      "outputs": [],
      "source": [
        "def sample_restaurants(n):\n",
        "  avg_ratings = np.random.uniform(1.0, 5.0, n)\n",
        "  num_reviews = np.round(np.exp(np.random.uniform(0.0, np.log(200), n)))\n",
        "  dollar_ratings = np.random.choice([\"D\", \"DD\", \"DDD\", \"DDDD\"], n)\n",
        "  ctr_labels = click_through_rate(avg_ratings, num_reviews, dollar_ratings)\n",
        "  return avg_ratings, num_reviews, dollar_ratings, ctr_labels\n",
        "\n",
        "\n",
        "np.random.seed(42)\n",
        "avg_ratings, num_reviews, dollar_ratings, ctr_labels = sample_restaurants(2000)\n",
        "\n",
        "figsize(5, 5)\n",
        "fig, axs = plt.subplots(1, 1, sharey=False, tight_layout=False)\n",
        "for rating, marker in [(\"D\", \"o\"), (\"DD\", \"^\"), (\"DDD\", \"+\"), (\"DDDD\", \"x\")]:\n",
        "  plt.scatter(\n",
        "      x=avg_ratings[np.where(dollar_ratings == rating)],\n",
        "      y=num_reviews[np.where(dollar_ratings == rating)],\n",
        "      c=ctr_labels[np.where(dollar_ratings == rating)],\n",
        "      vmin=0,\n",
        "      vmax=1,\n",
        "      marker=marker,\n",
        "      label=rating)\n",
        "plt.xlabel(\"Average Rating\")\n",
        "plt.ylabel(\"Number of Reviews\")\n",
        "plt.legend()\n",
        "plt.xlim((1, 5))\n",
        "plt.title(\"Distribution of restaurants\")\n",
        "_ = fig.colorbar(color_bar(), cax=fig.add_axes([0.95, 0.2, 0.01, 0.6]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRetsfLv_JSR"
      },
      "source": [
        "훈련, 검증 및 테스트 데이터세트를 생성해 보겠습니다. 검색 결과에 레스토랑이 표시되면 사용자의 참여(클릭 또는 클릭 없음)를 샘플 포인트로 기록할 수 있습니다.\n",
        "\n",
        "실제로 사용자가 모든 검색 결과를 확인하지 않는 경우가 많습니다. 즉, 사용자는 현재 사용 중인 순위 모델에서 이미 '좋은' 것으로 간주되는 식당만 볼 수 있습니다. 결과적으로 '좋은' 레스토랑은 훈련 데이터세트에서 더 자주 좋은 인상을 남기고 더 과장되게 표현됩니다. 더 많은 특성을 사용할 때 훈련 데이터세트에서는 특성 공간의 '나쁜' 부분에 큰 간격이 생길 수 있습니다.\n",
        "\n",
        "모델이 순위 지정에 사용되면 훈련 데이터세트로 잘 표현되지 않는 보다 균일한 분포로 모든 관련 결과에 대해 평가되는 경우가 많습니다. 이 경우 과도하게 표현된 데이터 포인트에 과대 적합이 발생하여 일반화될 수 없기 때문에, 유연하고 복잡한 모델은 실패할 수 있습니다. 이 문제는 도메인 지식을 적용하여 모델이 훈련 데이터세트에서 선택할 수 없을 때 합리적인 예측을 할 수 있도록 안내하는 *형상 제약 조건*을 추가함으로써 처리합니다.\n",
        "\n",
        "이 예에서 훈련 데이터세트는 대부분 우수하고 인기 있는 음식점과의 사용자 상호 작용으로 구성됩니다. 테스트 데이터세트에는 위에서 설명한 평가 설정을 시뮬레이션하도록 균일한 분포가 있습니다. 해당 테스트 데이터세트는 실제 문제 설정에서는 사용할 수 없습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jS6WOtXQ8jwX"
      },
      "outputs": [],
      "source": [
        "def sample_dataset(n, testing_set):\n",
        "  (avg_ratings, num_reviews, dollar_ratings, ctr_labels) = sample_restaurants(n)\n",
        "  if testing_set:\n",
        "    # Testing has a more uniform distribution over all restaurants.\n",
        "    num_views = np.random.poisson(lam=3, size=n)\n",
        "  else:\n",
        "    # Training/validation datasets have more views on popular restaurants.\n",
        "    num_views = np.random.poisson(lam=ctr_labels * num_reviews / 50.0, size=n)\n",
        "\n",
        "  return pd.DataFrame({\n",
        "      \"avg_rating\": np.repeat(avg_ratings, num_views),\n",
        "      \"num_reviews\": np.repeat(num_reviews, num_views),\n",
        "      \"dollar_rating\": np.repeat(dollar_ratings, num_views),\n",
        "      \"clicked\": np.random.binomial(n=1, p=np.repeat(ctr_labels, num_views))\n",
        "  })\n",
        "\n",
        "\n",
        "# Generate datasets.\n",
        "np.random.seed(42)\n",
        "data_train = sample_dataset(500, testing_set=False)\n",
        "data_val = sample_dataset(500, testing_set=False)\n",
        "data_test = sample_dataset(500, testing_set=True)\n",
        "\n",
        "# Plotting dataset densities.\n",
        "figsize(12, 5)\n",
        "fig, axs = plt.subplots(1, 2, sharey=False, tight_layout=False)\n",
        "for ax, data, title in [(axs[0], data_train, \"training\"),\n",
        "                        (axs[1], data_test, \"testing\")]:\n",
        "  _, _, _, density = ax.hist2d(\n",
        "      x=data[\"avg_rating\"],\n",
        "      y=data[\"num_reviews\"],\n",
        "      bins=(np.linspace(1, 5, num=21), np.linspace(0, 200, num=21)),\n",
        "      density=True,\n",
        "      cmap=\"Blues\",\n",
        "  )\n",
        "  ax.set(xlim=(1, 5))\n",
        "  ax.set(ylim=(0, 200))\n",
        "  ax.set(xlabel=\"Average Rating\")\n",
        "  ax.set(ylabel=\"Number of Reviews\")\n",
        "  ax.title.set_text(\"Density of {} examples\".format(title))\n",
        "  _ = fig.colorbar(density, ax=ax)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fVyLgpCT1nW"
      },
      "source": [
        "훈련 및 평가에 사용되는 input_fns 정의하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DYzRTRR2GKoS"
      },
      "outputs": [],
      "source": [
        "train_input_fn = tf.compat.v1.estimator.inputs.pandas_input_fn(\n",
        "    x=data_train,\n",
        "    y=data_train[\"clicked\"],\n",
        "    batch_size=BATCH_SIZE,\n",
        "    num_epochs=NUM_EPOCHS,\n",
        "    shuffle=False,\n",
        ")\n",
        "\n",
        "# feature_analysis_input_fn is used for TF Lattice estimators.\n",
        "feature_analysis_input_fn = tf.compat.v1.estimator.inputs.pandas_input_fn(\n",
        "    x=data_train,\n",
        "    y=data_train[\"clicked\"],\n",
        "    batch_size=BATCH_SIZE,\n",
        "    num_epochs=1,\n",
        "    shuffle=False,\n",
        ")\n",
        "\n",
        "val_input_fn = tf.compat.v1.estimator.inputs.pandas_input_fn(\n",
        "    x=data_val,\n",
        "    y=data_val[\"clicked\"],\n",
        "    batch_size=BATCH_SIZE,\n",
        "    num_epochs=1,\n",
        "    shuffle=False,\n",
        ")\n",
        "\n",
        "test_input_fn = tf.compat.v1.estimator.inputs.pandas_input_fn(\n",
        "    x=data_test,\n",
        "    y=data_test[\"clicked\"],\n",
        "    batch_size=BATCH_SIZE,\n",
        "    num_epochs=1,\n",
        "    shuffle=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qoTrw3FZqvPK"
      },
      "source": [
        "## 그래디언트 Boosted 트리 적합화하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZklNowexE3wB"
      },
      "source": [
        "`avg_rating`과 `num_reviews` 두 가지 특성으로 시작하겠습니다.\n",
        "\n",
        "검증 및 테스트 메트릭을 플롯하고 계산하기 위한 몇 가지 보조 함수를 만듭니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SX6rARJWURWl"
      },
      "outputs": [],
      "source": [
        "def analyze_two_d_estimator(estimator, name):\n",
        "  # Extract validation metrics.\n",
        "  metric = estimator.evaluate(input_fn=val_input_fn)\n",
        "  print(\"Validation AUC: {}\".format(metric[\"auc\"]))\n",
        "  metric = estimator.evaluate(input_fn=test_input_fn)\n",
        "  print(\"Testing AUC: {}\".format(metric[\"auc\"]))\n",
        "\n",
        "  def two_d_pred(avg_ratings, num_reviews):\n",
        "    results = estimator.predict(\n",
        "        tf.compat.v1.estimator.inputs.pandas_input_fn(\n",
        "            x=pd.DataFrame({\n",
        "                \"avg_rating\": avg_ratings,\n",
        "                \"num_reviews\": num_reviews,\n",
        "            }),\n",
        "            shuffle=False,\n",
        "        ))\n",
        "    return [x[\"logistic\"][0] for x in results]\n",
        "\n",
        "  def two_d_click_through_rate(avg_ratings, num_reviews):\n",
        "    return np.mean([\n",
        "        click_through_rate(avg_ratings, num_reviews,\n",
        "                           np.repeat(d, len(avg_ratings)))\n",
        "        for d in [\"D\", \"DD\", \"DDD\", \"DDDD\"]\n",
        "    ],\n",
        "                   axis=0)\n",
        "\n",
        "  figsize(11, 5)\n",
        "  plot_fns([(\"{} Estimated CTR\".format(name), two_d_pred),\n",
        "            (\"CTR\", two_d_click_through_rate)],\n",
        "           split_by_dollar=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVef4f8yUUbs"
      },
      "source": [
        "TensorFlow 그래디언트 boosted 결정 트리를 데이터세트에 적합하도록 맞출 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DnPYlRAo2mnQ"
      },
      "outputs": [],
      "source": [
        "feature_columns = [\n",
        "    tf.feature_column.numeric_column(\"num_reviews\"),\n",
        "    tf.feature_column.numeric_column(\"avg_rating\"),\n",
        "]\n",
        "gbt_estimator = tf.estimator.BoostedTreesClassifier(\n",
        "    feature_columns=feature_columns,\n",
        "    # Hyper-params optimized on validation set.\n",
        "    n_batches_per_layer=1,\n",
        "    max_depth=2,\n",
        "    n_trees=50,\n",
        "    learning_rate=0.05,\n",
        "    config=tf.estimator.RunConfig(tf_random_seed=42),\n",
        ")\n",
        "gbt_estimator.train(input_fn=train_input_fn)\n",
        "analyze_two_d_estimator(gbt_estimator, \"GBT\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYZtd6YvsNdn"
      },
      "source": [
        "모델이 실제 CTR의 일반적인 형상을 포착하고 적절한 검증 메트릭을 가지고 있지만, 입력 공간의 여러 부분에서 반직관적인 동작을 보입니다. 평균 평점 또는 리뷰 수가 증가하면 예상 CTR이 감소하는데, 이는 훈련 데이터세트에서 잘 다루지 않는 영역에 샘플 포인트가 부족하기 때문입니다. 모델은 데이터에서만 올바른 동작을 추론할 방법이 없습니다.\n",
        "\n",
        "이 문제를 해결하기 위해 모델이 평균 평점과 리뷰 수에 대해 단조롭게 증가하는 값을 출력해야 한다는 형상 제약 조건을 적용합니다. 나중에 TFL에서 이를 구현하는 방법을 살펴보겠습니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uf7WqGooFiEp"
      },
      "source": [
        "## DNN 적합화하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_s2aT3x0E_tF"
      },
      "source": [
        "DNN 분류자로 같은 단계를 반복할 수 있습니다. 여기서 비슷한 패턴이 관찰되는데 리뷰 수가 적은 샘플 포인트가 충분하지 않으면 무의미한 외삽이 발생합니다. 검증 메트릭이 트리 솔루션보다 우수하더라도 테스트 메트릭은 훨씬 나쁘다는 점을 유의하세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gFUeG6kLDNhO"
      },
      "outputs": [],
      "source": [
        "feature_columns = [\n",
        "    tf.feature_column.numeric_column(\"num_reviews\"),\n",
        "    tf.feature_column.numeric_column(\"avg_rating\"),\n",
        "]\n",
        "dnn_estimator = tf.estimator.DNNClassifier(\n",
        "    feature_columns=feature_columns,\n",
        "    # Hyper-params optimized on validation set.\n",
        "    hidden_units=[16, 8, 8],\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
        "    config=tf.estimator.RunConfig(tf_random_seed=42),\n",
        ")\n",
        "dnn_estimator.train(input_fn=train_input_fn)\n",
        "analyze_two_d_estimator(dnn_estimator, \"DNN\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Avkw-okw7JL"
      },
      "source": [
        "## 형상 제약 조건"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ExyethCFBrP"
      },
      "source": [
        "TensorFlow Lattice(TFL)는 훈련 데이터 이상의 모델 동작을 보호하기 위해 형상 제약 조건을 적용하는 데 중점을 둡니다. 이러한 형상 제약 조건은 TFL Keras 레이어에 적용됩니다. 자세한 내용은 [JMLR 논문](http://jmlr.org/papers/volume17/15-243/15-243.pdf)에서 찾을 수 있습니다.\n",
        "\n",
        "이 튜토리얼에서는 다양한 형상 제약을 다루기 위해 준비된 TF estimator를 사용하지만, 해당 모든 단계는 TFL Keras 레이어에서 생성된 모델로 수행할 수 있습니다.\n",
        "\n",
        "다른 TensorFlow estimator와 마찬가지로 준비된 TFL estimator는 [특성 열](https://www.tensorflow.org/api_docs/python/tf/feature_column)을 사용하여 입력 형식을 정의하고 훈련 input_fn을 사용하여 데이터를 전달합니다. 준비된 TFL estimator을 사용하려면 다음이 필요합니다.\n",
        "\n",
        "- *모델 구성*: 모델 아키텍처 및 특성별 형상 제약 조건 및 regularizer를 정의합니다.\n",
        "- *특성 분석 input_fn*: TFL 초기화를 위해 데이터를 전달하는 TF input_fn.\n",
        "\n",
        "자세한 설명은 준비된 estimator 튜토리얼 또는 API 설명서를 참조하세요."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anyCM4sCpOSo"
      },
      "source": [
        "### 단조\n",
        "\n",
        "먼저 두 특성에 단조 형상 제약 조건을 추가하여 단조 문제를 해결합니다.\n",
        "\n",
        "TFL에 형상 제약 조건을 적용하기 위해 *특성 구성*에 제약 조건을 지정합니다. 다음 코드는 `monotonicity=\"increasing\"`을 설정하여 `num_reviews` 및 `avg_rating` 모두에 대해 출력이 단조롭게 증가하도록 요구할 수 있는 방법을 보여줍니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FCm1lOjmwur_"
      },
      "outputs": [],
      "source": [
        "feature_columns = [\n",
        "    tf.feature_column.numeric_column(\"num_reviews\"),\n",
        "    tf.feature_column.numeric_column(\"avg_rating\"),\n",
        "]\n",
        "model_config = tfl.configs.CalibratedLatticeConfig(\n",
        "    feature_configs=[\n",
        "        tfl.configs.FeatureConfig(\n",
        "            name=\"num_reviews\",\n",
        "            lattice_size=2,\n",
        "            monotonicity=\"increasing\",\n",
        "            pwl_calibration_num_keypoints=20,\n",
        "        ),\n",
        "        tfl.configs.FeatureConfig(\n",
        "            name=\"avg_rating\",\n",
        "            lattice_size=2,\n",
        "            monotonicity=\"increasing\",\n",
        "            pwl_calibration_num_keypoints=20,\n",
        "        )\n",
        "    ])\n",
        "tfl_estimator = tfl.estimators.CannedClassifier(\n",
        "    feature_columns=feature_columns,\n",
        "    model_config=model_config,\n",
        "    feature_analysis_input_fn=feature_analysis_input_fn,\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
        "    config=tf.estimator.RunConfig(tf_random_seed=42),\n",
        ")\n",
        "tfl_estimator.train(input_fn=train_input_fn)\n",
        "analyze_two_d_estimator(tfl_estimator, \"TF Lattice\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubNRBCWW5wQ9"
      },
      "source": [
        "`CalibratedLatticeConfig`를 사용하면 먼저 *calibrator*를 각 입력(숫자 특성에 대한 부분 선형 함수)에 적용한 다음 *격자* 레이어를 적용하여 보정된 특성을 비선형적으로 융합하는 준비된 분류자를 생성합니다. `tfl.visualization`을 사용하여 모델을 시각화할 수 있습니다. 특히 다음 플롯은 미리 준비된 estimator에 포함된 두 개의 훈련된 calibrator를 보여줍니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "both",
        "id": "C0py9Q6OBRBE"
      },
      "outputs": [],
      "source": [
        "def save_and_visualize_lattice(tfl_estimator):\n",
        "  saved_model_path = tfl_estimator.export_saved_model(\n",
        "      \"/tmp/TensorFlow_Lattice_101/\",\n",
        "      tf.estimator.export.build_parsing_serving_input_receiver_fn(\n",
        "          feature_spec=tf.feature_column.make_parse_example_spec(\n",
        "              feature_columns)))\n",
        "  model_graph = tfl.estimators.get_model_graph(saved_model_path)\n",
        "  figsize(8, 8)\n",
        "  tfl.visualization.draw_model_graph(model_graph)\n",
        "  return model_graph\n",
        "\n",
        "_ = save_and_visualize_lattice(tfl_estimator)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vZ5fShXs504"
      },
      "source": [
        "제약 조건이 추가되면 평균 평점이 증가하거나 리뷰 수가 증가함에 따라 예상 CTR이 항상 증가합니다. 이것은 calibrator와 격자가 단조로운지 확인하여 수행됩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfniRZCHIvfK"
      },
      "source": [
        "### 감소 수익\n",
        "\n",
        "[감소 수익](https://en.wikipedia.org/wiki/Diminishing_returns)은 특정 특성값을 증가시키는 한계 이득이 값이 증가함에 따라 감소한다는 것을 의미합니다. 해당 경우에는 `num_reviews` 특성이 이 패턴을 따를 것으로 예상하므로 그에 따라 calibrator를 구성할 수 있습니다. 감소하는 수익률은 두 가지 충분한 조건으로 분해할 수 있습니다.\n",
        "\n",
        "- calibrator가 단조롭게 증가하고 있으며\n",
        "- calibrator는 오목합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XQrM9BskY-wx"
      },
      "outputs": [],
      "source": [
        "feature_columns = [\n",
        "    tf.feature_column.numeric_column(\"num_reviews\"),\n",
        "    tf.feature_column.numeric_column(\"avg_rating\"),\n",
        "]\n",
        "model_config = tfl.configs.CalibratedLatticeConfig(\n",
        "    feature_configs=[\n",
        "        tfl.configs.FeatureConfig(\n",
        "            name=\"num_reviews\",\n",
        "            lattice_size=2,\n",
        "            monotonicity=\"increasing\",\n",
        "            pwl_calibration_convexity=\"concave\",\n",
        "            pwl_calibration_num_keypoints=20,\n",
        "        ),\n",
        "        tfl.configs.FeatureConfig(\n",
        "            name=\"avg_rating\",\n",
        "            lattice_size=2,\n",
        "            monotonicity=\"increasing\",\n",
        "            pwl_calibration_num_keypoints=20,\n",
        "        )\n",
        "    ])\n",
        "tfl_estimator = tfl.estimators.CannedClassifier(\n",
        "    feature_columns=feature_columns,\n",
        "    model_config=model_config,\n",
        "    feature_analysis_input_fn=feature_analysis_input_fn,\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
        "    config=tf.estimator.RunConfig(tf_random_seed=42),\n",
        ")\n",
        "tfl_estimator.train(input_fn=train_input_fn)\n",
        "analyze_two_d_estimator(tfl_estimator, \"TF Lattice\")\n",
        "_ = save_and_visualize_lattice(tfl_estimator)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSmzHkPUo9u5"
      },
      "source": [
        "오목 제약 조건을 추가하여 테스트 메트릭이 어떻게 향상되는지 확인하세요. 예측 플롯은 또한 지상 진실과 더 유사합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6CP2Ovapiu3"
      },
      "source": [
        "### 2D 형상 제약 조건: 신뢰\n",
        "\n",
        "리뷰가 한두 개밖에 없는 레스토랑의 별 5개는 신뢰할 수 없는 평가일 가능성이 높지만(실제 레스토랑 경험은 나쁠 수 있습니다), 수백 개의 리뷰가 있는 레스토랑에 대한 4성급은 훨씬 더 신뢰할 수 있습니다(이 경우에 레스토랑 경험은 좋을 것입니다). 레스토랑 리뷰 수는 평균 평점에 대한 신뢰도에 영향을 미친다는 것을 알 수 있습니다.\n",
        "\n",
        "TFL 신뢰 제약 조건을 실행하여 한 특성의 더 큰(또는 더 작은) 값이 다른 특성에 대한 더 많은 신뢰 또는 신뢰를 나타냄을 모델에 알릴 수 있습니다. 이는 특성 구성에서 `reflects_trust_in` 구성을 설정하여 수행됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OA14j0erm6TJ"
      },
      "outputs": [],
      "source": [
        "feature_columns = [\n",
        "    tf.feature_column.numeric_column(\"num_reviews\"),\n",
        "    tf.feature_column.numeric_column(\"avg_rating\"),\n",
        "]\n",
        "model_config = tfl.configs.CalibratedLatticeConfig(\n",
        "    feature_configs=[\n",
        "        tfl.configs.FeatureConfig(\n",
        "            name=\"num_reviews\",\n",
        "            lattice_size=2,\n",
        "            monotonicity=\"increasing\",\n",
        "            pwl_calibration_convexity=\"concave\",\n",
        "            pwl_calibration_num_keypoints=20,\n",
        "            # Larger num_reviews indicating more trust in avg_rating.\n",
        "            reflects_trust_in=[\n",
        "                tfl.configs.TrustConfig(\n",
        "                    feature_name=\"avg_rating\", trust_type=\"edgeworth\"),\n",
        "            ],\n",
        "        ),\n",
        "        tfl.configs.FeatureConfig(\n",
        "            name=\"avg_rating\",\n",
        "            lattice_size=2,\n",
        "            monotonicity=\"increasing\",\n",
        "            pwl_calibration_num_keypoints=20,\n",
        "        )\n",
        "    ])\n",
        "tfl_estimator = tfl.estimators.CannedClassifier(\n",
        "    feature_columns=feature_columns,\n",
        "    model_config=model_config,\n",
        "    feature_analysis_input_fn=feature_analysis_input_fn,\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
        "    config=tf.estimator.RunConfig(tf_random_seed=42),\n",
        ")\n",
        "tfl_estimator.train(input_fn=train_input_fn)\n",
        "analyze_two_d_estimator(tfl_estimator, \"TF Lattice\")\n",
        "model_graph = save_and_visualize_lattice(tfl_estimator)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "puvP9X8XxyRV"
      },
      "source": [
        "다음 플롯은 훈련된 격자 함수를 나타냅니다. 신뢰 제약 조건으로 인해, 보정된 `num_reviews`의 큰 값이 보정된 `avg_rating`에 대한 경사를 더 높여서 격자 출력에서 더 중요한 이동이 있을 것을 예상합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "both",
        "id": "RounEQebxxnA"
      },
      "outputs": [],
      "source": [
        "lat_mesh_n = 12\n",
        "lat_mesh_x, lat_mesh_y = tfl.test_utils.two_dim_mesh_grid(\n",
        "    lat_mesh_n**2, 0, 0, 1, 1)\n",
        "lat_mesh_fn = tfl.test_utils.get_hypercube_interpolation_fn(\n",
        "    model_graph.output_node.weights.flatten())\n",
        "lat_mesh_z = [\n",
        "    lat_mesh_fn([lat_mesh_x.flatten()[i],\n",
        "                 lat_mesh_y.flatten()[i]]) for i in range(lat_mesh_n**2)\n",
        "]\n",
        "trust_plt = tfl.visualization.plot_outputs(\n",
        "    (lat_mesh_x, lat_mesh_y),\n",
        "    {\"Lattice Lookup\": lat_mesh_z},\n",
        "    figsize=(6, 6),\n",
        ")\n",
        "trust_plt.title(\"Trust\")\n",
        "trust_plt.xlabel(\"Calibrated avg_rating\")\n",
        "trust_plt.ylabel(\"Calibrated num_reviews\")\n",
        "trust_plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKe3UHX6pUjw"
      },
      "source": [
        "### Smoothing Calibrator\n",
        "\n",
        "이제 `avg_rating`의 calibrator를 살펴보겠습니다. 단조롭게 증가하지만 기울기의 변화는 갑작스럽고 해석하기 어렵습니다. 이는 `regularizer_configs`의 regularizer 설정으로 이 calibrator를 스무딩하는 것을 고려해볼 수 있음을 의미합니다.\n",
        "\n",
        "여기에서는 곡률의 변화를 줄이기 위해 `wrinkle` regularizer를 적용합니다. 또한 `laplacian` regularizer를 사용하여 calibrator를 평면화하고 `hessian` regularizer를 사용하여 보다 선형적으로 만들 수 있습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qxFHH3hSpWfq"
      },
      "outputs": [],
      "source": [
        "feature_columns = [\n",
        "    tf.feature_column.numeric_column(\"num_reviews\"),\n",
        "    tf.feature_column.numeric_column(\"avg_rating\"),\n",
        "]\n",
        "model_config = tfl.configs.CalibratedLatticeConfig(\n",
        "    feature_configs=[\n",
        "        tfl.configs.FeatureConfig(\n",
        "            name=\"num_reviews\",\n",
        "            lattice_size=2,\n",
        "            monotonicity=\"increasing\",\n",
        "            pwl_calibration_convexity=\"concave\",\n",
        "            pwl_calibration_num_keypoints=20,\n",
        "            regularizer_configs=[\n",
        "                tfl.configs.RegularizerConfig(name=\"calib_wrinkle\", l2=1.0),\n",
        "            ],\n",
        "            reflects_trust_in=[\n",
        "                tfl.configs.TrustConfig(\n",
        "                    feature_name=\"avg_rating\", trust_type=\"edgeworth\"),\n",
        "            ],\n",
        "        ),\n",
        "        tfl.configs.FeatureConfig(\n",
        "            name=\"avg_rating\",\n",
        "            lattice_size=2,\n",
        "            monotonicity=\"increasing\",\n",
        "            pwl_calibration_num_keypoints=20,\n",
        "            regularizer_configs=[\n",
        "                tfl.configs.RegularizerConfig(name=\"calib_wrinkle\", l2=1.0),\n",
        "            ],\n",
        "        )\n",
        "    ])\n",
        "tfl_estimator = tfl.estimators.CannedClassifier(\n",
        "    feature_columns=feature_columns,\n",
        "    model_config=model_config,\n",
        "    feature_analysis_input_fn=feature_analysis_input_fn,\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
        "    config=tf.estimator.RunConfig(tf_random_seed=42),\n",
        ")\n",
        "tfl_estimator.train(input_fn=train_input_fn)\n",
        "analyze_two_d_estimator(tfl_estimator, \"TF Lattice\")\n",
        "_ = save_and_visualize_lattice(tfl_estimator)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHpp4goLvuPi"
      },
      "source": [
        "이제 calibrator가 매끄럽고 전체 예상 CTR이 실제와 더 잘 일치합니다. 해당 적용은 테스트 메트릭과 등고선 플롯 모두에 반영됩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSUd6aFlpYz4"
      },
      "source": [
        "### 범주형 보정을 위한 부분 단조\n",
        "\n",
        "지금까지 모델에서 숫자 특성 중 두 가지만 사용했습니다. 여기에서는 범주형 보정 레이어를 사용하여 세 번째 특성을 추가합니다. 다시 플롯 및 메트릭 계산을 위한 도우미 함수를 설정하는 것으로 시작합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5tLDKwTmjrLw"
      },
      "outputs": [],
      "source": [
        "def analyze_three_d_estimator(estimator, name):\n",
        "  # Extract validation metrics.\n",
        "  metric = estimator.evaluate(input_fn=val_input_fn)\n",
        "  print(\"Validation AUC: {}\".format(metric[\"auc\"]))\n",
        "  metric = estimator.evaluate(input_fn=test_input_fn)\n",
        "  print(\"Testing AUC: {}\".format(metric[\"auc\"]))\n",
        "\n",
        "  def three_d_pred(avg_ratings, num_reviews, dollar_rating):\n",
        "    results = estimator.predict(\n",
        "        tf.compat.v1.estimator.inputs.pandas_input_fn(\n",
        "            x=pd.DataFrame({\n",
        "                \"avg_rating\": avg_ratings,\n",
        "                \"num_reviews\": num_reviews,\n",
        "                \"dollar_rating\": dollar_rating,\n",
        "            }),\n",
        "            shuffle=False,\n",
        "        ))\n",
        "    return [x[\"logistic\"][0] for x in results]\n",
        "\n",
        "  figsize(11, 22)\n",
        "  plot_fns([(\"{} Estimated CTR\".format(name), three_d_pred),\n",
        "            (\"CTR\", click_through_rate)],\n",
        "           split_by_dollar=True)\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnPiqf4rq6kJ"
      },
      "source": [
        "세 번째 특성인 `dollar_rating`을 포함하려면 범주형 특성이 특성 열과 특성 구성 모두에서 TFL 내에서 약간 다른 처리가 필요하다는 점을 기억해야 합니다. 여기서 다른 모든 입력이 고정될 때 'DD' 레스토랑의 출력이 'D' 레스토랑보다 커야 한다는 부분 단조 제약 조건을 적용합니다. 해당 적용은 특성 구성에서 `monotonicity` 설정을 사용하여 수행됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m-w7iGEEpgGt"
      },
      "outputs": [],
      "source": [
        "feature_columns = [\n",
        "    tf.feature_column.numeric_column(\"num_reviews\"),\n",
        "    tf.feature_column.numeric_column(\"avg_rating\"),\n",
        "    tf.feature_column.categorical_column_with_vocabulary_list(\n",
        "        \"dollar_rating\",\n",
        "        vocabulary_list=[\"D\", \"DD\", \"DDD\", \"DDDD\"],\n",
        "        dtype=tf.string,\n",
        "        default_value=0),\n",
        "]\n",
        "model_config = tfl.configs.CalibratedLatticeConfig(\n",
        "    feature_configs=[\n",
        "        tfl.configs.FeatureConfig(\n",
        "            name=\"num_reviews\",\n",
        "            lattice_size=2,\n",
        "            monotonicity=\"increasing\",\n",
        "            pwl_calibration_convexity=\"concave\",\n",
        "            pwl_calibration_num_keypoints=20,\n",
        "            regularizer_configs=[\n",
        "                tfl.configs.RegularizerConfig(name=\"calib_wrinkle\", l2=1.0),\n",
        "            ],\n",
        "            reflects_trust_in=[\n",
        "                tfl.configs.TrustConfig(\n",
        "                    feature_name=\"avg_rating\", trust_type=\"edgeworth\"),\n",
        "            ],\n",
        "        ),\n",
        "        tfl.configs.FeatureConfig(\n",
        "            name=\"avg_rating\",\n",
        "            lattice_size=2,\n",
        "            monotonicity=\"increasing\",\n",
        "            pwl_calibration_num_keypoints=20,\n",
        "            regularizer_configs=[\n",
        "                tfl.configs.RegularizerConfig(name=\"calib_wrinkle\", l2=1.0),\n",
        "            ],\n",
        "        ),\n",
        "        tfl.configs.FeatureConfig(\n",
        "            name=\"dollar_rating\",\n",
        "            lattice_size=2,\n",
        "            pwl_calibration_num_keypoints=4,\n",
        "            # Here we only specify one monotonicity:\n",
        "            # `D` resturants has smaller value than `DD` restaurants\n",
        "            monotonicity=[(\"D\", \"DD\")],\n",
        "        ),\n",
        "    ])\n",
        "tfl_estimator = tfl.estimators.CannedClassifier(\n",
        "    feature_columns=feature_columns,\n",
        "    model_config=model_config,\n",
        "    feature_analysis_input_fn=feature_analysis_input_fn,\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
        "    config=tf.estimator.RunConfig(tf_random_seed=42),\n",
        ")\n",
        "tfl_estimator.train(input_fn=train_input_fn)\n",
        "analyze_three_d_estimator(tfl_estimator, \"TF Lattice\")\n",
        "_ = save_and_visualize_lattice(tfl_estimator)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdIzhYL79_Pp"
      },
      "source": [
        "범주형 calibrator는 모델 출력의 선호도를 보여줍니다. DD &gt; D &gt; DDD &gt; DDDD는 설정과 일치합니다. 결측값에 대한 열도 있습니다. 훈련 및 테스트 데이터에는 누락된 특성이 없지만, 모델은 다운스트림 모델 제공 중에 발생하는 누락된 값에 대한 대체 값을 제공합니다.\n",
        "\n",
        "`dollar_rating`을 조건으로 이 모델의 예상 CTR도 플롯합니다. 필요한 모든 제약 조건이 각 슬라이스에서 충족됩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rh0H2b6l_rwZ"
      },
      "source": [
        "### 출력 보정"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPb2ri4e7HXF"
      },
      "source": [
        "지금까지 훈련한 모든 TFL 모델의 경우 격자 레이어(모델 그래프에서 'Lattice'로 표시됨)가 모델 예측을 직접 출력합니다. 때때로 격자 출력이 모델 출력을 내도록 재조정되어야 하는지는 확실하지 않습니다.\n",
        "\n",
        "- 특성은 $log$ 카운트이고 레이블은 카운트입니다.\n",
        "- 격자는 매우 적은 수의 꼭짓점을 갖도록 구성되지만 레이블 분포는 비교적 복잡합니다.\n",
        "\n",
        "이러한 경우 격자 출력과 모델 출력 사이에 또 다른 calibrator를 추가하여 모델 유연성을 높일 수 있습니다. 방금 구축한 모델에 5개의 키포인트가 있는 보정 레이어를 추가하겠습니다. 또한 함수를 원활하게 유지하기 위해 출력 calibrator용 regularizer를 추가합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k5Sg_gUj_0i4"
      },
      "outputs": [],
      "source": [
        "feature_columns = [\n",
        "    tf.feature_column.numeric_column(\"num_reviews\"),\n",
        "    tf.feature_column.numeric_column(\"avg_rating\"),\n",
        "    tf.feature_column.categorical_column_with_vocabulary_list(\n",
        "        \"dollar_rating\",\n",
        "        vocabulary_list=[\"D\", \"DD\", \"DDD\", \"DDDD\"],\n",
        "        dtype=tf.string,\n",
        "        default_value=0),\n",
        "]\n",
        "model_config = tfl.configs.CalibratedLatticeConfig(\n",
        "    output_calibration=True,\n",
        "    output_calibration_num_keypoints=5,\n",
        "    regularizer_configs=[\n",
        "        tfl.configs.RegularizerConfig(name=\"output_calib_wrinkle\", l2=0.1),\n",
        "    ],\n",
        "    feature_configs=[\n",
        "    tfl.configs.FeatureConfig(\n",
        "        name=\"num_reviews\",\n",
        "        lattice_size=2,\n",
        "        monotonicity=\"increasing\",\n",
        "        pwl_calibration_convexity=\"concave\",\n",
        "        pwl_calibration_num_keypoints=20,\n",
        "        regularizer_configs=[\n",
        "            tfl.configs.RegularizerConfig(name=\"calib_wrinkle\", l2=1.0),\n",
        "        ],\n",
        "        reflects_trust_in=[\n",
        "            tfl.configs.TrustConfig(\n",
        "                feature_name=\"avg_rating\", trust_type=\"edgeworth\"),\n",
        "        ],\n",
        "    ),\n",
        "    tfl.configs.FeatureConfig(\n",
        "        name=\"avg_rating\",\n",
        "        lattice_size=2,\n",
        "        monotonicity=\"increasing\",\n",
        "        pwl_calibration_num_keypoints=20,\n",
        "        regularizer_configs=[\n",
        "            tfl.configs.RegularizerConfig(name=\"calib_wrinkle\", l2=1.0),\n",
        "        ],\n",
        "    ),\n",
        "    tfl.configs.FeatureConfig(\n",
        "        name=\"dollar_rating\",\n",
        "        lattice_size=2,\n",
        "        pwl_calibration_num_keypoints=4,\n",
        "        # Here we only specify one monotonicity:\n",
        "        # `D` resturants has smaller value than `DD` restaurants\n",
        "        monotonicity=[(\"D\", \"DD\")],\n",
        "    ),\n",
        "])\n",
        "tfl_estimator = tfl.estimators.CannedClassifier(\n",
        "    feature_columns=feature_columns,\n",
        "    model_config=model_config,\n",
        "    feature_analysis_input_fn=feature_analysis_input_fn,\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
        "    config=tf.estimator.RunConfig(tf_random_seed=42),\n",
        ")\n",
        "tfl_estimator.train(input_fn=train_input_fn)\n",
        "analyze_three_d_estimator(tfl_estimator, \"TF Lattice\")\n",
        "_ = save_and_visualize_lattice(tfl_estimator)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLOGDrYY0hH7"
      },
      "source": [
        "최종 테스트 메트릭과 플롯은 상식적인 제약 조건을 사용하는 것이 모델이 예기치 않은 동작을 방지하고 전체 입력 공간으로 더 잘 외삽하는 데 어떻게 도움이 되는지 보여줍니다."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "shape_constraints.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
