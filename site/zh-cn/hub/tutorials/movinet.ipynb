{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "toCy3v03Dwx7"
      },
      "source": [
        "##### Copyright 2021 The TensorFlow Hub Authors.\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QKe-ubNcDvgv"
      },
      "outputs": [],
      "source": [
        "# Copyright 2021 The TensorFlow Hub Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# =============================================================================="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFdPvlXBOdUN"
      },
      "source": [
        "# 用于流式动作识别的 MoViNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfBg1C5NB3X0"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>     <a target=\"_blank\" href=\"https://tensorflow.google.cn/hub/tutorials/movinet\"><img src=\"https://tensorflow.google.cn/images/tf_logo_32px.png\">在 TensorFlow.org 上查看</a>\n",
        "</td>\n",
        "  <td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/zh-cn/hub/tutorials/movinet.ipynb\"><img src=\"https://tensorflow.google.cn/images/colab_logo_32px.png\">在 Google Colab 中运行</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/zh-cn/hub/tutorials/movinet.ipynb\">     <img src=\"https://tensorflow.google.cn/images/GitHub-Mark-32px.png\">     在 GitHub 上查看源代码</a></td>\n",
        "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/zh-cn/hub/tutorials/movinet.ipynb\"><img src=\"https://tensorflow.google.cn/images/download_logo_32px.png\">下载笔记本</a>   </td>\n",
        "  <td>     <a href=\"https://tfhub.dev/google/collections/movinet/1\"><img src=\"https://tensorflow.google.cn/images/hub_logo_32px.png\">查看 TF Hub 模型 </a>\n",
        "</td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vxk2Kbc_KSP"
      },
      "source": [
        "本教程运行预训练的视频分类模型来对给定视频中的活动（例如跳舞、游泳、骑自行车等）进行分类。\n",
        "\n",
        "本教程中使用的模型架构称为 [MoViNet](https://arxiv.org/pdf/2103.11511.pdf)（移动视频网络）。MoVieNet 是一系列在庞大数据集 ([Kinetics 600](https://deepmind.com/research/open-source/kinetics)) 上训练的高效视频分类模型。\n",
        "\n",
        "与 TF Hub 上提供的 [i3d 模型](https://tfhub.dev/s?q=i3d-kinetics)相比，MoViNet 还支持流式视频的逐帧推断。\n",
        "\n",
        "预训练模型可从 [TF Hub](https://tfhub.dev/google/collections/movinet/1) 获得。TF Hub 集合还包括为 [TFLite](https://tensorflow.org/lite) 优化的量化模型。\n",
        "\n",
        "这些模型的源代码可在 [TensorFlow Model Garden](https://github.com/tensorflow/models/tree/master/official/projects/movinet) 中找到。包括[本教程的较长版本](https://colab.sandbox.google.com/github/tensorflow/models/blob/master/official/projects/movinet/movinet_tutorial.ipynb)，较长版本还介绍了如何构建和微调 MoViNet 模型。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3E96e1UKQ8uR"
      },
      "source": [
        "![jumping jacks plot](https://storage.googleapis.com/tf_model_garden/vision/movinet/artifacts/jumpingjacks_plot.gif)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_oLnvJy7kz5"
      },
      "source": [
        "## 安装\n",
        "\n",
        "对于较小模型 (A0-A2) 的推断，CPU 对于此 Colab 来说已经足够。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GUgUMGmY1yq-"
      },
      "outputs": [],
      "source": [
        "!sudo apt install -y ffmpeg\n",
        "!pip install -q mediapy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s3khsunT7kWa"
      },
      "outputs": [],
      "source": [
        "!pip uninstall -q -y opencv-python-headless\n",
        "!pip install -q \"opencv-python-headless<4.3\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dI_1csl6Q-gH"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import pathlib\n",
        "\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import mediapy as media\n",
        "import numpy as np\n",
        "import PIL\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tqdm\n",
        "\n",
        "mpl.rcParams.update({\n",
        "    'font.size': 10,\n",
        "})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pn8K9oWbmREi"
      },
      "source": [
        "获取 kinetics 600 标签列表，并打印前几个标签："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2VJUAcjhkfb3"
      },
      "outputs": [],
      "source": [
        "labels_path = tf.keras.utils.get_file(\n",
        "    fname='labels.txt',\n",
        "    origin='https://raw.githubusercontent.com/tensorflow/models/f8af2291cced43fc9f1d9b41ddbf772ae7b0d7d2/official/projects/movinet/files/kinetics_600_labels.txt'\n",
        ")\n",
        "labels_path = pathlib.Path(labels_path)\n",
        "\n",
        "lines = labels_path.read_text().splitlines()\n",
        "KINETICS_600_LABELS = np.array([line.strip() for line in lines])\n",
        "KINETICS_600_LABELS[:20]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9BU5XsOmaq3"
      },
      "source": [
        "为了提供一个简单的示例视频进行分类，我们可以加载一个正在执行的跳跃运动的简短 gif。\n",
        "\n",
        "![jumping jacks](https://github.com/tensorflow/models/raw/f8af2291cced43fc9f1d9b41ddbf772ae7b0d7d2/official/projects/movinet/files/jumpingjack.gif)\n",
        "\n",
        "出处：[Bobby Bluford 教练](https://www.youtube.com/watch?v=-AxHpj-EuPg)根据 CC-BY 许可在 YouTube 上分享的视频。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8aFKMbr4mfSg"
      },
      "source": [
        "下载 gif。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w62jqXhaSb15"
      },
      "outputs": [],
      "source": [
        "jumpingjack_url = 'https://github.com/tensorflow/models/raw/f8af2291cced43fc9f1d9b41ddbf772ae7b0d7d2/official/projects/movinet/files/jumpingjack.gif'\n",
        "jumpingjack_path = tf.keras.utils.get_file(\n",
        "    fname='jumpingjack.gif',\n",
        "    origin=jumpingjack_url,\n",
        "    cache_dir='.', cache_subdir='.',\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdRS_22PebfB"
      },
      "source": [
        "定义一个将 gif 文件读入 `tf.Tensor` 的函数："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mPhmCu6oSi5f"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "# Read and process a video\n",
        "def load_gif(file_path, image_size=(224, 224)):\n",
        "  \"\"\"Loads a gif file into a TF tensor.\n",
        "\n",
        "  Use images resized to match what's expected by your model.\n",
        "  The model pages say the \"A2\" models expect 224 x 224 images at 5 fps\n",
        "\n",
        "  Args:\n",
        "    file_path: path to the location of a gif file.\n",
        "    image_size: a tuple of target size.\n",
        "\n",
        "  Returns:\n",
        "    a video of the gif file\n",
        "  \"\"\"\n",
        "  # Load a gif file, convert it to a TF tensor\n",
        "  raw = tf.io.read_file(file_path)\n",
        "  video = tf.io.decode_gif(raw)\n",
        "  # Resize the video\n",
        "  video = tf.image.resize(video, image_size)\n",
        "  # change dtype to a float32\n",
        "  # Hub models always want images normalized to [0,1]\n",
        "  # ref: https://tensorflow.google.cn/hub/common_signatures/images#input\n",
        "  video = tf.cast(video, tf.float32) / 255.\n",
        "  return video"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xx7cZm8vpDJm"
      },
      "source": [
        "视频的形状为 `(frames, height, width, colors)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E7k_PmbFSkHv"
      },
      "outputs": [],
      "source": [
        "jumpingjack=load_gif(jumpingjack_path)\n",
        "jumpingjack.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LcKFy3oedBvF"
      },
      "source": [
        "## 如何使用模型\n",
        "\n",
        "本部分包含演示如何使用 [TensorFlow Hub 中的模型](https://tfhub.dev/google/collections/movinet/1)的演练。如果您只想查看模型的实际运作，请跳至下一部分。\n",
        "\n",
        "每个模型都有两个版本：`base` 和 `streaming`。\n",
        "\n",
        "- `base` 版本将视频作为输入，并返回帧上的平均概率。\n",
        "- `streaming` 版本将视频帧和 RNN 状态作为输入，并返回该帧的预测和新的 RNN 状态。 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQO6Zb8Hm-9q"
      },
      "source": [
        "### 基础模型"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfnYU20JnPqp"
      },
      "source": [
        "[从 TensorFlow Hub 下载预训练模型](https://tfhub.dev/tensorflow/movinet/a2/base/kinetics-600/classification/3)。 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FnpPo6HSR7qv"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "id = 'a2'\n",
        "mode = 'base'\n",
        "version = '3'\n",
        "hub_url = f'https://tfhub.dev/tensorflow/movinet/{id}/{mode}/kinetics-600/classification/{version}'\n",
        "model = hub.load(hub_url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvaFwKhxndmb"
      },
      "source": [
        "此版本的模型具有一个 `signature`。它接受一个 `image` 参数，此参数是一个形状为 `(batch, frames, height, width, colors)` 的 `tf.float32`。它返回包含一个输出的字典：一个由形状为 `(batch, classes)` 的 logit 组成的 `tf.float32` 张量。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7GzZ4Y03T_gH"
      },
      "outputs": [],
      "source": [
        "sig = model.signatures['serving_default']\n",
        "print(sig.pretty_printed_signature())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4Xny1ANomi4"
      },
      "source": [
        "要在视频上运行此签名，您需要先将外部 `batch` 维度添加到视频中。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LBOFEDG1XvZE"
      },
      "outputs": [],
      "source": [
        "#warmup\n",
        "sig(image = jumpingjack[tf.newaxis, :1]);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jCeW3KycVbGn"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "logits = sig(image = jumpingjack[tf.newaxis, ...])\n",
        "logits = logits['classifier_head'][0]\n",
        "\n",
        "print(logits.shape)\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AE8doqkPpxED"
      },
      "source": [
        "定义一个 `get_top_k` 函数，将上述输出处理打包以备后用。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OozPNO6LvZ00"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "# Get top_k labels and probabilities\n",
        "def get_top_k(probs, k=5, label_map=KINETICS_600_LABELS):\n",
        "  \"\"\"Outputs the top k model labels and probabilities on the given video.\n",
        "\n",
        "  Args:\n",
        "    probs: probability tensor of shape (num_frames, num_classes) that represents\n",
        "      the probability of each class on each frame.\n",
        "    k: the number of top predictions to select.\n",
        "    label_map: a list of labels to map logit indices to label strings.\n",
        "\n",
        "  Returns:\n",
        "    a tuple of the top-k labels and probabilities.\n",
        "  \"\"\"\n",
        "  # Sort predictions to find top_k\n",
        "  top_predictions = tf.argsort(probs, axis=-1, direction='DESCENDING')[:k]\n",
        "  # collect the labels of top_k predictions\n",
        "  top_labels = tf.gather(label_map, top_predictions, axis=-1)\n",
        "  # decode lablels\n",
        "  top_labels = [label.decode('utf8') for label in top_labels.numpy()]\n",
        "  # top_k probabilities of the predictions\n",
        "  top_probs = tf.gather(probs, top_predictions, axis=-1).numpy()\n",
        "  return tuple(zip(top_labels, top_probs))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTfKMT29pP_Z"
      },
      "source": [
        "将 `logits` 转换为概率，并查找视频的前 5 个类。模型确认该视频可能是 `jumping jacks`。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z-SrNGsGV5Mt"
      },
      "outputs": [],
      "source": [
        "probs = tf.nn.softmax(logits, axis=-1)\n",
        "for label, p in get_top_k(probs):\n",
        "  print(f'{label:20s}: {p:.3f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltdijoQpqjxZ"
      },
      "source": [
        "### 流式模型"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dqdUPQXq45b"
      },
      "source": [
        "上一部分使用了一个贯穿整个视频的模型。通常在处理视频时，您不希望在最后进行单次预测，而是希望逐帧更新预测。`stream` 版本的模型可让您实现此目的。\n",
        "\n",
        "加载 `stream` 版本的模型。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mxt0hRXFZkAM"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "id = 'a2'\n",
        "mode = 'stream'\n",
        "version = '3'\n",
        "hub_url = f'https://tfhub.dev/tensorflow/movinet/{id}/{mode}/kinetics-600/classification/{version}'\n",
        "model = hub.load(hub_url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDswtsGgsYGS"
      },
      "source": [
        "此模型的用法比 `base` 模型略微复杂一些。您必须跟踪模型 RNN 的内部状态。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0fM_Vb1VsbDm"
      },
      "outputs": [],
      "source": [
        "list(model.signatures.keys())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojr1_iYCtPvp"
      },
      "source": [
        "`init_states` 签名将视频的**形状** `(batch, frames, height, width, colors)` 作为输入，并返回包含初始 RNN 状态的大型张量字典： "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "67loYFGpo_RP"
      },
      "outputs": [],
      "source": [
        "lines = model.signatures['init_states'].pretty_printed_signature().splitlines()\n",
        "lines = lines[:10]\n",
        "lines.append('      ...')\n",
        "print('.\\n'.join(lines))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v5lG3vejn5df"
      },
      "outputs": [],
      "source": [
        "initial_state = model.init_states(jumpingjack[tf.newaxis, ...].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J3DwmyHnuhH_"
      },
      "outputs": [],
      "source": [
        "type(initial_state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K8SyiEU6tB-e"
      },
      "outputs": [],
      "source": [
        "list(sorted(initial_state.keys()))[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xeMCzJMBvwRF"
      },
      "source": [
        "获得 RNN 的初始状态后，您可以传递状态和视频帧作为输入（保持视频帧的 `(batch, frames, height, width, colors)` 形状）。该模型会返回一个 `(logits, state)` 对。\n",
        "\n",
        "刚看到第一帧后，模型不相信视频是“跳跃运动”："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "McSLdIgtsI3d"
      },
      "outputs": [],
      "source": [
        "inputs = initial_state.copy()\n",
        "\n",
        "# Add the batch axis, take the first frme, but keep the frame-axis.\n",
        "inputs['image'] = jumpingjack[tf.newaxis, 0:1, ...] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WlH7PqLPX664"
      },
      "outputs": [],
      "source": [
        "# warmup\n",
        "model(inputs);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7uzNXtu7X5sr"
      },
      "outputs": [],
      "source": [
        "logits, new_state = model(inputs)\n",
        "logits = logits[0]\n",
        "probs = tf.nn.softmax(logits, axis=-1)\n",
        "\n",
        "for label, p in get_top_k(probs):\n",
        "  print(f'{label:20s}: {p:.3f}')\n",
        "\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLU644FQwXSb"
      },
      "source": [
        "如果您在循环中运行模型，并在每一帧中传递更新的状态，模型会迅速收敛到正确的结果："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fzm7T4ImmIEg"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "state = initial_state.copy()\n",
        "all_logits = []\n",
        "\n",
        "for n in range(len(jumpingjack)):\n",
        "  inputs = state\n",
        "  inputs['image'] = jumpingjack[tf.newaxis, n:n+1, ...]\n",
        "  result, state = model(inputs)\n",
        "  all_logits.append(logits)\n",
        "\n",
        "probabilities = tf.nn.softmax(all_logits, axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B7UtHoSWcOT2"
      },
      "outputs": [],
      "source": [
        "for label, p in get_top_k(probabilities[-1]):\n",
        "  print(f'{label:20s}: {p:.3f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ffV3NhZcsrv"
      },
      "outputs": [],
      "source": [
        "id = tf.argmax(probabilities[-1])\n",
        "plt.plot(probabilities[:, id])\n",
        "plt.xlabel('Frame #')\n",
        "plt.ylabel(f\"p('{KINETICS_600_LABELS[id]}')\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7MZ_AfRW845"
      },
      "source": [
        "您可能会注意到，最终概率比上一部分中运行 `base` 模型的确定性要高得多。`base` 模型返回帧上预测的平均值。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Wij4tsyW8dR"
      },
      "outputs": [],
      "source": [
        "for label, p in get_top_k(tf.reduce_mean(probabilities, axis=0)):\n",
        "  print(f'{label:20s}: {p:.3f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLUoC9ejggGo"
      },
      "source": [
        "## 让预测变成随时间变化的动画\n",
        "\n",
        "上一部分详细介绍了如何使用这些模型。本部分在此基础上生成一些不错的推断动画。 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OnFqOXazoWgy"
      },
      "source": [
        "下面的隐藏单元定义了本部分中使用的辅助函数。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "dx55NK3ZoZeh"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "# Get top_k labels and probabilities predicted using MoViNets streaming model\n",
        "def get_top_k_streaming_labels(probs, k=5, label_map=KINETICS_600_LABELS):\n",
        "  \"\"\"Returns the top-k labels over an entire video sequence.\n",
        "\n",
        "  Args:\n",
        "    probs: probability tensor of shape (num_frames, num_classes) that represents\n",
        "      the probability of each class on each frame.\n",
        "    k: the number of top predictions to select.\n",
        "    label_map: a list of labels to map logit indices to label strings.\n",
        "\n",
        "  Returns:\n",
        "    a tuple of the top-k probabilities, labels, and logit indices\n",
        "  \"\"\"\n",
        "  top_categories_last = tf.argsort(probs, -1, 'DESCENDING')[-1, :1]\n",
        "  # Sort predictions to find top_k\n",
        "  categories = tf.argsort(probs, -1, 'DESCENDING')[:, :k]\n",
        "  categories = tf.reshape(categories, [-1])\n",
        "\n",
        "  counts = sorted([\n",
        "      (i.numpy(), tf.reduce_sum(tf.cast(categories == i, tf.int32)).numpy())\n",
        "      for i in tf.unique(categories)[0]\n",
        "  ], key=lambda x: x[1], reverse=True)\n",
        "\n",
        "  top_probs_idx = tf.constant([i for i, _ in counts[:k]])\n",
        "  top_probs_idx = tf.concat([top_categories_last, top_probs_idx], 0)\n",
        "  # find unique indices of categories\n",
        "  top_probs_idx = tf.unique(top_probs_idx)[0][:k+1]\n",
        "  # top_k probabilities of the predictions\n",
        "  top_probs = tf.gather(probs, top_probs_idx, axis=-1)\n",
        "  top_probs = tf.transpose(top_probs, perm=(1, 0))\n",
        "  # collect the labels of top_k predictions\n",
        "  top_labels = tf.gather(label_map, top_probs_idx, axis=0)\n",
        "  # decode the top_k labels\n",
        "  top_labels = [label.decode('utf8') for label in top_labels.numpy()]\n",
        "\n",
        "  return top_probs, top_labels, top_probs_idx\n",
        "\n",
        "# Plot top_k predictions at a given time step\n",
        "def plot_streaming_top_preds_at_step(\n",
        "    top_probs,\n",
        "    top_labels,\n",
        "    step=None,\n",
        "    image=None,\n",
        "    legend_loc='lower left',\n",
        "    duration_seconds=10,\n",
        "    figure_height=500,\n",
        "    playhead_scale=0.8,\n",
        "    grid_alpha=0.3):\n",
        "  \"\"\"Generates a plot of the top video model predictions at a given time step.\n",
        "\n",
        "  Args:\n",
        "    top_probs: a tensor of shape (k, num_frames) representing the top-k\n",
        "      probabilities over all frames.\n",
        "    top_labels: a list of length k that represents the top-k label strings.\n",
        "    step: the current time step in the range [0, num_frames].\n",
        "    image: the image frame to display at the current time step.\n",
        "    legend_loc: the placement location of the legend.\n",
        "    duration_seconds: the total duration of the video.\n",
        "    figure_height: the output figure height.\n",
        "    playhead_scale: scale value for the playhead.\n",
        "    grid_alpha: alpha value for the gridlines.\n",
        "\n",
        "  Returns:\n",
        "    A tuple of the output numpy image, figure, and axes.\n",
        "  \"\"\"\n",
        "  # find number of top_k labels and frames in the video\n",
        "  num_labels, num_frames = top_probs.shape\n",
        "  if step is None:\n",
        "    step = num_frames\n",
        "  # Visualize frames and top_k probabilities of streaming video\n",
        "  fig = plt.figure(figsize=(6.5, 7), dpi=300)\n",
        "  gs = mpl.gridspec.GridSpec(8, 1)\n",
        "  ax2 = plt.subplot(gs[:-3, :])\n",
        "  ax = plt.subplot(gs[-3:, :])\n",
        "  # display the frame\n",
        "  if image is not None:\n",
        "    ax2.imshow(image, interpolation='nearest')\n",
        "    ax2.axis('off')\n",
        "  # x-axis (frame number)\n",
        "  preview_line_x = tf.linspace(0., duration_seconds, num_frames)\n",
        "  # y-axis (top_k probabilities)\n",
        "  preview_line_y = top_probs\n",
        "\n",
        "  line_x = preview_line_x[:step+1]\n",
        "  line_y = preview_line_y[:, :step+1]\n",
        "\n",
        "  for i in range(num_labels):\n",
        "    ax.plot(preview_line_x, preview_line_y[i], label=None, linewidth='1.5',\n",
        "            linestyle=':', color='gray')\n",
        "    ax.plot(line_x, line_y[i], label=top_labels[i], linewidth='2.0')\n",
        "\n",
        "\n",
        "  ax.grid(which='major', linestyle=':', linewidth='1.0', alpha=grid_alpha)\n",
        "  ax.grid(which='minor', linestyle=':', linewidth='0.5', alpha=grid_alpha)\n",
        "\n",
        "  min_height = tf.reduce_min(top_probs) * playhead_scale\n",
        "  max_height = tf.reduce_max(top_probs)\n",
        "  ax.vlines(preview_line_x[step], min_height, max_height, colors='red')\n",
        "  ax.scatter(preview_line_x[step], max_height, color='red')\n",
        "\n",
        "  ax.legend(loc=legend_loc)\n",
        "\n",
        "  plt.xlim(0, duration_seconds)\n",
        "  plt.ylabel('Probability')\n",
        "  plt.xlabel('Time (s)')\n",
        "  plt.yscale('log')\n",
        "\n",
        "  fig.tight_layout()\n",
        "  fig.canvas.draw()\n",
        "\n",
        "  data = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)\n",
        "  data = data.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
        "  plt.close()\n",
        "\n",
        "  figure_width = int(figure_height * data.shape[1] / data.shape[0])\n",
        "  image = PIL.Image.fromarray(data).resize([figure_width, figure_height])\n",
        "  image = np.array(image)\n",
        "\n",
        "  return image\n",
        "\n",
        "# Plotting top_k predictions from MoViNets streaming model\n",
        "def plot_streaming_top_preds(\n",
        "    probs,\n",
        "    video,\n",
        "    top_k=5,\n",
        "    video_fps=25.,\n",
        "    figure_height=500,\n",
        "    use_progbar=True):\n",
        "  \"\"\"Generates a video plot of the top video model predictions.\n",
        "\n",
        "  Args:\n",
        "    probs: probability tensor of shape (num_frames, num_classes) that represents\n",
        "      the probability of each class on each frame.\n",
        "    video: the video to display in the plot.\n",
        "    top_k: the number of top predictions to select.\n",
        "    video_fps: the input video fps.\n",
        "    figure_fps: the output video fps.\n",
        "    figure_height: the height of the output video.\n",
        "    use_progbar: display a progress bar.\n",
        "\n",
        "  Returns:\n",
        "    A numpy array representing the output video.\n",
        "  \"\"\"\n",
        "  # select number of frames per second\n",
        "  video_fps = 8.\n",
        "  # select height of the image\n",
        "  figure_height = 500\n",
        "  # number of time steps of the given video\n",
        "  steps = video.shape[0]\n",
        "  # estimate duration of the video (in seconds)\n",
        "  duration = steps / video_fps\n",
        "  # estiamte top_k probabilities and corresponding labels\n",
        "  top_probs, top_labels, _ = get_top_k_streaming_labels(probs, k=top_k)\n",
        "\n",
        "  images = []\n",
        "  step_generator = tqdm.trange(steps) if use_progbar else range(steps)\n",
        "  for i in step_generator:\n",
        "    image = plot_streaming_top_preds_at_step(\n",
        "        top_probs=top_probs,\n",
        "        top_labels=top_labels,\n",
        "        step=i,\n",
        "        image=video[i],\n",
        "        duration_seconds=duration,\n",
        "        figure_height=figure_height,\n",
        "    )\n",
        "    images.append(image)\n",
        "\n",
        "  return np.array(images)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLgFBslcZOQO"
      },
      "source": [
        "首先，在视频的帧上运行流式模型，然后收集 logit："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tXWR13wthnK5"
      },
      "outputs": [],
      "source": [
        "init_states = model.init_states(jumpingjack[tf.newaxis].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YqSkt7l8ltwt"
      },
      "outputs": [],
      "source": [
        "# Insert your video clip here\n",
        "video = jumpingjack\n",
        "images = tf.split(video[tf.newaxis], video.shape[0], axis=1)\n",
        "\n",
        "all_logits = []\n",
        "\n",
        "# To run on a video, pass in one frame at a time\n",
        "states = init_states\n",
        "for image in tqdm.tqdm(images):\n",
        "  # predictions for each frame\n",
        "  logits, states = model({**states, 'image': image})\n",
        "  all_logits.append(logits)\n",
        "\n",
        "# concatinating all the logits\n",
        "logits = tf.concat(all_logits, 0)\n",
        "# estimating probabilities\n",
        "probs = tf.nn.softmax(logits, axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OOGcCMMJyuPl"
      },
      "outputs": [],
      "source": [
        "final_probs = probs[-1]\n",
        "print('Top_k predictions and their probablities\\n')\n",
        "for label, p in get_top_k(final_probs):\n",
        "  print(f'{label:20s}: {p:.3f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GaybT0rbZct-"
      },
      "source": [
        "将概率序列转换为视频："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xdox556CtMRb"
      },
      "outputs": [],
      "source": [
        "# Generate a plot and output to a video tensor\n",
        "plot_video = plot_streaming_top_preds(probs, video, video_fps=8.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NSStKE9klCs3"
      },
      "outputs": [],
      "source": [
        "# For gif format, set codec='gif'\n",
        "media.show_video(plot_video, fps=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCImgZ3OdJw7"
      },
      "source": [
        "## 资源\n",
        "\n",
        "预训练模型可从 [TF Hub](https://tfhub.dev/google/collections/movinet/1) 获得。TF Hub 集合还包括为 [TFLite](https://tensorflow.org/lite) 优化的量化模型。\n",
        "\n",
        "这些模型的源代码可在 [TensorFlow Model Garden](https://github.com/tensorflow/models/tree/master/official/projects/movinet) 中找到。包括[本教程的较长版本](https://colab.sandbox.google.com/github/tensorflow/models/blob/master/official/projects/movinet/movinet_tutorial.ipynb)，较长版本还介绍了如何构建和微调 MoViNet 模型。 "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "movinet.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
