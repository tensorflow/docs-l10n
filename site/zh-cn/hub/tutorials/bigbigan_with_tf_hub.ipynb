{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLOYL1PJAAtK"
      },
      "source": [
        "##### Copyright 2019 The TensorFlow Hub Authors.\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3fJWQ8WSAFhh"
      },
      "outputs": [],
      "source": [
        "# Copyright 2019 The TensorFlow Hub Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# =============================================================================="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1NTVIH6ABK-"
      },
      "source": [
        "# 使用 BigBiGAN 生成图像\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfBg1C5NB3X0"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td><a target=\"_blank\" href=\"https://tensorflow.google.cn/hub/tutorials/bigbigan_with_tf_hub\"><img src=\"https://tensorflow.google.cn/images/tf_logo_32px.png\">在 TensorFlow.org 查看</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/zh-cn/hub/tutorials/bigbigan_with_tf_hub.ipynb\"><img src=\"https://tensorflow.google.cn/images/colab_logo_32px.png\">在 Google Colab 中运行 </a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/zh-cn/hub/tutorials/bigbigan_with_tf_hub.ipynb\"><img src=\"https://tensorflow.google.cn/images/GitHub-Mark-32px.png\">在 GitHub 上查看源代码</a></td>\n",
        "  <td><a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/zh-cn/hub/tutorials/bigbigan_with_tf_hub.ipynb\"><img src=\"https://tensorflow.google.cn/images/download_logo_32px.png\">下载笔记本</a></td>\n",
        "  <td><a href=\"https://tfhub.dev/s?q=experts%2Fbert\"><img src=\"https://tensorflow.google.cn/images/hub_logo_32px.png\">查看 TF Hub 模型</a></td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVvOoEhswyZg"
      },
      "source": [
        "此笔记本演示了 [TF Hub](https://tfhub.dev/s?publisher=deepmind&q=bigbigan) 上可用的 *BigBiGAN* 模型。\n",
        "\n",
        "BigBiGAN 通过添加可用于无监督表示学习的*编码器*模块，对标准 (Big)GAN 进行了扩展。大致来说，在给定实际数据 `x` 的情况下，编码器可以通过预测潜在的 `z` 来使生成器逆转。有关这些模型的更多信息，请参阅 [arXiv 上的 BigBiGAN 论文](https://arxiv.org/abs/1907.02544) [1]。\n",
        "\n",
        "连接到运行时后，请按照以下说明开始操作：\n",
        "\n",
        "1. （可选）在下面的第一个代码单元中更新所选的 **`module_path`**，为不同的编码器架构加载 BigBiGAN 生成器。\n",
        "2. 点击 **Runtime &gt; Run all** 按顺序运行每个单元。然后，下方会自动显示输出（包括 BigBiGAN 样本的可视化和重构）。\n",
        "\n",
        "注：如果遇到任何问题，可以点击 **Runtime &gt; Restart and run all...**，重启运行时并从头开始运行所有单元。\n",
        "\n",
        "[1] Jeff Donahue and Karen Simonyan. [Large Scale Adversarial Representation Learning](https://arxiv.org/abs/1907.02544). *arxiv:1907.02544*, 2019."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DtGFwUKOA9jt"
      },
      "source": [
        "首先，设置模块路径。默认情况下，我们从 **`https://tfhub.dev/deepmind/bigbigan-resnet50/1`** 使用基于 ResNet-50 的较小编码器加载 BigBiGAN 模型。要加载基于 RevNet-50-x4 的较大模型以获得最佳的表示学习结果，请注释掉有效的 **`module_path`** 设置，然后取消注释另一个设置。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xoY9pl0FBoUS"
      },
      "outputs": [],
      "source": [
        "module_path = 'https://tfhub.dev/deepmind/bigbigan-resnet50/1'  # ResNet-50\n",
        "# module_path = 'https://tfhub.dev/deepmind/bigbigan-revnet50x4/1'  # RevNet-50 x4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lr01cszC_vcC"
      },
      "source": [
        "## 设置"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TPdT-hYj1XXQ"
      },
      "outputs": [],
      "source": [
        "import io\n",
        "import IPython.display\n",
        "import PIL.Image\n",
        "from pprint import pformat\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "\n",
        "import tensorflow_hub as hub"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ouePZy6-CFJl"
      },
      "source": [
        "## 定义一些显示图像的函数"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MBQPtmrY2N91"
      },
      "outputs": [],
      "source": [
        "def imgrid(imarray, cols=4, pad=1, padval=255, row_major=True):\n",
        "  \"\"\"Lays out a [N, H, W, C] image array as a single image grid.\"\"\"\n",
        "  pad = int(pad)\n",
        "  if pad < 0:\n",
        "    raise ValueError('pad must be non-negative')\n",
        "  cols = int(cols)\n",
        "  assert cols >= 1\n",
        "  N, H, W, C = imarray.shape\n",
        "  rows = N // cols + int(N % cols != 0)\n",
        "  batch_pad = rows * cols - N\n",
        "  assert batch_pad >= 0\n",
        "  post_pad = [batch_pad, pad, pad, 0]\n",
        "  pad_arg = [[0, p] for p in post_pad]\n",
        "  imarray = np.pad(imarray, pad_arg, 'constant', constant_values=padval)\n",
        "  H += pad\n",
        "  W += pad\n",
        "  grid = (imarray\n",
        "          .reshape(rows, cols, H, W, C)\n",
        "          .transpose(0, 2, 1, 3, 4)\n",
        "          .reshape(rows*H, cols*W, C))\n",
        "  if pad:\n",
        "    grid = grid[:-pad, :-pad]\n",
        "  return grid\n",
        "\n",
        "def interleave(*args):\n",
        "  \"\"\"Interleaves input arrays of the same shape along the batch axis.\"\"\"\n",
        "  if not args:\n",
        "    raise ValueError('At least one argument is required.')\n",
        "  a0 = args[0]\n",
        "  if any(a.shape != a0.shape for a in args):\n",
        "    raise ValueError('All inputs must have the same shape.')\n",
        "  if not a0.shape:\n",
        "    raise ValueError('Inputs must have at least one axis.')\n",
        "  out = np.transpose(args, [1, 0] + list(range(2, len(a0.shape) + 1)))\n",
        "  out = out.reshape(-1, *a0.shape[1:])\n",
        "  return out\n",
        "\n",
        "def imshow(a, format='png', jpeg_fallback=True):\n",
        "  \"\"\"Displays an image in the given format.\"\"\"\n",
        "  a = a.astype(np.uint8)\n",
        "  data = io.BytesIO()\n",
        "  PIL.Image.fromarray(a).save(data, format)\n",
        "  im_data = data.getvalue()\n",
        "  try:\n",
        "    disp = IPython.display.display(IPython.display.Image(im_data))\n",
        "  except IOError:\n",
        "    if jpeg_fallback and format != 'jpeg':\n",
        "      print ('Warning: image was too large to display in format \"{}\"; '\n",
        "             'trying jpeg instead.').format(format)\n",
        "      return imshow(a, format='jpeg')\n",
        "    else:\n",
        "      raise\n",
        "  return disp\n",
        "\n",
        "def image_to_uint8(x):\n",
        "  \"\"\"Converts [-1, 1] float array to [0, 255] uint8.\"\"\"\n",
        "  x = np.asarray(x)\n",
        "  x = (256. / 2.) * (x + 1.)\n",
        "  x = np.clip(x, 0, 255)\n",
        "  x = x.astype(np.uint8)\n",
        "  return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ASXPMb6CaXR"
      },
      "source": [
        "## 加载 BigBiGAN TF Hub 模块并显示其可用功能"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IuG7G1ToCtaf"
      },
      "outputs": [],
      "source": [
        "# module = hub.Module(module_path, trainable=True, tags={'train'})  # training\n",
        "module = hub.Module(module_path)  # inference\n",
        "\n",
        "for signature in module.get_signature_names():\n",
        "  print('Signature:', signature)\n",
        "  print('Inputs:', pformat(module.get_input_info_dict(signature)))\n",
        "  print('Outputs:', pformat(module.get_output_info_dict(signature)))\n",
        "  print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sAY-AmcNCj9_"
      },
      "source": [
        "## 定义封装容器类来方便地访问各种函数"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aTKHkxfx1dAL"
      },
      "outputs": [],
      "source": [
        "class BigBiGAN(object):\n",
        "\n",
        "  def __init__(self, module):\n",
        "    \"\"\"Initialize a BigBiGAN from the given TF Hub module.\"\"\"\n",
        "    self._module = module\n",
        "\n",
        "  def generate(self, z, upsample=False):\n",
        "    \"\"\"Run a batch of latents z through the generator to generate images.\n",
        "\n",
        "    Args:\n",
        "      z: A batch of 120D Gaussian latents, shape [N, 120].\n",
        "\n",
        "    Returns: a batch of generated RGB images, shape [N, 128, 128, 3], range\n",
        "      [-1, 1].\n",
        "    \"\"\"\n",
        "    outputs = self._module(z, signature='generate', as_dict=True)\n",
        "    return outputs['upsampled' if upsample else 'default']\n",
        "\n",
        "  def make_generator_ph(self):\n",
        "    \"\"\"Creates a tf.placeholder with the dtype & shape of generator inputs.\"\"\"\n",
        "    info = self._module.get_input_info_dict('generate')['z']\n",
        "    return tf.placeholder(dtype=info.dtype, shape=info.get_shape())\n",
        "\n",
        "  def gen_pairs_for_disc(self, z):\n",
        "    \"\"\"Compute generator input pairs (G(z), z) for discriminator, given z.\n",
        "\n",
        "    Args:\n",
        "      z: A batch of latents (120D standard Gaussians), shape [N, 120].\n",
        "\n",
        "    Returns: a tuple (G(z), z) of discriminator inputs.\n",
        "    \"\"\"\n",
        "    # Downsample 256x256 image x for 128x128 discriminator input.\n",
        "    x = self.generate(z)\n",
        "    return x, z\n",
        "\n",
        "  def encode(self, x, return_all_features=False):\n",
        "    \"\"\"Run a batch of images x through the encoder.\n",
        "\n",
        "    Args:\n",
        "      x: A batch of data (256x256 RGB images), shape [N, 256, 256, 3], range\n",
        "        [-1, 1].\n",
        "      return_all_features: If True, return all features computed by the encoder.\n",
        "        Otherwise (default) just return a sample z_hat.\n",
        "\n",
        "    Returns: the sample z_hat of shape [N, 120] (or a dict of all features if\n",
        "      return_all_features).\n",
        "    \"\"\"\n",
        "    outputs = self._module(x, signature='encode', as_dict=True)\n",
        "    return outputs if return_all_features else outputs['z_sample']\n",
        "\n",
        "  def make_encoder_ph(self):\n",
        "    \"\"\"Creates a tf.placeholder with the dtype & shape of encoder inputs.\"\"\"\n",
        "    info = self._module.get_input_info_dict('encode')['x']\n",
        "    return tf.placeholder(dtype=info.dtype, shape=info.get_shape())\n",
        "\n",
        "  def enc_pairs_for_disc(self, x):\n",
        "    \"\"\"Compute encoder input pairs (x, E(x)) for discriminator, given x.\n",
        "\n",
        "    Args:\n",
        "      x: A batch of data (256x256 RGB images), shape [N, 256, 256, 3], range\n",
        "        [-1, 1].\n",
        "\n",
        "    Returns: a tuple (downsample(x), E(x)) of discriminator inputs.\n",
        "    \"\"\"\n",
        "    # Downsample 256x256 image x for 128x128 discriminator input.\n",
        "    x_down = tf.nn.avg_pool(x, ksize=2, strides=2, padding='SAME')\n",
        "    z = self.encode(x)\n",
        "    return x_down, z\n",
        "\n",
        "  def discriminate(self, x, z):\n",
        "    \"\"\"Compute the discriminator scores for pairs of data (x, z).\n",
        "\n",
        "    (x, z) must be batches with the same leading batch dimension, and joint\n",
        "      scores are computed on corresponding pairs x[i] and z[i].\n",
        "\n",
        "    Args:\n",
        "      x: A batch of data (128x128 RGB images), shape [N, 128, 128, 3], range\n",
        "        [-1, 1].\n",
        "      z: A batch of latents (120D standard Gaussians), shape [N, 120].\n",
        "\n",
        "    Returns:\n",
        "      A dict of scores:\n",
        "        score_xz: the joint scores for the (x, z) pairs.\n",
        "        score_x: the unary scores for x only.\n",
        "        score_z: the unary scores for z only.\n",
        "    \"\"\"\n",
        "    inputs = dict(x=x, z=z)\n",
        "    return self._module(inputs, signature='discriminate', as_dict=True)\n",
        "\n",
        "  def reconstruct_x(self, x, use_sample=True, upsample=False):\n",
        "    \"\"\"Compute BigBiGAN reconstructions of images x via G(E(x)).\n",
        "\n",
        "    Args:\n",
        "      x: A batch of data (256x256 RGB images), shape [N, 256, 256, 3], range\n",
        "        [-1, 1].\n",
        "      use_sample: takes a sample z_hat ~ E(x). Otherwise, deterministically\n",
        "        use the mean. (Though a sample z_hat may be far from the mean z,\n",
        "        typically the resulting recons G(z_hat) and G(z) are very\n",
        "        similar.\n",
        "      upsample: if set, upsample the reconstruction to the input resolution\n",
        "        (256x256). Otherwise return the raw lower resolution generator output\n",
        "        (128x128).\n",
        "\n",
        "    Returns: a batch of recons G(E(x)), shape [N, 256, 256, 3] if\n",
        "      `upsample`, otherwise [N, 128, 128, 3].\n",
        "    \"\"\"\n",
        "    if use_sample:\n",
        "      z = self.encode(x)\n",
        "    else:\n",
        "      z = self.encode(x, return_all_features=True)['z_mean']\n",
        "    recons = self.generate(z, upsample=upsample)\n",
        "    return recons\n",
        "\n",
        "  def losses(self, x, z):\n",
        "    \"\"\"Compute per-module BigBiGAN losses given data & latent sample batches.\n",
        "\n",
        "    Args:\n",
        "      x: A batch of data (256x256 RGB images), shape [N, 256, 256, 3], range\n",
        "        [-1, 1].\n",
        "      z: A batch of latents (120D standard Gaussians), shape [M, 120].\n",
        "\n",
        "    For the original BigBiGAN losses, pass batches of size N=M=2048, with z's\n",
        "    sampled from a 120D standard Gaussian (e.g., np.random.randn(2048, 120)),\n",
        "    and x's sampled from the ImageNet (ILSVRC2012) training set with the\n",
        "    \"ResNet-style\" preprocessing from:\n",
        "\n",
        "        https://github.com/tensorflow/tpu/blob/master/models/official/resnet/resnet_preprocessing.py\n",
        "\n",
        "    Returns:\n",
        "      A dict of per-module losses:\n",
        "        disc: loss for the discriminator.\n",
        "        enc: loss for the encoder.\n",
        "        gen: loss for the generator.\n",
        "    \"\"\"\n",
        "    # Compute discriminator scores on (x, E(x)) pairs.\n",
        "    # Downsample 256x256 image x for 128x128 discriminator input.\n",
        "    scores_enc_x_dict = self.discriminate(*self.enc_pairs_for_disc(x))\n",
        "    scores_enc_x = tf.concat([scores_enc_x_dict['score_xz'],\n",
        "                              scores_enc_x_dict['score_x'],\n",
        "                              scores_enc_x_dict['score_z']], axis=0)\n",
        "\n",
        "    # Compute discriminator scores on (G(z), z) pairs.\n",
        "    scores_gen_z_dict = self.discriminate(*self.gen_pairs_for_disc(z))\n",
        "    scores_gen_z = tf.concat([scores_gen_z_dict['score_xz'],\n",
        "                              scores_gen_z_dict['score_x'],\n",
        "                              scores_gen_z_dict['score_z']], axis=0)\n",
        "\n",
        "    disc_loss_enc_x = tf.reduce_mean(tf.nn.relu(1. - scores_enc_x))\n",
        "    disc_loss_gen_z = tf.reduce_mean(tf.nn.relu(1. + scores_gen_z))\n",
        "    disc_loss = disc_loss_enc_x + disc_loss_gen_z\n",
        "\n",
        "    enc_loss = tf.reduce_mean(scores_enc_x)\n",
        "    gen_loss = tf.reduce_mean(-scores_gen_z)\n",
        "\n",
        "    return dict(disc=disc_loss, enc=enc_loss, gen=gen_loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5L5SFfH4C9gu"
      },
      "source": [
        "## 创建张量稍后用于计算样本、重构、判别器得分和损失"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "goxtzcb-19NA"
      },
      "outputs": [],
      "source": [
        "bigbigan = BigBiGAN(module)\n",
        "\n",
        "# Make input placeholders for x (`enc_ph`) and z (`gen_ph`).\n",
        "enc_ph = bigbigan.make_encoder_ph()\n",
        "gen_ph = bigbigan.make_generator_ph()\n",
        "\n",
        "# Compute samples G(z) from encoder input z (`gen_ph`).\n",
        "gen_samples = bigbigan.generate(gen_ph)\n",
        "\n",
        "# Compute reconstructions G(E(x)) of encoder input x (`enc_ph`).\n",
        "recon_x = bigbigan.reconstruct_x(enc_ph, upsample=True)\n",
        "\n",
        "# Compute encoder features used for representation learning evaluations given\n",
        "# encoder input x (`enc_ph`).\n",
        "enc_features = bigbigan.encode(enc_ph, return_all_features=True)\n",
        "\n",
        "# Compute discriminator scores for encoder pairs (x, E(x)) given x (`enc_ph`)\n",
        "# and generator pairs (G(z), z) given z (`gen_ph`).\n",
        "disc_scores_enc = bigbigan.discriminate(*bigbigan.enc_pairs_for_disc(enc_ph))\n",
        "disc_scores_gen = bigbigan.discriminate(*bigbigan.gen_pairs_for_disc(gen_ph))\n",
        "\n",
        "# Compute losses.\n",
        "losses = bigbigan.losses(enc_ph, gen_ph)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ly7LWnSUDQ_P"
      },
      "source": [
        "## 创建 TensorFlow 会话并初始化变量"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CPnzCHDWFJwx"
      },
      "outputs": [],
      "source": [
        "init = tf.global_variables_initializer()\n",
        "sess = tf.Session()\n",
        "sess.run(init)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcEVS26D-ues"
      },
      "source": [
        "# 生成器样本"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYSA8Zvb-w7S"
      },
      "source": [
        "首先，我们对来自标准高斯（通过 `np.random.randn`）的生成器输入 `z` 进行采样，并显示其生成的图像，从而对预训练 BigBiGAN 生成器的样本进行可视化。到目前为止，我们并没有超越标准 GAN 的上限，目前仅使用了生成器（并忽略了编码器）。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9zfpvw8fGNMr"
      },
      "outputs": [],
      "source": [
        "feed_dict = {gen_ph: np.random.randn(32, 120)}\n",
        "_out_samples = sess.run(gen_samples, feed_dict=feed_dict)\n",
        "print('samples shape:', _out_samples.shape)\n",
        "imshow(imgrid(image_to_uint8(_out_samples), cols=4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9v58CTfl8jTc"
      },
      "source": [
        "# 从 TF-Flowers 数据集加载 `test_images`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0kmzQ4EqKJt"
      },
      "source": [
        "BigBiGAN 在 ImageNet 上进行了训练，但由于它太大而无法在本演示中使用，因此我们使用较小的 TF-Flowers [1] 数据集作为可视化重构和计算编码器特征的输入。\n",
        "\n",
        "在下面的单元中，我们加载 TF-Flowers（如果需要，请下载数据集），并将 256x256 RGB 图像样本的固定批次存储在 NumPy 数组 `test_images` 中。\n",
        "\n",
        "[1] https://tensorflow.google.cn/datasets/catalog/tf_flowers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OBgpkMdkUjL-"
      },
      "outputs": [],
      "source": [
        "def get_flowers_data():\n",
        "  \"\"\"Returns a [32, 256, 256, 3] np.array of preprocessed TF-Flowers samples.\"\"\"\n",
        "  import tensorflow_datasets as tfds\n",
        "  ds, info = tfds.load('tf_flowers', split='train', with_info=True)\n",
        "\n",
        "  # Just get the images themselves as we don't need labels for this demo.\n",
        "  ds = ds.map(lambda x: x['image'])\n",
        "\n",
        "  # Filter out small images (with minor edge length <256).\n",
        "  ds = ds.filter(lambda x: tf.reduce_min(tf.shape(x)[:2]) >= 256)\n",
        "\n",
        "  # Take the center square crop of the image and resize to 256x256.\n",
        "  def crop_and_resize(image):\n",
        "    imsize = tf.shape(image)[:2]\n",
        "    minor_edge = tf.reduce_min(imsize)\n",
        "    start = (imsize - minor_edge) // 2\n",
        "    stop = start + minor_edge\n",
        "    cropped_image = image[start[0] : stop[0], start[1] : stop[1]]\n",
        "    resized_image = tf.image.resize_bicubic([cropped_image], [256, 256])[0]\n",
        "    return resized_image\n",
        "  ds = ds.map(crop_and_resize)\n",
        "\n",
        "  # Convert images from [0, 255] uint8 to [-1, 1] float32.\n",
        "  ds = ds.map(lambda image: tf.cast(image, tf.float32) / (255. / 2.) - 1)\n",
        "\n",
        "  # Take the first 32 samples.\n",
        "  ds = ds.take(32)\n",
        "\n",
        "  return np.array(list(tfds.as_numpy(ds)))\n",
        "\n",
        "test_images = get_flowers_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAFJQU597n2A"
      },
      "source": [
        "# 重构"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmCQ9N9b7ptM"
      },
      "source": [
        "现在，我们通过编码器传递真实图像并通过生成器传回，以此方式在给定图像 `x` 的情况下计算 `G(E(x))`，从而实现对 BigBiGAN 重构的可视化。输入图像 `x` 显示在下方左列中，而相应的重构显示在右列中。\n",
        "\n",
        "请注意，重构并不是输入图像的像素级完美匹配；相反，它们倾向于捕获输入的高级语义内容，同时“忽略”大部分低级细节。这表明 BigBiGAN 编码器可能会学习捕获关于图像的高级语义信息（即，我们希望在表示学习方法中看到的那些信息）的类型。\n",
        "\n",
        "还要注意，256x256 输入图像的原始重构的分辨率为生成器生成的较低分辨率 (128x128)。出于可视化的目的，我们会对它们进行上采样。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R2F3eq8aFRle"
      },
      "outputs": [],
      "source": [
        "test_images_batch = test_images[:16]\n",
        "_out_recons = sess.run(recon_x, feed_dict={enc_ph: test_images_batch})\n",
        "print('reconstructions shape:', _out_recons.shape)\n",
        "\n",
        "inputs_and_recons = interleave(test_images_batch, _out_recons)\n",
        "print('inputs_and_recons shape:', inputs_and_recons.shape)\n",
        "imshow(imgrid(image_to_uint8(inputs_and_recons), cols=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPpW3qdbEpXL"
      },
      "source": [
        "# 编码器特征"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2gAW76YxEsZa"
      },
      "source": [
        "现在，我们演示如何通过用于标准表示学习评估的编码器来计算特征。\n",
        "\n",
        "这些特征可用在基于线性或最近邻的分类器中。我们还包括全局平均池化（`avepool_feat` 键）后获取的标准特征，以及用于获得最佳结果的较大的“BN+CReLU”特征（`bn_crelu_feat` 键）。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hpZYe5S_FQEw"
      },
      "outputs": [],
      "source": [
        "_out_features = sess.run(enc_features, feed_dict={enc_ph: test_images_batch})\n",
        "print('AvePool features shape:', _out_features['avepool_feat'].shape)\n",
        "print('BN+CReLU features shape:', _out_features['bn_crelu_feat'].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGzahsms2w9a"
      },
      "source": [
        "# 判别器得分和损失"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2_5BIBN21Hr"
      },
      "source": [
        "最后，我们将在编码器和生成器对的批次上计算判别器得分和损失。这些损失可以传递给优化器来训练 BigBiGAN。\n",
        "\n",
        "我们将上述图像批次用作编码器输入 `x`，将编码器得分作为 `D(x, E(x))` 进行计算。对于生成器输入，我们通过 `np.random.randn` 从 120D 标准高斯对 `z` 进行采样，将生成器得分作为 `D(G(z), z)` 进行计算。\n",
        "\n",
        "判别器预测 `(x, z)` 对的联合得分 `score_xz`，以及 `x` 和 `z` 的一元得分 `score_x` 和 `score_z`。经过训练，它可为编码器对给出高（正）分，并为生成器对给出低（负）分。尽管一元 `score_z` 在两种情况下均为负值，但这对于下面的代码基本成立，这表明编码器输出 `E(x)` 与高斯的实际样本类似。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8JJ8Go0dr22-"
      },
      "outputs": [],
      "source": [
        "feed_dict = {enc_ph: test_images, gen_ph: np.random.randn(32, 120)}\n",
        "_out_scores_enc, _out_scores_gen, _out_losses = sess.run(\n",
        "    [disc_scores_enc, disc_scores_gen, losses], feed_dict=feed_dict)\n",
        "print('Encoder scores:', {k: v.mean() for k, v in _out_scores_enc.items()})\n",
        "print('Generator scores:', {k: v.mean() for k, v in _out_scores_gen.items()})\n",
        "print('Losses:', _out_losses)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "9v58CTfl8jTc"
      ],
      "name": "bigbigan_with_tf_hub.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
