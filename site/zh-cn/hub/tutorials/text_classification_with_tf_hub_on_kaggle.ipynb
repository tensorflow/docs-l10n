{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6ZDpd9XzFeN"
      },
      "source": [
        "##### Copyright 2018 The TensorFlow Hub Authors.\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "KUu4vOt5zI9d"
      },
      "outputs": [],
      "source": [
        "# Copyright 2018 The TensorFlow Hub Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# =============================================================================="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ok9PfyoQ2rH_"
      },
      "source": [
        "# 如何使用 TF-Hub 解决 Kaggle 上的问题\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfBg1C5NB3X0"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>     <a target=\"_blank\" href=\"https://tensorflow.google.cn/hub/tutorials/text_classification_with_tf_hub_on_kaggle\"><img src=\"https://tensorflow.google.cn/images/tf_logo_32px.png\">View on TensorFlow.org</a>   </td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/zh-cn/hub/tutorials/text_classification_with_tf_hub_on_kaggle.ipynb\"><img src=\"https://tensorflow.google.cn/images/colab_logo_32px.png\">Run in Google Colab</a>   </td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/zh-cn/hub/tutorials/text_classification_with_tf_hub_on_kaggle.ipynb\"><img src=\"https://tensorflow.google.cn/images/GitHub-Mark-32px.png\">View on GitHub</a>   </td>\n",
        "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/zh-cn/hub/tutorials/text_classification_with_tf_hub_on_kaggle.ipynb\"><img src=\"https://tensorflow.google.cn/images/download_logo_32px.png\">Download notebook</a>   </td>\n",
        "  <td><a href=\"https://tfhub.dev/google/nnlm-en-dim128/1\"><img src=\"https://tensorflow.google.cn/images/hub_logo_32px.png\">查看 TF Hub 模型</a></td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "556YQZLUO4Ih"
      },
      "source": [
        "TF-Hub 是一个平台，用于共享打包为可重用资源的机器学习专业知识，尤其是经过预训练的**模块**。在本教程中，我们将使用 TF-Hub 文本嵌入向量模块来训练具有合理基线准确率的简单情感分类器。之后，我们会将预测结果提交给 Kaggle。\n",
        "\n",
        "有关使用 TF-Hub 进行文本分类的更详细教程，以及提高准确率的后续步骤，请查看[使用 TF-Hub 进行分本分类](https://colab.research.google.com/github/tensorflow/hub/blob/master/docs/tutorials/text_classification_with_tf_hub.ipynb)。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4DN769E2O_R"
      },
      "source": [
        "## 设置"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9KyLct9rq0lo"
      },
      "outputs": [],
      "source": [
        "!pip install -q kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v7hy0bhngTUp"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import zipfile\n",
        "\n",
        "from sklearn import model_selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvgBdeMsuu_3"
      },
      "source": [
        "由于本教程将使用 Kaggle 中的数据集，因此需要为您的 Kaggle 帐号[创建 API 令牌](https://github.com/Kaggle/kaggle-api)，并将其上传到 Colab 环境。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nI7C-Zc4urOH"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pathlib\n",
        "\n",
        "# Upload the API token.\n",
        "def get_kaggle():\n",
        "  try:\n",
        "    import kaggle\n",
        "    return kaggle\n",
        "  except OSError:\n",
        "    pass\n",
        "\n",
        "  token_file = pathlib.Path(\"~/.kaggle/kaggle.json\").expanduser()\n",
        "  token_file.parent.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "  try:\n",
        "    from google.colab import files\n",
        "  except ImportError:\n",
        "    raise ValueError(\"Could not find kaggle token.\")\n",
        "\n",
        "  uploaded = files.upload()\n",
        "  token_content = uploaded.get('kaggle.json', None)\n",
        "  if token_content:\n",
        "    token_file.write_bytes(token_content)\n",
        "    token_file.chmod(0o600)\n",
        "  else:\n",
        "    raise ValueError('Need a file named \"kaggle.json\"')\n",
        "  \n",
        "  import kaggle\n",
        "  return kaggle\n",
        "\n",
        "\n",
        "kaggle = get_kaggle()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OPyVxHuiTEE"
      },
      "source": [
        "# 开始\n",
        "\n",
        "## 数据\n",
        "\n",
        "我们将尝试完成 Kaggle 的 [Sentiment Analysis on Movie Reviews](https://www.kaggle.com/c/sentiment-analysis-on-movie-reviews/data) 任务。数据集由 Rotten Tomatoes 电影评论中符合句法的子短语组成。任务是采用五分制将短语标记为**负面**或**正面**。\n",
        "\n",
        "在使用此 API 下载数据之前，您必须[接受竞赛规则](https://www.kaggle.com/c/sentiment-analysis-on-movie-reviews/data)。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "both",
        "id": "rKzc-fOGV72G"
      },
      "outputs": [],
      "source": [
        "SENTIMENT_LABELS = [\n",
        "    \"negative\", \"somewhat negative\", \"neutral\", \"somewhat positive\", \"positive\"\n",
        "]\n",
        "\n",
        "# Add a column with readable values representing the sentiment.\n",
        "def add_readable_labels_column(df, sentiment_value_column):\n",
        "  df[\"SentimentLabel\"] = df[sentiment_value_column].replace(\n",
        "      range(5), SENTIMENT_LABELS)\n",
        "    \n",
        "# Download data from Kaggle and create a DataFrame.\n",
        "def load_data_from_zip(path):\n",
        "  with zipfile.ZipFile(path, \"r\") as zip_ref:\n",
        "    name = zip_ref.namelist()[0]\n",
        "    with zip_ref.open(name) as zf:\n",
        "      return pd.read_csv(zf, sep=\"\\t\", index_col=0)\n",
        "\n",
        "\n",
        "# The data does not come with a validation set so we'll create one from the\n",
        "# training set.\n",
        "def get_data(competition, train_file, test_file, validation_set_ratio=0.1):\n",
        "  data_path = pathlib.Path(\"data\")\n",
        "  kaggle.api.competition_download_files(competition, data_path)\n",
        "  competition_path = (data_path/competition)\n",
        "  competition_path.mkdir(exist_ok=True, parents=True)\n",
        "  competition_zip_path = competition_path.with_suffix(\".zip\")\n",
        "\n",
        "  with zipfile.ZipFile(competition_zip_path, \"r\") as zip_ref:\n",
        "    zip_ref.extractall(competition_path)\n",
        "  \n",
        "  train_df = load_data_from_zip(competition_path/train_file)\n",
        "  test_df = load_data_from_zip(competition_path/test_file)\n",
        "\n",
        "  # Add a human readable label.\n",
        "  add_readable_labels_column(train_df, \"Sentiment\")\n",
        "\n",
        "  # We split by sentence ids, because we don't want to have phrases belonging\n",
        "  # to the same sentence in both training and validation set.\n",
        "  train_indices, validation_indices = model_selection.train_test_split(\n",
        "      np.unique(train_df[\"SentenceId\"]),\n",
        "      test_size=validation_set_ratio,\n",
        "      random_state=0)\n",
        "\n",
        "  validation_df = train_df[train_df[\"SentenceId\"].isin(validation_indices)]\n",
        "  train_df = train_df[train_df[\"SentenceId\"].isin(train_indices)]\n",
        "  print(\"Split the training data into %d training and %d validation examples.\" %\n",
        "        (len(train_df), len(validation_df)))\n",
        "\n",
        "  return train_df, validation_df, test_df\n",
        "\n",
        "\n",
        "train_df, validation_df, test_df = get_data(\n",
        "    \"sentiment-analysis-on-movie-reviews\",\n",
        "    \"train.tsv.zip\", \"test.tsv.zip\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFq_EyS1BEyK"
      },
      "source": [
        "注：本竞赛的任务不是对整个评论进行评分，而是对评论中的各个短语进行评分。这是一项更加艰巨的任务。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "42hgsiWNq5y9"
      },
      "outputs": [],
      "source": [
        "train_df.head(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPuHgx3BWBOg"
      },
      "source": [
        "## 训练模型\n",
        "\n",
        "*注：我们也可以将此任务建模为回归模型，请参阅[使用 TF-Hub 进行文本分类](https://colab.research.google.com/github/tensorflow/hub/blob/master/docs/tutorials/text_classification_with_tf_hub.ipynb)。*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23U30yEkVq4w"
      },
      "outputs": [],
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self, hub_url):\n",
        "    super().__init__()\n",
        "    self.hub_url = hub_url\n",
        "    self.embed = hub.load(self.hub_url).signatures['default']\n",
        "    self.sequential = tf.keras.Sequential([\n",
        "      tf.keras.layers.Dense(500),\n",
        "      tf.keras.layers.Dense(100),\n",
        "      tf.keras.layers.Dense(5),\n",
        "    ])\n",
        "\n",
        "  def call(self, inputs):\n",
        "    phrases = inputs['Phrase'][:,0]\n",
        "    embedding = 5*self.embed(phrases)['default']\n",
        "    return self.sequential(embedding)\n",
        "\n",
        "  def get_config(self):\n",
        "    return {\"hub_url\":self.hub_url}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JE--GDMM2tSp"
      },
      "outputs": [],
      "source": [
        "model = MyModel(\"https://tfhub.dev/google/nnlm-en-dim128/1\")\n",
        "model.compile(\n",
        "    loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    optimizer=tf.optimizers.Adam(), \n",
        "    metrics = [tf.keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\")])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SRr-lvhstiNw"
      },
      "outputs": [],
      "source": [
        "history = model.fit(x=dict(train_df), y=train_df['Sentiment'],\n",
        "          validation_data=(dict(validation_df), validation_df['Sentiment']),\n",
        "          epochs = 25)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8j7YTRSe7Pj"
      },
      "source": [
        "# 预测\n",
        "\n",
        "为验证集和训练集运行预测。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iGqVNSl87bgN"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zbLg5LzGwAfC"
      },
      "outputs": [],
      "source": [
        "train_eval_result = model.evaluate(dict(train_df), train_df['Sentiment'])\n",
        "validation_eval_result = model.evaluate(dict(validation_df), validation_df['Sentiment'])\n",
        "\n",
        "print(f\"Training set accuracy: {train_eval_result[1]}\")\n",
        "print(f\"Validation set accuracy: {validation_eval_result[1]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DR2IsTF5vuAX"
      },
      "source": [
        "## 混淆矩阵\n",
        "\n",
        "另一个非常有趣的统计数据（尤其对于多类问题而言）是[混淆矩阵](https://en.wikipedia.org/wiki/Confusion_matrix)。混淆矩阵允许可视化显示正确和错误标记的样本的比例。我们可以很容易看出分类器出现了多大偏差，以及标签分布是否有意义。理想情况下，预测中的最大数值应沿对角线分布。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yKUnJFYY8bO_"
      },
      "outputs": [],
      "source": [
        "predictions = model.predict(dict(validation_df))\n",
        "predictions = tf.argmax(predictions, axis=-1)\n",
        "predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fjAs8W_Z9BvP"
      },
      "outputs": [],
      "source": [
        "cm = tf.math.confusion_matrix(validation_df['Sentiment'], predictions)\n",
        "cm = cm/cm.numpy().sum(axis=1)[:, tf.newaxis]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nT71CtArpsKz"
      },
      "outputs": [],
      "source": [
        "sns.heatmap(\n",
        "    cm, annot=True,\n",
        "    xticklabels=SENTIMENT_LABELS,\n",
        "    yticklabels=SENTIMENT_LABELS)\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pic7o2m04weY"
      },
      "source": [
        "我们可以将以下代码粘贴到代码单元，然后执行该代码，从而轻松将预测值提交回 Kaggle：\n",
        "\n",
        "```python\n",
        "test_predictions = model.predict(dict(test_df))\n",
        "test_predictions = np.argmax(test_predictions, axis=-1)\n",
        "\n",
        "result_df = test_df.copy()\n",
        "\n",
        "result_df[\"Predictions\"] = test_predictions\n",
        "\n",
        "result_df.to_csv(\n",
        "    \"predictions.csv\",\n",
        "    columns=[\"Predictions\"],\n",
        "    header=[\"Sentiment\"])\n",
        "kaggle.api.competition_submit(\"predictions.csv\", \"Submitted from Colab\",\n",
        "                              \"sentiment-analysis-on-movie-reviews\")\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50BLu-JX_dlm"
      },
      "source": [
        "提交后，[查看排行榜](https://www.kaggle.com/c/sentiment-analysis-on-movie-reviews/leaderboard)了解您的表现。"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "text_classification_with_tf_hub_on_kaggle.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
