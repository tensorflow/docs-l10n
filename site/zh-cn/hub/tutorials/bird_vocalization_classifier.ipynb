{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QD3FvutQsaqc"
      },
      "source": [
        "##### Copyright 2023 The TensorFlow Hub Authors.\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-5fm9kVRsfuG"
      },
      "outputs": [],
      "source": [
        "#@title Copyright 2023 The TensorFlow Hub Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# =============================================================================="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNDQZiSGtXMu"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <!-- <td>\n",
        "    <a target=\"_blank\" href=\"https://tensorflow.google.cn/hub/tutorials/bird_vocalization_classifier\"><img src=\"https://tensorflow.google.cn/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
        "  </td> -->\n",
        "  <td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/zh-cn/hub/tutorials/bird_vocalization_classifier.ipynb\"><img src=\"https://tensorflow.google.cn/images/colab_logo_32px.png\">在 Google Colab 中运行</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/zh-cn/hub/tutorials/bird_vocalization_classifier.ipynb\"><img src=\"https://tensorflow.google.cn/images/GitHub-Mark-32px.png\">在 GitHub 上查看源代码</a>\n",
        "</td>\n",
        "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/zh-cn/hub/tutorials/bird_vocalization_classifier.ipynb\"><img src=\"https://tensorflow.google.cn/images/download_logo_32px.png\">下载笔记本</a>\n",
        "</td>\n",
        "  <td>     <a href=\"https://tfhub.dev/google/bird-vocalization-classifier/1\"><img src=\"https://tensorflow.google.cn/images/hub_logo_32px.png\">查看 TF Hub 模型</a>\n",
        "</td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JAO_rv_QEBr"
      },
      "source": [
        "# 使用 Google Bird Vocalization 模型\n",
        "\n",
        "Google Bird Vocalization 是一个全球鸟类嵌入和分类模型。\n",
        "\n",
        "此模型需要以 32kHz 采样的 5 秒音频片段作为输入\n",
        "\n",
        "此模型为音频的每个输入窗口输出逻辑和嵌入向量。\n",
        "\n",
        "在此笔记本上，您会学习如何将音频正确提供给模型以及如何使用 logit 进行推断。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bytIYq0MjEKT"
      },
      "outputs": [],
      "source": [
        "!pip install -q \"tensorflow_io==0.28.*\"\n",
        "!pip install -q librosa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aXXTdq-eq6lk"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_io as tfio\n",
        "\n",
        "import numpy as np\n",
        "import librosa\n",
        "\n",
        "import csv\n",
        "import io\n",
        "\n",
        "from IPython.display import Audio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6mFpgMWQjgk"
      },
      "source": [
        "从 TFHub 加载模型"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CQ1P3IkpQiya"
      },
      "outputs": [],
      "source": [
        "model_handle = \"https://tfhub.dev/google/bird-vocalization-classifier/1\"\n",
        "model = hub.load(model_handle)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3OOw23B3fZT6"
      },
      "source": [
        "我们来加载训练模型使用的标签。\n",
        "\n",
        "标签文件位于 assets 文件夹中的 label.csv 下。每行都是一个 ebird id。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f5i-R4k9ZhwN"
      },
      "outputs": [],
      "source": [
        "# Find the name of the class with the top score when mean-aggregated across frames.\n",
        "def class_names_from_csv(class_map_csv_text):\n",
        "  \"\"\"Returns list of class names corresponding to score vector.\"\"\"\n",
        "  with open(labels_path) as csv_file:\n",
        "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
        "    class_names = [mid for mid, desc in csv_reader]\n",
        "    return class_names[1:]\n",
        "\n",
        "labels_path = hub.resolve(model_handle) + \"/assets/label.csv\"\n",
        "classes = class_names_from_csv(labels_path)\n",
        "print(classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2JYPafeRRi_"
      },
      "source": [
        "`frame_audio` 函数基于 [Chirp 库](https://github.com/google-research/chirp/blob/10c5faa325a3c3468fa6f18a736fc1aeb9bf8129/chirp/inference/interface.py#L128)版本，但使用 tf.signal 而不是 librosa。\n",
        "\n",
        "`ensure_sample_rate` 是一个用于确保模型使用的任何音频都具有 32kHz 预期采样率的函数"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t65gi_DTrRaa"
      },
      "outputs": [],
      "source": [
        "def frame_audio(\n",
        "      audio_array: np.ndarray,\n",
        "      window_size_s: float = 5.0,\n",
        "      hop_size_s: float = 5.0,\n",
        "      sample_rate = 32000,\n",
        "  ) -> np.ndarray:\n",
        "    \"\"\"Helper function for framing audio for inference.\"\"\"\n",
        "    if window_size_s is None or window_size_s < 0:\n",
        "      return audio_array[np.newaxis, :]\n",
        "    frame_length = int(window_size_s * sample_rate)\n",
        "    hop_length = int(hop_size_s * sample_rate)\n",
        "    framed_audio = tf.signal.frame(audio_array, frame_length, hop_length, pad_end=True)\n",
        "    return framed_audio\n",
        "\n",
        "def ensure_sample_rate(waveform, original_sample_rate,\n",
        "                       desired_sample_rate=32000):\n",
        "  \"\"\"Resample waveform if required.\"\"\"\n",
        "  if original_sample_rate != desired_sample_rate:\n",
        "    waveform = tfio.audio.resample(waveform, original_sample_rate, desired_sample_rate)\n",
        "  return desired_sample_rate, waveform"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7uAuI4f6ehb"
      },
      "source": [
        "我们从 Wikipedia 加载一个文件。\n",
        "\n",
        "更准确地说，是[常见黑鸟](https://es.wikipedia.org/wiki/Turdus_merula)的声音\n",
        "\n",
        "<p><img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/a/a9/Common_Blackbird.jpg/1200px-Common_Blackbird.jpg\" alt=\"Common Blackbird.jpg\" class=\"\"></p>\n",
        ":-:\n",
        "*作者：<a rel=\"nofollow\" class=\"external text\" href=\"http://photo-natur.de\">Andreas Trepte</a> - <span class=\"int-own-work\" lang=\"en\">自有作品</span>，<a href=\"https://creativecommons.org/licenses/by-sa/2.5\" title=\"Creative Commons Attribution-Share Alike 2.5\">CC BY-SA 2.5</a>，<a href=\"https://commons.wikimedia.org/w/index.php?curid=16110223\">链接</a>*\n",
        "\n",
        "此音频由 Oona Räisänen (Mysid) 根据公共领域许可提供。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "whkmGeJ9lmyd"
      },
      "outputs": [],
      "source": [
        "!curl -O  \"https://upload.wikimedia.org/wikipedia/commons/7/7c/Turdus_merula_2.ogg\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ff6nOV2EurAO"
      },
      "outputs": [],
      "source": [
        "turdus_merula = \"Turdus_merula_2.ogg\"\n",
        "\n",
        "audio, sample_rate = librosa.load(turdus_merula)\n",
        "\n",
        "sample_rate, wav_data_turdus = ensure_sample_rate(audio, sample_rate)\n",
        "Audio(wav_data_turdus, rate=sample_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjpKLk9K7TTV"
      },
      "source": [
        "此音频有 24 秒，而模型需要 5 秒的块。\n",
        "\n",
        "`frame_audio` 函数可以解决此问题并将音频拆分为适当的帧"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VzgK0xWw9g8X"
      },
      "outputs": [],
      "source": [
        "fixed_tm = frame_audio(wav_data_turdus)\n",
        "fixed_tm.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rU5-UqaCAVZ7"
      },
      "source": [
        "我们只在第一帧应用模型："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0zveWSOU9QBC"
      },
      "outputs": [],
      "source": [
        "logits, embeddings = model.infer_tf(fixed_tm[:1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osmRNWciEEuG"
      },
      "source": [
        "label.csv 文件包含 ebird id。乌鸫的 ebird id 为 eurbla"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E-UehjA6Acn_"
      },
      "outputs": [],
      "source": [
        "probabilities = tf.nn.softmax(logits)\n",
        "argmax = np.argmax(probabilities)\n",
        "print(f\"The audio is from the class {classes[argmax]} (element:{argmax} in the label.csv file), with probability of {probabilities[0][argmax]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGK84egXBg2f"
      },
      "source": [
        "现在我们在所有帧上应用模型：\n",
        "\n",
        "*注*：此代码也基于 [Chirp 库](https://github.com/google-research/chirp/blob/d6ff5e7cee3865940f31697bf4b70176c1072572/chirp/inference/models.py#L174)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UT_Im9i50EGy"
      },
      "outputs": [],
      "source": [
        "all_logits, all_embeddings = model.infer_tf(fixed_tm[:1])\n",
        "for window in fixed_tm[1:]:\n",
        "  logits, embeddings = model.infer_tf(window[np.newaxis, :])\n",
        "  all_logits = np.concatenate([all_logits, logits], axis=0)\n",
        "\n",
        "all_logits.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kKuJWq4SxyR1"
      },
      "outputs": [],
      "source": [
        "frame = 0\n",
        "for frame_logits in all_logits:\n",
        "  probabilities = tf.nn.softmax(frame_logits)\n",
        "  argmax = np.argmax(probabilities)\n",
        "  print(f\"For frame {frame}, the audio is from the class {classes[argmax]} (element:{argmax} in the label.csv file), with probability of {probabilities[argmax]}\")\n",
        "  frame += 1"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "bird_vocalization_classifier.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
