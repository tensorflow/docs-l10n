{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNLUPuRpkFv_"
      },
      "source": [
        "##### Copyright 2022 The TensorFlow Hub Authors.\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "DQcWZm0FkPk-"
      },
      "outputs": [],
      "source": [
        "#@title Copyright 2022 The TensorFlow Hub Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# =============================================================================="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Exbxve1rHlrF"
      },
      "source": [
        "# 使用 FILM 模型进行帧插值\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMWFVTlbrQ8m"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>     <a target=\"_blank\" href=\"https://tensorflow.google.cn/hub/tutorials/tf_hub_film_example\"><img src=\"https://tensorflow.google.cn/images/tf_logo_32px.png\">在 TensorFlow.org 上查看</a> </td>\n",
        "  <td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/zh-cn/hub/tutorials/tf_hub_film_example.ipynb\"><img src=\"https://tensorflow.google.cn/images/colab_logo_32px.png\">在 Google Colab 中运行</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/zh-cn/hub/tutorials/tf_hub_film_example.ipynb\"><img src=\"https://tensorflow.google.cn/images/GitHub-Mark-32px.png\">在 GitHub 上查看源代码</a></td>\n",
        "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/zh-cn/hub/tutorials/tf_hub_film_example.ipynb\"><img src=\"https://tensorflow.google.cn/images/download_logo_32px.png\">下载笔记本</a>\n",
        "</td>\n",
        "  <td>     <a href=\"https://tfhub.dev/google/film/1\"><img src=\"https://tensorflow.google.cn/images/hub_logo_32px.png\">查看 TF Hub 模型</a> </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61H28S7ArUAZ"
      },
      "source": [
        "帧插值是从一组给定图像合成许多中间图像的任务。这项技术通常用于帧速率上采样或创建慢动作视频效果。\n",
        "\n",
        "在此 Colab 中，您将使用 FILM 模型进行帧插值。Colab 还提供了用于从插值的中间图像创建视频的代码段。\n",
        "\n",
        "有关 FILM 研究的更多信息，可以在此处阅读更多内容：\n",
        "\n",
        "- Google AI 博客：[Large Motion Frame Interpolation](https://ai.googleblog.com/2022/10/large-motion-frame-interpolation.html)\n",
        "- FILM 项目页面：[Frame Interpolation for Large Motion](https://film-net.github.io/)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVX7s6zMulsu"
      },
      "source": [
        "## 安装"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oi5t2OEJsGBW"
      },
      "outputs": [],
      "source": [
        "!pip install mediapy\n",
        "!sudo apt-get install -y ffmpeg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BA1tq39MjOiF"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "import requests\n",
        "import numpy as np\n",
        "\n",
        "from typing import Generator, Iterable, List, Optional\n",
        "import mediapy as media"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTgXmeYGnT7q"
      },
      "source": [
        "## 从 TFHub 加载模型\n",
        "\n",
        "要从 TensorFlow Hub 加载模型，您需要 tfhub 库和模型句柄，即它的文档网址。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GojhvyAtjUt0"
      },
      "outputs": [],
      "source": [
        "model = hub.load(\"https://tfhub.dev/google/film/1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOQJPsu2CwPk"
      },
      "source": [
        "## 从网址或本地加载图像的效用函数\n",
        "\n",
        "此函数可以加载图像并使其准备好供模型稍后使用。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BPnh5uhQvFln"
      },
      "outputs": [],
      "source": [
        "_UINT8_MAX_F = float(np.iinfo(np.uint8).max)\n",
        "\n",
        "def load_image(img_url: str):\n",
        "  \"\"\"Returns an image with shape [height, width, num_channels], with pixels in [0..1] range, and type np.float32.\"\"\"\n",
        "\n",
        "  if (img_url.startswith(\"https\")):\n",
        "    user_agent = {'User-agent': 'Colab Sample (https://tensorflow.org)'}\n",
        "    response = requests.get(img_url, headers=user_agent)\n",
        "    image_data = response.content\n",
        "  else:\n",
        "    image_data = tf.io.read_file(img_url)\n",
        "\n",
        "  image = tf.io.decode_image(image_data, channels=3)\n",
        "  image_numpy = tf.cast(image, dtype=tf.float32).numpy()\n",
        "  return image_numpy / _UINT8_MAX_F\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjDFns1zp5y6"
      },
      "source": [
        "FILM 的模型输入是一个包含键 `time`、`x0`、`x1` 的字典：\n",
        "\n",
        "- `time`：插值帧的位置。中间为 `0.5`。\n",
        "- `x0`：初始帧。\n",
        "- `x1`：最后一帧。\n",
        "\n",
        "两个帧都需要归一化（在上面的函数 `load_image` 中完成），其中每个像素都处于 `[0..1]` 范围内。\n",
        "\n",
        "`time` 是 `[0..1]` 之间的一个值，它表示生成的图像应该位于何处。0.5 是输入图像之间的中间值。\n",
        "\n",
        "全部三个值也需要有一个批次维度。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VEQNQlHGsWSM"
      },
      "outputs": [],
      "source": [
        "# using images from the FILM repository (https://github.com/google-research/frame-interpolation/)\n",
        "\n",
        "image_1_url = \"https://github.com/google-research/frame-interpolation/blob/main/photos/one.png?raw=true\"\n",
        "image_2_url = \"https://github.com/google-research/frame-interpolation/blob/main/photos/two.png?raw=true\"\n",
        "\n",
        "time = np.array([0.5], dtype=np.float32)\n",
        "\n",
        "image1 = load_image(image_1_url)\n",
        "image2 = load_image(image_2_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r6_MQE9EuF_K"
      },
      "outputs": [],
      "source": [
        "input = {\n",
        "    'time': np.expand_dims(time, axis=0), # adding the batch dimension to the time\n",
        "     'x0': np.expand_dims(image1, axis=0), # adding the batch dimension to the image\n",
        "     'x1': np.expand_dims(image2, axis=0)  # adding the batch dimension to the image\n",
        "}\n",
        "mid_frame = model(input)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZkzYE2bptfD"
      },
      "source": [
        "该模型输出了几个结果，但您将在此处使用的是 `image` 键，其值为插值帧。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eClVbNFhA5Py"
      },
      "outputs": [],
      "source": [
        "print(mid_frame.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rE2csH3u8ePe"
      },
      "outputs": [],
      "source": [
        "frames = [image1, mid_frame['image'][0].numpy(), image2]\n",
        "\n",
        "media.show_images(frames, titles=['input image one', 'generated image', 'input image two'], height=250)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fS1AT8kn-f_l"
      },
      "source": [
        "我们从生成的帧创建一个视频"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oFc53B3p37SH"
      },
      "outputs": [],
      "source": [
        "media.show_video(frames, fps=3, title='FILM interpolated video')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5AOFNkj-lfO"
      },
      "source": [
        "## 定义帧插值器库\n",
        "\n",
        "如您所见，过渡不太流畅。\n",
        "\n",
        "要改进这一点，您需要更多插值帧。\n",
        "\n",
        "您可以使用中间图像多次运行模型，但有更好的解决方案。\n",
        "\n",
        "要生成许多插值图像并获得更流畅的视频，您可以创建一个插值器库。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tsoDv_9geoZn"
      },
      "outputs": [],
      "source": [
        "\"\"\"A wrapper class for running a frame interpolation based on the FILM model on TFHub\n",
        "\n",
        "Usage:\n",
        "  interpolator = Interpolator()\n",
        "  result_batch = interpolator(image_batch_0, image_batch_1, batch_dt)\n",
        "  Where image_batch_1 and image_batch_2 are numpy tensors with TF standard\n",
        "  (B,H,W,C) layout, batch_dt is the sub-frame time in range [0..1], (B,) layout.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def _pad_to_align(x, align):\n",
        "  \"\"\"Pads image batch x so width and height divide by align.\n",
        "\n",
        "  Args:\n",
        "    x: Image batch to align.\n",
        "    align: Number to align to.\n",
        "\n",
        "  Returns:\n",
        "    1) An image padded so width % align == 0 and height % align == 0.\n",
        "    2) A bounding box that can be fed readily to tf.image.crop_to_bounding_box\n",
        "      to undo the padding.\n",
        "  \"\"\"\n",
        "  # Input checking.\n",
        "  assert np.ndim(x) == 4\n",
        "  assert align > 0, 'align must be a positive number.'\n",
        "\n",
        "  height, width = x.shape[-3:-1]\n",
        "  height_to_pad = (align - height % align) if height % align != 0 else 0\n",
        "  width_to_pad = (align - width % align) if width % align != 0 else 0\n",
        "\n",
        "  bbox_to_pad = {\n",
        "      'offset_height': height_to_pad // 2,\n",
        "      'offset_width': width_to_pad // 2,\n",
        "      'target_height': height + height_to_pad,\n",
        "      'target_width': width + width_to_pad\n",
        "  }\n",
        "  padded_x = tf.image.pad_to_bounding_box(x, **bbox_to_pad)\n",
        "  bbox_to_crop = {\n",
        "      'offset_height': height_to_pad // 2,\n",
        "      'offset_width': width_to_pad // 2,\n",
        "      'target_height': height,\n",
        "      'target_width': width\n",
        "  }\n",
        "  return padded_x, bbox_to_crop\n",
        "\n",
        "\n",
        "class Interpolator:\n",
        "  \"\"\"A class for generating interpolated frames between two input frames.\n",
        "\n",
        "  Uses the Film model from TFHub\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, align: int = 64) -> None:\n",
        "    \"\"\"Loads a saved model.\n",
        "\n",
        "    Args:\n",
        "      align: 'If >1, pad the input size so it divides with this before\n",
        "        inference.'\n",
        "    \"\"\"\n",
        "    self._model = hub.load(\"https://tfhub.dev/google/film/1\")\n",
        "    self._align = align\n",
        "\n",
        "  def __call__(self, x0: np.ndarray, x1: np.ndarray,\n",
        "               dt: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"Generates an interpolated frame between given two batches of frames.\n",
        "\n",
        "    All inputs should be np.float32 datatype.\n",
        "\n",
        "    Args:\n",
        "      x0: First image batch. Dimensions: (batch_size, height, width, channels)\n",
        "      x1: Second image batch. Dimensions: (batch_size, height, width, channels)\n",
        "      dt: Sub-frame time. Range [0,1]. Dimensions: (batch_size,)\n",
        "\n",
        "    Returns:\n",
        "      The result with dimensions (batch_size, height, width, channels).\n",
        "    \"\"\"\n",
        "    if self._align is not None:\n",
        "      x0, bbox_to_crop = _pad_to_align(x0, self._align)\n",
        "      x1, _ = _pad_to_align(x1, self._align)\n",
        "\n",
        "    inputs = {'x0': x0, 'x1': x1, 'time': dt[..., np.newaxis]}\n",
        "    result = self._model(inputs, training=False)\n",
        "    image = result['image']\n",
        "\n",
        "    if self._align is not None:\n",
        "      image = tf.image.crop_to_bounding_box(image, **bbox_to_crop)\n",
        "    return image.numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeGYaNBd_7a5"
      },
      "source": [
        "## 帧和视频生成效用函数"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gOJxup6s_1DP"
      },
      "outputs": [],
      "source": [
        "def _recursive_generator(\n",
        "    frame1: np.ndarray, frame2: np.ndarray, num_recursions: int,\n",
        "    interpolator: Interpolator) -> Generator[np.ndarray, None, None]:\n",
        "  \"\"\"Splits halfway to repeatedly generate more frames.\n",
        "\n",
        "  Args:\n",
        "    frame1: Input image 1.\n",
        "    frame2: Input image 2.\n",
        "    num_recursions: How many times to interpolate the consecutive image pairs.\n",
        "    interpolator: The frame interpolator instance.\n",
        "\n",
        "  Yields:\n",
        "    The interpolated frames, including the first frame (frame1), but excluding\n",
        "    the final frame2.\n",
        "  \"\"\"\n",
        "  if num_recursions == 0:\n",
        "    yield frame1\n",
        "  else:\n",
        "    # Adds the batch dimension to all inputs before calling the interpolator,\n",
        "    # and remove it afterwards.\n",
        "    time = np.full(shape=(1,), fill_value=0.5, dtype=np.float32)\n",
        "    mid_frame = interpolator(\n",
        "        np.expand_dims(frame1, axis=0), np.expand_dims(frame2, axis=0), time)[0]\n",
        "    yield from _recursive_generator(frame1, mid_frame, num_recursions - 1,\n",
        "                                    interpolator)\n",
        "    yield from _recursive_generator(mid_frame, frame2, num_recursions - 1,\n",
        "                                    interpolator)\n",
        "\n",
        "\n",
        "def interpolate_recursively(\n",
        "    frames: List[np.ndarray], num_recursions: int,\n",
        "    interpolator: Interpolator) -> Iterable[np.ndarray]:\n",
        "  \"\"\"Generates interpolated frames by repeatedly interpolating the midpoint.\n",
        "\n",
        "  Args:\n",
        "    frames: List of input frames. Expected shape (H, W, 3). The colors should be\n",
        "      in the range[0, 1] and in gamma space.\n",
        "    num_recursions: Number of times to do recursive midpoint\n",
        "      interpolation.\n",
        "    interpolator: The frame interpolation model to use.\n",
        "\n",
        "  Yields:\n",
        "    The interpolated frames (including the inputs).\n",
        "  \"\"\"\n",
        "  n = len(frames)\n",
        "  for i in range(1, n):\n",
        "    yield from _recursive_generator(frames[i - 1], frames[i],\n",
        "                                    times_to_interpolate, interpolator)\n",
        "  # Separately yield the final frame.\n",
        "  yield frames[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X1R2KjhEAHu0"
      },
      "outputs": [],
      "source": [
        "times_to_interpolate = 6\n",
        "interpolator = Interpolator()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZUo8tg1AYvZ"
      },
      "source": [
        "## 运行插值器"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QMMNjs7sAWTG"
      },
      "outputs": [],
      "source": [
        "input_frames = [image1, image2]\n",
        "frames = list(\n",
        "    interpolate_recursively(input_frames, times_to_interpolate,\n",
        "                                        interpolator))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s9mHHyCAAhrM"
      },
      "outputs": [],
      "source": [
        "print(f'video with {len(frames)} frames')\n",
        "media.show_video(frames, fps=30, title='FILM interpolated video')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0AZKeMVFwAc"
      },
      "source": [
        "有关详情，可以访问 [FILM 的模型仓库](https://github.com/google-research/frame-interpolation)。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8764ry3SGDks"
      },
      "source": [
        "## 引用\n",
        "\n",
        "如果您发现此模型和代码对您的工作有用，请通过引用以下代码适当地致谢：\n",
        "\n",
        "```\n",
        "@inproceedings{reda2022film,\n",
        " title = {FILM: Frame Interpolation for Large Motion},\n",
        " author = {Fitsum Reda and Janne Kontkanen and Eric Tabellion and Deqing Sun and Caroline Pantofaru and Brian Curless},\n",
        " booktitle = {The European Conference on Computer Vision (ECCV)},\n",
        " year = {2022}\n",
        "}\n",
        "```\n",
        "\n",
        "```\n",
        "@misc{film-tf,\n",
        "  title = {Tensorflow 2 Implementation of \"FILM: Frame Interpolation for Large Motion\"},\n",
        "  author = {Fitsum Reda and Janne Kontkanen and Eric Tabellion and Deqing Sun and Caroline Pantofaru and Brian Curless},\n",
        "  year = {2022},\n",
        "  publisher = {GitHub},\n",
        "  journal = {GitHub repository},\n",
        "  howpublished = {\\url{https://github.com/google-research/frame-interpolation}}\n",
        "}\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "tf_hub_film_example.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
