{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KimMZUVqcJ8_"
      },
      "source": [
        "##### Copyright 2021 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "BRQ6HQ8zcV5v"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlWzg1D9_EhW"
      },
      "source": [
        "# 利用量化调试器检查量化错误"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLoHL19yb-a0"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>     <a target=\"_blank\" href=\"https://tensorflow.google.cn/lite/performance/quantization_debugger\"><img src=\"https://tensorflow.google.cn/images/tf_logo_32px.png\">在 TensorFlow.org 上查看</a> </td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/zh-cn/lite/performance/quantization_debugger.ipynb\"><img src=\"https://tensorflow.google.cn/images/colab_logo_32px.png\">在 Google Colab 运行</a> </td>\n",
        "  <td><a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/zh-cn/lite/performance/quantization_debugger.ipynb\"><img src=\"https://tensorflow.google.cn/images/GitHub-Mark-32px.png\">在 GitHub 上查看源代码</a></td>\n",
        "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/zh-cn/lite/performance/quantization_debugger.ipynb\"><img src=\"https://tensorflow.google.cn/images/download_logo_32px.png\">Download notebook</a>   </td>\n",
        "  <td>     <a href=\"https://tfhub.dev/google/imagenet/mobilenet_v3_small_100_224/classification/5\"><img src=\"https://tensorflow.google.cn/images/hub_logo_32px.png\">查看 TF Hub 模型 </a> </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWO_yYDGcGWY"
      },
      "source": [
        "尽管全整数量化能够改进模型大小和延迟，但量化后的模型并不总是像预期的那样工作。通常预计模型质量（例如准确率、mAP、WER）略低于原始浮点模型。但是，在某些情况下，模型质量可能会低于您的预期，或者生成完全错误的结果。\n",
        "\n",
        "发生这种问题时，找出量化错误的根本原因既棘手又痛苦。为了协助这一模型检查过程，可使用**量化调试器**来识别有问题的层，而**选择性量化**可将这些有问题的层保留为浮点，以便以减少量化带来的好处为代价来恢复模型准确率。\n",
        "\n",
        "注：此 API 是实验性的，在改进过程中可能会有一些突破性变化。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kD29R1I_Mn6"
      },
      "source": [
        "## 量化调试器\n",
        "\n",
        "量化调试器使得在现有模型中进行量化质量指标分析成为可能。量化调试器可以自动化过程，以便使用调试数据集运行模型，并收集每个张量的量化质量指标。\n",
        "\n",
        "注：量化调试器和选择性量化目前仅适用于使用 int8 激活的全整数量化。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "221Qon7G_PmZ"
      },
      "source": [
        "### <a>先决条件</a>\n",
        "\n",
        "如果您已经有了量化模型的流水线，那么您就有了运行量化调试器所需的所有组件！\n",
        "\n",
        "- 要量化的模型\n",
        "- 有代表性的数据集\n",
        "\n",
        "除了模型和数据之外，您还需要使用数据处理框架（例如 pandas、Google Sheet）来分析导出的结果。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTEEzJWo_iZ_"
      },
      "source": [
        "### 安装\n",
        "\n",
        "本部分会准备各种库、MobileNet v3 模型和包含 100 个图像的测试数据集。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l7epUDUP_6qo"
      },
      "outputs": [],
      "source": [
        "# Quantization debugger is available from TensorFlow 2.7.0\n",
        "!pip uninstall -y tensorflow\n",
        "!pip install tf-nightly\n",
        "!pip install tensorflow_datasets --upgrade  # imagenet_v2 needs latest checksum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LLsgiUZe_hIa"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_hub as hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "veWjO3u32vzz"
      },
      "outputs": [],
      "source": [
        "#@title Boilerplates and helpers\n",
        "MODEL_URI = 'https://tfhub.dev/google/imagenet/mobilenet_v3_small_100_224/classification/5'\n",
        "\n",
        "\n",
        "def process_image(data):\n",
        "  data['image'] = tf.image.resize(data['image'], (224, 224)) / 255.0\n",
        "  return data\n",
        "\n",
        "\n",
        "# Representative dataset\n",
        "def representative_dataset(dataset):\n",
        "\n",
        "  def _data_gen():\n",
        "    for data in dataset.batch(1):\n",
        "      yield [data['image']]\n",
        "\n",
        "  return _data_gen\n",
        "\n",
        "\n",
        "def eval_tflite(tflite_model, dataset):\n",
        "  \"\"\"Evaluates tensorflow lite classification model with the given dataset.\"\"\"\n",
        "  interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
        "  interpreter.allocate_tensors()\n",
        "\n",
        "  input_idx = interpreter.get_input_details()[0]['index']\n",
        "  output_idx = interpreter.get_output_details()[0]['index']\n",
        "\n",
        "  results = []\n",
        "\n",
        "  for data in representative_dataset(dataset)():\n",
        "    interpreter.set_tensor(input_idx, data[0])\n",
        "    interpreter.invoke()\n",
        "    results.append(interpreter.get_tensor(output_idx).flatten())\n",
        "\n",
        "  results = np.array(results)\n",
        "  gt_labels = np.array(list(dataset.map(lambda data: data['label'] + 1)))\n",
        "  accuracy = (\n",
        "      np.sum(np.argsort(results, axis=1)[:, -5:] == gt_labels.reshape(-1, 1)) /\n",
        "      gt_labels.size)\n",
        "  print(f'Top-5 accuracy (quantized): {accuracy * 100:.2f}%')\n",
        "\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Input(shape=(224, 224, 3), batch_size=1),\n",
        "  hub.KerasLayer(MODEL_URI)\n",
        "])\n",
        "model.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics='sparse_top_k_categorical_accuracy')\n",
        "model.build([1, 224, 224, 3])\n",
        "\n",
        "# Prepare dataset with 100 examples\n",
        "ds = tfds.load('imagenet_v2', split='test[:1%]')\n",
        "ds = ds.map(process_image)\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.representative_dataset = representative_dataset(ds)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "quantized_model = converter.convert()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7mX-R-xK4ADB"
      },
      "outputs": [],
      "source": [
        "test_ds = ds.map(lambda data: (data['image'], data['label'] + 1)).batch(16)\n",
        "loss, acc = model.evaluate(test_ds)\n",
        "print(f'Top-5 accuracy (float): {acc * 100:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mnp6yBnJSCoh"
      },
      "outputs": [],
      "source": [
        "eval_tflite(quantized_model, ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tblkk3cxxpuw"
      },
      "source": [
        "我们可以看到，对于我们的小数据集，原始模型具有更高的 top-5 准确率，而量化模型的准确率损失很大。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBBcfCQw_Wqd"
      },
      "source": [
        "### 第 1 步：调试器准备\n",
        "\n",
        "使用量化调试器的最简单方式是提供您一直用于量化模型的 `tf.lite.TFLiteConverter`。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NOByihbD_NZZ"
      },
      "outputs": [],
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.representative_dataset = representative_dataset(ds)\n",
        "\n",
        "# my_debug_dataset should have the same format as my_representative_dataset\n",
        "debugger = tf.lite.experimental.QuantizationDebugger(\n",
        "    converter=converter, debug_dataset=representative_dataset(ds))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vR1IIrmQS9W"
      },
      "source": [
        "### 第 2 步：运行调试器并获取结果\n",
        "\n",
        "当您调用 `QuantizationDebugger.run()` 时，调试器将记录相同运算位置的浮点张量和量化张量之间的差异，并使用给定的指标来处理它们。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HsUM54g-_E52"
      },
      "outputs": [],
      "source": [
        "debugger.run()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQpX_SBUQXvr"
      },
      "source": [
        "可以使用 `QuantizationDebugger.layer_statistics` 来访问处理后的指标，也可以使用 `QuantizationDebugger.layer_statistics_dump()` 将其转储为 CSV 格式的文本文件。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U-AGYUAbQUmx"
      },
      "outputs": [],
      "source": [
        "RESULTS_FILE = '/tmp/debugger_results.csv'\n",
        "with open(RESULTS_FILE, 'w') as f:\n",
        "  debugger.layer_statistics_dump(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LQzEi6VnQaen"
      },
      "outputs": [],
      "source": [
        "!head /tmp/debugger_results.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4np7VqU-Qfke"
      },
      "source": [
        "对于转储中的每一行，首先是运算名称和索引，然后是量化参数和错误指标（如果有的话，包括[用户定义的错误指标](#custom-metrics)）。所得到的 CSV 文件可用于挑选具有较大量化错误指标的问题层。\n",
        "\n",
        "我们可以使用 pandas 或其他数据处理库来检查详细的每层错误指标。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XUcSqYFGQb-f"
      },
      "outputs": [],
      "source": [
        "layer_stats = pd.read_csv(RESULTS_FILE)\n",
        "layer_stats.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7C_oHxWFOV6M"
      },
      "source": [
        "### 第 3 步：数据分析\n",
        "\n",
        "有多种方法可以分析结果。首先，我们来添加一些从调试器输出中派生的有用指标。（`scale` 表示每个张量的量化尺度因子。)\n",
        "\n",
        "- 范围 (`256 / scale`)\n",
        "- RMSE / scale (`sqrt(mean_squared_error) / scale`)\n",
        "\n",
        "当量化分布与原始浮点分布相似时，`RMSE / scale` 接近于 `1 / sqrt(12)` (~ 0.289)，表明量化模型较好。该值越大，该层就越有可能没有被很好地量化。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mwviORyJN6e5"
      },
      "outputs": [],
      "source": [
        "layer_stats['range'] = 255.0 * layer_stats['scale']\n",
        "layer_stats['rmse/scale'] = layer_stats.apply(\n",
        "    lambda row: np.sqrt(row['mean_squared_error']) / row['scale'], axis=1)\n",
        "layer_stats[['op_name', 'range', 'rmse/scale']].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oAAv35CdPvc4"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15, 5))\n",
        "ax1 = plt.subplot(121)\n",
        "ax1.bar(np.arange(len(layer_stats)), layer_stats['range'])\n",
        "ax1.set_ylabel('range')\n",
        "ax2 = plt.subplot(122)\n",
        "ax2.bar(np.arange(len(layer_stats)), layer_stats['rmse/scale'])\n",
        "ax2.set_ylabel('rmse/scale')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pqUQvRUWB3Q"
      },
      "source": [
        "有许多范围很广的层，还有一些层的 `RMSE/scale` 值很高。我们来获取具有较高错误指标的层。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UqFsUX4_Q-cE"
      },
      "outputs": [],
      "source": [
        "layer_stats[layer_stats['rmse/scale'] > 0.7][[\n",
        "    'op_name', 'range', 'rmse/scale', 'tensor_name'\n",
        "]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHeALFTGWl_e"
      },
      "source": [
        "对于这些层，您可以尝试选择性量化，以查看不量化这些层是否会提高模型质量。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cvdkjsbwYC6e"
      },
      "outputs": [],
      "source": [
        "suspected_layers = list(\n",
        "    layer_stats[layer_stats['rmse/scale'] > 0.7]['tensor_name'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6RQw9JobOTR"
      },
      "source": [
        "此外，跳过前几层的量化也有助于提高量化模型的质量。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ikF2bp6NZcXN"
      },
      "outputs": [],
      "source": [
        "suspected_layers.extend(list(layer_stats[:5]['tensor_name']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1DfT78w6W6Li"
      },
      "source": [
        "## 选择性量化"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pubC-01cGEH"
      },
      "source": [
        "选择性量化会跳过对某些节点的量化，因此计算可以在原始的浮点域中进行。当跳过正确的层时，我们可以期待一些模型质量恢复，但代价是增加延迟和模型大小。\n",
        "\n",
        "然而，如果您计划在仅限整数的加速器（例如，Hexagon DSP、Edge TPU）上运行量化模型，选择性量化将导致模型碎片化，并将导致较慢的推断延迟，这主要是由 CPU 和这些加速器之间的数据传输开销引起的。为防止出现这种情况，您可以考虑运行[量化感知训练](https://tensorflow.google.cn/model_optimization/guide/quantization/training)以保持所有层为整数，同时保持模型准确率。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQFBfR7YW-oh"
      },
      "source": [
        "量化调试器的选项接受 `denylisted_nodes` 和 `denylisted_ops` 选项，用于跳过特定层或特定运算的所有实例的量化。使用上一步准备的 `suspected_layers`，我们可以使用量化调试器来获得选择性量化的模型。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K5KD0JAEbpsv"
      },
      "outputs": [],
      "source": [
        "debug_options = tf.lite.experimental.QuantizationDebugOptions(\n",
        "    denylisted_nodes=suspected_layers)\n",
        "debugger = tf.lite.experimental.QuantizationDebugger(\n",
        "    converter=converter,\n",
        "    debug_dataset=representative_dataset(ds),\n",
        "    debug_options=debug_options)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pfj9gzv4b7h4"
      },
      "outputs": [],
      "source": [
        "selective_quantized_model = debugger.get_nondebug_quantized_model()\n",
        "eval_tflite(selective_quantized_model, ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1RkfMYSHdtZy"
      },
      "source": [
        "与原始浮点模型相比，准确率仍然较低，但我们通过跳过 111 层中的约 10 层的量化，使整个量化模型有了显著的改善。\n",
        "\n",
        "您还可以尝试不量化同一类中的所有运算。例如，要跳过所有均值运算的量化，可以将 `MEAN` 传递给 `denylisted_ops`。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ruUoP7SgcLpO"
      },
      "outputs": [],
      "source": [
        "debug_options = tf.lite.experimental.QuantizationDebugOptions(\n",
        "    denylisted_ops=['MEAN'])\n",
        "debugger = tf.lite.experimental.QuantizationDebugger(\n",
        "    converter=converter,\n",
        "    debug_dataset=representative_dataset(ds),\n",
        "    debug_options=debug_options)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oY6kb5g_cO4H"
      },
      "outputs": [],
      "source": [
        "selective_quantized_model = debugger.get_nondebug_quantized_model()\n",
        "eval_tflite(selective_quantized_model, ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xa8488TeAyx-"
      },
      "source": [
        "通过这些技术，我们能够提高量化后的 MobileNet V3 模型的准确率。接下来，我们将探索先进的技术来进一步提高模型的准确率。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZD75cY9PUb2u"
      },
      "source": [
        "## 高级用法\n",
        "\n",
        "使用以下功能，您可以进一步自定义调试流水线。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVj9yrQoUfGo"
      },
      "source": [
        "### 自定义指标\n",
        "\n",
        "默认情况下，量化调试器会为每个浮点量化差异发出五个指标：张量大小、标准差、平均误差、最大绝对误差和均方误差。您可以通过将更多自定义指标传递给选项来添加更多自定义指标。对于每个指标，结果应该是单个浮点值，结果指标将是所有示例中指标的平均值。\n",
        "\n",
        "- `layer_debug_metrics`：根据浮点和量化运算输出的每个运算输出的差异计算指标。\n",
        "- `layer_direct_compare_metrics`：这将基于原始浮点和量化张量及其量化参数（尺度、零点）计算指标，而不是仅获取差异\n",
        "- `model_debug_metrics`：**仅在将 `float_model_(path|content)` 传递给调试器时使用**。除了运算级指标外，还将最终层输出与原始浮动模型的参考输出进行比较。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WqmRQSxoVVwu"
      },
      "outputs": [],
      "source": [
        "debug_options = tf.lite.experimental.QuantizationDebugOptions(\n",
        "    layer_debug_metrics={\n",
        "        'mean_abs_error': (lambda diff: np.mean(np.abs(diff)))\n",
        "    },\n",
        "    layer_direct_compare_metrics={\n",
        "        'correlation':\n",
        "            lambda f, q, s, zp: (np.corrcoef(f.flatten(),\n",
        "                                             (q.flatten() - zp) / s)[0, 1])\n",
        "    },\n",
        "    model_debug_metrics={\n",
        "        'argmax_accuracy': (lambda f, q: np.mean(np.argmax(f) == np.argmax(q)))\n",
        "    })\n",
        "\n",
        "debugger = tf.lite.experimental.QuantizationDebugger(\n",
        "    converter=converter,\n",
        "    debug_dataset=representative_dataset(ds),\n",
        "    debug_options=debug_options)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PVQ4nEicXz2l"
      },
      "outputs": [],
      "source": [
        "debugger.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dfKA90csX9UL"
      },
      "outputs": [],
      "source": [
        "CUSTOM_RESULTS_FILE = '/tmp/debugger_results.csv'\n",
        "with open(CUSTOM_RESULTS_FILE, 'w') as f:\n",
        "  debugger.layer_statistics_dump(f)\n",
        "\n",
        "custom_layer_stats = pd.read_csv(CUSTOM_RESULTS_FILE)\n",
        "custom_layer_stats[['op_name', 'mean_abs_error', 'correlation']].tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qqq30oWsZF5b"
      },
      "source": [
        "`model_debug_metrics` 的结果可以单独在 `debugger.model_statistics` 中看到。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wrXlmzEHYhQ5"
      },
      "outputs": [],
      "source": [
        "debugger.model_statistics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqJBLIsoUyIg"
      },
      "source": [
        "### 使用（内部）mlir_quantize API 访问深度功能\n",
        "\n",
        "注：以下部分的某些功能，`TFLiteConverter._experimental_calibrate_only` 和 `converter.mlir_quantize` 为实验性内部 API，可能会有非向后兼容的更改。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VJm66Cz-XpeF"
      },
      "outputs": [],
      "source": [
        "from tensorflow.lite.python import convert"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2krUVzpiUp3u"
      },
      "source": [
        "#### 全模型验证模式\n",
        "\n",
        "调试模型生成的默认行为是按层验证。在该模式下，浮点和量化运算对的输入来自相同的源（先前的量化运算）。另一种模式是全模型验证，其中浮点模型和量化模型是分开的。此模式将有助于观察错误是如何在模型中向下传播的。若要启用，请在手动生成调试模型时，将 `enable_whole_model_verify=True` 设置为 `convert.mlir_quantize`。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5zykINDlVLSg"
      },
      "outputs": [],
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.representative_dataset = representative_dataset(ds)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter._experimental_calibrate_only = True\n",
        "calibrated_model = converter.convert()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eqvXlEiFXfSu"
      },
      "outputs": [],
      "source": [
        "# Note that enable_numeric_verify and enable_whole_model_verify are set.\n",
        "quantized_model = convert.mlir_quantize(\n",
        "    calibrated_model,\n",
        "    enable_numeric_verify=True,\n",
        "    enable_whole_model_verify=True)\n",
        "debugger = tf.lite.experimental.QuantizationDebugger(\n",
        "    quant_debug_model_content=quantized_model,\n",
        "    debug_dataset=representative_dataset(ds))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQ6TFsXQVHMe"
      },
      "source": [
        "#### 来自已经校准的模型的选择性量化\n",
        "\n",
        "您可以直接调用 `convert.mlir_quantize` 从已校准的模型中获取选择性量化模型。当您想要校准一次模型，并尝试各种拒绝列表组合时，这将特别有用。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZCS-Fa9lbdc0"
      },
      "outputs": [],
      "source": [
        "selective_quantized_model = convert.mlir_quantize(\n",
        "    calibrated_model, denylisted_nodes=suspected_layers)\n",
        "eval_tflite(selective_quantized_model, ds)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Eq_8T2oauIED"
      ],
      "name": "quantization_debugger.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
