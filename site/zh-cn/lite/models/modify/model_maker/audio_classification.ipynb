{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3XX46cTrh6iD"
      },
      "source": [
        "##### Copyright 2021 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "sKrlWr6Kh-mF"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hST65kOHXpiL"
      },
      "source": [
        "# 基于 TensorFlow Lite Model Maker 的音频域迁移学习\n",
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>     <a target=\"_blank\" href=\"https://tensorflow.google.cn/lite/models/modify/model_maker/audio_classification\"><img src=\"https://tensorflow.google.cn/images/tf_logo_32px.png\">在 TensorFlow.org 上查看</a>\n",
        "</td>\n",
        "  <td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/zh-cn/lite/models/modify/model_maker/audio_classification.ipynb\"><img src=\"https://tensorflow.google.cn/images/colab_logo_32px.png\">在 Google Colab 中运行</a></td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/zh-cn/lite/models/modify/model_maker/audio_classification.ipynb\"><img src=\"https://tensorflow.google.cn/images/GitHub-Mark-32px.png\">在 Github 上查看源代码</a>\n",
        "</td>\n",
        "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/zh-cn/lite/models/modify/model_maker/audio_classification.ipynb\"><img src=\"https://tensorflow.google.cn/images/download_logo_32px.png\">下载笔记本</a>\n",
        "</td>\n",
        "  <td>     <a href=\"https://tfhub.dev/google/yamnet/1\"><img src=\"https://tensorflow.google.cn/images/hub_logo_32px.png\">查看 TF Hub 模型 </a>\n",
        "</td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BB5k6xNKJ5Xe"
      },
      "source": [
        "在此 CoLab 笔记本中，您将学习如何使用 [TensorFlow Lite Model Maker](https://tensorflow.google.cn/lite/models/modify/model_maker) 来训练自定义音频分类模型。\n",
        "\n",
        "Model Maker 库能够使用迁移学习来简化使用自定义数据集训练 TensorFlow Lite 模型的过程。使用您自己的自定义数据集重新训练 TensorFlow Lite 模型可以减少所需的训练数据量，并将缩短训练时间。\n",
        "\n",
        "这是[在 Android 上自定义并部署音频模型 Codelab](https://codelabs.developers.google.com/codelabs/tflite-audio-classification-custom-model-android) 中的一部分。\n",
        "\n",
        "您将使用一个自定义的鸟类数据集，并导出一个可在手机上使用的 TFLite 模型、一个可用于在浏览器中进行推断的 TensorFlow.JS 模型，以及一个可用于服务的 SavedModel 版本。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AeZZ_cSsZfPx"
      },
      "source": [
        "## 安装依赖项\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wbMc4vHjaYdQ"
      },
      "outputs": [],
      "source": [
        "!sudo apt -y install libportaudio2\n",
        "!pip install tflite-model-maker"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2ck_Ghdcgt9"
      },
      "source": [
        "## 导入 TensorFlow、Model Maker 和其他库\n",
        "\n",
        "在所需的依赖项中，您将使用 TensorFlow 和 Model Maker。除了这些，其他依赖项用于音频操作、播放和可视化。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rwUA9u4oWoCR"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tflite_model_maker as mm\n",
        "from tflite_model_maker import audio_classifier\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import itertools\n",
        "import glob\n",
        "import random\n",
        "\n",
        "from IPython.display import Audio, Image\n",
        "from scipy.io import wavfile\n",
        "\n",
        "print(f\"TensorFlow Version: {tf.__version__}\")\n",
        "print(f\"Model Maker Version: {mm.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIfm2TxKZAuA"
      },
      "source": [
        "## Birds 数据集\n",
        "\n",
        "Birds 数据集是 5 种鸟类歌声的教育集合：\n",
        "\n",
        "- White-breasted Wood-Wren（白胸林鹩）\n",
        "- House Sparrow（家麻雀）\n",
        "- Red Crossbill（红交嘴雀）\n",
        "- Chestnut-crowned Antpitta（栗顶蚁鸫）\n",
        "- Azara's Spinetail（阿氏针尾雀）\n",
        "\n",
        "原始音频来自 [Xeno-canto](https://www.xeno-canto.org/)，这是一个致力于分享世界各地鸟鸣的网站。\n",
        "\n",
        "我们从下载数据开始。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "upNRfilkNSmr"
      },
      "outputs": [],
      "source": [
        "birds_dataset_folder = tf.keras.utils.get_file('birds_dataset.zip',\n",
        "                                                'https://storage.googleapis.com/laurencemoroney-blog.appspot.com/birds_dataset.zip',\n",
        "                                                cache_dir='./',\n",
        "                                                cache_subdir='dataset',\n",
        "                                                extract=True)\n",
        "                                                "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "441bbzZ5d6oq"
      },
      "source": [
        "## 探索数据\n",
        "\n",
        "音频已被拆分为训练文件夹和测试文件夹。在每个拆分的文件夹中，每种鸟都有一个文件夹，使用它们的 `bird_code` 作为文件名。\n",
        "\n",
        "音频均为单声道，采样率为 16 kHz。\n",
        "\n",
        "有关每个文件的详细信息，请阅读 `metadata.csv` 文件。其中包含所有文件的作者、链接和一些详细信息。在本教程中，您不需要自己阅读它。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ayd7UqCfQQFU"
      },
      "outputs": [],
      "source": [
        "# @title [Run this] Util functions and data structures.\n",
        "\n",
        "data_dir = './dataset/small_birds_dataset'\n",
        "\n",
        "bird_code_to_name = {\n",
        "  'wbwwre1': 'White-breasted Wood-Wren',\n",
        "  'houspa': 'House Sparrow',\n",
        "  'redcro': 'Red Crossbill',  \n",
        "  'chcant2': 'Chestnut-crowned Antpitta',\n",
        "  'azaspi1': \"Azara's Spinetail\",   \n",
        "}\n",
        "\n",
        "birds_images = {\n",
        "  'wbwwre1': 'https://upload.wikimedia.org/wikipedia/commons/thumb/2/22/Henicorhina_leucosticta_%28Cucarachero_pechiblanco%29_-_Juvenil_%2814037225664%29.jpg/640px-Henicorhina_leucosticta_%28Cucarachero_pechiblanco%29_-_Juvenil_%2814037225664%29.jpg', # \tAlejandro Bayer Tamayo from Armenia, Colombia \n",
        "  'houspa': 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/52/House_Sparrow%2C_England_-_May_09.jpg/571px-House_Sparrow%2C_England_-_May_09.jpg', # \tDiliff\n",
        "  'redcro': 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/49/Red_Crossbills_%28Male%29.jpg/640px-Red_Crossbills_%28Male%29.jpg', #  Elaine R. Wilson, www.naturespicsonline.com\n",
        "  'chcant2': 'https://upload.wikimedia.org/wikipedia/commons/thumb/6/67/Chestnut-crowned_antpitta_%2846933264335%29.jpg/640px-Chestnut-crowned_antpitta_%2846933264335%29.jpg', # \tMike's Birds from Riverside, CA, US\n",
        "  'azaspi1': 'https://upload.wikimedia.org/wikipedia/commons/thumb/b/b2/Synallaxis_azarae_76608368.jpg/640px-Synallaxis_azarae_76608368.jpg', # https://www.inaturalist.org/photos/76608368\n",
        "}\n",
        "\n",
        "test_files = os.path.abspath(os.path.join(data_dir, 'test/*/*.wav'))\n",
        "\n",
        "def get_random_audio_file():\n",
        "  test_list = glob.glob(test_files)\n",
        "  random_audio_path = random.choice(test_list)\n",
        "  return random_audio_path\n",
        "\n",
        "\n",
        "def show_bird_data(audio_path):\n",
        "  sample_rate, audio_data = wavfile.read(audio_path, 'rb')\n",
        "\n",
        "  bird_code = audio_path.split('/')[-2]\n",
        "  print(f'Bird name: {bird_code_to_name[bird_code]}')\n",
        "  print(f'Bird code: {bird_code}')\n",
        "  display(Image(birds_images[bird_code]))\n",
        "\n",
        "  plttitle = f'{bird_code_to_name[bird_code]} ({bird_code})'\n",
        "  plt.title(plttitle)\n",
        "  plt.plot(audio_data)\n",
        "  display(Audio(audio_data, rate=sample_rate))\n",
        "\n",
        "print('functions and data structures created')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yrv0uD7aXYl4"
      },
      "source": [
        "### 播放一些音频\n",
        "\n",
        "为了更好地理解数据，我们来听一听测试拆分中的随机音频文件。\n",
        "\n",
        "注：在本笔记本的后面部分，您将对此音频运行推断以进行测试"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tEeMZh-VQy97"
      },
      "outputs": [],
      "source": [
        "random_audio = get_random_audio_file()\n",
        "show_bird_data(random_audio)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQj1Mf7YZELS"
      },
      "source": [
        "## 训练模型\n",
        "\n",
        "使用 Model Maker 制作音频时，必须从模型规范开始。这是基本模型，您的新模型将从中提取信息以学习新类。它还会影响如何转换数据集以符合模型规范参数，例如：采样率、通道数。\n",
        "\n",
        "[YAMNet](https://tfhub.dev/google/yamnet/1) 是在 AudioSet 数据集上训练的音频事件分类器，用于从 AudioSet 本体预测音频事件。\n",
        "\n",
        "它的输入频率预计为 16 kHz，具有 1 个通道。\n",
        "\n",
        "您无需自己进行任何重采样。Model Maker 会为您完成。\n",
        "\n",
        "- `frame_length` 用于确定每个训练样本的长度。在此示例中为 EXPECTED_WAVEFORM_LENGTH * 3s\n",
        "\n",
        "- `frame_steps` 用于确定训练样本之间的距离。在本例中，第 i 个样本将在第 (i-1) 个样本后的 EXPECTED_WAVEFORM_LENGTH * 6s 处开始。\n",
        "\n",
        "设置这些值的原因是为了绕过现实世界数据集中的一些限制。\n",
        "\n",
        "例如，在鸟类数据集中，鸟类并不总是唱歌。它们会唱歌，休息，然后再唱歌，中间会有噪音。拥有较长的帧将有助于捕捉歌声，但将其设置得太长会减少用于训练的样本数量。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tUcxtfHXY7XS"
      },
      "outputs": [],
      "source": [
        "spec = audio_classifier.YamNetSpec(\n",
        "    keep_yamnet_and_custom_heads=True,\n",
        "    frame_step=3 * audio_classifier.YamNetSpec.EXPECTED_WAVEFORM_LENGTH,\n",
        "    frame_length=6 * audio_classifier.YamNetSpec.EXPECTED_WAVEFORM_LENGTH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EF185yZ_M7zu"
      },
      "source": [
        "## 加载数据\n",
        "\n",
        "Model Maker 具有从文件夹加载数据并以模型规范的预期格式提供数据的 API。\n",
        "\n",
        "训练拆分和测试拆分基于文件夹。验证数据集将被创建为训练拆分的 20%。\n",
        "\n",
        "注：`cache=True` 对于提高之后的训练速度很重要，但它也需要更多的 RAM 来保存数据。对于 Birds 数据集，这不是问题，因为它只有 300MB，但如果您使用自己的数据，则必须加以注意。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cX0RqETqZgzo"
      },
      "outputs": [],
      "source": [
        "train_data = audio_classifier.DataLoader.from_folder(\n",
        "    spec, os.path.join(data_dir, 'train'), cache=True)\n",
        "train_data, validation_data = train_data.split(0.8)\n",
        "test_data = audio_classifier.DataLoader.from_folder(\n",
        "    spec, os.path.join(data_dir, 'test'), cache=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ziMghju-Rts2"
      },
      "source": [
        "## 训练模型\n",
        "\n",
        "audio_classifier 具有 [`create`](https://tensorflow.google.cn/lite/api_docs/python/tflite_model_maker/audio_classifier/create) 方法，用于创建并开始训练模型。\n",
        "\n",
        "您可以自定义许多参数，有关更多信息，请阅读文档中的更多详细信息。\n",
        "\n",
        "在第一次尝试中，您将使用所有默认配置并训练 100 个周期。\n",
        "\n",
        "注：第一个周期会比所有其他周期花费更长的时间，因为此时会创建缓存。之后，每一个周期花费近 1 秒。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8r6Awvl4ZkIv"
      },
      "outputs": [],
      "source": [
        "batch_size = 128\n",
        "epochs = 100\n",
        "\n",
        "print('Training the model')\n",
        "model = audio_classifier.create(\n",
        "    train_data,\n",
        "    spec,\n",
        "    validation_data,\n",
        "    batch_size=batch_size,\n",
        "    epochs=epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXMEHZkAxJTl"
      },
      "source": [
        "准确率看起来很好，但重要的是对测试数据运行评估步骤，并验证您的模型是否能够在非种子数据上取得良好的结果。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GDoQACMrZnOx"
      },
      "outputs": [],
      "source": [
        "print('Evaluating the model')\n",
        "model.evaluate(test_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QRRAM39aOxS"
      },
      "source": [
        "## 理解模型\n",
        "\n",
        "训练分类器时，查看[混淆矩阵](https://en.wikipedia.org/wiki/Confusion_matrix)非常实用。混淆矩阵可帮助您详细了解分类器在测试数据上的性能。\n",
        "\n",
        "Model Maker 已经为您创建了混淆矩阵。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zqB3c0368iH3"
      },
      "outputs": [],
      "source": [
        "def show_confusion_matrix(confusion, test_labels):\n",
        "  \"\"\"Compute confusion matrix and normalize.\"\"\"\n",
        "  confusion_normalized = confusion.astype(\"float\") / confusion.sum(axis=1)\n",
        "  axis_labels = test_labels\n",
        "  ax = sns.heatmap(\n",
        "      confusion_normalized, xticklabels=axis_labels, yticklabels=axis_labels,\n",
        "      cmap='Blues', annot=True, fmt='.2f', square=True)\n",
        "  plt.title(\"Confusion matrix\")\n",
        "  plt.ylabel(\"True label\")\n",
        "  plt.xlabel(\"Predicted label\")\n",
        "\n",
        "confusion_matrix = model.confusion_matrix(test_data)\n",
        "show_confusion_matrix(confusion_matrix.numpy(), test_data.index_to_label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gr1s7juBy7H"
      },
      "source": [
        "## 测试模型 [可选]\n",
        "\n",
        "您可以使用测试数据集中的样本音频试用该模型，以查看结果。\n",
        "\n",
        "首先，您获得应用模型。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PmlmTl42Bq_u"
      },
      "outputs": [],
      "source": [
        "serving_model = model.create_serving_model()\n",
        "\n",
        "print(f'Model\\'s input shape and type: {serving_model.inputs}')\n",
        "print(f'Model\\'s output shape and type: {serving_model.outputs}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQsZFO2mrYhx"
      },
      "source": [
        "回到您之前加载的随机音频"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8dv5ViK0reXc"
      },
      "outputs": [],
      "source": [
        "# if you want to try another file just uncoment the line below\n",
        "random_audio = get_random_audio_file()\n",
        "show_bird_data(random_audio)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uixOfKSUj_9m"
      },
      "source": [
        "创建的模型具有固定的输入窗口。\n",
        "\n",
        "对于给定的音频文件，您必须将其拆分成预期大小的数据窗口。最后一个窗口可能需要用零填充。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YAvGKQL0lNty"
      },
      "outputs": [],
      "source": [
        "sample_rate, audio_data = wavfile.read(random_audio, 'rb')\n",
        "\n",
        "audio_data = np.array(audio_data) / tf.int16.max\n",
        "input_size = serving_model.input_shape[1]\n",
        "\n",
        "splitted_audio_data = tf.signal.frame(audio_data, input_size, input_size, pad_end=True, pad_value=0)\n",
        "\n",
        "print(f'Test audio path: {random_audio}')\n",
        "print(f'Original size of the audio data: {len(audio_data)}')\n",
        "print(f'Number of windows for inference: {len(splitted_audio_data)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLxKd0eFkMcR"
      },
      "source": [
        "您将循环遍历所有拆分的音频，并为每个音频应用模型。\n",
        "\n",
        "您刚刚训练的模型有两个输出：原始 YAMNet 的输出和您刚刚训练的输出。这一点很重要，因为现实世界的环境比鸟鸣要复杂得多。您可以使用 YAMNet 的输出过滤掉不相关的音频，例如，在鸟类用例中，如果 YAMNet 没有对 Birds 或 Animals 进行分类，这可能表明您的模型的输出可能具有不相关的分类。\n",
        "\n",
        "下面打印了两个输出，以便于理解它们之间的关系。您的模型犯错的大多数时候是当 YAMNet 的预测与您的领域不相关时（例如：鸟类）。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4-8fJLrxGwYT"
      },
      "outputs": [],
      "source": [
        "print(random_audio)\n",
        "\n",
        "results = []\n",
        "print('Result of the window ith:  your model class -> score,  (spec class -> score)')\n",
        "for i, data in enumerate(splitted_audio_data):\n",
        "  yamnet_output, inference = serving_model(data)\n",
        "  results.append(inference[0].numpy())\n",
        "  result_index = tf.argmax(inference[0])\n",
        "  spec_result_index = tf.argmax(yamnet_output[0])\n",
        "  t = spec._yamnet_labels()[spec_result_index]\n",
        "  result_str = f'Result of the window {i}: ' \\\n",
        "  f'\\t{test_data.index_to_label[result_index]} -> {inference[0][result_index].numpy():.3f}, ' \\\n",
        "  f'\\t({spec._yamnet_labels()[spec_result_index]} -> {yamnet_output[0][spec_result_index]:.3f})'\n",
        "  print(result_str)\n",
        "\n",
        "\n",
        "results_np = np.array(results)\n",
        "mean_results = results_np.mean(axis=0)\n",
        "result_index = mean_results.argmax()\n",
        "print(f'Mean result: {test_data.index_to_label[result_index]} -> {mean_results[result_index]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yASrikBgZ9ZO"
      },
      "source": [
        "## 导出模型\n",
        "\n",
        "最后一步是导出要在嵌入式设备或浏览器上使用的模型。\n",
        "\n",
        "`export` 方法能够为您导出这两种格式。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xw_ehPxAdQlz"
      },
      "outputs": [],
      "source": [
        "models_path = './birds_models'\n",
        "print(f'Exporing the TFLite model to {models_path}')\n",
        "\n",
        "model.export(models_path, tflite_filename='my_birds_model.tflite')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjZRKmurA3y_"
      },
      "source": [
        "您还可以导出 SavedModel 版本，以便在 Python 环境中应用或使用。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "veBwppOsA-kn"
      },
      "outputs": [],
      "source": [
        "model.export(models_path, export_format=[mm.ExportFormat.SAVED_MODEL, mm.ExportFormat.LABEL])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xr0idac6xfi"
      },
      "source": [
        "## 后续步骤\n",
        "\n",
        "您成功了。\n",
        "\n",
        "现在，您的新模型可以使用 [TFLite AudioClassifier Task API](https://tensorflow.google.cn/lite/inference_with_metadata/task_library/audio_classifier) 部署在移动设备上。\n",
        "\n",
        "您还可以使用具有不同类的您自己的数据尝试相同的过程，这里是[用于音频分类的 Model Maker](https://tensorflow.google.cn/lite/api_docs/python/tflite_model_maker/audio_classifier) 的文档。\n",
        "\n",
        "您还可以从端到端参考应用中学习：[Android](https://github.com/tensorflow/examples/tree/master/lite/examples/sound_classification/android/)，[iOS](https://github.com/tensorflow/examples/tree/master/lite/examples/sound_classification/ios)。"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "audio_classification.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
