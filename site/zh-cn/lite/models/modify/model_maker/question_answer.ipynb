{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2q27gKz1H20"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "TUfAcER1oUS6"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gb7qyhNL1yWt"
      },
      "source": [
        "# 使用 TensorFlow Lite Model Maker 的 BERT 问答"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fw5Y7snSuG51"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>     <a target=\"_blank\" href=\"https://tensorflow.google.cn/lite/tutorials/model_maker_question_answer\"><img src=\"https://tensorflow.google.cn/images/tf_logo_32px.png\">在 TensorFlow.org 上查看</a>   </td>\n",
        "  <td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/zh-cn/lite/models/modify/model_maker/question_answer.ipynb\"><img src=\"https://tensorflow.google.cn/images/colab_logo_32px.png\">在 Google Colab 中运行 </a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/zh-cn/lite/models/modify/model_maker/question_answer.ipynb\">     <img src=\"https://tensorflow.google.cn/images/GitHub-Mark-32px.png\">     在 GitHub 上查看源代码</a></td>\n",
        "  <td><a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/zh-cn/lite/models/modify/model_maker/question_answer.ipynb\"><img src=\"https://tensorflow.google.cn/images/download_logo_32px.png\">下载笔记本</a></td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sr3q-gvm3cI8"
      },
      "source": [
        "TensorFlow Lite Model Maker 库简化了在设备端机器学习应用中部署 TensorFlow 模型时修改此模型并将其转换为特定输入数据的过程。\n",
        "\n",
        "此笔记本展示了一个端到端示例，该示例利用 Model Maker 库说明了如何对用于问答任务的常用问答模型进行修改和转换。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxEHFTk755qw"
      },
      "source": [
        "# BERT 问答任务简介"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFbKTCF25-SG"
      },
      "source": [
        "此库中支持的任务是提取性问答任务，这意味着给定一个段落和一个问题，答案就是段落中的跨度。下图给出了一个问答示例。\n",
        "\n",
        "<p align=\"center\"><img src=\"https://storage.googleapis.com/download.tensorflow.org/models/tflite/screenshots/model_maker_squad_showcase.png\"></p>\n",
        "\n",
        "<p align=\"center\">\n",
        "    <em>答案是段落中的跨度（图片来源：<a href=\"https://rajpurkar.github.io/mlx/qa-and-squad/\">SQuAD 博客</a>）</em>\n",
        "</p>\n",
        "\n",
        "对于问答任务的模型，输入应当是经过预处理的段落和问题对，输出应当是段落中每个词例的起始 logits 和结束 logits。可以根据段落和问题的长度设置和调整输入的大小。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gb7P4WQta8Ub"
      },
      "source": [
        "## 端到端概述\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7cIHjIfbDlG"
      },
      "source": [
        "以下代码段演示了如何在几行代码内获得模型。整个过程包括 5 个步骤：(1) 选择模型，(2) 加载数据，(3) 重新训练模型，(4) 评估，以及 (5) 将其导出为 TensorFlow Lite 格式。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQPdlxZBYuZG"
      },
      "source": [
        "```python\n",
        "# Chooses a model specification that represents the model.\n",
        "spec = model_spec.get('mobilebert_qa')\n",
        "\n",
        "# Gets the training data and validation data.\n",
        "train_data = DataLoader.from_squad(train_data_path, spec, is_training=True)\n",
        "validation_data = DataLoader.from_squad(validation_data_path, spec, is_training=False)\n",
        "\n",
        "# Fine-tunes the model.\n",
        "model = question_answer.create(train_data, model_spec=spec)\n",
        "\n",
        "# Gets the evaluation result.\n",
        "metric = model.evaluate(validation_data)\n",
        "\n",
        "# Exports the model to the TensorFlow Lite format with metadata in the export directory.\n",
        "model.export(export_dir)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exScAdvBbNEi"
      },
      "source": [
        "以下部分将更详细地说明上面的代码。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcLF2PKkSbV3"
      },
      "source": [
        "## 前提条件\n",
        "\n",
        "要运行此示例，请安装所需的软件包，包括 [GitHub 仓库](https://github.com/tensorflow/examples/tree/master/tensorflow_examples/lite/model_maker)中的 Model Maker 软件包。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qhl8lqVamEty"
      },
      "outputs": [],
      "source": [
        "!sudo apt -y install libportaudio2\n",
        "!pip install -q tflite-model-maker-nightly"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6lRhVK9Q_0U"
      },
      "source": [
        "导入所需的软件包。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XtxiUeZEiXpt"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "assert tf.__version__.startswith('2')\n",
        "\n",
        "from tflite_model_maker import model_spec\n",
        "from tflite_model_maker import question_answer\n",
        "from tflite_model_maker.config import ExportFormat\n",
        "from tflite_model_maker.question_answer import DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l65ctmtW7_FF"
      },
      "source": [
        "“端到端概述”演示了一个简单的端到端示例。以下部分会分步介绍该示例，以展示更多详细信息。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJ_B8fMDOhMR"
      },
      "source": [
        "## 选择代表问答模型的 model_spec\n",
        "\n",
        "每个 `model_spec` 对象都代表一个特定的问答模型。Model Maker 目前支持 MobileBERT 和 BERT-Base 模型。\n",
        "\n",
        "支持的模型 | model_spec 的名称 | 模型说明\n",
        "--- | --- | ---\n",
        "[MobileBERT](https://arxiv.org/pdf/2004.02984.pdf) | 'mobilebert_qa' | 比 BERT-Base 小 4.3 倍、快 5.5 倍，同时可获得极具竞争力的结果，适用于设备端场景。\n",
        "[MobileBERT-SQuAD](https://arxiv.org/pdf/2004.02984.pdf) | 'mobilebert_qa_squad' | 与 MobileBERT 模型相同的模型架构，初始模型已基于 [SQuAD1.1](https://rajpurkar.github.io/SQuAD-explorer/) 进行了重新训练。\n",
        "[BERT-Base](https://arxiv.org/pdf/1810.04805.pdf) | 'bert_qa' | NLP 任务中广泛使用的标准 BERT 模型。\n",
        "\n",
        "在本教程中，我们以 [MobileBERT-SQuAD](https://arxiv.org/pdf/2004.02984.pdf) 为例。由于该模型已基于 [SQuAD1.1](https://rajpurkar.github.io/SQuAD-explorer/) 进行了重新训练，因此可以更快地覆盖问答任务。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vEAWuZQ1PFiX"
      },
      "outputs": [],
      "source": [
        "spec = model_spec.get('mobilebert_qa_squad')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygEncJxtl-nQ"
      },
      "source": [
        "## 加载特定于设备端 ML 应用的输入数据并对这些数据进行预处理\n",
        "\n",
        "[TriviaQA](https://nlp.cs.washington.edu/triviaqa/) 是一个阅读理解数据集，包含超过 65 万个问题-答案-证据三元组。在本教程中，您将使用此数据集的一个子集来学习如何使用 Model Maker 库。\n",
        "\n",
        "要加载数据，请通过使用 `--sample_size=8000` 和一组 `web` 数据运行[转换器 Python 脚本](https://github.com/mandarjoshi90/triviaqa#miscellaneous)，将 TriviaQA 数据集转换为 [SQuAD1.1](https://rajpurkar.github.io/SQuAD-explorer/) 格式。按照以下方式稍微修改一下转换代码：\n",
        "\n",
        "- 跳过无法在上下文文档中找到任何答案的样本；\n",
        "- 在不使用大写或小写的上下文中获取原始答案。\n",
        "\n",
        "下载已转换数据集的归档版本。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7tOfUr2KlgpU"
      },
      "outputs": [],
      "source": [
        "train_data_path = tf.keras.utils.get_file(\n",
        "    fname='triviaqa-web-train-8000.json',\n",
        "    origin='https://storage.googleapis.com/download.tensorflow.org/models/tflite/dataset/triviaqa-web-train-8000.json')\n",
        "validation_data_path = tf.keras.utils.get_file(\n",
        "    fname='triviaqa-verified-web-dev.json',\n",
        "    origin='https://storage.googleapis.com/download.tensorflow.org/models/tflite/dataset/triviaqa-verified-web-dev.json')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfZk8GNr_1nc"
      },
      "source": [
        "您还可以使用自己的数据集训练 MobileBERT 模型。如果您正在 Colab 上运行此笔记本，请使用左侧边栏上传数据。\n",
        "\n",
        " <img src=\"https://storage.googleapis.com/download.tensorflow.org/models/tflite/screenshots/model_maker_question_answer.png\" alt=\"上传文件\">\n",
        "\n",
        "如果您不想将数据上传到云端，也可以按照[指南](https://github.com/tensorflow/examples/tree/master/tensorflow_examples/lite/model_maker)离线运行库。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E051HBUM5owi"
      },
      "source": [
        "使用 `DataLoader.from_squad` 方法根据特定的 <code>model_spec</code> 加载和预处理 [SQuAD 格式](https://rajpurkar.github.io/SQuAD-explorer/)数据。您可以使用 SQuAD2.0 或 SQuAD1.1 格式。将参数 `version_2_with_negative` 设置为 `True` 表示格式为 SQuAD2.0。否则，格式为 SQuAD1.1。默认情况下，`version_2_with_negative` 为 `False`。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I_fOlZsklmlL"
      },
      "outputs": [],
      "source": [
        "train_data = DataLoader.from_squad(train_data_path, spec, is_training=True)\n",
        "validation_data = DataLoader.from_squad(validation_data_path, spec, is_training=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWuoensX4vDA"
      },
      "source": [
        "## 自定义 TensorFlow 模型\n",
        "\n",
        "根据加载的数据创建自定义问答模型。`create` 函数包括以下步骤：\n",
        "\n",
        "1. 根据 `model_spec` 为问答创建模型。\n",
        "2. 训练问答模型。根据 `model_spec` 对象中的两个变量 `default_training_epochs` 和 `default_batch_size` 设置默认周期和默认批次大小。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TvYSUuJY3QxR"
      },
      "outputs": [],
      "source": [
        "model = question_answer.create(train_data, model_spec=spec)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JKI-pNc8idH"
      },
      "source": [
        "看一下详细的模型结构。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gd7Hs8TF8n3H"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LP5FPk_tOxoZ"
      },
      "source": [
        "## 评估自定义的模型\n",
        "\n",
        "基于验证数据评估模型并获得一个指标字典，包括 `f1` 得分和 `exact match` 等。请注意，对于 SQuAD1.1 和 SQuAD2.0，指标不同。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A8c2ZQ0J3Riy"
      },
      "outputs": [],
      "source": [
        "model.evaluate(validation_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeHoGAceO2xV"
      },
      "source": [
        "## 导出到 TensorFlow Lite 模型\n",
        "\n",
        "将经过训练的模型转换为带有[元数据](https://tensorflow.google.cn/lite/models/convert/metadata)的 TensorFlow Lite 模型格式，以便您以后可以在设备端 ML 应用中使用。词汇文件嵌入在元数据中。默认的 TFLite 文件名是 `model.tflite`。\n",
        "\n",
        "在许多设备端 ML 应用中，模型大小是一个重要因素。因此，建议您应用量化模型以使其更小并可能加快运行速度。对于 BERT 和 MobileBERT 模型，默认的训练后量化技术是动态范围量化。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Im6wA9lK3TQB"
      },
      "outputs": [],
      "source": [
        "model.export(export_dir='.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w12kvDdHJIGH"
      },
      "source": [
        "您可以通过从 Colab 的左侧边栏中下载并使用 [TensorFlow Lite Task Library](https://github.com/tensorflow/examples/tree/master/lite/examples/bert_qa/android) 中的 [BertQuestionAnswerer API](https://tensorflow.google.cn/lite/inference_with_metadata/task_library/bert_question_answerer)，在 [bert_qa](https://tensorflow.google.cn/lite/inference_with_metadata/task_library/overview) 参考应用中使用 TensorFlow Lite 模型文件。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFnJPvq3VGh3"
      },
      "source": [
        "允许的导出格式可以是以下列表中的一个或多个：\n",
        "\n",
        "- `ExportFormat.TFLITE`\n",
        "- `ExportFormat.VOCAB`\n",
        "- `ExportFormat.SAVED_MODEL`\n",
        "\n",
        "默认情况下，它仅导出带有元数据的 TensorFlow Lite 模型。您也可以有选择地导出不同的文件。例如，仅导出 vocab 文件，如下所示："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ro2hz4kXVImY"
      },
      "outputs": [],
      "source": [
        "model.export(export_dir='.', export_format=ExportFormat.VOCAB)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZKYthlVrTos"
      },
      "source": [
        "您也可以使用 `evaluate_tflite` 方法评估 tflite 模型。预计此步骤需要较长时间。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ochbq95ZrVFX"
      },
      "outputs": [],
      "source": [
        "model.evaluate_tflite('model.tflite', validation_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EoWiA_zX8rxE"
      },
      "source": [
        "## 高级用法\n",
        "\n",
        "`create` 函数是此库的关键部分，其中 `model_spec` 参数定义了模型规范。目前支持 `BertQASpec` 类。有 2 种模型：MobileBERT 模型和 BERT-Base 模型。`create` 函数包括以下步骤：\n",
        "\n",
        "1. 根据 `model_spec` 为问答创建模型。\n",
        "2. 训练问答模型。\n",
        "\n",
        "本部分介绍了几个高级主题，包括调整模型、调整训练超参数等。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwtiksguDfhl"
      },
      "source": [
        "### 调整模型\n",
        "\n",
        "您可以在 `BertQASpec` 类中调整模型基础架构，例如参数 `seq_len` 和 `query_len`。\n",
        "\n",
        "模型的可调参数：\n",
        "\n",
        "- `seq_len`：馈入模型的段落的长度。\n",
        "- `query_len`：馈入模型的问题的长度。\n",
        "- `doc_stride`：执行滑动窗口方法以获取文档块时的步长。\n",
        "- `initializer_range`：truncated_normal_initializer 的 stdev，用于初始化所有权重矩阵。\n",
        "- `trainable`：布尔值，预训练层是否可训练。\n",
        "\n",
        "训练流水线的可调参数：\n",
        "\n",
        "- `model_dir`：模型检查点文件的位置。如果未设置，将使用临时目录。\n",
        "- `dropout_rate`：随机失活率。\n",
        "- `learning_rate`：Adam 的初始学习率。\n",
        "- `predict_batch_size`：预测的批次大小。\n",
        "- `tpu`：要连接的 TPU 地址。仅在使用 TPU 时使用。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cAOd5_bzH9AQ"
      },
      "source": [
        "例如，您可以训练具有更长序列长度的模型。如果更改模型，必须首先构造一个新的 `model_spec`。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e9WBN0UTQoMN"
      },
      "outputs": [],
      "source": [
        "new_spec = model_spec.get('mobilebert_qa')\n",
        "new_spec.seq_len = 512"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LSTdghTP0Cv"
      },
      "source": [
        "其余步骤相同。请注意，您必须重新运行 `dataloader` 和 `create` 部分，因为不同的模型规范可能具有不同的预处理步骤。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvQuy7RSDir3"
      },
      "source": [
        "### 调整训练超参数\n",
        "\n",
        "您还可以调整训练超参数（例如 `epochs` 和 `batch_size`）来影响模型性能。例如，\n",
        "\n",
        "- `epochs`：更多周期可能会获得更好的性能，但也可能导致过拟合。\n",
        "- `batch_size`：一个训练步骤中要使用的样本数。\n",
        "\n",
        "例如，您可以使用更多的周期和更大的批次大小进行训练，代码如下：\n",
        "\n",
        "```python\n",
        "model = question_answer.create(train_data, model_spec=spec, epochs=5, batch_size=64)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eq6B9lKMfhS6"
      },
      "source": [
        "### 更改模型架构\n",
        "\n",
        "您可以通过更改 `model_spec` 来更改数据训练的基础模型。例如，要更改为 BERT-Base 模型，请运行：\n",
        "\n",
        "```python\n",
        "spec = model_spec.get('bert_qa')\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2d7yycrgu6L"
      },
      "source": [
        "其余步骤相同。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFQrDMXzOVoB"
      },
      "source": [
        "### 在 TensorFlow Lite 模型上自定义训练后量化\n",
        "\n",
        "[训练后量化](https://tensorflow.google.cn/lite/performance/post_training_quantization)是一种转换技术，可以缩减模型大小并缩短推断延迟，同时改善 CPU 和硬件加速器推断速度，且几乎不会降低模型准确率。因此，它被广泛用于优化模型。\n",
        "\n",
        "Model Maker 库在导出模型时会应用默认的训练后量化技术。如果您想自定义训练后量化，Model Maker 也支持使用 [QuantizationConfig](https://tensorflow.google.cn/lite/api_docs/python/tflite_model_maker/config/QuantizationConfig) 的多个训练后量化选项。我们以 float16 量化为例。首先，定义量化配置。\n",
        "\n",
        "```python\n",
        "config = QuantizationConfig.for_float16()\n",
        "```\n",
        "\n",
        "然后，我们使用此配置导出 TensorFlow Lite 模型。\n",
        "\n",
        "```python\n",
        "model.export(export_dir='.', tflite_filename='model_fp16.tflite', quantization_config=config)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPVopCeB6LV6"
      },
      "source": [
        "# 阅读更多\n",
        "\n",
        "您可以阅读我们的 [BERT 问答](https://tensorflow.google.cn/lite/examples/bert_qa/overview)示例以了解技术细节。如需了解更多信息，请参阅：\n",
        "\n",
        "- TensorFlow Lite Model Maker [指南](https://tensorflow.google.cn/lite/models/modify/model_maker)和 [API 参考](https://tensorflow.google.cn/lite/api_docs/python/tflite_model_maker)。\n",
        "- Task Library：用于部署的 [ImageClassifier](https://tensorflow.google.cn/lite/inference_with_metadata/task_library/bert_question_answerer)。\n",
        "- 端到端参考应用：[Android](https://github.com/tensorflow/examples/tree/master/lite/examples/bert_qa/android) 和 [iOS](https://github.com/tensorflow/examples/tree/master/lite/examples/bert_qa/ios)。"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "question_answer.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
