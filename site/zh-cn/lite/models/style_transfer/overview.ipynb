{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_nWetWWd_ns"
      },
      "source": [
        "##### Copyright 2019 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "2pHVBk_seED1"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7vSdG6sAIQn"
      },
      "source": [
        "# 使用 TensorFlow Lite 进行艺术风格迁移"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwc5GKHBASdc"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>     <a target=\"_blank\" href=\"https://tensorflow.google.cn/lite/examples/style_transfer/overview\"><img src=\"https://tensorflow.google.cn/images/tf_logo_32px.png\">在 TensorFlow.org 上查看</a> </td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/zh-cn/lite/models/style_transfer/overview.ipynb\"><img src=\"https://tensorflow.google.cn/images/colab_logo_32px.png\">在 Google Colab 运行</a> </td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/zh-cn/lite/models/style_transfer/overview.ipynb\"><img src=\"https://tensorflow.google.cn/images/GitHub-Mark-32px.png\">在 GitHub 上查看源代码</a> </td>\n",
        "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/zh-cn/lite/models/style_transfer/overview.ipynb\"><img src=\"https://tensorflow.google.cn/images/download_logo_32px.png\">下载笔记本</a>   </td>\n",
        "  <td>     <a href=\"https://tfhub.dev/google/magenta/arbitrary-image-stylization-v1-256/2\"><img src=\"https://tensorflow.google.cn/images/hub_logo_32px.png\">查看 TF Hub 模型 </a> </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31O0iaROAw8z"
      },
      "source": [
        "最近，深度学习领域最令人激动的发展之一是[艺术风格迁移](https://arxiv.org/abs/1508.06576)（或者说是创建新图像的能力），这种技术称为[混仿](https://en.wikipedia.org/wiki/Pastiche)，它基于两张输入图像：一张代表艺术风格，另一张代表内容。\n",
        "\n",
        "![Style transfer example](https://storage.googleapis.com/download.tensorflow.org/models/tflite/arbitrary_style_transfer/formula.png)\n",
        "\n",
        "利用这种技术，我们可以使用一系列风格生成漂亮的新作品。\n",
        "\n",
        "![Style transfer example](https://storage.googleapis.com/download.tensorflow.org/models/tflite/arbitrary_style_transfer/table.png)\n",
        "\n",
        "如果您是 TensorFlow Lite 新用户，并且使用的是 Android 平台，我们建议您研究以下可以帮助您入门的示例应用。\n",
        "\n",
        "<a class=\"button button-primary\" href=\"https://github.com/tensorflow/examples/tree/master/lite/examples/style_transfer/android\">Android 示例</a> <a class=\"button button-primary\" href=\"https://github.com/tensorflow/examples/tree/master/lite/examples/style_transfer/ios\">iOS 示例</a>\n",
        "\n",
        "如果您使用的不是 Android 或 iOS 平台，或者您已经熟悉 <a href=\"https://tensorflow.google.cn/api_docs/python/tf/lite\">TensorFlow Lite API</a>，则可以按照本教程学习如何使用预训练的 TensorFlow Lite 模型为任何一对内容与风格图像应用风格迁移。利用该模型，您可以将风格迁移添加到自己的移动应用。\n",
        "\n",
        "该模型在 [GitHub](https://github.com/tensorflow/magenta/tree/master/magenta/models/arbitrary_image_stylization#train-a-model-on-a-large-dataset-with-data-augmentation-to-run-on-mobile) 上开源。您可以使用不同的参数重新训练它（例如，提高内容层权重，使输出图像看起来更像内容图像）。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ak0S4gkOCSxs"
      },
      "source": [
        "## 了解模型架构"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oee6G_bBCgAM"
      },
      "source": [
        "![Model Architecture](https://storage.googleapis.com/download.tensorflow.org/models/tflite/arbitrary_style_transfer/architecture.png)\n",
        "\n",
        "该艺术风格迁移模型包括两个子模型：\n",
        "\n",
        "1. **风格预测模型**：一个基于 MobilenetV2 的神经网络，它将输入风格图像转换为 100 维风格瓶颈向量。\n",
        "2. **风格迁移模型**：将风格瓶颈向量应用到内容图像并创建风格化图像的神经网络。\n",
        "\n",
        "如果您的应用只需要支持一组固定的风格图像，则可以提前计算其风格瓶颈向量，并从应用的二进制文件中排除风格预测模型。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7ZETsRVNMo7"
      },
      "source": [
        "## 设置"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3n8oObKZN4c8"
      },
      "source": [
        "导入依赖项。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xz62Lb1oNm97"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Ua5FpcJNrIj"
      },
      "outputs": [],
      "source": [
        "import IPython.display as display\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "mpl.rcParams['figure.figsize'] = (12,12)\n",
        "mpl.rcParams['axes.grid'] = False\n",
        "\n",
        "import numpy as np\n",
        "import time\n",
        "import functools"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1b988wrrQnVF"
      },
      "source": [
        "下载内容和风格图像以及预训练的 TensorFlow Lite 模型。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "16g57cIMQnen"
      },
      "outputs": [],
      "source": [
        "content_path = tf.keras.utils.get_file('belfry.jpg','https://storage.googleapis.com/khanhlvg-public.appspot.com/arbitrary-style-transfer/belfry-2611573_1280.jpg')\n",
        "style_path = tf.keras.utils.get_file('style23.jpg','https://storage.googleapis.com/khanhlvg-public.appspot.com/arbitrary-style-transfer/style23.jpg')\n",
        "\n",
        "style_predict_path = tf.keras.utils.get_file('style_predict.tflite', 'https://tfhub.dev/google/lite-model/magenta/arbitrary-image-stylization-v1-256/int8/prediction/1?lite-format=tflite')\n",
        "style_transform_path = tf.keras.utils.get_file('style_transform.tflite', 'https://tfhub.dev/google/lite-model/magenta/arbitrary-image-stylization-v1-256/int8/transfer/1?lite-format=tflite')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQZXL7kON-gM"
      },
      "source": [
        "## 预处理输入\n",
        "\n",
        "- 内容图像和风格图像必须是 RGB 格式，且像素值为 [0..1] 范围内的 float32 数字。\n",
        "- 风格图像大小必须为 (1, 256, 256, 3)。我们从中间裁剪该图像并调整其大小。\n",
        "- 内容图像必须为 (1, 384, 384, 3)。我们从中间裁剪该图像并调整其大小。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cg0Vi-rXRUFl"
      },
      "outputs": [],
      "source": [
        "# Function to load an image from a file, and add a batch dimension.\n",
        "def load_img(path_to_img):\n",
        "  img = tf.io.read_file(path_to_img)\n",
        "  img = tf.io.decode_image(img, channels=3)\n",
        "  img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "  img = img[tf.newaxis, :]\n",
        "\n",
        "  return img\n",
        "\n",
        "# Function to pre-process by resizing an central cropping it.\n",
        "def preprocess_image(image, target_dim):\n",
        "  # Resize the image so that the shorter dimension becomes 256px.\n",
        "  shape = tf.cast(tf.shape(image)[1:-1], tf.float32)\n",
        "  short_dim = min(shape)\n",
        "  scale = target_dim / short_dim\n",
        "  new_shape = tf.cast(shape * scale, tf.int32)\n",
        "  image = tf.image.resize(image, new_shape)\n",
        "\n",
        "  # Central crop the image.\n",
        "  image = tf.image.resize_with_crop_or_pad(image, target_dim, target_dim)\n",
        "\n",
        "  return image\n",
        "\n",
        "# Load the input images.\n",
        "content_image = load_img(content_path)\n",
        "style_image = load_img(style_path)\n",
        "\n",
        "# Preprocess the input images.\n",
        "preprocessed_content_image = preprocess_image(content_image, 384)\n",
        "preprocessed_style_image = preprocess_image(style_image, 256)\n",
        "\n",
        "print('Style Image Shape:', preprocessed_style_image.shape)\n",
        "print('Content Image Shape:', preprocessed_content_image.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xE4Yt8nArTeR"
      },
      "source": [
        "## 可视化输入"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ncPA4esJRcEu"
      },
      "outputs": [],
      "source": [
        "def imshow(image, title=None):\n",
        "  if len(image.shape) > 3:\n",
        "    image = tf.squeeze(image, axis=0)\n",
        "\n",
        "  plt.imshow(image)\n",
        "  if title:\n",
        "    plt.title(title)\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "imshow(preprocessed_content_image, 'Content Image')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "imshow(preprocessed_style_image, 'Style Image')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJ7R-CHbjC3s"
      },
      "source": [
        "## 使用 TensorFlow Lite 运行风格迁移"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euu00ldHjKwD"
      },
      "source": [
        "### 风格预测"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o3zd9cTFRiS_"
      },
      "outputs": [],
      "source": [
        "# Function to run style prediction on preprocessed style image.\n",
        "def run_style_predict(preprocessed_style_image):\n",
        "  # Load the model.\n",
        "  interpreter = tf.lite.Interpreter(model_path=style_predict_path)\n",
        "\n",
        "  # Set model input.\n",
        "  interpreter.allocate_tensors()\n",
        "  input_details = interpreter.get_input_details()\n",
        "  interpreter.set_tensor(input_details[0][\"index\"], preprocessed_style_image)\n",
        "\n",
        "  # Calculate style bottleneck.\n",
        "  interpreter.invoke()\n",
        "  style_bottleneck = interpreter.tensor(\n",
        "      interpreter.get_output_details()[0][\"index\"]\n",
        "      )()\n",
        "\n",
        "  return style_bottleneck\n",
        "\n",
        "# Calculate style bottleneck for the preprocessed style image.\n",
        "style_bottleneck = run_style_predict(preprocessed_style_image)\n",
        "print('Style Bottleneck Shape:', style_bottleneck.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00t8S2PekIyW"
      },
      "source": [
        "### 风格迁移"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cZp5bCj8SX1w"
      },
      "outputs": [],
      "source": [
        "# Run style transform on preprocessed style image\n",
        "def run_style_transform(style_bottleneck, preprocessed_content_image):\n",
        "  # Load the model.\n",
        "  interpreter = tf.lite.Interpreter(model_path=style_transform_path)\n",
        "\n",
        "  # Set model input.\n",
        "  input_details = interpreter.get_input_details()\n",
        "  interpreter.allocate_tensors()\n",
        "\n",
        "  # Set model inputs.\n",
        "  interpreter.set_tensor(input_details[0][\"index\"], preprocessed_content_image)\n",
        "  interpreter.set_tensor(input_details[1][\"index\"], style_bottleneck)\n",
        "  interpreter.invoke()\n",
        "\n",
        "  # Transform content image.\n",
        "  stylized_image = interpreter.tensor(\n",
        "      interpreter.get_output_details()[0][\"index\"]\n",
        "      )()\n",
        "\n",
        "  return stylized_image\n",
        "\n",
        "# Stylize the content image using the style bottleneck.\n",
        "stylized_image = run_style_transform(style_bottleneck, preprocessed_content_image)\n",
        "\n",
        "# Visualize the output.\n",
        "imshow(stylized_image, 'Stylized Image')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vv_71Td-QtrW"
      },
      "source": [
        "### 风格混合\n",
        "\n",
        "我们可以将内容图像的风格混合到风格化输出中，使输出看起来更像内容图像。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eJcAURXQQtJ7"
      },
      "outputs": [],
      "source": [
        "# Calculate style bottleneck of the content image.\n",
        "style_bottleneck_content = run_style_predict(\n",
        "    preprocess_image(content_image, 256)\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4S3yg2MgkmRD"
      },
      "outputs": [],
      "source": [
        "# Define content blending ratio between [0..1].\n",
        "# 0.0: 0% style extracts from content image.\n",
        "# 1.0: 100% style extracted from content image.\n",
        "content_blending_ratio = 0.5 #@param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "\n",
        "# Blend the style bottleneck of style image and content image\n",
        "style_bottleneck_blended = content_blending_ratio * style_bottleneck_content \\\n",
        "                           + (1 - content_blending_ratio) * style_bottleneck\n",
        "\n",
        "# Stylize the content image using the style bottleneck.\n",
        "stylized_image_blended = run_style_transform(style_bottleneck_blended,\n",
        "                                             preprocessed_content_image)\n",
        "\n",
        "# Visualize the output.\n",
        "imshow(stylized_image_blended, 'Blended Stylized Image')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9k9jGIep8p1c"
      },
      "source": [
        "## 性能基准\n",
        "\n",
        "性能基准数值通过使用[此处所述](https://tensorflow.google.cn/lite/performance/benchmarks)的工具生成。\n",
        "\n",
        "<table>\n",
        "<thead>\n",
        "<tr>\n",
        "<th>模型名称</th> <th>模型大小</th>  <th>设备</th> <th>NNAPI</th> <th>CPU</th> <th>GPU</th>\n",
        "</tr> </thead>\n",
        "<tr> <td rowspan=\"3\"> <a href=\"https://tfhub.dev/google/lite-model/magenta/arbitrary-image-stylization-v1-256/int8/prediction/1?lite-format=tflite\">风格预测模型 (int8)</a> </td>\n",
        "<td rowspan=\"3\">2.8 Mb</td>\n",
        "<td>Pixel 3 (Android 10)</td> <td>142ms</td>\n",
        "<td>14ms*</td>\n",
        "<td></td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>Pixel 4 (Android 10)</td> <td>5.2ms</td>\n",
        "<td>6.7ms*</td>\n",
        "<td></td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>iPhone XS (iOS 12.4.1)</td> <td></td>\n",
        "<td>10.7ms**</td>\n",
        "<td></td>\n",
        "</tr>\n",
        "<tr> <td rowspan=\"3\"> <a href=\"https://tfhub.dev/google/lite-model/magenta/arbitrary-image-stylization-v1-256/int8/transfer/1?lite-format=tflite\">风格转换模型 (int8)</a> </td>\n",
        "<td rowspan=\"3\">0.2 Mb</td>\n",
        "<td>Pixel 3 (Android 10)</td> <td></td>\n",
        "<td>540ms*</td>\n",
        "<td></td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>Pixel 4 (Android 10)</td> <td></td>\n",
        "<td>405ms*</td>\n",
        "<td></td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>iPhone XS (iOS 12.4.1)</td> <td></td>\n",
        "<td>251ms**</td>\n",
        "<td></td>\n",
        "</tr>\n",
        "<tr> <td rowspan=\"2\"> <a href=\"https://tfhub.dev/google/lite-model/magenta/arbitrary-image-stylization-v1-256/fp16/prediction/1?lite-format=tflite\">风格预测模型 (float16)</a> </td>\n",
        "<td rowspan=\"2\">4.7 Mb</td>\n",
        "<td>Pixel 3 (Android 10)</td> <td>86ms</td>\n",
        "<td>28ms*</td>\n",
        "<td>9.1ms</td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>Pixel 4 (Android 10)</td>\n",
        "<td>32ms</td>\n",
        "<td>12ms*</td>\n",
        "<td>10ms</td>\n",
        "</tr>\n",
        "<tr> <td rowspan=\"2\"> <a href=\"https://tfhub.dev/google/lite-model/magenta/arbitrary-image-stylization-v1-256/fp16/transfer/1?lite-format=tflite\">风格转换模型 (float16)</a> </td>\n",
        "<td rowspan=\"2\">0.4 Mb</td>\n",
        "<td>Pixel 3 (Android 10)</td> <td>1095ms</td>\n",
        "<td>545ms*</td>\n",
        "<td>42ms</td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>Pixel 4 (Android 10)</td>\n",
        "<td>603ms</td>\n",
        "<td>377ms*</td>\n",
        "<td>42ms</td>\n",
        "</tr>\n",
        "</table>\n",
        "\n",
        "** 使用 4 个线程。<br>*\n",
        "*** 为了获得最佳性能结果，在 iPhone 上使用 2 个线程。*\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "overview.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
