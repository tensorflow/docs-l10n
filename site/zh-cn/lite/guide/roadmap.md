# TensorFlow Lite 路线图

**更新时间：2021 年 5 月**

下面提供了我们的路线图的简要概览。请注意，该路线图随时可能发生变化，以下顺序也不代表任何类型的优先级。

我们将路线图分为四个关键部分：易用性、性能、优化和可移植性。我们非常希望您能对我们的路线图提出意见，并在 [TensorFlow Lite 讨论组](https://groups.google.com/a/tensorflow.org/g/tflite)中提供反馈。

## 易用性

- **扩大了运算范围**
    - 根据用户反馈添加目标运算。
    - 为特定的域和区域添加目标运算，包括随机运算、基本 Keras 层运算、哈希表、精选训练运算。
- **更多辅助工具**
    - 提供 TensorFlow 计算图注解和兼容性工具，以在训练和转换后验证 TFLite和硬件加速器的兼容性。
    - 允许在转换过程中针对特定加速器进行目标确定和优化。
- **设备端训练**
    - 支持用于个性化和迁移学习的设备端训练，包括演示端到端使用的 Colab。
    - 支持变量/资源类型（用于推断和训练）。
    - 支持转换和执行具有多个函数（或签名）入口点的计算图。
- **增强了 Android Studio 集成**
    - 将 TFLite 模型拖放到 Android Studio 中即可生成模型接口。
    - 改进 Android Studio 性能分析支持，包括内存性能分析。
- **Model Maker**
    - 支持较新的任务，包括目标检测、推荐和音频分类，涵盖了各种常见用法。
    - 支持能够使迁移学习更容易的数据集。
- **Task Library**
    - 支持更多的模型类型（如音频、自然语言处理）以及相关的预处理和后处理功能。
    - 使用 Task API 更新更多参考示例。
    - 支持所有任务的开箱即用加速。
- **更多 SOTA 模型和示例**
    - 添加更多示例（例如音频、自然语言处理、结构数据相关），以演示模型用法以及覆盖不同平台的新功能和 API。
    - 为设备端创建可共享的主干模型，以降低训练和部署成本。
- **跨多个平台无缝部署**
    - 在 Web 上运行 TensorFlow Lite 模型。
- **改进了跨平台支持**
    - 扩展和改进适用于 Android 上的 Java、iOS 上的 Swift、RPI 上的 Python 的 API。
    - 增强 CMake 支持（例如，更广泛的加速器支持）。
- **更好的前端支持**
    - 改进与各种创作前端的兼容性，包括 Keras、tf.numpy。

## 性能

- **更出色的工具**
    - 用于跟踪每个版本的性能增益的公共信息中心。
    - 用于更好地了解计算图与目标加速器兼容性的工具。
- **改善的 CPU 性能**
    - 默认启用 XNNPack，用于更快的浮点推断。
    - 内核经过优化的端到端半精度 (Float16) 支持。
- **更新的 NN API 支持**
    - 全面支持较新的 Android 版 NN API 功能、运算和类型。
- **GPU 优化**
    - 通过委托序列化支持缩短启动时间。
    - 用于零复制推断的硬件缓冲区互操作。
    - 支持更广泛的设备加速。
    - 更大的算子覆盖范围。

## 优化

- **量化**

    - 旨在从量化中排除某些层的选择性训练后量化。
    - 用于逐层检查量化误差损失的量化调试程序。
    - 将量化感知训练应用于更大的模型覆盖范围，例如 TensorFlow Model Garden。
    - 训练后动态范围量化的质量和性能改进。
    - 允许 SVD 等压缩算法的 Tensor Compression API。

- **剪枝/稀疏**

    - 组合可配置的训练时间（剪枝+量化感知训练）API。
    - 增加对 TF Model Garden 模型的稀疏应用。
    - TensorFlow Lite 中的稀疏模型执行支持。

## 可移植性

- **微控制器支持**
    - 增加了对语音和图像分类的一系列 32 位 MCU 架构用例的支持。
    - 音频前端：图形音频预处理和加速支持。
    - 视觉和音频数据的示例代码和模型。
