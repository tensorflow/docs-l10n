{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Pmxv2ioyCRw"
      },
      "source": [
        "##### Copyright 2019 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "b-2ShX25yNWf"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pa49bUnKyRgF"
      },
      "source": [
        "# 时间序列预测"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11Ilg92myRcw"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td> <img src=\"https://tensorflow.google.cn/images/tf_logo_32px.png\"><a target=\"_blank\" href=\"https://tensorflow.google.cn/tutorials/structured_data/time_series\">在 TensorFlow.org 上查看</a> </td>\n",
        "  <td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/zh-cn/tutorials/structured_data/time_series.ipynb\"><img src=\"https://github.com/tensorflow/docs-l10n/blob/master/site/zh-cn/tutorials/structured_data/time_series.ipynb\">在 Google Colab 中运行</a></td>\n",
        "  <td> <img src=\"https://tensorflow.google.cn/images/GitHub-Mark-32px.png\"><a target=\"_blank\" href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/zh-cn/tutorials/structured_data/time_series.ipynb\">在 GitHub 上查看源代码</a> </td>\n",
        "  <td> <img src=\"https://tensorflow.google.cn/images/download_logo_32px.png\"><a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/tutorials/structured_data/time_series.ipynb\">下载笔记本</a> </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GU8C5qm_4vZb"
      },
      "source": [
        "本教程是使用 TensorFlow 进行时间序列预测的简介。它构建了几种不同样式的模型，包括卷积神经网络 (CNN) 和循环神经网络 (RNN)。\n",
        "\n",
        "本教程包括两个主要部分，每个部分包含若干小节：\n",
        "\n",
        "- 预测单个时间步骤：\n",
        "    - 单个特征。\n",
        "    - 所有特征。\n",
        "- 预测多个时间步骤：\n",
        "    - 单次：一次做出所有预测。\n",
        "    - 自回归：一次做出一个预测，并将输出馈送回模型。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVhK72Pu1cJL"
      },
      "source": [
        "## 安装"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7rZnJaGTWQw0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import datetime\n",
        "\n",
        "import IPython\n",
        "import IPython.display\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "\n",
        "mpl.rcParams['figure.figsize'] = (8, 6)\n",
        "mpl.rcParams['axes.grid'] = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TokBlnUhWFw9"
      },
      "source": [
        "## 天气数据集\n",
        "\n",
        "本教程使用由<a href=\"https://www.bgc-jena.mpg.de/wetter/\" class=\"external\">马克斯·普朗克生物地球化学研究所</a>记录的<a href=\"https://www.bgc-jena.mpg.de\" class=\"external\">[天气时间序列数据集</a>。\n",
        "\n",
        "此数据集包含了 14 个不同特征，例如气温、气压和湿度。自 2003 年起，这些数据每 10 分钟就会被收集一次。为了提高效率，您将仅使用 2009 至 2016 年之间收集的数据。数据集的这一部分由 François Chollet 为他的 [Deep Learning with Python](https://www.manning.com/books/deep-learning-with-python) 一书所准备。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xyv_i85IWInT"
      },
      "outputs": [],
      "source": [
        "zip_path = tf.keras.utils.get_file(\n",
        "    origin='https://storage.googleapis.com/tensorflow/tf-keras-datasets/jena_climate_2009_2016.csv.zip',\n",
        "    fname='jena_climate_2009_2016.csv.zip',\n",
        "    extract=True)\n",
        "csv_path, _ = os.path.splitext(zip_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R81Wx8WP4c3G"
      },
      "source": [
        "本教程仅处理**每小时预测**，因此先从 10 分钟间隔到 1 小时对数据进行下采样："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TX6uGeeeWIkG"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(csv_path)\n",
        "# Slice [start:stop:step], starting from index 5 take every 6th record.\n",
        "df = df[5::6]\n",
        "\n",
        "date_time = pd.to_datetime(df.pop('Date Time'), format='%d.%m.%Y %H:%M:%S')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdbOWXiTWM2T"
      },
      "source": [
        "让我们看一下数据。下面是前几行："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ojHE-iCCWIhz"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRzj1inMfgcO"
      },
      "source": [
        "下面是一些特征随时间的演变："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vg5XIc5tfNlG"
      },
      "outputs": [],
      "source": [
        "plot_cols = ['T (degC)', 'p (mbar)', 'rho (g/m**3)']\n",
        "plot_features = df[plot_cols]\n",
        "plot_features.index = date_time\n",
        "_ = plot_features.plot(subplots=True)\n",
        "\n",
        "plot_features = df[plot_cols][:480]\n",
        "plot_features.index = date_time[:480]\n",
        "_ = plot_features.plot(subplots=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXWLG0_WBhZS"
      },
      "source": [
        "### 检查和清理"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhmZXJew6GlS"
      },
      "source": [
        "接下来，看一下数据集的统计数据："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h510pgKVrrai"
      },
      "outputs": [],
      "source": [
        "df.describe().transpose()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzOTnWOoWMGK"
      },
      "source": [
        "#### 风速"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i47LiW5DCVsP"
      },
      "source": [
        "值得注意的一件事是风速 (`wv (m/s)`) 的 `min` 值和最大值 (`max. wv (m/s)`) 列。这个 `-9999` 可能是错误的。\n",
        "\n",
        "有一个单独的风向列，因此速度应大于零 (`>=0`)。将其替换为零："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qFOq0_80vF4d"
      },
      "outputs": [],
      "source": [
        "wv = df['wv (m/s)']\n",
        "bad_wv = wv == -9999.0\n",
        "wv[bad_wv] = 0.0\n",
        "\n",
        "max_wv = df['max. wv (m/s)']\n",
        "bad_max_wv = max_wv == -9999.0\n",
        "max_wv[bad_max_wv] = 0.0\n",
        "\n",
        "# The above inplace edits are reflected in the DataFrame.\n",
        "df['wv (m/s)'].min()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtmu2IBPgPG8"
      },
      "source": [
        "### 特征工程\n",
        "\n",
        "在潜心构建模型之前，务必了解数据并确保传递格式正确的数据。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYyEaqiD6j4s"
      },
      "source": [
        "#### 风\n",
        "\n",
        "数据的最后一列 `wd (deg)` 以度为单位给出了风向。角度不是很好的模型输入：360° 和 0° 应该会彼此接近，并平滑换行。如果不吹风，方向则无关紧要。\n",
        "\n",
        "现在，风数据的分布状况如下："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YO7JGTcWQG2z"
      },
      "outputs": [],
      "source": [
        "plt.hist2d(df['wd (deg)'], df['wv (m/s)'], bins=(50, 50), vmax=400)\n",
        "plt.colorbar()\n",
        "plt.xlabel('Wind Direction [deg]')\n",
        "plt.ylabel('Wind Velocity [m/s]')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWnf5dwMU1_g"
      },
      "source": [
        "但是，如果将风向和风速列转换为风**向量**，模型将更容易解释："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6GmSTHXw6lI1"
      },
      "outputs": [],
      "source": [
        "wv = df.pop('wv (m/s)')\n",
        "max_wv = df.pop('max. wv (m/s)')\n",
        "\n",
        "# Convert to radians.\n",
        "wd_rad = df.pop('wd (deg)')*np.pi / 180\n",
        "\n",
        "# Calculate the wind x and y components.\n",
        "df['Wx'] = wv*np.cos(wd_rad)\n",
        "df['Wy'] = wv*np.sin(wd_rad)\n",
        "\n",
        "# Calculate the max wind x and y components.\n",
        "df['max Wx'] = max_wv*np.cos(wd_rad)\n",
        "df['max Wy'] = max_wv*np.sin(wd_rad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7iI0zDoxWDyB"
      },
      "source": [
        "模型正确解释风向量的分布要简单得多："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bMgCG5o2SYKD"
      },
      "outputs": [],
      "source": [
        "plt.hist2d(df['Wx'], df['Wy'], bins=(50, 50), vmax=400)\n",
        "plt.colorbar()\n",
        "plt.xlabel('Wind X [m/s]')\n",
        "plt.ylabel('Wind Y [m/s]')\n",
        "ax = plt.gca()\n",
        "ax.axis('tight')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8im1ttOWlRB"
      },
      "source": [
        "#### 时间"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7YE21HKK40zQ"
      },
      "source": [
        "同样，`Date Time` 列非常有用，但不是以这种字符串形式。首先将其转换为秒："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LIFf-VjMfnh3"
      },
      "outputs": [],
      "source": [
        "timestamp_s = date_time.map(pd.Timestamp.timestamp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EC_pnM1D5Sgc"
      },
      "source": [
        "与风向类似，以秒为单位的时间不是有用的模型输入。作为天气数据，它有清晰的每日和每年周期性。可以通过多种方式处理周期性。\n",
        "\n",
        "您可以通过使用正弦和余弦变换为清晰的“一天中的时间”和“一年中的时间”信号来获得可用的信号："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MBfX6CDwax73"
      },
      "outputs": [],
      "source": [
        "day = 24*60*60\n",
        "year = (365.2425)*day\n",
        "\n",
        "df['Day sin'] = np.sin(timestamp_s * (2 * np.pi / day))\n",
        "df['Day cos'] = np.cos(timestamp_s * (2 * np.pi / day))\n",
        "df['Year sin'] = np.sin(timestamp_s * (2 * np.pi / year))\n",
        "df['Year cos'] = np.cos(timestamp_s * (2 * np.pi / year))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mXBbTJZfuuTC"
      },
      "outputs": [],
      "source": [
        "plt.plot(np.array(df['Day sin'])[:25])\n",
        "plt.plot(np.array(df['Day cos'])[:25])\n",
        "plt.xlabel('Time [h]')\n",
        "plt.title('Time of day signal')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HiurzTGQgf_D"
      },
      "source": [
        "这使模型能够访问最重要的频率特征。在这种情况下，您提前知道了哪些频率很重要。\n",
        "\n",
        "如果您没有该信息，则可以通过使用<a href=\"https://en.wikipedia.org/wiki/Fast_Fourier_transform\" class=\"external\">快速傅里叶变换</a>提取特征来确定哪些频率重要。要检验假设，下面是温度随时间变化的 `tf.signal.rfft`。请注意 `1/year` 和 `1/day` 附近频率的明显峰值：\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EN4U1fcMiTYs"
      },
      "outputs": [],
      "source": [
        "fft = tf.signal.rfft(df['T (degC)'])\n",
        "f_per_dataset = np.arange(0, len(fft))\n",
        "\n",
        "n_samples_h = len(df['T (degC)'])\n",
        "hours_per_year = 24*365.2524\n",
        "years_per_dataset = n_samples_h/(hours_per_year)\n",
        "\n",
        "f_per_year = f_per_dataset/years_per_dataset\n",
        "plt.step(f_per_year, np.abs(fft))\n",
        "plt.xscale('log')\n",
        "plt.ylim(0, 400000)\n",
        "plt.xlim([0.1, max(plt.xlim())])\n",
        "plt.xticks([1, 365.2524], labels=['1/Year', '1/day'])\n",
        "_ = plt.xlabel('Frequency (log scale)')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rbL8bSGDHy3"
      },
      "source": [
        "### 拆分数据"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qoFJZmXBaxCc"
      },
      "source": [
        "您将使用 `(70%, 20%, 10%)` 拆分出训练集、验证集和测试集。请注意，在拆分前数据**没有**随机打乱顺序。这有两个原因：\n",
        "\n",
        "1. 确保仍然可以将数据切入连续样本的窗口。\n",
        "2. 确保训练后在收集的数据上对模型进行评估，验证/测试结果更加真实。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ia-MPAHxbInX"
      },
      "outputs": [],
      "source": [
        "column_indices = {name: i for i, name in enumerate(df.columns)}\n",
        "\n",
        "n = len(df)\n",
        "train_df = df[0:int(n*0.7)]\n",
        "val_df = df[int(n*0.7):int(n*0.9)]\n",
        "test_df = df[int(n*0.9):]\n",
        "\n",
        "num_features = df.shape[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-eFckdUUHWmT"
      },
      "source": [
        "### 归一化数据\n",
        "\n",
        "在训练神经网络之前缩放特征很重要。归一化是进行此类缩放的常见方式：减去平均值，然后除以每个特征的标准偏差。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxbIic5TMlxx"
      },
      "source": [
        "平均值和标准偏差应仅使用训练数据进行计算，从而使模型无法访问验证集和测试集中的值。\n",
        "\n",
        "有待商榷的是：模型在训练时不应访问训练集中的未来值，以及应该使用移动平均数来进行此类规范化。这不是本教程的重点，验证集和测试集会确保我们获得（某种程度上）可靠的指标。因此，为了简单起见，本教程使用的是简单平均数。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eji6njXvHusN"
      },
      "outputs": [],
      "source": [
        "train_mean = train_df.mean()\n",
        "train_std = train_df.std()\n",
        "\n",
        "train_df = (train_df - train_mean) / train_std\n",
        "val_df = (val_df - train_mean) / train_std\n",
        "test_df = (test_df - train_mean) / train_std"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6ufs8kk9JQw"
      },
      "source": [
        "现在看一下这些特征的分布。部分特征的尾部确实很长，但没有类似 `-9999` 风速值的明显错误。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T0UYEnkwm8Fe"
      },
      "outputs": [],
      "source": [
        "df_std = (df - train_mean) / train_std\n",
        "df_std = df_std.melt(var_name='Column', value_name='Normalized')\n",
        "plt.figure(figsize=(12, 6))\n",
        "ax = sns.violinplot(x='Column', y='Normalized', data=df_std)\n",
        "_ = ax.set_xticklabels(df.keys(), rotation=90)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBBmdxZ2HgfJ"
      },
      "source": [
        "## 数据窗口化\n",
        "\n",
        "本教程中的模型将基于来自数据连续样本的窗口进行一组预测。\n",
        "\n",
        "输入窗口的主要特征包括：\n",
        "\n",
        "- 输入和标签窗口的宽度（时间步骤数量）。\n",
        "- 它们之间的时间偏移量。\n",
        "- 用作输入、标签或两者的特征。\n",
        "\n",
        "本教程构建了各种模型（包括线性、DNN、CNN 和 RNN 模型），并将它们用于以下两种情况：\n",
        "\n",
        "- *单输出*和*多输出*预测。\n",
        "- *单时间步骤*和*多时间步骤*预测。\n",
        "\n",
        "本部分重点介绍实现数据窗口化，以便将其重用到上述所有模型。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAhGUVx1jtOy"
      },
      "source": [
        "根据任务和模型类型，您可能需要生成各种数据窗口。下面是一些示例：\n",
        "\n",
        "1. 例如，要在给定 24 小时历史记录的情况下对未来 24 小时作出一次预测，可以定义如下窗口：\n",
        "\n",
        "![对未来 24 小时的一次预测。](images/raw_window_24h.png)\n",
        "\n",
        "1. 给定 6 小时的历史记录，对未来 1 小时作出一次预测的模型将需要类似下面的窗口：\n",
        "\n",
        "![对未来 1 小时的一次预测。](images/raw_window_1h.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sa2BbfNZt8wy"
      },
      "source": [
        "本部分的剩余内容会定义 `WindowGenerator` 类。此类可以：\n",
        "\n",
        "1. 处理如上图所示的索引和偏移量。\n",
        "2. 将特征窗口拆分为 `(features, labels)` 对。\n",
        "3. 绘制结果窗口的内容。\n",
        "4. 使用 `tf.data.Dataset` 从训练、评估和测试数据高效生成这些窗口的批次。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfx3jGjyziUF"
      },
      "source": [
        "### 1. 索引和偏移量\n",
        "\n",
        "首先创建 `WindowGenerator` 类。`__init__` 方法包含输入和标签索引的所有必要逻辑。\n",
        "\n",
        "它还将训练、评估和测试 DataFrame 作为输出。这些稍后将被转换为窗口的 `tf.data.Dataset`。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kem30j8QHxyW"
      },
      "outputs": [],
      "source": [
        "class WindowGenerator():\n",
        "  def __init__(self, input_width, label_width, shift,\n",
        "               train_df=train_df, val_df=val_df, test_df=test_df,\n",
        "               label_columns=None):\n",
        "    # Store the raw data.\n",
        "    self.train_df = train_df\n",
        "    self.val_df = val_df\n",
        "    self.test_df = test_df\n",
        "\n",
        "    # Work out the label column indices.\n",
        "    self.label_columns = label_columns\n",
        "    if label_columns is not None:\n",
        "      self.label_columns_indices = {name: i for i, name in\n",
        "                                    enumerate(label_columns)}\n",
        "    self.column_indices = {name: i for i, name in\n",
        "                           enumerate(train_df.columns)}\n",
        "\n",
        "    # Work out the window parameters.\n",
        "    self.input_width = input_width\n",
        "    self.label_width = label_width\n",
        "    self.shift = shift\n",
        "\n",
        "    self.total_window_size = input_width + shift\n",
        "\n",
        "    self.input_slice = slice(0, input_width)\n",
        "    self.input_indices = np.arange(self.total_window_size)[self.input_slice]\n",
        "\n",
        "    self.label_start = self.total_window_size - self.label_width\n",
        "    self.labels_slice = slice(self.label_start, None)\n",
        "    self.label_indices = np.arange(self.total_window_size)[self.labels_slice]\n",
        "\n",
        "  def __repr__(self):\n",
        "    return '\\n'.join([\n",
        "        f'Total window size: {self.total_window_size}',\n",
        "        f'Input indices: {self.input_indices}',\n",
        "        f'Label indices: {self.label_indices}',\n",
        "        f'Label column name(s): {self.label_columns}'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVJgblsYzL1g"
      },
      "source": [
        "下面是创建本部分开头图表中所示的两个窗口的代码："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IsM5kRkz0UwK"
      },
      "outputs": [],
      "source": [
        "w1 = WindowGenerator(input_width=24, label_width=1, shift=24,\n",
        "                     label_columns=['T (degC)'])\n",
        "w1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "viwKsYeAKFUn"
      },
      "outputs": [],
      "source": [
        "w2 = WindowGenerator(input_width=6, label_width=1, shift=1,\n",
        "                     label_columns=['T (degC)'])\n",
        "w2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJaUyTWQJd-L"
      },
      "source": [
        "### 2. 拆分\n",
        "\n",
        "给定一个连续输入的列表，`split_window` 方法会将它们转换为输入窗口和标签窗口。\n",
        "\n",
        "您之前定义的示例 `w2` 将按以下方式拆分：\n",
        "\n",
        "![初始窗口都是连续的样本，这会将其拆分成一个（输入，标签）对](images/split_window.png)\n",
        "\n",
        "此图不显示数据的 `features` 轴，但此 `split_window` 函数还会处理 `label_columns`，因此可以将其用于单输出和多输出样本。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W4KbxfzqkXPW"
      },
      "outputs": [],
      "source": [
        "def split_window(self, features):\n",
        "  inputs = features[:, self.input_slice, :]\n",
        "  labels = features[:, self.labels_slice, :]\n",
        "  if self.label_columns is not None:\n",
        "    labels = tf.stack(\n",
        "        [labels[:, :, self.column_indices[name]] for name in self.label_columns],\n",
        "        axis=-1)\n",
        "\n",
        "  # Slicing doesn't preserve static shape information, so set the shapes\n",
        "  # manually. This way the `tf.data.Datasets` are easier to inspect.\n",
        "  inputs.set_shape([None, self.input_width, None])\n",
        "  labels.set_shape([None, self.label_width, None])\n",
        "\n",
        "  return inputs, labels\n",
        "\n",
        "WindowGenerator.split_window = split_window"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6U6VtVuM15s"
      },
      "source": [
        "试试以下代码："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YeCWbq6KLmL7"
      },
      "outputs": [],
      "source": [
        "# Stack three slices, the length of the total window.\n",
        "example_window = tf.stack([np.array(train_df[:w2.total_window_size]),\n",
        "                           np.array(train_df[100:100+w2.total_window_size]),\n",
        "                           np.array(train_df[200:200+w2.total_window_size])])\n",
        "\n",
        "example_inputs, example_labels = w2.split_window(example_window)\n",
        "\n",
        "print('All shapes are: (batch, time, features)')\n",
        "print(f'Window shape: {example_window.shape}')\n",
        "print(f'Inputs shape: {example_inputs.shape}')\n",
        "print(f'Labels shape: {example_labels.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtMk1ffk2Mmd"
      },
      "source": [
        "通常，TensorFlow 中的数据会被打包到数组中，其中最外层索引是交叉样本（“批次”维度）。中间索引是“时间”和“空间”（宽度、高度）维度。最内层索引是特征。\n",
        "\n",
        "上面的代码使用了三个 7 时间步骤窗口的批次，每个时间步骤有 19 个特征。它将其拆分成一个 6 时间步骤的批次、19 个特征输入和一个 1 时间步骤 1 特征的标签。该标签仅有一个特征，因为 `WindowGenerator` 已使用 `label_columns=['T (degC)']` 进行了初始化。最初，本教程将构建预测单个输出标签的模型。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFZukGXrJoGo"
      },
      "source": [
        "### 3. 绘图\n",
        "\n",
        "下面是一个绘图方法，可以对拆分窗口进行简单可视化："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fmgd1qkYUWT7"
      },
      "outputs": [],
      "source": [
        "w2.example = example_inputs, example_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jIrYccI-Hm3B"
      },
      "outputs": [],
      "source": [
        "def plot(self, model=None, plot_col='T (degC)', max_subplots=3):\n",
        "  inputs, labels = self.example\n",
        "  plt.figure(figsize=(12, 8))\n",
        "  plot_col_index = self.column_indices[plot_col]\n",
        "  max_n = min(max_subplots, len(inputs))\n",
        "  for n in range(max_n):\n",
        "    plt.subplot(max_n, 1, n+1)\n",
        "    plt.ylabel(f'{plot_col} [normed]')\n",
        "    plt.plot(self.input_indices, inputs[n, :, plot_col_index],\n",
        "             label='Inputs', marker='.', zorder=-10)\n",
        "\n",
        "    if self.label_columns:\n",
        "      label_col_index = self.label_columns_indices.get(plot_col, None)\n",
        "    else:\n",
        "      label_col_index = plot_col_index\n",
        "\n",
        "    if label_col_index is None:\n",
        "      continue\n",
        "\n",
        "    plt.scatter(self.label_indices, labels[n, :, label_col_index],\n",
        "                edgecolors='k', label='Labels', c='#2ca02c', s=64)\n",
        "    if model is not None:\n",
        "      predictions = model(inputs)\n",
        "      plt.scatter(self.label_indices, predictions[n, :, label_col_index],\n",
        "                  marker='X', edgecolors='k', label='Predictions',\n",
        "                  c='#ff7f0e', s=64)\n",
        "\n",
        "    if n == 0:\n",
        "      plt.legend()\n",
        "\n",
        "  plt.xlabel('Time [h]')\n",
        "\n",
        "WindowGenerator.plot = plot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXvctEuK68vX"
      },
      "source": [
        "此绘图根据项目引用的时间来对齐输入、标签和（稍后的）预测："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XjTqUnglOOni"
      },
      "outputs": [],
      "source": [
        "w2.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqiqcPOldPG6"
      },
      "source": [
        "您可以绘制其他列，但是样本窗口 `w2` 配置仅包含 `T (degC)` 列的标签。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EBRe4wnlfCH8"
      },
      "outputs": [],
      "source": [
        "w2.plot(plot_col='p (mbar)')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCvD-UaUzYMw"
      },
      "source": [
        "### 4. 创建 `tf.data.Dataset`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLO3SFR9Osdf"
      },
      "source": [
        "最后，此 `make_dataset` 方法将获取时间序列 DataFrame 并使用 `tf.keras.utils.timeseries_dataset_from_array` 函数将其转换为 `(input_window, label_window)` 对的 `tf.data.Dataset`。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "35qoSQeRVfJg"
      },
      "outputs": [],
      "source": [
        "def make_dataset(self, data):\n",
        "  data = np.array(data, dtype=np.float32)\n",
        "  ds = tf.keras.utils.timeseries_dataset_from_array(\n",
        "      data=data,\n",
        "      targets=None,\n",
        "      sequence_length=self.total_window_size,\n",
        "      sequence_stride=1,\n",
        "      shuffle=True,\n",
        "      batch_size=32,)\n",
        "\n",
        "  ds = ds.map(self.split_window)\n",
        "\n",
        "  return ds\n",
        "\n",
        "WindowGenerator.make_dataset = make_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvsxQwJaCift"
      },
      "source": [
        "`WindowGenerator` 对象包含训练、验证和测试数据。\n",
        "\n",
        "使用您之前定义的 `make_dataset` 方法添加属性以作为 `tf.data.Dataset` 访问它们。此外，添加一个标准样本批次以便于访问和绘图："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2jZ2KkqGCfzu"
      },
      "outputs": [],
      "source": [
        "@property\n",
        "def train(self):\n",
        "  return self.make_dataset(self.train_df)\n",
        "\n",
        "@property\n",
        "def val(self):\n",
        "  return self.make_dataset(self.val_df)\n",
        "\n",
        "@property\n",
        "def test(self):\n",
        "  return self.make_dataset(self.test_df)\n",
        "\n",
        "@property\n",
        "def example(self):\n",
        "  \"\"\"Get and cache an example batch of `inputs, labels` for plotting.\"\"\"\n",
        "  result = getattr(self, '_example', None)\n",
        "  if result is None:\n",
        "    # No example batch was found, so get one from the `.train` dataset\n",
        "    result = next(iter(self.train))\n",
        "    # And cache it for next time\n",
        "    self._example = result\n",
        "  return result\n",
        "\n",
        "WindowGenerator.train = train\n",
        "WindowGenerator.val = val\n",
        "WindowGenerator.test = test\n",
        "WindowGenerator.example = example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fF_Vj6Iw3Y2w"
      },
      "source": [
        "现在，`WindowGenerator` 对象允许您访问 `tf.data.Dataset` 对象，因此您可以轻松迭代数据。\n",
        "\n",
        "`Dataset.element_spec` 属性会告诉您数据集元素的结构、数据类型和形状。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "daJ0-U383YVs"
      },
      "outputs": [],
      "source": [
        "# Each element is an (inputs, label) pair.\n",
        "w2.train.element_spec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKTx3_Z7ua-n"
      },
      "source": [
        "在 `Dataset` 上进行迭代会产生具体批次："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6gtKXEgf4Iml"
      },
      "outputs": [],
      "source": [
        "for example_inputs, example_labels in w2.train.take(1):\n",
        "  print(f'Inputs shape (batch, time, features): {example_inputs.shape}')\n",
        "  print(f'Labels shape (batch, time, features): {example_labels.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LyuGuJUgjUK3"
      },
      "source": [
        "## 单步模型\n",
        "\n",
        "基于此类数据能够构建的最简单模型，能够仅根据当前条件预测单个特征的值，即未来的一个时间步骤（1 小时）。\n",
        "\n",
        "因此，从构建模型开始，预测未来 1 小时的 `T (degC)` 值。\n",
        "\n",
        "![预测下一个时间步骤](images/narrow_window.png)\n",
        "\n",
        "配置 `WindowGenerator` 对象以生成下列单步 `(input, label)` 对："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G5QX1G1JTPCr"
      },
      "outputs": [],
      "source": [
        "single_step_window = WindowGenerator(\n",
        "    input_width=1, label_width=1, shift=1,\n",
        "    label_columns=['T (degC)'])\n",
        "single_step_window"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKTm8ajVGw4N"
      },
      "source": [
        "`window` 会根据训练、验证和测试集创建 `tf.data.Datasets`，使您可以轻松迭代数据批次。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Do4ILUaBF8oc"
      },
      "outputs": [],
      "source": [
        "for example_inputs, example_labels in single_step_window.train.take(1):\n",
        "  print(f'Inputs shape (batch, time, features): {example_inputs.shape}')\n",
        "  print(f'Labels shape (batch, time, features): {example_labels.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1bbPiR3VAm_"
      },
      "source": [
        "### 基线\n",
        "\n",
        "在构建可训练模型之前，最好将性能基线作为与以后更复杂的模型进行比较的点。\n",
        "\n",
        "第一个任务是在给定所有特征的当前值的情况下，预测未来 1 小时的温度。当前值包括当前温度。\n",
        "\n",
        "因此，从仅返回当前温度作为预测值的模型开始，预测“无变化”。这是一个合理的基线，因为温度变化缓慢。当然，如果您对更远的未来进行预测，此基线的效果就不那么好了。\n",
        "\n",
        "![将输入发送到输出](https://github.com/tensorflow/docs-l10n/blob/master/site/en-snapshot/tutorials/structured_data/images/baseline.png?raw=true)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9TybQaIsi3yg"
      },
      "outputs": [],
      "source": [
        "class Baseline(tf.keras.Model):\n",
        "  def __init__(self, label_index=None):\n",
        "    super().__init__()\n",
        "    self.label_index = label_index\n",
        "\n",
        "  def call(self, inputs):\n",
        "    if self.label_index is None:\n",
        "      return inputs\n",
        "    result = inputs[:, :, self.label_index]\n",
        "    return result[:, :, tf.newaxis]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vb3f948i8p8"
      },
      "source": [
        "实例化并评估此模型："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IS3-QKc4sX0D"
      },
      "outputs": [],
      "source": [
        "baseline = Baseline(label_index=column_indices['T (degC)'])\n",
        "\n",
        "baseline.compile(loss=tf.keras.losses.MeanSquaredError(),\n",
        "                 metrics=[tf.keras.metrics.MeanAbsoluteError()])\n",
        "\n",
        "val_performance = {}\n",
        "performance = {}\n",
        "val_performance['Baseline'] = baseline.evaluate(single_step_window.val)\n",
        "performance['Baseline'] = baseline.evaluate(single_step_window.test, verbose=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhBxQcCSs7Ec"
      },
      "source": [
        "上面的代码打印了一些性能指标，但这些指标并没有使您对模型的运行情况有所了解。\n",
        "\n",
        "`WindowGenerator` 有一种绘制方法，但只有一个样本，绘图不是很有趣。\n",
        "\n",
        "因此，创建一个更宽的 `WindowGenerator` 来一次生成包含 24 小时连续输入和标签的窗口。新的 `wide_window` 变量不会更改模型的运算方式。模型仍会根据单个输入时间步骤对未来 1 小时进行预测。这里 `time` 轴的作用类似于 `batch` 轴：每个预测都是独立进行的，时间步骤之间没有交互："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C8jNR5uuJ5Zp"
      },
      "outputs": [],
      "source": [
        "wide_window = WindowGenerator(\n",
        "    input_width=24, label_width=24, shift=1,\n",
        "    label_columns=['T (degC)'])\n",
        "\n",
        "wide_window"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAnj7CFZkuYv"
      },
      "source": [
        "此扩展窗口可以直接传递到相同的 `baseline` 模型，而无需修改任何代码。能做到这一点是因为输入和标签具有相同数量的时间步骤，并且基线只是将输入转发至输出：\n",
        "\n",
        "![对未来 1 小时进行一次预测，每小时一次。](images/last_window.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sGKdvdg087qs"
      },
      "outputs": [],
      "source": [
        "print('Input shape:', wide_window.example[0].shape)\n",
        "print('Output shape:', baseline(wide_window.example[0]).shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKqQHX1K0JW-"
      },
      "source": [
        "通过绘制基线模型的预测值，可以注意到只是标签向右移动了 1 小时："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jQyAPVLgWTOZ"
      },
      "outputs": [],
      "source": [
        "wide_window.plot(baseline)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e93TLUhfAVg2"
      },
      "source": [
        "在上面三个样本的绘图中，单步模型运行了 24 个小时。这需要一些解释：\n",
        "\n",
        "- 蓝色的 `Inputs` 行显示每个时间步骤的输入温度。模型会接收所有特征，而该绘图仅显示温度。\n",
        "- 绿色的 `Labels` 点显示目标预测值。这些点在预测时间，而不是输入时间显示。这就是为什么标签范围相对于输入移动了 1 步。\n",
        "- 橙色的 `Predictions` 叉是模型针对每个输出时间步骤的预测。如果模型能够进行完美预测，则预测值将直接落在 `Labels` 上。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4aOJScj52Yu"
      },
      "source": [
        "### 线性模型\n",
        "\n",
        "可以应用于此任务的最简单的**可训练**模型是在输入和输出之间插入线性转换。在这种情况下，时间步骤的输出仅取决于该步骤：\n",
        "\n",
        "![单步预测](images/narrow_window.png)\n",
        "\n",
        "没有设置 `activation` 的 `tf.keras.layers.Dense` 层是线性模型。层仅会将数据的最后一个轴从 `(batch, time, inputs)` 转换为 `(batch, time, units)`；它会单独应用于 `batch` 和 `time` 轴的每个条目。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6341OXuQ5xA9"
      },
      "outputs": [],
      "source": [
        "linear = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(units=1)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KwaOM8RucUSn"
      },
      "outputs": [],
      "source": [
        "print('Input shape:', single_step_window.example[0].shape)\n",
        "print('Output shape:', linear(single_step_window.example[0]).shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMZTYIj3bYLg"
      },
      "source": [
        "本教程训练许多模型，因此将训练过程打包到一个函数中："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CbCL6VIrk-Gt"
      },
      "outputs": [],
      "source": [
        "MAX_EPOCHS = 20\n",
        "\n",
        "def compile_and_fit(model, window, patience=2):\n",
        "  early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
        "                                                    patience=patience,\n",
        "                                                    mode='min')\n",
        "\n",
        "  model.compile(loss=tf.keras.losses.MeanSquaredError(),\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[tf.keras.metrics.MeanAbsoluteError()])\n",
        "\n",
        "  history = model.fit(window.train, epochs=MAX_EPOCHS,\n",
        "                      validation_data=window.val,\n",
        "                      callbacks=[early_stopping])\n",
        "  return history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OobVjM-schwj"
      },
      "source": [
        "训练模型并评估其性能："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9agbz2qB9bLS"
      },
      "outputs": [],
      "source": [
        "history = compile_and_fit(linear, single_step_window)\n",
        "\n",
        "val_performance['Linear'] = linear.evaluate(single_step_window.val)\n",
        "performance['Linear'] = linear.evaluate(single_step_window.test, verbose=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7U9XukYh8beN"
      },
      "source": [
        "与 `baseline` 模型类似，可以在宽度窗口的批次上调用线性模型。使用这种方式，模型会在连续的时间步骤上进行一系列独立预测。`time` 轴的作用类似于另一个 `batch` 轴。在每个时间步骤上，预测之间没有交互。\n",
        "\n",
        "![单步预测](images/wide_window.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K9UVM5Sw9KQN"
      },
      "outputs": [],
      "source": [
        "print('Input shape:', wide_window.example[0].shape)\n",
        "print('Output shape:', baseline(wide_window.example[0]).shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-CGj85oKaOG"
      },
      "source": [
        "下面是 `wide_widow` 上它的样本预测绘图。请注意，在许多情况下，预测值显然比仅返回输入温度更好，但在某些情况下则会更差："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bCC8VVo-OvwV"
      },
      "outputs": [],
      "source": [
        "wide_window.plot(linear)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Is51vU8EMl6c"
      },
      "source": [
        "线性模型的优点之一是它们相对易于解释。您可以拉取层的权重，并呈现分配给每个输入的权重："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d4uCTbsmK8VI"
      },
      "outputs": [],
      "source": [
        "plt.bar(x = range(len(train_df.columns)),\n",
        "        height=linear.layers[0].kernel[:,0].numpy())\n",
        "axis = plt.gca()\n",
        "axis.set_xticks(range(len(train_df.columns)))\n",
        "_ = axis.set_xticklabels(train_df.columns, rotation=90)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ylng7215boIY"
      },
      "source": [
        "有时模型甚至不会将大多数权重放在输入 `T (degC)` 上。这是随机初始化的风险之一。 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W18e6da1cNbw"
      },
      "source": [
        "### 密集\n",
        "\n",
        "在应用实际运算多个时间步骤的模型之前，值得研究一下更深、更强大的单输入步骤模型的性能。\n",
        "\n",
        "下面是一个与 `linear` 模型类似的模型，只不过它在输入和输出之间堆叠了几个 `Dense` 层： "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z86WkYp7cNAD"
      },
      "outputs": [],
      "source": [
        "dense = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
        "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
        "    tf.keras.layers.Dense(units=1)\n",
        "])\n",
        "\n",
        "history = compile_and_fit(dense, single_step_window)\n",
        "\n",
        "val_performance['Dense'] = dense.evaluate(single_step_window.val)\n",
        "performance['Dense'] = dense.evaluate(single_step_window.test, verbose=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5dv_whJdswH"
      },
      "source": [
        "### 多步密集\n",
        "\n",
        "单时间步骤模型没有其输入的当前值的上下文。它看不到输入特征随时间变化的情况。要解决此问题，模型在进行预测时需要访问多个时间步骤：\n",
        "\n",
        "![每次预测都使用三个时间步骤。](images/conv_window.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zac-ti8agbJ7"
      },
      "source": [
        "`baseline`、`linear` 和 `dense` 模型会单独处理每个时间步骤。在这里，模型将接受多个时间步骤作为输入，以生成单个输出。\n",
        "\n",
        "创建一个 `WindowGenerator`，它将生成 3 小时输入和 1 小时标签的批次："
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtN4BwZ37niR"
      },
      "source": [
        "请注意，`Window` 的 `shift` 参数与两个窗口的末尾相关。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lBh0j5djUKY2"
      },
      "outputs": [],
      "source": [
        "CONV_WIDTH = 3\n",
        "conv_window = WindowGenerator(\n",
        "    input_width=CONV_WIDTH,\n",
        "    label_width=1,\n",
        "    shift=1,\n",
        "    label_columns=['T (degC)'])\n",
        "\n",
        "conv_window"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dCQ5gvs68Xkd"
      },
      "outputs": [],
      "source": [
        "conv_window.plot()\n",
        "plt.title(\"Given 3 hours of inputs, predict 1 hour into the future.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "We0HdMxKeqB_"
      },
      "source": [
        "您可以通过添加 `tf.keras.layers.Flatten` 作为模型的第一层，在多输入步骤窗口上训练 `dense` 模型："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oNQnUOkOnC1G"
      },
      "outputs": [],
      "source": [
        "multi_step_dense = tf.keras.Sequential([\n",
        "    # Shape: (time, features) => (time*features)\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(units=32, activation='relu'),\n",
        "    tf.keras.layers.Dense(units=32, activation='relu'),\n",
        "    tf.keras.layers.Dense(units=1),\n",
        "    # Add back the time dimension.\n",
        "    # Shape: (outputs) => (1, outputs)\n",
        "    tf.keras.layers.Reshape([1, -1]),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cayD74luo4Vq"
      },
      "outputs": [],
      "source": [
        "print('Input shape:', conv_window.example[0].shape)\n",
        "print('Output shape:', multi_step_dense(conv_window.example[0]).shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fu91yEbRo9-J"
      },
      "outputs": [],
      "source": [
        "history = compile_and_fit(multi_step_dense, conv_window)\n",
        "\n",
        "IPython.display.clear_output()\n",
        "val_performance['Multi step dense'] = multi_step_dense.evaluate(conv_window.val)\n",
        "performance['Multi step dense'] = multi_step_dense.evaluate(conv_window.test, verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tnqdXYT6pkEh"
      },
      "outputs": [],
      "source": [
        "conv_window.plot(multi_step_dense)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWfrsP8mq8lV"
      },
      "source": [
        "此方法的主要缺点是，生成的模型只能在具有此形状的输入窗口上执行。 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j-q6tz5Yq8Jk"
      },
      "outputs": [],
      "source": [
        "print('Input shape:', wide_window.example[0].shape)\n",
        "try:\n",
        "  print('Output shape:', multi_step_dense(wide_window.example[0]).shape)\n",
        "except Exception as e:\n",
        "  print(f'\\n{type(e).__name__}:{e}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvvajm3ip_8V"
      },
      "source": [
        "下一部分中的卷积模型将解决这个问题。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrpU6gwSJome"
      },
      "source": [
        "### 卷积神经网络\n",
        "\n",
        "卷积层 (`tf.keras.layers.Conv1D`) 也需要多个时间步骤作为每个预测的输入。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdLBwoaHmsWb"
      },
      "source": [
        "下面的模型与 `multi_step_dense` **相同**，使用卷积进行了重写。\n",
        "\n",
        "请注意以下变化：\n",
        "\n",
        "- `tf.keras.layers.Flatten` 和第一个 `tf.keras.layers.Dense` 替换成了 `tf.keras.layers.Conv1D`。\n",
        "- 由于卷积将时间轴保留在其输出中，不再需要 `tf.keras.layers.Reshape`。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5azaMBj4ac9t"
      },
      "outputs": [],
      "source": [
        "conv_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv1D(filters=32,\n",
        "                           kernel_size=(CONV_WIDTH,),\n",
        "                           activation='relu'),\n",
        "    tf.keras.layers.Dense(units=32, activation='relu'),\n",
        "    tf.keras.layers.Dense(units=1),\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftaH6B5ECRiK"
      },
      "source": [
        "在一个样本批次上运行上述模型，以查看模型是否生成了具有预期形状的输出："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5YNgt1-e98lH"
      },
      "outputs": [],
      "source": [
        "print(\"Conv model on `conv_window`\")\n",
        "print('Input shape:', conv_window.example[0].shape)\n",
        "print('Output shape:', conv_model(conv_window.example[0]).shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5m4kC-jGCY3x"
      },
      "source": [
        "在 `conv_window` 上训练和评估上述模型，它应该提供与 `multi_step_dense` 模型类似的性能。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QDVWdm4paUW7"
      },
      "outputs": [],
      "source": [
        "history = compile_and_fit(conv_model, conv_window)\n",
        "\n",
        "IPython.display.clear_output()\n",
        "val_performance['Conv'] = conv_model.evaluate(conv_window.val)\n",
        "performance['Conv'] = conv_model.evaluate(conv_window.test, verbose=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYRipDeXs0Kr"
      },
      "source": [
        "此 `conv_model` 和 `multi_step_dense` 模型的区别在于，`conv_model` 可以在任意长度的输入上运行。卷积层应用于输入的滑动窗口：\n",
        "\n",
        "![在序列上执行卷积模型](images/wide_conv_window.png)\n",
        "\n",
        "如果在较宽的输入上运行此模型，它将生成较宽的输出："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hoqccxx9r5jF"
      },
      "outputs": [],
      "source": [
        "print(\"Wide window\")\n",
        "print('Input shape:', wide_window.example[0].shape)\n",
        "print('Labels shape:', wide_window.example[1].shape)\n",
        "print('Output shape:', conv_model(wide_window.example[0]).shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_WGxtLIHhRF"
      },
      "source": [
        "请注意，输出比输入短。要进行训练或绘图，需要标签和预测具有相同长度。因此，构建 `WindowGenerator` 以使用一些额外输入时间步骤生成宽窗口，从而使标签和预测长度匹配： "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_VPvJ_VwTc0f"
      },
      "outputs": [],
      "source": [
        "LABEL_WIDTH = 24\n",
        "INPUT_WIDTH = LABEL_WIDTH + (CONV_WIDTH - 1)\n",
        "wide_conv_window = WindowGenerator(\n",
        "    input_width=INPUT_WIDTH,\n",
        "    label_width=LABEL_WIDTH,\n",
        "    shift=1,\n",
        "    label_columns=['T (degC)'])\n",
        "\n",
        "wide_conv_window"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gtqlWYXeKXej"
      },
      "outputs": [],
      "source": [
        "print(\"Wide conv window\")\n",
        "print('Input shape:', wide_conv_window.example[0].shape)\n",
        "print('Labels shape:', wide_conv_window.example[1].shape)\n",
        "print('Output shape:', conv_model(wide_conv_window.example[0]).shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzxbbS56cSBV"
      },
      "source": [
        "现在，您可以在更宽的窗口上绘制模型的预测。请注意第一个预测之前的 3 个输入时间步骤。这里的每个预测都基于之前的 3 个时间步骤："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gR7VyL45UuEe"
      },
      "outputs": [],
      "source": [
        "wide_conv_window.plot(conv_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4crpOcoMlSe"
      },
      "source": [
        "### 循环神经网络\n",
        "\n",
        "循环神经网络 (RNN) 是一种非常适合时间序列数据的神经网络。RNN 分步处理时间序列，从时间步骤到时间步骤地维护内部状态。\n",
        "\n",
        "您可以在[使用 RNN 的文本生成](https://tensorflow.google.cn/text/tutorials/text_generation)教程和[使用 Keras 的递归神经网络 (RNN)](https://tensorflow.google.cn/guide/keras/rnn) 指南中了解详情。\n",
        "\n",
        "在本教程中，您将使用称为“长短期记忆网络”(`tf.keras.layers.LSTM`) 的 RNN 层。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfQbHSMb1ATa"
      },
      "source": [
        "对所有 Keras RNN 层（例如 `tf.keras.layers.LSTM`）都很重要的一个构造函数参数是 `return_sequences`。此设置可以通过以下两种方式配置层：\n",
        "\n",
        "1. 如果为 `False`（默认值），则层仅返回最终时间步骤的输出，使模型有时间在进行单个预测前对其内部状态进行预热：\n",
        "\n",
        "![lstm 预热并进行单一预测](https://github.com/tensorflow/docs-l10n/blob/master/site/zh-cn/tutorials/structured_data/images/lstm_1_window.png?raw=true)\n",
        "\n",
        "1. 如果为 `True`，层将为每个输入返回一个输出。这对以下情况十分有用：\n",
        "    - 堆叠 RNN 层。\n",
        "    - 同时在多个时间步骤上训练模型。\n",
        "\n",
        "![lstm在每个时间步后进行预测](images/lstm_many_window.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DXKLCJy8nWNU"
      },
      "outputs": [],
      "source": [
        "lstm_model = tf.keras.models.Sequential([\n",
        "    # Shape [batch, time, features] => [batch, time, lstm_units]\n",
        "    tf.keras.layers.LSTM(32, return_sequences=True),\n",
        "    # Shape => [batch, time, features]\n",
        "    tf.keras.layers.Dense(units=1)\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F124B00KZcLC"
      },
      "source": [
        "`return_sequences=True` 时，模型一次可以在 24 小时的数据上进行训练。\n",
        "\n",
        "注：这将对模型的性能给出悲观看法。在第一个时间步骤中，模型无法访问之前的步骤，因此无法比之前展示的简单 `linear` 和 `dense` 模型表现得更好。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eZEROCQVYV6q"
      },
      "outputs": [],
      "source": [
        "print('Input shape:', wide_window.example[0].shape)\n",
        "print('Output shape:', lstm_model(wide_window.example[0]).shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uvdWRl1e9WJl"
      },
      "outputs": [],
      "source": [
        "history = compile_and_fit(lstm_model, wide_window)\n",
        "\n",
        "IPython.display.clear_output()\n",
        "val_performance['LSTM'] = lstm_model.evaluate(wide_window.val)\n",
        "performance['LSTM'] = lstm_model.evaluate(wide_window.test, verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NwAOWCVgB26e"
      },
      "outputs": [],
      "source": [
        "wide_window.plot(lstm_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYglOCKehi8F"
      },
      "source": [
        "### 性能"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pCk0_rwhi8H"
      },
      "source": [
        "使用此数据集时，通常每个模型的性能都比之前的模型稍好一些："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JjEkt488hi8I"
      },
      "outputs": [],
      "source": [
        "x = np.arange(len(performance))\n",
        "width = 0.3\n",
        "metric_name = 'mean_absolute_error'\n",
        "metric_index = lstm_model.metrics_names.index('mean_absolute_error')\n",
        "val_mae = [v[metric_index] for v in val_performance.values()]\n",
        "test_mae = [v[metric_index] for v in performance.values()]\n",
        "\n",
        "plt.ylabel('mean_absolute_error [T (degC), normalized]')\n",
        "plt.bar(x - 0.17, val_mae, width, label='Validation')\n",
        "plt.bar(x + 0.17, test_mae, width, label='Test')\n",
        "plt.xticks(ticks=x, labels=performance.keys(),\n",
        "           rotation=45)\n",
        "_ = plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cBMCpsdphi8L"
      },
      "outputs": [],
      "source": [
        "for name, value in performance.items():\n",
        "  print(f'{name:12s}: {value[1]:0.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5rUJ_2YMWzG"
      },
      "source": [
        "### 多输出模型\n",
        "\n",
        "到目前为止，所有模型都为单个时间步骤预测了单个输出特征，`T (degC)`。\n",
        "\n",
        "只需更改输出层中的单元数并调整训练窗口，以将所有特征包括在 `labels` (`example_labels`) 中，就可以将所有上述模型转换为预测多个特征："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Gk0Z91xjOwv"
      },
      "outputs": [],
      "source": [
        "single_step_window = WindowGenerator(\n",
        "    # `WindowGenerator` returns all features as labels if you \n",
        "    # don't set the `label_columns` argument.\n",
        "    input_width=1, label_width=1, shift=1)\n",
        "\n",
        "wide_window = WindowGenerator(\n",
        "    input_width=24, label_width=24, shift=1)\n",
        "\n",
        "for example_inputs, example_labels in wide_window.train.take(1):\n",
        "  print(f'Inputs shape (batch, time, features): {example_inputs.shape}')\n",
        "  print(f'Labels shape (batch, time, features): {example_labels.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmcjHfDskX1N"
      },
      "source": [
        "请注意，上面标签的 `features` 轴现在具有与输入相同的深度，而不是 1。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9k7S5IHNhSNF"
      },
      "source": [
        "#### 基线\n",
        "\n",
        "此处可以使用相同的基线模型 (`Baseline`)，但这次重复所有特征，而不是选择特定的 `label_index`："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sqqB9W-pjr5i"
      },
      "outputs": [],
      "source": [
        "baseline = Baseline()\n",
        "baseline.compile(loss=tf.keras.losses.MeanSquaredError(),\n",
        "                 metrics=[tf.keras.metrics.MeanAbsoluteError()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ltQdgaqQjQWu"
      },
      "outputs": [],
      "source": [
        "val_performance = {}\n",
        "performance = {}\n",
        "val_performance['Baseline'] = baseline.evaluate(wide_window.val)\n",
        "performance['Baseline'] = baseline.evaluate(wide_window.test, verbose=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfbCrf5q3P6n"
      },
      "source": [
        "#### 密集"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NdpzH1dYjdIN"
      },
      "outputs": [],
      "source": [
        "dense = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
        "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
        "    tf.keras.layers.Dense(units=num_features)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6uHuU9Cd3PTo"
      },
      "outputs": [],
      "source": [
        "history = compile_and_fit(dense, single_step_window)\n",
        "\n",
        "IPython.display.clear_output()\n",
        "val_performance['Dense'] = dense.evaluate(single_step_window.val)\n",
        "performance['Dense'] = dense.evaluate(single_step_window.test, verbose=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsc9pur_mHsx"
      },
      "source": [
        "#### RNN\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4QbGLMyomXaz"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "wide_window = WindowGenerator(\n",
        "    input_width=24, label_width=24, shift=1)\n",
        "\n",
        "lstm_model = tf.keras.models.Sequential([\n",
        "    # Shape [batch, time, features] => [batch, time, lstm_units]\n",
        "    tf.keras.layers.LSTM(32, return_sequences=True),\n",
        "    # Shape => [batch, time, features]\n",
        "    tf.keras.layers.Dense(units=num_features)\n",
        "])\n",
        "\n",
        "history = compile_and_fit(lstm_model, wide_window)\n",
        "\n",
        "IPython.display.clear_output()\n",
        "val_performance['LSTM'] = lstm_model.evaluate( wide_window.val)\n",
        "performance['LSTM'] = lstm_model.evaluate( wide_window.test, verbose=0)\n",
        "\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwhY2f_Nn0_K"
      },
      "source": [
        "<a id=\"residual\"></a>\n",
        "\n",
        "#### 高级：残差连接\n",
        "\n",
        "先前的 `Baseline` 模型利用了以下事实：序列在时间步骤之间不会剧烈变化。到目前为止，本教程中训练的每个模型都进行了随机初始化，然后必须学习输出相较上一个时间步骤改变较小这一知识。\n",
        "\n",
        "尽管您可以通过仔细初始化来解决此问题，但将此问题构建到模型结构中则更加简单。\n",
        "\n",
        "在时间序列分析中构建的模型，通常会预测下一个时间步骤中的值会如何变化，而非直接预测下一个值。类似地，深度学习中的<a href=\"https://arxiv.org/abs/1512.03385\" class=\"external\">残差网络</a>（或 ResNet）指的是，每一层都会添加到模型的累计结果中的架构。\n",
        "\n",
        "这就是利用“改变应该较小”这一知识的方式。\n",
        "\n",
        "![带有残差连接的模型](images/residual.png)\n",
        "\n",
        "本质上，这将初始化模型以匹配 `Baseline`。对于此任务，它可以帮助模型更快收敛，且性能稍好。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yP58A_ORx0kM"
      },
      "source": [
        "该方法可以与本教程中讨论的任何模型结合使用。\n",
        "\n",
        "这里将它应用于 LSTM 模型，请注意 `tf.initializers.zeros` 的使用，以确保初始的预测改变很小，并且不会压制残差连接。此处的梯度没有破坏对称性的问题，因为 `zeros` 仅用于最后一层。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7YlfnDQC22TQ"
      },
      "outputs": [],
      "source": [
        "class ResidualWrapper(tf.keras.Model):\n",
        "  def __init__(self, model):\n",
        "    super().__init__()\n",
        "    self.model = model\n",
        "\n",
        "  def call(self, inputs, *args, **kwargs):\n",
        "    delta = self.model(inputs, *args, **kwargs)\n",
        "\n",
        "    # The prediction for each time step is the input\n",
        "    # from the previous time step plus the delta\n",
        "    # calculated by the model.\n",
        "    return inputs + delta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NNeH02pspc9B"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "residual_lstm = ResidualWrapper(\n",
        "    tf.keras.Sequential([\n",
        "    tf.keras.layers.LSTM(32, return_sequences=True),\n",
        "    tf.keras.layers.Dense(\n",
        "        num_features,\n",
        "        # The predicted deltas should start small.\n",
        "        # Therefore, initialize the output layer with zeros.\n",
        "        kernel_initializer=tf.initializers.zeros())\n",
        "]))\n",
        "\n",
        "history = compile_and_fit(residual_lstm, wide_window)\n",
        "\n",
        "IPython.display.clear_output()\n",
        "val_performance['Residual LSTM'] = residual_lstm.evaluate(wide_window.val)\n",
        "performance['Residual LSTM'] = residual_lstm.evaluate(wide_window.test, verbose=0)\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I42Er9Du6co1"
      },
      "source": [
        "#### 性能"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZxR38P_6pUi"
      },
      "source": [
        "以下是这些多输出模型的整体性能。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6XgTK9tnr7rc"
      },
      "outputs": [],
      "source": [
        "x = np.arange(len(performance))\n",
        "width = 0.3\n",
        "\n",
        "metric_name = 'mean_absolute_error'\n",
        "metric_index = lstm_model.metrics_names.index('mean_absolute_error')\n",
        "val_mae = [v[metric_index] for v in val_performance.values()]\n",
        "test_mae = [v[metric_index] for v in performance.values()]\n",
        "\n",
        "plt.bar(x - 0.17, val_mae, width, label='Validation')\n",
        "plt.bar(x + 0.17, test_mae, width, label='Test')\n",
        "plt.xticks(ticks=x, labels=performance.keys(),\n",
        "           rotation=45)\n",
        "plt.ylabel('MAE (average over all outputs)')\n",
        "_ = plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "URz3ajCc6kBj"
      },
      "outputs": [],
      "source": [
        "for name, value in performance.items():\n",
        "  print(f'{name:15s}: {value[1]:0.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Vt2MJhNxwPU"
      },
      "source": [
        "以上性能是所有模型输出的平均值。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYokb7Om2YbK"
      },
      "source": [
        "## 多步模型\n",
        "\n",
        "前几个部分中的单输出和多输出模型都对未来 1 小时进行**单个时间步骤预测**。\n",
        "\n",
        "本部分介绍如何扩展这些模型以进行**多时间步骤预测**。\n",
        "\n",
        "在多步预测中，模型需要学习预测一系列未来值。因此，与单步模型（仅预测单个未来点）不同，多步模型预测未来值的序列。\n",
        "\n",
        "大致有两种预测方法：\n",
        "\n",
        "1. 单次预测，一次预测整个时间序列。\n",
        "2. 自回归预测，模型仅进行单步预测并将输出作为输入进行反馈。\n",
        "\n",
        "在本部分中，所有模型都将预测**所有输出时间步骤中的所有特征**。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFsDAwVt4_rq"
      },
      "source": [
        "对于多步模型而言，训练数据仍由每小时样本组成。但是，在这里，模型将在给定过去 24 小时的情况下学习预测未来 24 小时。\n",
        "\n",
        "下面是一个 `Window` 对象，该对象从数据集生成以下切片："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1cFYtsz6XiGw"
      },
      "outputs": [],
      "source": [
        "OUT_STEPS = 24\n",
        "multi_window = WindowGenerator(input_width=24,\n",
        "                               label_width=OUT_STEPS,\n",
        "                               shift=OUT_STEPS)\n",
        "\n",
        "multi_window.plot()\n",
        "multi_window"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lg8SInh9Jzd"
      },
      "source": [
        "### 基线"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axwpoWYOApJL"
      },
      "source": [
        "此任务的一个简单基线是针对所需数量的输出时间步骤重复上一个输入时间步骤：\n",
        "\n",
        "![对每个输出步骤重复最后一次输入](images/multistep_last.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_5iaHSaJ9Rxv"
      },
      "outputs": [],
      "source": [
        "class MultiStepLastBaseline(tf.keras.Model):\n",
        "  def call(self, inputs):\n",
        "    return tf.tile(inputs[:, -1:, :], [1, OUT_STEPS, 1])\n",
        "\n",
        "last_baseline = MultiStepLastBaseline()\n",
        "last_baseline.compile(loss=tf.keras.losses.MeanSquaredError(),\n",
        "                      metrics=[tf.keras.metrics.MeanAbsoluteError()])\n",
        "\n",
        "multi_val_performance = {}\n",
        "multi_performance = {}\n",
        "\n",
        "multi_val_performance['Last'] = last_baseline.evaluate(multi_window.val)\n",
        "multi_performance['Last'] = last_baseline.evaluate(multi_window.test, verbose=0)\n",
        "multi_window.plot(last_baseline)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvHZ93ObAfMA"
      },
      "source": [
        "由于此任务是在给定过去 24 小时的情况下预测未来 24 小时，另一种简单的方式是重复前一天，假设明天是类似的：\n",
        "\n",
        "![重复前一天](images/multistep_repeat.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L8Y1uMhGwIRs"
      },
      "outputs": [],
      "source": [
        "class RepeatBaseline(tf.keras.Model):\n",
        "  def call(self, inputs):\n",
        "    return inputs\n",
        "\n",
        "repeat_baseline = RepeatBaseline()\n",
        "repeat_baseline.compile(loss=tf.keras.losses.MeanSquaredError(),\n",
        "                        metrics=[tf.keras.metrics.MeanAbsoluteError()])\n",
        "\n",
        "multi_val_performance['Repeat'] = repeat_baseline.evaluate(multi_window.val)\n",
        "multi_performance['Repeat'] = repeat_baseline.evaluate(multi_window.test, verbose=0)\n",
        "multi_window.plot(repeat_baseline)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbndS-ct9C2Q"
      },
      "source": [
        "### 单次模型\n",
        "\n",
        "解决此问题的一种高级方法是使用“单次”模型，该模型可以在单个步骤中对整个序列进行预测。\n",
        "\n",
        "这可以使用 `OUT_STEPS*features` 输出单元作为 `tf.keras.layers.Dense` 高效实现。模型只需要将输出调整为所需的 `(OUTPUT_STEPS, features)`。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCKS4m1VKrDQ"
      },
      "source": [
        "#### 线性\n",
        "\n",
        "基于最后输入时间步骤的简单线性模型优于任何基线，但能力不足。该模型需要根据线性投影的单个输入时间步骤来预测 `OUTPUT_STEPS` 个时间步骤。它只能捕获行为的低维度切片，可能主要基于一天中的时间和一年中的时间。\n",
        "\n",
        "![从上一个时间步骤预测所有时间步骤](images/multistep_dense.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kfRz_WVhIQcd"
      },
      "outputs": [],
      "source": [
        "multi_linear_model = tf.keras.Sequential([\n",
        "    # Take the last time-step.\n",
        "    # Shape [batch, time, features] => [batch, 1, features]\n",
        "    tf.keras.layers.Lambda(lambda x: x[:, -1:, :]),\n",
        "    # Shape => [batch, 1, out_steps*features]\n",
        "    tf.keras.layers.Dense(OUT_STEPS*num_features,\n",
        "                          kernel_initializer=tf.initializers.zeros()),\n",
        "    # Shape => [batch, out_steps, features]\n",
        "    tf.keras.layers.Reshape([OUT_STEPS, num_features])\n",
        "])\n",
        "\n",
        "history = compile_and_fit(multi_linear_model, multi_window)\n",
        "\n",
        "IPython.display.clear_output()\n",
        "multi_val_performance['Linear'] = multi_linear_model.evaluate(multi_window.val)\n",
        "multi_performance['Linear'] = multi_linear_model.evaluate(multi_window.test, verbose=0)\n",
        "multi_window.plot(multi_linear_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zi2TMHk2IRrh"
      },
      "source": [
        "#### 密集\n",
        "\n",
        "在输入和输出之间添加 `tf.keras.layers.Dense` 可为线性模型提供更大能力，但仍仅基于单个输入时间步骤。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jezm-BKaGj91"
      },
      "outputs": [],
      "source": [
        "multi_dense_model = tf.keras.Sequential([\n",
        "    # Take the last time step.\n",
        "    # Shape [batch, time, features] => [batch, 1, features]\n",
        "    tf.keras.layers.Lambda(lambda x: x[:, -1:, :]),\n",
        "    # Shape => [batch, 1, dense_units]\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    # Shape => [batch, out_steps*features]\n",
        "    tf.keras.layers.Dense(OUT_STEPS*num_features,\n",
        "                          kernel_initializer=tf.initializers.zeros()),\n",
        "    # Shape => [batch, out_steps, features]\n",
        "    tf.keras.layers.Reshape([OUT_STEPS, num_features])\n",
        "])\n",
        "\n",
        "history = compile_and_fit(multi_dense_model, multi_window)\n",
        "\n",
        "IPython.display.clear_output()\n",
        "multi_val_performance['Dense'] = multi_dense_model.evaluate(multi_window.val)\n",
        "multi_performance['Dense'] = multi_dense_model.evaluate(multi_window.test, verbose=0)\n",
        "multi_window.plot(multi_dense_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icsBAjCzMaMl"
      },
      "source": [
        "#### CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34lCZrWYNBwd"
      },
      "source": [
        "卷积模型基于固定宽度的历史记录进行预测，可能比密集模型的性能更好，因为它可以看到随时间变化的情况：\n",
        "\n",
        "![卷积模型查看事物如何随时间变化。](images/multistep_conv.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0xJoIP6PMWMI"
      },
      "outputs": [],
      "source": [
        "CONV_WIDTH = 3\n",
        "multi_conv_model = tf.keras.Sequential([\n",
        "    # Shape [batch, time, features] => [batch, CONV_WIDTH, features]\n",
        "    tf.keras.layers.Lambda(lambda x: x[:, -CONV_WIDTH:, :]),\n",
        "    # Shape => [batch, 1, conv_units]\n",
        "    tf.keras.layers.Conv1D(256, activation='relu', kernel_size=(CONV_WIDTH)),\n",
        "    # Shape => [batch, 1,  out_steps*features]\n",
        "    tf.keras.layers.Dense(OUT_STEPS*num_features,\n",
        "                          kernel_initializer=tf.initializers.zeros()),\n",
        "    # Shape => [batch, out_steps, features]\n",
        "    tf.keras.layers.Reshape([OUT_STEPS, num_features])\n",
        "])\n",
        "\n",
        "history = compile_and_fit(multi_conv_model, multi_window)\n",
        "\n",
        "IPython.display.clear_output()\n",
        "\n",
        "multi_val_performance['Conv'] = multi_conv_model.evaluate(multi_window.val)\n",
        "multi_performance['Conv'] = multi_conv_model.evaluate(multi_window.test, verbose=0)\n",
        "multi_window.plot(multi_conv_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "weBjeZAFJOP4"
      },
      "source": [
        "#### RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8022xOKxOO92"
      },
      "source": [
        "如果循环模型与模型所做的预测相关，则可以学习使用较长的输入历史记录。在这里，模型将积累 24 小时的内部状态，然后对接下来的 24 小时进行单次预测。\n",
        "\n",
        "在此单次格式中，LSTM 只需要在最后一个时间步骤上生成输出，因此在 `tf.keras.layers.LSTM` 中设置 `return_sequences=False`。\n",
        "\n",
        "![lstm 积累输入窗口的状态，并对未来 24 小时进行一次预测。](images/multistep_lstm.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bf1ks6RTzF64"
      },
      "outputs": [],
      "source": [
        "multi_lstm_model = tf.keras.Sequential([\n",
        "    # Shape [batch, time, features] => [batch, lstm_units].\n",
        "    # Adding more `lstm_units` just overfits more quickly.\n",
        "    tf.keras.layers.LSTM(32, return_sequences=False),\n",
        "    # Shape => [batch, out_steps*features].\n",
        "    tf.keras.layers.Dense(OUT_STEPS*num_features,\n",
        "                          kernel_initializer=tf.initializers.zeros()),\n",
        "    # Shape => [batch, out_steps, features].\n",
        "    tf.keras.layers.Reshape([OUT_STEPS, num_features])\n",
        "])\n",
        "\n",
        "history = compile_and_fit(multi_lstm_model, multi_window)\n",
        "\n",
        "IPython.display.clear_output()\n",
        "\n",
        "multi_val_performance['LSTM'] = multi_lstm_model.evaluate(multi_window.val)\n",
        "multi_performance['LSTM'] = multi_lstm_model.evaluate(multi_window.test, verbose=0)\n",
        "multi_window.plot(multi_lstm_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5n-1cDW12Vo"
      },
      "source": [
        "### 高级：自回归模型\n",
        "\n",
        "上述模型均在单个步骤中预测整个输出序列。\n",
        "\n",
        "在某些情况下，模型将此预测分解为单个时间步骤可能比较有帮助。 然后，模型的每个输出都可以在每个步骤反馈给自己，并可以根据前一个输出进行预测，就像经典的<a href=\"https://arxiv.org/abs/1308.0850\" class=\"external\">使用循环神经网络生成序列</a>中介绍的一样。\n",
        "\n",
        "此类模型的一个明显优势是可以将其设置为生成长度不同的输出。\n",
        "\n",
        "您可以采用本教程前半部分中训练的任意一个单步多输出模型，并在自回归反馈循环中运行，但是在这里，您将重点关注经过显式训练的模型。\n",
        "\n",
        "![将模型的输出反馈到其输入](images/multistep_autoregressive.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKRreBbULRXY"
      },
      "source": [
        "#### RNN\n",
        "\n",
        "本教程仅构建自回归 RNN 模型，但是该模式可以应用于设计为输出单个时间步骤的任何模型。\n",
        "\n",
        "模型将具有与之前的单步 LSTM 模型相同的基本形式：一个 `tf.keras.layers.LSTM` ，后接一个将 `LSTM` 层输出转换为模型预测的 `tf.keras.layers.Dense` 层。\n",
        "\n",
        "`tf.keras.layers.LSTM` 是封装在更高级 `tf.keras.layers.RNN` 中的 `tf.keras.layers.LSTMCell`，它为您管理状态和序列结果（有关详细信息，请参阅[使用 Keras 的循环神经网络 (RNN)](https://tensorflow.google.cn/guide/keras/rnn) 指南）。\n",
        "\n",
        "在这种情况下，模型必须手动管理每个步骤的输入，因此它直接将 `tf.keras.layers.LSTMCell` 用于较低级别的单个时间步骤接口。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s5tz3Nu0R5JG"
      },
      "outputs": [],
      "source": [
        "class FeedBack(tf.keras.Model):\n",
        "  def __init__(self, units, out_steps):\n",
        "    super().__init__()\n",
        "    self.out_steps = out_steps\n",
        "    self.units = units\n",
        "    self.lstm_cell = tf.keras.layers.LSTMCell(units)\n",
        "    # Also wrap the LSTMCell in an RNN to simplify the `warmup` method.\n",
        "    self.lstm_rnn = tf.keras.layers.RNN(self.lstm_cell, return_state=True)\n",
        "    self.dense = tf.keras.layers.Dense(num_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2OXVM9G1U7xR"
      },
      "outputs": [],
      "source": [
        "feedback_model = FeedBack(units=32, out_steps=OUT_STEPS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ph5uFSfTUNho"
      },
      "source": [
        "该模型需要的第一个方法是 `warmup`，用来根据输入初始化其内部状态。训练后，此状态将捕获输入历史记录的相关部分。这等效于先前的单步 `LSTM` 模型："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vM2K_LLdRjDZ"
      },
      "outputs": [],
      "source": [
        "def warmup(self, inputs):\n",
        "  # inputs.shape => (batch, time, features)\n",
        "  # x.shape => (batch, lstm_units)\n",
        "  x, *state = self.lstm_rnn(inputs)\n",
        "\n",
        "  # predictions.shape => (batch, features)\n",
        "  prediction = self.dense(x)\n",
        "  return prediction, state\n",
        "\n",
        "FeedBack.warmup = warmup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JkaSYaZ9eB7"
      },
      "source": [
        "此方法返回单个时间步骤预测以及 `LSTM` 的内部状态："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w9Fz6NTKXXwU"
      },
      "outputs": [],
      "source": [
        "prediction, state = feedback_model.warmup(multi_window.example[0])\n",
        "prediction.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_ZdvPjdX3y3"
      },
      "source": [
        "有了 `RNN` 的状态和初始预测，您现在可以继续迭代模型，并在每一步将预测作为输入反馈给模型。\n",
        "\n",
        "收集输出预测的最简单方式是使用 Python 列表，并在循环后使用 `tf.stack`。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yotTad3nZXQU"
      },
      "source": [
        "注：像这样堆叠 Python 列表仅适用于 Eager-Execution，使用 `Model.compile(..., run_eagerly=True)` 进行训练，或使用固定长度的输出。对于动态输出长度，您需要使用 `tf.TensorArray` 代替 Python 列表，并用 `tf.range` 代替 Python `range`。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g1GRDu3mZtr9"
      },
      "outputs": [],
      "source": [
        "def call(self, inputs, training=None):\n",
        "  # Use a TensorArray to capture dynamically unrolled outputs.\n",
        "  predictions = []\n",
        "  # Initialize the LSTM state.\n",
        "  prediction, state = self.warmup(inputs)\n",
        "\n",
        "  # Insert the first prediction.\n",
        "  predictions.append(prediction)\n",
        "\n",
        "  # Run the rest of the prediction steps.\n",
        "  for n in range(1, self.out_steps):\n",
        "    # Use the last prediction as input.\n",
        "    x = prediction\n",
        "    # Execute one lstm step.\n",
        "    x, state = self.lstm_cell(x, states=state,\n",
        "                              training=training)\n",
        "    # Convert the lstm output to a prediction.\n",
        "    prediction = self.dense(x)\n",
        "    # Add the prediction to the output.\n",
        "    predictions.append(prediction)\n",
        "\n",
        "  # predictions.shape => (time, batch, features)\n",
        "  predictions = tf.stack(predictions)\n",
        "  # predictions.shape => (batch, time, features)\n",
        "  predictions = tf.transpose(predictions, [1, 0, 2])\n",
        "  return predictions\n",
        "\n",
        "FeedBack.call = call"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ubop-YWp15XW"
      },
      "source": [
        "在示例输入上运行此模型："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xja83zEYaM2D"
      },
      "outputs": [],
      "source": [
        "print('Output shape (batch, time, features): ', feedback_model(multi_window.example[0]).shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMs0rYB8be9M"
      },
      "source": [
        "现在，训练模型："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VBRVG2hnNyrO"
      },
      "outputs": [],
      "source": [
        "history = compile_and_fit(feedback_model, multi_window)\n",
        "\n",
        "IPython.display.clear_output()\n",
        "\n",
        "multi_val_performance['AR LSTM'] = feedback_model.evaluate(multi_window.val)\n",
        "multi_performance['AR LSTM'] = feedback_model.evaluate(multi_window.test, verbose=0)\n",
        "multi_window.plot(feedback_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGjcJsAQJUkI"
      },
      "source": [
        "### 性能"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sODAwr2ndtDB"
      },
      "source": [
        "在这个问题上，作为模型复杂性的函数，返回值在明显递减。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZwWBA8S6B3L"
      },
      "outputs": [],
      "source": [
        "x = np.arange(len(multi_performance))\n",
        "width = 0.3\n",
        "\n",
        "metric_name = 'mean_absolute_error'\n",
        "metric_index = lstm_model.metrics_names.index('mean_absolute_error')\n",
        "val_mae = [v[metric_index] for v in multi_val_performance.values()]\n",
        "test_mae = [v[metric_index] for v in multi_performance.values()]\n",
        "\n",
        "plt.bar(x - 0.17, val_mae, width, label='Validation')\n",
        "plt.bar(x + 0.17, test_mae, width, label='Test')\n",
        "plt.xticks(ticks=x, labels=multi_performance.keys(),\n",
        "           rotation=45)\n",
        "plt.ylabel(f'MAE (average over all times and outputs)')\n",
        "_ = plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zq3hUsedCEmJ"
      },
      "source": [
        "本教程前半部分的多输出模型的指标显示了所有输出特征的平均性能。这些性能类似，但在输出时间步骤上也进行了平均。 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jKq3eAIvH4Db"
      },
      "outputs": [],
      "source": [
        "for name, value in multi_performance.items():\n",
        "  print(f'{name:8s}: {value[1]:0.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpBFwfnaHP23"
      },
      "source": [
        "从密集模型到卷积模型和循环模型，所获得的增益只有百分之几（如果有的话），而自回归模型的表现显然更差。因此，在**这个**问题上使用这些更复杂的方法可能并不值得，但如果不尝试就无从知晓，而且这些模型可能会对**您的**问题有所帮助。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOzaIRYBhqwg"
      },
      "source": [
        "## 后续步骤\n",
        "\n",
        "本教程是使用 TensorFlow 进行时间序列预测的简单介绍。\n",
        "\n",
        "要了解更多信息，请参阅：\n",
        "\n",
        "- <a href=\"https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/\" class=\"external\">Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow</a>（第 2 版）第 15 章。\n",
        "- [Python 深度学习](https://www.manning.com/books/deep-learning-with-python)第 6 章。\n",
        "- <a href=\"https://www.udacity.com/course/intro-to-tensorflow-for-deep-learning--ud187\" class=\"external\">Udacity 的 Intro to TensorFlow for deep learning</a> 第 8 课，包括<a href=\"https://github.com/tensorflow/examples/tree/master/courses/udacity_intro_to_tensorflow_for_deep_learning\" class=\"external\">练习笔记本</a>。\n",
        "\n",
        "还要记住，您可以在 TensorFlow 中实现任何<a href=\"https://otexts.com/fpp2/index.html\" class=\"external\">经典时间序列模型</a>，本教程仅重点介绍了 TensorFlow 的内置功能。\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "time_series.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
