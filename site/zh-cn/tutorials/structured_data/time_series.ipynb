{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Pmxv2ioyCRw"
      },
      "source": [
        "##### Copyright 2019 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "b-2ShX25yNWf"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pa49bUnKyRgF"
      },
      "source": [
        "# 时间序列预测"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11Ilg92myRcw"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "<img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\"><a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/structured_data/time_series\">在 TensorFlow.org 上查看</a>\n",
        "</td>\n",
        "  <td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/structured_data/time_series.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">在 Google Colab 中运行</a></td>\n",
        "  <td>\n",
        "<img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\"><a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/time_series.ipynb\">在 GitHub 上查看源代码</a>\n",
        "</td>\n",
        "  <td>\n",
        "<img src=\"https://www.tensorflow.org/images/download_logo_32px.png\"><a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/tutorials/structured_data/time_series.ipynb\">下载笔记本</a>\n",
        "</td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GU8C5qm_4vZb"
      },
      "source": [
        "本教程是使用 TensorFlow 进行时间序列预测的简介。它构建了几种不同样式的模型，包括卷积神经网络 (CNN) 和循环神经网络 (RNN)。\n",
        "\n",
        "本教程包括两个主要部分，每个部分包含若干小节：\n",
        "\n",
        "- 预测单个时间步骤：\n",
        "    - 单个特征。\n",
        "    - 所有特征。\n",
        "- 预测多个时间步骤：\n",
        "    - 单次：一次做出所有预测。\n",
        "    - 自回归：一次做出一个预测，并将输出馈送回模型。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVhK72Pu1cJL"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7rZnJaGTWQw0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import datetime\n",
        "\n",
        "import IPython\n",
        "import IPython.display\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "\n",
        "mpl.rcParams['figure.figsize'] = (8, 6)\n",
        "mpl.rcParams['axes.grid'] = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TokBlnUhWFw9"
      },
      "source": [
        "## 天气数据集\n",
        "\n",
        "本教程使用由<a href=\"https://www.bgc-jena.mpg.de/wetter/\" class=\"external\">马克斯·普朗克生物地球化学研究所</a>记录的<a href=\"https://www.bgc-jena.mpg.de\" class=\"external\">[天气时间序列数据集</a>。\n",
        "\n",
        "此数据集包含了 14 个不同特征，例如气温、气压和湿度。自 2003 年起，这些数据每 10 分钟就会被收集一次。为了提高效率，您将仅使用 2009 至 2016 年之间收集的数据。数据集的这一部分由 François Chollet 为他的 [Deep Learning with Python](https://www.manning.com/books/deep-learning-with-python) 一书所准备。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xyv_i85IWInT"
      },
      "outputs": [],
      "source": [
        "zip_path = tf.keras.utils.get_file(\n",
        "    origin='https://storage.googleapis.com/tensorflow/tf-keras-datasets/jena_climate_2009_2016.csv.zip',\n",
        "    fname='jena_climate_2009_2016.csv.zip',\n",
        "    extract=True)\n",
        "csv_path, _ = os.path.splitext(zip_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R81Wx8WP4c3G"
      },
      "source": [
        "This tutorial will just deal with **hourly predictions**, so start by sub-sampling the data from 10-minute intervals to one-hour intervals:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TX6uGeeeWIkG"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(csv_path)\n",
        "# Slice [start:stop:step], starting from index 5 take every 6th record.\n",
        "df = df[5::6]\n",
        "\n",
        "date_time = pd.to_datetime(df.pop('Date Time'), format='%d.%m.%Y %H:%M:%S')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdbOWXiTWM2T"
      },
      "source": [
        "让我们看一下数据。下面是前几行："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ojHE-iCCWIhz"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRzj1inMfgcO"
      },
      "source": [
        "Here is the evolution of a few features over time:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vg5XIc5tfNlG"
      },
      "outputs": [],
      "source": [
        "plot_cols = ['T (degC)', 'p (mbar)', 'rho (g/m**3)']\n",
        "plot_features = df[plot_cols]\n",
        "plot_features.index = date_time\n",
        "_ = plot_features.plot(subplots=True)\n",
        "\n",
        "plot_features = df[plot_cols][:480]\n",
        "plot_features.index = date_time[:480]\n",
        "_ = plot_features.plot(subplots=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXWLG0_WBhZS"
      },
      "source": [
        "### 检查和清理"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhmZXJew6GlS"
      },
      "source": [
        "Next, look at the statistics of the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h510pgKVrrai"
      },
      "outputs": [],
      "source": [
        "df.describe().transpose()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzOTnWOoWMGK"
      },
      "source": [
        "#### 风速"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i47LiW5DCVsP"
      },
      "source": [
        "One thing that should stand out is the `min` value of the wind velocity (`wv (m/s)`) and the maximum value (`max. wv (m/s)`) columns. This `-9999` is likely erroneous.\n",
        "\n",
        "There's a separate wind direction column, so the velocity should be greater than zero (`>=0`). Replace it with zeros:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qFOq0_80vF4d"
      },
      "outputs": [],
      "source": [
        "wv = df['wv (m/s)']\n",
        "bad_wv = wv == -9999.0\n",
        "wv[bad_wv] = 0.0\n",
        "\n",
        "max_wv = df['max. wv (m/s)']\n",
        "bad_max_wv = max_wv == -9999.0\n",
        "max_wv[bad_max_wv] = 0.0\n",
        "\n",
        "# The above inplace edits are reflected in the DataFrame.\n",
        "df['wv (m/s)'].min()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtmu2IBPgPG8"
      },
      "source": [
        "### 特征工程\n",
        "\n",
        "Before diving in to build a model, it's important to understand your data and be sure that you're passing the model appropriately formatted data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYyEaqiD6j4s"
      },
      "source": [
        "#### 风\n",
        "\n",
        "The last column of the data, `wd (deg)`—gives the wind direction in units of degrees. Angles do not make good model inputs: 360° and 0° should be close to each other and wrap around smoothly. Direction shouldn't matter if the wind is not blowing.\n",
        "\n",
        "现在，风数据的分布状况如下："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YO7JGTcWQG2z"
      },
      "outputs": [],
      "source": [
        "plt.hist2d(df['wd (deg)'], df['wv (m/s)'], bins=(50, 50), vmax=400)\n",
        "plt.colorbar()\n",
        "plt.xlabel('Wind Direction [deg]')\n",
        "plt.ylabel('Wind Velocity [m/s]')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWnf5dwMU1_g"
      },
      "source": [
        "但是，如果将风向和风速列转换为风**向量**，模型将更容易解释："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6GmSTHXw6lI1"
      },
      "outputs": [],
      "source": [
        "wv = df.pop('wv (m/s)')\n",
        "max_wv = df.pop('max. wv (m/s)')\n",
        "\n",
        "# Convert to radians.\n",
        "wd_rad = df.pop('wd (deg)')*np.pi / 180\n",
        "\n",
        "# Calculate the wind x and y components.\n",
        "df['Wx'] = wv*np.cos(wd_rad)\n",
        "df['Wy'] = wv*np.sin(wd_rad)\n",
        "\n",
        "# Calculate the max wind x and y components.\n",
        "df['max Wx'] = max_wv*np.cos(wd_rad)\n",
        "df['max Wy'] = max_wv*np.sin(wd_rad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7iI0zDoxWDyB"
      },
      "source": [
        "The distribution of wind vectors is much simpler for the model to correctly interpret:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bMgCG5o2SYKD"
      },
      "outputs": [],
      "source": [
        "plt.hist2d(df['Wx'], df['Wy'], bins=(50, 50), vmax=400)\n",
        "plt.colorbar()\n",
        "plt.xlabel('Wind X [m/s]')\n",
        "plt.ylabel('Wind Y [m/s]')\n",
        "ax = plt.gca()\n",
        "ax.axis('tight')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8im1ttOWlRB"
      },
      "source": [
        "#### 时间"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7YE21HKK40zQ"
      },
      "source": [
        "Similarly, the `Date Time` column is very useful, but not in this string form. Start by converting it to seconds:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LIFf-VjMfnh3"
      },
      "outputs": [],
      "source": [
        "timestamp_s = date_time.map(pd.Timestamp.timestamp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EC_pnM1D5Sgc"
      },
      "source": [
        "Similar to the wind direction, the time in seconds is not a useful model input. Being weather data, it has clear daily and yearly periodicity. There are many ways you could deal with periodicity.\n",
        "\n",
        "You can get usable signals by using sine and cosine transforms to clear \"Time of day\" and \"Time of year\" signals:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MBfX6CDwax73"
      },
      "outputs": [],
      "source": [
        "day = 24*60*60\n",
        "year = (365.2425)*day\n",
        "\n",
        "df['Day sin'] = np.sin(timestamp_s * (2 * np.pi / day))\n",
        "df['Day cos'] = np.cos(timestamp_s * (2 * np.pi / day))\n",
        "df['Year sin'] = np.sin(timestamp_s * (2 * np.pi / year))\n",
        "df['Year cos'] = np.cos(timestamp_s * (2 * np.pi / year))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mXBbTJZfuuTC"
      },
      "outputs": [],
      "source": [
        "plt.plot(np.array(df['Day sin'])[:25])\n",
        "plt.plot(np.array(df['Day cos'])[:25])\n",
        "plt.xlabel('Time [h]')\n",
        "plt.title('Time of day signal')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HiurzTGQgf_D"
      },
      "source": [
        "This gives the model access to the most important frequency features. In this case you knew ahead of time which frequencies were important. \n",
        "\n",
        "If you don't have that information, you can determine which frequencies are important by extracting features with <a href=\"https://en.wikipedia.org/wiki/Fast_Fourier_transform\" class=\"external\">Fast Fourier Transform</a>. To check the assumptions, here is the `tf.signal.rfft` of the temperature over time. Note the obvious peaks at frequencies near `1/year` and `1/day`:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EN4U1fcMiTYs"
      },
      "outputs": [],
      "source": [
        "fft = tf.signal.rfft(df['T (degC)'])\n",
        "f_per_dataset = np.arange(0, len(fft))\n",
        "\n",
        "n_samples_h = len(df['T (degC)'])\n",
        "hours_per_year = 24*365.2524\n",
        "years_per_dataset = n_samples_h/(hours_per_year)\n",
        "\n",
        "f_per_year = f_per_dataset/years_per_dataset\n",
        "plt.step(f_per_year, np.abs(fft))\n",
        "plt.xscale('log')\n",
        "plt.ylim(0, 400000)\n",
        "plt.xlim([0.1, max(plt.xlim())])\n",
        "plt.xticks([1, 365.2524], labels=['1/Year', '1/day'])\n",
        "_ = plt.xlabel('Frequency (log scale)')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rbL8bSGDHy3"
      },
      "source": [
        "### 拆分数据"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qoFJZmXBaxCc"
      },
      "source": [
        "You'll use a `(70%, 20%, 10%)` split for the training, validation, and test sets. Note the data is **not** being randomly shuffled before splitting. This is for two reasons:\n",
        "\n",
        "1. 确保仍然可以将数据切入连续样本的窗口。\n",
        "2. It ensures that the validation/test results are more realistic, being evaluated on the data collected after the model was trained."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ia-MPAHxbInX"
      },
      "outputs": [],
      "source": [
        "column_indices = {name: i for i, name in enumerate(df.columns)}\n",
        "\n",
        "n = len(df)\n",
        "train_df = df[0:int(n*0.7)]\n",
        "val_df = df[int(n*0.7):int(n*0.9)]\n",
        "test_df = df[int(n*0.9):]\n",
        "\n",
        "num_features = df.shape[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-eFckdUUHWmT"
      },
      "source": [
        "### 归一化数据\n",
        "\n",
        "It is important to scale features before training a neural network. Normalization is a common way of doing this scaling: subtract the mean and divide by the standard deviation of each feature."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxbIic5TMlxx"
      },
      "source": [
        "平均值和标准偏差应仅使用训练数据进行计算，从而使模型无法访问验证集和测试集中的值。\n",
        "\n",
        "It's also arguable that the model shouldn't have access to future values in the training set when training, and that this normalization should be done using moving averages. That's not the focus of this tutorial, and the validation and test sets ensure that you get (somewhat) honest metrics. So, in the interest of simplicity this tutorial uses a simple average."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eji6njXvHusN"
      },
      "outputs": [],
      "source": [
        "train_mean = train_df.mean()\n",
        "train_std = train_df.std()\n",
        "\n",
        "train_df = (train_df - train_mean) / train_std\n",
        "val_df = (val_df - train_mean) / train_std\n",
        "test_df = (test_df - train_mean) / train_std"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6ufs8kk9JQw"
      },
      "source": [
        "Now, peek at the distribution of the features. Some features do have long tails, but there are no obvious errors like the `-9999` wind velocity value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T0UYEnkwm8Fe"
      },
      "outputs": [],
      "source": [
        "df_std = (df - train_mean) / train_std\n",
        "df_std = df_std.melt(var_name='Column', value_name='Normalized')\n",
        "plt.figure(figsize=(12, 6))\n",
        "ax = sns.violinplot(x='Column', y='Normalized', data=df_std)\n",
        "_ = ax.set_xticklabels(df.keys(), rotation=90)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBBmdxZ2HgfJ"
      },
      "source": [
        "## 数据窗口化\n",
        "\n",
        "本教程中的模型将基于来自数据连续样本的窗口进行一组预测。\n",
        "\n",
        "输入窗口的主要特征包括：\n",
        "\n",
        "- The width (number of time steps) of the input and label windows.\n",
        "- 它们之间的时间偏移量。\n",
        "- 用作输入、标签或两者的特征。\n",
        "\n",
        "本教程构建了各种模型（包括线性、DNN、CNN 和 RNN 模型），并将它们用于以下两种情况：\n",
        "\n",
        "- *单输出*和*多输出*预测。\n",
        "- *单时间步骤*和*多时间步骤*预测。\n",
        "\n",
        "本部分重点介绍实现数据窗口化，以便将其重用到上述所有模型。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAhGUVx1jtOy"
      },
      "source": [
        "根据任务和模型类型，您可能需要生成各种数据窗口。下面是一些示例：\n",
        "\n",
        "1. For example, to make a single prediction 24 hours into the future, given 24 hours of history, you might define a window like this:\n",
        "\n",
        "![One prediction 24 hours into the future.](images/raw_window_24h.png)\n",
        "\n",
        "1. A model that makes a prediction one hour into the future, given six hours of history, would need a window like this:\n",
        "\n",
        "![One prediction one hour into the future.](images/raw_window_1h.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sa2BbfNZt8wy"
      },
      "source": [
        "本部分的剩余内容会定义 `WindowGenerator` 类。此类可以：\n",
        "\n",
        "1. 处理如上图所示的索引和偏移量。\n",
        "2. Split windows of features into `(features, labels)` pairs.\n",
        "3. 绘制结果窗口的内容。\n",
        "4. 使用 `tf.data.Dataset` 从训练、评估和测试数据高效生成这些窗口的批次。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfx3jGjyziUF"
      },
      "source": [
        "### 1. 索引和偏移量\n",
        "\n",
        "首先创建 `WindowGenerator` 类。`__init__` 方法包含输入和标签索引的所有必要逻辑。\n",
        "\n",
        "It also takes the training, evaluation, and test DataFrames as input. These will be converted to `tf.data.Dataset`s of windows later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kem30j8QHxyW"
      },
      "outputs": [],
      "source": [
        "class WindowGenerator():\n",
        "  def __init__(self, input_width, label_width, shift,\n",
        "               train_df=train_df, val_df=val_df, test_df=test_df,\n",
        "               label_columns=None):\n",
        "    # Store the raw data.\n",
        "    self.train_df = train_df\n",
        "    self.val_df = val_df\n",
        "    self.test_df = test_df\n",
        "\n",
        "    # Work out the label column indices.\n",
        "    self.label_columns = label_columns\n",
        "    if label_columns is not None:\n",
        "      self.label_columns_indices = {name: i for i, name in\n",
        "                                    enumerate(label_columns)}\n",
        "    self.column_indices = {name: i for i, name in\n",
        "                           enumerate(train_df.columns)}\n",
        "\n",
        "    # Work out the window parameters.\n",
        "    self.input_width = input_width\n",
        "    self.label_width = label_width\n",
        "    self.shift = shift\n",
        "\n",
        "    self.total_window_size = input_width + shift\n",
        "\n",
        "    self.input_slice = slice(0, input_width)\n",
        "    self.input_indices = np.arange(self.total_window_size)[self.input_slice]\n",
        "\n",
        "    self.label_start = self.total_window_size - self.label_width\n",
        "    self.labels_slice = slice(self.label_start, None)\n",
        "    self.label_indices = np.arange(self.total_window_size)[self.labels_slice]\n",
        "\n",
        "  def __repr__(self):\n",
        "    return '\\n'.join([\n",
        "        f'Total window size: {self.total_window_size}',\n",
        "        f'Input indices: {self.input_indices}',\n",
        "        f'Label indices: {self.label_indices}',\n",
        "        f'Label column name(s): {self.label_columns}'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVJgblsYzL1g"
      },
      "source": [
        "下面是创建本部分开头图表中所示的两个窗口的代码："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IsM5kRkz0UwK"
      },
      "outputs": [],
      "source": [
        "w1 = WindowGenerator(input_width=24, label_width=1, shift=24,\n",
        "                     label_columns=['T (degC)'])\n",
        "w1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "viwKsYeAKFUn"
      },
      "outputs": [],
      "source": [
        "w2 = WindowGenerator(input_width=6, label_width=1, shift=1,\n",
        "                     label_columns=['T (degC)'])\n",
        "w2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJaUyTWQJd-L"
      },
      "source": [
        "### 2. 拆分\n",
        "\n",
        "Given a list of consecutive inputs, the `split_window` method will convert them to a window of inputs and a window of labels.\n",
        "\n",
        "The example `w2` you define earlier will be split like this:\n",
        "\n",
        "![The initial window is all consecutive samples, this splits it into an (inputs, labels) pairs](images/split_window.png)\n",
        "\n",
        "此图不显示数据的 `features` 轴，但此 `split_window` 函数还会处理 `label_columns`，因此可以将其用于单输出和多输出样本。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W4KbxfzqkXPW"
      },
      "outputs": [],
      "source": [
        "def split_window(self, features):\n",
        "  inputs = features[:, self.input_slice, :]\n",
        "  labels = features[:, self.labels_slice, :]\n",
        "  if self.label_columns is not None:\n",
        "    labels = tf.stack(\n",
        "        [labels[:, :, self.column_indices[name]] for name in self.label_columns],\n",
        "        axis=-1)\n",
        "\n",
        "  # Slicing doesn't preserve static shape information, so set the shapes\n",
        "  # manually. This way the `tf.data.Datasets` are easier to inspect.\n",
        "  inputs.set_shape([None, self.input_width, None])\n",
        "  labels.set_shape([None, self.label_width, None])\n",
        "\n",
        "  return inputs, labels\n",
        "\n",
        "WindowGenerator.split_window = split_window"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6U6VtVuM15s"
      },
      "source": [
        "试试以下代码："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YeCWbq6KLmL7"
      },
      "outputs": [],
      "source": [
        "# Stack three slices, the length of the total window.\n",
        "example_window = tf.stack([np.array(train_df[:w2.total_window_size]),\n",
        "                           np.array(train_df[100:100+w2.total_window_size]),\n",
        "                           np.array(train_df[200:200+w2.total_window_size])])\n",
        "\n",
        "example_inputs, example_labels = w2.split_window(example_window)\n",
        "\n",
        "print('All shapes are: (batch, time, features)')\n",
        "print(f'Window shape: {example_window.shape}')\n",
        "print(f'Inputs shape: {example_inputs.shape}')\n",
        "print(f'Labels shape: {example_labels.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtMk1ffk2Mmd"
      },
      "source": [
        "Typically, data in TensorFlow is packed into arrays where the outermost index is across examples (the \"batch\" dimension). The middle indices are the \"time\" or \"space\" (width, height) dimension(s). The innermost indices are the features.\n",
        "\n",
        "The code above took a batch of three 7-time step windows with 19 features at each time step. It splits them into a batch of 6-time step 19-feature inputs, and a 1-time step 1-feature label. The label only has one feature because the `WindowGenerator` was initialized with `label_columns=['T (degC)']`. Initially, this tutorial will build models that predict single output labels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFZukGXrJoGo"
      },
      "source": [
        "### 3. 绘图\n",
        "\n",
        "下面是一个绘图方法，可以对拆分窗口进行简单可视化："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fmgd1qkYUWT7"
      },
      "outputs": [],
      "source": [
        "w2.example = example_inputs, example_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jIrYccI-Hm3B"
      },
      "outputs": [],
      "source": [
        "def plot(self, model=None, plot_col='T (degC)', max_subplots=3):\n",
        "  inputs, labels = self.example\n",
        "  plt.figure(figsize=(12, 8))\n",
        "  plot_col_index = self.column_indices[plot_col]\n",
        "  max_n = min(max_subplots, len(inputs))\n",
        "  for n in range(max_n):\n",
        "    plt.subplot(max_n, 1, n+1)\n",
        "    plt.ylabel(f'{plot_col} [normed]')\n",
        "    plt.plot(self.input_indices, inputs[n, :, plot_col_index],\n",
        "             label='Inputs', marker='.', zorder=-10)\n",
        "\n",
        "    if self.label_columns:\n",
        "      label_col_index = self.label_columns_indices.get(plot_col, None)\n",
        "    else:\n",
        "      label_col_index = plot_col_index\n",
        "\n",
        "    if label_col_index is None:\n",
        "      continue\n",
        "\n",
        "    plt.scatter(self.label_indices, labels[n, :, label_col_index],\n",
        "                edgecolors='k', label='Labels', c='#2ca02c', s=64)\n",
        "    if model is not None:\n",
        "      predictions = model(inputs)\n",
        "      plt.scatter(self.label_indices, predictions[n, :, label_col_index],\n",
        "                  marker='X', edgecolors='k', label='Predictions',\n",
        "                  c='#ff7f0e', s=64)\n",
        "\n",
        "    if n == 0:\n",
        "      plt.legend()\n",
        "\n",
        "  plt.xlabel('Time [h]')\n",
        "\n",
        "WindowGenerator.plot = plot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXvctEuK68vX"
      },
      "source": [
        "此绘图根据项目引用的时间来对齐输入、标签和（稍后的）预测："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XjTqUnglOOni"
      },
      "outputs": [],
      "source": [
        "w2.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqiqcPOldPG6"
      },
      "source": [
        "您可以绘制其他列，但是样本窗口 `w2` 配置仅包含 `T (degC)` 列的标签。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EBRe4wnlfCH8"
      },
      "outputs": [],
      "source": [
        "w2.plot(plot_col='p (mbar)')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCvD-UaUzYMw"
      },
      "source": [
        "### 4. 创建 `tf.data.Dataset`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLO3SFR9Osdf"
      },
      "source": [
        "Finally, this `make_dataset` method will take a time series DataFrame and convert it to a `tf.data.Dataset` of `(input_window, label_window)` pairs using the `tf.keras.utils.timeseries_dataset_from_array` function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "35qoSQeRVfJg"
      },
      "outputs": [],
      "source": [
        "def make_dataset(self, data):\n",
        "  data = np.array(data, dtype=np.float32)\n",
        "  ds = tf.keras.utils.timeseries_dataset_from_array(\n",
        "      data=data,\n",
        "      targets=None,\n",
        "      sequence_length=self.total_window_size,\n",
        "      sequence_stride=1,\n",
        "      shuffle=True,\n",
        "      batch_size=32,)\n",
        "\n",
        "  ds = ds.map(self.split_window)\n",
        "\n",
        "  return ds\n",
        "\n",
        "WindowGenerator.make_dataset = make_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvsxQwJaCift"
      },
      "source": [
        "The `WindowGenerator` object holds training, validation, and test data.\n",
        "\n",
        "Add properties for accessing them as `tf.data.Dataset`s using the `make_dataset` method you defined earlier. Also, add a standard example batch for easy access and plotting:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2jZ2KkqGCfzu"
      },
      "outputs": [],
      "source": [
        "@property\n",
        "def train(self):\n",
        "  return self.make_dataset(self.train_df)\n",
        "\n",
        "@property\n",
        "def val(self):\n",
        "  return self.make_dataset(self.val_df)\n",
        "\n",
        "@property\n",
        "def test(self):\n",
        "  return self.make_dataset(self.test_df)\n",
        "\n",
        "@property\n",
        "def example(self):\n",
        "  \"\"\"Get and cache an example batch of `inputs, labels` for plotting.\"\"\"\n",
        "  result = getattr(self, '_example', None)\n",
        "  if result is None:\n",
        "    # No example batch was found, so get one from the `.train` dataset\n",
        "    result = next(iter(self.train))\n",
        "    # And cache it for next time\n",
        "    self._example = result\n",
        "  return result\n",
        "\n",
        "WindowGenerator.train = train\n",
        "WindowGenerator.val = val\n",
        "WindowGenerator.test = test\n",
        "WindowGenerator.example = example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fF_Vj6Iw3Y2w"
      },
      "source": [
        "Now, the `WindowGenerator` object gives you access to the `tf.data.Dataset` objects, so you can easily iterate over the data.\n",
        "\n",
        "The `Dataset.element_spec` property tells you the structure, data types, and shapes of the dataset elements."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "daJ0-U383YVs"
      },
      "outputs": [],
      "source": [
        "# Each element is an (inputs, label) pair.\n",
        "w2.train.element_spec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKTx3_Z7ua-n"
      },
      "source": [
        "在 `Dataset` 上进行迭代会产生具体批次："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6gtKXEgf4Iml"
      },
      "outputs": [],
      "source": [
        "for example_inputs, example_labels in w2.train.take(1):\n",
        "  print(f'Inputs shape (batch, time, features): {example_inputs.shape}')\n",
        "  print(f'Labels shape (batch, time, features): {example_labels.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LyuGuJUgjUK3"
      },
      "source": [
        "## 单步模型\n",
        "\n",
        "The simplest model you can build on this sort of data is one that predicts a single feature's value—1 time step (one hour) into the future based only on the current conditions.\n",
        "\n",
        "So, start by building models to predict the `T (degC)` value one hour into the future.\n",
        "\n",
        "![Predict the next time step](images/narrow_window.png)\n",
        "\n",
        "配置 `WindowGenerator` 对象以生成下列单步 `(input, label)` 对："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G5QX1G1JTPCr"
      },
      "outputs": [],
      "source": [
        "single_step_window = WindowGenerator(\n",
        "    input_width=1, label_width=1, shift=1,\n",
        "    label_columns=['T (degC)'])\n",
        "single_step_window"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKTm8ajVGw4N"
      },
      "source": [
        "`window` 会根据训练、验证和测试集创建 `tf.data.Datasets`，使您可以轻松迭代数据批次。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Do4ILUaBF8oc"
      },
      "outputs": [],
      "source": [
        "for example_inputs, example_labels in single_step_window.train.take(1):\n",
        "  print(f'Inputs shape (batch, time, features): {example_inputs.shape}')\n",
        "  print(f'Labels shape (batch, time, features): {example_labels.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1bbPiR3VAm_"
      },
      "source": [
        "### 基线\n",
        "\n",
        "在构建可训练模型之前，最好将性能基线作为与以后更复杂的模型进行比较的点。\n",
        "\n",
        "This first task is to predict temperature one hour into the future, given the current value of all features. The current values include the current temperature.\n",
        "\n",
        "So, start with a model that just returns the current temperature as the prediction, predicting \"No change\". This is a reasonable baseline since temperature changes slowly. Of course, this baseline will work less well if you make a prediction further in the future.\n",
        "\n",
        "![Send the input to the output](images/baseline.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9TybQaIsi3yg"
      },
      "outputs": [],
      "source": [
        "class Baseline(tf.keras.Model):\n",
        "  def __init__(self, label_index=None):\n",
        "    super().__init__()\n",
        "    self.label_index = label_index\n",
        "\n",
        "  def call(self, inputs):\n",
        "    if self.label_index is None:\n",
        "      return inputs\n",
        "    result = inputs[:, :, self.label_index]\n",
        "    return result[:, :, tf.newaxis]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vb3f948i8p8"
      },
      "source": [
        "实例化并评估此模型："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IS3-QKc4sX0D"
      },
      "outputs": [],
      "source": [
        "baseline = Baseline(label_index=column_indices['T (degC)'])\n",
        "\n",
        "baseline.compile(loss=tf.keras.losses.MeanSquaredError(),\n",
        "                 metrics=[tf.keras.metrics.MeanAbsoluteError()])\n",
        "\n",
        "val_performance = {}\n",
        "performance = {}\n",
        "val_performance['Baseline'] = baseline.evaluate(single_step_window.val)\n",
        "performance['Baseline'] = baseline.evaluate(single_step_window.test, verbose=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhBxQcCSs7Ec"
      },
      "source": [
        "上面的代码打印了一些性能指标，但这些指标并没有使您对模型的运行情况有所了解。\n",
        "\n",
        "The `WindowGenerator` has a plot method, but the plots won't be very interesting with only a single sample.\n",
        "\n",
        "So, create a wider `WindowGenerator` that generates windows 24 hours of consecutive inputs and labels at a time. The new `wide_window` variable doesn't change the way the model operates. The model still makes predictions one hour into the future based on a single input time step. Here, the `time` axis acts like the `batch` axis: each prediction is made independently with no interaction between time steps:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C8jNR5uuJ5Zp"
      },
      "outputs": [],
      "source": [
        "wide_window = WindowGenerator(\n",
        "    input_width=24, label_width=24, shift=1,\n",
        "    label_columns=['T (degC)'])\n",
        "\n",
        "wide_window"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAnj7CFZkuYv"
      },
      "source": [
        "此扩展窗口可以直接传递到相同的 `baseline` 模型，而无需修改任何代码。能做到这一点是因为输入和标签具有相同数量的时间步骤，并且基线只是将输入转发至输出：\n",
        "\n",
        "![One prediction 1h into the future, ever hour.](images/last_window.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sGKdvdg087qs"
      },
      "outputs": [],
      "source": [
        "print('Input shape:', wide_window.example[0].shape)\n",
        "print('Output shape:', baseline(wide_window.example[0]).shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKqQHX1K0JW-"
      },
      "source": [
        "By plotting the baseline model's predictions, notice that it is simply the labels shifted right by one hour:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jQyAPVLgWTOZ"
      },
      "outputs": [],
      "source": [
        "wide_window.plot(baseline)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e93TLUhfAVg2"
      },
      "source": [
        "In the above plots of three examples the single step model is run over the course of 24 hours. This deserves some explanation:\n",
        "\n",
        "- The blue `Inputs` line shows the input temperature at each time step. The model receives all features, this plot only shows the temperature.\n",
        "- The green `Labels` dots show the target prediction value. These dots are shown at the prediction time, not the input time. That is why the range of labels is shifted 1 step relative to the inputs.\n",
        "- The orange `Predictions` crosses are the model's prediction's for each output time step. If the model were predicting perfectly the predictions would land directly on the `Labels`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4aOJScj52Yu"
      },
      "source": [
        "### 线性模型\n",
        "\n",
        "可以应用于此任务的最简单的**可训练**模型是在输入和输出之间插入线性转换。在这种情况下，时间步骤的输出仅取决于该步骤：\n",
        "\n",
        "![A single step prediction](images/narrow_window.png)\n",
        "\n",
        "A `tf.keras.layers.Dense` layer with no `activation` set is a linear model. The layer only transforms the last axis of the data from `(batch, time, inputs)` to `(batch, time, units)`; it is applied independently to every item across the `batch` and `time` axes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6341OXuQ5xA9"
      },
      "outputs": [],
      "source": [
        "linear = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(units=1)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KwaOM8RucUSn"
      },
      "outputs": [],
      "source": [
        "print('Input shape:', single_step_window.example[0].shape)\n",
        "print('Output shape:', linear(single_step_window.example[0]).shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMZTYIj3bYLg"
      },
      "source": [
        "本教程训练许多模型，因此将训练过程打包到一个函数中："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CbCL6VIrk-Gt"
      },
      "outputs": [],
      "source": [
        "MAX_EPOCHS = 20\n",
        "\n",
        "def compile_and_fit(model, window, patience=2):\n",
        "  early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
        "                                                    patience=patience,\n",
        "                                                    mode='min')\n",
        "\n",
        "  model.compile(loss=tf.keras.losses.MeanSquaredError(),\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[tf.keras.metrics.MeanAbsoluteError()])\n",
        "\n",
        "  history = model.fit(window.train, epochs=MAX_EPOCHS,\n",
        "                      validation_data=window.val,\n",
        "                      callbacks=[early_stopping])\n",
        "  return history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OobVjM-schwj"
      },
      "source": [
        "训练模型并评估其性能："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9agbz2qB9bLS"
      },
      "outputs": [],
      "source": [
        "history = compile_and_fit(linear, single_step_window)\n",
        "\n",
        "val_performance['Linear'] = linear.evaluate(single_step_window.val)\n",
        "performance['Linear'] = linear.evaluate(single_step_window.test, verbose=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7U9XukYh8beN"
      },
      "source": [
        "Like the `baseline` model, the linear model can be called on batches of wide windows. Used this way the model makes a set of independent predictions on consecutive time steps. The `time` axis acts like another `batch` axis. There are no interactions between the predictions at each time step.\n",
        "\n",
        "![A single step prediction](images/wide_window.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K9UVM5Sw9KQN"
      },
      "outputs": [],
      "source": [
        "print('Input shape:', wide_window.example[0].shape)\n",
        "print('Output shape:', baseline(wide_window.example[0]).shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-CGj85oKaOG"
      },
      "source": [
        "下面是 `wide_widow` 上它的样本预测绘图。请注意，在许多情况下，预测值显然比仅返回输入温度更好，但在某些情况下则会更差："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bCC8VVo-OvwV"
      },
      "outputs": [],
      "source": [
        "wide_window.plot(linear)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Is51vU8EMl6c"
      },
      "source": [
        "One advantage to linear models is that they're relatively simple to  interpret.\n",
        "You can pull out the layer's weights and visualize the weight assigned to each input:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d4uCTbsmK8VI"
      },
      "outputs": [],
      "source": [
        "plt.bar(x = range(len(train_df.columns)),\n",
        "        height=linear.layers[0].kernel[:,0].numpy())\n",
        "axis = plt.gca()\n",
        "axis.set_xticks(range(len(train_df.columns)))\n",
        "_ = axis.set_xticklabels(train_df.columns, rotation=90)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ylng7215boIY"
      },
      "source": [
        "有时模型甚至不会将大多数权重放在输入 `T (degC)` 上。这是随机初始化的风险之一。 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W18e6da1cNbw"
      },
      "source": [
        "### 密集\n",
        "\n",
        "在应用实际运算多个时间步骤的模型之前，值得研究一下更深、更强大的单输入步骤模型的性能。\n",
        "\n",
        "下面是一个与 `linear` 模型类似的模型，只不过它在输入和输出之间堆叠了几个 `Dense` 层： "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z86WkYp7cNAD"
      },
      "outputs": [],
      "source": [
        "dense = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
        "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
        "    tf.keras.layers.Dense(units=1)\n",
        "])\n",
        "\n",
        "history = compile_and_fit(dense, single_step_window)\n",
        "\n",
        "val_performance['Dense'] = dense.evaluate(single_step_window.val)\n",
        "performance['Dense'] = dense.evaluate(single_step_window.test, verbose=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5dv_whJdswH"
      },
      "source": [
        "### 多步密集\n",
        "\n",
        "单时间步骤模型没有其输入的当前值的上下文。它看不到输入特征随时间变化的情况。要解决此问题，模型在进行预测时需要访问多个时间步骤：\n",
        "\n",
        "![Three time steps are used for each prediction.](images/conv_window.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zac-ti8agbJ7"
      },
      "source": [
        "`baseline`、`linear` 和 `dense` 模型会单独处理每个时间步骤。在这里，模型将接受多个时间步骤作为输入，以生成单个输出。\n",
        "\n",
        "Create a `WindowGenerator` that will produce batches of three-hour inputs and one-hour labels:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtN4BwZ37niR"
      },
      "source": [
        "请注意，`Window` 的 `shift` 参数与两个窗口的末尾相关。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lBh0j5djUKY2"
      },
      "outputs": [],
      "source": [
        "CONV_WIDTH = 3\n",
        "conv_window = WindowGenerator(\n",
        "    input_width=CONV_WIDTH,\n",
        "    label_width=1,\n",
        "    shift=1,\n",
        "    label_columns=['T (degC)'])\n",
        "\n",
        "conv_window"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dCQ5gvs68Xkd"
      },
      "outputs": [],
      "source": [
        "conv_window.plot()\n",
        "plt.title(\"Given 3 hours of inputs, predict 1 hour into the future.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "We0HdMxKeqB_"
      },
      "source": [
        "You could train a `dense` model on a multiple-input-step window by adding a `tf.keras.layers.Flatten` as the first layer of the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oNQnUOkOnC1G"
      },
      "outputs": [],
      "source": [
        "multi_step_dense = tf.keras.Sequential([\n",
        "    # Shape: (time, features) => (time*features)\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(units=32, activation='relu'),\n",
        "    tf.keras.layers.Dense(units=32, activation='relu'),\n",
        "    tf.keras.layers.Dense(units=1),\n",
        "    # Add back the time dimension.\n",
        "    # Shape: (outputs) => (1, outputs)\n",
        "    tf.keras.layers.Reshape([1, -1]),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cayD74luo4Vq"
      },
      "outputs": [],
      "source": [
        "print('Input shape:', conv_window.example[0].shape)\n",
        "print('Output shape:', multi_step_dense(conv_window.example[0]).shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fu91yEbRo9-J"
      },
      "outputs": [],
      "source": [
        "history = compile_and_fit(multi_step_dense, conv_window)\n",
        "\n",
        "IPython.display.clear_output()\n",
        "val_performance['Multi step dense'] = multi_step_dense.evaluate(conv_window.val)\n",
        "performance['Multi step dense'] = multi_step_dense.evaluate(conv_window.test, verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tnqdXYT6pkEh"
      },
      "outputs": [],
      "source": [
        "conv_window.plot(multi_step_dense)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWfrsP8mq8lV"
      },
      "source": [
        "The main down-side of this approach is that the resulting model can only be executed on input windows of exactly this shape. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j-q6tz5Yq8Jk"
      },
      "outputs": [],
      "source": [
        "print('Input shape:', wide_window.example[0].shape)\n",
        "try:\n",
        "  print('Output shape:', multi_step_dense(wide_window.example[0]).shape)\n",
        "except Exception as e:\n",
        "  print(f'\\n{type(e).__name__}:{e}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvvajm3ip_8V"
      },
      "source": [
        "下一部分中的卷积模型将解决这个问题。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrpU6gwSJome"
      },
      "source": [
        "### 卷积神经网络\n",
        "\n",
        "A convolution layer (`tf.keras.layers.Conv1D`) also takes multiple time steps as input to each prediction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdLBwoaHmsWb"
      },
      "source": [
        "下面的模型与 `multi_step_dense` **相同**，使用卷积进行了重写。\n",
        "\n",
        "请注意以下变化：\n",
        "\n",
        "- The `tf.keras.layers.Flatten` and the first `tf.keras.layers.Dense` are replaced by a `tf.keras.layers.Conv1D`.\n",
        "- The `tf.keras.layers.Reshape` is no longer necessary since the convolution keeps the time axis in its output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5azaMBj4ac9t"
      },
      "outputs": [],
      "source": [
        "conv_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv1D(filters=32,\n",
        "                           kernel_size=(CONV_WIDTH,),\n",
        "                           activation='relu'),\n",
        "    tf.keras.layers.Dense(units=32, activation='relu'),\n",
        "    tf.keras.layers.Dense(units=1),\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftaH6B5ECRiK"
      },
      "source": [
        "Run it on an example batch to check that the model produces outputs with the expected shape:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5YNgt1-e98lH"
      },
      "outputs": [],
      "source": [
        "print(\"Conv model on `conv_window`\")\n",
        "print('Input shape:', conv_window.example[0].shape)\n",
        "print('Output shape:', conv_model(conv_window.example[0]).shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5m4kC-jGCY3x"
      },
      "source": [
        "在 `conv_window` 上训练和评估上述模型，它应该提供与 `multi_step_dense` 模型类似的性能。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QDVWdm4paUW7"
      },
      "outputs": [],
      "source": [
        "history = compile_and_fit(conv_model, conv_window)\n",
        "\n",
        "IPython.display.clear_output()\n",
        "val_performance['Conv'] = conv_model.evaluate(conv_window.val)\n",
        "performance['Conv'] = conv_model.evaluate(conv_window.test, verbose=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYRipDeXs0Kr"
      },
      "source": [
        "此 `conv_model` 和 `multi_step_dense` 模型的区别在于，`conv_model` 可以在任意长度的输入上运行。卷积层应用于输入的滑动窗口：\n",
        "\n",
        "![Executing a convolutional model on a sequence](images/wide_conv_window.png)\n",
        "\n",
        "如果在较宽的输入上运行此模型，它将生成较宽的输出："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hoqccxx9r5jF"
      },
      "outputs": [],
      "source": [
        "print(\"Wide window\")\n",
        "print('Input shape:', wide_window.example[0].shape)\n",
        "print('Labels shape:', wide_window.example[1].shape)\n",
        "print('Output shape:', conv_model(wide_window.example[0]).shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_WGxtLIHhRF"
      },
      "source": [
        "请注意，输出比输入短。要进行训练或绘图，需要标签和预测具有相同长度。因此，构建 `WindowGenerator` 以使用一些额外输入时间步骤生成宽窗口，从而使标签和预测长度匹配： "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_VPvJ_VwTc0f"
      },
      "outputs": [],
      "source": [
        "LABEL_WIDTH = 24\n",
        "INPUT_WIDTH = LABEL_WIDTH + (CONV_WIDTH - 1)\n",
        "wide_conv_window = WindowGenerator(\n",
        "    input_width=INPUT_WIDTH,\n",
        "    label_width=LABEL_WIDTH,\n",
        "    shift=1,\n",
        "    label_columns=['T (degC)'])\n",
        "\n",
        "wide_conv_window"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gtqlWYXeKXej"
      },
      "outputs": [],
      "source": [
        "print(\"Wide conv window\")\n",
        "print('Input shape:', wide_conv_window.example[0].shape)\n",
        "print('Labels shape:', wide_conv_window.example[1].shape)\n",
        "print('Output shape:', conv_model(wide_conv_window.example[0]).shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzxbbS56cSBV"
      },
      "source": [
        "Now, you can plot the model's predictions on a wider window. Note the 3 input time steps before the first prediction. Every prediction here is based on the 3 preceding time steps:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gR7VyL45UuEe"
      },
      "outputs": [],
      "source": [
        "wide_conv_window.plot(conv_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4crpOcoMlSe"
      },
      "source": [
        "### 循环神经网络\n",
        "\n",
        "循环神经网络 (RNN) 是一种非常适合时间序列数据的神经网络。RNN 分步处理时间序列，从时间步骤到时间步骤地维护内部状态。\n",
        "\n",
        "You can learn more in the [Text generation with an RNN](https://www.tensorflow.org/text/tutorials/text_generation) tutorial and the [Recurrent Neural Networks (RNN) with Keras](https://www.tensorflow.org/guide/keras/rnn) guide.\n",
        "\n",
        "In this tutorial, you will use an RNN layer called Long Short-Term Memory (`tf.keras.layers.LSTM`)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfQbHSMb1ATa"
      },
      "source": [
        "An important constructor argument for all Keras RNN layers, such as `tf.keras.layers.LSTM`, is the `return_sequences` argument. This setting can configure the layer in one of two ways:\n",
        "\n",
        "1. 如果为 `False`（默认值），则层仅返回最终时间步骤的输出，使模型有时间在进行单个预测前对其内部状态进行预热：\n",
        "\n",
        "![An LSTM warming up and making a single prediction](images/lstm_1_window.png)\n",
        "\n",
        "1. If `True`, the layer returns an output for each input. This is useful for:\n",
        "    - 堆叠 RNN 层。\n",
        "    - 同时在多个时间步骤上训练模型。\n",
        "\n",
        "![An LSTM making a prediction after every time step](images/lstm_many_window.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DXKLCJy8nWNU"
      },
      "outputs": [],
      "source": [
        "lstm_model = tf.keras.models.Sequential([\n",
        "    # Shape [batch, time, features] => [batch, time, lstm_units]\n",
        "    tf.keras.layers.LSTM(32, return_sequences=True),\n",
        "    # Shape => [batch, time, features]\n",
        "    tf.keras.layers.Dense(units=1)\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F124B00KZcLC"
      },
      "source": [
        "With `return_sequences=True`, the model can be trained on 24 hours of data at a time.\n",
        "\n",
        "Note: This will give a pessimistic view of the model's performance. On the first time step, the model has no access to previous steps and, therefore, can't do any better than the simple `linear` and `dense` models shown earlier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eZEROCQVYV6q"
      },
      "outputs": [],
      "source": [
        "print('Input shape:', wide_window.example[0].shape)\n",
        "print('Output shape:', lstm_model(wide_window.example[0]).shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uvdWRl1e9WJl"
      },
      "outputs": [],
      "source": [
        "history = compile_and_fit(lstm_model, wide_window)\n",
        "\n",
        "IPython.display.clear_output()\n",
        "val_performance['LSTM'] = lstm_model.evaluate(wide_window.val)\n",
        "performance['LSTM'] = lstm_model.evaluate(wide_window.test, verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NwAOWCVgB26e"
      },
      "outputs": [],
      "source": [
        "wide_window.plot(lstm_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYglOCKehi8F"
      },
      "source": [
        "### 性能"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pCk0_rwhi8H"
      },
      "source": [
        "With this dataset typically each of the models does slightly better than the one before it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JjEkt488hi8I"
      },
      "outputs": [],
      "source": [
        "x = np.arange(len(performance))\n",
        "width = 0.3\n",
        "metric_name = 'mean_absolute_error'\n",
        "metric_index = lstm_model.metrics_names.index('mean_absolute_error')\n",
        "val_mae = [v[metric_index] for v in val_performance.values()]\n",
        "test_mae = [v[metric_index] for v in performance.values()]\n",
        "\n",
        "plt.ylabel('mean_absolute_error [T (degC), normalized]')\n",
        "plt.bar(x - 0.17, val_mae, width, label='Validation')\n",
        "plt.bar(x + 0.17, test_mae, width, label='Test')\n",
        "plt.xticks(ticks=x, labels=performance.keys(),\n",
        "           rotation=45)\n",
        "_ = plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cBMCpsdphi8L"
      },
      "outputs": [],
      "source": [
        "for name, value in performance.items():\n",
        "  print(f'{name:12s}: {value[1]:0.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5rUJ_2YMWzG"
      },
      "source": [
        "### 多输出模型\n",
        "\n",
        "到目前为止，所有模型都为单个时间步骤预测了单个输出特征，`T (degC)`。\n",
        "\n",
        "All of these models can be converted to predict multiple features just by changing the number of units in the output layer and adjusting the training windows to include all features in the `labels` (`example_labels`):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Gk0Z91xjOwv"
      },
      "outputs": [],
      "source": [
        "single_step_window = WindowGenerator(\n",
        "    # `WindowGenerator` returns all features as labels if you \n",
        "    # don't set the `label_columns` argument.\n",
        "    input_width=1, label_width=1, shift=1)\n",
        "\n",
        "wide_window = WindowGenerator(\n",
        "    input_width=24, label_width=24, shift=1)\n",
        "\n",
        "for example_inputs, example_labels in wide_window.train.take(1):\n",
        "  print(f'Inputs shape (batch, time, features): {example_inputs.shape}')\n",
        "  print(f'Labels shape (batch, time, features): {example_labels.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmcjHfDskX1N"
      },
      "source": [
        "请注意，上面标签的 `features` 轴现在具有与输入相同的深度，而不是 1。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9k7S5IHNhSNF"
      },
      "source": [
        "#### 基线\n",
        "\n",
        "The same baseline model (`Baseline`) can be used here, but this time repeating all features instead of selecting a specific `label_index`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sqqB9W-pjr5i"
      },
      "outputs": [],
      "source": [
        "baseline = Baseline()\n",
        "baseline.compile(loss=tf.keras.losses.MeanSquaredError(),\n",
        "                 metrics=[tf.keras.metrics.MeanAbsoluteError()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ltQdgaqQjQWu"
      },
      "outputs": [],
      "source": [
        "val_performance = {}\n",
        "performance = {}\n",
        "val_performance['Baseline'] = baseline.evaluate(wide_window.val)\n",
        "performance['Baseline'] = baseline.evaluate(wide_window.test, verbose=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfbCrf5q3P6n"
      },
      "source": [
        "#### 密集"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NdpzH1dYjdIN"
      },
      "outputs": [],
      "source": [
        "dense = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
        "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
        "    tf.keras.layers.Dense(units=num_features)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6uHuU9Cd3PTo"
      },
      "outputs": [],
      "source": [
        "history = compile_and_fit(dense, single_step_window)\n",
        "\n",
        "IPython.display.clear_output()\n",
        "val_performance['Dense'] = dense.evaluate(single_step_window.val)\n",
        "performance['Dense'] = dense.evaluate(single_step_window.test, verbose=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsc9pur_mHsx"
      },
      "source": [
        "#### RNN\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4QbGLMyomXaz"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "wide_window = WindowGenerator(\n",
        "    input_width=24, label_width=24, shift=1)\n",
        "\n",
        "lstm_model = tf.keras.models.Sequential([\n",
        "    # Shape [batch, time, features] => [batch, time, lstm_units]\n",
        "    tf.keras.layers.LSTM(32, return_sequences=True),\n",
        "    # Shape => [batch, time, features]\n",
        "    tf.keras.layers.Dense(units=num_features)\n",
        "])\n",
        "\n",
        "history = compile_and_fit(lstm_model, wide_window)\n",
        "\n",
        "IPython.display.clear_output()\n",
        "val_performance['LSTM'] = lstm_model.evaluate( wide_window.val)\n",
        "performance['LSTM'] = lstm_model.evaluate( wide_window.test, verbose=0)\n",
        "\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwhY2f_Nn0_K"
      },
      "source": [
        "<a id=\"residual\"></a>\n",
        "\n",
        "#### 高级：残差连接\n",
        "\n",
        "先前的 `Baseline` 模型利用了以下事实：序列在时间步骤之间不会剧烈变化。到目前为止，本教程中训练的每个模型都进行了随机初始化，然后必须学习输出相较上一个时间步骤改变较小这一知识。\n",
        "\n",
        "尽管您可以通过仔细初始化来解决此问题，但将此问题构建到模型结构中则更加简单。\n",
        "\n",
        "It's common in time series analysis to build models that instead of predicting the next value, predict how the value will change in the next time step. Similarly, <a href=\"https://arxiv.org/abs/1512.03385\" class=\"external\">residual networks</a>—or ResNets—in deep learning refer to architectures where each layer adds to the model's accumulating result.\n",
        "\n",
        "这就是利用“改变应该较小”这一知识的方式。\n",
        "\n",
        "![A model with a residual connection](images/residual.png)\n",
        "\n",
        "Essentially, this initializes the model to match the `Baseline`. For this task it helps models converge faster, with slightly better performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yP58A_ORx0kM"
      },
      "source": [
        "该方法可以与本教程中讨论的任何模型结合使用。\n",
        "\n",
        "Here, it is being applied to the LSTM model, note the use of the `tf.initializers.zeros` to ensure that the initial predicted changes are small, and don't overpower the residual connection. There are no symmetry-breaking concerns for the gradients here, since the `zeros` are only used on the last layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7YlfnDQC22TQ"
      },
      "outputs": [],
      "source": [
        "class ResidualWrapper(tf.keras.Model):\n",
        "  def __init__(self, model):\n",
        "    super().__init__()\n",
        "    self.model = model\n",
        "\n",
        "  def call(self, inputs, *args, **kwargs):\n",
        "    delta = self.model(inputs, *args, **kwargs)\n",
        "\n",
        "    # The prediction for each time step is the input\n",
        "    # from the previous time step plus the delta\n",
        "    # calculated by the model.\n",
        "    return inputs + delta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NNeH02pspc9B"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "residual_lstm = ResidualWrapper(\n",
        "    tf.keras.Sequential([\n",
        "    tf.keras.layers.LSTM(32, return_sequences=True),\n",
        "    tf.keras.layers.Dense(\n",
        "        num_features,\n",
        "        # The predicted deltas should start small.\n",
        "        # Therefore, initialize the output layer with zeros.\n",
        "        kernel_initializer=tf.initializers.zeros())\n",
        "]))\n",
        "\n",
        "history = compile_and_fit(residual_lstm, wide_window)\n",
        "\n",
        "IPython.display.clear_output()\n",
        "val_performance['Residual LSTM'] = residual_lstm.evaluate(wide_window.val)\n",
        "performance['Residual LSTM'] = residual_lstm.evaluate(wide_window.test, verbose=0)\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I42Er9Du6co1"
      },
      "source": [
        "#### 性能"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZxR38P_6pUi"
      },
      "source": [
        "以下是这些多输出模型的整体性能。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6XgTK9tnr7rc"
      },
      "outputs": [],
      "source": [
        "x = np.arange(len(performance))\n",
        "width = 0.3\n",
        "\n",
        "metric_name = 'mean_absolute_error'\n",
        "metric_index = lstm_model.metrics_names.index('mean_absolute_error')\n",
        "val_mae = [v[metric_index] for v in val_performance.values()]\n",
        "test_mae = [v[metric_index] for v in performance.values()]\n",
        "\n",
        "plt.bar(x - 0.17, val_mae, width, label='Validation')\n",
        "plt.bar(x + 0.17, test_mae, width, label='Test')\n",
        "plt.xticks(ticks=x, labels=performance.keys(),\n",
        "           rotation=45)\n",
        "plt.ylabel('MAE (average over all outputs)')\n",
        "_ = plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "URz3ajCc6kBj"
      },
      "outputs": [],
      "source": [
        "for name, value in performance.items():\n",
        "  print(f'{name:15s}: {value[1]:0.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Vt2MJhNxwPU"
      },
      "source": [
        "以上性能是所有模型输出的平均值。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYokb7Om2YbK"
      },
      "source": [
        "## 多步模型\n",
        "\n",
        "Both the single-output and multiple-output models in the previous sections made **single time step predictions**, one hour into the future.\n",
        "\n",
        "本部分介绍如何扩展这些模型以进行**多时间步骤预测**。\n",
        "\n",
        "在多步预测中，模型需要学习预测一系列未来值。因此，与单步模型（仅预测单个未来点）不同，多步模型预测未来值的序列。\n",
        "\n",
        "大致有两种预测方法：\n",
        "\n",
        "1. 单次预测，一次预测整个时间序列。\n",
        "2. 自回归预测，模型仅进行单步预测并将输出作为输入进行反馈。\n",
        "\n",
        "在本部分中，所有模型都将预测**所有输出时间步骤中的所有特征**。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFsDAwVt4_rq"
      },
      "source": [
        "For the multi-step model, the training data again consists of hourly samples. However, here, the models will learn to predict 24 hours into the future, given 24 hours of the past.\n",
        "\n",
        "下面是一个 `Window` 对象，该对象从数据集生成以下切片："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1cFYtsz6XiGw"
      },
      "outputs": [],
      "source": [
        "OUT_STEPS = 24\n",
        "multi_window = WindowGenerator(input_width=24,\n",
        "                               label_width=OUT_STEPS,\n",
        "                               shift=OUT_STEPS)\n",
        "\n",
        "multi_window.plot()\n",
        "multi_window"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lg8SInh9Jzd"
      },
      "source": [
        "### 基线"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axwpoWYOApJL"
      },
      "source": [
        "此任务的一个简单基线是针对所需数量的输出时间步骤重复上一个输入时间步骤：\n",
        "\n",
        "![Repeat the last input, for each output step](images/multistep_last.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_5iaHSaJ9Rxv"
      },
      "outputs": [],
      "source": [
        "class MultiStepLastBaseline(tf.keras.Model):\n",
        "  def call(self, inputs):\n",
        "    return tf.tile(inputs[:, -1:, :], [1, OUT_STEPS, 1])\n",
        "\n",
        "last_baseline = MultiStepLastBaseline()\n",
        "last_baseline.compile(loss=tf.keras.losses.MeanSquaredError(),\n",
        "                      metrics=[tf.keras.metrics.MeanAbsoluteError()])\n",
        "\n",
        "multi_val_performance = {}\n",
        "multi_performance = {}\n",
        "\n",
        "multi_val_performance['Last'] = last_baseline.evaluate(multi_window.val)\n",
        "multi_performance['Last'] = last_baseline.evaluate(multi_window.test, verbose=0)\n",
        "multi_window.plot(last_baseline)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvHZ93ObAfMA"
      },
      "source": [
        "Since this task is to predict 24 hours into the future, given 24 hours of the past, another simple approach is to repeat the previous day, assuming tomorrow will be similar:\n",
        "\n",
        "![Repeat the previous day](images/multistep_repeat.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L8Y1uMhGwIRs"
      },
      "outputs": [],
      "source": [
        "class RepeatBaseline(tf.keras.Model):\n",
        "  def call(self, inputs):\n",
        "    return inputs\n",
        "\n",
        "repeat_baseline = RepeatBaseline()\n",
        "repeat_baseline.compile(loss=tf.keras.losses.MeanSquaredError(),\n",
        "                        metrics=[tf.keras.metrics.MeanAbsoluteError()])\n",
        "\n",
        "multi_val_performance['Repeat'] = repeat_baseline.evaluate(multi_window.val)\n",
        "multi_performance['Repeat'] = repeat_baseline.evaluate(multi_window.test, verbose=0)\n",
        "multi_window.plot(repeat_baseline)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbndS-ct9C2Q"
      },
      "source": [
        "### 单次模型\n",
        "\n",
        "One high-level approach to this problem is to use a \"single-shot\" model, where the model makes the entire sequence prediction in a single step.\n",
        "\n",
        "This can be implemented efficiently as a `tf.keras.layers.Dense` with `OUT_STEPS*features` output units. The model just needs to reshape that output to the required `(OUTPUT_STEPS, features)`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCKS4m1VKrDQ"
      },
      "source": [
        "#### 线性\n",
        "\n",
        "基于最后输入时间步骤的简单线性模型优于任何基线，但能力不足。该模型需要根据线性投影的单个输入时间步骤来预测 `OUTPUT_STEPS` 个时间步骤。它只能捕获行为的低维度切片，可能主要基于一天中的时间和一年中的时间。\n",
        "\n",
        "![Predict all timesteps from the last time-step](images/multistep_dense.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kfRz_WVhIQcd"
      },
      "outputs": [],
      "source": [
        "multi_linear_model = tf.keras.Sequential([\n",
        "    # Take the last time-step.\n",
        "    # Shape [batch, time, features] => [batch, 1, features]\n",
        "    tf.keras.layers.Lambda(lambda x: x[:, -1:, :]),\n",
        "    # Shape => [batch, 1, out_steps*features]\n",
        "    tf.keras.layers.Dense(OUT_STEPS*num_features,\n",
        "                          kernel_initializer=tf.initializers.zeros()),\n",
        "    # Shape => [batch, out_steps, features]\n",
        "    tf.keras.layers.Reshape([OUT_STEPS, num_features])\n",
        "])\n",
        "\n",
        "history = compile_and_fit(multi_linear_model, multi_window)\n",
        "\n",
        "IPython.display.clear_output()\n",
        "multi_val_performance['Linear'] = multi_linear_model.evaluate(multi_window.val)\n",
        "multi_performance['Linear'] = multi_linear_model.evaluate(multi_window.test, verbose=0)\n",
        "multi_window.plot(multi_linear_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zi2TMHk2IRrh"
      },
      "source": [
        "#### 密集\n",
        "\n",
        "Adding a `tf.keras.layers.Dense` between the input and output gives the linear model more power, but is still only based on a single input time step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jezm-BKaGj91"
      },
      "outputs": [],
      "source": [
        "multi_dense_model = tf.keras.Sequential([\n",
        "    # Take the last time step.\n",
        "    # Shape [batch, time, features] => [batch, 1, features]\n",
        "    tf.keras.layers.Lambda(lambda x: x[:, -1:, :]),\n",
        "    # Shape => [batch, 1, dense_units]\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    # Shape => [batch, out_steps*features]\n",
        "    tf.keras.layers.Dense(OUT_STEPS*num_features,\n",
        "                          kernel_initializer=tf.initializers.zeros()),\n",
        "    # Shape => [batch, out_steps, features]\n",
        "    tf.keras.layers.Reshape([OUT_STEPS, num_features])\n",
        "])\n",
        "\n",
        "history = compile_and_fit(multi_dense_model, multi_window)\n",
        "\n",
        "IPython.display.clear_output()\n",
        "multi_val_performance['Dense'] = multi_dense_model.evaluate(multi_window.val)\n",
        "multi_performance['Dense'] = multi_dense_model.evaluate(multi_window.test, verbose=0)\n",
        "multi_window.plot(multi_dense_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icsBAjCzMaMl"
      },
      "source": [
        "#### CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34lCZrWYNBwd"
      },
      "source": [
        "卷积模型基于固定宽度的历史记录进行预测，可能比密集模型的性能更好，因为它可以看到随时间变化的情况：\n",
        "\n",
        "![A convolutional model sees how things change over time](images/multistep_conv.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0xJoIP6PMWMI"
      },
      "outputs": [],
      "source": [
        "CONV_WIDTH = 3\n",
        "multi_conv_model = tf.keras.Sequential([\n",
        "    # Shape [batch, time, features] => [batch, CONV_WIDTH, features]\n",
        "    tf.keras.layers.Lambda(lambda x: x[:, -CONV_WIDTH:, :]),\n",
        "    # Shape => [batch, 1, conv_units]\n",
        "    tf.keras.layers.Conv1D(256, activation='relu', kernel_size=(CONV_WIDTH)),\n",
        "    # Shape => [batch, 1,  out_steps*features]\n",
        "    tf.keras.layers.Dense(OUT_STEPS*num_features,\n",
        "                          kernel_initializer=tf.initializers.zeros()),\n",
        "    # Shape => [batch, out_steps, features]\n",
        "    tf.keras.layers.Reshape([OUT_STEPS, num_features])\n",
        "])\n",
        "\n",
        "history = compile_and_fit(multi_conv_model, multi_window)\n",
        "\n",
        "IPython.display.clear_output()\n",
        "\n",
        "multi_val_performance['Conv'] = multi_conv_model.evaluate(multi_window.val)\n",
        "multi_performance['Conv'] = multi_conv_model.evaluate(multi_window.test, verbose=0)\n",
        "multi_window.plot(multi_conv_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "weBjeZAFJOP4"
      },
      "source": [
        "#### RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8022xOKxOO92"
      },
      "source": [
        "A recurrent model can learn to use a long history of inputs, if it's relevant to the predictions the model is making. Here the model will accumulate internal state for 24 hours, before making a single prediction for the next 24 hours.\n",
        "\n",
        "In this single-shot format, the LSTM only needs to produce an output at the last time step, so set `return_sequences=False` in `tf.keras.layers.LSTM`.\n",
        "\n",
        "![The LSTM accumulates state over the input window, and makes a single prediction for the next 24 hours](images/multistep_lstm.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bf1ks6RTzF64"
      },
      "outputs": [],
      "source": [
        "multi_lstm_model = tf.keras.Sequential([\n",
        "    # Shape [batch, time, features] => [batch, lstm_units].\n",
        "    # Adding more `lstm_units` just overfits more quickly.\n",
        "    tf.keras.layers.LSTM(32, return_sequences=False),\n",
        "    # Shape => [batch, out_steps*features].\n",
        "    tf.keras.layers.Dense(OUT_STEPS*num_features,\n",
        "                          kernel_initializer=tf.initializers.zeros()),\n",
        "    # Shape => [batch, out_steps, features].\n",
        "    tf.keras.layers.Reshape([OUT_STEPS, num_features])\n",
        "])\n",
        "\n",
        "history = compile_and_fit(multi_lstm_model, multi_window)\n",
        "\n",
        "IPython.display.clear_output()\n",
        "\n",
        "multi_val_performance['LSTM'] = multi_lstm_model.evaluate(multi_window.val)\n",
        "multi_performance['LSTM'] = multi_lstm_model.evaluate(multi_window.test, verbose=0)\n",
        "multi_window.plot(multi_lstm_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5n-1cDW12Vo"
      },
      "source": [
        "### 高级：自回归模型\n",
        "\n",
        "上述模型均在单个步骤中预测整个输出序列。\n",
        "\n",
        "In some cases it may be helpful for the model to decompose this prediction into individual time steps. Then, each model's output can be fed back into itself at each step and predictions can be made conditioned on the previous one, like in the classic <a href=\"https://arxiv.org/abs/1308.0850\" class=\"external\">Generating Sequences With Recurrent Neural Networks</a>.\n",
        "\n",
        "此类模型的一个明显优势是可以将其设置为生成长度不同的输出。\n",
        "\n",
        "您可以采用本教程前半部分中训练的任意一个单步多输出模型，并在自回归反馈循环中运行，但是在这里，您将重点关注经过显式训练的模型。\n",
        "\n",
        "![Feedback a model's output to its input](images/multistep_autoregressive.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKRreBbULRXY"
      },
      "source": [
        "#### RNN\n",
        "\n",
        "本教程仅构建自回归 RNN 模型，但是该模式可以应用于设计为输出单个时间步骤的任何模型。\n",
        "\n",
        "The model will have the same basic form as the single-step LSTM models from earlier: a `tf.keras.layers.LSTM` layer followed by a `tf.keras.layers.Dense` layer that converts the `LSTM` layer's outputs to model predictions.\n",
        "\n",
        "A `tf.keras.layers.LSTM` is a `tf.keras.layers.LSTMCell` wrapped in the higher level `tf.keras.layers.RNN` that manages the state and sequence results for you (Check out the [Recurrent Neural Networks (RNN) with Keras](https://www.tensorflow.org/guide/keras/rnn) guide for details).\n",
        "\n",
        "In this case, the model has to manually manage the inputs for each step, so it uses `tf.keras.layers.LSTMCell` directly for the lower level, single time step interface."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s5tz3Nu0R5JG"
      },
      "outputs": [],
      "source": [
        "class FeedBack(tf.keras.Model):\n",
        "  def __init__(self, units, out_steps):\n",
        "    super().__init__()\n",
        "    self.out_steps = out_steps\n",
        "    self.units = units\n",
        "    self.lstm_cell = tf.keras.layers.LSTMCell(units)\n",
        "    # Also wrap the LSTMCell in an RNN to simplify the `warmup` method.\n",
        "    self.lstm_rnn = tf.keras.layers.RNN(self.lstm_cell, return_state=True)\n",
        "    self.dense = tf.keras.layers.Dense(num_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2OXVM9G1U7xR"
      },
      "outputs": [],
      "source": [
        "feedback_model = FeedBack(units=32, out_steps=OUT_STEPS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ph5uFSfTUNho"
      },
      "source": [
        "The first method this model needs is a `warmup` method to initialize its internal state based on the inputs. Once trained, this state will capture the relevant parts of the input history. This is equivalent to the single-step `LSTM` model from earlier:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vM2K_LLdRjDZ"
      },
      "outputs": [],
      "source": [
        "def warmup(self, inputs):\n",
        "  # inputs.shape => (batch, time, features)\n",
        "  # x.shape => (batch, lstm_units)\n",
        "  x, *state = self.lstm_rnn(inputs)\n",
        "\n",
        "  # predictions.shape => (batch, features)\n",
        "  prediction = self.dense(x)\n",
        "  return prediction, state\n",
        "\n",
        "FeedBack.warmup = warmup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JkaSYaZ9eB7"
      },
      "source": [
        "This method returns a single time-step prediction and the internal state of the `LSTM`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w9Fz6NTKXXwU"
      },
      "outputs": [],
      "source": [
        "prediction, state = feedback_model.warmup(multi_window.example[0])\n",
        "prediction.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_ZdvPjdX3y3"
      },
      "source": [
        "有了 `RNN` 的状态和初始预测，您现在可以继续迭代模型，并在每一步将预测作为输入反馈给模型。\n",
        "\n",
        "The simplest approach for collecting the output predictions is to use a Python list and a `tf.stack` after the loop."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yotTad3nZXQU"
      },
      "source": [
        "Note: Stacking a Python list like this only works with eager-execution, using `Model.compile(..., run_eagerly=True)` for training, or with a fixed length output. For a dynamic output length, you would need to use a `tf.TensorArray` instead of a Python list, and `tf.range` instead of the Python `range`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g1GRDu3mZtr9"
      },
      "outputs": [],
      "source": [
        "def call(self, inputs, training=None):\n",
        "  # Use a TensorArray to capture dynamically unrolled outputs.\n",
        "  predictions = []\n",
        "  # Initialize the LSTM state.\n",
        "  prediction, state = self.warmup(inputs)\n",
        "\n",
        "  # Insert the first prediction.\n",
        "  predictions.append(prediction)\n",
        "\n",
        "  # Run the rest of the prediction steps.\n",
        "  for n in range(1, self.out_steps):\n",
        "    # Use the last prediction as input.\n",
        "    x = prediction\n",
        "    # Execute one lstm step.\n",
        "    x, state = self.lstm_cell(x, states=state,\n",
        "                              training=training)\n",
        "    # Convert the lstm output to a prediction.\n",
        "    prediction = self.dense(x)\n",
        "    # Add the prediction to the output.\n",
        "    predictions.append(prediction)\n",
        "\n",
        "  # predictions.shape => (time, batch, features)\n",
        "  predictions = tf.stack(predictions)\n",
        "  # predictions.shape => (batch, time, features)\n",
        "  predictions = tf.transpose(predictions, [1, 0, 2])\n",
        "  return predictions\n",
        "\n",
        "FeedBack.call = call"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ubop-YWp15XW"
      },
      "source": [
        "在示例输入上运行此模型："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xja83zEYaM2D"
      },
      "outputs": [],
      "source": [
        "print('Output shape (batch, time, features): ', feedback_model(multi_window.example[0]).shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMs0rYB8be9M"
      },
      "source": [
        "Now, train the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VBRVG2hnNyrO"
      },
      "outputs": [],
      "source": [
        "history = compile_and_fit(feedback_model, multi_window)\n",
        "\n",
        "IPython.display.clear_output()\n",
        "\n",
        "multi_val_performance['AR LSTM'] = feedback_model.evaluate(multi_window.val)\n",
        "multi_performance['AR LSTM'] = feedback_model.evaluate(multi_window.test, verbose=0)\n",
        "multi_window.plot(feedback_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGjcJsAQJUkI"
      },
      "source": [
        "### 性能"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sODAwr2ndtDB"
      },
      "source": [
        "There are clearly diminishing returns as a function of model complexity on this problem:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZwWBA8S6B3L"
      },
      "outputs": [],
      "source": [
        "x = np.arange(len(multi_performance))\n",
        "width = 0.3\n",
        "\n",
        "metric_name = 'mean_absolute_error'\n",
        "metric_index = lstm_model.metrics_names.index('mean_absolute_error')\n",
        "val_mae = [v[metric_index] for v in multi_val_performance.values()]\n",
        "test_mae = [v[metric_index] for v in multi_performance.values()]\n",
        "\n",
        "plt.bar(x - 0.17, val_mae, width, label='Validation')\n",
        "plt.bar(x + 0.17, test_mae, width, label='Test')\n",
        "plt.xticks(ticks=x, labels=multi_performance.keys(),\n",
        "           rotation=45)\n",
        "plt.ylabel(f'MAE (average over all times and outputs)')\n",
        "_ = plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zq3hUsedCEmJ"
      },
      "source": [
        "The metrics for the multi-output models in the first half of this tutorial show the performance averaged across all output features. These performances are similar but also averaged across output time steps. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jKq3eAIvH4Db"
      },
      "outputs": [],
      "source": [
        "for name, value in multi_performance.items():\n",
        "  print(f'{name:8s}: {value[1]:0.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpBFwfnaHP23"
      },
      "source": [
        "从密集模型到卷积模型和循环模型，所获得的增益只有百分之几（如果有的话），而自回归模型的表现显然更差。因此，在**这个**问题上使用这些更复杂的方法可能并不值得，但如果不尝试就无从知晓，而且这些模型可能会对**您的**问题有所帮助。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOzaIRYBhqwg"
      },
      "source": [
        "## 后续步骤\n",
        "\n",
        "本教程是使用 TensorFlow 进行时间序列预测的简单介绍。\n",
        "\n",
        "To learn more, refer to:\n",
        "\n",
        "- Chapter 15 of <a href=\"https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/\" class=\"external\">Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow</a>, 2nd Edition.\n",
        "- [Python 深度学习](https://www.manning.com/books/deep-learning-with-python)第 6 章。\n",
        "- Lesson 8 of <a href=\"https://www.udacity.com/course/intro-to-tensorflow-for-deep-learning--ud187\" class=\"external\">Udacity's intro to TensorFlow for deep learning</a>, including the <a href=\"https://github.com/tensorflow/examples/tree/master/courses/udacity_intro_to_tensorflow_for_deep_learning\" class=\"external\">exercise notebooks</a>.\n",
        "\n",
        "Also, remember that you can implement any <a href=\"https://otexts.com/fpp2/index.html\" class=\"external\">classical time series model</a> in TensorFlow—this tutorial just focuses on TensorFlow's built-in functionality.\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "time_series.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
