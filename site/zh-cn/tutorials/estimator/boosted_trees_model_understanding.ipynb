{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7765UFHoyGx6"
      },
      "source": [
        "##### Copyright 2019 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "KVtTDrUNyL7x"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0_fqL3ayLHX"
      },
      "source": [
        "# 梯度提升树（Gradient Boosted Trees）：模型理解"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PS6_yKSoyLAl"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>     <a target=\"_blank\" href=\"https://tensorflow.google.cn/tutorials/estimator/boosted_trees_model_understanding\"><img src=\"https://tensorflow.google.cn/images/tf_logo_32px.png\"> 在 TensorFlow.org 上查看</a>   </td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/zh-cn/tutorials/estimator/boosted_trees_model_understanding.ipynb\"><img src=\"https://tensorflow.google.cn/images/colab_logo_32px.png\">在 Google Colab 中运行</a>   </td>\n",
        "  <td> <img><a>在 GitHub 上查看源代码</a> </td>\n",
        "  <td> <img><a>下载笔记本</a> </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pV4mnvs7l40o"
      },
      "source": [
        "> 警告：不建议将 Estimator 用于新代码。Estimator 运行 `v1.Session` 风格的代码，此类代码更加难以正确编写，并且可能会出现意外行为，尤其是与 TF 2 代码结合使用时。Estimator 确实在我们的[兼容性保证](https://tensorflow.org/guide/versions)范围内，但除了安全漏洞之外不会得到任何修复。请参阅[迁移指南](https://tensorflow.org/guide/migrate)以了解详情。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4L1ffaFp2gT"
      },
      "source": [
        "**注**：[TensorFlow Decision Forests](https://tensorflow.org/decision_forests) 中提供了许多最先进决策森林算法基于现代 Keras 的实现。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dW3r7qVxzqN5"
      },
      "source": [
        "对于梯度提升模型（Gradient Boosting model）的端到端演示（end-to-end walkthrough），请查阅[在 Tensorflow 中训练提升树（Boosted Trees）模型](./boosted_trees)。在本教程中，您将：\n",
        "\n",
        "- 学习如何对提升树模型进行*局部*和*全局*解释\n",
        "- 直观地了解提升树模型如何拟合数据集\n",
        "\n",
        "## 如何对提升树模型（Boosted Trees model）进行局部解释和全局解释\n",
        "\n",
        "局部可解释性指模型的预测在单一样本层面的理解程度，而全局可解释性指模型作为一个整体的理解能力。这种技术可以帮助机器学习 (ML) 从业者在模型开发阶段检测偏差和错误。\n",
        "\n",
        "对于局部可解释性，您将了解到如何创造并可视化每个实例（per-instance）的贡献度。区别于特征重要性，这种贡献被称为 DFCs（定向特征贡献，directional feature contributions）。\n",
        "\n",
        "对于全局可解释性，您将检索并呈现基于增益的特征重要性、[排列特征重要性](https://www.stat.berkeley.edu/~breiman/randomforest2001.pdf)，显示汇总的 DFC。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eylrTPAN3rJV"
      },
      "source": [
        "## 加载泰坦尼克数据集（titanic）\n",
        "\n",
        "本教程使用泰坦尼克数据集，旨在已知乘客的性别，年龄和客舱等级等特征的情况下预测的存活率。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "132V3PZ8V8VA"
      },
      "outputs": [],
      "source": [
        "!pip install statsmodels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KuhAiPfZ3rJW"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from IPython.display import clear_output\n",
        "\n",
        "# Load dataset.\n",
        "dftrain = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/train.csv')\n",
        "dfeval = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/eval.csv')\n",
        "y_train = dftrain.pop('survived')\n",
        "y_eval = dfeval.pop('survived')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sp1ShjJJeyH3"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "tf.random.set_seed(123)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ioodHdVJVdA"
      },
      "source": [
        "有关特征的描述，请参阅之前的教程。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krkRHuMp3rJn"
      },
      "source": [
        "## 创建特征列, 输入函数并训练 estimator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JiJ6K3hr1lXW"
      },
      "source": [
        "### 数据预处理"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udMytRJC05oW"
      },
      "source": [
        "特征处理，使用原始的数值特征和独热编码（one-hot-encoding）处理过的非数值特征（如性别，舱位）别建立数据集。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "upaNWxcF3rJn"
      },
      "outputs": [],
      "source": [
        "fc = tf.feature_column\n",
        "CATEGORICAL_COLUMNS = ['sex', 'n_siblings_spouses', 'parch', 'class', 'deck',\n",
        "                       'embark_town', 'alone']\n",
        "NUMERIC_COLUMNS = ['age', 'fare']\n",
        "\n",
        "def one_hot_cat_column(feature_name, vocab):\n",
        "  return fc.indicator_column(\n",
        "      fc.categorical_column_with_vocabulary_list(feature_name,\n",
        "                                                 vocab))\n",
        "feature_columns = []\n",
        "for feature_name in CATEGORICAL_COLUMNS:\n",
        "  # Need to one-hot encode categorical features.\n",
        "  vocabulary = dftrain[feature_name].unique()\n",
        "  feature_columns.append(one_hot_cat_column(feature_name, vocabulary))\n",
        "\n",
        "for feature_name in NUMERIC_COLUMNS:\n",
        "  feature_columns.append(fc.numeric_column(feature_name,\n",
        "                                           dtype=tf.float32))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rTefnXe1n0v"
      },
      "source": [
        "### 构建输入 pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-UOlROp33rJo"
      },
      "source": [
        "使用 API [`tf.data`](https://tensorflow.google.cn/api_docs/python/tf/data) 中的 `from_tensor_slices` 方法建立输入方程来从 Pandas 中直接读取数据。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9dquwCQB3rJp"
      },
      "outputs": [],
      "source": [
        "# 当数据集小的时候，将整个数据集作为一个 batch。\n",
        "NUM_EXAMPLES = len(y_train)\n",
        "\n",
        "def make_input_fn(X, y, n_epochs=None, shuffle=True):\n",
        "  def input_fn():\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((X.to_dict(orient='list'), y))\n",
        "    if shuffle:\n",
        "      dataset = dataset.shuffle(NUM_EXAMPLES)\n",
        "    # 训练时让数据迭代尽可能多次 （n_epochs=None）。\n",
        "    dataset = (dataset\n",
        "      .repeat(n_epochs)\n",
        "      .batch(NUM_EXAMPLES))\n",
        "    return dataset\n",
        "  return input_fn\n",
        "\n",
        "# 训练并评估输入函数。\n",
        "train_input_fn = make_input_fn(dftrain, y_train)\n",
        "eval_input_fn = make_input_fn(dfeval, y_eval, shuffle=False, n_epochs=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HttfNNlN3rJr"
      },
      "source": [
        "### 训练模型"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tgEzMtlw3rJu"
      },
      "outputs": [],
      "source": [
        "params = {\n",
        "  'n_trees': 50,\n",
        "  'max_depth': 3,\n",
        "  'n_batches_per_layer': 1,\n",
        "  # You must enable center_bias = True to get DFCs. This will force the model to\n",
        "  # make an initial prediction before using any features (e.g. use the mean of\n",
        "  # the training labels for regression or log odds for classification when\n",
        "  # using cross entropy loss).\n",
        "  'center_bias': True\n",
        "}\n",
        "\n",
        "est = tf.estimator.BoostedTreesClassifier(feature_columns, **params)\n",
        "# Train model.\n",
        "est.train(train_input_fn, max_steps=100)\n",
        "\n",
        "# Evaluation.\n",
        "results = est.evaluate(eval_input_fn)\n",
        "clear_output()\n",
        "pd.Series(results).to_frame()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgAz3jDa_tRA"
      },
      "source": [
        "出于性能原因，当您的数据适合内存时，我们建议在 `tf.estimator.BoostedTreesClassifier` 函数中使用参数 `train_in_memory=True`。但是，如果训练时间不是关注的问题，或者如果您有一个非常大的数据集并且想要进行分布式训练，请使用上面显示的 `tf.estimator.BoostedTrees` API。\n",
        "\n",
        "当您使用此方法时，请不要对数据分批（batch），而是对整个数据集进行操作。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y7ztzoSk_vjY"
      },
      "outputs": [],
      "source": [
        "in_memory_params = dict(params)\n",
        "in_memory_params['n_batches_per_layer'] = 1\n",
        "# In-memory input_fn does not use batching.\n",
        "def make_inmemory_train_input_fn(X, y):\n",
        "  y = np.expand_dims(y, axis=1)\n",
        "  def input_fn():\n",
        "    return dict(X), y\n",
        "  return input_fn\n",
        "train_input_fn = make_inmemory_train_input_fn(dftrain, y_train)\n",
        "\n",
        "# Train the model.\n",
        "est = tf.estimator.BoostedTreesClassifier(\n",
        "    feature_columns, \n",
        "    train_in_memory=True, \n",
        "    **in_memory_params)\n",
        "\n",
        "est.train(train_input_fn)\n",
        "print(est.evaluate(eval_input_fn))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSZYqNcRuczV"
      },
      "source": [
        "## 模型说明与绘制"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BjcfLiI3uczW"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns_colors = sns.color_palette('colorblind')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywTtbBvBuczY"
      },
      "source": [
        "## 局部可解释性（Local interpretability）\n",
        "\n",
        "接下来，您将输出定向特征贡献（DFCs）来解释单个预测。输出依据 [Palczewska et al](https://arxiv.org/pdf/1312.1121.pdf) 和 Saabas 在 [解释随机森林（Interpreting Random Forests）](http://blog.datadive.net/interpreting-random-forests/) 中提出的方法产生(scikit-learn 中随机森林相关的包 [`treeinterpreter`](https://github.com/andosa/treeinterpreter) 使用原理相同的远离). 使用以下语句输出 DFCs:\n",
        "\n",
        "`pred_dicts = list(est.experimental_predict_with_explanations(pred_input_fn))`\n",
        "\n",
        "（注：该方法被命名为实验性，因为我们可能会在放弃实验性前缀之前修改 API。）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TIL93B4sDRqE"
      },
      "outputs": [],
      "source": [
        "pred_dicts = list(est.experimental_predict_with_explanations(eval_input_fn))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tDPoRx_ZaY1E"
      },
      "outputs": [],
      "source": [
        "# Create DFC Pandas dataframe.\n",
        "labels = y_eval.values\n",
        "probs = pd.Series([pred['probabilities'][1] for pred in pred_dicts])\n",
        "df_dfc = pd.DataFrame([pred['dfc'] for pred in pred_dicts])\n",
        "df_dfc.describe().T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUKSaVoraY1C"
      },
      "source": [
        "DFC 有一个非常好的属性，即贡献 + 偏差的总和等于给定样本的预测。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hd9VuizRaY1H"
      },
      "outputs": [],
      "source": [
        "# Sum of DFCs + bias == probabality.\n",
        "bias = pred_dicts[0]['bias']\n",
        "dfc_prob = df_dfc.sum(axis=1) + bias\n",
        "np.testing.assert_almost_equal(dfc_prob.values,\n",
        "                               probs.values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tx5p4vEhuczg"
      },
      "source": [
        "为单个乘客绘制 DFCs，绘图时按贡献的方向性对其进行涂色并添加特征的值。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6z_Tq1Pquczj"
      },
      "outputs": [],
      "source": [
        "# Boilerplate code for plotting :)\n",
        "def _get_color(value):\n",
        "    \"\"\"To make positive DFCs plot green, negative DFCs plot red.\"\"\"\n",
        "    green, red = sns.color_palette()[2:4]\n",
        "    if value >= 0: return green\n",
        "    return red\n",
        "\n",
        "def _add_feature_values(feature_values, ax):\n",
        "    \"\"\"Display feature's values on left of plot.\"\"\"\n",
        "    x_coord = ax.get_xlim()[0]\n",
        "    OFFSET = 0.15\n",
        "    for y_coord, (feat_name, feat_val) in enumerate(feature_values.items()):\n",
        "        t = plt.text(x_coord, y_coord - OFFSET, '{}'.format(feat_val), size=12)\n",
        "        t.set_bbox(dict(facecolor='white', alpha=0.5))\n",
        "    from matplotlib.font_manager import FontProperties\n",
        "    font = FontProperties()\n",
        "    font.set_weight('bold')\n",
        "    t = plt.text(x_coord, y_coord + 1 - OFFSET, 'feature\\nvalue',\n",
        "    fontproperties=font, size=12)\n",
        "\n",
        "def plot_example(example):\n",
        "  TOP_N = 8 # View top 8 features.\n",
        "  sorted_ix = example.abs().sort_values()[-TOP_N:].index  # Sort by magnitude.\n",
        "  example = example[sorted_ix]\n",
        "  colors = example.map(_get_color).tolist()\n",
        "  ax = example.to_frame().plot(kind='barh',\n",
        "                          color=colors,\n",
        "                          legend=None,\n",
        "                          alpha=0.75,\n",
        "                          figsize=(10,6))\n",
        "  ax.grid(False, axis='y')\n",
        "  ax.set_yticklabels(ax.get_yticklabels(), size=14)\n",
        "\n",
        "  # Add feature values.\n",
        "  _add_feature_values(dfeval.iloc[ID][sorted_ix], ax)\n",
        "  return ax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ht1P2-1euczk"
      },
      "outputs": [],
      "source": [
        "# Plot results.\n",
        "ID = 182\n",
        "example = df_dfc.iloc[ID]  # Choose ith example from evaluation set.\n",
        "TOP_N = 8  # View top 8 features.\n",
        "sorted_ix = example.abs().sort_values()[-TOP_N:].index\n",
        "ax = plot_example(example)\n",
        "ax.set_title('Feature contributions for example {}\\n pred: {:1.2f}; label: {}'.format(ID, probs[ID], labels[ID]))\n",
        "ax.set_xlabel('Contribution to predicted probability', size=14)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPXgWyFcfzAc"
      },
      "source": [
        "更大的贡献值意味着对模型的预测有更大的影响。负的贡献表示此样例该特征的值减小了减小了模型的预测，正贡献值表示增加了模型的预测。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0swvlkZFaY1Z"
      },
      "source": [
        "您也可以使用小提琴图（violin plot）来绘制该样例的 DFCs 并与整体分布比较。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zo7rNd1v_5e2"
      },
      "outputs": [],
      "source": [
        "# Boilerplate plotting code.\n",
        "def dist_violin_plot(df_dfc, ID):\n",
        "  # Initialize plot.\n",
        "  fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
        "\n",
        "  # Create example dataframe.\n",
        "  TOP_N = 8  # View top 8 features.\n",
        "  example = df_dfc.iloc[ID]\n",
        "  ix = example.abs().sort_values()[-TOP_N:].index\n",
        "  example = example[ix]\n",
        "  example_df = example.to_frame(name='dfc')\n",
        "\n",
        "  # Add contributions of entire distribution.\n",
        "  parts=ax.violinplot([df_dfc[w] for w in ix],\n",
        "                 vert=False,\n",
        "                 showextrema=False,\n",
        "                 widths=0.7,\n",
        "                 positions=np.arange(len(ix)))\n",
        "  face_color = sns_colors[0]\n",
        "  alpha = 0.15\n",
        "  for pc in parts['bodies']:\n",
        "      pc.set_facecolor(face_color)\n",
        "      pc.set_alpha(alpha)\n",
        "\n",
        "  # Add feature values.\n",
        "  _add_feature_values(dfeval.iloc[ID][sorted_ix], ax)\n",
        "\n",
        "  # Add local contributions.\n",
        "  ax.scatter(example,\n",
        "              np.arange(example.shape[0]),\n",
        "              color=sns.color_palette()[2],\n",
        "              s=100,\n",
        "              marker=\"s\",\n",
        "              label='contributions for example')\n",
        "\n",
        "  # Legend\n",
        "  # Proxy plot, to show violinplot dist on legend.\n",
        "  ax.plot([0,0], [1,1], label='eval set contributions\\ndistributions',\n",
        "          color=face_color, alpha=alpha, linewidth=10)\n",
        "  legend = ax.legend(loc='lower right', shadow=True, fontsize='x-large',\n",
        "                     frameon=True)\n",
        "  legend.get_frame().set_facecolor('white')\n",
        "\n",
        "  # Format plot.\n",
        "  ax.set_yticks(np.arange(example.shape[0]))\n",
        "  ax.set_yticklabels(example.index)\n",
        "  ax.grid(False, axis='y')\n",
        "  ax.set_xlabel('Contribution to predicted probability', size=14)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PiLw2tlm_9aK"
      },
      "source": [
        "绘制此样例。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VkCqraA2uczm"
      },
      "outputs": [],
      "source": [
        "dist_violin_plot(df_dfc, ID)\n",
        "plt.title('Feature contributions for example {}\\n pred: {:1.2f}; label: {}'.format(ID, probs[ID], labels[ID]))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVJFM85SAWVq"
      },
      "source": [
        "最后，第三方的工具，如：[LIME](https://github.com/marcotcr/lime) 和 [shap](https://github.com/slundberg/shap) 也可以帮助理解模型的各个预测。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PnNXH6mZuczr"
      },
      "source": [
        "## 全局特征重要性（Global feature importances）\n",
        "\n",
        "此外，您或许想了解模型这个整体而不是单个预测。接下来，您将计算并使用：\n",
        "\n",
        "- 使用 `est.experimental_feature_importances` 得到基于增益的特征重要性\n",
        "- 排列特征重要性（Permutation feature importances）\n",
        "- 使用 `est.experimental_predict_with_explanations` 得到总 DFCs。\n",
        "\n",
        "基于增益的特征重要性在分离特定特征时测量损失的变化。而排列特征重要性是在评估集上通过每次打乱一个特征后观察模型性能的变化计算而出。\n",
        "\n",
        "一般来说，排列特征重要性要优于基于增益的特征重要性，尽管这两种方法在潜在预测变量的测量范围或类别数量不确定时和特征相关联时不可信（[来源](https://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-9-307)）。 对不同种类特征重要性的更透彻概括和更翔实讨论请参考 [这篇文章](http://explained.ai/rf-importance/index.html) 。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ocBcMatuczs"
      },
      "source": [
        "### 基于增益的特征重要性（Gain-based feature importances）"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMaxCgPbBJ-j"
      },
      "source": [
        "基于增益的特征重要性使用 `est.experimental_feature_importances` 内置到 TensorFlow 提升树 Estimator 中。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pPTxbAaeuczt"
      },
      "outputs": [],
      "source": [
        "importances = est.experimental_feature_importances(normalize=True)\n",
        "df_imp = pd.Series(importances)\n",
        "\n",
        "# Visualize importances.\n",
        "N = 8\n",
        "ax = (df_imp.iloc[0:N][::-1]\n",
        "    .plot(kind='barh',\n",
        "          color=sns_colors[0],\n",
        "          title='Gain feature importances',\n",
        "          figsize=(10, 6)))\n",
        "ax.grid(False, axis='y')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GvfAcBeGuczw"
      },
      "source": [
        "### 平均绝对 DFCs\n",
        "\n",
        "您还可以得到绝对DFCs的平均值来从全局的角度分析影响。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JkvAWLWLuczx"
      },
      "outputs": [],
      "source": [
        "# Plot.\n",
        "dfc_mean = df_dfc.abs().mean()\n",
        "N = 8\n",
        "sorted_ix = dfc_mean.abs().sort_values()[-N:].index  # Average and sort by absolute.\n",
        "ax = dfc_mean[sorted_ix].plot(kind='barh',\n",
        "                       color=sns_colors[1],\n",
        "                       title='Mean |directional feature contributions|',\n",
        "                       figsize=(10, 6))\n",
        "ax.grid(False, axis='y')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0k_DvPLaY1o"
      },
      "source": [
        "您可以看到 DFCs 如何随特征的值变化而变化。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZcIfN1IpaY1o"
      },
      "outputs": [],
      "source": [
        "FEATURE = 'fare'\n",
        "feature = pd.Series(df_dfc[FEATURE].values, index=dfeval[FEATURE].values).sort_index()\n",
        "ax = sns.regplot(feature.index.values, feature.values, lowess=True)\n",
        "ax.set_ylabel('contribution')\n",
        "ax.set_xlabel(FEATURE)\n",
        "ax.set_xlim(0, 100)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbpG72ULucz0"
      },
      "source": [
        "### 排列特征重要性（Permutation feature importances）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6esOw1VOucz0"
      },
      "outputs": [],
      "source": [
        "def permutation_importances(est, X_eval, y_eval, metric, features):\n",
        "    \"\"\"Column by column, shuffle values and observe effect on eval set.\n",
        "\n",
        "    source: http://explained.ai/rf-importance/index.html\n",
        "    A similar approach can be done during training. See \"Drop-column importance\"\n",
        "    in the above article.\"\"\"\n",
        "    baseline = metric(est, X_eval, y_eval)\n",
        "    imp = []\n",
        "    for col in features:\n",
        "        save = X_eval[col].copy()\n",
        "        X_eval[col] = np.random.permutation(X_eval[col])\n",
        "        m = metric(est, X_eval, y_eval)\n",
        "        X_eval[col] = save\n",
        "        imp.append(baseline - m)\n",
        "    return np.array(imp)\n",
        "\n",
        "def accuracy_metric(est, X, y):\n",
        "    \"\"\"TensorFlow estimator accuracy.\"\"\"\n",
        "    eval_input_fn = make_input_fn(X,\n",
        "                                  y=y,\n",
        "                                  shuffle=False,\n",
        "                                  n_epochs=1)\n",
        "    return est.evaluate(input_fn=eval_input_fn)['accuracy']\n",
        "features = CATEGORICAL_COLUMNS + NUMERIC_COLUMNS\n",
        "importances = permutation_importances(est, dfeval, y_eval, accuracy_metric,\n",
        "                                      features)\n",
        "df_imp = pd.Series(importances, index=features)\n",
        "\n",
        "sorted_ix = df_imp.abs().sort_values().index\n",
        "ax = df_imp[sorted_ix][-5:].plot(kind='barh', color=sns_colors[2], figsize=(10, 6))\n",
        "ax.grid(False, axis='y')\n",
        "ax.set_title('Permutation feature importance')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E236y3pVEzHg"
      },
      "source": [
        "## 可视化模型拟合过程"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TrcQ-839EzZ6"
      },
      "source": [
        "首先，使用以下公式构建训练数据：\n",
        "\n",
        "$$z=x* e^{-x^2 - y^2}$$\n",
        "\n",
        "其中， (z) 是您要试着预测的值（因变量），(x) 和 (y) 是特征。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e8woaj81GGE9"
      },
      "outputs": [],
      "source": [
        "from numpy.random import uniform, seed\n",
        "from scipy.interpolate import griddata\n",
        "\n",
        "# Create fake data\n",
        "seed(0)\n",
        "npts = 5000\n",
        "x = uniform(-2, 2, npts)\n",
        "y = uniform(-2, 2, npts)\n",
        "z = x*np.exp(-x**2 - y**2)\n",
        "xy = np.zeros((2,np.size(x)))\n",
        "xy[0] = x\n",
        "xy[1] = y\n",
        "xy = xy.T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GRI3KHfLZsGP"
      },
      "outputs": [],
      "source": [
        "# Prep data for training.\n",
        "df = pd.DataFrame({'x': x, 'y': y, 'z': z})\n",
        "\n",
        "xi = np.linspace(-2.0, 2.0, 200),\n",
        "yi = np.linspace(-2.1, 2.1, 210),\n",
        "xi,yi = np.meshgrid(xi, yi)\n",
        "\n",
        "df_predict = pd.DataFrame({\n",
        "    'x' : xi.flatten(),\n",
        "    'y' : yi.flatten(),\n",
        "})\n",
        "predict_shape = xi.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w0JnH4IhZuAb"
      },
      "outputs": [],
      "source": [
        "def plot_contour(x, y, z, **kwargs):\n",
        "  # Grid the data.\n",
        "  plt.figure(figsize=(10, 8))\n",
        "  # Contour the gridded data, plotting dots at the nonuniform data points.\n",
        "  CS = plt.contour(x, y, z, 15, linewidths=0.5, colors='k')\n",
        "  CS = plt.contourf(x, y, z, 15,\n",
        "                    vmax=abs(zi).max(), vmin=-abs(zi).max(), cmap='RdBu_r')\n",
        "  plt.colorbar()  # Draw colorbar.\n",
        "  # Plot data points.\n",
        "  plt.xlim(-2, 2)\n",
        "  plt.ylim(-2, 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KF7WsIcYGF_E"
      },
      "source": [
        "您可以可视化这个方程，红色代表较大的值。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WrxuqaaXGFOK"
      },
      "outputs": [],
      "source": [
        "zi = griddata(xy, z, (xi, yi), method='linear', fill_value='0')\n",
        "plot_contour(xi, yi, zi)\n",
        "plt.scatter(df.x, df.y, marker='.')\n",
        "plt.title('Contour on training data')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hoANr0f2GFrM"
      },
      "outputs": [],
      "source": [
        "fc = [tf.feature_column.numeric_column('x'),\n",
        "      tf.feature_column.numeric_column('y')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xVRWyoY3ayTK"
      },
      "outputs": [],
      "source": [
        "def predict(est):\n",
        "  \"\"\"Predictions from a given estimator.\"\"\"\n",
        "  predict_input_fn = lambda: tf.data.Dataset.from_tensors(dict(df_predict))\n",
        "  preds = np.array([p['predictions'][0] for p in est.predict(predict_input_fn)])\n",
        "  return preds.reshape(predict_shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyPu5618GU7K"
      },
      "source": [
        "首先，我们尝试用线性模型拟合数据。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zUIV2IVgGVSk"
      },
      "outputs": [],
      "source": [
        "train_input_fn = make_input_fn(df, df.z)\n",
        "est = tf.estimator.LinearRegressor(fc)\n",
        "est.train(train_input_fn, max_steps=500);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_u4WAcCqfbco"
      },
      "outputs": [],
      "source": [
        "plot_contour(xi, yi, predict(est))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XD_fMAUtSCSa"
      },
      "source": [
        "可见，拟合效果并不好。接下来，我们试着用 GBDT 模型拟合并了解模型是如何拟合方程的。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-dHlKFlFgHDQ"
      },
      "outputs": [],
      "source": [
        "n_trees = 37 #@param {type: \"slider\", min: 1, max: 80, step: 1}\n",
        "\n",
        "est = tf.estimator.BoostedTreesRegressor(fc, n_batches_per_layer=1, n_trees=n_trees)\n",
        "est.train(train_input_fn, max_steps=500)\n",
        "clear_output()\n",
        "plot_contour(xi, yi, predict(est))\n",
        "plt.text(-1.8, 2.1, '# trees: {}'.format(n_trees), color='w', backgroundcolor='black', size=20)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WcZ9fubh1wT"
      },
      "source": [
        "随着树的数量增加，模型的预测越来越接近真实方程。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cj8u3NCG-IKX"
      },
      "source": [
        "![](https://tensorflow.google.cn/images/boosted_trees/boosted_trees_ntrees.gif)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMKoEZnCdrsp"
      },
      "source": [
        "## 总结"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSZUSrjXdw9g"
      },
      "source": [
        "在本教程中，您学习了如何使用定向特征贡献和特征重要性技术来解释提升树模型。这些技术可以帮助您了解特征如何影响模型的预测。 最后，您还通过查看多个模型的决策图面直观地了解了提升树模型如何拟合复杂函数。"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "boosted_trees_model_understanding.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
