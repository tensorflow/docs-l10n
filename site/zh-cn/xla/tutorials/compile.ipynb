{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4TSNCvpENrW"
      },
      "source": [
        "##### Copyright 2019 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "vamNSA0vEP-m"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1oSi4lHFt3z"
      },
      "source": [
        "# 将 XLA 与 tf.function 结合使用"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7noD9NjFRL-"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td><a target=\"_blank\" href=\"https://tensorflow.google.cn/xla/tutorials/compile\"><img src=\"https://tensorflow.google.cn/images/tf_logo_32px.png\">在 TensorFlow.org 查看</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/zh-cn/xla/tutorials/compile.ipynb\"><img src=\"https://tensorflow.google.cn/images/colab_logo_32px.png\">在 Google Colab 中运行 </a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/zh-cn/xla/tutorials/compile.ipynb\"><img src=\"https://tensorflow.google.cn/images/GitHub-Mark-32px.png\">在 GitHub 中查看源代码</a></td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDy5lSBd4BDE"
      },
      "source": [
        "本教程将训练一个 TensorFlow 模型来对 MNIST 数据集进行分类，我们会使用 XLA 编译训练函数。\n",
        "\n",
        "首先，加载 TensorFlow 并启用 Eager Execution。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ukTmcHYkwx8f"
      },
      "outputs": [],
      "source": [
        "# In TF 2.4 jit_compile is called experimental_compile\n",
        "!pip install tf-nightly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "45kUPj5ZFrRa"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "tf.compat.v1.enable_eager_execution()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZVNiRmTDV-5"
      },
      "source": [
        "随后，定义一些必要的常量并准备 MNIST 数据集。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f37TSEGvGX4_"
      },
      "outputs": [],
      "source": [
        "# Size of each input image, 28 x 28 pixels\n",
        "IMAGE_SIZE = 28 * 28\n",
        "# Number of distinct number labels, [0..9]\n",
        "NUM_CLASSES = 10\n",
        "# Number of examples in each training batch (step)\n",
        "TRAIN_BATCH_SIZE = 100\n",
        "# Number of training steps to run\n",
        "TRAIN_STEPS = 1000\n",
        "\n",
        "# Loads MNIST dataset.\n",
        "train, test = tf.keras.datasets.mnist.load_data()\n",
        "train_ds = tf.data.Dataset.from_tensor_slices(train).batch(TRAIN_BATCH_SIZE).repeat()\n",
        "\n",
        "# Casting from raw data to the required datatypes.\n",
        "def cast(images, labels):\n",
        "  images = tf.cast(\n",
        "      tf.reshape(images, [-1, IMAGE_SIZE]), tf.float32)\n",
        "  labels = tf.cast(labels, tf.int64)\n",
        "  return (images, labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lv7I-u_82v1S"
      },
      "source": [
        "最后，定义模型和优化器。该模型使用单个密集层。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7O2NcEfG206Q"
      },
      "outputs": [],
      "source": [
        "layer = tf.keras.layers.Dense(NUM_CLASSES)\n",
        "optimizer = tf.keras.optimizers.Adam()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_ZehpZP-SfS"
      },
      "source": [
        "# 定义训练函数\n",
        "\n",
        "在训练函数中，您可以使用上面定义的层来获取预测的标签，然后使用优化器来尽可能减小损失的梯度。为了使用 XLA 编译计算，请将其置于 `jit_compile=True` 的 `tf.function` 中。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZbhJl_WvGa3g"
      },
      "outputs": [],
      "source": [
        "@tf.function(experimental_compile=True)\n",
        "def train_mnist(images, labels):\n",
        "    images, labels = cast(images, labels)\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "      predicted_labels = layer(images)\n",
        "      loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
        "          logits=predicted_labels, labels=labels\n",
        "      ))\n",
        "    layer_variables = layer.trainable_variables\n",
        "    grads = tape.gradient(loss, layer_variables)\n",
        "    optimizer.apply_gradients(zip(grads, layer_variables))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZD1m_n1DxAF"
      },
      "source": [
        "# 训练并测试模型"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gukC2Hol3sFZ"
      },
      "source": [
        "定义训练函数后，请定义模型。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qe28bAHNHUG2"
      },
      "outputs": [],
      "source": [
        "for images, labels in train_ds:\n",
        "  if optimizer.iterations > TRAIN_STEPS:\n",
        "    break\n",
        "  train_mnist(images, labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgsKmz3n2UiW"
      },
      "source": [
        "最后，检查准确率："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_GxF6jTRHVuA"
      },
      "outputs": [],
      "source": [
        "images, labels = cast(test[0], test[1])\n",
        "predicted_labels = layer(images)\n",
        "correct_prediction = tf.equal(tf.argmax(predicted_labels, 1), labels)\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "print(\"Prediction accuracy after training: %s\" % accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXoOjJnuZRaV"
      },
      "source": [
        "在后台，XLA 编译器将整个 TF 函数编译为 HLO，后者已启用融合优化。使用自省工具，我们可以查看 HLO 代码（“stage”的其他有趣的可能值是优化后的 HLO 的 `optimized_hlo` 和 Graphviz 计算图的 `optimized_hlo_dot`）："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_a8GsNLVaLSQ"
      },
      "outputs": [],
      "source": [
        "print(train_mnist.experimental_get_compiler_ir(images, labels)(stage='hlo'))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "compile.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
