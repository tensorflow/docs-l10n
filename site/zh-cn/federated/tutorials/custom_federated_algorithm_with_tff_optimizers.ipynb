{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkdnLiKk71g-"
      },
      "source": [
        "##### Copyright 2021 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "0asMuNro71hA"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPFgLeZIsZ3Q"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>     <a target=\"_blank\" href=\"https://tensorflow.google.cn/federated/tutorials/custom_federated_algorithm_with_tff_optimizers\"><img src=\"https://tensorflow.google.cn/images/tf_logo_32px.png\">在 TensorFlow.org 上查看</a> </td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/zh-cn/federated/tutorials/custom_federated_algorithm_with_tff_optimizers.ipynb\"><img src=\"https://tensorflow.google.cn/images/colab_logo_32px.png\">在 Google Colab 中运行</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/zh-cn/federated/tutorials/custom_federated_algorithm_with_tff_optimizers.ipynb\"><img src=\"https://tensorflow.google.cn/images/GitHub-Mark-32px.png\">在 GitHub 上查看源代码</a>\n",
        "</td>\n",
        "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/zh-cn/federated/tutorials/custom_federated_algorithm_with_tff_optimizers.ipynb\"><img src=\"https://tensorflow.google.cn/images/download_logo_32px.png\">下载笔记本</a>   </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Zv28F7QLo8O"
      },
      "source": [
        "# 在自定义迭代过程中使用 TFF 优化器\n",
        "\n",
        "这是用于为[联合平均](https://arxiv.org/abs/1602.05629)算法构建自定义迭代过程的替代方法，可作为[构建您自己的联合学习算法](https://arxiv.org/abs/1602.05629)教程和 [simple_fedavg](https://github.com/tensorflow/federated/tree/main/tensorflow_federated/examples/simple_fedavg) 示例的补充。本教程将使用 [TFF 优化器](https://github.com/tensorflow/federated/tree/main/tensorflow_federated/python/learning/optimizers)而非 Keras 优化器。TFF 优化器抽象被设计为 state-in-state-out，从而更容易融入到 TFF 迭代过程中。`tff.learning` API 也接受 TFF 优化器作为输入参数。 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnUwFbCAKB2r"
      },
      "source": [
        "## 准备工作\n",
        "\n",
        "开始之前，请运行以下代码来确保您的环境已正确设置。如果未看到问候语，请参阅[安装](../install.md)指南查看说明。 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZrGitA_KnRO0"
      },
      "outputs": [],
      "source": [
        "#@test {\"skip\": true}\n",
        "!pip install --quiet --upgrade tensorflow-federated\n",
        "!pip install --quiet --upgrade nest-asyncio\n",
        "\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HGTM6tWOLo8M"
      },
      "outputs": [],
      "source": [
        "import functools\n",
        "import attr\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_federated as tff"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQ_N9XbULo8P"
      },
      "source": [
        "## 准备数据和模型\n",
        "\n",
        "EMNIST 数据处理和模型与 [simple_fedavg](https://github.com/tensorflow/federated/tree/main/tensorflow_federated/examples/simple_fedavg) 示例非常相似。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Blrh8zJgLo8R"
      },
      "outputs": [],
      "source": [
        "only_digits=True\n",
        "\n",
        "# Load dataset.\n",
        "emnist_train, emnist_test = tff.simulation.datasets.emnist.load_data(only_digits)\n",
        "\n",
        "# Define preprocessing functions.\n",
        "def preprocess_fn(dataset, batch_size=16):\n",
        "\n",
        "  def batch_format_fn(element):\n",
        "    return (tf.expand_dims(element['pixels'], -1), element['label'])\n",
        "\n",
        "  return dataset.batch(batch_size).map(batch_format_fn)\n",
        "\n",
        "# Preprocess and sample clients for prototyping.\n",
        "train_client_ids = sorted(emnist_train.client_ids)\n",
        "train_data = emnist_train.preprocess(preprocess_fn)\n",
        "central_test_data = preprocess_fn(\n",
        "    emnist_train.create_tf_dataset_for_client(train_client_ids[0]))\n",
        "\n",
        "# Define model.\n",
        "def create_keras_model():\n",
        "  \"\"\"The CNN model used in https://arxiv.org/abs/1602.05629.\"\"\"\n",
        "  data_format = 'channels_last'\n",
        "  input_shape = [28, 28, 1]\n",
        "\n",
        "  max_pool = functools.partial(\n",
        "      tf.keras.layers.MaxPooling2D,\n",
        "      pool_size=(2, 2),\n",
        "      padding='same',\n",
        "      data_format=data_format)\n",
        "  conv2d = functools.partial(\n",
        "      tf.keras.layers.Conv2D,\n",
        "      kernel_size=5,\n",
        "      padding='same',\n",
        "      data_format=data_format,\n",
        "      activation=tf.nn.relu)\n",
        "\n",
        "  model = tf.keras.models.Sequential([\n",
        "      conv2d(filters=32, input_shape=input_shape),\n",
        "      max_pool(),\n",
        "      conv2d(filters=64),\n",
        "      max_pool(),\n",
        "      tf.keras.layers.Flatten(),\n",
        "      tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "      tf.keras.layers.Dense(10 if only_digits else 62),\n",
        "  ])\n",
        "\n",
        "  return model\n",
        "\n",
        "# Wrap as `tff.learning.Model`.\n",
        "def model_fn():\n",
        "  keras_model = create_keras_model()\n",
        "  return tff.learning.from_keras_model(\n",
        "      keras_model,\n",
        "      input_spec=central_test_data.element_spec,\n",
        "      loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPOWP2JjsfTk"
      },
      "source": [
        "## 自定义迭代过程\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50N36Zz8qyY-"
      },
      "source": [
        "在许多情况下，联合算法包括 4 个主要组件：\n",
        "\n",
        "1. 服务器到客户端的广播步骤。\n",
        "2. 本地客户端更新步骤。\n",
        "3. 客户端到服务器的上传步骤。\n",
        "4. 服务器更新步骤。\n",
        "\n",
        "在 TFF 中，我们通常将联合算法表示为 [`tff.templates.IterativeProcess`](https://tensorflow.google.cn/federated/api_docs/python/tff/templates/IterativeProcess)（我们始终将其称为 `IterativeProcess`）。这是一个包含 `initialize` 和 `next` 函数的类。在此，`initialize` 将用于初始化服务器，`next` 将执行一个通信轮次的联合算法。\n",
        "\n",
        "我们将引入不同的组件来构建联合平均 (FedAvg) 算法，将在客户端更新步骤中使用一个优化器，在服务器更新步骤中使用另一个优化器。客户端和服务器更新的核心逻辑可以用纯 TF 块来表示。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxpNYucgLo8g"
      },
      "source": [
        "### TF 块：客户端和服务器更新\n",
        "\n",
        "在每个客户端上，本地 `client_optimizer` 都会初始化并用于更新客户端模型权重。在服务器端，`server_optimizer` 将使用*上*一轮的状态，并更新下一轮的状态。 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c5rHPKreLo8g"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def client_update(model, dataset, server_weights, client_optimizer):\n",
        "  \"\"\"Performs local training on the client's dataset.\"\"\"\n",
        "  # Initialize the client model with the current server weights.\n",
        "  client_weights = model.trainable_variables\n",
        "  # Assign the server weights to the client model.\n",
        "  tf.nest.map_structure(lambda x, y: x.assign(y),\n",
        "                        client_weights, server_weights)\n",
        "  # Initialize the client optimizer.\n",
        "  trainable_tensor_specs = tf.nest.map_structure(\n",
        "          lambda v: tf.TensorSpec(v.shape, v.dtype), client_weights)\n",
        "  optimizer_state = client_optimizer.initialize(trainable_tensor_specs)\n",
        "  # Use the client_optimizer to update the local model.\n",
        "  for batch in iter(dataset):\n",
        "    with tf.GradientTape() as tape:\n",
        "      # Compute a forward pass on the batch of data.\n",
        "      outputs = model.forward_pass(batch)\n",
        "    # Compute the corresponding gradient.\n",
        "    grads = tape.gradient(outputs.loss, client_weights)\n",
        "    # Apply the gradient using a client optimizer.\n",
        "    optimizer_state, updated_weights = client_optimizer.next(\n",
        "        optimizer_state, client_weights, grads)\n",
        "    tf.nest.map_structure(lambda a, b: a.assign(b), \n",
        "                          client_weights, updated_weights)\n",
        "  # Return model deltas.\n",
        "  return tf.nest.map_structure(tf.subtract, client_weights, server_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rYxErLvHLo8i"
      },
      "outputs": [],
      "source": [
        "@attr.s(eq=False, frozen=True, slots=True)\n",
        "class ServerState(object):\n",
        "  trainable_weights = attr.ib()\n",
        "  optimizer_state = attr.ib()\n",
        "\n",
        "@tf.function\n",
        "def server_update(server_state, mean_model_delta, server_optimizer):\n",
        "  \"\"\"Updates the server model weights.\"\"\"\n",
        "  # Use aggregated negative model delta as pseudo gradient. \n",
        "  negative_weights_delta = tf.nest.map_structure(\n",
        "      lambda w: -1.0 * w, mean_model_delta)\n",
        "  new_optimizer_state, updated_weights = server_optimizer.next(\n",
        "      server_state.optimizer_state, server_state.trainable_weights, \n",
        "      negative_weights_delta)\n",
        "  return tff.structure.update_struct(\n",
        "      server_state,\n",
        "      trainable_weights=updated_weights,\n",
        "      optimizer_state=new_optimizer_state)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0zNTO7LLo84"
      },
      "source": [
        "### TFF 块：`tff.tf_computation` 和 `tff.federated_computation`\n",
        "\n",
        "我们现在使用 TFF 进行编排，并为 FedAvg 构建迭代过程。我们必须用 `tff.tf_computation` 包装上面定义的 TF 块，并在 `tff.federated_computation` 函数中使用 TFF 方法 `tff.federated_broadcast`、`tff.federated_map`、`tff.federated_mean`。在定义自定义迭代过程时，将 `tff.learning.optimizers.Optimizer` API 与 `initialize` 和 `next` 函数一起使用非常方便。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jJY9xUBZLo84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "server_state_type:\n",
            " <\n",
            "  trainable_weights=<\n",
            "    float32[5,5,1,32],\n",
            "    float32[32],\n",
            "    float32[5,5,32,64],\n",
            "    float32[64],\n",
            "    float32[3136,512],\n",
            "    float32[512],\n",
            "    float32[512,10],\n",
            "    float32[10]\n",
            "  >,\n",
            "  optimizer_state=<\n",
            "    float32[5,5,1,32],\n",
            "    float32[32],\n",
            "    float32[5,5,32,64],\n",
            "    float32[64],\n",
            "    float32[3136,512],\n",
            "    float32[512],\n",
            "    float32[512,10],\n",
            "    float32[10]\n",
            "  >\n",
            ">\n",
            "trainable_weights_type:\n",
            " <\n",
            "  float32[5,5,1,32],\n",
            "  float32[32],\n",
            "  float32[5,5,32,64],\n",
            "  float32[64],\n",
            "  float32[3136,512],\n",
            "  float32[512],\n",
            "  float32[512,10],\n",
            "  float32[10]\n",
            ">\n",
            "tf_dataset_type:\n",
            " <\n",
            "  float32[?,28,28,1],\n",
            "  int32[?]\n",
            ">*\n",
            "type signature of `initialize`:\n",
            " ( -> <\n",
            "  trainable_weights=<\n",
            "    float32[5,5,1,32],\n",
            "    float32[32],\n",
            "    float32[5,5,32,64],\n",
            "    float32[64],\n",
            "    float32[3136,512],\n",
            "    float32[512],\n",
            "    float32[512,10],\n",
            "    float32[10]\n",
            "  >,\n",
            "  optimizer_state=<\n",
            "    float32[5,5,1,32],\n",
            "    float32[32],\n",
            "    float32[5,5,32,64],\n",
            "    float32[64],\n",
            "    float32[3136,512],\n",
            "    float32[512],\n",
            "    float32[512,10],\n",
            "    float32[10]\n",
            "  >\n",
            ">@SERVER)\n",
            "type signature of `next`:\n",
            " (<\n",
            "  server_state=<\n",
            "    trainable_weights=<\n",
            "      float32[5,5,1,32],\n",
            "      float32[32],\n",
            "      float32[5,5,32,64],\n",
            "      float32[64],\n",
            "      float32[3136,512],\n",
            "      float32[512],\n",
            "      float32[512,10],\n",
            "      float32[10]\n",
            "    >,\n",
            "    optimizer_state=<\n",
            "      float32[5,5,1,32],\n",
            "      float32[32],\n",
            "      float32[5,5,32,64],\n",
            "      float32[64],\n",
            "      float32[3136,512],\n",
            "      float32[512],\n",
            "      float32[512,10],\n",
            "      float32[10]\n",
            "    >\n",
            "  >@SERVER,\n",
            "  federated_dataset={<\n",
            "    float32[?,28,28,1],\n",
            "    int32[?]\n",
            "  >*}@CLIENTS\n",
            "> -> <\n",
            "  trainable_weights=<\n",
            "    float32[5,5,1,32],\n",
            "    float32[32],\n",
            "    float32[5,5,32,64],\n",
            "    float32[64],\n",
            "    float32[3136,512],\n",
            "    float32[512],\n",
            "    float32[512,10],\n",
            "    float32[10]\n",
            "  >,\n",
            "  optimizer_state=<\n",
            "    float32[5,5,1,32],\n",
            "    float32[32],\n",
            "    float32[5,5,32,64],\n",
            "    float32[64],\n",
            "    float32[3136,512],\n",
            "    float32[512],\n",
            "    float32[512,10],\n",
            "    float32[10]\n",
            "  >\n",
            ">@SERVER)\n"
          ]
        }
      ],
      "source": [
        "# 1. Server and client optimizer to be used.\n",
        "server_optimizer = tff.learning.optimizers.build_sgdm(\n",
        "    learning_rate=0.05, momentum=0.9)\n",
        "client_optimizer = tff.learning.optimizers.build_sgdm(\n",
        "    learning_rate=0.01)\n",
        "\n",
        "# 2. Functions return initial state on server. \n",
        "@tff.tf_computation\n",
        "def server_init():\n",
        "  model = model_fn()\n",
        "  trainable_tensor_specs = tf.nest.map_structure(\n",
        "        lambda v: tf.TensorSpec(v.shape, v.dtype), model.trainable_variables)\n",
        "  optimizer_state = server_optimizer.initialize(trainable_tensor_specs)\n",
        "  return ServerState(\n",
        "      trainable_weights=model.trainable_variables,\n",
        "      optimizer_state=optimizer_state)\n",
        "\n",
        "@tff.federated_computation\n",
        "def server_init_tff():\n",
        "  return tff.federated_value(server_init(), tff.SERVER)\n",
        "\n",
        "# 3. One round of computation and communication.\n",
        "server_state_type = server_init.type_signature.result\n",
        "print('server_state_type:\\n', \n",
        "      server_state_type.formatted_representation())\n",
        "trainable_weights_type = server_state_type.trainable_weights\n",
        "print('trainable_weights_type:\\n', \n",
        "      trainable_weights_type.formatted_representation())\n",
        "\n",
        "# 3-1. Wrap server and client TF blocks with `tff.tf_computation`.\n",
        "@tff.tf_computation(server_state_type, trainable_weights_type)\n",
        "def server_update_fn(server_state, model_delta):\n",
        "  return server_update(server_state, model_delta, server_optimizer)\n",
        "\n",
        "whimsy_model = model_fn()\n",
        "tf_dataset_type = tff.SequenceType(whimsy_model.input_spec)\n",
        "print('tf_dataset_type:\\n', \n",
        "      tf_dataset_type.formatted_representation())\n",
        "@tff.tf_computation(tf_dataset_type, trainable_weights_type)\n",
        "def client_update_fn(dataset, server_weights):\n",
        "  model = model_fn()\n",
        "  return client_update(model, dataset, server_weights, client_optimizer)\n",
        "\n",
        "# 3-2. Orchestration with `tff.federated_computation`.\n",
        "federated_server_type = tff.FederatedType(server_state_type, tff.SERVER)\n",
        "federated_dataset_type = tff.FederatedType(tf_dataset_type, tff.CLIENTS)\n",
        "@tff.federated_computation(federated_server_type, federated_dataset_type)\n",
        "def run_one_round(server_state, federated_dataset):\n",
        "  # Server-to-client broadcast.\n",
        "  server_weights_at_client = tff.federated_broadcast(\n",
        "      server_state.trainable_weights)\n",
        "  # Local client update.\n",
        "  model_deltas = tff.federated_map(\n",
        "      client_update_fn, (federated_dataset, server_weights_at_client))\n",
        "  # Client-to-server upload and aggregation.\n",
        "  mean_model_delta = tff.federated_mean(model_deltas)\n",
        "  # Server update.\n",
        "  server_state = tff.federated_map(\n",
        "      server_update_fn, (server_state, mean_model_delta))\n",
        "  return server_state\n",
        "\n",
        "# 4. Build the iterative process for FedAvg.\n",
        "fedavg_process = tff.templates.IterativeProcess(\n",
        "    initialize_fn=server_init_tff, next_fn=run_one_round)\n",
        "print('type signature of `initialize`:\\n', \n",
        "      fedavg_process.initialize.type_signature.formatted_representation())\n",
        "print('type signature of `next`:\\n', \n",
        "      fedavg_process.next.type_signature.formatted_representation())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4UYZ3qeMLo9N"
      },
      "source": [
        "## 评估算法"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwd9Gs0ULo9O"
      },
      "source": [
        "我们在集中评估数据集上评估性能。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EdNgYoIwLo9P"
      },
      "outputs": [],
      "source": [
        "def evaluate(server_state):\n",
        "  keras_model = create_keras_model()\n",
        "  tf.nest.map_structure(\n",
        "      lambda var, t: var.assign(t),\n",
        "      keras_model.trainable_weights, server_state.trainable_weights)\n",
        "  metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "  for batch in iter(central_test_data):\n",
        "    preds = keras_model(batch[0], training=False)\n",
        "    metric.update_state(y_true=batch[1], y_pred=preds)\n",
        "  return metric.result().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CDarZn71G2mH"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initial test accuracy 0.09677419\n",
            "Test accuracy 0.13978495\n"
          ]
        }
      ],
      "source": [
        "server_state = fedavg_process.initialize()\n",
        "acc = evaluate(server_state)\n",
        "print('Initial test accuracy', acc)\n",
        "\n",
        "# Evaluate after a few rounds\n",
        "CLIENTS_PER_ROUND=2\n",
        "sampled_clients = train_client_ids[:CLIENTS_PER_ROUND]\n",
        "sampled_train_data = [\n",
        "    train_data.create_tf_dataset_for_client(client)\n",
        "    for client in sampled_clients]\n",
        "for round in range(20):\n",
        "  server_state = fedavg_process.next(server_state, sampled_train_data)\n",
        "acc = evaluate(server_state)\n",
        "print('Test accuracy', acc)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "custom_federated_algorithm_with_tff_optimizers.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
