{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tce3stUlHN0L"
      },
      "source": [
        "##### Copyright 2021 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tuOe1ymfHZPu"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfBg1C5NB3X0"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>     <a target=\"_blank\" href=\"https://www.tensorflow.org/federated/tutorials/jax_support\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">在 TensorFlow.org 上查看</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/federated/blob/v0.34.0/docs/tutorials/jax_support.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">在 Google Colab 中运行</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/federated/blob/v0.34.0/docs/tutorials/jax_support.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">在 GitHub 上查看源代码</a>\n",
        "</td>\n",
        "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/federated/docs/tutorials/jax_support.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">下载笔记本</a>\n",
        "</td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANjgx215o-Ik"
      },
      "source": [
        "# TFF 中对 JAX 的实验性支持\n",
        "\n",
        "除了作为 TensorFlow 生态系统的一部分，TFF 还致力于实现与其他前端和后端 ML 框架的互操作性。目前，对其他 ML 框架的支持仍处于孵化阶段，所支持的 API 和功能可能会发生变化（很大程度上取决于 TFF 用户的需求）。本教程描述如何使用 TFF 和 JAX 作为替代的 ML 前端，以及如何使用 XLA 编译器作为替代的后端。这里展示的示例基于一个完全原生的端到端 JAX/XLA 堆栈。跨框架混合代码（例如，JAX 和 TensorFlow）的可能性将在未来的教程中进行讨论。\n",
        "\n",
        "我们一如既往地欢迎您的贡献。如果对 JAX/XLA 的支持或与其他 ML 框架的互操作能力对您来说很重要，请考虑帮助我们发展这些功能，使其与 TFF 的其他功能持平。\n",
        "\n",
        "## 开始之前\n",
        "\n",
        "关于如何配置您的环境，请参阅 TFF 文档的正文。根据运行本教程的位置，您可能希望取消注释并运行下面的部分或全部代码。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WuK9Wi9hT4Ch"
      },
      "outputs": [],
      "source": [
        "# !pip install --quiet --upgrade tensorflow-federated\n",
        "# !pip install --quiet --upgrade nest-asyncio\n",
        "# import nest_asyncio\n",
        "# nest_asyncio.apply()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0mcgo-lm6q9"
      },
      "source": [
        "本教程还假设您已经阅读了 TFF 的主要 TensorFlow 教程，并且熟悉 TFF 核心概念。如果您还没有阅读这些内容，请考虑至少审阅其中一个。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZgqoOutssD-e"
      },
      "source": [
        "## JAX 计算\n",
        "\n",
        "在 TFF 中对 JAX 的支持被设计成与 TFF 与 TensorFlow 互操作的方式对称，从导入开始："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NacZ6Aw6lZ_v"
      },
      "outputs": [],
      "source": [
        "import jax\n",
        "import numpy as np\n",
        "import tensorflow_federated as tff"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1yQB7evJlI_Z"
      },
      "source": [
        "此外，与 TensorFlow 一样，表达任何 TFF 代码的基础是本地运行的逻辑。如下所示，您可以使用 `@tff.jax_computation` 封装容器在 JAX 中表达该逻辑。它的行为类似于您现在所熟悉的 `@tff.tf_computation` 。我们先从简单的内容开始，例如，将两个整数相加的计算："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mu3ErwoOmqIG"
      },
      "outputs": [],
      "source": [
        "@tff.jax_computation(np.int32, np.int32)\n",
        "def add_numbers(x, y):\n",
        "  return jax.numpy.add(x, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-YIXXa4nkow"
      },
      "source": [
        "您可以像通常使用 TFF计 算一样使用上面定义的 JAX 计算。例如，您可以查看其类型签名，如下所示："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qTpGm32Onj-U"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'(<x=int32,y=int32> -> int32)'"
            ]
          },
          "execution_count": 4,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "str(add_numbers.type_signature)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2J8Pphy5rAJR"
      },
      "source": [
        "请注意，我们使用了 `np.int32` 来定义参数类型。TFF 不区分 Numpy 类型（如 `np.int32`）和 TensorFlow 类型（如 `tf.int32`）。从 TFF 的角度来看，它们只是指代同一事物的不同方式。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gff68zawrdB2"
      },
      "source": [
        "接下来，请记住 TFF 不是 Python（如果您不熟悉此内容，请查看我们之前的部分教程，如，有关自定义算法的内容）。您可以将 `@tff.jax_computation` 封装容器与任意可以跟踪和序列化的 JAX 代码一起使用，即您通常会使用 `@jax.jit` 进行注解并应被编译成 XLA 的代码（但您无需真的使用 `@jax.jit` 注解将 JAX 代码嵌入到 TFF 中）。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w--t1lDesKNg"
      },
      "source": [
        "实际上，TFF 会在底层立即将 JAX 计算编译成 XLA。您可以通过手动从 `add_numbers` 中提取和打印序列化的 XLA 代码来亲自查看，如下所示："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HCJlOjN3qumu"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'xla'"
            ]
          },
          "execution_count": 5,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "comp_pb = tff.framework.serialize_computation(add_numbers)\n",
        "comp_pb.WhichOneof('computation')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dBWGR0_gs8JJ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "HloModule xla_computation_add_numbers.7\n",
            "\n",
            "ENTRY xla_computation_add_numbers.7 {\n",
            "  constant.4 = pred[] constant(false)\n",
            "  parameter.1 = (s32[], s32[]) parameter(0)\n",
            "  get-tuple-element.2 = s32[] get-tuple-element(parameter.1), index=0\n",
            "  get-tuple-element.3 = s32[] get-tuple-element(parameter.1), index=1\n",
            "  add.5 = s32[] add(get-tuple-element.2, get-tuple-element.3)\n",
            "  ROOT tuple.6 = (s32[]) tuple(add.5)\n",
            "}\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "xla_code = jax.lib.xla_client.XlaComputation(comp_pb.xla.hlo_module.value)\n",
        "print(xla_code.as_hlo_text())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMOV9sbWtzNB"
      },
      "source": [
        "对于在 TensorFlow 表达的计算，可以将表示为 XLA 代码的 JAX 计算看作 `tf.GraphDef` 的功能对等项。它可移植并可在各种支持 XLA 的环境中执行，就像 `tf.GraphDef` 可以在任何 TensorFlow 运行时上执行一样。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPN_fjW4uEjg"
      },
      "source": [
        "TFF 提供了一个基于 XLA 编译器的运行时堆栈作为后端。可以通过以下方式激活："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DoIkNfhftp2r"
      },
      "outputs": [],
      "source": [
        "tff.backends.xla.set_local_python_execution_context()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrELxlxGucY0"
      },
      "source": [
        "现在，您可以执行我们上面定义的计算："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZLfwnzh5ubeA"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "execution_count": 8,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "add_numbers(2, 3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Flmb2lyGuhM6"
      },
      "source": [
        "很简单。我们来继续做一些更复杂的事情，比如 MNIST。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxbDbwa-w0rj"
      },
      "source": [
        "## 使用预设 API 的 MNIST 训练示例\n",
        "\n",
        "像往常一样，我们首先为数据批次和模型定义一组 TFF 类型（请记住，TFF 是一个强类型框架）。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AyAAQEtxu2Jg"
      },
      "outputs": [],
      "source": [
        "import collections\n",
        "\n",
        "BATCH_TYPE = collections.OrderedDict([\n",
        "    ('pixels', tff.TensorType(np.float32, (50, 784))),\n",
        "    ('labels', tff.TensorType(np.int32, (50,)))\n",
        "])\n",
        "\n",
        "MODEL_TYPE = collections.OrderedDict([\n",
        "    ('weights', tff.TensorType(np.float32, (784, 10))),\n",
        "    ('bias', tff.TensorType(np.float32, (10,)))\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4rCcC4lvBKm"
      },
      "source": [
        "现在，我们以模型和单批数据为参数，在 JAX 中为模型定义一个损失函数："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l7Y-PyVJvGlB"
      },
      "outputs": [],
      "source": [
        "def loss(model, batch):\n",
        "  y = jax.nn.softmax(\n",
        "      jax.numpy.add(\n",
        "          jax.numpy.matmul(batch['pixels'], model['weights']), model['bias']))\n",
        "  targets = jax.nn.one_hot(jax.numpy.reshape(batch['labels'], -1), 10)\n",
        "  return -jax.numpy.mean(jax.numpy.sum(targets * jax.numpy.log(y), axis=1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGnwZTjUxJi4"
      },
      "source": [
        "现在，一种方法是使用预设 API。<br>下面是一个示例，演示如何使用我们的 API 根据刚才定义的损失函数创建训练流程。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pSoB_jW3xfRd"
      },
      "outputs": [],
      "source": [
        "STEP_SIZE = 0.001\n",
        "\n",
        "trainer = tff.learning.build_jax_federated_averaging_process(\n",
        "    BATCH_TYPE, MODEL_TYPE, loss, STEP_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8TS_LDnxktY"
      },
      "source": [
        "您可以像使用 TensorFlow 中的 `tf.Keras` 模型的 trainer 构建一样，使用上面的代码。例如，以下是如何为训练创建初始模型的方法："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "roJas9RGx9Sv"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Struct([('weights', array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)), ('bias', array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32))])"
            ]
          },
          "execution_count": 12,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "initial_model = trainer.initialize()\n",
        "initial_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9Ii7c24yDcX"
      },
      "source": [
        "为了进行实际训练，我们需要一些数据。简单起见，我们随机生成数据。由于数据是随机的，我们将对训练数据进行评估，否则，对于随机评估数据，很难期望模型正常执行。此外，对于这个小规模演示，我们无需担心随机采样的客户端（我们会将其作为练习，让用户按照其他教程中的模板来探索这些类型的变化）："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z7hnu5QUwYOG"
      },
      "outputs": [],
      "source": [
        "def random_batch():\n",
        "  pixels = np.random.uniform(\n",
        "      low=0.0, high=1.0, size=(50, 784)).astype(np.float32)\n",
        "  labels = np.random.randint(low=0, high=9, size=(50,), dtype=np.int32)\n",
        "  return collections.OrderedDict([('pixels', pixels), ('labels', labels)])\n",
        "\n",
        "NUM_CLIENTS = 2\n",
        "NUM_BATCHES = 10\n",
        "\n",
        "train_data = [\n",
        "    [random_batch() for _ in range(NUM_BATCHES)]\n",
        "    for _ in range(NUM_CLIENTS)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tET5dIv3yoPR"
      },
      "source": [
        "有了这些准备工作，我们可以执行单个步骤的训练，如下所示："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c2BDLhjdyrtX"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Struct([('weights', array([[ 1.04456245e-04, -1.53498477e-05,  2.54597180e-05, ...,\n",
              "         5.61640409e-05, -5.32875274e-05, -4.62881755e-04],\n",
              "       [ 7.30908650e-05,  4.67643113e-05,  2.03352147e-06, ...,\n",
              "         3.77510623e-05,  3.52839161e-05, -4.59865667e-04],\n",
              "       [ 8.14835730e-05,  3.03147244e-05, -1.89143739e-05, ...,\n",
              "         1.12527239e-04,  4.09212225e-06, -4.59960109e-04],\n",
              "       ...,\n",
              "       [ 9.23552434e-05,  2.44302555e-06, -2.20817346e-05, ...,\n",
              "         7.61375341e-05,  1.76906979e-05, -4.43495519e-04],\n",
              "       [ 1.17451040e-04,  2.47748958e-05,  1.04728279e-05, ...,\n",
              "         5.26388249e-07,  7.21131510e-05, -4.67137404e-04],\n",
              "       [ 3.75041491e-05,  6.58061981e-05,  1.14522081e-05, ...,\n",
              "         2.52584141e-05,  3.55410739e-05, -4.30888613e-04]], dtype=float32)), ('bias', array([ 1.5096272e-04,  2.6502126e-05, -1.9462314e-05,  8.1269856e-05,\n",
              "        2.1832302e-04,  1.6636557e-04,  1.2815947e-04,  9.0642272e-05,\n",
              "        7.7109929e-05, -9.1987278e-04], dtype=float32))])"
            ]
          },
          "execution_count": 14,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trained_model = trainer.next(initial_model, train_data)\n",
        "trained_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCdbr2ivy2oW"
      },
      "source": [
        "我们来评估一下训练步骤的结果。简单起见，我们可以对其进行集中评估："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EgzZd7GEzMyi"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.3025854\n",
            "2.282762\n"
          ]
        }
      ],
      "source": [
        "import itertools\n",
        "eval_data = list(itertools.chain.from_iterable(train_data))\n",
        "\n",
        "def average_loss(model, data):\n",
        "  return np.mean([loss(model, batch) for batch in data])\n",
        "\n",
        "print (average_loss(initial_model, eval_data))\n",
        "print (average_loss(trained_model, eval_data))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhsYzZsM05Jd"
      },
      "source": [
        "损失正在减少。太棒了！现在，我们来多运行几轮："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nB1hZJyR1AN9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.2685437\n",
            "2.257856\n",
            "2.2495182\n",
            "2.2428129\n",
            "2.2372835\n",
            "2.2326245\n",
            "2.2286277\n",
            "2.2251441\n",
            "2.2220676\n",
            "2.219318\n",
            "2.2168345\n",
            "2.2145717\n",
            "2.2124937\n",
            "2.2105706\n",
            "2.2087805\n",
            "2.2071042\n",
            "2.2055268\n",
            "2.2040353\n",
            "2.2026198\n",
            "2.2012706\n"
          ]
        }
      ],
      "source": [
        "NUM_ROUNDS = 20\n",
        "for _ in range(NUM_ROUNDS):\n",
        "  trained_model = trainer.next(trained_model, train_data)\n",
        "  print(average_loss(trained_model, eval_data))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBC-Mp930_Yn"
      },
      "source": [
        "如您所见，尽管实验性 API 在功能上还不能与 TensorFlow API 相提并论，将 JAX 与 TFF 配合使用并没有太大的不同。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFg1CaGf1vqe"
      },
      "source": [
        "## 在底层\n",
        "\n",
        "如果您不喜欢使用我们的预设 API，您可以实现您自己的自定义计算。所用方法与您在 TensorFlow 的自定义算法教程中看到的大致相同，只是您将使用 JAX 的梯度下降机制。例如，下面是定义能够在单个 mini-batch 上更新模型的 JAX 计算的方法："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hw-p7DAN2G7B"
      },
      "outputs": [],
      "source": [
        "@tff.jax_computation(MODEL_TYPE, BATCH_TYPE)\n",
        "def train_on_one_batch(model, batch):\n",
        "  grads = jax.grad(loss)(model, batch)\n",
        "  return collections.OrderedDict([\n",
        "      (k, model[k] - STEP_SIZE * grads[k]) for k in ['weights', 'bias']\n",
        "  ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0pDsem22R6x"
      },
      "source": [
        "下面是测试其是否能够正常工作的方法："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LBB84zAO2Y4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.3025854\n",
            "2.2977567\n"
          ]
        }
      ],
      "source": [
        "sample_batch = random_batch()\n",
        "trained_model = train_on_one_batch(initial_model, sample_batch)\n",
        "print(average_loss(initial_model, [sample_batch]))\n",
        "print(average_loss(trained_model, [sample_batch]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SE99B3L3McK"
      },
      "source": [
        "使用 JAX 需要注意的一点是，它不提供与 `tf.data.Dataset` 相同的功能。因此，为了迭代数据集，您需要使用 TFF 的声明性结构来对序列进行操作，如下所示："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QT3rqv4x3ipO"
      },
      "outputs": [],
      "source": [
        "@tff.federated_computation(MODEL_TYPE, tff.SequenceType(BATCH_TYPE))\n",
        "def train_on_one_client(model, batches):\n",
        "  return tff.sequence_reduce(batches, model, train_on_one_batch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csx5qskW3quD"
      },
      "source": [
        "我们来了解一下它的工作方式："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y9-NLvAM3sE_"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.3025854\n",
            "2.2284968\n"
          ]
        }
      ],
      "source": [
        "sample_dataset = [random_batch() for _ in range(100)]\n",
        "trained_model = train_on_one_client(initial_model, sample_dataset)\n",
        "print(average_loss(initial_model, sample_dataset))\n",
        "print(average_loss(trained_model, sample_dataset))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2D0ApaBl4JMf"
      },
      "source": [
        "执行单轮训练的计算和您在 TensorFlow 教程中看到的一样："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RVqbU1p-9i2j"
      },
      "outputs": [],
      "source": [
        "@tff.federated_computation(\n",
        "    tff.FederatedType(MODEL_TYPE, tff.SERVER),\n",
        "    tff.FederatedType(tff.SequenceType(BATCH_TYPE), tff.CLIENTS))\n",
        "def train_one_round(model, federated_data):\n",
        "  locally_trained_models = tff.federated_map(\n",
        "      train_on_one_client,\n",
        "      collections.OrderedDict([\n",
        "          ('model', tff.federated_broadcast(model)),\n",
        "          ('batches', federated_data)]))\n",
        "  return tff.federated_mean(locally_trained_models)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHzYmP6K-HBs"
      },
      "source": [
        "我们来了解一下它的工作方式："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1XFsQxT2-GVT"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.3025854\n",
            "2.282762\n"
          ]
        }
      ],
      "source": [
        "trained_model = train_one_round(initial_model, train_data)\n",
        "print(average_loss(initial_model, eval_data))\n",
        "print(average_loss(trained_model, eval_data))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDiW1NgL9iT7"
      },
      "source": [
        "如您所见，在 TFF 中使用 JAX，无论是通过预设 API，还是直接使用低级 TFF 构造，都与将 TFF 与 TensorFlow 一起使用类似。请继续关注未来的更新，如果您希望看到对跨 ML 框架的互操作性的更好支持，请随时向我们发送拉取请求！"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "jax_support.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
