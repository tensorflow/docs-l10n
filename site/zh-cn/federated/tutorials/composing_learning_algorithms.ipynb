{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkdnLiKk71g-"
      },
      "source": [
        "##### Copyright 2022 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "0asMuNro71hA"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXslvcRocA-0"
      },
      "source": [
        "# 组合学习算法"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XBJJIqwcXKd"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>     <a target=\"_blank\" href=\"https://tensorflow.google.cn/federated/tutorials/composing_learning_algorithms\"><img src=\"https://tensorflow.google.cn/images/tf_logo_32px.png\">在 TensorFlow.org 上查看</a> </td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/zh-cn/federated/tutorials/composing_learning_algorithms.ipynb\"><img src=\"https://tensorflow.google.cn/images/colab_logo_32px.png\">在 Google Colab 中运行</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/zh-cn/federated/tutorials/composing_learning_algorithms.ipynb\"><img src=\"https://tensorflow.google.cn/images/GitHub-Mark-32px.png\">在 GitHub 上查看源代码</a>\n",
        "</td>\n",
        "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/zh-cn/federated/tutorials/composing_learning_algorithms.ipynb\"><img src=\"https://tensorflow.google.cn/images/download_logo_32px.png\">下载笔记本</a>   </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnUwFbCAKB2r"
      },
      "source": [
        "## 准备工作\n",
        "\n",
        "开始之前，请运行以下代码来确保您的环境已正确设置。如果未看到问候语，请参阅[安装](../install.md)指南查看说明。 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZrGitA_KnRO0"
      },
      "outputs": [],
      "source": [
        "#@test {\"skip\": true}\n",
        "!pip install --quiet --upgrade tensorflow-federated\n",
        "!pip install --quiet --upgrade nest-asyncio\n",
        "\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HGTM6tWOLo8M"
      },
      "outputs": [],
      "source": [
        "from typing import Callable\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_federated as tff"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yr3ztf28fa1F"
      },
      "source": [
        "**注**：本 Colab 已通过验证，可与[最新发布版本](https://github.com/tensorflow/federated#compatibility)的 `tensorflow_federated` pip 软件包一起使用，但 Tensorflow Federated 项目仍处于预发布开发阶段，可能无法在 `main` 上运行。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFlTaHe0jV2S"
      },
      "source": [
        "# 组合学习算法"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zQlyijofSzI"
      },
      "source": [
        "[构建您自己的联合学习算法教程](https://github.com/tensorflow/federated/blob/v0.36.0/docs/tutorials/building_your_own_federated_learning_algorithm.ipynb)使用 TFF 的 Federated Core 直接实现了联合平均 (FedAvg) 算法的一个版本。\n",
        "\n",
        "在本教程中，您将使用 TFF 的 API 中的联合学习组件以模块化方式构建联合学习算法，而无需从头开始重新实现所有内容。\n",
        "\n",
        "出于本教程的目的，您将实现能够在局部训练中使用梯度裁剪的 FedAvg 的变体。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHwcFnLAjqcG"
      },
      "source": [
        "## 学习算法构建块\n",
        "\n",
        "概括来讲，许多学习算法都可以划分为四大独立组件，称为**构建块**。包括：\n",
        "\n",
        "1. 分发器（即服务器到客户端的通信）\n",
        "2. 客户端工作（即本地客户端计算）\n",
        "3. 聚合器（即客户端到服务器的通信）\n",
        "4. 终结器（即使用聚合客户端输出的服务器计算）"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwhOtjlvjboB"
      },
      "source": [
        "[构建您自己的联合学习算法教程](https://github.com/tensorflow/federated/blob/v0.36.0/docs/tutorials/building_your_own_federated_learning_algorithm.ipynb)从头开始实现了上述所有构建块，但通常不必这样做。相反，您可以重用相似算法的构建块。\n",
        "\n",
        "在这种情况下，要实现采用梯度裁剪的 FedAvg，只需修改**客户端工作**构建块即可。其余块可以与普通 FedAvg 中使用块的相同。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMnd0RvGlGjK"
      },
      "source": [
        "# 实现客户端工作\n",
        "\n",
        "首先，让我们编写采用梯度裁剪进行本地模型训练的 TF 逻辑。为简单起见，裁剪梯度的范数最大为 1。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lqZ-c4MphTU"
      },
      "source": [
        "## TF 逻辑"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pIw7QQCqltdV"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def client_update(model: tff.learning.Model,\n",
        "                  dataset: tf.data.Dataset,\n",
        "                  server_weights: tff.learning.ModelWeights,\n",
        "                  client_optimizer: tf.keras.optimizers.Optimizer):\n",
        "  \"\"\"Performs training (using the server model weights) on the client's dataset.\"\"\"\n",
        "  # Initialize the client model with the current server weights.\n",
        "  client_weights = tff.learning.ModelWeights.from_model(model)\n",
        "  tf.nest.map_structure(lambda x, y: x.assign(y),\n",
        "                        client_weights, server_weights)\n",
        "\n",
        "  # Use the client_optimizer to update the local model.\n",
        "  # Keep track of the number of examples as well.\n",
        "  num_examples = 0.0\n",
        "  for batch in dataset:\n",
        "    with tf.GradientTape() as tape:\n",
        "      # Compute a forward pass on the batch of data\n",
        "      outputs = model.forward_pass(batch)\n",
        "      num_examples += tf.cast(outputs.num_examples, tf.float32)\n",
        "\n",
        "    # Compute the corresponding gradient\n",
        "    grads = tape.gradient(outputs.loss, client_weights.trainable)\n",
        "\n",
        "    # Compute the gradient norm and clip\n",
        "    gradient_norm = tf.linalg.global_norm(grads)\n",
        "    if gradient_norm > 1:\n",
        "      grads = tf.nest.map_structure(lambda x: x/gradient_norm, grads)\n",
        "\n",
        "    grads_and_vars = zip(grads, client_weights.trainable)\n",
        "\n",
        "    # Apply the gradient using a client optimizer.\n",
        "    client_optimizer.apply_gradients(grads_and_vars)\n",
        "\n",
        "  # Compute the difference between the server weights and the client weights\n",
        "  client_update = tf.nest.map_structure(tf.subtract,\n",
        "                                        client_weights.trainable,\n",
        "                                        server_weights.trainable)\n",
        "\n",
        "  return tff.learning.templates.ClientResult(\n",
        "      update=client_update, update_weight=num_examples)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fe_emK8LpQe0"
      },
      "source": [
        "关于上方代码，有几个要点。首先，它会跟踪所见样本的数量，因为这将构成客户端更新的*权重*（计算客户端的平均值时）。\n",
        "\n",
        "其次，它会使用 [`tff.learning.templates.ClientResult`](https://tensorflow.google.cn/federated/api_docs/python/tff/learning/templates/ClientResult) 来包装输出。此返回类型用于标准化 `tff.learning` 中的客户端工作构建块。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5aKjB1Vpiv3"
      },
      "source": [
        "## 创建 ClientWorkProcess"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6IvXUJAzm8ab"
      },
      "source": [
        "虽然上方的 TF 逻辑将采用裁剪进行本地训练，但仍需要将其包装在 TFF 代码中以创建必要的构建块。\n",
        "\n",
        "具体而言，这 4 个构建块将表示为 [`tff.templates.MeasuredProcess`](https://tensorflow.google.cn/federated/api_docs/python/tff/templates/MeasuredProcess)。这意味着 4 个块均具有用于实例化和运行计算的 `initialize` 和 `next` 函数。\n",
        "\n",
        "这使每个构建块都可以根据需要跟踪自己的**状态**（存储在服务器上）以执行其运算。虽然本教程中不予使用，但它可用于跟踪发生了多少次迭代，或跟踪优化器状态等用途。\n",
        "\n",
        "客户端工作 TF 逻辑通常应包装为 [`tff.learning.templates.ClientWorkProcess`](https://tensorflow.google.cn/federated/api_docs/python/tff/learning/templates/ClientWorkProcess)，它可以编码进出客户端局部训练的预期类型。它可以由模型和优化器进行参数化，如下所示。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X-I-jPsZmmMy"
      },
      "outputs": [],
      "source": [
        "def build_gradient_clipping_client_work(\n",
        "    model_fn: Callable[[], tff.learning.Model],\n",
        "    optimizer_fn: Callable[[], tf.keras.optimizers.Optimizer],\n",
        ") -> tff.learning.templates.ClientWorkProcess:\n",
        "  \"\"\"Creates a client work process that uses gradient clipping.\"\"\"\n",
        "\n",
        "  with tf.Graph().as_default():\n",
        "    # Wrap model construction in a graph to avoid polluting the global context\n",
        "    # with variables created for this model.\n",
        "    model = model_fn()\n",
        "  data_type = tff.SequenceType(model.input_spec)\n",
        "  model_weights_type = tff.learning.framework.weights_type_from_model(model)\n",
        "\n",
        "  @tff.federated_computation\n",
        "  def initialize_fn():\n",
        "    return tff.federated_value((), tff.SERVER)\n",
        "\n",
        "  @tff.tf_computation(model_weights_type, data_type)\n",
        "  def client_update_computation(model_weights, dataset):\n",
        "    model = model_fn()\n",
        "    optimizer = optimizer_fn()\n",
        "    return client_update(model, dataset, model_weights, optimizer)\n",
        "\n",
        "  @tff.federated_computation(\n",
        "      initialize_fn.type_signature.result,\n",
        "      tff.type_at_clients(model_weights_type),\n",
        "      tff.type_at_clients(data_type)\n",
        "  )\n",
        "  def next_fn(state, model_weights, client_dataset):\n",
        "    client_result = tff.federated_map(\n",
        "        client_update_computation, (model_weights, client_dataset))\n",
        "    # Return empty measurements, though a more complete algorithm might\n",
        "    # measure something here.\n",
        "    measurements = tff.federated_value((), tff.SERVER)\n",
        "    return tff.templates.MeasuredProcessOutput(state, client_result,\n",
        "                                               measurements)\n",
        "  return tff.learning.templates.ClientWorkProcess(\n",
        "      initialize_fn, next_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMUX0d0Sx1Gq"
      },
      "source": [
        "# 组合学习算法\n",
        "\n",
        "让我们将上方的客户端工作置于成熟的算法中。首先，让我们设置我们的数据和模型。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQ_N9XbULo8P"
      },
      "source": [
        "## 准备输入数据\n",
        "\n",
        "加载和预处理包含在 TFF 中的 EMNIST 数据集。有关详情，请参阅[图像分类](federated_learning_for_image_classification.ipynb)教程。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-WdnFluLLo8P"
      },
      "outputs": [],
      "source": [
        "emnist_train, emnist_test = tff.simulation.datasets.emnist.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kq8893GogB8E"
      },
      "source": [
        "为了将数据集馈送到我们的模型中，数据将被展平并转换为 `(flattened_image_vector, label)` 形式的元组。\n",
        "\n",
        "让我们选择少量客户端，并将上述预处理应用于其数据集。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Blrh8zJgLo8R"
      },
      "outputs": [],
      "source": [
        "NUM_CLIENTS = 10\n",
        "BATCH_SIZE = 20\n",
        "\n",
        "def preprocess(dataset):\n",
        "\n",
        "  def batch_format_fn(element):\n",
        "    \"\"\"Flatten a batch of EMNIST data and return a (features, label) tuple.\"\"\"\n",
        "    return (tf.reshape(element['pixels'], [-1, 784]), \n",
        "            tf.reshape(element['label'], [-1, 1]))\n",
        "\n",
        "  return dataset.batch(BATCH_SIZE).map(batch_format_fn)\n",
        "\n",
        "client_ids = sorted(emnist_train.client_ids)[:NUM_CLIENTS]\n",
        "federated_train_data = [preprocess(emnist_train.create_tf_dataset_for_client(x))\n",
        "  for x in client_ids\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNO_Y9j_Lo8X"
      },
      "source": [
        "## 准备模型"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJ0I89ixz8yV"
      },
      "source": [
        "此处使用与[图像分类](federated_learning_for_image_classification.ipynb)教程中相同的模型。此模型（通过 `tf.keras` 实现）具有一个隐藏层，随后是一个 softmax 层。为了在 TFF 中使用此模型，Keras 模型被包装为 [`tff.learning.Model`](https://tensorflow.google.cn/federated/api_docs/python/tff/learning/Model)。这使我们可以在 TFF 中执行模型的[前向传递](https://tensorflow.google.cn/federated/api_docs/python/tff/learning/Model#forward_pass)，并[提取模型输出](https://tensorflow.google.cn/federated/api_docs/python/tff/learning/Model#report_local_unfinalized_metrics)。有关详情，另请参阅[图像分类](federated_learning_for_image_classification.ipynb)教程。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yfld4oFNLo8Y"
      },
      "outputs": [],
      "source": [
        "def create_keras_model():\n",
        "  initializer = tf.keras.initializers.GlorotNormal(seed=0)\n",
        "  return tf.keras.models.Sequential([\n",
        "      tf.keras.layers.Input(shape=(784,)),\n",
        "      tf.keras.layers.Dense(10, kernel_initializer=initializer),\n",
        "      tf.keras.layers.Softmax(),\n",
        "  ])\n",
        "\n",
        "def model_fn():\n",
        "  keras_model = create_keras_model()\n",
        "  return tff.learning.from_keras_model(\n",
        "      keras_model,\n",
        "      input_spec=federated_train_data[0].element_spec,\n",
        "      loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7BPxQoGH0bEl"
      },
      "source": [
        "## 准备优化器"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRw9zwdh0dnL"
      },
      "source": [
        "就像在 [`tff.learning.algorithms.build_weighted_fed_avg`](https://tensorflow.google.cn/federated/api_docs/python/tff/learning/algorithms/build_weighted_fed_avg) 中一样，此处有两个优化器：客户端优化器和服务器优化器。为简单起见，优化器将为具有不同学习率的 SGD。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kOO1ObqJ0cmX"
      },
      "outputs": [],
      "source": [
        "client_optimizer_fn = lambda: tf.keras.optimizers.SGD(learning_rate=0.01)\n",
        "server_optimizer_fn = lambda: tf.keras.optimizers.SGD(learning_rate=1.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R64okB7k06sc"
      },
      "source": [
        "## 定义构建块\n",
        "\n",
        "客户端工作构建块、数据、模型和优化器现已设置完成，接下来还要为分发器、聚合器和终结器创建构建块。这可以通过借用 TFF 中可用并由 FedAvg 使用的一些默认值来完成。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iwXOTPeIx2nx"
      },
      "outputs": [],
      "source": [
        "@tff.tf_computation()\n",
        "def initial_model_weights_fn():\n",
        "  return tff.learning.ModelWeights.from_model(model_fn())\n",
        "\n",
        "model_weights_type = initial_model_weights_fn.type_signature.result\n",
        "\n",
        "distributor = tff.learning.templates.build_broadcast_process(model_weights_type)\n",
        "client_work = build_gradient_clipping_client_work(model_fn, client_optimizer_fn)\n",
        "\n",
        "# TFF aggregators use a factory pattern, which create an aggregator\n",
        "# based on the output type of the client work. This also uses a float (the number\n",
        "# of examples) to govern the weight in the average being computed.)\n",
        "aggregator_factory = tff.aggregators.MeanFactory()\n",
        "aggregator = aggregator_factory.create(model_weights_type.trainable,\n",
        "                                       tff.TensorType(tf.float32))\n",
        "finalizer = tff.learning.templates.build_apply_optimizer_finalizer(\n",
        "    server_optimizer_fn, model_weights_type)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEYYNHqI1Jif"
      },
      "source": [
        "## 组合构建块\n",
        "\n",
        "最后，您可以使用 TFF 中的内置**组合器**将构建块组合到一起。这是一种相对简单的组合器，采用上方的 4 个构建块并将它们的类型连接在一起。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z_86iNeM0IBm"
      },
      "outputs": [],
      "source": [
        "fed_avg_with_clipping = tff.learning.templates.compose_learning_process(\n",
        "    initial_model_weights_fn,\n",
        "    distributor,\n",
        "    client_work,\n",
        "    aggregator,\n",
        "    finalizer\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcK69pCG16-E"
      },
      "source": [
        "# 运行算法\n",
        "\n",
        "算法现已就绪，让我们运行该算法。首先**初始化**该算法。该算法的**状态**对于每个构建块都有一个组件，以及一个用于*全局模型权重*的组件。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jg22oFx11YKK"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "()"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "state = fed_avg_with_clipping.initialize()\n",
        "\n",
        "state.client_work"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmCiEdoq2doJ"
      },
      "source": [
        "正如预期，客户端工作具有空状态（请记住上方的客户端工作代码！）。但是，其他构建块可能具有非空状态。例如，终结器会跟踪发生了多少次迭代。由于 `next` 尚未运行，它的状态为 `0`。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kEuB-8Z71-bd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0]"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "state.finalizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2N9XObhZ2zSQ"
      },
      "source": [
        "现在进行一轮训练。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tKhPuBgW1-3c"
      },
      "outputs": [],
      "source": [
        "learning_process_output = fed_avg_with_clipping.next(state, federated_train_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7L0jKEe29bk"
      },
      "source": [
        "此项的输出 (`tff.learning.templates.LearningProcessOutput`) 具有 `.state` 和 `.metrics` 输出。让我们看看这两者。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AMsBmmQz28AZ"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[1]"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "learning_process_output.state.finalizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwcfhAbP3VkH"
      },
      "source": [
        "显然，由于已经运行了一轮 `.next`，终结器状态递增 1。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0K91G_Ob3E05"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "OrderedDict([('distributor', ()),\n",
              "             ('client_work', ()),\n",
              "             ('aggregator',\n",
              "              OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "             ('finalizer', ())])"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "learning_process_output.metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sDyO9uz3Jaz"
      },
      "source": [
        "虽然指标为空，但对于更加复杂和实际的算法，它们通常会包含大量实用信息。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPpxe7Ie3gLJ"
      },
      "source": [
        "# 结论"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8uEZw-T3iBB"
      },
      "source": [
        "通过使用上述构建块/组合器框架，您无需从头开始重新处理所有内容，即可创建全新的学习算法。然而，这只是起点。这个框架使通过简单修改 FedAvg 的形式表达算法变得更加容易。有关更多算法，请参阅 [`tff.learning.algorithms`](https://tensorflow.google.cn/federated/api_docs/python/tff/learning/algorithms)，其中包含诸如 [FedProx](https://tensorflow.google.cn/federated/api_docs/python/tff/learning/algorithms/build_weighted_fed_prox) 和[客户端学习率调度 FedAvg](https://tensorflow.google.cn/federated/api_docs/python/tff/learning/algorithms/build_weighted_fed_avg_with_optimizer_schedule) 等算法。这些 API 甚至可以帮助实现诸如[联合 K 均值聚类](https://tensorflow.google.cn/federated/api_docs/python/tff/learning/algorithms/build_fed_kmeans)等全新算法。"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "composing_learning_algorithms.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
