{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjUA6S30k52h"
      },
      "source": [
        "##### Copyright 2021 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "SpNWyqewk8fE"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6x1ypzczQCwy"
      },
      "source": [
        "# 使用 TFX 流水线和 TensorFlow Data Validation 进行数据验证"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HU9YYythm0dx"
      },
      "source": [
        "注：我们建议在 Colab 笔记本中运行本教程，无需进行设置！只需点击“在 Google Colab 中运行”。\n",
        "\n",
        "<div class=\"devsite-table-wrapper\"><table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "<td><a target=\"_blank\" href=\"https://tensorflow.google.cn/tfx/tutorials/tfx/penguin_tfdv\"> <img src=\"https://tensorflow.google.cn/images/tf_logo_32px.png\">在 TensorFlow.org 上查看</a></td>\n",
        "<td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/zh-cn/tfx/tutorials/tfx/penguin_tfdv.ipynb\"> <img src=\"https://tensorflow.google.cn/images/colab_logo_32px.png\">在 Google Colab 中运行</a></td>\n",
        "<td><a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/zh-cn/tfx/tutorials/tfx/penguin_tfdv.ipynb\"> <img width=\"32px\" src=\"https://tensorflow.google.cn/images/GitHub-Mark-32px.png\">在 GitHub 上查看源代码</a></td>\n",
        "<td><a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/zh-cn/tfx/tutorials/tfx/penguin_tfdv.ipynb\"><img src=\"https://tensorflow.google.cn/images/download_logo_32px.png\">下载笔记本</a></td>\n",
        "</table></div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_VuwrlnvQJ5k"
      },
      "source": [
        "在这个基于笔记本的教程中，我们将创建和运行 TFX 流水线来验证输入数据并创建机器学习模型。此笔记本基于我们在[简单 TFX 流水线教程](https://tensorflow.google.cn/tfx/tutorials/tfx/penguin_simple)中构建的 TFX 流水线。如果您尚未阅读该教程，请先阅读，然后再继续此笔记本。\n",
        "\n",
        "所有数据科学或机器学习项目的第一项任务都是理解和清理数据，其中包括：\n",
        "\n",
        "- 理解每个特征的数据类型、分布和其他信息（例如，平均值或唯一值的个数）\n",
        "- 生成描述数据的初步架构\n",
        "- 针对给定架构识别数据中的异常和缺失值\n",
        "\n",
        "在本教程中，我们将创建两个 TFX 流水线。\n",
        "\n",
        "首先，我们将创建一个流水线来分析数据集并生成给定数据集的初步架构。此流水线将包含两个新组件：`StatisticsGen` 和 `SchemaGen`。\n",
        "\n",
        "拥有适当的数据架构后，我们将创建一个流水线以基于上一个教程中的流水线来训练机器学习分类模型。在此流水线中，我们将使用第一个流水线中的架构和一个新的组件 `ExampleValidator` 来验证输入数据。\n",
        "\n",
        "StatisticsGen、SchemaGen 和 ExampleValidator 这三个新组件是用于数据分析和验证的 TFX 组件，它们是使用 [TensorFlow Data Validation](https://tensorflow.google.cn/tfx/guide/tfdv) 库实现的。\n",
        "\n",
        "要详细了解 TFX 中的各种概念，请参阅[了解 TFX 流水线](https://tensorflow.google.cn/tfx/guide/understanding_tfx_pipelines)。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fmgi8ZvQkScg"
      },
      "source": [
        "## 安装\n",
        "\n",
        "我们首先需要安装 TFX Python 软件包并下载将用于模型的数据集。\n",
        "\n",
        "### 升级 Pip\n",
        "\n",
        "为了避免在本地运行时升级系统中的 Pip，请检查以确保在 Colab 中运行。当然，可以对本地系统单独升级。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "as4OTe2ukSqm"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  import colab\n",
        "  !pip install --upgrade pip\n",
        "except:\n",
        "  pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZOYTt1RW4TK"
      },
      "source": [
        "### 安装 TFX\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iyQtljP-qPHY"
      },
      "outputs": [],
      "source": [
        "!pip install -U tfx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwT0nov5QO1M"
      },
      "source": [
        "### 是否已重新启动运行时？\n",
        "\n",
        "如果您使用的是 Google Colab，则在首次运行上面的代码单元时必须重新启动运行时，方法是点击上面的“RESTART RUNTIME”按钮或使用“Runtime &gt; Restart runtime ...”菜单。这样做的原因是 Colab 加载软件包的方式。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDnPgN8UJtzN"
      },
      "source": [
        "检查 TensorFlow 和 TFX 版本。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6jh7vKSRqPHb"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "print('TensorFlow version: {}'.format(tf.__version__))\n",
        "from tfx import v1 as tfx\n",
        "print('TFX version: {}'.format(tfx.__version__))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDtLdSkvqPHe"
      },
      "source": [
        "### 设置变量\n",
        "\n",
        "有一些变量用于定义流水线。您可以根据需要自定义这些变量。默认情况下，流水线的所有输出都将在当前目录下生成。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EcUseqJaE2XN"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# We will create two pipelines. One for schema generation and one for training.\n",
        "SCHEMA_PIPELINE_NAME = \"penguin-tfdv-schema\"\n",
        "PIPELINE_NAME = \"penguin-tfdv\"\n",
        "\n",
        "# Output directory to store artifacts generated from the pipeline.\n",
        "SCHEMA_PIPELINE_ROOT = os.path.join('pipelines', SCHEMA_PIPELINE_NAME)\n",
        "PIPELINE_ROOT = os.path.join('pipelines', PIPELINE_NAME)\n",
        "# Path to a SQLite DB file to use as an MLMD storage.\n",
        "SCHEMA_METADATA_PATH = os.path.join('metadata', SCHEMA_PIPELINE_NAME,\n",
        "                                    'metadata.db')\n",
        "METADATA_PATH = os.path.join('metadata', PIPELINE_NAME, 'metadata.db')\n",
        "\n",
        "# Output directory where created models from the pipeline will be exported.\n",
        "SERVING_MODEL_DIR = os.path.join('serving_model', PIPELINE_NAME)\n",
        "\n",
        "from absl import logging\n",
        "logging.set_verbosity(logging.INFO)  # Set default logging level."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsO0l5F3dzOr"
      },
      "source": [
        "### 准备样本数据\n",
        "\n",
        "我们将下载要在我们的 TFX 流水线中使用的样本数据集。我们要使用的数据集为 [Palmer Penguins 数据集](https://allisonhorst.github.io/palmerpenguins/articles/intro.html)，该数据集也在其他 [TFX 示例](https://github.com/tensorflow/tfx/tree/master/tfx/examples/penguin)中使用。\n",
        "\n",
        "该数据集中有四个数字特征：\n",
        "\n",
        "- culmen_length_mm\n",
        "- culmen_depth_mm\n",
        "- flipper_length_mm\n",
        "- body_mass_g\n",
        "\n",
        "所有特征均已归一化为具有范围 [0,1]。我们将建立一个预测企鹅 `species` 的分类模型。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IjE8MkZidzO0"
      },
      "source": [
        "由于 TFX ExampleGen 组件从目录中读取输入，我们需要创建一个目录并将数据集复制到其中。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZSfs6qFgdzO1"
      },
      "outputs": [],
      "source": [
        "import urllib.request\n",
        "import tempfile\n",
        "\n",
        "DATA_ROOT = tempfile.mkdtemp(prefix='tfx-data')  # Create a temporary directory.\n",
        "_data_url = 'https://raw.githubusercontent.com/tensorflow/tfx/master/tfx/examples/penguin/data/labelled/penguins_processed.csv'\n",
        "_data_filepath = os.path.join(DATA_ROOT, \"data.csv\")\n",
        "urllib.request.urlretrieve(_data_url, _data_filepath)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5s3wGpndzO1"
      },
      "source": [
        "快速浏览一下 CSV 文件。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nLn9ith2dzO1"
      },
      "outputs": [],
      "source": [
        "!head {_data_filepath}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8EOfCy1dzO2"
      },
      "source": [
        "您应该能够看到五个特征列。`species` 为 0、1 或 2 之一，所有其他特征的值应介于 0 和 1 之间。我们将创建一个 TFX 流水线来分析此数据集。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePhfeYv0fVu1"
      },
      "source": [
        "## 生成初步架构\n",
        "\n",
        "TFX 流水线是使用 Python API 定义的。我们将创建一个流水线以自动从输入样本生成架构。该架构可由人工审核并根据需要进行调整。架构生成后，就可用于后续任务中的训练和样本验证了。\n",
        "\n",
        "除了在[简单 TFX 流水线教程](https://tensorflow.google.cn/tfx/tutorials/tfx/penguin_simple)中使用的 `CsvExampleGen` 之外，我们还将使用 `StatisticsGen` 和 `SchemaGen`：\n",
        "\n",
        "- [StatisticsGen](https://tensorflow.google.cn/tfx/guide/statsgen) 用于计算数据集的统计信息。\n",
        "- [SchemaGen](https://tensorflow.google.cn/tfx/guide/schemagen) 用于检查统计信息并创建初始数据架构。\n",
        "\n",
        "请参阅每个组件的指南或 [TFX 组件教程](https://tensorflow.google.cn/tfx/tutorials/tfx/components_keras)以详细了解这些组件。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUFq55kCgwsm"
      },
      "source": [
        "### 编写流水线定义\n",
        "\n",
        "我们定义一个函数来创建 TFX 流水线。`Pipeline` 对象表示 TFX 流水线，可以使用 TFX 支持的流水线编排系统之一来运行。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GfQ6FAk9gxJ2"
      },
      "outputs": [],
      "source": [
        "def _create_schema_pipeline(pipeline_name: str,\n",
        "                            pipeline_root: str,\n",
        "                            data_root: str,\n",
        "                            metadata_path: str) -> tfx.dsl.Pipeline:\n",
        "  \"\"\"Creates a pipeline for schema generation.\"\"\"\n",
        "  # Brings data into the pipeline.\n",
        "  example_gen = tfx.components.CsvExampleGen(input_base=data_root)\n",
        "\n",
        "  # NEW: Computes statistics over data for visualization and schema generation.\n",
        "  statistics_gen = tfx.components.StatisticsGen(\n",
        "      examples=example_gen.outputs['examples'])\n",
        "\n",
        "  # NEW: Generates schema based on the generated statistics.\n",
        "  schema_gen = tfx.components.SchemaGen(\n",
        "      statistics=statistics_gen.outputs['statistics'], infer_feature_shape=True)\n",
        "\n",
        "  components = [\n",
        "      example_gen,\n",
        "      statistics_gen,\n",
        "      schema_gen,\n",
        "  ]\n",
        "\n",
        "  return tfx.dsl.Pipeline(\n",
        "      pipeline_name=pipeline_name,\n",
        "      pipeline_root=pipeline_root,\n",
        "      metadata_connection_config=tfx.orchestration.metadata\n",
        "      .sqlite_metadata_connection_config(metadata_path),\n",
        "      components=components)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RuKFLI_Og2xr"
      },
      "source": [
        "### 运行流水线\n",
        "\n",
        "我们将像上一教程一样使用 `LocalDagRunner`。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BQspf0ajg9AO"
      },
      "outputs": [],
      "source": [
        "tfx.orchestration.LocalDagRunner().run(\n",
        "  _create_schema_pipeline(\n",
        "      pipeline_name=SCHEMA_PIPELINE_NAME,\n",
        "      pipeline_root=SCHEMA_PIPELINE_ROOT,\n",
        "      data_root=DATA_ROOT,\n",
        "      metadata_path=SCHEMA_METADATA_PATH))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VD4LsLHBi2O4"
      },
      "source": [
        "如果流水线成功完成，您应该看到“INFO:absl:Component SchemaGen is finished.”。\n",
        "\n",
        "我们将检查流水线的输出，以便了解我们的数据集。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWpckstgg9Zs"
      },
      "source": [
        "### 检查流水线的输出"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tL1wWoDh5wkj"
      },
      "source": [
        "如上一教程所述，TFX 流水线会生成两种输出：工件和[元数据 DB(MLMD)](https://tensorflow.google.cn/tfx/guide/mlmd)，其中包含工件和流水线执行的元数据。我们在上方单元中定义了这些输出的位置。默认情况下，工件存储在 `pipelines` 目录下，元数据以 sqlite 数据库形式存储在 `metadata` 目录下。\n",
        "\n",
        "您可以使用 MLMD API 以编程方式定位这些输出。首先，我们将定义一些效用函数来搜索刚刚生成的输出工件。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K0i_jTvOI8mv"
      },
      "outputs": [],
      "source": [
        "from ml_metadata.proto import metadata_store_pb2\n",
        "# Non-public APIs, just for showcase.\n",
        "from tfx.orchestration.portable.mlmd import execution_lib\n",
        "\n",
        "# TODO(b/171447278): Move these functions into the TFX library.\n",
        "\n",
        "def get_latest_artifacts(metadata, pipeline_name, component_id):\n",
        "  \"\"\"Output artifacts of the latest run of the component.\"\"\"\n",
        "  context = metadata.store.get_context_by_type_and_name(\n",
        "      'node', f'{pipeline_name}.{component_id}')\n",
        "  executions = metadata.store.get_executions_by_context(context.id)\n",
        "  latest_execution = max(executions,\n",
        "                         key=lambda e:e.last_update_time_since_epoch)\n",
        "  return execution_lib.get_artifacts_dict(metadata, latest_execution.id,\n",
        "                                          [metadata_store_pb2.Event.OUTPUT])\n",
        "\n",
        "# Non-public APIs, just for showcase.\n",
        "from tfx.orchestration.experimental.interactive import visualizations\n",
        "\n",
        "def visualize_artifacts(artifacts):\n",
        "  \"\"\"Visualizes artifacts using standard visualization modules.\"\"\"\n",
        "  for artifact in artifacts:\n",
        "    visualization = visualizations.get_registry().get_visualization(\n",
        "        artifact.type_name)\n",
        "    if visualization:\n",
        "      visualization.display(artifact)\n",
        "\n",
        "from tfx.orchestration.experimental.interactive import standard_visualizations\n",
        "standard_visualizations.register_standard_visualizations()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2CE1dk_3irPL"
      },
      "source": [
        "现在，我们可以检查流水线执行的输出。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hRKSjXzsiqh0"
      },
      "outputs": [],
      "source": [
        "# Non-public APIs, just for showcase.\n",
        "from tfx.orchestration.metadata import Metadata\n",
        "from tfx.types import standard_component_specs\n",
        "\n",
        "metadata_connection_config = tfx.orchestration.metadata.sqlite_metadata_connection_config(\n",
        "    SCHEMA_METADATA_PATH)\n",
        "\n",
        "with Metadata(metadata_connection_config) as metadata_handler:\n",
        "  # Find output artifacts from MLMD.\n",
        "  stat_gen_output = get_latest_artifacts(metadata_handler, SCHEMA_PIPELINE_NAME,\n",
        "                                         'StatisticsGen')\n",
        "  stats_artifacts = stat_gen_output[standard_component_specs.STATISTICS_KEY]\n",
        "\n",
        "  schema_gen_output = get_latest_artifacts(metadata_handler,\n",
        "                                           SCHEMA_PIPELINE_NAME, 'SchemaGen')\n",
        "  schema_artifacts = schema_gen_output[standard_component_specs.SCHEMA_KEY]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9e8i0K-Aiqh-"
      },
      "source": [
        "是时候检查每个组件的输出了。如上所述，在 `StatisticsGen` 和 `SchemaGen` 中使用了 [Tensorflow Data Validation(TFDV)](https://tensorflow.google.cn/tfx/data_validation/get_started)，并且 TFDV 还提供了这些组件输出的呈现。\n",
        "\n",
        "在本教程中，我们将使用 TFX 中的呈现辅助方法，它们会在内部使用 TFDV 来显示呈现效果。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRGC4X1Ziqh-"
      },
      "source": [
        "#### 检查 StatisticsGen 的输出\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3StnKm04iqh-"
      },
      "outputs": [],
      "source": [
        "# docs-infra: no-execute\n",
        "visualize_artifacts(stats_artifacts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPfVPFTW0Jh2"
      },
      "source": [
        "<!-- <img class=\"tfo-display-only-on-site\"\n",
        "src=\"images/penguin_tfdv/penguin_tfdv_statistics.png\"/> -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yS1XXFtfiqh-"
      },
      "source": [
        "您可以查看输入数据的各种统计信息。这些统计信息会提供给 `SchemaGen` 以自动构造数据初始架构。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20HK9JS7iqh-"
      },
      "source": [
        "#### 检查 SchemaGen 的输出\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MVmlot5ziqh_"
      },
      "outputs": [],
      "source": [
        "visualize_artifacts(schema_artifacts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ldXsv2iiqh_"
      },
      "source": [
        "此架构由 StatisticsGen 的输出自动推断而来。您应该能够看到 4 个浮点数特征和 1 个整数特征。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKpFPwEWhCoB"
      },
      "source": [
        "### 导出架构以供将来使用\n",
        "\n",
        "我们需要检查和细化生成的架构。架构经检查后，需要持续用于后续的机器学习模型训练流水线中。换言之，您可能需要将架构文件添加到您的版本控制系统以便用于实际用例。在本教程中，为了简单起见，我们仅将架构复制到预定义的文件系统路径。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Pyi0oaKmRTg"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "\n",
        "_schema_filename = 'schema.pbtxt'\n",
        "SCHEMA_PATH = 'schema'\n",
        "\n",
        "os.makedirs(SCHEMA_PATH, exist_ok=True)\n",
        "_generated_path = os.path.join(schema_artifacts[0].uri, _schema_filename)\n",
        "\n",
        "# Copy the 'schema.pbtxt' file from the artifact uri to a predefined path.\n",
        "shutil.copy(_generated_path, SCHEMA_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05U8uQ6dnlB4"
      },
      "source": [
        "架构文件使用了[协议缓冲区文本格式](https://googleapis.dev/python/protobuf/latest/google/protobuf/text_format.html)和 [TensorFlow Metadata 架构 proto](https://github.com/tensorflow/metadata/blob/master/tensorflow_metadata/proto/v0/schema.proto) 的实例。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uwHO7-HfnlWs"
      },
      "outputs": [],
      "source": [
        "print(f'Schema at {SCHEMA_PATH}-----')\n",
        "!cat {SCHEMA_PATH}/*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjKigLTNos4F"
      },
      "source": [
        "您应确保检查架构定义，并可能需要视情况对其进行编辑。在本教程中，我们将仅使用未经更改的生成架构。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nH6gizcpSwWV"
      },
      "source": [
        "## 验证输入样本并训练机器学习模型\n",
        "\n",
        "我们将回到我们在[简单 TFX 流水线教程](https://tensorflow.google.cn/tfx/tutorials/tfx/penguin_simple)中创建的流水线，以训练机器学习模型并使用生成的架构来编写模型训练代码。\n",
        "\n",
        "我们还将添加 [ExampleValidator](https://tensorflow.google.cn/tfx/guide/exampleval) 组件，该组件将在传入的数据集中查找与架构相关的异常和缺失值。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOjDv93eS5xV"
      },
      "source": [
        "### 编写模型训练代码\n",
        "\n",
        "我们需要像在[简单 TFX 流水线教程](https://tensorflow.google.cn/tfx/tutorials/tfx/penguin_simple)中那样编写模型代码。\n",
        "\n",
        "模型本身与上一教程中的模型相同，但本次我们将使用生成自上一流水线的架构，而非手动指定特征。大部分代码均未改变。唯一的区别是我们不需要在此文件中指定特征的名称和类型。相反，我们将从*架构*文件中读取它们。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aES7Hv5QTDK3"
      },
      "outputs": [],
      "source": [
        "_trainer_module_file = 'penguin_trainer.py'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gnc67uQNTDfW"
      },
      "outputs": [],
      "source": [
        "%%writefile {_trainer_module_file}\n",
        "\n",
        "from typing import List\n",
        "from absl import logging\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow_transform.tf_metadata import schema_utils\n",
        "\n",
        "from tfx import v1 as tfx\n",
        "from tfx_bsl.public import tfxio\n",
        "from tensorflow_metadata.proto.v0 import schema_pb2\n",
        "\n",
        "# We don't need to specify _FEATURE_KEYS and _FEATURE_SPEC any more.\n",
        "# Those information can be read from the given schema file.\n",
        "\n",
        "_LABEL_KEY = 'species'\n",
        "\n",
        "_TRAIN_BATCH_SIZE = 20\n",
        "_EVAL_BATCH_SIZE = 10\n",
        "\n",
        "def _input_fn(file_pattern: List[str],\n",
        "              data_accessor: tfx.components.DataAccessor,\n",
        "              schema: schema_pb2.Schema,\n",
        "              batch_size: int = 200) -> tf.data.Dataset:\n",
        "  \"\"\"Generates features and label for training.\n",
        "\n",
        "  Args:\n",
        "    file_pattern: List of paths or patterns of input tfrecord files.\n",
        "    data_accessor: DataAccessor for converting input to RecordBatch.\n",
        "    schema: schema of the input data.\n",
        "    batch_size: representing the number of consecutive elements of returned\n",
        "      dataset to combine in a single batch\n",
        "\n",
        "  Returns:\n",
        "    A dataset that contains (features, indices) tuple where features is a\n",
        "      dictionary of Tensors, and indices is a single Tensor of label indices.\n",
        "  \"\"\"\n",
        "  return data_accessor.tf_dataset_factory(\n",
        "      file_pattern,\n",
        "      tfxio.TensorFlowDatasetOptions(\n",
        "          batch_size=batch_size, label_key=_LABEL_KEY),\n",
        "      schema=schema).repeat()\n",
        "\n",
        "\n",
        "def _build_keras_model(schema: schema_pb2.Schema) -> tf.keras.Model:\n",
        "  \"\"\"Creates a DNN Keras model for classifying penguin data.\n",
        "\n",
        "  Returns:\n",
        "    A Keras Model.\n",
        "  \"\"\"\n",
        "  # The model below is built with Functional API, please refer to\n",
        "  # https://tensorflow.google.cn/guide/keras/overview for all API options.\n",
        "\n",
        "  # ++ Changed code: Uses all features in the schema except the label.\n",
        "  feature_keys = [f.name for f in schema.feature if f.name != _LABEL_KEY]\n",
        "  inputs = [keras.layers.Input(shape=(1,), name=f) for f in feature_keys]\n",
        "  # ++ End of the changed code.\n",
        "\n",
        "  d = keras.layers.concatenate(inputs)\n",
        "  for _ in range(2):\n",
        "    d = keras.layers.Dense(8, activation='relu')(d)\n",
        "  outputs = keras.layers.Dense(3)(d)\n",
        "\n",
        "  model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "  model.compile(\n",
        "      optimizer=keras.optimizers.Adam(1e-2),\n",
        "      loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "      metrics=[keras.metrics.SparseCategoricalAccuracy()])\n",
        "\n",
        "  model.summary(print_fn=logging.info)\n",
        "  return model\n",
        "\n",
        "\n",
        "# TFX Trainer will call this function.\n",
        "def run_fn(fn_args: tfx.components.FnArgs):\n",
        "  \"\"\"Train the model based on given args.\n",
        "\n",
        "  Args:\n",
        "    fn_args: Holds args used to train the model as name/value pairs.\n",
        "  \"\"\"\n",
        "\n",
        "  # ++ Changed code: Reads in schema file passed to the Trainer component.\n",
        "  schema = tfx.utils.parse_pbtxt_file(fn_args.schema_path, schema_pb2.Schema())\n",
        "  # ++ End of the changed code.\n",
        "\n",
        "  train_dataset = _input_fn(\n",
        "      fn_args.train_files,\n",
        "      fn_args.data_accessor,\n",
        "      schema,\n",
        "      batch_size=_TRAIN_BATCH_SIZE)\n",
        "  eval_dataset = _input_fn(\n",
        "      fn_args.eval_files,\n",
        "      fn_args.data_accessor,\n",
        "      schema,\n",
        "      batch_size=_EVAL_BATCH_SIZE)\n",
        "\n",
        "  model = _build_keras_model(schema)\n",
        "  model.fit(\n",
        "      train_dataset,\n",
        "      steps_per_epoch=fn_args.train_steps,\n",
        "      validation_data=eval_dataset,\n",
        "      validation_steps=fn_args.eval_steps)\n",
        "\n",
        "  # The result of the training should be saved in `fn_args.serving_model_dir`\n",
        "  # directory.\n",
        "  model.save(fn_args.serving_model_dir, save_format='tf')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blaw0rs-emEf"
      },
      "source": [
        "现在，您已经完成了为模型训练构建 TFX 流水线的所有准备步骤。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3OkNz3gTLwM"
      },
      "source": [
        "### 编写流水线定义\n",
        "\n",
        "我们将添加两个新组件：`Importer` 和 `ExampleValidator`。Importer 会将外部文件引入 TFX 流水线。在本例中，它是一个包含架构定义的文件。ExampleValidator 将检查输入数据并验证是否所有输入数据均符合我们提供的数据架构。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M49yYVNBTPd4"
      },
      "outputs": [],
      "source": [
        "def _create_pipeline(pipeline_name: str, pipeline_root: str, data_root: str,\n",
        "                     schema_path: str, module_file: str, serving_model_dir: str,\n",
        "                     metadata_path: str) -> tfx.dsl.Pipeline:\n",
        "  \"\"\"Creates a pipeline using predefined schema with TFX.\"\"\"\n",
        "  # Brings data into the pipeline.\n",
        "  example_gen = tfx.components.CsvExampleGen(input_base=data_root)\n",
        "\n",
        "  # Computes statistics over data for visualization and example validation.\n",
        "  statistics_gen = tfx.components.StatisticsGen(\n",
        "      examples=example_gen.outputs['examples'])\n",
        "\n",
        "  # NEW: Import the schema.\n",
        "  schema_importer = tfx.dsl.Importer(\n",
        "      source_uri=schema_path,\n",
        "      artifact_type=tfx.types.standard_artifacts.Schema).with_id(\n",
        "          'schema_importer')\n",
        "\n",
        "  # NEW: Performs anomaly detection based on statistics and data schema.\n",
        "  example_validator = tfx.components.ExampleValidator(\n",
        "      statistics=statistics_gen.outputs['statistics'],\n",
        "      schema=schema_importer.outputs['result'])\n",
        "\n",
        "  # Uses user-provided Python function that trains a model.\n",
        "  trainer = tfx.components.Trainer(\n",
        "      module_file=module_file,\n",
        "      examples=example_gen.outputs['examples'],\n",
        "      schema=schema_importer.outputs['result'],  # Pass the imported schema.\n",
        "      train_args=tfx.proto.TrainArgs(num_steps=100),\n",
        "      eval_args=tfx.proto.EvalArgs(num_steps=5))\n",
        "\n",
        "  # Pushes the model to a filesystem destination.\n",
        "  pusher = tfx.components.Pusher(\n",
        "      model=trainer.outputs['model'],\n",
        "      push_destination=tfx.proto.PushDestination(\n",
        "          filesystem=tfx.proto.PushDestination.Filesystem(\n",
        "              base_directory=serving_model_dir)))\n",
        "\n",
        "  components = [\n",
        "      example_gen,\n",
        "\n",
        "      # NEW: Following three components were added to the pipeline.\n",
        "      statistics_gen,\n",
        "      schema_importer,\n",
        "      example_validator,\n",
        "\n",
        "      trainer,\n",
        "      pusher,\n",
        "  ]\n",
        "\n",
        "  return tfx.dsl.Pipeline(\n",
        "      pipeline_name=pipeline_name,\n",
        "      pipeline_root=pipeline_root,\n",
        "      metadata_connection_config=tfx.orchestration.metadata\n",
        "      .sqlite_metadata_connection_config(metadata_path),\n",
        "      components=components)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJbq07THU2GV"
      },
      "source": [
        "### 运行流水线\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fAtfOZTYWJu-"
      },
      "outputs": [],
      "source": [
        "tfx.orchestration.LocalDagRunner().run(\n",
        "  _create_pipeline(\n",
        "      pipeline_name=PIPELINE_NAME,\n",
        "      pipeline_root=PIPELINE_ROOT,\n",
        "      data_root=DATA_ROOT,\n",
        "      schema_path=SCHEMA_PATH,\n",
        "      module_file=_trainer_module_file,\n",
        "      serving_model_dir=SERVING_MODEL_DIR,\n",
        "      metadata_path=METADATA_PATH))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZ3nTzG8uAzn"
      },
      "source": [
        "如果流水线成功完成，您应该看到“INFO:absl:Component Pusher is finished.”。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uuD5FRPAcOn8"
      },
      "source": [
        "### 检查流水线的输出\n",
        "\n",
        "我们已经训练了企鹅分类模型，并且还在 ExampleValidator 组件中验证了输入样本。我们可以像之前的流水线一样分析 ExampleValidator 的输出。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TtsrZEUB1-J4"
      },
      "outputs": [],
      "source": [
        "metadata_connection_config = tfx.orchestration.metadata.sqlite_metadata_connection_config(\n",
        "    METADATA_PATH)\n",
        "\n",
        "with Metadata(metadata_connection_config) as metadata_handler:\n",
        "  ev_output = get_latest_artifacts(metadata_handler, PIPELINE_NAME,\n",
        "                                   'ExampleValidator')\n",
        "  anomalies_artifacts = ev_output[standard_component_specs.ANOMALIES_KEY]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3U5MNAUIdBtN"
      },
      "source": [
        "来自 ExampleValidator 的 ExampleAnomalies 也可以得到呈现。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F-4oAjGR-IR0"
      },
      "outputs": [],
      "source": [
        "visualize_artifacts(anomalies_artifacts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t026ZzbU0961"
      },
      "source": [
        "对于每个样本拆分，您都应该看到“No anomalies found”。由于我们使用了在此流水线中生成架构所使用的相同数据，预计不会出现异常。如果您使用新传入数据重复运行此流水线，则 ExampleValidator 应能发现新数据与现有架构之间的任何差异。\n",
        "\n",
        "如果发现任何异常，您可以检查您的数据以确认是否有任何样本不符合您的假设。其他组件（如 StatisticsGen）的输出可能会非常有用。但是，发现的任何异常都不会阻止流水线的进一步执行。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08R8qvweThRf"
      },
      "source": [
        "## 后续步骤\n",
        "\n",
        "您可以在 https://tensorflow.google.cn/tfx/tutorials 上找到更多资源。\n",
        "\n",
        "要详细了解 TFX 中的各种概念，请参阅[了解 TFX 流水线](https://tensorflow.google.cn/tfx/guide/understanding_tfx_pipelines)。\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "DjUA6S30k52h"
      ],
      "name": "penguin_tfdv.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
