{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pknVo1kM2wI2"
      },
      "source": [
        "##### Copyright 2021 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "SoFqANDE222Y"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6x1ypzczQCwy"
      },
      "source": [
        "# Vertex AI Training 和 Serving（使用 TFX 和 Vertex Pipelines）\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_445qeKq8e3-"
      },
      "source": [
        "<div class=\"devsite-table-wrapper\"><table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "<td>     <a target=\"_blank\" href=\"https://tensorflow.google.cn/tfx/tutorials/tfx/gcp/vertex_pipelines_vertex_training\"><img src=\"https://tensorflow.google.cn/images/tf_logo_32px.png\">在 Tensorflow.org 上查看</a> </td>\n",
        "<td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/zh-cn/tfx/tutorials/tfx/gcp/vertex_pipelines_vertex_training.ipynb\"><img src=\"https://tensorflow.google.cn/images/colab_logo_32px.png\">在 Google Colab 运行</a> </td>\n",
        "<td><a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/zh-cn/tfx/tutorials/tfx/gcp/vertex_pipelines_vertex_training.ipynb\"><img width=\"32px\" src=\"https://tensorflow.google.cn/images/GitHub-Mark-32px.png\">在 Github 上查看源代码</a></td>\n",
        "<td><a href=\"https://storage.googleapis.com/tensorflow_docs/tfx/docs/tutorials/tfx/gcp/vertex_pipelines_vertex_training.ipynb\"><img src=\"https://tensorflow.google.cn/images/download_logo_32px.png\">下载笔记本</a></td>\n",
        "<td><a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?q=download_url%3Dhttps://storage.googleapis.com/tensorflow_docs/docs-l10n/site/zh-cn/tfx/tutorials/tfx/gcp/vertex_pipelines_vertex_training.ipynb\"><img src=\"https://tensorflow.google.cn/images/download_logo_32px.png\">在 Google Cloud Vertex AI Workbench 中运行</a></td>\n",
        "</table></div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_VuwrlnvQJ5k"
      },
      "source": [
        "这个基于笔记本的教程将创建并运行 TFX 流水线，该流水线使用 Vertex AI Training 服务训练 ML 模型并将其发布到 Vertex AI 以便应用。\n",
        "\n",
        "此笔记本基于我们在[适用于 Vertex Pipelines 的简单 TFX 流水线教程](https://tensorflow.google.cn/tfx/tutorials/tfx/gcp/vertex_pipelines_simple)中构建的 TFX 流水线。如果您还未阅读该教程，应在继续使用此笔记本之前阅读它。\n",
        "\n",
        "您可以使用 AutoML 在 Vertex AI 上训练模型，也可以使用自定义训练。在自定义训练中，您可以选择许多不同的机器类型来支持您的训练作业、启用分布式训练、使用超参数调整以及使用 GPU 进行加速。\n",
        "\n",
        "您还可以将经过训练的模型部署到 Vertex AI 模型并创建端点，从而应用预测请求。\n",
        "\n",
        "在本教程中，我们将配合使用 Vertex AI Training 和自定义作业来训练 TFX 流水线中的模型。我们还将部署模型以使用 Vertex AI 应用预测请求。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5Pv2qm3wfpL"
      },
      "source": [
        "此笔记本旨在于 [Google Colab](https://colab.research.google.com/notebooks/intro.ipynb) 或 [AI Platform Notebooks](https://cloud.google.com/ai-platform-notebooks) 上运行。如果您不使用其中之一，只需单击上面的“在 Google Colab 中运行”按钮即可。\n",
        "\n",
        "## 设置\n",
        "\n",
        "如果您已经完成[适用于 Vertex Pipelines 的简单 TFX 流水线教程](https://tensorflow.google.cn/tfx/tutorials/tfx/gcp/vertex_pipelines_simple)，您将拥有一个 GCP 工作项目和一个 GCS 存储桶，这就是本教程所需要的全部内容。如果您错过了初步教程，请先阅读它。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwZ0aXisoBFW"
      },
      "source": [
        "### 安装 python 软件包"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WC9W_S-bONgl"
      },
      "source": [
        "我们将安装所需的 Python 软件包（包括 TFX 和 KFP），以编写 ML 流水线并将作业提交到 Vertex Pipelines。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iyQtljP-qPHY"
      },
      "outputs": [],
      "source": [
        "# Use the latest version of pip.\n",
        "!pip install --upgrade pip\n",
        "!pip install --upgrade \"tfx[kfp]<2\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwT0nov5QO1M"
      },
      "source": [
        "#### 是否已重新启动运行时？\n",
        "\n",
        "如果您使用的是 Google Colab，则在首次运行上面的代码单元时必须重新启动运行时，方法是单击上面的“重新启动运行时”按钮或使用“运行时 &gt; 重新启动运行时...”菜单。这样做的原因是 Colab 加载软件包的方式。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CRyIL4LVDlQ"
      },
      "source": [
        "如果您不在 Colab 上，可以使用以下代码单元重新启动运行时。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KHTSzMygoBF6"
      },
      "outputs": [],
      "source": [
        "# docs_infra: no_execute\n",
        "import sys\n",
        "if not 'google.colab' in sys.modules:\n",
        "  # Automatically restart kernel after installs\n",
        "  import IPython\n",
        "  app = IPython.Application.instance()\n",
        "  app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gckGHdW9iPrq"
      },
      "source": [
        "### 登录 Google 获取此笔记本\n",
        "\n",
        "如果您在 Colab 上运行此笔记本，请使用您的用户帐户进行身份验证："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kZQA0KrfXCvU"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "if 'google.colab' in sys.modules:\n",
        "  from google.colab import auth\n",
        "  auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaqJjbmk6o0o"
      },
      "source": [
        "**如果您在 AI Platform Notebooks 上**，请在运行下一部分之前通过 Google Cloud 进行身份验证，方法是运行\n",
        "\n",
        "```sh\n",
        "gcloud auth login\n",
        "```\n",
        "\n",
        "运行位置为**终端窗口** （可通过菜单中的**文件** &gt; **新建**打开）。您只需对每个笔记本实例执行一次此操作。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_SveIKxaENu"
      },
      "source": [
        "检查软件包版本。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xd-iP9wEaENu"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "print('TensorFlow version: {}'.format(tf.__version__))\n",
        "from tfx import v1 as tfx\n",
        "print('TFX version: {}'.format(tfx.__version__))\n",
        "import kfp\n",
        "print('KFP version: {}'.format(kfp.__version__))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDtLdSkvqPHe"
      },
      "source": [
        "### 设置变量\n",
        "\n",
        "我们将在下面设置一些用于自定义流水线的变量。所需信息如下：\n",
        "\n",
        "- GCP 项目 ID。请参阅[找出项目 ID](https://cloud.google.com/resource-manager/docs/creating-managing-projects#identifying_projects)。\n",
        "- 用于运行流水线的 GCP 区域。有关 Vertex Pipelines 在其中可用的区域的更多信息，请参阅 [Vertex AI 位置指南](https://cloud.google.com/vertex-ai/docs/general/locations#feature-availability)。\n",
        "- 用于存储流水线输出的 Google Cloud Storage 存储桶。\n",
        "\n",
        "**在下面的代码单元中输入所需值，然后再运行它**。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EcUseqJaE2XN"
      },
      "outputs": [],
      "source": [
        "GOOGLE_CLOUD_PROJECT = ''     # <--- ENTER THIS\n",
        "GOOGLE_CLOUD_REGION = ''      # <--- ENTER THIS\n",
        "GCS_BUCKET_NAME = ''          # <--- ENTER THIS\n",
        "\n",
        "if not (GOOGLE_CLOUD_PROJECT and GOOGLE_CLOUD_REGION and GCS_BUCKET_NAME):\n",
        "    from absl import logging\n",
        "    logging.error('Please set all required parameters.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAaCPLjgiJrO"
      },
      "source": [
        "设置 `gcloud` 以使用您的项目。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VkWdxe4TXRHk"
      },
      "outputs": [],
      "source": [
        "!gcloud config set project {GOOGLE_CLOUD_PROJECT}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CPN6UL5CazNy"
      },
      "outputs": [],
      "source": [
        "PIPELINE_NAME = 'penguin-vertex-training'\n",
        "\n",
        "# Path to various pipeline artifact.\n",
        "PIPELINE_ROOT = 'gs://{}/pipeline_root/{}'.format(GCS_BUCKET_NAME, PIPELINE_NAME)\n",
        "\n",
        "# Paths for users' Python module.\n",
        "MODULE_ROOT = 'gs://{}/pipeline_module/{}'.format(GCS_BUCKET_NAME, PIPELINE_NAME)\n",
        "\n",
        "# Paths for users' data.\n",
        "DATA_ROOT = 'gs://{}/data/{}'.format(GCS_BUCKET_NAME, PIPELINE_NAME)\n",
        "\n",
        "# Name of Vertex AI Endpoint.\n",
        "ENDPOINT_NAME = 'prediction-' + PIPELINE_NAME\n",
        "\n",
        "print('PIPELINE_ROOT: {}'.format(PIPELINE_ROOT))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8F2SRwRLSYGa"
      },
      "source": [
        "### 准备示例数据\n",
        "\n",
        "我们将使用与[简单 TFX 流水线教程](https://allisonhorst.github.io/palmerpenguins/articles/intro.html)相同的 [Palmer Penguins 数据集](https://tensorflow.google.cn/tfx/tutorials/tfx/penguin_simple)。\n",
        "\n",
        "此数据集中有四个数字特征，这些特征已标准化为具有范围 [0,1]。我们将建立一个预测企鹅 `species` 的分类模型。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11J7XiCq6AFP"
      },
      "source": [
        "我们需要创建我们自己的数据集副本。因为 TFX ExampleGen 从目录中读取输入，所以我们需要在 GCS 上创建一个目录并将数据集复制到其中。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4fxMs6u86acP"
      },
      "outputs": [],
      "source": [
        "!gsutil cp gs://download.tensorflow.org/data/palmer_penguins/penguins_processed.csv {DATA_ROOT}/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASpoNmxKSQjI"
      },
      "source": [
        "快速浏览一下 CSV 文件。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-eSz28UDSnlG"
      },
      "outputs": [],
      "source": [
        "!gsutil cat {DATA_ROOT}/penguins_processed.csv | head"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nH6gizcpSwWV"
      },
      "source": [
        "## 创建流水线\n",
        "\n",
        "我们的流水线将与我们在[适用于 Vertex Pipelines 的简单 TFX 流水线教程](https://tensorflow.google.cn/tfx/tutorials/tfx/gcp/vertex_pipelines_simple)中创建的流水线非常相似。该流水线将包含三个组件：CsvExampleGen、Trainer 和 Pusher。但是，我们将使用特殊的 Trainer 和 Pusher 组件。Trainer 组件会将训练工作负载移动到 Vertex AI，Pusher 组件则会将经过训练的 ML 模型发布到 Vertex AI 而不是文件系统。\n",
        "\n",
        "TFX 提供一个特殊的 `Trainer`，用于将训练作业提交给 Vertex AI Training 服务。我们所要做的就是在扩展模块中使用 `Trainer`（而非标准 `Trainer` 组件）以及一些必需的 GCP 参数。\n",
        "\n",
        "在本教程中，我们将首先使用多个 CPU 运行 Vertex AI Training 作业，然后再使用一个 GPU 来运行。\n",
        "\n",
        "TFX 还提供一个特殊的 `Pusher`，用于将模型上传到 *Vertex AI 模型*。`Pusher` 还将创建 *Vertex AI 端点*资源以应用在线预测。要了解有关 Vertex AI 提供的在线预测的更多信息，请参阅 [Vertex AI 文档](https://cloud.google.com/vertex-ai/docs/predictions/getting-predictions)。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOjDv93eS5xV"
      },
      "source": [
        "### 编写模型代码。\n",
        "\n",
        "该模型本身与[简单 TFX 流水线教程](https://tensorflow.google.cn/tfx/tutorials/tfx/penguin_simple)中的模型几乎相似。\n",
        "\n",
        "我们将添加可创建 [TensorFlow 分布策略](https://tensorflow.google.cn/guide/distributed_training)的 `_get_distribution_strategy()` 函数，其用于 `run_fn`，以便在 GPU 可用时使用 MirroredStrategy。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aES7Hv5QTDK3"
      },
      "outputs": [],
      "source": [
        "_trainer_module_file = 'penguin_trainer.py'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gnc67uQNTDfW"
      },
      "outputs": [],
      "source": [
        "%%writefile {_trainer_module_file}\n",
        "\n",
        "# Copied from https://tensorflow.google.cn/tfx/tutorials/tfx/penguin_simple and\n",
        "# slightly modified run_fn() to add distribution_strategy.\n",
        "\n",
        "from typing import List\n",
        "from absl import logging\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow_metadata.proto.v0 import schema_pb2\n",
        "from tensorflow_transform.tf_metadata import schema_utils\n",
        "\n",
        "from tfx import v1 as tfx\n",
        "from tfx_bsl.public import tfxio\n",
        "\n",
        "_FEATURE_KEYS = [\n",
        "    'culmen_length_mm', 'culmen_depth_mm', 'flipper_length_mm', 'body_mass_g'\n",
        "]\n",
        "_LABEL_KEY = 'species'\n",
        "\n",
        "_TRAIN_BATCH_SIZE = 20\n",
        "_EVAL_BATCH_SIZE = 10\n",
        "\n",
        "# Since we're not generating or creating a schema, we will instead create\n",
        "# a feature spec.  Since there are a fairly small number of features this is\n",
        "# manageable for this dataset.\n",
        "_FEATURE_SPEC = {\n",
        "    **{\n",
        "        feature: tf.io.FixedLenFeature(shape=[1], dtype=tf.float32)\n",
        "        for feature in _FEATURE_KEYS\n",
        "    }, _LABEL_KEY: tf.io.FixedLenFeature(shape=[1], dtype=tf.int64)\n",
        "}\n",
        "\n",
        "\n",
        "def _input_fn(file_pattern: List[str],\n",
        "              data_accessor: tfx.components.DataAccessor,\n",
        "              schema: schema_pb2.Schema,\n",
        "              batch_size: int) -> tf.data.Dataset:\n",
        "  \"\"\"Generates features and label for training.\n",
        "\n",
        "  Args:\n",
        "    file_pattern: List of paths or patterns of input tfrecord files.\n",
        "    data_accessor: DataAccessor for converting input to RecordBatch.\n",
        "    schema: schema of the input data.\n",
        "    batch_size: representing the number of consecutive elements of returned\n",
        "      dataset to combine in a single batch\n",
        "\n",
        "  Returns:\n",
        "    A dataset that contains (features, indices) tuple where features is a\n",
        "      dictionary of Tensors, and indices is a single Tensor of label indices.\n",
        "  \"\"\"\n",
        "  return data_accessor.tf_dataset_factory(\n",
        "      file_pattern,\n",
        "      tfxio.TensorFlowDatasetOptions(\n",
        "          batch_size=batch_size, label_key=_LABEL_KEY),\n",
        "      schema=schema).repeat()\n",
        "\n",
        "\n",
        "def _make_keras_model() -> tf.keras.Model:\n",
        "  \"\"\"Creates a DNN Keras model for classifying penguin data.\n",
        "\n",
        "  Returns:\n",
        "    A Keras Model.\n",
        "  \"\"\"\n",
        "  # The model below is built with Functional API, please refer to\n",
        "  # https://tensorflow.google.cn/guide/keras/overview for all API options.\n",
        "  inputs = [keras.layers.Input(shape=(1,), name=f) for f in _FEATURE_KEYS]\n",
        "  d = keras.layers.concatenate(inputs)\n",
        "  for _ in range(2):\n",
        "    d = keras.layers.Dense(8, activation='relu')(d)\n",
        "  outputs = keras.layers.Dense(3)(d)\n",
        "\n",
        "  model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "  model.compile(\n",
        "      optimizer=keras.optimizers.Adam(1e-2),\n",
        "      loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "      metrics=[keras.metrics.SparseCategoricalAccuracy()])\n",
        "\n",
        "  model.summary(print_fn=logging.info)\n",
        "  return model\n",
        "\n",
        "\n",
        "# NEW: Read `use_gpu` from the custom_config of the Trainer.\n",
        "#      if it uses GPU, enable MirroredStrategy.\n",
        "def _get_distribution_strategy(fn_args: tfx.components.FnArgs):\n",
        "  if fn_args.custom_config.get('use_gpu', False):\n",
        "    logging.info('Using MirroredStrategy with one GPU.')\n",
        "    return tf.distribute.MirroredStrategy(devices=['device:GPU:0'])\n",
        "  return None\n",
        "\n",
        "\n",
        "# TFX Trainer will call this function.\n",
        "def run_fn(fn_args: tfx.components.FnArgs):\n",
        "  \"\"\"Train the model based on given args.\n",
        "\n",
        "  Args:\n",
        "    fn_args: Holds args used to train the model as name/value pairs.\n",
        "  \"\"\"\n",
        "\n",
        "  # This schema is usually either an output of SchemaGen or a manually-curated\n",
        "  # version provided by pipeline author. A schema can also derived from TFT\n",
        "  # graph if a Transform component is used. In the case when either is missing,\n",
        "  # `schema_from_feature_spec` could be used to generate schema from very simple\n",
        "  # feature_spec, but the schema returned would be very primitive.\n",
        "  schema = schema_utils.schema_from_feature_spec(_FEATURE_SPEC)\n",
        "\n",
        "  train_dataset = _input_fn(\n",
        "      fn_args.train_files,\n",
        "      fn_args.data_accessor,\n",
        "      schema,\n",
        "      batch_size=_TRAIN_BATCH_SIZE)\n",
        "  eval_dataset = _input_fn(\n",
        "      fn_args.eval_files,\n",
        "      fn_args.data_accessor,\n",
        "      schema,\n",
        "      batch_size=_EVAL_BATCH_SIZE)\n",
        "\n",
        "  # NEW: If we have a distribution strategy, build a model in a strategy scope.\n",
        "  strategy = _get_distribution_strategy(fn_args)\n",
        "  if strategy is None:\n",
        "    model = _make_keras_model()\n",
        "  else:\n",
        "    with strategy.scope():\n",
        "      model = _make_keras_model()\n",
        "\n",
        "  model.fit(\n",
        "      train_dataset,\n",
        "      steps_per_epoch=fn_args.train_steps,\n",
        "      validation_data=eval_dataset,\n",
        "      validation_steps=fn_args.eval_steps)\n",
        "\n",
        "  # The result of the training should be saved in `fn_args.serving_model_dir`\n",
        "  # directory.\n",
        "  model.save(fn_args.serving_model_dir, save_format='tf')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LsYx8MpYvPv"
      },
      "source": [
        "将模块文件复制到可从流水线组件进行访问的 GCS。\n",
        "\n",
        "否则，您可能需要构建包含模块文件的容器映像并使用该映像来运行流水线和 AI Platform Training 作业。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rMMs5wuNYAbc"
      },
      "outputs": [],
      "source": [
        "!gsutil cp {_trainer_module_file} {MODULE_ROOT}/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3OkNz3gTLwM"
      },
      "source": [
        "### 编写流水线定义\n",
        "\n",
        "我们将定义一个函数来创建 TFX 流水线。它具有与[简单 TFX 流水线教程](https://tensorflow.google.cn/tfx/tutorials/tfx/penguin_simple)中相同的三个组件，但我们将在 GCP 扩展模块中使用 `Trainer` 和 `Pusher` 组件。\n",
        "\n",
        "`tfx.extensions.google_cloud_ai_platform.Trainer` 的行为类似于普通 `Trainer`，只是将模型训练的计算移动到云。它在 Vertex AI Training 服务中启动自定义作业，而且编排系统中的 Trainer 组件会一直等待，直到 Vertex AI Training 作业完成。\n",
        "\n",
        "`tfx.extensions.google_cloud_ai_platform.Pusher` 使用经过训练的模型创建 Vertex AI 模型和 Vertex AI 端点。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M49yYVNBTPd4"
      },
      "outputs": [],
      "source": [
        "def _create_pipeline(pipeline_name: str, pipeline_root: str, data_root: str,\n",
        "                     module_file: str, endpoint_name: str, project_id: str,\n",
        "                     region: str, use_gpu: bool) -> tfx.dsl.Pipeline:\n",
        "  \"\"\"Implements the penguin pipeline with TFX.\"\"\"\n",
        "  # Brings data into the pipeline or otherwise joins/converts training data.\n",
        "  example_gen = tfx.components.CsvExampleGen(input_base=data_root)\n",
        "\n",
        "  # NEW: Configuration for Vertex AI Training.\n",
        "  # This dictionary will be passed as `CustomJobSpec`.\n",
        "  vertex_job_spec = {\n",
        "      'project': project_id,\n",
        "      'worker_pool_specs': [{\n",
        "          'machine_spec': {\n",
        "              'machine_type': 'n1-standard-4',\n",
        "          },\n",
        "          'replica_count': 1,\n",
        "          'container_spec': {\n",
        "              'image_uri': 'gcr.io/tfx-oss-public/tfx:{}'.format(tfx.__version__),\n",
        "          },\n",
        "      }],\n",
        "  }\n",
        "  if use_gpu:\n",
        "    # See https://cloud.google.com/vertex-ai/docs/reference/rest/v1/MachineSpec#acceleratortype\n",
        "    # for available machine types.\n",
        "    vertex_job_spec['worker_pool_specs'][0]['machine_spec'].update({\n",
        "        'accelerator_type': 'NVIDIA_TESLA_K80',\n",
        "        'accelerator_count': 1\n",
        "    })\n",
        "\n",
        "  # Trains a model using Vertex AI Training.\n",
        "  # NEW: We need to specify a Trainer for GCP with related configs.\n",
        "  trainer = tfx.extensions.google_cloud_ai_platform.Trainer(\n",
        "      module_file=module_file,\n",
        "      examples=example_gen.outputs['examples'],\n",
        "      train_args=tfx.proto.TrainArgs(num_steps=100),\n",
        "      eval_args=tfx.proto.EvalArgs(num_steps=5),\n",
        "      custom_config={\n",
        "          tfx.extensions.google_cloud_ai_platform.ENABLE_VERTEX_KEY:\n",
        "              True,\n",
        "          tfx.extensions.google_cloud_ai_platform.VERTEX_REGION_KEY:\n",
        "              region,\n",
        "          tfx.extensions.google_cloud_ai_platform.TRAINING_ARGS_KEY:\n",
        "              vertex_job_spec,\n",
        "          'use_gpu':\n",
        "              use_gpu,\n",
        "      })\n",
        "\n",
        "  # NEW: Configuration for pusher.\n",
        "  vertex_serving_spec = {\n",
        "      'project_id': project_id,\n",
        "      'endpoint_name': endpoint_name,\n",
        "      # Remaining argument is passed to aiplatform.Model.deploy()\n",
        "      # See https://cloud.google.com/vertex-ai/docs/predictions/deploy-model-api#deploy_the_model\n",
        "      # for the detail.\n",
        "      #\n",
        "      # Machine type is the compute resource to serve prediction requests.\n",
        "      # See https://cloud.google.com/vertex-ai/docs/predictions/configure-compute#machine-types\n",
        "      # for available machine types and acccerators.\n",
        "      'machine_type': 'n1-standard-4',\n",
        "  }\n",
        "\n",
        "  # Vertex AI provides pre-built containers with various configurations for\n",
        "  # serving.\n",
        "  # See https://cloud.google.com/vertex-ai/docs/predictions/pre-built-containers\n",
        "  # for available container images.\n",
        "  serving_image = 'us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-6:latest'\n",
        "  if use_gpu:\n",
        "    vertex_serving_spec.update({\n",
        "        'accelerator_type': 'NVIDIA_TESLA_K80',\n",
        "        'accelerator_count': 1\n",
        "    })\n",
        "    serving_image = 'us-docker.pkg.dev/vertex-ai/prediction/tf2-gpu.2-6:latest'\n",
        "\n",
        "  # NEW: Pushes the model to Vertex AI.\n",
        "  pusher = tfx.extensions.google_cloud_ai_platform.Pusher(\n",
        "      model=trainer.outputs['model'],\n",
        "      custom_config={\n",
        "          tfx.extensions.google_cloud_ai_platform.ENABLE_VERTEX_KEY:\n",
        "              True,\n",
        "          tfx.extensions.google_cloud_ai_platform.VERTEX_REGION_KEY:\n",
        "              region,\n",
        "          tfx.extensions.google_cloud_ai_platform.VERTEX_CONTAINER_IMAGE_URI_KEY:\n",
        "              serving_image,\n",
        "          tfx.extensions.google_cloud_ai_platform.SERVING_ARGS_KEY:\n",
        "            vertex_serving_spec,\n",
        "      })\n",
        "\n",
        "  components = [\n",
        "      example_gen,\n",
        "      trainer,\n",
        "      pusher,\n",
        "  ]\n",
        "\n",
        "  return tfx.dsl.Pipeline(\n",
        "      pipeline_name=pipeline_name,\n",
        "      pipeline_root=pipeline_root,\n",
        "      components=components)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJbq07THU2GV"
      },
      "source": [
        "## 在 Vertex Pipelines 上运行流水线。\n",
        "\n",
        "我们将使用 Vertex Pipelines 来运行流水线，就像我们在[适用于 Vertex Pipelines 的简单 TFX 流水线教程](https://tensorflow.google.cn/tfx/tutorials/tfx/gcp/vertex_pipelines_simple)中所做的那样。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fAtfOZTYWJu-"
      },
      "outputs": [],
      "source": [
        "# docs_infra: no_execute\n",
        "import os\n",
        "\n",
        "PIPELINE_DEFINITION_FILE = PIPELINE_NAME + '_pipeline.json'\n",
        "\n",
        "runner = tfx.orchestration.experimental.KubeflowV2DagRunner(\n",
        "    config=tfx.orchestration.experimental.KubeflowV2DagRunnerConfig(),\n",
        "    output_filename=PIPELINE_DEFINITION_FILE)\n",
        "_ = runner.run(\n",
        "    _create_pipeline(\n",
        "        pipeline_name=PIPELINE_NAME,\n",
        "        pipeline_root=PIPELINE_ROOT,\n",
        "        data_root=DATA_ROOT,\n",
        "        module_file=os.path.join(MODULE_ROOT, _trainer_module_file),\n",
        "        endpoint_name=ENDPOINT_NAME,\n",
        "        project_id=GOOGLE_CLOUD_PROJECT,\n",
        "        region=GOOGLE_CLOUD_REGION,\n",
        "        # We will use CPUs only for now.\n",
        "        use_gpu=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWyITYSDd8w4"
      },
      "source": [
        "生成的定义文件可以使用 `google-cloud-aiplatform` 软件包中的 Google Cloud aiplatform 客户端提交。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tI71jlEvWMV7"
      },
      "outputs": [],
      "source": [
        "# docs_infra: no_execute\n",
        "from google.cloud import aiplatform\n",
        "from google.cloud.aiplatform import pipeline_jobs\n",
        "import logging\n",
        "logging.getLogger().setLevel(logging.INFO)\n",
        "\n",
        "aiplatform.init(project=GOOGLE_CLOUD_PROJECT, location=GOOGLE_CLOUD_REGION)\n",
        "\n",
        "job = pipeline_jobs.PipelineJob(template_path=PIPELINE_DEFINITION_FILE,\n",
        "                                display_name=PIPELINE_NAME)\n",
        "job.submit()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3k9f5IVQXcQ"
      },
      "source": [
        "现在，您可以访问上面输出中的链接或访问 [Google Cloud Console](https://console.cloud.google.com/) 中的“Vertex AI &gt; 流水线”来查看进度。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyN4bM8GOHHt"
      },
      "source": [
        "## 使用预测请求进行测试\n",
        "\n",
        "流水线完成后，您将在“Vertex AI &gt; 端点”中的端点之一处找到*已部署*的模型。我们需要知道端点的 ID 才能向新端点发送预测请求。这与我们上面输入的*端点名称*不同。您可以在 <code>Google Cloud Console</code> 的<a>“端点”页面</a>找到 ID，它看起来是一个很长的编号。\n",
        "\n",
        "**设置下面的 ENDPOINT_ID，然后再运行它。**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "51EWzkj8Wdly"
      },
      "outputs": [],
      "source": [
        "ENDPOINT_ID=''     # <--- ENTER THIS\n",
        "if not ENDPOINT_ID:\n",
        "    from absl import logging\n",
        "    logging.error('Please set the endpoint id.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9maWD7pK-yf"
      },
      "source": [
        "我们使用相同的 aiplatform 客户端向端点发送请求。我们将发送企鹅物种分类的预测请求。输入是我们使用的四个特征，模型将返回三个值，因为我们的模型为每个物种输出一个值。\n",
        "\n",
        "例如，以下具体示例在索引“2”处具有最大值，并将打印“2”。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gdzxst2_OoXH"
      },
      "outputs": [],
      "source": [
        "# docs_infra: no_execute\n",
        "import numpy as np\n",
        "\n",
        "# The AI Platform services require regional API endpoints.\n",
        "client_options = {\n",
        "    'api_endpoint': GOOGLE_CLOUD_REGION + '-aiplatform.googleapis.com'\n",
        "    }\n",
        "# Initialize client that will be used to create and send requests.\n",
        "client = aiplatform.gapic.PredictionServiceClient(client_options=client_options)\n",
        "\n",
        "# Set data values for the prediction request.\n",
        "# Our model expects 4 feature inputs and produces 3 output values for each\n",
        "# species. Note that the output is logit value rather than probabilities.\n",
        "# See the model code to understand input / output structure.\n",
        "instances = [{\n",
        "    'culmen_length_mm':[0.71],\n",
        "    'culmen_depth_mm':[0.38],\n",
        "    'flipper_length_mm':[0.98],\n",
        "    'body_mass_g': [0.78],\n",
        "}]\n",
        "\n",
        "endpoint = client.endpoint_path(\n",
        "    project=GOOGLE_CLOUD_PROJECT,\n",
        "    location=GOOGLE_CLOUD_REGION,\n",
        "    endpoint=ENDPOINT_ID,\n",
        ")\n",
        "# Send a prediction request and get response.\n",
        "response = client.predict(endpoint=endpoint, instances=instances)\n",
        "\n",
        "# Uses argmax to find the index of the maximum value.\n",
        "print('species:', np.argmax(response.predictions[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5OBJLMLOowD"
      },
      "source": [
        "有关在线预测的详细信息，请访问 <code>Google Cloud Console</code> 中的<a>“端点”页面</a>。您可以找到有关发送示例请求和更多资源链接的指南。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DgVvdYPzzW6k"
      },
      "source": [
        "## 使用 GPU 运行流水线\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ht0Zpgx3L82g"
      },
      "source": [
        "Vertex AI 支持使用各种机器类型进行训练，包括对 GPU 的支持。有关可用选项，请参阅[机器规格参考](https://cloud.google.com/vertex-ai/docs/reference/rest/v1/MachineSpec#acceleratortype)。\n",
        "\n",
        "我们已经定义了流水线来支持 GPU 训练。我们需要做的就是将 `use_gpu` 标志设置为 True。之后将会使用包含一个 NVIDIA_TESLA_K80 的机器规格创建流水线，我们的模型训练代码将使用 `tf.distribute.MirroredStrategy`。\n",
        "\n",
        "请注意，`use_gpu` 标志不是 Vertex 或 TFX API 的一部分。它只用于控制本教程中的训练代码。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1TwX6bcsLo_g"
      },
      "outputs": [],
      "source": [
        "# docs_infra: no_execute\n",
        "runner.run(\n",
        "    _create_pipeline(\n",
        "        pipeline_name=PIPELINE_NAME,\n",
        "        pipeline_root=PIPELINE_ROOT,\n",
        "        data_root=DATA_ROOT,\n",
        "        module_file=os.path.join(MODULE_ROOT, _trainer_module_file),\n",
        "        endpoint_name=ENDPOINT_NAME,\n",
        "        project_id=GOOGLE_CLOUD_PROJECT,\n",
        "        region=GOOGLE_CLOUD_REGION,\n",
        "        # Updated: Use GPUs. We will use a NVIDIA_TESLA_K80 and \n",
        "        # the model code will use tf.distribute.MirroredStrategy.\n",
        "        use_gpu=True))\n",
        "\n",
        "job = pipeline_jobs.PipelineJob(template_path=PIPELINE_DEFINITION_FILE,\n",
        "                                display_name=PIPELINE_NAME)\n",
        "job.submit()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xc9XsjlyKoZe"
      },
      "source": [
        "现在，您可以访问上面输出中的链接或访问 [Google Cloud Console](https://console.cloud.google.com/) 中的“Vertex AI &gt; 流水线”来查看进度。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_coFG3sqSJQ"
      },
      "source": [
        "## 清理\n",
        "\n",
        "您已在本教程中创建了 Vertex AI 模型和端点。请首先转到[端点](https://console.cloud.google.com/vertex-ai/endpoints)并从端点*取消部署*模型，以此方式删除这些资源以避免任何不必要的费用。然后，您可以单独删除端点和模型。"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "pknVo1kM2wI2",
        "8F2SRwRLSYGa"
      ],
      "name": "vertex_pipelines_vertex_training.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
