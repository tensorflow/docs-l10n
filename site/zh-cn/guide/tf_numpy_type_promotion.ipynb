{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjN_IJ8mhJ-4"
      },
      "source": [
        "##### Copyright 2023 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "sY3Ffd83hK3b"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03Pw58e6mTHI"
      },
      "source": [
        "# TF-NumPy 类型提升"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9nPKvxK-_pM"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>     <a target=\"_blank\" href=\"https://tensorflow.google.cn/guide/tf_numpy_type_promotion\"><img src=\"https://tensorflow.google.cn/images/tf_logo_32px.png\">在 TensorFlow.org 上查看</a>\n",
        "</td>\n",
        "  <td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/zh-cn/guide/tf_numpy_type_promotion.ipynb\"><img src=\"https://tensorflow.google.cn/images/colab_logo_32px.png\">在 Google Colab 中运行</a></td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/zh-cn/guide/tf_numpy_type_promotion.ipynb\"><img src=\"https://tensorflow.google.cn/images/GitHub-Mark-32px.png\">在 Github 上查看源代码</a>\n",
        "</td>\n",
        "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/zh-cn/guide/tf_numpy_type_promotion.ipynb\"><img src=\"https://tensorflow.google.cn/images/download_logo_32px.png\">下载笔记本</a>   </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uma-W5v__DYh"
      },
      "source": [
        "## 文本特征向量\n",
        "\n",
        "TensorFlow 中的类型提升有 4 个选项。\n",
        "\n",
        "- 默认情况下，TensorFlow 会引发错误，而不是提升混合类型运算的类型。\n",
        "- 运行 `tf.numpy.experimental_enable_numpy_behavior()` 会将 TensorFlow 切换为使用 [NumPy 类型提升规则](https://tensorflow.google.cn/guide/tf_numpy#type_promotion)。\n",
        "- **本文档**介绍了 TensorFlow 2.15（或目前为 `tf-nightly`）中提供的两个新选项："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vMvEKDFOsau7"
      },
      "outputs": [],
      "source": [
        "!pip install -q tf_nightly"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6hOFBfPsd3y"
      },
      "source": [
        "**注**：`experimental_enable_numpy_behavior` 会更改所有 TensorFlow 的行为。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ob1HNwUmYR5b"
      },
      "source": [
        "## 安装"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AJR558zjAZQu"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow.experimental.numpy as tnp\n",
        "\n",
        "print(\"Using TensorFlow version %s\" % tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6tacoy0DU6e"
      },
      "source": [
        "### 启用新类型提升\n",
        "\n",
        "为了在 TF-Numpy 中使用[类似 JAX 的类型提升](https://jax.readthedocs.io/en/latest/type_promotion.html)，请在为 TensorFlow 启用 NumPy 行为时指定 `'all'` 或 `'safe'` 作为数据类型转换模式。\n",
        "\n",
        "此新系统 (`dtype_conversion_mode=\"all\"`) 可结合、可交换，并且可以轻松控制最终的浮点数宽度（它不会自动转换为更宽的浮点数）。它确实引入了一些溢出和精度损失的风险，但 `dtype_conversion_mode=\"safe\"` 会强制您显式处理这些情况。[下一部分](#two_modes)将更详细地解释这两种模式。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TfCyofpFDQxm"
      },
      "outputs": [],
      "source": [
        "tnp.experimental_enable_numpy_behavior(dtype_conversion_mode=\"all\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEMXK8-ZWMun"
      },
      "source": [
        "<a name=\"two_modes\">\n",
        "</a>\n",
        "\n",
        "## 两种模式：ALL 模式与 SAFE 模式\n",
        "\n",
        "在新提升系统中，我们引入了两种模式：`ALL` 模式和 `SAFE` 模式。`SAFE` 模式用于减轻可能导致精度损失或位加宽的“风险”提升的担忧。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ULvTWj_KnHU"
      },
      "source": [
        "### 数据类型\n",
        "\n",
        "为简洁起见，我们将使用以下缩写。\n",
        "\n",
        "- `b` 表示 `tf.bool`\n",
        "- `u8` 表示 `tf.uint8`\n",
        "- `i16` 表示 `tf.int16`\n",
        "- `i32` 表示 `tf.int32`\n",
        "- `bf16` 表示 `tf.bfloat16`\n",
        "- `f32` 表示 `tf.float32`\n",
        "- `f64` 表示 `tf.float64`\n",
        "- `i32*` 表示 Python `int` 或弱类型 `i32`\n",
        "- `f32*` 表示 Python `float` 浮点型或弱类型 `f32`\n",
        "- `c128*` 表示 Python `complex` 或弱类型 `c128`\n",
        "\n",
        "星号 (*) 表示相应的类型是“弱类型”- 此类数据类型是由系统临时推断的，可以遵从其他数据类型。[此处](#weak_tensor)更详细地解释了这个概念。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXZxLCkuzzq3"
      },
      "source": [
        "### 精度损失运算示例\n",
        "\n",
        "在以下示例中，`ALL` 模式下允许使用 `i32` + `f32`，但由于精度损失的风险，`SAFE` 模式下不允许使用。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y-yeIvstWStL"
      },
      "outputs": [],
      "source": [
        "# i32 + f32 returns a f32 result in ALL mode.\n",
        "tnp.experimental_enable_numpy_behavior(dtype_conversion_mode=\"all\")\n",
        "a = tf.constant(10, dtype = tf.int32)\n",
        "b = tf.constant(5.0, dtype = tf.float32)\n",
        "a + b  # <tf.Tensor: shape=(), dtype=float32, numpy=15.0>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JNNmZow2WY3G"
      },
      "outputs": [],
      "source": [
        "# This promotion is not allowed in SAFE mode.\n",
        "tnp.experimental_enable_numpy_behavior(dtype_conversion_mode=\"safe\")\n",
        "a = tf.constant(10, dtype = tf.int32)\n",
        "b = tf.constant(5.0, dtype = tf.float32)\n",
        "try:\n",
        "  a + b\n",
        "except TypeError as e:\n",
        "   print(f'{type(e)}: {e}')  # TypeError: explicitly specify the dtype or switch to ALL mode."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0x4Qhff0AKS"
      },
      "source": [
        "### 位加宽运算示例\n",
        "\n",
        "在以下示例中，ALL 模式下允许使用 `i8` + `u32`，但由于位加宽，SAFE 模式下不允许使用，这意味着使用的位数多于输入中的位数。请注意，新的类型提升语义仅允许必要的位加宽。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Etbv-WoWzUXf"
      },
      "outputs": [],
      "source": [
        "# i8 + u32 returns an i64 result in ALL mode.\n",
        "tnp.experimental_enable_numpy_behavior(dtype_conversion_mode=\"all\")\n",
        "a = tf.constant(10, dtype = tf.int8)\n",
        "b = tf.constant(5, dtype = tf.uint32)\n",
        "a + b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yKRdvtvw0Lvt"
      },
      "outputs": [],
      "source": [
        "# This promotion is not allowed in SAFE mode.\n",
        "tnp.experimental_enable_numpy_behavior(dtype_conversion_mode=\"safe\")\n",
        "a = tf.constant(10, dtype = tf.int8)\n",
        "b = tf.constant(5, dtype = tf.uint32)\n",
        "try:\n",
        "  a + b\n",
        "except TypeError as e:\n",
        "   print(f'{type(e)}: {e}')  # TypeError: explicitly specify the dtype or switch to ALL mode."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yh2BwqUzH3C3"
      },
      "source": [
        "## 基于点阵的系统"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHUnfTPiYVN5"
      },
      "source": [
        "### 类型提升点阵\n",
        "\n",
        "新的类型提升行为通过以下类型提升点阵来确定：\n",
        "\n",
        "![Type Promotion Lattice](https://tensorflow.org/guide/images/new_type_promotion/type_promotion_lattice.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QykluwRyDDle"
      },
      "source": [
        "更具体地说，任何两种类型之间的提升是通过查找两个节点的第一个公共子节点（包括节点本身）来确定的。\n",
        "\n",
        "例如，在上图中，`i8` 和 `i32` 的第一个公共子节点是 `i32`，因为沿着箭头方向，这两个节点在 `i32` 处第一次相交。\n",
        "\n",
        "类似地，在另一个示例中，`u64` 和 `f16` 之间的结果提升类型为 `f16`。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nthziRHaDAUY"
      },
      "source": [
        "<a name=\"promotion_table\">\n",
        "</a>\n",
        "\n",
        "### 类型提升表\n",
        "\n",
        "按照点阵行进会生成下面的二进制提升表：\n",
        "\n",
        "**注**：`SAFE` 不允许高亮显示的单元格。`ALL` 模式允许全部情况。\n",
        "\n",
        "![Type Promotion Table](https://tensorflow.org/guide/images/new_type_promotion/type_promotion_table.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPDt5QTkucSC"
      },
      "source": [
        "## 新类型提升的优点\n",
        "\n",
        "我们针对新类型提升采用类似 JAX 的基于点阵的系统，它具有以下优点："
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUS_b13nue1p"
      },
      "source": [
        "<a name=\"lattice_system_design\">\n",
        "</a>\n",
        "\n",
        "#### 基于点阵的系统的优点\n",
        "\n",
        "首先，使用基于点阵的系统可以确保三个非常重要的属性：\n",
        "\n",
        "- 存在性：任何类型的组合都存在唯一的结果提升类型。\n",
        "- 交换性：`a + b = b + a`\n",
        "- 结合性：`a + (b + c) = (a + b) = c`\n",
        "\n",
        "这三个属性对于构建一致且可预测的类型提升语义至关重要。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sz88hRR6uhls"
      },
      "source": [
        "#### 类似 JAX 的点阵系统的优点\n",
        "\n",
        "类似 JAX 的点阵系统的另一个重要优点是，除了无符号整数之外，它避免了所有超出必要范围的提升。这意味着没有 64 位输入就无法获得 64 位结果。这对于加速器上的工作特别有利，因为它可以避免不必要的 64 位值，这在旧类型提升中十分常见。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlylb7ieOVbJ"
      },
      "source": [
        "不过，这需要一定的权衡：混合浮点/整数提升很容易导致精度损失。例如，在下面的示例中，`i64` + `f16` 会导致将 `i64` 提升为 `f16`。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "abqIkV02OXEF"
      },
      "outputs": [],
      "source": [
        "# The first input is promoted to f16 in ALL mode.\n",
        "tnp.experimental_enable_numpy_behavior(dtype_conversion_mode=\"all\")\n",
        "tf.constant(1, tf.int64) + tf.constant(3.2, tf.float16)  # <tf.Tensor: shape=(), dtype=float16, numpy=4.2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYnh1gZdObfI"
      },
      "source": [
        "为了缓解这种担忧，我们引入了 `SAFE` 模式，此模式会禁止这些“风险”提升。\n",
        "\n",
        "**注**：要详细了解构造点阵系统的设计注意事项，请参阅 [JAX 的类型提升语义设计](https://jax.readthedocs.io/en/latest/jep/9407-type-promotion.html)。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAc7LFV0S2dP"
      },
      "source": [
        "<a name=\"weak_tensor\">\n",
        "</a>\n",
        "\n",
        "## WeakTensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olQ2gsFlS9BH"
      },
      "source": [
        "### 概述\n",
        "\n",
        "*WeakTensor* 是“弱类型”的张量，类似于 [JAX 中的概念](https://jax.readthedocs.io/en/latest/type_promotion.html#weakly-typed-values-in-jax)。\n",
        "\n",
        "`WeakTensor` 的数据类型是由系统临时推断的，并且可以遵从其他数据类型。在新类型提升中引入此概念的目的是防止 TF 值与没有用户显式指定类型的值（例如 Python 标量文字）之间的二进制运算中出现不需要的类型提升。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYmoFIqZTFtw"
      },
      "source": [
        "例如，在下面的示例中，`tf.constant(1.2)` 被视为“弱”，因为它没有特定的数据类型。因此，`tf.constant(1.2)` 遵从 `tf.constant(3.1, tf.float16)` 的类型，产生 `f16` 输出。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eSBv_mzyTE97"
      },
      "outputs": [],
      "source": [
        "tf.constant(1.2) + tf.constant(3.1, tf.float16)  # <tf.Tensor: shape=(), dtype=float16, numpy=4.3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxuqBIFuTm5Z"
      },
      "source": [
        "### WeakTensor 构造\n",
        "\n",
        "如果您创建张量而不指定数据类型，则会创建 WeakTensor。可以通过检查张量字符串表示末尾的弱特性来检查张量是否为“弱”张量。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7UmunnJ8Tru3"
      },
      "source": [
        "**第一种情况**：使用没有用户指定数据类型的输入调用 `tf.constant` 时。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fLEtMluNTsI5"
      },
      "outputs": [],
      "source": [
        "tf.constant(5)  # <tf.Tensor: shape=(), dtype=int32, numpy=5, weak=True>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZQX6MBWHTt__"
      },
      "outputs": [],
      "source": [
        "tf.constant([5.0, 10.0, 3])  # <tf.Tensor: shape=(3,), dtype=float32, numpy=array([ 5., 10.,  3.], dtype=float32), weak=True>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ftsKSC5BTweP"
      },
      "outputs": [],
      "source": [
        "# A normal Tensor is created when dtype arg is specified.\n",
        "tf.constant(5, tf.int32)  # <tf.Tensor: shape=(), dtype=int32, numpy=5>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqhoRy5iTyag"
      },
      "source": [
        "**第二种情况**：当没有用户指定数据类型的输入被传递到[支持 WeakTensor 的 API](#weak_tensor_apis) 中时。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DuwpgoQJTzE-"
      },
      "outputs": [],
      "source": [
        "tf.math.abs([100.0, 4.0])  # <tf.Tensor: shape=(2,), dtype=float32, numpy=array([100., 4.], dtype=float32), weak=True>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTcoR1xvR39k"
      },
      "source": [
        "##开启新类型提升的效果\n",
        "\n",
        "以下是由于开启新类型提升而引起的更改的非详尽清单。\n",
        "\n",
        "- 提升结果更一致且可预测。\n",
        "- 降低位加宽的风险。\n",
        "- `tf.Tensor` 数学 dunder 方法使用新类型提升。\n",
        "- `tf.constant` 可以返回 `WeakTensor`。\n",
        "- 当传入一个数据类型与 `dtype` 参数不同的张量输入时，`tf.constant` 允许隐式转换。\n",
        "- `tf.Variable` 就地运算（`assign`、`assign-add`、`assign-sub`）允许隐式转换。\n",
        "- `tnp.array(1)` 和 `tnp.array(1.0)` 返回 32 位 WeakTensor。\n",
        "- 将创建 `WeakTensor` 用于[支持 WeakTensor 的一元和二元 API](#weak_tensor_apis)。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KyvonwYcsFX2"
      },
      "source": [
        "### 提升结果更一致且可预测性提升\n",
        "\n",
        "使用[基于点阵的系统](#lattice_system_design)允许新类型提升产生一致且可预测的类型提升结果。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0Z1njfb7lRa"
      },
      "source": [
        "#### 旧类型提升\n",
        "\n",
        "使用旧类型提升更改运算顺序会产生不一致的结果。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M1Ca9v4m7z8e"
      },
      "outputs": [],
      "source": [
        "# Setup\n",
        "tnp.experimental_enable_numpy_behavior(dtype_conversion_mode=\"legacy\")\n",
        "a = np.array(1, dtype=np.int8)\n",
        "b = tf.constant(1)\n",
        "c = np.array(1, dtype=np.float16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WwhTzJ-a4rTc"
      },
      "outputs": [],
      "source": [
        "# (a + b) + c throws an InvalidArgumentError.\n",
        "try:\n",
        "  tf.add(tf.add(a, b), c)\n",
        "except tf.errors.InvalidArgumentError as e:\n",
        "  print(f'{type(e)}: {e}')  # InvalidArgumentError"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d3qDgVYn7ezT"
      },
      "outputs": [],
      "source": [
        "# (b + a) + c returns an i32 result.\n",
        "tf.add(tf.add(b, a), c)  # <tf.Tensor: shape=(), dtype=int32, numpy=3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMH1skEs7oI5"
      },
      "source": [
        "#### 新类型提升\n",
        "\n",
        "无论顺序如何，新类型提升都会产生一致的结果。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BOHyJJ8z8uCN"
      },
      "outputs": [],
      "source": [
        "tnp.experimental_enable_numpy_behavior(dtype_conversion_mode=\"all\")\n",
        "a = np.array(1, dtype=np.int8)\n",
        "b = tf.constant(1)\n",
        "c = np.array(1, dtype=np.float16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZUKU70jf7E1l"
      },
      "outputs": [],
      "source": [
        "# (a + b) + c returns a f16 result.\n",
        "tf.add(tf.add(a, b), c)  # <tf.Tensor: shape=(), dtype=float16, numpy=3.0>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YOEycjFx7qDn"
      },
      "outputs": [],
      "source": [
        "# (b + a) + c also returns a f16 result.\n",
        "tf.add(tf.add(b, a), c)  # <tf.Tensor: shape=(), dtype=float16, numpy=3.0>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpGMkm6aJsn6"
      },
      "source": [
        "### 降低位加宽的风险"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxV2AL-U9Grg"
      },
      "source": [
        "#### 旧类型提升\n",
        "\n",
        "旧类型提升通常会产生 64 位结果。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7L1pxyvn9MlP"
      },
      "outputs": [],
      "source": [
        "tnp.experimental_enable_numpy_behavior(dtype_conversion_mode=\"legacy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zMJVFdWf4XHp"
      },
      "outputs": [],
      "source": [
        "np.array(3.2, np.float16) + tf.constant(1, tf.int8) + tf.constant(50)  # <tf.Tensor: shape=(), dtype=float64, numpy=54.19921875>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBhUH_wD9Is7"
      },
      "source": [
        "#### 新类型提升\n",
        "\n",
        "新类型提升返回所需位数最少的结果。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aJsj2ZyI9T9Y"
      },
      "outputs": [],
      "source": [
        "tnp.experimental_enable_numpy_behavior(dtype_conversion_mode=\"all\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jj0N_Plp4X9l"
      },
      "outputs": [],
      "source": [
        "np.array(3.2, np.float16) + tf.constant(1, tf.int8) + tf.constant(50)  # <tf.Tensor: shape=(), dtype=float16, numpy=54.2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKUx7xe-KZ5O"
      },
      "source": [
        "### tf.Tensor 数学 dunder 方法\n",
        "\n",
        "所有 `tf.Tensor` 数学 dunder 方法都将遵循新类型提升。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2c3icBUX4wNl"
      },
      "outputs": [],
      "source": [
        "-tf.constant(5)  # <tf.Tensor: shape=(), dtype=int32, numpy=-5, weak=True>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ydJHQjid45s7"
      },
      "outputs": [],
      "source": [
        "tf.constant(5, tf.int16) - tf.constant(1, tf.float32)  # <tf.Tensor: shape=(), dtype=float32, numpy=4.0>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLbIjIvbKqcU"
      },
      "source": [
        "### tf.Variable 就地运算\n",
        "\n",
        "`tf.Variable` 就地运算中允许隐式转换。\n",
        "\n",
        "**注**：任何导致数据类型与变量的原始数据类型不同的提升都是不允许的。原因是 `tf.Variable` 不能更改其数据类型。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QsXhyK1h-i5S"
      },
      "outputs": [],
      "source": [
        "tnp.experimental_enable_numpy_behavior(dtype_conversion_mode=\"all\")\n",
        "a = tf.Variable(10, tf.int32)\n",
        "a.assign_add(tf.constant(5, tf.int16))  # <tf.Variable shape=() dtype=int32, numpy=15>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PiA4H-otLDit"
      },
      "source": [
        "### tf.constant 隐式转换\n",
        "\n",
        "在旧类型提升中，`tf.constant` 要求输入张量与数据类型参数具有相同的数据类型。不过，在新类型提升中，我们将张量隐式转换为指定的数据类型。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ArrQ9Dj0_OR8"
      },
      "outputs": [],
      "source": [
        "tnp.experimental_enable_numpy_behavior(dtype_conversion_mode=\"all\")\n",
        "a = tf.constant(10, tf.int16)\n",
        "tf.constant(a, tf.float32)  # <tf.Tensor: shape=(), dtype=float32, numpy=10.0>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAcK_-XnLWaP"
      },
      "source": [
        "### TF-NumPy 数组\n",
        "\n",
        "对于使用新类型提升的 Python 输入，`tnp.array` 默认为 `i32*` 和 `f32*`。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K1pZnYNh_ahm"
      },
      "outputs": [],
      "source": [
        "tnp.array(1)  # <tf.Tensor: shape=(), dtype=int32, numpy=1, weak=True>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QoQl2PYP_fMT"
      },
      "outputs": [],
      "source": [
        "tnp.array(1.0)  # <tf.Tensor: shape=(), dtype=int32, numpy=1, weak=True>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wK5DpQ3Pz3k5"
      },
      "source": [
        "##输入类型推断\n",
        "\n",
        "下面是在新类型提升中推断不同输入类型的方式。\n",
        "\n",
        "- `tf.Tensor`：由于 `tf.Tensor` 具有数据类型属性，我们不做进一步的推断。\n",
        "- NumPy 类型：包括 `np.array(1)`、`np.int16(1)` 和 `np.float` 等类型。由于 NumPy 输入也具有数据类型属性，我们将数据类型属性作为结果推断类型。请注意，NumPy 默认为 `i64` 和 `f64`。\n",
        "- Python 标量/嵌套类型：包括 `1`、`[1, 2, 3]` 和 `(1.0, 2.0)` 等类型。\n",
        "    - Python `int` 被推断为 `i32*`。\n",
        "    - Python `float` 被推断为 `f32*`。\n",
        "    - Python `complex` 被推断为 `c128*`。\n",
        "- 如果输入不属于上述任何类别，但具有数据类型属性，我们将数据类型属性作为结果推断类型。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_SPfalfSPgg"
      },
      "source": [
        "# 延伸阅读\n",
        "\n",
        "新类型提升与 JAX-NumPy 的类型提升非常相似。如果想了解有关新类型提升和设计选择的更多详细信息，请查阅以下资源。\n",
        "\n",
        "- [JAX 类型提升语义](https://jax.readthedocs.io/en/latest/type_promotion.html)\n",
        "- [JAX 类型提升语义设计](https://jax.readthedocs.io/en/latest/jep/9407-type-promotion.html)\n",
        "- [旧 TF-NumPy 提升语义](https://tensorflow.google.cn/guide/tf_numpy#type_promotion)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qg5xBbImT31S"
      },
      "source": [
        "# 参考"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjB0CVhVXBfW"
      },
      "source": [
        "<a name=\"weak_tensor_apis\">\n",
        "</a>\n",
        "\n",
        "## 支持 WeakTensor 的 API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GVbqlN9aBS2"
      },
      "source": [
        "以下是支持 `WeakTensor` 的 API 列表。\n",
        "\n",
        "对于一元运算，这意味着如果传入没有用户指定类型的输入，它将返回 `WeakTensor`。\n",
        "\n",
        "对于二元运算，它将遵循[此处](#promotion_table)的提升表。它可能会也可能不会返回 `WeakTensor`，具体取决于两个输入的提升结果。\n",
        "\n",
        "**注**：支持所有数学运算（`+`、`-`、`*`、...）。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gi-G68Z8WN2P"
      },
      "source": [
        "- `tf.bitwise.invert`\n",
        "- `tf.clip_by_value`\n",
        "- `tf.debugging.check_numerics`\n",
        "- `tf.expand_dims`\n",
        "- `tf.identity`\n",
        "- `tf.image.adjust_brightness`\n",
        "- `tf.image.adjust_gamma`\n",
        "- `tf.image.extract_patches`\n",
        "- `tf.image.random_brightness`\n",
        "- `tf.image.stateless_random_brightness`\n",
        "- `tf.linalg.diag`\n",
        "- `tf.linalg.diag_part`\n",
        "- `tf.linalg.matmul`\n",
        "- `tf.linalg.matrix_transpose`\n",
        "- `tf.linalg.tensor_diag_part`\n",
        "- `tf.linalg.trace`\n",
        "- `tf.math.abs`\n",
        "- `tf.math.acos`\n",
        "- `tf.math.acosh`\n",
        "- `tf.math.add`\n",
        "- `tf.math.angle`\n",
        "- `tf.math.asin`\n",
        "- `tf.math.asinh`\n",
        "- `tf.math.atan`\n",
        "- `tf.math.atanh`\n",
        "- `tf.math.ceil`\n",
        "- `tf.math.conj`\n",
        "- `tf.math.cos`\n",
        "- `tf.math.cosh`\n",
        "- `tf.math.digamma`\n",
        "- `tf.math.divide_no_nan`\n",
        "- `tf.math.divide`\n",
        "- `tf.math.erf`\n",
        "- `tf.math.erfc`\n",
        "- `tf.math.erfcinv`\n",
        "- `tf.math.erfinv`\n",
        "- `tf.math.exp`\n",
        "- `tf.math.expm1`\n",
        "- `tf.math.floor`\n",
        "- `tf.math.floordiv`\n",
        "- `tf.math.floormod`\n",
        "- `tf.math.imag`\n",
        "- `tf.math.lgamma`\n",
        "- `tf.math.log1p`\n",
        "- `tf.math.log_sigmoid`\n",
        "- `tf.math.log`\n",
        "- `tf.math.multiply_no_nan`\n",
        "- `tf.math.multiply`\n",
        "- `tf.math.ndtri`\n",
        "- `tf.math.negative`\n",
        "- `tf.math.pow`\n",
        "- `tf.math.real`\n",
        "- `tf.math.real`\n",
        "- `tf.math.reciprocal_no_nan`\n",
        "- `tf.math.reciprocal`\n",
        "- `tf.math.reduce_euclidean_norm`\n",
        "- `tf.math.reduce_logsumexp`\n",
        "- `tf.math.reduce_max`\n",
        "- `tf.math.reduce_mean`\n",
        "- `tf.math.reduce_min`\n",
        "- `tf.math.reduce_prod`\n",
        "- `tf.math.reduce_std`\n",
        "- `tf.math.reduce_sum`\n",
        "- `tf.math.reduce_variance`\n",
        "- `tf.math.rint`\n",
        "- `tf.math.round`\n",
        "- `tf.math.rsqrt`\n",
        "- `tf.math.scalar_mul`\n",
        "- `tf.math.sigmoid`\n",
        "- `tf.math.sign`\n",
        "- `tf.math.sin`\n",
        "- `tf.math.sinh`\n",
        "- `tf.math.softplus`\n",
        "- `tf.math.special.bessel_i0`\n",
        "- `tf.math.special.bessel_i0e`\n",
        "- `tf.math.special.bessel_i1`\n",
        "- `tf.math.special.bessel_i1e`\n",
        "- `tf.math.special.bessel_j0`\n",
        "- `tf.math.special.bessel_j1`\n",
        "- `tf.math.special.bessel_k0`\n",
        "- `tf.math.special.bessel_k0e`\n",
        "- `tf.math.special.bessel_k1`\n",
        "- `tf.math.special.bessel_k1e`\n",
        "- `tf.math.special.bessel_y0`\n",
        "- `tf.math.special.bessel_y1`\n",
        "- `tf.math.special.dawsn`\n",
        "- `tf.math.special.expint`\n",
        "- `tf.math.special.fresnel_cos`\n",
        "- `tf.math.special.fresnel_sin`\n",
        "- `tf.math.special.spence`\n",
        "- `tf.math.sqrt`\n",
        "- `tf.math.square`\n",
        "- `tf.math.subtract`\n",
        "- `tf.math.tan`\n",
        "- `tf.math.tanh`\n",
        "- `tf.nn.depth_to_space`\n",
        "- `tf.nn.elu`\n",
        "- `tf.nn.gelu`\n",
        "- `tf.nn.leaky_relu`\n",
        "- `tf.nn.log_softmax`\n",
        "- `tf.nn.relu6`\n",
        "- `tf.nn.relu`\n",
        "- `tf.nn.selu`\n",
        "- `tf.nn.softsign`\n",
        "- `tf.nn.space_to_depth`\n",
        "- `tf.nn.swish`\n",
        "- `tf.ones_like`\n",
        "- `tf.realdiv`\n",
        "- `tf.reshape`\n",
        "- `tf.squeeze`\n",
        "- `tf.stop_gradient`\n",
        "- `tf.transpose`\n",
        "- `tf.truncatediv`\n",
        "- `tf.truncatemod`\n",
        "- `tf.zeros_like`\n",
        "- `tf.experimental.numpy.abs`\n",
        "- `tf.experimental.numpy.absolute`\n",
        "- `tf.experimental.numpy.amax`\n",
        "- `tf.experimental.numpy.amin`\n",
        "- `tf.experimental.numpy.angle`\n",
        "- `tf.experimental.numpy.arange`\n",
        "- `tf.experimental.numpy.arccos`\n",
        "- `tf.experimental.numpy.arccosh`\n",
        "- `tf.experimental.numpy.arcsin`\n",
        "- `tf.experimental.numpy.arcsinh`\n",
        "- `tf.experimental.numpy.arctan`\n",
        "- `tf.experimental.numpy.arctanh`\n",
        "- `tf.experimental.numpy.around`\n",
        "- `tf.experimental.numpy.array`\n",
        "- `tf.experimental.numpy.asanyarray`\n",
        "- `tf.experimental.numpy.asarray`\n",
        "- `tf.experimental.numpy.ascontiguousarray`\n",
        "- `tf.experimental.numpy.average`\n",
        "- `tf.experimental.numpy.bitwise_not`\n",
        "- `tf.experimental.numpy.cbrt`\n",
        "- `tf.experimental.numpy.ceil`\n",
        "- `tf.experimental.numpy.conj`\n",
        "- `tf.experimental.numpy.conjugate`\n",
        "- `tf.experimental.numpy.copy`\n",
        "- `tf.experimental.numpy.cos`\n",
        "- `tf.experimental.numpy.cosh`\n",
        "- `tf.experimental.numpy.cumprod`\n",
        "- `tf.experimental.numpy.cumsum`\n",
        "- `tf.experimental.numpy.deg2rad`\n",
        "- `tf.experimental.numpy.diag`\n",
        "- `tf.experimental.numpy.diagflat`\n",
        "- `tf.experimental.numpy.diagonal`\n",
        "- `tf.experimental.numpy.diff`\n",
        "- `tf.experimental.numpy.empty_like`\n",
        "- `tf.experimental.numpy.exp2`\n",
        "- `tf.experimental.numpy.exp`\n",
        "- `tf.experimental.numpy.expand_dims`\n",
        "- `tf.experimental.numpy.expm1`\n",
        "- `tf.experimental.numpy.fabs`\n",
        "- `tf.experimental.numpy.fix`\n",
        "- `tf.experimental.numpy.flatten`\n",
        "- `tf.experimental.numpy.flip`\n",
        "- `tf.experimental.numpy.fliplr`\n",
        "- `tf.experimental.numpy.flipud`\n",
        "- `tf.experimental.numpy.floor`\n",
        "- `tf.experimental.numpy.full_like`\n",
        "- `tf.experimental.numpy.imag`\n",
        "- `tf.experimental.numpy.log10`\n",
        "- `tf.experimental.numpy.log1p`\n",
        "- `tf.experimental.numpy.log2`\n",
        "- `tf.experimental.numpy.log`\n",
        "- `tf.experimental.numpy.max`\n",
        "- `tf.experimental.numpy.mean`\n",
        "- `tf.experimental.numpy.min`\n",
        "- `tf.experimental.numpy.moveaxis`\n",
        "- `tf.experimental.numpy.nanmean`\n",
        "- `tf.experimental.numpy.negative`\n",
        "- `tf.experimental.numpy.ones_like`\n",
        "- `tf.experimental.numpy.positive`\n",
        "- `tf.experimental.numpy.prod`\n",
        "- `tf.experimental.numpy.rad2deg`\n",
        "- `tf.experimental.numpy.ravel`\n",
        "- `tf.experimental.numpy.real`\n",
        "- `tf.experimental.numpy.reciprocal`\n",
        "- `tf.experimental.numpy.repeat`\n",
        "- `tf.experimental.numpy.reshape`\n",
        "- `tf.experimental.numpy.rot90`\n",
        "- `tf.experimental.numpy.round`\n",
        "- `tf.experimental.numpy.signbit`\n",
        "- `tf.experimental.numpy.sin`\n",
        "- `tf.experimental.numpy.sinc`\n",
        "- `tf.experimental.numpy.sinh`\n",
        "- `tf.experimental.numpy.sort`\n",
        "- `tf.experimental.numpy.sqrt`\n",
        "- `tf.experimental.numpy.square`\n",
        "- `tf.experimental.numpy.squeeze`\n",
        "- `tf.experimental.numpy.std`\n",
        "- `tf.experimental.numpy.sum`\n",
        "- `tf.experimental.numpy.swapaxes`\n",
        "- `tf.experimental.numpy.tan`\n",
        "- `tf.experimental.numpy.tanh`\n",
        "- `tf.experimental.numpy.trace`\n",
        "- `tf.experimental.numpy.transpose`\n",
        "- `tf.experimental.numpy.triu`\n",
        "- `tf.experimental.numpy.vander`\n",
        "- `tf.experimental.numpy.var`\n",
        "- `tf.experimental.numpy.zeros_like`"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "tf_numpy_type_promotion.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
