{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjN_IJ8mhJ-4"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "sY3Ffd83hK3b"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03Pw58e6mTHI"
      },
      "source": [
        "# TensorFlow 上的 NumPy API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WpGysDJmZsg"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td><a target=\"_blank\" href=\"https://tensorflow.google.cn/guide/tf_numpy\"><img src=\"https://tensorflow.google.cn/images/tf_logo_32px.png\">在  TensorFlow.org 上查看</a></td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/zh-cn/guide/tf_numpy.ipynb\"><img src=\"https://tensorflow.google.cn/images/colab_logo_32px.png\">在 Google Colab 运行</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/zh-cn/guide/tf_numpy.ipynb\"><img src=\"https://tensorflow.google.cn/images/GitHub-Mark-32px.png\">在 Github 上查看源代码</a>\n",
        "</td>\n",
        "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/zh-cn/guide/tf_numpy.ipynb\"><img src=\"https://tensorflow.google.cn/images/download_logo_32px.png\">下载笔记本</a>\n",
        "</td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2enCDi_FvCR"
      },
      "source": [
        "## 概述\n",
        "\n",
        "TensorFlow 实现了一部分 [NumPy API](https://numpy.org/doc/stable/index.html)，这些 API 以 `tf.experimental.numpy` 形式提供。这样可以运行由 TensorFlow 加速的 NumPy 代码，并使用 TensorFlow 的所有 API。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ob1HNwUmYR5b"
      },
      "source": [
        "## 安装\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AJR558zjAZQu"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow.experimental.numpy as tnp\n",
        "import timeit\n",
        "\n",
        "print(\"Using TensorFlow version %s\" % tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6tacoy0DU6e"
      },
      "source": [
        "### 启用 NumPy 行为\n",
        "\n",
        "要将 `tnp` 用作 NumPy，请为 TensorFlow 启用 NumPy 行为："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TfCyofpFDQxm"
      },
      "outputs": [],
      "source": [
        "tnp.experimental_enable_numpy_behavior()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "et9D5wq0D1H2"
      },
      "source": [
        "此调用可在 TensorFlow 中启用类型提升，并在将文字转换为张量时更改类型推断，以更严格地遵循 NumPy 标准。\n",
        "\n",
        "注意：此调用将更改整个 TensorFlow 的行为，而不仅仅是 `tf.experimental.numpy` 模块。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yh2BwqUzH3C3"
      },
      "source": [
        "## TensorFlow NumPy ND 数组\n",
        "\n",
        "称为 **ND Array** 的实例 `tf.experimental.numpy.ndarray` 表示放置在特定设备上的给定 `dtype` 的多维密集数组。它是 `tf.Tensor` 的别名。请查看 ND 数组类来获取有用的方法，例如 `ndarray.T`、`ndarray.reshape`、`ndarray.ravel` 等。\n",
        "\n",
        "首先，创建一个 ND 数组对象，然后调用不同的方法。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-BHJjxigJ2H1"
      },
      "outputs": [],
      "source": [
        "# Create an ND array and check out different attributes.\n",
        "ones = tnp.ones([5, 3], dtype=tnp.float32)\n",
        "print(\"Created ND array with shape = %s, rank = %s, \"\n",
        "      \"dtype = %s on device = %s\\n\" % (\n",
        "          ones.shape, ones.ndim, ones.dtype, ones.device))\n",
        "\n",
        "# `ndarray` is just an alias to `tf.Tensor`.\n",
        "print(\"Is `ones` an instance of tf.Tensor: %s\\n\" % isinstance(ones, tf.Tensor))\n",
        "\n",
        "# Try commonly used member functions.\n",
        "print(\"ndarray.T has shape %s\" % str(ones.T.shape))\n",
        "print(\"narray.reshape(-1) has shape %s\" % ones.reshape(-1).shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BOY8CGRKEhE"
      },
      "source": [
        "### 类型提升\n",
        "\n",
        "TensorFlow 中的类型提升有 4 个选项。\n",
        "\n",
        "- 默认情况下，TensorFlow 会引发错误，而不是提升混合类型运算的类型。\n",
        "- 运行 `tf.numpy.experimental_enable_numpy_behavior()` 会将 TensorFlow 切换为使用 `NumPy` 类型提升规则（如下所述）。\n",
        "- 在 TensorFlow 2.15 之后，有两个新选项（有关详细信息，请参阅 [TF NumPy 类型提升](tf_numpy_type_promotion.ipynb)）：\n",
        "    - `tf.numpy.experimental_enable_numpy_behavior(dtype_conversion_mode=\"all\")` 使用 Jax 类型提升规则。\n",
        "    - `tf.numpy.experimental_enable_numpy_behavior(dtype_conversion_mode=\"safe\")` 使用 Jax 类型提升规则，但不允许某些不安全的提升。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXskSHrX5J45"
      },
      "source": [
        "#### NumPy 类型提升\n",
        "\n",
        "TensorFlow NumPy API 具有明确定义的语义，可用于将文字转换为 ND 数组，以及对 ND 数组输入执行类型提升。有关更多详细信息，请参阅 [`np.result_type`](https://numpy.org/doc/1.16/reference/generated/numpy.result_type.html)。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcRznNaMj27J"
      },
      "source": [
        "TensorFlow API 保持 `tf.Tensor` 输入不变并且不对其执行类型提升，而 TensorFlow NumPy API 则根据 NumPy 类型提升规则来提升所有输入。在下一个示例中，您将执行类型提升。首先，对不同类型的 ND 数组输入运行加法并记下输出类型。TensorFlow API 不允许这些类型提升。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uHmBi4KZI2t1"
      },
      "outputs": [],
      "source": [
        "print(\"Type promotion for operations\")\n",
        "values = [tnp.asarray(1, dtype=d) for d in\n",
        "          (tnp.int32, tnp.int64, tnp.float32, tnp.float64)]\n",
        "for i, v1 in enumerate(values):\n",
        "  for v2 in values[i + 1:]:\n",
        "    print(\"%s + %s => %s\" %\n",
        "          (v1.dtype.name, v2.dtype.name, (v1 + v2).dtype.name))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrpIoOc7oqox"
      },
      "source": [
        "最后，使用 `ndarray.asarray` 将文字转换为 ND 数组，并记录结果类型。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1m1cp8_VooNk"
      },
      "outputs": [],
      "source": [
        "print(\"Type inference during array creation\")\n",
        "print(\"tnp.asarray(1).dtype == tnp.%s\" % tnp.asarray(1).dtype.name)\n",
        "print(\"tnp.asarray(1.).dtype == tnp.%s\\n\" % tnp.asarray(1.).dtype.name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kd-_iccXoRL8"
      },
      "source": [
        "将文字转换为 ND 数组时，NumPy 倾向于使用 `tnp.int64` 和 `tnp.float64` 之类的宽类型。相反，`tf.convert_to_tensor` 则倾向于使用 `tf.int32` 和 `tf.float32` 类型将常量转换为 `tf.Tensor`。TensorFlow NumPy API 遵循整数的 NumPy 行为。对于浮点数，`experimental_enable_numpy_behavior` 的 `prefer_float32` 参数可让您控制倾向于使用 `tf.float32` 而不是 `tf.float64`（默认为 `False`）。例如："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4gKasnH0j84C"
      },
      "outputs": [],
      "source": [
        "tnp.experimental_enable_numpy_behavior(prefer_float32=True)\n",
        "print(\"When prefer_float32 is True:\")\n",
        "print(\"tnp.asarray(1.).dtype == tnp.%s\" % tnp.asarray(1.).dtype.name)\n",
        "print(\"tnp.add(1., 2.).dtype == tnp.%s\" % tnp.add(1., 2.).dtype.name)\n",
        "\n",
        "tnp.experimental_enable_numpy_behavior(prefer_float32=False)\n",
        "print(\"When prefer_float32 is False:\")\n",
        "print(\"tnp.asarray(1.).dtype == tnp.%s\" % tnp.asarray(1.).dtype.name)\n",
        "print(\"tnp.add(1., 2.).dtype == tnp.%s\" % tnp.add(1., 2.).dtype.name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwCCDxSZOfA1"
      },
      "source": [
        "### 广播\n",
        "\n",
        "与 TensorFlow 类似，NumPy 为“广播”值定义了丰富的语义。您可以查看 [NumPy 广播指南](https://numpy.org/doc/stable/user/basics.broadcasting.html)了解更多信息，还可将其与 [TensorFlow 广播语义](https://tensorflow.google.cn/guide/tensor#broadcasting)进行比较。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qlyOShxIO0s2"
      },
      "outputs": [],
      "source": [
        "x = tnp.ones([2, 3])\n",
        "y = tnp.ones([3])\n",
        "z = tnp.ones([1, 2, 1])\n",
        "print(\"Broadcasting shapes %s, %s and %s gives shape %s\" % (\n",
        "    x.shape, y.shape, z.shape, (x + y + z).shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEVr4ctRPrqR"
      },
      "source": [
        "### 索引\n",
        "\n",
        "NumPy 定义了非常复杂的索引规则。请参阅 [NumPy 索引指南](https://numpy.org/doc/1.16/reference/arrays.indexing.html)。请注意，下面的示例将 ND 数组用作索引。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lRsrtnd3YyMj"
      },
      "outputs": [],
      "source": [
        "x = tnp.arange(24).reshape(2, 3, 4)\n",
        "\n",
        "print(\"Basic indexing\")\n",
        "print(x[1, tnp.newaxis, 1:3, ...], \"\\n\")\n",
        "\n",
        "print(\"Boolean indexing\")\n",
        "print(x[:, (True, False, True)], \"\\n\")\n",
        "\n",
        "print(\"Advanced indexing\")\n",
        "print(x[1, (0, 0, 1), tnp.asarray([0, 1, 1])])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yRAaiGhlaNw7"
      },
      "outputs": [],
      "source": [
        "# Mutation is currently not supported\n",
        "try:\n",
        "  tnp.arange(6)[1] = -1\n",
        "except TypeError:\n",
        "  print(\"Currently, TensorFlow NumPy does not support mutation.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XfJ602j-GVD"
      },
      "source": [
        "### 示例模型\n",
        "\n",
        "接下来，您将看到如何创建一个模型并在该模型上运行推断。此简单模型应用 ReLU 层，随后是线性投影。后面的部分将展示如何使用 TensorFlow 的 `GradientTape` 计算此模型的梯度。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kR_KCh4kYEhm"
      },
      "outputs": [],
      "source": [
        "class Model(object):\n",
        "  \"\"\"Model with a dense and a linear layer.\"\"\"\n",
        "\n",
        "  def __init__(self):\n",
        "    self.weights = None\n",
        "\n",
        "  def predict(self, inputs):\n",
        "    if self.weights is None:\n",
        "      size = inputs.shape[1]\n",
        "      # Note that type `tnp.float32` is used for performance.\n",
        "      stddev = tnp.sqrt(size).astype(tnp.float32)\n",
        "      w1 = tnp.random.randn(size, 64).astype(tnp.float32) / stddev\n",
        "      bias = tnp.random.randn(64).astype(tnp.float32)\n",
        "      w2 = tnp.random.randn(64, 2).astype(tnp.float32) / 8\n",
        "      self.weights = (w1, bias, w2)\n",
        "    else:\n",
        "      w1, bias, w2 = self.weights\n",
        "    y = tnp.matmul(inputs, w1) + bias\n",
        "    y = tnp.maximum(y, 0)  # Relu\n",
        "    return tnp.matmul(y, w2)  # Linear projection\n",
        "\n",
        "model = Model()\n",
        "# Create input data and compute predictions.\n",
        "print(model.predict(tnp.ones([2, 32], dtype=tnp.float32)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSR7Ou5YcS38"
      },
      "source": [
        "## TensorFlow NumPy 和 NumPy\n",
        "\n",
        "TensorFlow NumPy 实现了完整 NumPy 规范的子集。尽管随着时间的推移会添加更多符号，但一些系统功能在不久的将来将不再受支持。这些功能包括 NumPy C API 支持、Swig 集成、Fortran 存储顺序、视图和 `stride_tricks` 以及一些 `dtype`（例如 `np.recarray`、`np.object`）。有关更多详细信息，请参阅 [TensorFlow NumPy API 文档](https://tensorflow.google.cn/api_docs/python/tf/experimental/numpy)。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jb1KXak2YlNN"
      },
      "source": [
        "### NumPy 互操作性\n",
        "\n",
        "TensorFlow ND 数组可与 NumPy 函数互操作。这些对象实现了 `__array__` 接口。NumPy 使用此接口先将函数参数转换为 `np.ndarray` 值，然后再对它们进行处理。\n",
        "\n",
        "同样，TensorFlow NumPy 函数可以接受不同类型的输入，包括 `np.ndarray`。通过在它们上面调用 `ndarray.asarray` 可将这些输入转换为 ND 数组。\n",
        "\n",
        "ND 数组与 `np.ndarray` 之间的转换可能会触发实际数据副本。有关更多详细信息，请参阅关于[缓冲区副本](#Buffer-copies)的部分。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cMOCgzQmeXRU"
      },
      "outputs": [],
      "source": [
        "# ND array passed into NumPy function.\n",
        "np_sum = np.sum(tnp.ones([2, 3]))\n",
        "print(\"sum = %s. Class: %s\" % (float(np_sum), np_sum.__class__))\n",
        "\n",
        "# `np.ndarray` passed into TensorFlow NumPy function.\n",
        "tnp_sum = tnp.sum(np.ones([2, 3]))\n",
        "print(\"sum = %s. Class: %s\" % (float(tnp_sum), tnp_sum.__class__))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZaLPjzxft780"
      },
      "outputs": [],
      "source": [
        "# It is easy to plot ND arrays, given the __array__ interface.\n",
        "labels = 15 + 2 * tnp.random.randn(1, 1000)\n",
        "_ = plt.hist(labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kF-Xyw3XWKqJ"
      },
      "source": [
        "### 缓冲区副本\n",
        "\n",
        "混合使用 TensorFlow NumPy 与 NumPy 代码可能会触发数据副本。这是因为 TensorFlow NumPy 对内存对齐的要求比 NumPy 更严格。\n",
        "\n",
        "当 `np.ndarray` 传递给 TensorFlow NumPy 时，它将检查对齐要求，并在需要时触发副本。将 ND 数组 CPU 缓冲区传递给 NumPy 时，该缓冲区通常会满足对齐要求，并且 NumPy 无需创建副本。\n",
        "\n",
        "ND 数组可以引用放置在本地 CPU 内存以外设备上的缓冲区。在这种情况下，调用 NumPy 函数将根据需要触发网络或设备上的副本。\n",
        "\n",
        "有鉴于此，与 NumPy API 调用混合使用时通常应谨慎操作，并且用户应当注意复制数据的开销。将 TensorFlow NumPy 调用与 TensorFlow 调用交错通常是安全的，可避免复制数据。有关更多详细信息，请参阅关于 [Tensorflow 互操作性](#tensorflow-interoperability)的部分。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RwljbqkBc7Ro"
      },
      "source": [
        "### 算子优先级\n",
        "\n",
        "TensorFlow NumPy 定义了一个优先级高于 NumPy 的 `__array_priority__`。这意味着，对于同时涉及 ND 数组和 `np.ndarray` 的算子，前者将获得优先权，即 `np.ndarray` 输入将转换为 ND 数组，并且将调用该算子的 TensorFlow NumPy 实现。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cbw8a3G_WUO7"
      },
      "outputs": [],
      "source": [
        "x = tnp.ones([2]) + np.ones([2])\n",
        "print(\"x = %s\\nclass = %s\" % (x, x.__class__))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNEab_Ctky83"
      },
      "source": [
        "## TF NumPy 和 TensorFlow\n",
        "\n",
        "TensorFlow NumPy 在 TensorFlow 上构建，因此可与 TensorFlow 无缝互操作。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fCcfgrlOnAhQ"
      },
      "source": [
        "### `tf.Tensor` 和 ND 数组\n",
        "\n",
        "ND 数组是 `tf.Tensor` 的别名，因此显然可以在不触发实际数据副本的情况下将它们混合到一起。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BkHVauKwnky_"
      },
      "outputs": [],
      "source": [
        "x = tf.constant([1, 2])\n",
        "print(x)\n",
        "\n",
        "# `asarray` and `convert_to_tensor` here are no-ops.\n",
        "tnp_x = tnp.asarray(x)\n",
        "print(tnp_x)\n",
        "print(tf.convert_to_tensor(tnp_x))\n",
        "\n",
        "# Note that tf.Tensor.numpy() will continue to return `np.ndarray`.\n",
        "print(x.numpy(), x.numpy().__class__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_151HQVBooxG"
      },
      "source": [
        "### TensorFlow 互操作性\n",
        "\n",
        "ND 数组可以传递给 TensorFlow API，因为 ND 数组只是 `tf.Tensor` 的别名。如上文所述，即使是放置在加速器或远程设备上的数据，这种互操作也不会创建数据副本。\n",
        "\n",
        "相反，可以将 `tf.Tensor` 对象传递给 `tf.experimental.numpy` API，而无需执行数据副本。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-QvxNhrFoz09"
      },
      "outputs": [],
      "source": [
        "# ND array passed into TensorFlow function.\n",
        "tf_sum = tf.reduce_sum(tnp.ones([2, 3], tnp.float32))\n",
        "print(\"Output = %s\" % tf_sum)\n",
        "\n",
        "# `tf.Tensor` passed into TensorFlow NumPy function.\n",
        "tnp_sum = tnp.sum(tf.ones([2, 3]))\n",
        "print(\"Output = %s\" % tnp_sum)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1b4HeAkhprF_"
      },
      "source": [
        "### 梯度和雅可比矩阵：tf.GradientTape\n",
        "\n",
        "TensorFlow 的 GradientTape 可通过 TensorFlow 和 TensorFlow NumPy 代码用于反向传播。\n",
        "\n",
        "使用在[示例模型](#example-modle)部分中创建的模型，并计算梯度和雅可比矩阵。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T47C9KS8pbsP"
      },
      "outputs": [],
      "source": [
        "def create_batch(batch_size=32):\n",
        "  \"\"\"Creates a batch of input and labels.\"\"\"\n",
        "  return (tnp.random.randn(batch_size, 32).astype(tnp.float32),\n",
        "          tnp.random.randn(batch_size, 2).astype(tnp.float32))\n",
        "\n",
        "def compute_gradients(model, inputs, labels):\n",
        "  \"\"\"Computes gradients of squared loss between model prediction and labels.\"\"\"\n",
        "  with tf.GradientTape() as tape:\n",
        "    assert model.weights is not None\n",
        "    # Note that `model.weights` need to be explicitly watched since they\n",
        "    # are not tf.Variables.\n",
        "    tape.watch(model.weights)\n",
        "    # Compute prediction and loss\n",
        "    prediction = model.predict(inputs)\n",
        "    loss = tnp.sum(tnp.square(prediction - labels))\n",
        "  # This call computes the gradient through the computation above.\n",
        "  return tape.gradient(loss, model.weights)\n",
        "\n",
        "inputs, labels = create_batch()\n",
        "gradients = compute_gradients(model, inputs, labels)\n",
        "\n",
        "# Inspect the shapes of returned gradients to verify they match the\n",
        "# parameter shapes.\n",
        "print(\"Parameter shapes:\", [w.shape for w in model.weights])\n",
        "print(\"Gradient shapes:\", [g.shape for g in gradients])\n",
        "# Verify that gradients are of type ND array.\n",
        "assert isinstance(gradients[0], tnp.ndarray)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TujVPDFwrdqp"
      },
      "outputs": [],
      "source": [
        "# Computes a batch of jacobians. Each row is the jacobian of an element in the\n",
        "# batch of outputs w.r.t. the corresponding input batch element.\n",
        "def prediction_batch_jacobian(inputs):\n",
        "  with tf.GradientTape() as tape:\n",
        "    tape.watch(inputs)\n",
        "    prediction = model.predict(inputs)\n",
        "  return prediction, tape.batch_jacobian(prediction, inputs)\n",
        "\n",
        "inp_batch = tnp.ones([16, 32], tnp.float32)\n",
        "output, batch_jacobian = prediction_batch_jacobian(inp_batch)\n",
        "# Note how the batch jacobian shape relates to the input and output shapes.\n",
        "print(\"Output shape: %s, input shape: %s\" % (output.shape, inp_batch.shape))\n",
        "print(\"Batch jacobian shape:\", batch_jacobian.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYq9wxfc1Dv_"
      },
      "source": [
        "### 跟踪编译：tf.function\n",
        "\n",
        "TensorFlow 的 `tf.function` 的工作方式是先“跟踪编译”代码，然后优化这些跟踪记录来提高性能。请参阅[计算图和函数简介](./intro_to_graphs.ipynb)。\n",
        "\n",
        "`tf.function` 也可用于优化 TensorFlow NumPy 代码。下面是一个演示加速的简单示例。请注意， `tf.function` 代码的主体包括对 TensorFlow NumPy API 的调用。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "05SrUulm1OlL"
      },
      "outputs": [],
      "source": [
        "inputs, labels = create_batch(512)\n",
        "print(\"Eager performance\")\n",
        "compute_gradients(model, inputs, labels)\n",
        "print(timeit.timeit(lambda: compute_gradients(model, inputs, labels),\n",
        "                    number=10) * 100, \"ms\")\n",
        "\n",
        "print(\"\\ntf.function compiled performance\")\n",
        "compiled_compute_gradients = tf.function(compute_gradients)\n",
        "compiled_compute_gradients(model, inputs, labels)  # warmup\n",
        "print(timeit.timeit(lambda: compiled_compute_gradients(model, inputs, labels),\n",
        "                    number=10) * 100, \"ms\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5w8YxR6ELmo1"
      },
      "source": [
        "### 向量化：tf.vectorized_map\n",
        "\n",
        "TensorFlow 内置对向量化并行循环的支持，可以将速度提高一到两个数量级。这些加速可通过 `tf.vectorized_map`  API 访问，并且也适用于 TensorFlow NumPy 代码。\n",
        "\n",
        "有时，计算一个批次中每个输出相对于相应的输入批次元素的梯度十分有用。可以使用 `tf.vectorized_map` 有效地完成此类计算，具体如下所示。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PemSIrs5L-VJ"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def vectorized_per_example_gradients(inputs, labels):\n",
        "  def single_example_gradient(arg):\n",
        "    inp, label = arg\n",
        "    return compute_gradients(model,\n",
        "                             tnp.expand_dims(inp, 0),\n",
        "                             tnp.expand_dims(label, 0))\n",
        "  # Note that a call to `tf.vectorized_map` semantically maps\n",
        "  # `single_example_gradient` over each row of `inputs` and `labels`.\n",
        "  # The interface is similar to `tf.map_fn`.\n",
        "  # The underlying machinery vectorizes away this map loop which gives\n",
        "  # nice speedups.\n",
        "  return tf.vectorized_map(single_example_gradient, (inputs, labels))\n",
        "\n",
        "batch_size = 128\n",
        "inputs, labels = create_batch(batch_size)\n",
        "\n",
        "per_example_gradients = vectorized_per_example_gradients(inputs, labels)\n",
        "for w, p in zip(model.weights, per_example_gradients):\n",
        "  print(\"Weight shape: %s, batch size: %s, per example gradient shape: %s \" % (\n",
        "      w.shape, batch_size, p.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_QZ5BjJmRAlG"
      },
      "outputs": [],
      "source": [
        "# Benchmark the vectorized computation above and compare with\n",
        "# unvectorized sequential computation using `tf.map_fn`.\n",
        "@tf.function\n",
        "def unvectorized_per_example_gradients(inputs, labels):\n",
        "  def single_example_gradient(arg):\n",
        "    inp, label = arg\n",
        "    return compute_gradients(model,\n",
        "                             tnp.expand_dims(inp, 0),\n",
        "                             tnp.expand_dims(label, 0))\n",
        "\n",
        "  return tf.map_fn(single_example_gradient, (inputs, labels),\n",
        "                   fn_output_signature=(tf.float32, tf.float32, tf.float32))\n",
        "\n",
        "print(\"Running vectorized computation\")\n",
        "print(timeit.timeit(lambda: vectorized_per_example_gradients(inputs, labels),\n",
        "                    number=10) * 100, \"ms\")\n",
        "\n",
        "print(\"\\nRunning unvectorized computation\")\n",
        "per_example_gradients = unvectorized_per_example_gradients(inputs, labels)\n",
        "print(timeit.timeit(lambda: unvectorized_per_example_gradients(inputs, labels),\n",
        "                    number=10) * 100, \"ms\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOTh-nkzaJd9"
      },
      "source": [
        "### 设备放置\n",
        "\n",
        "TensorFlow NumPy 可以将运算置于 CPU、GPU、TPU 和远程设备上。它使用标准的 TensorFlow 机制完成设备放置。下面我们将给出一个简单的示例，先列出所有设备，然后在特定设备上放置一些计算。\n",
        "\n",
        "TenorFlow 还具有用于在设备之间复制计算并执行集体缩减的 API，这里不作介绍。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0gHrwYYaTCE"
      },
      "source": [
        "#### 列出设备\n",
        "\n",
        "可以使用 `tf.config.list_logical_devices` 和 `tf.config.list_physical_devices` 查找要使用的设备。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NDEAd9m9aemS"
      },
      "outputs": [],
      "source": [
        "print(\"All logical devices:\", tf.config.list_logical_devices())\n",
        "print(\"All physical devices:\", tf.config.list_physical_devices())\n",
        "\n",
        "# Try to get the GPU device. If unavailable, fallback to CPU.\n",
        "try:\n",
        "  device = tf.config.list_logical_devices(device_type=\"GPU\")[0]\n",
        "except IndexError:\n",
        "  device = \"/device:CPU:0\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fihgfF_tahVx"
      },
      "source": [
        "#### 放置运算：**`tf.device`**\n",
        "\n",
        "通过在 `tf.device` 范围内调用设备，可以将运算放置在该设备上。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c7ELvLmnazfV"
      },
      "outputs": [],
      "source": [
        "print(\"Using device: %s\" % str(device))\n",
        "# Run operations in the `tf.device` scope.\n",
        "# If a GPU is available, these operations execute on the GPU and outputs are\n",
        "# placed on the GPU memory.\n",
        "with tf.device(device):\n",
        "  prediction = model.predict(create_batch(5)[0])\n",
        "\n",
        "print(\"prediction is placed on %s\" % prediction.device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-LK6wsHbBiM"
      },
      "source": [
        "#### 跨设备复制 ND 数组：**`tnp.copy`**\n",
        "\n",
        "调用位于某个设备范围内的 `tnp.copy` 会将数据复制到该设备，除非这些数据已存在于该设备上。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CCesyidaa-UT"
      },
      "outputs": [],
      "source": [
        "with tf.device(\"/device:CPU:0\"):\n",
        "  prediction_cpu = tnp.copy(prediction)\n",
        "print(prediction.device)\n",
        "print(prediction_cpu.device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AiYzRDOtKzAH"
      },
      "source": [
        "## 性能比较\n",
        "\n",
        "TensorFlow NumPy 使用高度优化的 TensorFlow 内核，这些内核可在 CPU、GPU 和 TPU 上调度。TensorFlow 还执行许多编译器优化（如运算融合），这些优化可转化为性能和内存改进。要了解更多信息，请参阅[使用 Grappler 进行 TensorFlow 计算图优化](./guide/graph_optimization)。\n",
        "\n",
        "但是，与 NumPy 相比，TensorFlow 在调度运算上的开销更高。对于由小型运算（短于约 10 微秒）组成的工作负载，这些开销会占用大部分运行时，此时，NumPy 可以提供更好的性能。对于其他情况，TensorFlow 通常会提供更好的性能。\n",
        "\n",
        "运行以下基准测试来比较 NumPy 和 TensorFlow NumPy 在不同输入大小下的性能。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "code",
        "id": "RExwjI9_pJG0"
      },
      "outputs": [],
      "source": [
        "def benchmark(f, inputs, number=30, force_gpu_sync=False):\n",
        "  \"\"\"Utility to benchmark `f` on each value in `inputs`.\"\"\"\n",
        "  times = []\n",
        "  for inp in inputs:\n",
        "    def _g():\n",
        "      if force_gpu_sync:\n",
        "        one = tnp.asarray(1)\n",
        "      f(inp)\n",
        "      if force_gpu_sync:\n",
        "        with tf.device(\"CPU:0\"):\n",
        "          tnp.copy(one)  # Force a sync for GPU case\n",
        "\n",
        "    _g()  # warmup\n",
        "    t = timeit.timeit(_g, number=number)\n",
        "    times.append(t * 1000. / number)\n",
        "  return times\n",
        "\n",
        "\n",
        "def plot(np_times, tnp_times, compiled_tnp_times, has_gpu, tnp_times_gpu):\n",
        "  \"\"\"Plot the different runtimes.\"\"\"\n",
        "  plt.xlabel(\"size\")\n",
        "  plt.ylabel(\"time (ms)\")\n",
        "  plt.title(\"Sigmoid benchmark: TF NumPy vs NumPy\")\n",
        "  plt.plot(sizes, np_times, label=\"NumPy\")\n",
        "  plt.plot(sizes, tnp_times, label=\"TF NumPy (CPU)\")\n",
        "  plt.plot(sizes, compiled_tnp_times, label=\"Compiled TF NumPy (CPU)\")\n",
        "  if has_gpu:\n",
        "    plt.plot(sizes, tnp_times_gpu, label=\"TF NumPy (GPU)\")\n",
        "  plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p-fs_H1lkLfV"
      },
      "outputs": [],
      "source": [
        "# Define a simple implementation of `sigmoid`, and benchmark it using\n",
        "# NumPy and TensorFlow NumPy for different input sizes.\n",
        "\n",
        "def np_sigmoid(y):\n",
        "  return 1. / (1. + np.exp(-y))\n",
        "\n",
        "def tnp_sigmoid(y):\n",
        "  return 1. / (1. + tnp.exp(-y))\n",
        "\n",
        "@tf.function\n",
        "def compiled_tnp_sigmoid(y):\n",
        "  return tnp_sigmoid(y)\n",
        "\n",
        "sizes = (2 ** 0, 2 ** 5, 2 ** 10, 2 ** 15, 2 ** 20)\n",
        "np_inputs = [np.random.randn(size).astype(np.float32) for size in sizes]\n",
        "np_times = benchmark(np_sigmoid, np_inputs)\n",
        "\n",
        "with tf.device(\"/device:CPU:0\"):\n",
        "  tnp_inputs = [tnp.random.randn(size).astype(np.float32) for size in sizes]\n",
        "  tnp_times = benchmark(tnp_sigmoid, tnp_inputs)\n",
        "  compiled_tnp_times = benchmark(compiled_tnp_sigmoid, tnp_inputs)\n",
        "\n",
        "has_gpu = len(tf.config.list_logical_devices(\"GPU\"))\n",
        "if has_gpu:\n",
        "  with tf.device(\"/device:GPU:0\"):\n",
        "    tnp_inputs = [tnp.random.randn(size).astype(np.float32) for size in sizes]\n",
        "    tnp_times_gpu = benchmark(compiled_tnp_sigmoid, tnp_inputs, 100, True)\n",
        "else:\n",
        "  tnp_times_gpu = None\n",
        "plot(np_times, tnp_times, compiled_tnp_times, has_gpu, tnp_times_gpu)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ReK_9k5D8BZQ"
      },
      "source": [
        "## 延伸阅读\n",
        "\n",
        "- [TensorFlow NumPy：分布式图像分类教程](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/numpy_ops/g3doc/TensorFlow_Numpy_Distributed_Image_Classification.ipynb)\n",
        "- [TensorFlow NumPy：Keras 和分布策略](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/numpy_ops/g3doc/TensorFlow_NumPy_Keras_and_Distribution_Strategy.ipynb)\n",
        "- [使用 Trax 和 TensorFlow NumPy 进行情感分析](https://github.com/google/trax/blob/master/trax/tf_numpy_and_keras.ipynb)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "tf_numpy.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
