{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tce3stUlHN0L"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tuOe1ymfHZPu"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drGgRRpWf2Qm"
      },
      "source": [
        "# 使用稀疏张量"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfBg1C5NB3X0"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>     <a target=\"_blank\" href=\"https://tensorflow.google.cn/guide/sparse_tensor\"><img src=\"https://tensorflow.google.cn/images/tf_logo_32px.png\">在 TensorFlow.org 上查看</a> </td>\n",
        "  <td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/zh-cn/guide/sparse_tensor_guide.ipynb\"><img src=\"https://tensorflow.google.cn/images/colab_logo_32px.png\">在 Google Colab 中运行</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/zh-cn/guide/sparse_tensor_guide.ipynb\">     <img src=\"https://tensorflow.google.cn/images/GitHub-Mark-32px.png\">     在 GitHub 上查看源代码</a></td>\n",
        "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/zh-cn/guide/sparse_tensor_guide.ipynb\"><img src=\"https://tensorflow.google.cn/images/download_logo_32px.png\">下载笔记本</a>   </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIiXFIS4fj1m"
      },
      "source": [
        "使用包含大量零值的张量时，务必以节省空间和时间的方式存储它们。稀疏张量可以高效存储和处理包含大量零值的张量。稀疏张量广泛用于 [TF-IDF](https://en.wikipedia.org/wiki/Tf%E2%80%93idf) 等编码方案，作为 NLP 应用中数据预处理的一部分，以及在计算机视觉应用中预处理具有大量暗像素的图像。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8XXQW3ENU5m"
      },
      "source": [
        "## TensorFlow 中的稀疏张量\n",
        "\n",
        "TensorFlow 通过 `tf.sparse.SparseTensor` 对象表示稀疏张量。目前，TensorFlow 中的稀疏张量使用坐标列表 (COO) 格式进行编码。这种编码格式针对嵌入向量等超稀疏矩阵进行了优化。\n",
        "\n",
        "稀疏张量的 COO 编码包括：\n",
        "\n",
        "- `values`：形状为 `[N]` 的一维张量，包含所有非零值。\n",
        "- `indices`：形状为 `[N, rank]` 的二维张量，包含非零值的索引。\n",
        "- `dense_shape`：形状为 `[rank]` 的一维张量，指定张量的形状。\n",
        "\n",
        "`tf.sparse.SparseTensor` 上下文中的***非零***值是未显式编码的值。可以在 COO 稀疏矩阵的 `values` 中显式包含零值，但在稀疏张量中引用非零值时，通常不包含这些“显式零”。\n",
        "\n",
        "注：`tf.sparse.SparseTensor` 不要求索引/值按任何特定顺序排列，但一些运算假定它们按行优先顺序排列。使用 `tf.sparse.reorder` 创建按规范行优先顺序排序的稀疏张量副本。 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Aq7ruwlyz79"
      },
      "source": [
        "## 创建 `tf.sparse.SparseTensor`\n",
        "\n",
        "通过直接指定它们的 `values`、`indices` 和 `dense_shape` 来构造稀疏张量。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SI2Mv3tihcmY"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vqQKGva4zSCs"
      },
      "outputs": [],
      "source": [
        "st1 = tf.sparse.SparseTensor(indices=[[0, 3], [2, 4]],\n",
        "                      values=[10, 20],\n",
        "                      dense_shape=[3, 10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9eJeh31fWyr"
      },
      "source": [
        "<img src=\"https://github.com/tensorflow/docs-l10n/blob/master/site/zh-cn/guide/images/sparse_tensor.png?raw=true\" class=\"\">  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-M3fMTFL0hXa"
      },
      "source": [
        "当您使用 `print()` 函数打印一个稀疏张量时，它会显示三个张量分量的内容："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3oHWtmsBMLAI"
      },
      "outputs": [],
      "source": [
        "print(st1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqePKJG6MNWk"
      },
      "source": [
        "如果非零 `values` 与其对应的 `indices` 对齐，则更容易理解稀疏张量的内容。定义一个辅助函数来以美观的格式打印稀疏张量，以便每个非零值都显示在自己的行上。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R_xFYuOo1ZE_"
      },
      "outputs": [],
      "source": [
        "def pprint_sparse_tensor(st):\n",
        "  s = \"<SparseTensor shape=%s \\n values={\" % (st.dense_shape.numpy().tolist(),)\n",
        "  for (index, value) in zip(st.indices, st.values):\n",
        "    s += f\"\\n  %s: %s\" % (index.numpy().tolist(), value.numpy().tolist())\n",
        "  return s + \"}>\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "be4Dyiqt0fEH"
      },
      "outputs": [],
      "source": [
        "print(pprint_sparse_tensor(st1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FBt8qk_zmz5"
      },
      "source": [
        "您还可以使用 `tf.sparse.from_dense` 从密集张量构造稀疏张量，并使用 `tf.sparse.to_dense` 将它们转换回密集张量。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cYwuCuNMf0Fu"
      },
      "outputs": [],
      "source": [
        "st2 = tf.sparse.from_dense([[1, 0, 0, 8], [0, 0, 0, 0], [0, 0, 3, 0]])\n",
        "print(pprint_sparse_tensor(st2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eFVPrwNPzyZw"
      },
      "outputs": [],
      "source": [
        "st3 = tf.sparse.to_dense(st2)\n",
        "print(st3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GeuvyL_Z0Mwh"
      },
      "source": [
        "## 操纵稀疏张量\n",
        "\n",
        "使用 `tf.sparse` 软件包中的实用工具来操纵稀疏张量。像 `tf.math.add` 这样可用于密集张量的算术操纵的运算不适用于稀疏张量。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMYW4U4Qavvd"
      },
      "source": [
        "使用 `tf.sparse.add` 添加相同形状的稀疏张量。 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vJwuSQIjayiN"
      },
      "outputs": [],
      "source": [
        "st_a = tf.sparse.SparseTensor(indices=[[0, 2], [3, 4]],\n",
        "                       values=[31, 2], \n",
        "                       dense_shape=[4, 10])\n",
        "\n",
        "st_b = tf.sparse.SparseTensor(indices=[[0, 2], [7, 0]],\n",
        "                       values=[56, 38],\n",
        "                       dense_shape=[4, 10])\n",
        "\n",
        "st_sum = tf.sparse.add(st_a, st_b)\n",
        "\n",
        "print(pprint_sparse_tensor(st_sum))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ls8_aQvnqZMj"
      },
      "source": [
        "使用 `tf.sparse.sparse_dense_matmul` 将稀疏张量与密集矩阵相乘。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S0tWRLiE04uL"
      },
      "outputs": [],
      "source": [
        "st_c = tf.sparse.SparseTensor(indices=([0, 1], [1, 0], [1, 1]),\n",
        "                       values=[13, 15, 17],\n",
        "                       dense_shape=(2,2))\n",
        "\n",
        "mb = tf.constant([[4], [6]])\n",
        "product = tf.sparse.sparse_dense_matmul(st_c, mb)\n",
        "\n",
        "print(product)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hxClYvfceZA"
      },
      "source": [
        "使用 `tf.sparse.concat` 将稀疏张量放在一起，使用 `tf.sparse.slice` 将它们分开。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cp4NEW_5yLEY"
      },
      "outputs": [],
      "source": [
        "sparse_pattern_A = tf.sparse.SparseTensor(indices = [[2,4], [3,3], [3,4], [4,3], [4,4], [5,4]],\n",
        "                         values = [1,1,1,1,1,1],\n",
        "                         dense_shape = [8,5])\n",
        "sparse_pattern_B = tf.sparse.SparseTensor(indices = [[0,2], [1,1], [1,3], [2,0], [2,4], [2,5], [3,5], \n",
        "                                              [4,5], [5,0], [5,4], [5,5], [6,1], [6,3], [7,2]],\n",
        "                         values = [1,1,1,1,1,1,1,1,1,1,1,1,1,1],\n",
        "                         dense_shape = [8,6])\n",
        "sparse_pattern_C = tf.sparse.SparseTensor(indices = [[3,0], [4,0]],\n",
        "                         values = [1,1],\n",
        "                         dense_shape = [8,6])\n",
        "\n",
        "sparse_patterns_list = [sparse_pattern_A, sparse_pattern_B, sparse_pattern_C]\n",
        "sparse_pattern = tf.sparse.concat(axis=1, sp_inputs=sparse_patterns_list)\n",
        "print(tf.sparse.to_dense(sparse_pattern))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XmE87XVPWPmc"
      },
      "outputs": [],
      "source": [
        "sparse_slice_A = tf.sparse.slice(sparse_pattern_A, start = [0,0], size = [8,5])\n",
        "sparse_slice_B = tf.sparse.slice(sparse_pattern_B, start = [0,5], size = [8,6])\n",
        "sparse_slice_C = tf.sparse.slice(sparse_pattern_C, start = [0,10], size = [8,6])\n",
        "print(tf.sparse.to_dense(sparse_slice_A))\n",
        "print(tf.sparse.to_dense(sparse_slice_B))\n",
        "print(tf.sparse.to_dense(sparse_slice_C))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37SOx7wB1eSX"
      },
      "source": [
        "如果使用的是 TensorFlow 2.4 或更高版本，请使用 `tf.sparse.map_values` 对稀疏张量中的非零值执行逐元素运算。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "daZaPkkA1d09"
      },
      "outputs": [],
      "source": [
        "st2_plus_5 = tf.sparse.map_values(tf.add, st2, 5)\n",
        "print(tf.sparse.to_dense(st2_plus_5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zkRcxeo2Elw"
      },
      "source": [
        "请注意，仅修改了非零值 – 零值保持为零。\n",
        "\n",
        "同样，可以遵循下方 TensorFlow 早期版本的设计模式："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bFSNOOqC0ySb"
      },
      "outputs": [],
      "source": [
        "st2_plus_5 = tf.sparse.SparseTensor(\n",
        "    st2.indices,\n",
        "    st2.values + 5,\n",
        "    st2.dense_shape)\n",
        "print(tf.sparse.to_dense(st2_plus_5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFhO2ZZ53ga1"
      },
      "source": [
        "## 将 `tf.sparse.SparseTensor` 与其他 TensorFlow API 一起使用\n",
        "\n",
        "稀疏张量透明地与这些 TensorFlow API 一起使用：\n",
        "\n",
        "- `tf.keras`\n",
        "- `tf.data`\n",
        "- `tf.Train.Example` protobuf\n",
        "- `tf.function`\n",
        "- `tf.while_loop`\n",
        "- `tf.cond`\n",
        "- `tf.identity`\n",
        "- `tf.cast`\n",
        "- `tf.print`\n",
        "- `tf.saved_model`\n",
        "- `tf.io.serialize_sparse`\n",
        "- `tf.io.serialize_many_sparse`\n",
        "- `tf.io.deserialize_many_sparse`\n",
        "- `tf.math.abs`\n",
        "- `tf.math.negative`\n",
        "- `tf.math.sign`\n",
        "- `tf.math.square`\n",
        "- `tf.math.sqrt`\n",
        "- `tf.math.erf`\n",
        "- `tf.math.tanh`\n",
        "- `tf.math.bessel_i0e`\n",
        "- `tf.math.bessel_i1e`\n",
        "\n",
        "下面显示了上述 API 的一些示例。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uNUl7EgSYGC"
      },
      "source": [
        "### `tf.keras`\n",
        "\n",
        "`tf.keras` API 的一个子集支持稀疏张量，无需执行开销较大的类型转换或转换运算。可以利用 Keras API 将稀疏张量作为输入传递给 Keras 模型。调用 `tf.keras.Input` 或 `tf.keras.layers.InputLayer` 时设置 `sparse=True`。您可以在 Keras 层之间传递稀疏张量，也可以让 Keras 模型将它们作为输出返回。如果在模型中的 `tf.keras.layers.Dense` 层中使用稀疏张量，它们将输出密集张量。\n",
        "\n",
        "下面的示例展示了如果仅使用支持稀疏输入的层，如何将稀疏张量作为输入传递给 Keras 模型。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E8za5DK8vfo7"
      },
      "outputs": [],
      "source": [
        "x = tf.keras.Input(shape=(4,), sparse=True)\n",
        "y = tf.keras.layers.Dense(4)(x)\n",
        "model = tf.keras.Model(x, y)\n",
        "\n",
        "sparse_data = tf.sparse.SparseTensor(\n",
        "    indices = [(0,0),(0,1),(0,2),\n",
        "               (4,3),(5,0),(5,1)],\n",
        "    values = [1,1,1,1,1,1],\n",
        "    dense_shape = (6,4)\n",
        ")\n",
        "\n",
        "model(sparse_data)\n",
        "\n",
        "model.predict(sparse_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtVYmr7dt0-x"
      },
      "source": [
        "### `tf.data`\n",
        "\n",
        "`tf.data` API 可用于通过简单的可重用代码段构建复杂的输入流水线。它的核心数据结构是 `tf.data.Dataset`，表示一系列元素，每个元素包含一个或多个分量。\n",
        "\n",
        "#### 使用稀疏张量构建数据集\n",
        "\n",
        "使用用于从 `tf.Tensor` 或 NumPy 数组构建数据集的相同方法从稀疏张量构建数据集，例如 `tf.data.Dataset.from_tensor_slices`。此运算保留了数据的稀疏性。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3y9tiwuZ5oTD"
      },
      "outputs": [],
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices(sparse_data)\n",
        "for element in dataset: \n",
        "  print(pprint_sparse_tensor(element))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFaY5Org59qk"
      },
      "source": [
        "#### 批处理和取消批处理具有稀疏张量的数据集\n",
        "\n",
        "可以分别使用 `Dataset.batch` 和 `Dataset.unbatch` 方法批处理（将连续元素组合成单个元素）和取消批处理具有稀疏张量的数据集。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WkKE0VY66Ii2"
      },
      "outputs": [],
      "source": [
        "batched_dataset = dataset.batch(2)\n",
        "for element in batched_dataset:\n",
        "  print (pprint_sparse_tensor(element))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ikZzPxl56bx1"
      },
      "outputs": [],
      "source": [
        "unbatched_dataset = batched_dataset.unbatch()\n",
        "for element in unbatched_dataset:\n",
        "  print (pprint_sparse_tensor(element))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ywfpD_EIMd3"
      },
      "source": [
        "还可以使用 `tf.data.experimental.dense_to_sparse_batch` 将不同形状的数据集元素批处理为稀疏张量。 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oB8QKh7p6ltl"
      },
      "source": [
        "#### 转换具有稀疏张量的数据集\n",
        "\n",
        "使用 `Dataset.map` 在数据集中转换和创建稀疏张量。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E5lhicwef7Ah"
      },
      "outputs": [],
      "source": [
        "transform_dataset = dataset.map(lambda x: x*2)\n",
        "for i in transform_dataset:\n",
        "  print(pprint_sparse_tensor(i))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBfQvIVutp65"
      },
      "source": [
        "### tf.train.Example\n",
        "\n",
        "`tf.train.Example` 是 TensorFlow 数据的标准 protobuf 编码。将稀疏张量与 `tf.train.Example` 搭配使用时，您可以：\n",
        "\n",
        "- 使用 `tf.io.VarLenFeature` 将可变长度数据读入 `tf.sparse.SparseTensor`。但是，您应当考虑改用 `tf.io.RaggedFeature`。\n",
        "\n",
        "- 使用 `tf.io.SparseFeature` 将任意稀疏数据读入 `tf.sparse.SparseTensor`，它使用三个独立的特征键来存储 `indices`、`values` 和 `dense_shape`。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pir2Xt3nSe-4"
      },
      "source": [
        "### `tf.function`\n",
        "\n",
        "`tf.function` 装饰器为 Python 函数预先计算 TensorFlow 计算图，这样可以大幅提升 TensorFlow 代码的性能。稀疏张量能够透明地与 `tf.function` 和[具体函数](https://tensorflow.google.cn/guide/function#obtaining_concrete_functions)一起使用。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6jXDueTOSeYO"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def f(x,y):\n",
        "  return tf.sparse.sparse_dense_matmul(x,y)\n",
        "\n",
        "a = tf.sparse.SparseTensor(indices=[[0, 3], [2, 4]],\n",
        "                    values=[15, 25],\n",
        "                    dense_shape=[3, 10])\n",
        "\n",
        "b = tf.sparse.to_dense(tf.sparse.transpose(a))\n",
        "\n",
        "c = f(a,b)\n",
        "\n",
        "print(c)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPe5uC_X7XjZ"
      },
      "source": [
        "## 区分缺失值和零值\n",
        "\n",
        "`tf.sparse.SparseTensor` 上的大多数运算都以相同的方式处理缺失值和显式零值。这是特意这样设计的 – `tf.sparse.SparseTensor` 的行为应当像密集张量一样。\n",
        "\n",
        "但是，在少数情况下，区分零值和缺失值会十分有用。特别是，这样可以对训练数据中的缺失/未知数据进行编码。例如，考虑一个用例，其中包含一个分数张量（可以具有从 -Inf 到 +Inf 的任何浮点值），但缺少一些分数。可以使用稀疏张量对此张量进行编码，其中显式零是已知的零分数，但隐式零值实际上表示缺失数据，而不是零。\n",
        "\n",
        "注：这通常不是 `tf.sparse.SparseTensor` 的预期用途；并且您可能还想考虑其他技术来对此进行编码，例如使用单独的掩码张量来识别已知/未知值的位置。但是，在使用这种方式时要格外小心，因为大多数稀疏运算将以相同的方式处理显式和隐式零值。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZ17F9e3ZJDS"
      },
      "source": [
        "请注意，像 `tf.sparse.reduce_max` 这样的一些运算不会将缺失值视为零。例如，运行下面的代码块时，预期输出为 `0`。但是，由于此异常，输出为 `-3`。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kcNBVVtBZav_"
      },
      "outputs": [],
      "source": [
        "print(tf.sparse.reduce_max(tf.sparse.from_dense([-5, 0, -3])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhzWLW-bMfI5"
      },
      "source": [
        "相反，当您将 `tf.math.reduce_max` 应用于密集张量时，输出如预期的那样为 0。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Xy-g3VDNK9d"
      },
      "outputs": [],
      "source": [
        "print(tf.math.reduce_max([-5, 0, -3]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uK3U8l0kNL37"
      },
      "source": [
        "## 补充阅读和资源\n",
        "\n",
        "- 请参阅[张量指南](https://tensorflow.google.cn/guide/tensor)来了解张量。\n",
        "- 阅读[不规则张量指南](https://tensorflow.google.cn/guide/ragged_tensor)以了解如何使用不规则张量，这是一种可以处理非均匀数据的张量。\n",
        "- 在 [TensorFlow Model Garden](https://github.com/tensorflow/models) 中查看此目标检测模型，此模型在 [`tf.Example` 数据解码器](https://github.com/tensorflow/models/blob/9139a7b90112562aec1d7e328593681bd410e1e7/research/object_detection/data_decoders/tf_example_decoder.py)中使用稀疏张量。\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "sparse_tensor_guide.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
