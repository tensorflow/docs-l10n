{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tce3stUlHN0L"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "IcfrhafzkZbH"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFdPvlXBOdUN"
      },
      "source": [
        "# 剪枝综合指南"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfBg1C5NB3X0"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>     <a target=\"_blank\" href=\"https://tensorflow.google.cn/model_optimization/guide/pruning/comprehensive_guide\"><img src=\"https://tensorflow.google.cn/images/tf_logo_32px.png\">在 TensorFlow.org 上查看</a>   </td>\n",
        "  <td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/zh-cn/model_optimization/guide/pruning/comprehensive_guide.ipynb\"><img src=\"https://tensorflow.google.cn/images/colab_logo_32px.png\">在 Google Colab 中运行</a></td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/zh-cn/model_optimization/guide/pruning/comprehensive_guide.ipynb\"><img src=\"https://tensorflow.google.cn/images/GitHub-Mark-32px.png\">在 Github 上查看源代码</a>   </td>\n",
        "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/zh-cn/model_optimization/guide/pruning/comprehensive_guide.ipynb\"><img src=\"https://tensorflow.google.cn/images/download_logo_32px.png\">下载笔记本</a>   </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbORZA_bQx1G"
      },
      "source": [
        "欢迎阅读 Keras 权重剪枝综合指南。\n",
        "\n",
        "本页面记录了各种用例，并展示了如何将 API 用于每种用例​​。了解需要使用哪些 API 后，请在 [API 文档](https://tensorflow.google.cn/model_optimization/api_docs/python/tfmot/sparsity)中找到参数和底层详细信息：\n",
        "\n",
        "- 如果要查看剪枝的好处以及支持的功能，请参阅[概述](https://tensorflow.google.cn/model_optimization/guide/pruning)。\n",
        "- 有关单个端到端示例，请参阅[剪枝示例](https://tensorflow.google.cn/model_optimization/guide/pruning/pruning_with_keras)。\n",
        "\n",
        "涵盖以下用例：\n",
        "\n",
        "- 定义并训练剪枝模型。\n",
        "    - 序贯模型和函数式模型\n",
        "    - Keras model.fit 和自定义训练循环\n",
        "- 为剪枝模型设置检查点和进行反序列化。\n",
        "- 部署剪枝模型并查看压缩优势。\n",
        "\n",
        "有关剪枝算法的配置，请参阅 `tfmot.sparsity.keras.prune_low_magnitude` API 文档。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nuABqZnXVDvO"
      },
      "source": [
        "## 设置"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9mRDekZEfnR"
      },
      "source": [
        "如果只是寻找您需要的 API 并了解其用途，您可以只运行以下代码而无需阅读本部分。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "both",
        "id": "lvpH1Hg7ULFz"
      },
      "outputs": [],
      "source": [
        "! pip install -q tensorflow-model-optimization\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import tensorflow_model_optimization as tfmot\n",
        "\n",
        "%load_ext tensorboard\n",
        "\n",
        "import tempfile\n",
        "\n",
        "input_shape = [20]\n",
        "x_train = np.random.randn(1, 20).astype(np.float32)\n",
        "y_train = tf.keras.utils.to_categorical(np.random.randn(1), num_classes=20)\n",
        "\n",
        "def setup_model():\n",
        "  model = tf.keras.Sequential([\n",
        "      tf.keras.layers.Dense(20, input_shape=input_shape),\n",
        "      tf.keras.layers.Flatten()\n",
        "  ])\n",
        "  return model\n",
        "\n",
        "def setup_pretrained_weights():\n",
        "  model = setup_model()\n",
        "\n",
        "  model.compile(\n",
        "      loss=tf.keras.losses.categorical_crossentropy,\n",
        "      optimizer='adam',\n",
        "      metrics=['accuracy']\n",
        "  )\n",
        "\n",
        "  model.fit(x_train, y_train)\n",
        "\n",
        "  _, pretrained_weights = tempfile.mkstemp('.tf')\n",
        "\n",
        "  model.save_weights(pretrained_weights)\n",
        "\n",
        "  return pretrained_weights\n",
        "\n",
        "def get_gzipped_model_size(model):\n",
        "  # Returns size of gzipped model, in bytes.\n",
        "  import os\n",
        "  import zipfile\n",
        "\n",
        "  _, keras_file = tempfile.mkstemp('.h5')\n",
        "  model.save(keras_file, include_optimizer=False)\n",
        "\n",
        "  _, zipped_file = tempfile.mkstemp('.zip')\n",
        "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
        "    f.write(keras_file)\n",
        "\n",
        "  return os.path.getsize(zipped_file)\n",
        "\n",
        "setup_model()\n",
        "pretrained_weights = setup_pretrained_weights()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZyLYFTER4aP"
      },
      "source": [
        "## 定义模型"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ybigft1fTn4T"
      },
      "source": [
        "### 对整个模型进行剪枝（序贯模型和函数式模型）"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "puZvqnp1xsn-"
      },
      "source": [
        "**提高模型准确率的提示：**\n",
        "\n",
        "- 尝试“对某些层进行剪枝”以跳过修剪会最大程度降低准确率的层。\n",
        "- 与从头开始训练相比，通常最好通过剪枝进行微调。\n",
        "\n",
        "要通过剪枝训练整个模型，将 `tfmot.sparsity.keras.prune_low_magnitude` 应用于模型。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aIn-hFO_T_PU"
      },
      "outputs": [],
      "source": [
        "base_model = setup_model()\n",
        "base_model.load_weights(pretrained_weights) # optional but recommended.\n",
        "\n",
        "model_for_pruning = tfmot.sparsity.keras.prune_low_magnitude(base_model)\n",
        "\n",
        "model_for_pruning.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTbTLn3dZM7h"
      },
      "source": [
        "### 对某些层进行剪枝（序贯模型和函数式模型）"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbM8o832xTxV"
      },
      "source": [
        "修剪模型可能会对准确率造成负面影响。您可以选择性地对模型的某些层进行剪枝以探索如何在准确率、速度和模型大小之间进行权衡。\n",
        "\n",
        "**提高模型准确率的提示：**\n",
        "\n",
        "- 与从头开始训练相比，通常最好通过剪枝进行微调。\n",
        "- 尝试对后面的层而不是前面的层进行剪枝。\n",
        "- 避免对关键层（例如注意力机制）进行剪枝。\n",
        "\n",
        "**更多提示**：\n",
        "\n",
        "- `tfmot.sparsity.keras.prune_low_magnitude` API 文档提供了有关如何更改每层的剪枝配置的详细信息。\n",
        "\n",
        "在下面的示例中，仅对 `Dense` 层进行剪枝。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HN0B_QB-ZhE2"
      },
      "outputs": [],
      "source": [
        "# Create a base model\n",
        "base_model = setup_model()\n",
        "base_model.load_weights(pretrained_weights) # optional but recommended for model accuracy\n",
        "\n",
        "# Helper function uses `prune_low_magnitude` to make only the \n",
        "# Dense layers train with pruning.\n",
        "def apply_pruning_to_dense(layer):\n",
        "  if isinstance(layer, tf.keras.layers.Dense):\n",
        "    return tfmot.sparsity.keras.prune_low_magnitude(layer)\n",
        "  return layer\n",
        "\n",
        "# Use `tf.keras.models.clone_model` to apply `apply_pruning_to_dense` \n",
        "# to the layers of the model.\n",
        "model_for_pruning = tf.keras.models.clone_model(\n",
        "    base_model,\n",
        "    clone_function=apply_pruning_to_dense,\n",
        ")\n",
        "\n",
        "model_for_pruning.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HiA28PrrW11H"
      },
      "source": [
        "尽管此示例使用层的类型来决定要修剪的内容，但是对特定层进行剪枝的最简单方法是设置其 `name` 属性，然后在 `clone_function` 中查找该名称。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CjY_JyB808Da"
      },
      "outputs": [],
      "source": [
        "print(base_model.layers[0].name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpb_BydRaSoF"
      },
      "source": [
        "#### 更具可读性，但可能会降低模型准确率"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vqXeYffzSHp"
      },
      "source": [
        "这不兼容通过剪枝进行的微调，因此，它的准确率可能低于上述支持微调的示例。\n",
        "\n",
        "虽然在定义初始模型时可以应用 `prune_low_magnitude`，但之后加载权重在以下示例中不起作用。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5p5jvH5KznJ"
      },
      "source": [
        "**函数式模型示例**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Wow55hg5oiM"
      },
      "outputs": [],
      "source": [
        "# Use `prune_low_magnitude` to make the `Dense` layer train with pruning.\n",
        "i = tf.keras.Input(shape=(20,))\n",
        "x = tfmot.sparsity.keras.prune_low_magnitude(tf.keras.layers.Dense(10))(i)\n",
        "o = tf.keras.layers.Flatten()(x)\n",
        "model_for_pruning = tf.keras.Model(inputs=i, outputs=o)\n",
        "\n",
        "model_for_pruning.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIGj-r2of2ls"
      },
      "source": [
        "**序贯模型示例**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mQOiDUGgfi4y"
      },
      "outputs": [],
      "source": [
        "# Use `prune_low_magnitude` to make the `Dense` layer train with pruning.\n",
        "model_for_pruning = tf.keras.Sequential([\n",
        "  tfmot.sparsity.keras.prune_low_magnitude(tf.keras.layers.Dense(20, input_shape=input_shape)),\n",
        "  tf.keras.layers.Flatten()\n",
        "])\n",
        "\n",
        "model_for_pruning.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnMguvVSnUqD"
      },
      "source": [
        "### 对自定义 Keras 层进行剪枝或修改层的部分以进行剪枝"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLgH1aFMjTK4"
      },
      "source": [
        "**常见误区**：对偏差进行剪枝通常会严重损害模型准确率。\n",
        "\n",
        "`tfmot.sparsity.keras.PrunableLayer` 适用于两个用例：\n",
        "\n",
        "1. 对自定义 Keras 层进行剪枝\n",
        "2. 修改内置 Keras 层的某些部分以进行剪枝\n",
        "\n",
        "例如，API 默认只对 `Dense` 层的内核进行剪枝。下面的示例还会对偏差进行剪枝。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "77jgBjccnTh6"
      },
      "outputs": [],
      "source": [
        "class MyDenseLayer(tf.keras.layers.Dense, tfmot.sparsity.keras.PrunableLayer):\n",
        "\n",
        "  def get_prunable_weights(self):\n",
        "    # Prune bias also, though that usually harms model accuracy too much.\n",
        "    return [self.kernel, self.bias]\n",
        "\n",
        "# Use `prune_low_magnitude` to make the `MyDenseLayer` layer train with pruning.\n",
        "model_for_pruning = tf.keras.Sequential([\n",
        "  tfmot.sparsity.keras.prune_low_magnitude(MyDenseLayer(20, input_shape=input_shape)),\n",
        "  tf.keras.layers.Flatten()\n",
        "])\n",
        "\n",
        "model_for_pruning.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itAyTyzvRroH"
      },
      "source": [
        "## 训练模型"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4hnWH2NY5MO"
      },
      "source": [
        "### Model.fit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LYCDIunTE9B"
      },
      "source": [
        "在训练期间中调用 `tfmot.sparsity.keras.UpdatePruningStep` 回调。\n",
        "\n",
        "为了帮助调试训练，请使用 `tfmot.sparsity.keras.PruningSummaries` 回调。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fKZ2PxcpY_WV"
      },
      "outputs": [],
      "source": [
        "# Define the model.\n",
        "base_model = setup_model()\n",
        "base_model.load_weights(pretrained_weights) # optional but recommended for model accuracy\n",
        "model_for_pruning = tfmot.sparsity.keras.prune_low_magnitude(base_model)\n",
        "\n",
        "log_dir = tempfile.mkdtemp()\n",
        "callbacks = [\n",
        "    tfmot.sparsity.keras.UpdatePruningStep(),\n",
        "    # Log sparsity and other metrics in Tensorboard.\n",
        "    tfmot.sparsity.keras.PruningSummaries(log_dir=log_dir)\n",
        "]\n",
        "\n",
        "model_for_pruning.compile(\n",
        "      loss=tf.keras.losses.categorical_crossentropy,\n",
        "      optimizer='adam',\n",
        "      metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model_for_pruning.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    callbacks=callbacks,\n",
        "    epochs=2,\n",
        ")\n",
        "\n",
        "#docs_infra: no_execute\n",
        "%tensorboard --logdir={log_dir}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kcuGmf5MSnJ"
      },
      "source": [
        "对于非 Colab 用户，您可以在 [TensorBoard.dev](https://tensorboard.dev/experiment/XiNXEBjHQ3Oabc6jRLKiXQ/#scalars&_smoothingWeight=0) 上查看此代码块[先前运行的结果](https://tensorboard.dev/)。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDcSvbNdZA-1"
      },
      "source": [
        "### 自定义训练循环"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQA8GaD6T3-o"
      },
      "source": [
        "在训练期间中调用 `tfmot.sparsity.keras.UpdatePruningStep` 回调。\n",
        "\n",
        "为了帮助调试训练，请使用 `tfmot.sparsity.keras.PruningSummaries` 回调。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hPQUrkodbIF2"
      },
      "outputs": [],
      "source": [
        "# Define the model.\n",
        "base_model = setup_model()\n",
        "base_model.load_weights(pretrained_weights) # optional but recommended for model accuracy\n",
        "model_for_pruning = tfmot.sparsity.keras.prune_low_magnitude(base_model)\n",
        "\n",
        "# Boilerplate\n",
        "loss = tf.keras.losses.categorical_crossentropy\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "log_dir = tempfile.mkdtemp()\n",
        "unused_arg = -1\n",
        "epochs = 2\n",
        "batches = 1 # example is hardcoded so that the number of batches cannot change.\n",
        "\n",
        "# Non-boilerplate.\n",
        "model_for_pruning.optimizer = optimizer\n",
        "step_callback = tfmot.sparsity.keras.UpdatePruningStep()\n",
        "step_callback.set_model(model_for_pruning)\n",
        "log_callback = tfmot.sparsity.keras.PruningSummaries(log_dir=log_dir) # Log sparsity and other metrics in Tensorboard.\n",
        "log_callback.set_model(model_for_pruning)\n",
        "\n",
        "step_callback.on_train_begin() # run pruning callback\n",
        "for _ in range(epochs):\n",
        "  log_callback.on_epoch_begin(epoch=unused_arg) # run pruning callback\n",
        "  for _ in range(batches):\n",
        "    step_callback.on_train_batch_begin(batch=unused_arg) # run pruning callback\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "      logits = model_for_pruning(x_train, training=True)\n",
        "      loss_value = loss(y_train, logits)\n",
        "      grads = tape.gradient(loss_value, model_for_pruning.trainable_variables)\n",
        "      optimizer.apply_gradients(zip(grads, model_for_pruning.trainable_variables))\n",
        "\n",
        "  step_callback.on_epoch_end(batch=unused_arg) # run pruning callback\n",
        "\n",
        "#docs_infra: no_execute\n",
        "%tensorboard --logdir={log_dir}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vh4lJt4zMh1v"
      },
      "source": [
        "对于非 Colab 用户，您可以在 [TensorBoard.dev](https://tensorboard.dev/experiment/jDeGzF3xQeSyb7Qir1ZcBQ/#scalars&_smoothingWeight=0) 上查看此代码块[先前运行的结果](https://tensorboard.dev/)。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8H-8lQ-cPa-"
      },
      "source": [
        "### 提高剪枝模型准确率\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2t4fYXvAV1V"
      },
      "source": [
        "首先，查看 `tfmot.sparsity.keras.prune_low_magnitude` API 文档，了解什么是剪枝计划，以及每种类型的剪枝计划的数学。\n",
        "\n",
        "**提示**：\n",
        "\n",
        "- 对模型进行剪枝时，学习率不要太高或太低。将[剪枝计划](https://tensorflow.google.cn/model_optimization/api_docs/python/tfmot/sparsity/keras/PruningSchedule)视为一个超参数。\n",
        "\n",
        "- 作为快速测试，尝试在训练开始时将模型剪枝到最终的稀疏度（通过使用 `tfmot.sparsity.keras.ConstantSparsity` 计划将 `begin_step` 设置为 0 来实现）。如果运气好的话，会获得不错的结果。\n",
        "\n",
        "- 不要频繁剪枝，使模型有时间恢复。[剪枝计划](https://tensorflow.google.cn/model_optimization/api_docs/python/tfmot/sparsity/keras/PruningSchedule)提供了不错的默认频率。\n",
        "\n",
        "- 有关提高模型准确率的总体思路，请在“定义模型”下查找您的用例对应的提示。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpvX5IqahV1r"
      },
      "source": [
        "## 设置检查点和进行反序列化"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GuZ5wlij1dcJ"
      },
      "source": [
        "您必须在检查点操作期间保留优化器步骤。这意味着虽然可以在检查点操作中使用 Keras HDF5 模型，但不能使用 Keras HDF5 权重。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6khQg-q7imfH"
      },
      "outputs": [],
      "source": [
        "# Define the model.\n",
        "base_model = setup_model()\n",
        "base_model.load_weights(pretrained_weights) # optional but recommended for model accuracy\n",
        "model_for_pruning = tfmot.sparsity.keras.prune_low_magnitude(base_model)\n",
        "\n",
        "_, keras_model_file = tempfile.mkstemp('.h5')\n",
        "\n",
        "# Checkpoint: saving the optimizer is necessary (include_optimizer=True is the default).\n",
        "model_for_pruning.save(keras_model_file, include_optimizer=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-CLxooLYnRN"
      },
      "source": [
        "上述代码普遍适用。仅 HDF5 模型格式需要以下代码（HDF5 权重或其他格式不需要）。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2nGC1hZnYlzb"
      },
      "outputs": [],
      "source": [
        "# Deserialize model.\n",
        "with tfmot.sparsity.keras.prune_scope():\n",
        "  loaded_model = tf.keras.models.load_model(keras_model_file)\n",
        "\n",
        "loaded_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jew8M217SgQw"
      },
      "source": [
        "## 部署剪枝模型"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2uj4SfF1cnTR"
      },
      "source": [
        "### 导出大小经过压缩的模型"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57uNm47L4Yro"
      },
      "source": [
        "**常见误区**：要体现剪枝的压缩优势，`strip_pruning` 和应用标准压缩算法（例如通过 Gzip）缺一不可。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EZ3TD8cYkxZM"
      },
      "outputs": [],
      "source": [
        "# Define the model.\n",
        "base_model = setup_model()\n",
        "base_model.load_weights(pretrained_weights) # optional but recommended for model accuracy\n",
        "model_for_pruning = tfmot.sparsity.keras.prune_low_magnitude(base_model)\n",
        "\n",
        "# Typically you train the model here.\n",
        "\n",
        "model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
        "\n",
        "print(\"final model\")\n",
        "model_for_export.summary()\n",
        "\n",
        "print(\"\\n\")\n",
        "print(\"Size of gzipped pruned model without stripping: %.2f bytes\" % (get_gzipped_model_size(model_for_pruning)))\n",
        "print(\"Size of gzipped pruned model with stripping: %.2f bytes\" % (get_gzipped_model_size(model_for_export)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPXvYIHOctem"
      },
      "source": [
        "### 特定于硬件的优化"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqk0jI49c1mw"
      },
      "source": [
        "当不同的后端[启用剪枝以改善延迟]((https://github.com/tensorflow/model-optimization/issues/173))后，使用块稀疏度可以改善某些硬件的延迟。\n",
        "\n",
        "增加块大小将减小目标模型准确率可达到的峰值稀疏度。尽管如此，延迟仍可以改善。\n",
        "\n",
        "有关块稀疏度支持的功能的详细信息，请参阅 `tfmot.sparsity.keras.prune_low_magnitude` API 文档。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xedaVDeFc0bw"
      },
      "outputs": [],
      "source": [
        "base_model = setup_model()\n",
        "\n",
        "# For using intrinsics on a CPU with 128-bit registers, together with 8-bit\n",
        "# quantized weights, a 1x16 block size is nice because the block perfectly\n",
        "# fits into the register.\n",
        "pruning_params = {'block_size': [1, 16]}\n",
        "model_for_pruning = tfmot.sparsity.keras.prune_low_magnitude(base_model, **pruning_params)\n",
        "\n",
        "model_for_pruning.summary()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Tce3stUlHN0L"
      ],
      "name": "comprehensive_guide.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
