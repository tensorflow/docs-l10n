{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKT-NezBJ4Nd"
      },
      "source": [
        "##### Copyright 2021 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "DwBljPxTJ4Ng"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIb8SDeKJ4Nh"
      },
      "source": [
        "# 使用 XNNPACK 针对设备端推断进行剪枝"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RX1fje9OJ4Ni"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td><a target=\"_blank\" href=\"https://tensorflow.google.cn/model_optimization/guide/pruning/pruning_for_on_device_inference\">     <img src=\"https://tensorflow.google.cn/images/tf_logo_32px.png\">     在 TensorFlow.org 上查看</a></td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/zh-cn/model_optimization/guide/pruning/pruning_for_on_device_inference.ipynb\"><img src=\"https://tensorflow.google.cn/images/colab_logo_32px.png\">在 Google Colab 运行</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/zh-cn/model_optimization/guide/pruning/pruning_for_on_device_inference.ipynb\"><img src=\"https://tensorflow.google.cn/images/GitHub-Mark-32px.png\">在 GitHub 上查看源代码</a>\n",
        "</td>\n",
        "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/zh-cn/model_optimization/guide/pruning/pruning_for_on_device_inference.ipynb\"><img src=\"https://tensorflow.google.cn/images/download_logo_32px.png\">下载笔记本</a>   </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uCVQVRMJ4Nj"
      },
      "source": [
        "欢迎阅读 Keras 权重剪枝指南，了解如何通过 [XNNPACK](https://github.com/google/XNNPACK) 改善设备端推断的延迟。\n",
        "\n",
        "本指南将介绍新引入的 `tfmot.sparsity.keras.PruningPolicy` API 的用法，并演示如何在现代 CPU 上使用该 API 通过 [XNNPACK 稀疏推断](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/delegates/xnnpack/README.md#sparse-inference)加速大多数卷积模型。\n",
        "\n",
        "本指南涵盖模型创建过程的以下步骤：\n",
        "\n",
        "- 构建并训练密集基线\n",
        "- 使用剪枝微调模型\n",
        "- 转换为 TFLite\n",
        "- 设备端基准测试\n",
        "\n",
        "本指南未涵盖使用剪枝进行微调的最佳做法。有关此主题的更多详细信息，请查看我们的[综合指南](https://tensorflow.google.cn/model_optimization/guide/pruning/comprehensive_guide.md)。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UF5sWYUZJ4Nk"
      },
      "source": [
        "## 安装"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "re0qdmOAJ4Nk"
      },
      "outputs": [],
      "source": [
        "! pip install -q tensorflow\n",
        "! pip install -q tensorflow-model-optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aIn7sB8-J4Nk"
      },
      "outputs": [],
      "source": [
        "import tempfile\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow import keras\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_model_optimization as tfmot\n",
        "\n",
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOeRh5hvJ4Nl"
      },
      "source": [
        "## 构建和训练密集模型"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNxUSmleJ4Nl"
      },
      "source": [
        "我们为基于 [CIFAR10](https://www.cs.toronto.edu/~kriz/cifar.html) 数据集的分类任务构建并训练一个简单的基准 CNN。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ws4cmZCJJ4Nm"
      },
      "outputs": [],
      "source": [
        "# Load CIFAR10 dataset.\n",
        "(ds_train, ds_val, ds_test), ds_info = tfds.load(\n",
        "    'cifar10',\n",
        "    split=['train[:90%]', 'train[90%:]', 'test'],\n",
        "    as_supervised=True,\n",
        "    with_info=True,\n",
        ")\n",
        "\n",
        "# Normalize the input image so that each pixel value is between 0 and 1.\n",
        "def normalize_img(image, label):\n",
        "  \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
        "  return tf.image.convert_image_dtype(image, tf.float32), label\n",
        "\n",
        "# Load the data in batches of 128 images.\n",
        "batch_size = 128\n",
        "def prepare_dataset(ds, buffer_size=None):\n",
        "  ds = ds.map(normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "  ds = ds.cache()\n",
        "  if buffer_size:\n",
        "    ds = ds.shuffle(buffer_size)\n",
        "  ds = ds.batch(batch_size)\n",
        "  ds = ds.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "  return ds\n",
        "\n",
        "ds_train = prepare_dataset(ds_train,\n",
        "                           buffer_size=ds_info.splits['train'].num_examples)\n",
        "ds_val = prepare_dataset(ds_val)\n",
        "ds_test = prepare_dataset(ds_test)\n",
        "\n",
        "# Build the dense baseline model.\n",
        "dense_model = keras.Sequential([\n",
        "    keras.layers.InputLayer(input_shape=(32, 32, 3)),\n",
        "    keras.layers.ZeroPadding2D(padding=1),\n",
        "    keras.layers.Conv2D(\n",
        "        filters=8,\n",
        "        kernel_size=(3, 3),\n",
        "        strides=(2, 2),\n",
        "        padding='valid'),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.ReLU(),\n",
        "    keras.layers.DepthwiseConv2D(kernel_size=(3, 3), padding='same'),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.ReLU(),\n",
        "    keras.layers.Conv2D(filters=16, kernel_size=(1, 1)),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.ReLU(),\n",
        "    keras.layers.ZeroPadding2D(padding=1),\n",
        "    keras.layers.DepthwiseConv2D(\n",
        "        kernel_size=(3, 3), strides=(2, 2), padding='valid'),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.ReLU(),\n",
        "    keras.layers.Conv2D(filters=32, kernel_size=(1, 1)),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.ReLU(),\n",
        "    keras.layers.GlobalAveragePooling2D(),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(10)\n",
        "])\n",
        "\n",
        "# Compile and train the dense model for 10 epochs.\n",
        "dense_model.compile(\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy'])\n",
        "\n",
        "dense_model.fit(\n",
        "  ds_train,\n",
        "  epochs=10,\n",
        "  validation_data=ds_val)\n",
        "\n",
        "# Evaluate the dense model.\n",
        "_, dense_model_accuracy = dense_model.evaluate(ds_test, verbose=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32h7h4YYJ4Nn"
      },
      "source": [
        "## 构建稀疏模型"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXAXjJcuJ4Nn"
      },
      "source": [
        "使用[综合指南](https://tensorflow.google.cn/model_optimization/guide/pruning/comprehensive_guide.md)中的说明，我们应用 `tfmot.sparsity.keras.prune_low_magnitude` 函数，其参数旨在通过剪枝来实现设备端加速，即 `tfmot.sparsity.keras.PruneForLatencyOnXNNPack` 策略。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N1WQt5dmJ4Nn"
      },
      "outputs": [],
      "source": [
        "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
        "\n",
        "# Compute end step to finish pruning after after 5 epochs.\n",
        "end_epoch = 5\n",
        "\n",
        "num_iterations_per_epoch = len(ds_train)\n",
        "end_step =  num_iterations_per_epoch * end_epoch\n",
        "\n",
        "# Define parameters for pruning.\n",
        "pruning_params = {\n",
        "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.25,\n",
        "                                                               final_sparsity=0.75,\n",
        "                                                               begin_step=0,\n",
        "                                                               end_step=end_step),\n",
        "      'pruning_policy': tfmot.sparsity.keras.PruneForLatencyOnXNNPack()\n",
        "}\n",
        "\n",
        "# Try to apply pruning wrapper with pruning policy parameter.\n",
        "try:\n",
        "  model_for_pruning = prune_low_magnitude(dense_model, **pruning_params)\n",
        "except ValueError as e:\n",
        "  print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzDggTmYJ4No"
      },
      "source": [
        "调用 `prune_low_magnitude` 导致 `ValueError` 并显示消息 `Could not find a GlobalAveragePooling2D layer with keepdims = True in all output branches`。该消息表示采用 `tfmot.sparsity.keras.PruneForLatencyOnXNNPack` 策略的剪枝不支持该模型，具体来说，层 `GlobalAveragePooling2D` 要求参数 `keepdims = True`。让我们解决这个问题并重新应用 `prune_low_magnitude` 函数。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qvALAbZeJ4No"
      },
      "outputs": [],
      "source": [
        "fixed_dense_model = keras.Sequential([\n",
        "    keras.layers.InputLayer(input_shape=(32, 32, 3)),\n",
        "    keras.layers.ZeroPadding2D(padding=1),\n",
        "    keras.layers.Conv2D(\n",
        "        filters=8,\n",
        "        kernel_size=(3, 3),\n",
        "        strides=(2, 2),\n",
        "        padding='valid'),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.ReLU(),\n",
        "    keras.layers.DepthwiseConv2D(kernel_size=(3, 3), padding='same'),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.ReLU(),\n",
        "    keras.layers.Conv2D(filters=16, kernel_size=(1, 1)),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.ReLU(),\n",
        "    keras.layers.ZeroPadding2D(padding=1),\n",
        "    keras.layers.DepthwiseConv2D(\n",
        "        kernel_size=(3, 3), strides=(2, 2), padding='valid'),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.ReLU(),\n",
        "    keras.layers.Conv2D(filters=32, kernel_size=(1, 1)),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.ReLU(),\n",
        "    keras.layers.GlobalAveragePooling2D(keepdims=True),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(10)\n",
        "])\n",
        "\n",
        "# Use the pretrained model for pruning instead of training from scratch.\n",
        "fixed_dense_model.set_weights(dense_model.get_weights())\n",
        "\n",
        "# Try to reapply pruning wrapper.\n",
        "model_for_pruning = prune_low_magnitude(fixed_dense_model, **pruning_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51K8A0XCJ4Np"
      },
      "source": [
        "`prune_low_magnitude` 调用完成且没有任何错误，表示 `tfmot.sparsity.keras.PruneForLatencyOnXNNPack` 策略完全支持该模型，并且可以使用 [XNNPACK 稀疏推断](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/delegates/xnnpack/README.md#sparse-inference)进行加速。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NG4yrdNUJ4Np"
      },
      "source": [
        "### 微调稀疏模型"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EqhqM7AtJ4Np"
      },
      "source": [
        "在[剪枝示例](https://tensorflow.google.cn/model_optimization/guide/pruning/pruning_with_keras.md)之后，我们使用密集模型的权重来微调稀疏模型。我们以 25% 稀疏性（25% 的权重设置为零）开始对模型进行微调并以 75% 稀疏性结束。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GzdS6AgRJ4Np"
      },
      "outputs": [],
      "source": [
        "logdir = tempfile.mkdtemp()\n",
        "\n",
        "callbacks = [\n",
        "  tfmot.sparsity.keras.UpdatePruningStep(),\n",
        "  tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
        "]\n",
        "\n",
        "model_for_pruning.compile(\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy'])\n",
        "\n",
        "model_for_pruning.fit(\n",
        "  ds_train,\n",
        "  epochs=15,\n",
        "  validation_data=ds_val,\n",
        "  callbacks=callbacks)\n",
        "\n",
        "# Evaluate the dense model.\n",
        "_, pruned_model_accuracy = model_for_pruning.evaluate(ds_test, verbose=0)\n",
        "\n",
        "print('Dense model test accuracy:', dense_model_accuracy)\n",
        "print('Pruned model test accuracy:', pruned_model_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EeI9QSIMJ4Nq"
      },
      "source": [
        "日志按层显示稀疏度的进度。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fGDkSxKJJ4Nq"
      },
      "outputs": [],
      "source": [
        "#docs_infra: no_execute\n",
        "%tensorboard --logdir={logdir}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hJ5PX_y7psT"
      },
      "source": [
        "使用剪枝进行微调之后，与密集模型相比，测试准确率表现出一定程度的改善（43% 到 44%）。让我们使用 [TFLite 基准](https://tensorflow.google.cn/lite/performance/measurement)来比较设备端延迟。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xCRpxczJ4Nq"
      },
      "source": [
        "## 模型转换和基准测试\n",
        "\n",
        "要将剪枝后的模型转换为 TFLite，我们需要通过 `strip_pruning` 函数将 `PruneLowMagnitude` 包装器替换为原始层。此外，由于剪枝后的模型 (`model_for_pruning`) 的权重大多为零，我们可以应用优化 `tf.lite.Optimize.EXPERIMENTAL_SPARSITY` 来有效存储生成的 TFLite 模型。密集模型不需要此优化标志。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AAJr2XKCJ4Nr"
      },
      "outputs": [],
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(dense_model)\n",
        "dense_tflite_model = converter.convert()\n",
        "\n",
        "_, dense_tflite_file = tempfile.mkstemp('.tflite')\n",
        "with open(dense_tflite_file, 'wb') as f:\n",
        "  f.write(dense_tflite_model)\n",
        "\n",
        "model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export)\n",
        "converter.optimizations = [tf.lite.Optimize.EXPERIMENTAL_SPARSITY]\n",
        "pruned_tflite_model = converter.convert()\n",
        "\n",
        "_, pruned_tflite_file = tempfile.mkstemp('.tflite')\n",
        "with open(pruned_tflite_file, 'wb') as f:\n",
        "  f.write(pruned_tflite_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLClpRYq7psT"
      },
      "source": [
        "按照 [TFLite 模型基准测试工具](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/tools/benchmark)的说明，我们编译该工具，将其与密集模型和剪枝后的 TFLite 模型一起上传到 Android 设备，并在设备上对这两个模型进行基准测试。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-qamJwAM7psU"
      },
      "outputs": [],
      "source": [
        "! adb shell /data/local/tmp/benchmark_model \\\n",
        "    --graph=/data/local/tmp/dense_model.tflite \\\n",
        "    --use_xnnpack=true \\\n",
        "    --num_runs=100 \\\n",
        "    --num_threads=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fpTxyOcd7psU"
      },
      "outputs": [],
      "source": [
        "! adb shell /data/local/tmp/benchmark_model \\\n",
        "    --graph=/data/local/tmp/pruned_model.tflite \\\n",
        "    --use_xnnpack=true \\\n",
        "    --num_runs=100 \\\n",
        "    --num_threads=1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKOVVoYD7psU"
      },
      "source": [
        "Pixel 4 上的基准测试结果显示，密集模型的平均推断时间为 *17us*，剪枝后的模型的平均推断时间为 *12us*。设备端基准测试表明，即使是此类小型模型，延迟也有明显的 **5us** 或 **30%** 改善。根据我们的经验，基于 [MobileNetV3](https://tensorflow.google.cn/api_docs/python/tf/keras/applications/mobilenet_v3) 或 [EfficientNet-lite](https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet/lite) 的大型模型也有类似的性能改进。加速效果取决于 1x1 卷积对整体模型的相对贡献。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqL_Nhuw7psU"
      },
      "source": [
        "## 结论"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03Icj3vV7psU"
      },
      "source": [
        "在本教程中，我们展示了如何使用 TF MOT API 和 XNNPack 引入的新功能创建稀疏模型来提高设备端性能。这些稀疏模型比对应的密集模型更小更快，同时质量相同甚至更高。\n",
        "\n",
        "我们鼓励您试用这项新功能，这对于在设备上部署模型可能特别重要。"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "pruning_for_on_device_inference.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
