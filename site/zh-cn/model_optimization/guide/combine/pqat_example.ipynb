{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8b6f4aa6b1b5"
      },
      "source": [
        "**Copyright 2021 The TensorFlow Authors.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "mEE8NFIMSGO-"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfBg1C5NB3X0"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>     <a target=\"_blank\" href=\"https://tensorflow.google.cn/model_optimization/guide/combine/pqat_example\"><img src=\"https://tensorflow.google.cn/images/tf_logo_32px.png\">在 TensorFlow.org 上查看</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/zh-cn/model_optimization/guide/combine/pqat_example.ipynb\">     <img src=\"https://tensorflow.google.cn/images/colab_logo_32px.png\">     在 Google Colab 中运行</a>\n",
        "</td>\n",
        "  <td><a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/zh-cn/model_optimization/guide/combine/pqat_example.ipynb\">     <img src=\"https://tensorflow.google.cn/images/GitHub-Mark-32px.png\">     在 GitHub 上查看源代码</a></td>\n",
        "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/zh-cn/model_optimization/guide/combine/pqat_example.ipynb\"><img src=\"https://tensorflow.google.cn/images/download_logo_32px.png\">下载笔记本</a>   </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyiSRgdtSGPC"
      },
      "source": [
        "# 剪枝保留量化感知训练 (PQAT) Keras 示例"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKnJyAaASGPD"
      },
      "source": [
        "## 文本特征向量\n",
        "\n",
        "这是一个展示**剪枝保留量化感知训练 (PQAT)** API 用法的端到端示例，该 API 是 TensorFlow 模型优化工具包的协作优化流水线的一部分。\n",
        "\n",
        "### 其他页面\n",
        "\n",
        "有关流水线和其他可用技术的简介，请参阅[协作优化概述页面](https://tensorflow.google.cn/model_optimization/guide/combine/collaborative_optimization)。\n",
        "\n",
        "### 目录\n",
        "\n",
        "在本教程中，您将：\n",
        "\n",
        "1. 从头开始为 MNIST 数据集训练一个 `tf.keras` 模型。\n",
        "2. 使用稀疏性 API，通过剪枝对模型进行微调，并查看准确率。\n",
        "3. 应用 QAT 并观察稀疏性损失。\n",
        "4. 应用 PQAT 并观察之前应用的稀疏性已被保留。\n",
        "5. 生成一个 TFLite 模型并观察对其应用 PQAT 的效果。\n",
        "6. 将获得的 PQAT 模型准确率与使用训练后量化所量化的模型进行比较。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgcQznnZSGPE"
      },
      "source": [
        "## 安装\n",
        "\n",
        "您可以在本地 [virtualenv](https://tensorflow.google.cn/install/pip?lang=python3#2.-create-a-virtual-environment-recommended) 或 [Colab](https://colab.sandbox.google.com/) 中运行此 Jupyter 笔记本。有关设置依赖项的详细信息，请参阅[安装指南](https://tensorflow.google.cn/model_optimization/guide/install)。 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3asgXMqnSGPE"
      },
      "outputs": [],
      "source": [
        "! pip install -q tensorflow-model-optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gL6JiLXkSGPI"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "import tempfile\n",
        "import zipfile\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKzOfl5FSGPL"
      },
      "source": [
        "## 为 MNIST 训练不进行剪枝的 tf.keras 模型"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w7Fd6jZ7SGPL"
      },
      "outputs": [],
      "source": [
        "# Load MNIST dataset\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# Normalize the input image so that each pixel value is between 0 to 1.\n",
        "train_images = train_images / 255.0\n",
        "test_images  = test_images / 255.0\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.InputLayer(input_shape=(28, 28)),\n",
        "  tf.keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
        "  tf.keras.layers.Conv2D(filters=12, kernel_size=(3, 3),\n",
        "                         activation=tf.nn.relu),\n",
        "  tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(10)\n",
        "])\n",
        "\n",
        "# Train the digit classification model\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(\n",
        "    train_images,\n",
        "    train_labels,\n",
        "    validation_split=0.1,\n",
        "    epochs=10\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBOQ8MeESGPO"
      },
      "source": [
        "### 评估基准模型并保存以备稍后使用"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HYulekocSGPP"
      },
      "outputs": [],
      "source": [
        "_, baseline_model_accuracy = model.evaluate(\n",
        "    test_images, test_labels, verbose=0)\n",
        "\n",
        "print('Baseline test accuracy:', baseline_model_accuracy)\n",
        "\n",
        "_, keras_file = tempfile.mkstemp('.h5')\n",
        "print('Saving model to: ', keras_file)\n",
        "tf.keras.models.save_model(model, keras_file, include_optimizer=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWPgcnjKSGPR"
      },
      "source": [
        "## 将模型剪枝和微调至 50% 稀疏性"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2wKK7w9SGPS"
      },
      "source": [
        "应用 `prune_low_magnitude()` API 对整个预训练模型进行剪枝，以演示并观察其不仅能够在应用 zip 时有效缩减模型大小，还能保持良好的准确率。有关如何在保持目标准确率的同时以最佳方式使用 API 实现最佳压缩率，请参阅[剪枝综合指南](https://tensorflow.google.cn/model_optimization/guide/pruning/comprehensive_guide)。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ea40z522SGPT"
      },
      "source": [
        "### 定义模型并应用稀疏性 API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7aOB5vjOZMTS"
      },
      "source": [
        "在使用稀疏性 API 之前，需要对模型进行预训练。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OzqKKt0mSGPT"
      },
      "outputs": [],
      "source": [
        "import tensorflow_model_optimization as tfmot\n",
        "\n",
        "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
        "\n",
        "pruning_params = {\n",
        "      'pruning_schedule': tfmot.sparsity.keras.ConstantSparsity(0.5, begin_step=0, frequency=100)\n",
        "  }\n",
        "\n",
        "callbacks = [\n",
        "  tfmot.sparsity.keras.UpdatePruningStep()\n",
        "]\n",
        "\n",
        "pruned_model = prune_low_magnitude(model, **pruning_params)\n",
        "\n",
        "# Use smaller learning rate for fine-tuning\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
        "\n",
        "pruned_model.compile(\n",
        "  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "  optimizer=opt,\n",
        "  metrics=['accuracy'])\n",
        "\n",
        "pruned_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ev4MyClmSGPW"
      },
      "source": [
        "### 微调模型并根据基准评估准确率"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQoy9CcASGPX"
      },
      "source": [
        "在 3 个周期内使用剪枝对模型进行微调。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jn29-coXSGPX"
      },
      "outputs": [],
      "source": [
        "# Fine-tune model\n",
        "pruned_model.fit(\n",
        "  train_images,\n",
        "  train_labels,\n",
        "  epochs=3,\n",
        "  validation_split=0.1,\n",
        "  callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "198b9e9ce00b"
      },
      "source": [
        "定义辅助函数来计算和打印模型的稀疏性。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "69468934028c"
      },
      "outputs": [],
      "source": [
        "def print_model_weights_sparsity(model):\n",
        "\n",
        "    for layer in model.layers:\n",
        "        if isinstance(layer, tf.keras.layers.Wrapper):\n",
        "            weights = layer.trainable_weights\n",
        "        else:\n",
        "            weights = layer.weights\n",
        "        for weight in weights:\n",
        "            # ignore auxiliary quantization weights\n",
        "            if \"quantize_layer\" in weight.name:\n",
        "                continue\n",
        "            weight_size = weight.numpy().size\n",
        "            zero_num = np.count_nonzero(weight == 0)\n",
        "            print(\n",
        "                f\"{weight.name}: {zero_num/weight_size:.2%} sparsity \",\n",
        "                f\"({zero_num}/{weight_size})\",\n",
        "            )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abc304948a53"
      },
      "source": [
        "检查模型是否已被正确剪枝。我们需要先剥离剪枝包装器。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a3fada83ffd7"
      },
      "outputs": [],
      "source": [
        "stripped_pruned_model = tfmot.sparsity.keras.strip_pruning(pruned_model)\n",
        "\n",
        "print_model_weights_sparsity(stripped_pruned_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvaZKoxtTORx"
      },
      "source": [
        "对于本示例，与基准相比，剪枝后的测试准确率损失微乎其微。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bE7MxpWLTaQ1"
      },
      "outputs": [],
      "source": [
        "_, pruned_model_accuracy = pruned_model.evaluate(\n",
        "  test_images, test_labels, verbose=0)\n",
        "\n",
        "print('Baseline test accuracy:', baseline_model_accuracy)\n",
        "print('Pruned test accuracy:', pruned_model_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXfPMa6ISGPd"
      },
      "source": [
        "## 应用 QAT 和 PQAT 并检查两种情况下对模型稀疏性的影响"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zr_QIhcUeuC"
      },
      "source": [
        "接下来，我们对剪枝后的模型同时应用 QAT 和剪枝保留 QAT (PQAT)，并观察 PQAT 在剪枝后的模型中保留稀疏性。请注意，在应用 PQAT API 之前，我们使用 `tfmot.sparsity.keras.strip_pruning` 从模型中剥离了剪枝包装器。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4h6tSvMzSGPd"
      },
      "outputs": [],
      "source": [
        "# QAT\n",
        "qat_model = tfmot.quantization.keras.quantize_model(stripped_pruned_model)\n",
        "\n",
        "qat_model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "print('Train qat model:')\n",
        "qat_model.fit(train_images, train_labels, batch_size=128, epochs=1, validation_split=0.1)\n",
        "\n",
        "# PQAT\n",
        "quant_aware_annotate_model = tfmot.quantization.keras.quantize_annotate_model(\n",
        "              stripped_pruned_model)\n",
        "pqat_model = tfmot.quantization.keras.quantize_apply(\n",
        "              quant_aware_annotate_model,\n",
        "              tfmot.experimental.combine.Default8BitPrunePreserveQuantizeScheme())\n",
        "\n",
        "pqat_model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "print('Train pqat model:')\n",
        "pqat_model.fit(train_images, train_labels, batch_size=128, epochs=1, validation_split=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8e90c14cce8d"
      },
      "outputs": [],
      "source": [
        "print(\"QAT Model sparsity:\")\n",
        "print_model_weights_sparsity(qat_model)\n",
        "print(\"PQAT Model sparsity:\")\n",
        "print_model_weights_sparsity(pqat_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2877629dd054"
      },
      "source": [
        "## 查看 PQAT 模型的压缩优势\n",
        "\n",
        "定义辅助函数以获取压缩的模型文件。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b72869768986"
      },
      "outputs": [],
      "source": [
        "def get_gzipped_model_size(file):\n",
        "  # It returns the size of the gzipped model in kilobytes.\n",
        "\n",
        "  _, zipped_file = tempfile.mkstemp('.zip')\n",
        "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
        "    f.write(file)\n",
        "\n",
        "  return os.path.getsize(zipped_file)/1000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1ef78df5740"
      },
      "source": [
        "由于这是一个小型模型，因此两个模型之间的差异不是非常明显。将剪枝和 PQAT 应用于更大的生产模型将产生更显著的压缩效果。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "057965bfae3d"
      },
      "outputs": [],
      "source": [
        "# QAT model\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(qat_model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "qat_tflite_model = converter.convert()\n",
        "qat_model_file = 'qat_model.tflite'\n",
        "# Save the model.\n",
        "with open(qat_model_file, 'wb') as f:\n",
        "    f.write(qat_tflite_model)\n",
        "    \n",
        "# PQAT model\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(pqat_model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "pqat_tflite_model = converter.convert()\n",
        "pqat_model_file = 'pqat_model.tflite'\n",
        "# Save the model.\n",
        "with open(pqat_model_file, 'wb') as f:\n",
        "    f.write(pqat_tflite_model)\n",
        "    \n",
        "print(\"QAT model size: \", get_gzipped_model_size(qat_model_file), ' KB')\n",
        "print(\"PQAT model size: \", get_gzipped_model_size(pqat_model_file), ' KB')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "286cd588785a"
      },
      "source": [
        "## 查看从 TF 到 TFLite 的准确率持久性\n",
        "\n",
        "定义一个辅助函数，基于测试数据集评估 TFLite 模型。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8808bb8628bd"
      },
      "outputs": [],
      "source": [
        "def eval_model(interpreter):\n",
        "  input_index = interpreter.get_input_details()[0][\"index\"]\n",
        "  output_index = interpreter.get_output_details()[0][\"index\"]\n",
        "\n",
        "  # Run predictions on every image in the \"test\" dataset.\n",
        "  prediction_digits = []\n",
        "  for i, test_image in enumerate(test_images):\n",
        "    if i % 1000 == 0:\n",
        "      print(f\"Evaluated on {i} results so far.\")\n",
        "    # Pre-processing: add batch dimension and convert to float32 to match with\n",
        "    # the model's input data format.\n",
        "    test_image = np.expand_dims(test_image, axis=0).astype(np.float32)\n",
        "    interpreter.set_tensor(input_index, test_image)\n",
        "\n",
        "    # Run inference.\n",
        "    interpreter.invoke()\n",
        "\n",
        "    # Post-processing: remove batch dimension and find the digit with highest\n",
        "    # probability.\n",
        "    output = interpreter.tensor(output_index)\n",
        "    digit = np.argmax(output()[0])\n",
        "    prediction_digits.append(digit)\n",
        "\n",
        "  print('\\n')\n",
        "  # Compare prediction results with ground truth labels to calculate accuracy.\n",
        "  prediction_digits = np.array(prediction_digits)\n",
        "  accuracy = (prediction_digits == test_labels).mean()\n",
        "  return accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dd9e954bd826"
      },
      "source": [
        "评估已被剪枝和量化的模型后，您将看到 TFLite 后端保持 TensorFlow 的准确率。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4eaf0160ea09"
      },
      "outputs": [],
      "source": [
        "interpreter = tf.lite.Interpreter(pqat_model_file)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "pqat_test_accuracy = eval_model(interpreter)\n",
        "\n",
        "print('Pruned and quantized TFLite test_accuracy:', pqat_test_accuracy)\n",
        "print('Pruned TF test accuracy:', pruned_model_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26dec6d57704"
      },
      "source": [
        "## 应用训练后量化并与 PQAT 模型进行比较\n",
        "\n",
        "接下来，我们对剪枝后的模型使用一般训练后量化（无微调），并根据 PQAT 模型检查其准确率。这演示了为什么需要使用 PQAT 来提高量化模型的准确率。\n",
        "\n",
        "首先，根据前 1000 个训练图像定义一个校准数据集生成器。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e92771026b96"
      },
      "outputs": [],
      "source": [
        "def mnist_representative_data_gen():\n",
        "  for image in train_images[:1000]:  \n",
        "    image = np.expand_dims(image, axis=0).astype(np.float32)\n",
        "    yield [image]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "085aa0dbc8a8"
      },
      "source": [
        "对模型进行量化并将准确率与先前获得的 PQAT 模型进行比较。请注意，通过微调量化的模型会实现更高的准确率。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0c913c4d4f9b"
      },
      "outputs": [],
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(stripped_pruned_model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.representative_dataset = mnist_representative_data_gen\n",
        "post_training_tflite_model = converter.convert()\n",
        "post_training_model_file = 'post_training_model.tflite'\n",
        "# Save the model.\n",
        "with open(post_training_model_file, 'wb') as f:\n",
        "    f.write(post_training_tflite_model)\n",
        "    \n",
        "# Compare accuracy\n",
        "interpreter = tf.lite.Interpreter(post_training_model_file)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "post_training_test_accuracy = eval_model(interpreter)\n",
        "\n",
        "print('PQAT TFLite test_accuracy:', pqat_test_accuracy)\n",
        "print('Post-training (no fine-tuning) TF test accuracy:', post_training_test_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "422b323172c5"
      },
      "source": [
        "## 结论"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7JhbpowqSGP1"
      },
      "source": [
        "在本教程中，您学习了如何创建模型，使用稀疏性 API 对其进行剪枝，以及应用稀疏性保留量化感知训练 (PQAT) 以在使用 QAT 时保留稀疏性。将最终的 PQAT 模型与 QAT 模型进行了比较，以表明前者保留了稀疏性，而后者丢失了稀疏性。接下来，将模型转换为 TFLite 以显示链式剪枝和 PQAT 模型优化技术的压缩优势，并评估 TFLite 模型以确保在 TFLite 后端保持准确率。最后，将 PQAT 模型与使用训练后量化 API 实现的量化剪枝模型进行比较，以展示 PQAT 在恢复正常量化的准确率损失方面的优势。"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "pqat_example.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
