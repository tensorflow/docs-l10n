{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlE_jisTkXY4"
      },
      "source": [
        "**Copyright 2021 The TensorFlow Authors.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "mEE8NFIMSGO-"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyiSRgdtSGPC"
      },
      "source": [
        "# 稀疏性保留聚类 Keras 示例"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfBg1C5NB3X0"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>     <a target=\"_blank\" href=\"https://tensorflow.google.cn/model_optimization/guide/combine/sparse_clustering_example\"><img src=\"https://tensorflow.google.cn/images/tf_logo_32px.png\">在 TensorFlow.org 上查看</a>\n",
        "</td>\n",
        "  <td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/zh-cn/model_optimization/guide/combine/sparse_clustering_example.ipynb\"><img src=\"https://tensorflow.google.cn/images/colab_logo_32px.png\">在 Google Colab 中运行</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/zh-cn/model_optimization/guide/combine/sparse_clustering_example.ipynb\">     <img src=\"https://tensorflow.google.cn/images/GitHub-Mark-32px.png\">     在 GitHub 上查看源代码</a></td>\n",
        "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/zh-cn/model_optimization/guide/combine/sparse_clustering_example.ipynb\"><img src=\"https://tensorflow.google.cn/images/download_logo_32px.png\">下载笔记本</a>   </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKnJyAaASGPD"
      },
      "source": [
        "## 概述\n",
        "\n",
        "这是一个展示**稀疏性保留聚类** API 用法的端到端示例，该 API 是 TensorFlow 模型优化工具包的协作优化流水线的一部分。\n",
        "\n",
        "### 其他页面\n",
        "\n",
        "有关流水线和其他可用技术的简介，请参阅[协作优化概述页面](https://tensorflow.google.cn/model_optimization/guide/combine/collaborative_optimization)。\n",
        "\n",
        "### 目录\n",
        "\n",
        "在本教程中，您将：\n",
        "\n",
        "1. 从头开始为 MNIST 数据集训练一个 `tf.keras` 模型。\n",
        "2. 通过稀疏性对模型进行微调，查看准确率，并观察模型已被成功剪枝。\n",
        "3. 将权重聚类应用于剪枝后的模型并观察稀疏性损失。\n",
        "4. 对剪枝后的模型应用稀疏性保留聚类，并观察之前应用的稀疏性已被保留。\n",
        "5. 生成一个 TFLite 模型并检查剪枝后的聚类模型中是否保留了准确率。\n",
        "6. 比较不同模型的大小，以观察应用稀疏性以及稀疏性保留聚类协作优化技术的压缩优势。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgcQznnZSGPE"
      },
      "source": [
        "## 安装\n",
        "\n",
        "您可以在本地 [virtualenv](https://tensorflow.google.cn/install/pip?lang=python3#2.-create-a-virtual-environment-recommended) 或 [Colab](https://colab.sandbox.google.com/) 中运行此 Jupyter 笔记本。有关设置依赖项的详细信息，请参阅[安装指南](https://tensorflow.google.cn/model_optimization/guide/install)。 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3asgXMqnSGPE"
      },
      "outputs": [],
      "source": [
        "! pip install -q tensorflow-model-optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gL6JiLXkSGPI"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "import tempfile\n",
        "import zipfile\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKzOfl5FSGPL"
      },
      "source": [
        "## 为 MNIST 训练待剪枝和聚类的 tf.keras 模型"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w7Fd6jZ7SGPL"
      },
      "outputs": [],
      "source": [
        "# Load MNIST dataset\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# Normalize the input image so that each pixel value is between 0 to 1.\n",
        "train_images = train_images / 255.0\n",
        "test_images  = test_images / 255.0\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.InputLayer(input_shape=(28, 28)),\n",
        "  tf.keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
        "  tf.keras.layers.Conv2D(filters=12, kernel_size=(3, 3),\n",
        "                         activation=tf.nn.relu),\n",
        "  tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(10)\n",
        "])\n",
        "\n",
        "# Train the digit classification model\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(\n",
        "    train_images,\n",
        "    train_labels,\n",
        "    validation_split=0.1,\n",
        "    epochs=10\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBOQ8MeESGPO"
      },
      "source": [
        "### 评估基准模型并保存以备稍后使用"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HYulekocSGPP"
      },
      "outputs": [],
      "source": [
        "_, baseline_model_accuracy = model.evaluate(\n",
        "    test_images, test_labels, verbose=0)\n",
        "\n",
        "print('Baseline test accuracy:', baseline_model_accuracy)\n",
        "\n",
        "_, keras_file = tempfile.mkstemp('.h5')\n",
        "print('Saving model to: ', keras_file)\n",
        "tf.keras.models.save_model(model, keras_file, include_optimizer=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPoCr4OFkXZE"
      },
      "source": [
        "## 将模型剪枝和微调至 50% 稀疏性"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mucwWWikXZE"
      },
      "source": [
        "应用 `prune_low_magnitude()` API 对整个预训练模型进行剪枝，以获得要在下一步进行聚类的模型。有关如何在保持目标准确率的同时以最佳方式使用 API 实现最佳压缩率，请参阅[剪枝综合指南](https://tensorflow.google.cn/model_optimization/guide/pruning/comprehensive_guide)。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGfTFitgkXZF"
      },
      "source": [
        "### 定义模型并应用稀疏性 API\n",
        "\n",
        "请注意，使用的是预训练模型。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mqsN5tP-kXZF"
      },
      "outputs": [],
      "source": [
        "import tensorflow_model_optimization as tfmot\n",
        "\n",
        "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
        "\n",
        "pruning_params = {\n",
        "      'pruning_schedule': tfmot.sparsity.keras.ConstantSparsity(0.5, begin_step=0, frequency=100)\n",
        "  }\n",
        "\n",
        "callbacks = [\n",
        "  tfmot.sparsity.keras.UpdatePruningStep()\n",
        "]\n",
        "\n",
        "pruned_model = prune_low_magnitude(model, **pruning_params)\n",
        "\n",
        "# Use smaller learning rate for fine-tuning\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
        "\n",
        "pruned_model.compile(\n",
        "  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "  optimizer=opt,\n",
        "  metrics=['accuracy'])\n",
        "\n",
        "pruned_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mh6SzEP9kXZF"
      },
      "source": [
        "### 微调模型，检查稀疏性，并根据基准评估准确率\n",
        "\n",
        "在 3 个周期内使用剪枝对模型进行微调。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2aBxR8uEkXZG"
      },
      "outputs": [],
      "source": [
        "# Fine-tune model\n",
        "pruned_model.fit(\n",
        "  train_images,\n",
        "  train_labels,\n",
        "  epochs=3,\n",
        "  validation_split=0.1,\n",
        "  callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GALLq2ZlkXZG"
      },
      "source": [
        "定义辅助函数来计算和打印模型的稀疏性。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XL-zWoU4kXZG"
      },
      "outputs": [],
      "source": [
        "def print_model_weights_sparsity(model):\n",
        "\n",
        "    for layer in model.layers:\n",
        "        if isinstance(layer, tf.keras.layers.Wrapper):\n",
        "            weights = layer.trainable_weights\n",
        "        else:\n",
        "            weights = layer.weights\n",
        "        for weight in weights:\n",
        "            if \"kernel\" not in weight.name or \"centroid\" in weight.name:\n",
        "                continue\n",
        "            weight_size = weight.numpy().size\n",
        "            zero_num = np.count_nonzero(weight == 0)\n",
        "            print(\n",
        "                f\"{weight.name}: {zero_num/weight_size:.2%} sparsity \",\n",
        "                f\"({zero_num}/{weight_size})\",\n",
        "            )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZRAJVqWkXZG"
      },
      "source": [
        "检查模型内核是否已正确剪枝。我们需要先剥离剪枝包装器。我们还将创建模型的深度副本以在下一步使用。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_8_p--1NkXZG"
      },
      "outputs": [],
      "source": [
        "stripped_pruned_model = tfmot.sparsity.keras.strip_pruning(pruned_model)\n",
        "\n",
        "print_model_weights_sparsity(stripped_pruned_model)\n",
        "\n",
        "stripped_pruned_model_copy = tf.keras.models.clone_model(stripped_pruned_model)\n",
        "stripped_pruned_model_copy.set_weights(stripped_pruned_model.get_weights())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWPgcnjKSGPR"
      },
      "source": [
        "## 应用聚类和稀疏性保留聚类并检查其在两种情况下对模型稀疏性的影响"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2wKK7w9SGPS"
      },
      "source": [
        "接下来，我们对剪枝后的模型同时应用聚类和稀疏性保留聚类，并观察后者在剪枝后的模型中保留稀疏性。请注意，在应用聚类 API 之前，我们使用 `tfmot.sparsity.keras.strip_pruning` 从模型中剥离了剪枝包装器。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RetnGeQnkXZH"
      },
      "outputs": [],
      "source": [
        "# Clustering\n",
        "cluster_weights = tfmot.clustering.keras.cluster_weights\n",
        "CentroidInitialization = tfmot.clustering.keras.CentroidInitialization\n",
        "\n",
        "clustering_params = {\n",
        "  'number_of_clusters': 8,\n",
        "  'cluster_centroids_init': CentroidInitialization.KMEANS_PLUS_PLUS\n",
        "}\n",
        "\n",
        "clustered_model = cluster_weights(stripped_pruned_model, **clustering_params)\n",
        "\n",
        "clustered_model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print('Train clustering model:')\n",
        "clustered_model.fit(train_images, train_labels,epochs=3, validation_split=0.1)\n",
        "\n",
        "\n",
        "stripped_pruned_model.save(\"stripped_pruned_model_clustered.h5\")\n",
        "\n",
        "# Sparsity preserving clustering\n",
        "from tensorflow_model_optimization.python.core.clustering.keras.experimental import (\n",
        "    cluster,\n",
        ")\n",
        "\n",
        "cluster_weights = cluster.cluster_weights\n",
        "\n",
        "clustering_params = {\n",
        "  'number_of_clusters': 8,\n",
        "  'cluster_centroids_init': CentroidInitialization.KMEANS_PLUS_PLUS,\n",
        "  'preserve_sparsity': True\n",
        "}\n",
        "\n",
        "sparsity_clustered_model = cluster_weights(stripped_pruned_model_copy, **clustering_params)\n",
        "\n",
        "sparsity_clustered_model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print('Train sparsity preserving clustering model:')\n",
        "sparsity_clustered_model.fit(train_images, train_labels,epochs=3, validation_split=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_PNNJoQkXZH"
      },
      "source": [
        "检查两个模型的稀疏性。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iHN3NW8OkXZI"
      },
      "outputs": [],
      "source": [
        "print(\"Clustered Model sparsity:\\n\")\n",
        "print_model_weights_sparsity(clustered_model)\n",
        "print(\"\\nSparsity preserved clustered Model sparsity:\\n\")\n",
        "print_model_weights_sparsity(sparsity_clustered_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ea40z522SGPT"
      },
      "source": [
        "## 通过聚类创建小 1.6 倍的模型\n",
        "\n",
        "定义辅助函数以获取压缩的模型文件。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "obozrEwrkXZI"
      },
      "outputs": [],
      "source": [
        "def get_gzipped_model_size(file):\n",
        "  # It returns the size of the gzipped model in kilobytes.\n",
        "\n",
        "  _, zipped_file = tempfile.mkstemp('.zip')\n",
        "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
        "    f.write(file)\n",
        "\n",
        "  return os.path.getsize(zipped_file)/1000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RTjq8zjnkXZJ"
      },
      "outputs": [],
      "source": [
        "# Clustered model\n",
        "clustered_model_file = 'clustered_model.h5'\n",
        "\n",
        "# Save the model.\n",
        "clustered_model.save(clustered_model_file)\n",
        "    \n",
        "#Sparsity Preserve Clustered model\n",
        "sparsity_clustered_model_file = 'sparsity_clustered_model.h5'\n",
        "\n",
        "# Save the model.\n",
        "sparsity_clustered_model.save(sparsity_clustered_model_file)\n",
        "    \n",
        "print(\"Clustered Model size: \", get_gzipped_model_size(clustered_model_file), ' KB')\n",
        "print(\"Sparsity preserved clustered Model size: \", get_gzipped_model_size(sparsity_clustered_model_file), ' KB')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bNfCJrEkXZJ"
      },
      "source": [
        "## 通过将稀疏性保留权重聚类与训练后量化相结合来创建 TFLite 模型\n",
        "\n",
        "剥离聚类包装器并转换为 TFLite。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i4dI7XSakXZJ"
      },
      "outputs": [],
      "source": [
        "stripped_sparsity_clustered_model = tfmot.clustering.keras.strip_clustering(sparsity_clustered_model)\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(stripped_sparsity_clustered_model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "sparsity_clustered_quant_model = converter.convert()\n",
        "\n",
        "_, pruned_and_clustered_tflite_file = tempfile.mkstemp('.tflite')\n",
        "\n",
        "with open(pruned_and_clustered_tflite_file, 'wb') as f:\n",
        "  f.write(sparsity_clustered_quant_model)\n",
        "\n",
        "print(\"Sparsity preserved clustered Model size: \", get_gzipped_model_size(sparsity_clustered_model_file), ' KB')\n",
        "print(\"Sparsity preserved clustered and quantized TFLite model size:\",\n",
        "       get_gzipped_model_size(pruned_and_clustered_tflite_file), ' KB')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "konsqRkokXZK"
      },
      "source": [
        "## 查看从 TF 到 TFLite 的准确率持久性"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1HTl0x0kXZK"
      },
      "outputs": [],
      "source": [
        "def eval_model(interpreter):\n",
        "  input_index = interpreter.get_input_details()[0][\"index\"]\n",
        "  output_index = interpreter.get_output_details()[0][\"index\"]\n",
        "\n",
        "  # Run predictions on every image in the \"test\" dataset.\n",
        "  prediction_digits = []\n",
        "  for i, test_image in enumerate(test_images):\n",
        "    if i % 1000 == 0:\n",
        "      print(f\"Evaluated on {i} results so far.\")\n",
        "    # Pre-processing: add batch dimension and convert to float32 to match with\n",
        "    # the model's input data format.\n",
        "    test_image = np.expand_dims(test_image, axis=0).astype(np.float32)\n",
        "    interpreter.set_tensor(input_index, test_image)\n",
        "\n",
        "    # Run inference.\n",
        "    interpreter.invoke()\n",
        "\n",
        "    # Post-processing: remove batch dimension and find the digit with highest\n",
        "    # probability.\n",
        "    output = interpreter.tensor(output_index)\n",
        "    digit = np.argmax(output()[0])\n",
        "    prediction_digits.append(digit)\n",
        "\n",
        "  print('\\n')\n",
        "  # Compare prediction results with ground truth labels to calculate accuracy.\n",
        "  prediction_digits = np.array(prediction_digits)\n",
        "  accuracy = (prediction_digits == test_labels).mean()\n",
        "  return accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_I1gdnbCkXZK"
      },
      "source": [
        "评估已被剪枝、聚类和量化的模型后，您将看到 TFLite 后端保持 TensorFlow 的准确率。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lbumQ_-0kXZL"
      },
      "outputs": [],
      "source": [
        "# Keras model evaluation\n",
        "stripped_sparsity_clustered_model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "_, sparsity_clustered_keras_accuracy = stripped_sparsity_clustered_model.evaluate(\n",
        "    test_images, test_labels, verbose=0)\n",
        "\n",
        "# TFLite model evaluation\n",
        "interpreter = tf.lite.Interpreter(pruned_and_clustered_tflite_file)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "sparsity_clustered_tflite_accuracy = eval_model(interpreter)\n",
        "\n",
        "print('Pruned, clustered and quantized Keras model accuracy:', sparsity_clustered_keras_accuracy)\n",
        "print('Pruned, clustered and quantized TFLite model accuracy:', sparsity_clustered_tflite_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQFbw88ykXZL"
      },
      "source": [
        "## 结论"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7JhbpowqSGP1"
      },
      "source": [
        "在本教程中，您学习了如何创建模型，使用 `prune_low_magnitude()` API 对其进行剪枝，以及应用稀疏性保留聚类以在对权重进行聚类时保留稀疏性。将稀疏性保留聚类模型与聚类模型进行了比较，以表明前者保留了稀疏性，而后者丢失了稀疏性。接下来，将剪枝后的聚类模型转换为 TFLite，以展示链接剪枝和稀疏性保留聚类模型优化技术的压缩优势。最后，评估了 TFLite 模型以确保在 TFLite 后端保持准确率。"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "sparse_clustering_example.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
