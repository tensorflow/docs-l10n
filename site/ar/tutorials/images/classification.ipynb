{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBFXQGKYUc4X"
      },
      "source": [
        "##### Copyright 2018 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "1z4xy2gTUc4a"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FE7KNzPPVrVV"
      },
      "source": [
        "# Image classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwQtSOz0VrVX"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/images/classification\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/ar/tutorials/images/classification.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/ar/tutorials/images/classification.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/ar/tutorials/images/classification.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gN7G9GFmVrVY"
      },
      "source": [
        "في هذا الدرس سوف نقوم بشرح كيفية تصنيف القطط و الكلاب من الصور, سوف نقوم ببناء النموذج باستخدام `tf.keras.Sequential`\n",
        " `tf.keras.preprocessing.image.ImageDataGenerator`و سوف نقوم بتحميل الصور باستخدام \n",
        " في هذا الدرس سوف تكسب بعض المهارات العملية لهذه المبادئ:\n",
        " \n",
        " *  `tf.keras.preprocessing.image.ImageDataGenerator` التعامل مع البيانات و الصور باستخدام \n",
        " * التعرف علي مصطلح الoverfitting و التعرف علي كيفية منعها \n",
        " * كيفية جمع البيانات و زيادة البيانات و مصطلح الdropout وهما طرق لمحاربة الoverfitting في مهام رؤية الحاسوب \n",
        " \n",
        "في هذا الدرس سنقوم بتتبع سير العمل الطبيعي في مهام تعلم الآلة:\n",
        "\n",
        "\n",
        "\n",
        "1. فحص وفهم البيانات\n",
        "2. بناء و تحضير المدخلات\n",
        "3. بناء النموذج\n",
        "4. تدريب النموذج\n",
        "5. تقييم النموذج\n",
        "6. تحسين النموذج وتكرار الخطوات "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zF9uvbXNVrVY"
      },
      "source": [
        "## تضمين المكتبات التي سوف نحتاجها"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VddxeYBEVrVZ"
      },
      "source": [
        "سنبدأ بتضمين المكتبات المطلوبة.\n",
        "`os` و يتم استخدامها لقراءة الملفات \n",
        "NumPy يتم استخدامها للتعامل مع المصفوفات و القيام بعمليات المصفوفات عليهم \n",
        "`matplotlib.pyplot` لعرض الصور و رسم علاقات بين المتغيرات أثناء التدريب والتقييم"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "rtPGh2MAVrVa"
      },
      "outputs": [],
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jlchl4x2VrVg"
      },
      "source": [
        "نقوم بتضمين Tensorflow و Keras لكي نستطيع بناء النموذج"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "E82grprdYPI0"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "L1WtoaOHVrVh"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZZI6lNkVrVm"
      },
      "source": [
        "## نقوم بتحميل البيانات"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPHx8-t-VrVo"
      },
      "source": [
        " \n",
        " نبدأ بتحميل مجموعة البيانات, في  هذا الدرس يتم استخدام نسخة منتقية من \n",
        "<a href=\"https://www.kaggle.com/c/dogs-vs-cats/data\" target=\"_blank\">Dogs vs Cats</a>\n",
        " هذه المجموعة من Kaggle \n",
        "يمكنك تحميلها و وضعها في \"/tmp/\" directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C1nqr-CYY6uw"
      },
      "outputs": [],
      "source": [
        "_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
        "\n",
        "path_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)\n",
        "\n",
        "PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Giv0wMQzVrVw"
      },
      "source": [
        "تتكون مجموعة الصور من هذه الهيكلة\n",
        "<pre>\n",
        "<b>cats_and_dogs_filtered</b>\n",
        "|__ <b>train</b>\n",
        "    |______ <b>cats</b>: [cat.0.jpg, cat.1.jpg, cat.2.jpg ....]\n",
        "    |______ <b>dogs</b>: [dog.0.jpg, dog.1.jpg, dog.2.jpg ...]\n",
        "|__ <b>validation</b>\n",
        "    |______ <b>cats</b>: [cat.2000.jpg, cat.2001.jpg, cat.2002.jpg ....]\n",
        "    |______ <b>dogs</b>: [dog.2000.jpg, dog.2001.jpg, dog.2002.jpg ...]\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpmywIlsVrVx"
      },
      "source": [
        "بعد استخراج المحتويات \n",
        "نضع المسار للصور المستخدمة في التدريب و المسار للصور المستخدمة في التقييم في متغيرات"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "sRucI3QqVrVy"
      },
      "outputs": [],
      "source": [
        "train_dir = os.path.join(PATH, 'train')\n",
        "validation_dir = os.path.join(PATH, 'validation')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Utv3nryxVrV0"
      },
      "outputs": [],
      "source": [
        "train_cats_dir = os.path.join(train_dir, 'cats')  # directory with our training cat pictures\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs')  # directory with our training dog pictures\n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats')  # directory with our validation cat pictures\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs')  # directory with our validation dog pictures"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdrHHTy2VrV3"
      },
      "source": [
        "### فهم البيانات"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LblUYjl-VrV3"
      },
      "source": [
        "لنبدأ ننظر لعدد صور القطط وعدد صور الكلاب في مجموعة الصور"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "vc4u8e9hVrV4"
      },
      "outputs": [],
      "source": [
        "num_cats_tr = len(os.listdir(train_cats_dir))\n",
        "num_dogs_tr = len(os.listdir(train_dogs_dir))\n",
        "\n",
        "num_cats_val = len(os.listdir(validation_cats_dir))\n",
        "num_dogs_val = len(os.listdir(validation_dogs_dir))\n",
        "\n",
        "total_train = num_cats_tr + num_dogs_tr\n",
        "total_val = num_cats_val + num_dogs_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g4GGzGt0VrV7"
      },
      "outputs": [],
      "source": [
        "print('total training cat images:', num_cats_tr)\n",
        "print('total training dog images:', num_dogs_tr)\n",
        "\n",
        "print('total validation cat images:', num_cats_val)\n",
        "print('total validation dog images:', num_dogs_val)\n",
        "print(\"--\")\n",
        "print(\"Total training images:\", total_train)\n",
        "print(\"Total validation images:\", total_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Lp-0ejxOtP1"
      },
      "source": [
        "للتسهيل, نضع بعض المتغيرات التي سيتم استخدامها في التدريب"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "3NqNselLVrWA"
      },
      "outputs": [],
      "source": [
        "batch_size = 128\n",
        "epochs = 15\n",
        "IMG_HEIGHT = 150\n",
        "IMG_WIDTH = 150"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INn-cOn1VrWC"
      },
      "source": [
        "## تجهيز البيانات"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Jfk6aSAVrWD"
      },
      "source": [
        "تجهيز الصور قبل إدخالها الشبكة العصبية عن طريق:\n",
        "\n",
        "1. قراءة الصور من القرص.\n",
        "2. تحويل الصور إلي مصفوفات ثلاثية الأبعاد تتكون من 3 قنوان ألوان ( أحمر - أخضر - أزرق ).\n",
        "3. ﻷن الشبكة العصبية تفضل التعامل مع الأرقام الصغيرة نقوم بتحويل قيم المصفوفات التي تكون في مدي 0-255 إلي مدي 0-1 \n",
        "\n",
        " `ImageDataGenerator` لحسن الحظ يمكن تنفيذ كل هذه المهام باستخدام \n",
        "يمكنها قراءة الصور و تحويلها للشكل المطلوب الذي يسهل التعامل معه"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "syDdF_LWVrWE"
      },
      "outputs": [],
      "source": [
        "train_image_generator = ImageDataGenerator(rescale=1./255) # Generator for our training data\n",
        "validation_image_generator = ImageDataGenerator(rescale=1./255) # Generator for our validation data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLciCR_FVrWH"
      },
      "source": [
        "`flow_from_directory` تقوم بقراءة الصور من القرص و تحويل القيم بداخل المصفوفة إلي قيم بين 0 و 1 و تحويلها لشكل المصفوفة المطلوب"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pw94ajOOVrWI"
      },
      "outputs": [],
      "source": [
        "train_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                           directory=train_dir,\n",
        "                                                           shuffle=True,\n",
        "                                                           target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                           class_mode='binary')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2oUoKUzRVrWM"
      },
      "outputs": [],
      "source": [
        "val_data_gen = validation_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                              directory=validation_dir,\n",
        "                                                              target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                              class_mode='binary')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyexPJ8CVrWP"
      },
      "source": [
        "### عرض الصور التي سيتم التدرب عليها"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60CnhEL4VrWQ"
      },
      "source": [
        "Visualize the training images by extracting a batch of images from the training generator—which is 32 images in this example—then plot five of them with `matplotlib`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "3f0Z7NZgVrWQ"
      },
      "outputs": [],
      "source": [
        "sample_training_images, _ = next(train_data_gen)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49weMt5YVrWT"
      },
      "source": [
        " `next` تقوم بإرجاع جزء من مجموعة الصور. \n",
        " و القيمة التي تعود تكون علي الشكل`(x_train, y_train)` \n",
        "x_train هو مجموعة الصور التي سيتم التدرب عليها\n",
        "y_train هو اسم القسم الذي تنتمي إليه الصورة سواء كان قطة أو كلب"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "JMt2RES_VrWU"
      },
      "outputs": [],
      "source": [
        "# This function will plot images in the form of a grid with 1 row and 5 columns where images are placed in each column.\n",
        "def plotImages(images_arr):\n",
        "    fig, axes = plt.subplots(1, 5, figsize=(20,20))\n",
        "    axes = axes.flatten()\n",
        "    for img, ax in zip( images_arr, axes):\n",
        "        ax.imshow(img)\n",
        "        ax.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d_VVg_gEVrWW"
      },
      "outputs": [],
      "source": [
        "plotImages(sample_training_images[:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5Ej-HLGVrWZ"
      },
      "source": [
        "## بناء النموذج"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wEgW4i18VrWZ"
      },
      "source": [
        "النموذج يتكون من 3 طبقات من الconvolutions\n",
        "و بعد كل طبقة يوجد طبقة من ال max pool \n",
        "و بعدهم يوجد طبقة متصلة بالكامل تتكون من 512 وحدة مع دالة تفعيل `relu`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "F15-uwLPVrWa"
      },
      "outputs": [],
      "source": [
        "model = Sequential([\n",
        "    Conv2D(16, 3, padding='same', activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH ,3)),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(32, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(64, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(1)\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PI5cdkMQVrWc"
      },
      "source": [
        "### تدريب النموذج\n",
        "\n",
        "في هذا النموذج سوف نستخدم *ADAM*لتدريب النموذج\n",
        "و سوف يتم استخدام *binary cross entropy* لتقييم المخرجات من النموذج. \n",
        "لنري الدقة في التدريب والتقيم أثناء التدريب نقوم بتمرير `accuracy` إلي المعطي `metrics`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "6Mg7_TXOVrWd"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YmQZ3TAVrWg"
      },
      "source": [
        "### موجز النموذج\n",
        "\n",
        "سنري كل الطبقات في الشبكة لهذا النموذج باستخدام دالة  `summary`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vtny8hmBVrWh"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N06iqE8VVrWj"
      },
      "source": [
        "### تدريب النموذج"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oub9RtoFVrWk"
      },
      "source": [
        "باستخدام`fit_generator`  التي متضمنة في `ImageDataGenerator` نقوم بالتدريب."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KSF2HqhDVrWk"
      },
      "outputs": [],
      "source": [
        "history = model.fit_generator(\n",
        "    train_data_gen,\n",
        "    steps_per_epoch=total_train // batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=val_data_gen,\n",
        "    validation_steps=total_val // batch_size\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojJNteAGVrWo"
      },
      "source": [
        "### إظهار نتائج التدريب"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZPYT-EmVrWo"
      },
      "source": [
        "الأن سنري النتائج بعد تدريب النموذج"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K6oA77ADVrWp"
      },
      "outputs": [],
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss=history.history['loss']\n",
        "val_loss=history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDnr50l2VrWu"
      },
      "source": [
        "كما تري في هذه الرسوم \n",
        "فيوجد فاصل بين كفاءة النموذج في التدريب و كفائته في التقييم كما إنه حصل علي كفاءة 70% فقط في التقييم\n",
        "\n",
        "لنري ماذا حدث خطأ و نحاول تحسين الأداء"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLO7yhLlVrWu"
      },
      "source": [
        "## Overfitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNyx3Lp4VrWv"
      },
      "source": [
        "في الرسوم فوق, يظهر أن كفاءة النموذج أثناء التدريب في ازدياد مع الوقت بينما كفاءة النموذج أثناء تقييمه تقريبا ثابتة عند 70% و ذلك يبدو علامة علي الoverfitting \n",
        "\n",
        "عندما يكون هناك عدد قليل من الأمثلة التي يتم التدرب عليها. يمكن للنموذج أن يتعلم بعض الخصائص الغير مرغوب في تعلمها و يتعلم بعض الصفات الغير مميزة للمطلوب تعلمه و هذا يقلل من أداؤه عندما يري أمثلة جديدة لم يرها من قبل و يجد صعوبة في تعميم الصفات و الخصائص التي تعلمها لأنه تعلم أشياء غير مرغوبة وتسمي هذه الظاهرة بالoverfitting\n",
        "\n",
        "يوجد طرق عديدة لتجنب هذه الطاهرة و في هذا الدرس سوف نتعلم عن بعض الطرق و منهم data augmentation و dropout"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOoVpxFwVrWy"
      },
      "source": [
        "## Data augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wn_QLciWVrWy"
      },
      "source": [
        "يتم استخدام هذا المبدأ لتجنب الظاهرة التي تم وصفها سابقا\n",
        "و هذا المبدأ يعتمد بشكل أساسي علي زيادة عدد الأمئلة التي يتم التدرب عليها عن طريق زيادة الأمثلة باختلاق أكثر من مثال مختلف عن طريق مثال واحد علي سبيل المثال تغيير الألوان و الإضاءة في صورة أو تدوير و قلب الصور\n",
        "\n",
        "و يتم فعل ذلك باستخدام `tf.keras` باستخدام `ImageDataGenerator`\n",
        "و بإعطاءه بعض  التحويلات المراد تطبيقها علي الصور أثناء التدريب\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2uJ1G030VrWz"
      },
      "source": [
        "### تجميع و إظهار الصور"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvX7hHlgVrW0"
      },
      "source": [
        "نبدأ بتطبيق تقليب أفقي عشوائي للصور و نري كيف تتغير الصور بعد التغير"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlVj6VqaVrW0"
      },
      "source": [
        "### تطبيق تقليب أفقي"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcdvx4TVVrW1"
      },
      "source": [
        "نمرر `horizontal_flip` كمعطي ل `ImageDataGenerator` و نضع `True` للتطبيق"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Bi1_vHyBVrW2"
      },
      "outputs": [],
      "source": [
        "image_gen = ImageDataGenerator(rescale=1./255, horizontal_flip=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zvwqmefgVrW3"
      },
      "outputs": [],
      "source": [
        "train_data_gen = image_gen.flow_from_directory(batch_size=batch_size,\n",
        "                                               directory=train_dir,\n",
        "                                               shuffle=True,\n",
        "                                               target_size=(IMG_HEIGHT, IMG_WIDTH))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJpRSxJ-VrW7"
      },
      "source": [
        "نأخذ صورة كعينة من الأمثلة و نكررها 5 مرات فيتم القيام بتحويل الصورة 5 مرات"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "RrKGd_jjVrW7"
      },
      "outputs": [],
      "source": [
        "augmented_images = [train_data_gen[0][0][0] for i in range(5)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EvBZoQ9xVrW9"
      },
      "outputs": [],
      "source": [
        "# Re-use the same custom plotting function defined and used\n",
        "# above to visualize the training images\n",
        "plotImages(augmented_images)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7n9xcqCVrXB"
      },
      "source": [
        "### تدوير الصورة عشوائيا"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXnwkzFuVrXB"
      },
      "source": [
        "لنري طرق أخري لتجميع الصور و زيادة عدد الأمثلة وهي تدوير الصور عشوائيا 45 درجة"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "1zip35pDVrXB"
      },
      "outputs": [],
      "source": [
        "image_gen = ImageDataGenerator(rescale=1./255, rotation_range=45)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kVoWh4OIVrXD"
      },
      "outputs": [],
      "source": [
        "train_data_gen = image_gen.flow_from_directory(batch_size=batch_size,\n",
        "                                               directory=train_dir,\n",
        "                                               shuffle=True,\n",
        "                                               target_size=(IMG_HEIGHT, IMG_WIDTH))\n",
        "\n",
        "augmented_images = [train_data_gen[0][0][0] for i in range(5)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wmBx8NhrVrXK"
      },
      "outputs": [],
      "source": [
        "plotImages(augmented_images)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOqGPL76VrXM"
      },
      "source": [
        "### Apply zoom augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvqXaD8BVrXN"
      },
      "source": [
        "نقوم بتجميع الصورة وزيادة عددهم عن طريق تكبير الصورة"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "tGNKLa_YVrXR"
      },
      "outputs": [],
      "source": [
        "# zoom_range from 0 - 1 where 1 = 100%.\n",
        "image_gen = ImageDataGenerator(rescale=1./255, zoom_range=0.5) # "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VOvTs32FVrXU"
      },
      "outputs": [],
      "source": [
        "train_data_gen = image_gen.flow_from_directory(batch_size=batch_size,\n",
        "                                               directory=train_dir,\n",
        "                                               shuffle=True,\n",
        "                                               target_size=(IMG_HEIGHT, IMG_WIDTH))\n",
        "\n",
        "augmented_images = [train_data_gen[0][0][0] for i in range(5)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-KQWw8IZVrXZ"
      },
      "outputs": [],
      "source": [
        "plotImages(augmented_images)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usS13KCNVrXd"
      },
      "source": [
        "### وضع كل ذلك سويا"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OC8fIsalVrXd"
      },
      "source": [
        "بتطبيق جميع الطرق السابقة لزيادة عدد الأمثلة "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "gnr2xujaVrXe"
      },
      "outputs": [],
      "source": [
        "image_gen_train = ImageDataGenerator(\n",
        "                    rescale=1./255,\n",
        "                    rotation_range=45,\n",
        "                    width_shift_range=.15,\n",
        "                    height_shift_range=.15,\n",
        "                    horizontal_flip=True,\n",
        "                    zoom_range=0.5\n",
        "                    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K0Efxy7EVrXh"
      },
      "outputs": [],
      "source": [
        "train_data_gen = image_gen_train.flow_from_directory(batch_size=batch_size,\n",
        "                                                     directory=train_dir,\n",
        "                                                     shuffle=True,\n",
        "                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                     class_mode='binary')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AW-pV5awVrXl"
      },
      "source": [
        "توضيح كيف صورة واحدة تظهر مختلفة 5مرات عندما نقوم بتطبيق طرق زيادة الصور "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z2m68eMhVrXm"
      },
      "outputs": [],
      "source": [
        "augmented_images = [train_data_gen[0][0][0] for i in range(5)]\n",
        "plotImages(augmented_images)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8cUd7FXVrXq"
      },
      "source": [
        "### ننشئ مجموعة الصور المستخدمة في تقييم النموذج"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a99fDBt7VrXr"
      },
      "source": [
        "بشكل عام نقوم بتطبيق طرق زيادة الصور علي مجموعة الصور التي يتم عليها التدريب  فلذلك لن نقوم بهذه الطرق علي الصور التي يتم عليها تقييم النموذج و سيتم ذلك باستخدام `ImageDataGenerator`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "54x0aNbKVrXr"
      },
      "outputs": [],
      "source": [
        "image_gen_val = ImageDataGenerator(rescale=1./255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1PCHKzI8VrXv"
      },
      "outputs": [],
      "source": [
        "val_data_gen = image_gen_val.flow_from_directory(batch_size=batch_size,\n",
        "                                                 directory=validation_dir,\n",
        "                                                 target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                 class_mode='binary')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQGhdqHFVrXx"
      },
      "source": [
        "## Dropout"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Iq5TAH_VrXx"
      },
      "source": [
        "طريقة أخري لتجنب ظاهرة الoverfitting و هو الdropout \n",
        "و هي طريقة تجبر الشبكة العصبية علي جعل الأوزان في الشبكة تأخذ قيم صغيرة فقط و هذا يجعل توزيع قيم الأوزان في الشبكة العصبية بشكل منتظم أكثر\n",
        "\n",
        "عندما نقوم بتطبيق الdropout لطبقة \n",
        "يتم ايقاف بعض الوحدات في الشبكة بشكل عشوائي و يكون المخرج لها 0 \n",
        "هذه الطبقة تأخذ رقم بين 0 و 1 يعبر عن نسبة مئوية لعدد الوحدات التي سيتم توقيفها\n",
        "علي سبيل المثال إذا كانت القيمة 0.1 فهذا يعني أن 10% من عدد وحدات هذه الطبقة سيتم التوقف عن العمل\n",
        "\n",
        "سوف نقوم بإنشاء شبكة عصبية تعتمد علي هذا الأسلوب"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DyxxXRmVVrXy"
      },
      "source": [
        "## Creating a new network with Dropouts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Ba2LjtkVrXy"
      },
      "source": [
        "هنا نقوم بتطبيق الdropout لأول و أخر طبقة من الmax pool \n",
        "و بهذا سوف يتم ايقاف 20% من الوحدات عشوائيا في كل فترة تكرار للتدريب علي الصور و هذا بدوره يقلل من الoverfitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "2fjio8EsVrXz"
      },
      "outputs": [],
      "source": [
        "model_new = Sequential([\n",
        "    Conv2D(16, 3, padding='same', activation='relu', \n",
        "           input_shape=(IMG_HEIGHT, IMG_WIDTH ,3)),\n",
        "    MaxPooling2D(),\n",
        "    Dropout(0.2),\n",
        "    Conv2D(32, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(64, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Dropout(0.2),\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(1)\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tpTgIxWAVrX0"
      },
      "source": [
        "### نقوم بتدريب النموذج"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1osvc_iTVrX1"
      },
      "source": [
        "نبدأ في تدريب النموذج و نستخدم الاعدادات السابق ذكرها"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OkIJhS-WVrX1"
      },
      "outputs": [],
      "source": [
        "model_new.compile(optimizer='adam',\n",
        "                  loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "model_new.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KiDshEUVrX6"
      },
      "source": [
        "### تدريب النموذج"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFj0oVqVVrX6"
      },
      "source": [
        "بعدما قدمنا طرق زيادة الصور مع إضافة الdropout للشبكة العصبية نقوم بتدريب النموذج"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GWxHs_luVrX7"
      },
      "outputs": [],
      "source": [
        "history = model_new.fit_generator(\n",
        "    train_data_gen,\n",
        "    steps_per_epoch=total_train // batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=val_data_gen,\n",
        "    validation_steps=total_val // batch_size\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbdyqZdxVrYA"
      },
      "source": [
        "### إظهار نتائج النموذج"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgvF2nt7OtR7"
      },
      "source": [
        "إيضاح النتائج بعد تدريب النموذج الجديد, نري فارق ملحوظ ب\n",
        "\n",
        "Visualize the new model after training, you can see that there is significantly less overfitting than before. The accuracy should go up after training the model for more epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7BTeMuNAVrYC"
      },
      "outputs": [],
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "classification.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
