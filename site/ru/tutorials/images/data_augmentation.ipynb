{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4EFY9e5wRn7v"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "pkTRazeVRwDe"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VyOckJu6Rs-i"
      },
      "source": [
        "# Data augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HEsULqDR7AH"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/images/data_augmentation\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />Смотреть на TensorFlow.org</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/ru/tutorials/images/data_augmentation.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Запустить в Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/ru/tutorials/images/data_augmentation.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />Смотреть исходные файлы на GitHub</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/ru/tutorials/images/data_augmentation.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Скачать ноутбук</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8a2322303a3f"
      },
      "source": [
        "Note: Вся информация в этом разделе переведена с помощью русскоговорящего Tensorflow сообщества на общественных началах. Поскольку этот перевод не является официальным, мы не гарантируем что он на 100% аккуратен и соответствует [официальной документации на английском языке](https://www.tensorflow.org/?hl=en). Если у вас есть предложение как исправить этот перевод, мы будем очень рады увидеть pull request в [tensorflow/docs](https://github.com/tensorflow/docs) репозиторий GitHub. Если вы хотите помочь сделать документацию по Tensorflow лучше (сделать сам перевод или проверить перевод подготовленный кем-то другим), напишите нам на [docs-ru@tensorflow.org list](https://groups.google.com/a/tensorflow.org/forum/#!forum/docs-ru)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxIOE5RnSQtj"
      },
      "source": [
        "В этом уроке будет рассмотрено увеличение данных(аугментация): техника, позволяющай увеличить ваш тренировочный датасет с помощью случайных(но реалистичных) трансформаций изображения, например поворот. Вы изучиет два возможных способа аугментации данных. Первый - с использованием [Keras Preprocessing Layers](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/). Второй - используя `tf.image`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-UxHAqXmSXN5"
      },
      "source": [
        "## Импорт Tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C2Q5rPenTAJP"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.datasets import mnist"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ydx3SSoF4wpG"
      },
      "source": [
        "## Загрузка датасета\n",
        "\n",
        "В этом уроке используется датасет [tf_flowers](https://www.tensorflow.org/datasets/catalog/tf_flowers). Для удобства загрузите набор данных с помощью [TensorFlow Datasets](https://www.tensorflow.org/datasets). Если вы хотите узнать о других способах импорта данных, см. [load images](https://www.tensorflow.org/tutorials/load_data/images).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ytHhsYmO52zy"
      },
      "outputs": [],
      "source": [
        "(train_ds, val_ds, test_ds), metadata = tfds.load(\n",
        "    'tf_flowers',\n",
        "    split=['train[:80%]', 'train[80%:90%]', 'train[90%:]'],\n",
        "    with_info=True,\n",
        "    as_supervised=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjxEJtCwsnmm"
      },
      "source": [
        "Датасет \"flowers\" имеет 5 классов."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wKwx7vQuspxz"
      },
      "outputs": [],
      "source": [
        "num_classes = metadata.features['label'].num_classes\n",
        "print(num_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZAQW44949uw"
      },
      "source": [
        "Давайте возьмем изображение из датасета, чтобы использовать его для демонстрации аугментации."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kXlx1lCr5Bip"
      },
      "outputs": [],
      "source": [
        "get_label_name = metadata.features['label'].int2str\n",
        "\n",
        "image, label = next(iter(train_ds))\n",
        "_ = plt.imshow(image)\n",
        "_ = plt.title(get_label_name(label))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdJ6XA4q2nqK"
      },
      "source": [
        "## Использования слоя предобработки Keras(preprocessing layers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BTGz5AQ9LcD"
      },
      "source": [
        "Примечание. Слои [Keras Preprocesing Layers](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing), представленные в этом разделе, в настоящее время являются экспериментальными."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRMPnfzBB2hw"
      },
      "source": [
        "### Изменение размера и масштабирование\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhG7gSWmUMJx"
      },
      "source": [
        "Вы можете использовать слои предварительной обработки, чтобы [изменить размер изображений](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/Resizing) и [масштабировать изображения](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/Rescaling)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jMM3b85e3yhd"
      },
      "outputs": [],
      "source": [
        "IMG_SIZE = 180\n",
        "\n",
        "resize_and_rescale = tf.keras.Sequential([\n",
        "  layers.experimental.preprocessing.Resizing(IMG_SIZE, IMG_SIZE),\n",
        "  layers.experimental.preprocessing.Rescaling(1./255)\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4z8AV1WgnYNW"
      },
      "source": [
        "Примечание. Слой масштабирования выше нормализует значения пикселей до `[0,1]`. Если вместо этого вы хотите нормализовать до `[-1,1]`, нужно передать аргумент *offset = -1*: Rescaling (1./127.5, offset = -1)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQiTwsHJDHAD"
      },
      "source": [
        "Вы можете просмотреть результат применения этих слоев на изображение"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X9OLuR1bC1Pd"
      },
      "outputs": [],
      "source": [
        "result = resize_and_rescale(image)\n",
        "_ = plt.imshow(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxAMg8Zql5lw"
      },
      "source": [
        "Вы также можете убедится, что пиксели находятся в диапазоне `[0-1]`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DPTB8IQmSeKM"
      },
      "outputs": [],
      "source": [
        "print(\"Min and max pixel values:\", result.numpy().min(), result.numpy().max())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fL6M7fuivAw4"
      },
      "source": [
        "### Аугментация данных"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SL4Suj46ScfU"
      },
      "source": [
        "Вы также можете использовать слои предварительной обработки для аугментации данных."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-4PugTE-4sl"
      },
      "source": [
        "Давайте создадим несколько слоев предварительной обработки и повторно применим их к одному и тому же изображению."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Svu_5yfa_Jb7"
      },
      "outputs": [],
      "source": [
        "data_augmentation = tf.keras.Sequential([\n",
        "  layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
        "  layers.experimental.preprocessing.RandomRotation(0.2),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kfzEuaNg69iU"
      },
      "outputs": [],
      "source": [
        "# Добавим изображение в пакет\n",
        "image = tf.expand_dims(image, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eR4wwi5Q_UZK"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(9):\n",
        "  augmented_image = data_augmentation(image)\n",
        "  ax = plt.subplot(3, 3, i + 1)\n",
        "  plt.imshow(augmented_image[0])\n",
        "  plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jA17pEeS_2_-"
      },
      "source": [
        "Существует множество вариантов [предварительной обработки](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing), которые вы можете использовать для аугментации данных. Например слои: `layers.RandomContrast`, `layers.RandomCrop`, `layers.RandomZoom` и другие."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GG5RhIJtE0ng"
      },
      "source": [
        "### Два варианта использования слоев предварительной обработки\n",
        "\n",
        "Существует два способа использования слоев предварительной обработки, но с важными замечаниями."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MxGvUT727Po6"
      },
      "source": [
        "#### Способ 1: Сделать слой предварительной обработки частью вашей модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ULGJQjP6hHvu"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential([\n",
        "  resize_and_rescale,\n",
        "  data_augmentation,\n",
        "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  # Остальная часть вашей модели\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pc6ELneyhJN9"
      },
      "source": [
        "В этом случае следует помнить о двух важных моментах:\n",
        "\n",
        "* Аугментация данных будет выполняться на устройстве синхронно с остальными вашими слоями и будет использовать\n",
        " графический процессор.\n",
        "\n",
        "* Когда вы экспортируете вашу модель с помощью `model.save`, слои предварительной обработки будут сохранены вместе с остальной частью вашей модели. Если вы позже развернете эту модель, она автоматически нормализует изображения(в соответствии с конфигурацией ваших слоев). Это может избавить вас от необходимости заново реализовывать эту логику на стороне сервера."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syZwDSpiRXZP"
      },
      "source": [
        "Примечание. Увеличение данных не работает во время тестирования, поэтому входные изображения будут аугментироваться только во время вызовов `model.fit` (не `model.evaluate` или `model.predict`)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2X3JTeY_vfv"
      },
      "source": [
        "#### Способ 2: Применить слои предварительной обработки к датасету"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r1Bt7w5VhVDY"
      },
      "outputs": [],
      "source": [
        "aug_ds = train_ds.map(\n",
        "  lambda x, y: (resize_and_rescale(x, training=True), y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKqeahG2hVdV"
      },
      "source": [
        "При таком подходе вы используете `Dataset.map` для создания пакетов аугментированных изображений. \n",
        "В этом случае:\n",
        "* Увеличение данных происходит асинхронно на ЦП и не является блокирующим. Вы можете частично перекрывать обучение вашей модели на GPU с предварительной обработкой данных, используя `Dataset.prefetch`, как будет показано ниже.\n",
        "* В этом случае слои предварительной обработки не будут экспортированы вместе с моделью при вызове `model.save`. Вам нужно будет прикрепить их к вашей модели перед ее сохранением или повторной реализацией на стороне сервера. После обучения вы можете прикрепить слои предварительной обработки перед экспортом."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cgj51k9J7jfc"
      },
      "source": [
        "Вы можете найти пример первого варианта в учебнике [классификация изображений](https://www.tensorflow.org/tutorials/images/classification). Здесь продемонстрируем второй вариант."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31YwMQdrXKBP"
      },
      "source": [
        "### Применение слоев предварительной обработки к датасету"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUgW-2LOGiOT"
      },
      "source": [
        "Вы настроите датасеты для обучения, проверки и тестирования с помощью слоев предварительной обработки, которые вы создали выше. Также вы сконфигурируете датасеты для повышения производительности, используя параллельное чтение и буферизованную предварительную выборку, чтобы читать пакеты с диска без блокировки ввода-вывода. Вы можете узнать больше о производительности датасета в руководстве [Повышение производительности с помощью tf.data API](https://www.tensorflow.org/guide/data_performance)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eI7VdyqK767y"
      },
      "source": [
        "Примечание: аугментация данных должна применяться только к тренировочному датасету."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R5fGVMqlFxF7"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "def prepare(ds, shuffle=False, augment=False):\n",
        "  # Изменение размера и масштабирование всех наборов данных\n",
        "  ds = ds.map(lambda x, y: (resize_and_rescale(x), y), \n",
        "              num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "  if shuffle:\n",
        "    ds = ds.shuffle(1000)\n",
        "\n",
        "  # Пакетная обработка всех наборов данных\n",
        "  ds = ds.batch(batch_size)\n",
        "\n",
        "  # Используем аугментацию данных только на обучающем датасете\n",
        "  if augment:\n",
        "    ds = ds.map(lambda x, y: (data_augmentation(x, training=True), y), \n",
        "                num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "  # Используем буферизованную предварительную выборку для всех наборов данных\n",
        "  return ds.prefetch(buffer_size=AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N86SFGMBHcx-"
      },
      "outputs": [],
      "source": [
        "train_ds = prepare(train_ds, shuffle=True, augment=True)\n",
        "val_ds = prepare(val_ds)\n",
        "test_ds = prepare(test_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gplDz4ZV6kk"
      },
      "source": [
        "### Обучение модели\n",
        "\n",
        "В завершение, обучите модель, используя эти наборы данных. Эта модель не была настроена на точность (цель данного урока - показать вам механику)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IODSymGhq9N6"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential([\n",
        "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  layers.Dense(num_classes)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZnRJr95WY68k"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i_sDl9uZY9Mh"
      },
      "outputs": [],
      "source": [
        "epochs=5\n",
        "history = model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=epochs\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V9PSf4qgiQJG"
      },
      "outputs": [],
      "source": [
        "loss, acc = model.evaluate(test_ds)\n",
        "print(\"Accuracy\", acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BkRvvsXb6SI"
      },
      "source": [
        "### Пользовательская аугментация данных\n",
        "\n",
        "Вы также можете создавать собственные слои аугментации данных. В этом руководстве показаны два способа. \n",
        "1. Сначала вы создадите слой `layers.Lambda`. Это хороший способ написать лаконичный код. \n",
        "2. Затем вы напишете новый слой с помощью [наследования классов](https://www.tensorflow.org/guide/keras/custom_layers_and_models), это даст вам больше контроля. Оба слоя будут случайным образом инвертировать цвета изображения с некоторой вероятностью. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nMxEhIVXmAH0"
      },
      "outputs": [],
      "source": [
        "def random_invert_img(x, p=0.5):\n",
        "  if  tf.random.uniform([]) < p:\n",
        "    x = (255-x)\n",
        "  else:\n",
        "    x\n",
        "  return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C0huNpxdmDKu"
      },
      "outputs": [],
      "source": [
        "def random_invert(factor=0.5):\n",
        "  return layers.Lambda(lambda x: random_invert_img(x, factor))\n",
        "\n",
        "random_invert = random_invert()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wAcOluP0TNG6"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(9):\n",
        "  augmented_image = random_invert(image)\n",
        "  ax = plt.subplot(3, 3, i + 1)\n",
        "  plt.imshow(augmented_image[0].numpy().astype(\"uint8\"))\n",
        "  plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xd9XG2PLM5ZJ"
      },
      "source": [
        "Теперь реализуем настраиваемый слой с помощью [наследования класса](https://www.tensorflow.org/guide/keras/custom_layers_and_models)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d11eExc-Ke-7"
      },
      "outputs": [],
      "source": [
        "class RandomInvert(layers.Layer):\n",
        "  def __init__(self, factor=0.5, **kwargs):\n",
        "    super().__init__(**kwargs)\n",
        "    self.factor = factor\n",
        "\n",
        "  def call(self, x):\n",
        "    return random_invert_img(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qX-VQgkRL6fc"
      },
      "outputs": [],
      "source": [
        "_ = plt.imshow(RandomInvert()(image)[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0nmllnXZO6T"
      },
      "source": [
        "Оба эти слоя можно использовать, как описано в вариантах 1 и 2 выше."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7-k__2dAfX6"
      },
      "source": [
        "## Использование tf.image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJco2x35EAMs"
      },
      "source": [
        "Вышеупомянутые утилиты `layers.preprocessing` удобны, однако для более точного управления вы можете написать свои собственные конвейеры или слои аугментации, используя tf.data и tf.image. Вы также можете ознакомиться с [TensorFlow Addons Image: Operations](https://www.tensorflow.org/addons/tutorials/image_ops) и [TensorFlow I/O: преобразование цветового пространства](https://www.tensorflow.org/io/tutorials/colorspace)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xR1RvjYkdd_i"
      },
      "source": [
        "Поскольку датасет цветов ранее был аугментирован, давайте повторно импортируем его, чтобы начать все заново."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JB-lAS0z9ZJY"
      },
      "outputs": [],
      "source": [
        "(train_ds, val_ds, test_ds), metadata = tfds.load(\n",
        "    'tf_flowers',\n",
        "    split=['train[:80%]', 'train[80%:90%]', 'train[90%:]'],\n",
        "    with_info=True,\n",
        "    as_supervised=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQ3pqBTS9hNj"
      },
      "source": [
        "Получим изображение для работы."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dDsPaAi8de_j"
      },
      "outputs": [],
      "source": [
        "image, label = next(iter(train_ds))\n",
        "_ = plt.imshow(image)\n",
        "_ = plt.title(get_label_name(label))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chelxcPtFiTF"
      },
      "source": [
        "Для визуализации и сравнения исходных и дополненных изображений воспользуемся следующей функцией."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sN1ykjJCHikc"
      },
      "outputs": [],
      "source": [
        "def visualize(original, augmented):\n",
        "  fig = plt.figure()\n",
        "  plt.subplot(1,2,1)\n",
        "  plt.title('Original image')\n",
        "  plt.imshow(original)\n",
        "\n",
        "  plt.subplot(1,2,2)\n",
        "  plt.title('Augmented image')\n",
        "  plt.imshow(augmented)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5X4ijQYHmlt"
      },
      "source": [
        "### Аугментация данных"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRD9oujLHo6c"
      },
      "source": [
        "### Переворачивание изображения\n",
        "\n",
        "Отразим изображение по вертикали или горизонтали."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ZjVI24nIH0S"
      },
      "outputs": [],
      "source": [
        "flipped = tf.image.flip_left_right(image)\n",
        "visualize(image, flipped)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6iD_lLibIL9q"
      },
      "source": [
        "### Преобразование в серое\n",
        "\n",
        "Преобразование в изображение с оттенками серого"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ikaMj0guIRtL"
      },
      "outputs": [],
      "source": [
        "grayscaled = tf.image.rgb_to_grayscale(image)\n",
        "visualize(image, tf.squeeze(grayscaled))\n",
        "_ = plt.colorbar()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-5yjIs4IZ7v"
      },
      "source": [
        "### Насыщение изображение\n",
        "\n",
        "Увеличим насыщенность цветов изображения, задав коэффициент насыщенности."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PHz-NosiInmz"
      },
      "outputs": [],
      "source": [
        "saturated = tf.image.adjust_saturation(image, 3)\n",
        "visualize(image, saturated)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWXiy8qfIqdC"
      },
      "source": [
        "### Изменение яркости изображения\n",
        "\n",
        "Изменим яркость изображения, указав коэффициент яркости."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1hdG-j46I0nJ"
      },
      "outputs": [],
      "source": [
        "bright = tf.image.adjust_brightness(image, 0.4)\n",
        "visualize(image, bright)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjEOFEITJOr2"
      },
      "source": [
        "### Обрезка изображения по центру\n",
        "\n",
        "Обрежем изображение от центра до желаемой части изображения."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RWkK5GFHJUKT"
      },
      "outputs": [],
      "source": [
        "cropped = tf.image.central_crop(image, central_fraction=0.5)\n",
        "visualize(image,cropped)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unt76GebI3Gc"
      },
      "source": [
        "### Поворот изображения\n",
        "\n",
        "Повернем изображение на 90 градусов."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b19KuAhkJKR-"
      },
      "outputs": [],
      "source": [
        "rotated = tf.image.rot90(image)\n",
        "visualize(image, rotated)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "isrM-MZtpxTq"
      },
      "source": [
        "### Применение аугментации к датасету\n",
        "\n",
        "Как и раньше, применим аугментацию данных к набору данных с помощью `Dataset.map`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1JKmx06lfcFr"
      },
      "outputs": [],
      "source": [
        "def resize_and_rescale(image, label):\n",
        "  image = tf.cast(image, tf.float32)\n",
        "  image = tf.image.resize(image, [IMG_SIZE, IMG_SIZE])\n",
        "  image = (image / 255.0)\n",
        "  return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FvuNMF8qqRsD"
      },
      "outputs": [],
      "source": [
        "def augment(image,label):\n",
        "  image, label = resize_and_rescale(image, label)\n",
        "  # Add 6 pixels of padding\n",
        "  image = tf.image.resize_with_crop_or_pad(image, IMG_SIZE + 6, IMG_SIZE + 6) \n",
        "   # Random crop back to the original size\n",
        "  image = tf.image.random_crop(image, size=[IMG_SIZE, IMG_SIZE, 3])\n",
        "  image = tf.image.random_brightness(image, max_delta=0.5) # Random brightness\n",
        "  image = tf.clip_by_value(image, 0, 1)\n",
        "  return image, label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Khu7amifqbni"
      },
      "source": [
        "### Настройка датасетов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "khgl0CwEeZ-_"
      },
      "outputs": [],
      "source": [
        "train_ds = (\n",
        "    train_ds\n",
        "    .shuffle(1000)\n",
        "    .map(augment, num_parallel_calls=AUTOTUNE)\n",
        "    .batch(batch_size)\n",
        "    .prefetch(AUTOTUNE)\n",
        ") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4PUbgIYJebED"
      },
      "outputs": [],
      "source": [
        "val_ds = (\n",
        "    val_ds\n",
        "    .map(resize_and_rescale, num_parallel_calls=AUTOTUNE)\n",
        "    .batch(batch_size)\n",
        "    .prefetch(AUTOTUNE)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nQvQzKoQgBw2"
      },
      "outputs": [],
      "source": [
        "test_ds = (\n",
        "    test_ds\n",
        "    .map(resize_and_rescale, num_parallel_calls=AUTOTUNE)\n",
        "    .batch(batch_size)\n",
        "    .prefetch(AUTOTUNE)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKwCA6AOjTrc"
      },
      "source": [
        "Эти датасеты теперь можно использовать для обучения модели, как показано ранее."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YypDihDlj0no"
      },
      "source": [
        "## Что дальше?\n",
        "\n",
        "Это руководство показало вам как аугментировать данные с помощью [Keras Preprocessing Layers](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/) и `tf.image`. Чтобы узнать как включить слои предобработки в вашу модель - смотрите руководство по [Image classification](https://www.tensorflow.org/tutorials/images/classification). Вам также может быть интересно узнать, как слои предварительной обработки могут помочь в классификации текста - [Basic text classification](https://www.tensorflow.org/tutorials/keras/text_classification). Вы можете узнать больше о `tf.data` в этом [руководстве](https://www.tensorflow.org/guide/data), и вы можете узнать, как настроить входные конвейеры для повышения производительности [здесь](https://www.tensorflow.org/guide/data_performance)."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "data_augmentation.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
