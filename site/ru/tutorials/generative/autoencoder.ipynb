{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ndo4ERqnwQOU"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "MTKwbguKwT4R"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfNT-mlFwxVM"
      },
      "source": [
        "# Введение в автоэнкодеры"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0TD5ZrvEMbhZ"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/generative/autoencoder\">\n",
        "    <img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />\n",
        "    Смотрите на TensorFlow.org</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/community/site/ru/tutorials/generative/autoencoder.ipynb\">\n",
        "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />\n",
        "    Запустите в Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/community/site/ru/tutorials/generative/autoencoder.ipynb\">\n",
        "    <img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />\n",
        "    Изучайте код на GitHub</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/ru/tutorials/generative/autoencoder.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Скачайте ноутбук</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8a2322303a3f"
      },
      "source": [
        "Note: Вся информация в этом разделе переведена с помощью русскоговорящего Tensorflow сообщества на общественных началах. Поскольку этот перевод не является официальным, мы не гарантируем что он на 100% аккуратен и соответствует [официальной документации на английском языке](https://www.tensorflow.org/?hl=en). Если у вас есть предложение как исправить этот перевод, мы будем очень рады увидеть pull request в [tensorflow/docs](https://github.com/tensorflow/docs) репозиторий GitHub. Если вы хотите помочь сделать документацию по Tensorflow лучше (сделать сам перевод или проверить перевод подготовленный кем-то другим), напишите нам на [docs-ru@tensorflow.org list](https://groups.google.com/a/tensorflow.org/forum/#!forum/docs-ru)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITZuApL56Mny"
      },
      "source": [
        "В этом руководстве представлены три примера автоэнкодеров: основной, шумоподавление изображения и обнаружение аномалий.\n",
        "\n",
        "Автоэнкодер - это особый тип нейронной сети, которая обучается копировать свои входные данные в выходные данные. Например, учитывая изображение рукописной цифры, автокодер сначала кодирует изображение в скрытое представление меньшей размерности, а затем декодирует скрытое представление обратно в изображение. Автоэнкодер учится сжимать данные, сводя к минимуму ошибку восстановления.\n",
        "\n",
        "Чтобы узнать больше об автоэнкодерах, прочитайте главу 14 из [Deep Learning](https://www.deeplearningbook.org/) Яна Гудфеллоу, Йошуа Бенжио и Аарона Курвилля."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1_Y75QXJS6h"
      },
      "source": [
        "## Имопорт TensorFlow и библиотек"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YfIk2es3hJEd"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import layers, losses\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.models import Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYn4MdZnKCey"
      },
      "source": [
        "## Загрузка датасета\n",
        "Для начала вы обучите базовый автоэнкодер, используя набор данных Fashion MNIST. Каждое изображение в этом наборе данных имеет размер 28x28 пикселей."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YZm503-I_tji"
      },
      "outputs": [],
      "source": [
        "(x_train, _), (x_test, _) = fashion_mnist.load_data()\n",
        "\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "\n",
        "print (x_train.shape)\n",
        "print (x_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEdCXSwCoKok"
      },
      "source": [
        "## Первый пример: базовый автоэнкодер\n",
        "![Основные результаты автоэнкодера](images/intro_autoencoder_result.png)\n",
        "\n",
        "Определите автоэнкодер с двумя полносвязными слоями: `кодировщик`, который сжимает изображения в 64-мерный скрытый вектор, и `декодировщик`, который восстанавливает исходное изображение из скрытого пространства.\n",
        "\n",
        "Чтобы определить вашу модель, используйте [Keras Model Subclassing API](https://www.tensorflow.org/guide/keras/custom_layers_and_models).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0MUxidpyChjX"
      },
      "outputs": [],
      "source": [
        "latent_dim = 64 \n",
        "\n",
        "class Autoencoder(Model):\n",
        "  def __init__(self, encoding_dim):\n",
        "    super(Autoencoder, self).__init__()\n",
        "    self.latent_dim = latent_dim   \n",
        "    self.encoder = tf.keras.Sequential([\n",
        "      layers.Flatten(),\n",
        "      layers.Dense(latent_dim, activation='relu'),\n",
        "    ])\n",
        "    self.decoder = tf.keras.Sequential([\n",
        "      layers.Dense(784, activation='sigmoid'),\n",
        "      layers.Reshape((28, 28))\n",
        "    ])\n",
        "\n",
        "  def call(self, x):\n",
        "    encoded = self.encoder(x)\n",
        "    decoded = self.decoder(encoded)\n",
        "    return decoded\n",
        "  \n",
        "autoencoder = Autoencoder(latent_dim) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9I1JlqEIDCI4"
      },
      "outputs": [],
      "source": [
        "autoencoder.compile(optimizer='adam', loss=losses.MeanSquaredError())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oJSeMTroABs"
      },
      "source": [
        "Обучите модель, используя `x_train` как в качестве входных признаков, так и в качестве входных маркеров. `Энкодер` научится сжимать набор данных из 784 измерений в скрытое пространство, а `декодер` научится восстанавливать исходные изображения."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h1RI9OfHDBsK"
      },
      "outputs": [],
      "source": [
        "autoencoder.fit(x_train, x_train,\n",
        "                epochs=10,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test, x_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAM1QBhtoC-n"
      },
      "source": [
        "Теперь, когда модель обучена, давайте протестируем ее путем кодирования и декодирования изображений из тестового набора."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pbr5WCj7FQUi"
      },
      "outputs": [],
      "source": [
        "encoded_imgs = autoencoder.encoder(x_test).numpy()\n",
        "decoded_imgs = autoencoder.decoder(encoded_imgs).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s4LlDOS6FUA1"
      },
      "outputs": [],
      "source": [
        "n = 10\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(n):\n",
        "  # display original\n",
        "  ax = plt.subplot(2, n, i + 1)\n",
        "  plt.imshow(x_test[i])\n",
        "  plt.title(\"original\")\n",
        "  plt.gray()\n",
        "  ax.get_xaxis().set_visible(False)\n",
        "  ax.get_yaxis().set_visible(False)\n",
        "\n",
        "  # display reconstruction\n",
        "  ax = plt.subplot(2, n, i + 1 + n)\n",
        "  plt.imshow(decoded_imgs[i])\n",
        "  plt.title(\"reconstructed\")\n",
        "  plt.gray()\n",
        "  ax.get_xaxis().set_visible(False)\n",
        "  ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4gv6G8PoRQE"
      },
      "source": [
        "## Второй пример: уменьшение шума на изображении\n",
        "\n",
        "![Результаты шумоподавления изображения](images/image_denoise_fmnist_results.png)\n",
        "\n",
        "Автоэнкодер также можно обучить удалению шума с изображений. В следующем разделе вы создадите зашумленную версию набора данных Fashion MNIST, применив случайный шум к каждому изображению. Затем вы обучите автоэнкодер, используя зашумленное изображение в качестве входных данных и исходное изображение в качестве цели.\n",
        "\n",
        "Давайте повторно импортируем набор данных, чтобы убрать изменения, сделанные ранее."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gDYHJA2PCQ3m"
      },
      "outputs": [],
      "source": [
        "(x_train, _), (x_test, _) = fashion_mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uJZ-TcaqDBr5"
      },
      "outputs": [],
      "source": [
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "\n",
        "x_train = x_train[..., tf.newaxis]\n",
        "x_test = x_test[..., tf.newaxis]\n",
        "\n",
        "print(x_train.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPZl_6P65_8R"
      },
      "source": [
        "Добавление случайного шума к изображениям"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "axSMyxC354fc"
      },
      "outputs": [],
      "source": [
        "noise_factor = 0.2\n",
        "x_train_noisy = x_train + noise_factor * tf.random.normal(shape=x_train.shape) \n",
        "x_test_noisy = x_test + noise_factor * tf.random.normal(shape=x_test.shape) \n",
        "\n",
        "x_train_noisy = tf.clip_by_value(x_train_noisy, clip_value_min=0., clip_value_max=1.)\n",
        "x_test_noisy = tf.clip_by_value(x_test_noisy, clip_value_min=0., clip_value_max=1.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRxHe4XXltNd"
      },
      "source": [
        "Посмотрите зашумленные изображения."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "thKUmbVVCQpt"
      },
      "outputs": [],
      "source": [
        "n = 10\n",
        "plt.figure(figsize=(20, 2))\n",
        "for i in range(n):\n",
        "    ax = plt.subplot(1, n, i + 1)\n",
        "    plt.title(\"original + noise\")\n",
        "    plt.imshow(tf.squeeze(x_test_noisy[i]))\n",
        "    plt.gray()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sy9SY8jGl5aP"
      },
      "source": [
        "### Определениее сверточного автоенкодера"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vT_BhZngWMwp"
      },
      "source": [
        "В этом примере вы обучите сверточный автоэнкодер, используя слои [Conv2D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D) в `encoder` и [Conv2DTranspose](https : //www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2DTranspose) в `decoder`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R5KjoIlYCQko"
      },
      "outputs": [],
      "source": [
        "class Denoise(Model):\n",
        "  def __init__(self):\n",
        "    super(Denoise, self).__init__()\n",
        "    self.encoder = tf.keras.Sequential([\n",
        "      layers.Input(shape=(28, 28, 1)), \n",
        "      layers.Conv2D(16, (3,3), activation='relu', padding='same', strides=2),\n",
        "      layers.Conv2D(8, (3,3), activation='relu', padding='same', strides=2)])\n",
        "    \n",
        "    self.decoder = tf.keras.Sequential([\n",
        "      layers.Conv2DTranspose(8, kernel_size=3, strides=2, activation='relu', padding='same'),\n",
        "      layers.Conv2DTranspose(16, kernel_size=3, strides=2, activation='relu', padding='same'),\n",
        "      layers.Conv2D(1, kernel_size=(3,3), activation='sigmoid', padding='same')])\n",
        "    \n",
        "  def call(self, x):\n",
        "    encoded = self.encoder(x)\n",
        "    decoded = self.decoder(encoded)\n",
        "    return decoded\n",
        "\n",
        "autoencoder = Denoise()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QYKbiDFYCQfj"
      },
      "outputs": [],
      "source": [
        "autoencoder.compile(optimizer='adam', loss=losses.MeanSquaredError())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IssFr1BNCQX3"
      },
      "outputs": [],
      "source": [
        "autoencoder.fit(x_train_noisy, x_train,\n",
        "                epochs=10,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test_noisy, x_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G85xUVBGTAKp"
      },
      "source": [
        "Давайте взглянем на краткое описание енкодера. Обратите внимание, как изображения уменьшаются с 28x28 до 7x7."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oEpxlX6sTEQz"
      },
      "outputs": [],
      "source": [
        "autoencoder.encoder.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDZBfMx1UtXx"
      },
      "source": [
        "Декодер увеличивает разрешение изображения с 7x7 до 28x28."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pbeQtYMaUpro"
      },
      "outputs": [],
      "source": [
        "autoencoder.decoder.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7-VAuEy_N6M"
      },
      "source": [
        "Просмотрим зашумленные изображения и изображений с шумоподавлением, созданные автокодером."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t5IyPi1fCQQz"
      },
      "outputs": [],
      "source": [
        "encoded_imgs = autoencoder.encoder(x_test).numpy()\n",
        "decoded_imgs = autoencoder.decoder(encoded_imgs).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sfxr9NdBCP_x"
      },
      "outputs": [],
      "source": [
        "n = 10\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(n):\n",
        "\n",
        "    # display original + noise\n",
        "    ax = plt.subplot(2, n, i + 1)\n",
        "    plt.title(\"original + noise\")\n",
        "    plt.imshow(tf.squeeze(x_test_noisy[i]))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # display reconstruction\n",
        "    bx = plt.subplot(2, n, i + n + 1)\n",
        "    plt.title(\"reconstructed\")\n",
        "    plt.imshow(tf.squeeze(decoded_imgs[i]))\n",
        "    plt.gray()\n",
        "    bx.get_xaxis().set_visible(False)\n",
        "    bx.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErGrTnWHoUYl"
      },
      "source": [
        "## Третий пример: обнаружение аномалии\n",
        "\n",
        "## Обзор\n",
        "\n",
        "\n",
        "В этом примере вы обучите автоэнкодер обнаруживать аномалии в [наборе данных ECG5000](http://www.timeseriesclassification.com/description.php?Dataset=ECG5000). Этот набор данных содержит 5000 [электрокардиограмм](https://en.wikipedia.org/wiki/Electrocardiography), каждая из которых содержит 140 точек данных. Вы будете использовать упрощенную версию датасета, где каждый пример помечен как `0`(соответствует ненормальному ритму) или `1`(соответствует нормальному ритму). Вам нужно идентифицировать аномальные ритмы.\n",
        "\n",
        "Примечание. Это размеченный набор данных, поэтому вы можете назвать его `обучение с учителем`. Цель этого примера - проиллюстрировать концепции обнаружения аномалий, которые вы можете применить к большим наборам данных, где у вас нет размеченных меток(например, если у вас было несколько тысяч нормальных ритмов и только небольшое количество аномальных ритмов).\n",
        "\n",
        "Как вы обнаружите аномалии с помощью автокодировщика? Напомним, что автоэнкодер обучен минимизировать ошибку восстановления. Вы обучите автоэнкодер только нормальным ритмам, а затем воспользуетесь им для восстановления всех данных. Наша гипотеза состоит в том, что аномальные ритмы будут иметь более высокую ошибку восстановления. Таким образом вы классифицируете ритм как аномалию, если ошибка восстановления превышает фиксированный порог."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5estNaur_Mh"
      },
      "source": [
        "### Загрузка ECG датасета"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y35nsXLPsDNX"
      },
      "source": [
        "Набор данных, который вы будете использовать, основан на одном из [timeseriesclassification.com](http://www.timeseriesclassification.com/description.php?Dataset=ECG5000).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KmKRDJWgsFYa"
      },
      "outputs": [],
      "source": [
        "# Загружаем датасет\n",
        "dataframe = pd.read_csv('http://storage.googleapis.com/download.tensorflow.org/data/ecg.csv', header=None)\n",
        "raw_data = dataframe.values\n",
        "dataframe.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UmuCPVYKsKKx"
      },
      "outputs": [],
      "source": [
        "# Последний элемент строки содержит метку\n",
        "labels = raw_data[:, -1]\n",
        "\n",
        "# Остальные данные это данные электрокардиограмм\n",
        "data = raw_data[:, 0:-1]\n",
        "\n",
        "train_data, test_data, train_labels, test_labels = train_test_split(\n",
        "    data, labels, test_size=0.2, random_state=21\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "byK2vP7hsMbz"
      },
      "source": [
        "Нормализуем данные до `[0,1]`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tgMZVWRKsPx6"
      },
      "outputs": [],
      "source": [
        "min_val = tf.reduce_min(train_data)\n",
        "max_val = tf.reduce_max(train_data)\n",
        "\n",
        "train_data = (train_data - min_val) / (max_val - min_val)\n",
        "test_data = (test_data - min_val) / (max_val - min_val)\n",
        "\n",
        "train_data = tf.cast(train_data, tf.float32)\n",
        "test_data = tf.cast(test_data, tf.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdSYr2IPsTiz"
      },
      "source": [
        "Вы будете обучать автоэнкодер, используя только нормальные ритмы, которые в этом наборе данных обозначены как `1`. Отделите нормальные ритмы от ненормальных."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VvK4NRe8sVhE"
      },
      "outputs": [],
      "source": [
        "train_labels = train_labels.astype(bool)\n",
        "test_labels = test_labels.astype(bool)\n",
        "\n",
        "normal_train_data = train_data[train_labels]\n",
        "normal_test_data = test_data[test_labels]\n",
        "\n",
        "anomalous_train_data = train_data[~train_labels]\n",
        "anomalous_test_data = test_data[~test_labels]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVcTBDo-CqFS"
      },
      "source": [
        "Отрисуйте нормальные ритмы ECG. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZTlMIrpmseYe"
      },
      "outputs": [],
      "source": [
        "plt.grid()\n",
        "plt.plot(np.arange(140), normal_train_data[0])\n",
        "plt.title(\"A Normal ECG\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpI9by2ZA0NN"
      },
      "source": [
        "Отрисуйте ненормальные ритмы ECG."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zrpXREF2siBr"
      },
      "outputs": [],
      "source": [
        "plt.grid()\n",
        "plt.plot(np.arange(140), anomalous_train_data[0])\n",
        "plt.title(\"An Anomalous ECG\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0DS6QKZJslZz"
      },
      "source": [
        "### Создание модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bf6owZQDsp9y"
      },
      "outputs": [],
      "source": [
        "class AnomalyDetector(Model):\n",
        "  def __init__(self):\n",
        "    super(AnomalyDetector, self).__init__()\n",
        "    self.encoder = tf.keras.Sequential([\n",
        "      layers.Dense(32, activation=\"relu\"),\n",
        "      layers.Dense(16, activation=\"relu\"),\n",
        "      layers.Dense(8, activation=\"relu\")])\n",
        "    \n",
        "    self.decoder = tf.keras.Sequential([\n",
        "      layers.Dense(16, activation=\"relu\"),\n",
        "      layers.Dense(32, activation=\"relu\"),\n",
        "      layers.Dense(140, activation=\"sigmoid\")])\n",
        "    \n",
        "  def call(self, x):\n",
        "    encoded = self.encoder(x)\n",
        "    decoded = self.decoder(encoded)\n",
        "    return decoded\n",
        "\n",
        "autoencoder = AnomalyDetector()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gwRpBBbg463S"
      },
      "outputs": [],
      "source": [
        "autoencoder.compile(optimizer='adam', loss='mae')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zuTy60STBEy4"
      },
      "source": [
        "Обратите внимание, что автокодировщик обучается с использованием только нормальных ЭКГ, но оценивается с использованием полного набора данных."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V6NFSs-jsty2"
      },
      "outputs": [],
      "source": [
        "history = autoencoder.fit(normal_train_data, normal_train_data, \n",
        "          epochs=20, \n",
        "          batch_size=512,\n",
        "          validation_data=(test_data, test_data),\n",
        "          shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OEexphFwwTQS"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history[\"loss\"], label=\"Training Loss\")\n",
        "plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceI5lKv1BT-A"
      },
      "source": [
        "Вы быстро классифицируете ЭКГ как аномальную, если ошибка реконструкции больше одного стандартного отклонения от нормальных обучающих примеров. Сначала давайте построим нормальную ЭКГ из датасета, ее реконструкцию после кодирования и декодирования и ошибку реконструкции."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hmsk4DuktxJ2"
      },
      "outputs": [],
      "source": [
        "encoded_imgs = autoencoder.encoder(normal_test_data).numpy()\n",
        "decoded_imgs = autoencoder.decoder(encoded_imgs).numpy()\n",
        "\n",
        "plt.plot(normal_test_data[0],'b')\n",
        "plt.plot(decoded_imgs[0],'r')\n",
        "plt.fill_between(np.arange(140), decoded_imgs[0], normal_test_data[0], color='lightcoral' )\n",
        "plt.legend(labels=[\"Input\", \"Reconstruction\", \"Error\"])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocA_q9ufB_aF"
      },
      "source": [
        "Создайте аналогичный график, на этот раз для аномального примера."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vNFTuPhLwTBn"
      },
      "outputs": [],
      "source": [
        "encoded_imgs = autoencoder.encoder(anomalous_test_data).numpy()\n",
        "decoded_imgs = autoencoder.decoder(encoded_imgs).numpy()\n",
        "\n",
        "plt.plot(anomalous_test_data[0],'b')\n",
        "plt.plot(decoded_imgs[0],'r')\n",
        "plt.fill_between(np.arange(140), decoded_imgs[0], anomalous_test_data[0], color='lightcoral' )\n",
        "plt.legend(labels=[\"Input\", \"Reconstruction\", \"Error\"])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocimg3MBswdS"
      },
      "source": [
        "### Определение аномалий"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xnh8wmkDsypN"
      },
      "source": [
        "Вы можете обнаружить аномалии, вычисляя, превышают ли потери при реконструкции фиксированный порог. В этом руководстве вы рассчитаете среднюю среднюю ошибку для нормальных примеров из обучающего набора, а затем классифицируете будущие примеры как аномальные, если ошибка реконструкции превышает одно стандартное отклонение от обучающего набора."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TeuT8uTA5Y_w"
      },
      "source": [
        "Постройте график ошибки реконструкции на нормальных ЭКГ из обучающей выборки"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gwLuxrb-s0ss"
      },
      "outputs": [],
      "source": [
        "reconstructions = autoencoder.predict(normal_train_data)\n",
        "train_loss = tf.keras.losses.mae(reconstructions, normal_train_data)\n",
        "\n",
        "plt.hist(train_loss, bins=50)\n",
        "plt.xlabel(\"Train loss\")\n",
        "plt.ylabel(\"No of examples\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mh-3ChEF5hog"
      },
      "source": [
        "Выберите пороговое значение, которое на одно стандартное отклонение выше среднего."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "82hkl0Chs3P_"
      },
      "outputs": [],
      "source": [
        "threshold = np.mean(train_loss) + np.std(train_loss)\n",
        "print(\"Threshold: \", threshold)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEGlA1Be50Nj"
      },
      "source": [
        "Примечание. Существуют и другие стратегии, которые вы можете использовать для выбора порогового значения для определения аномалий. Правильный подход будет зависеть от вашего набора данных. Вы можете узнать больше по ссылкам в конце этого руководства."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpLSDAeb51D_"
      },
      "source": [
        "Если вы исследуете ошибку реконструкции для аномальных примеров, вы заметите, что большинство из них имеют бОльшую ошибку реконструкции, чем пороговое значение. Изменяя порог, вы можете настроить [precision](https://developers.google.com/machine-learning/glossary#precision) и [recall] (https://developers.google.com/machine-learning/glossary#recall) вашего классификатора."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sKVwjQK955Wy"
      },
      "outputs": [],
      "source": [
        "reconstructions = autoencoder.predict(anomalous_test_data)\n",
        "test_loss = tf.keras.losses.mae(reconstructions, anomalous_test_data)\n",
        "\n",
        "plt.hist(test_loss, bins=50)\n",
        "plt.xlabel(\"Test loss\")\n",
        "plt.ylabel(\"No of examples\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFVk_XGE6AX2"
      },
      "source": [
        "Классифицируйте ЭКГ как аномалию, если ошибка восстановления превышает пороговое значение."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mkgJZfhh6CHr"
      },
      "outputs": [],
      "source": [
        "def predict(model, data, threshold):\n",
        "  reconstructions = model(data)\n",
        "  loss = tf.keras.losses.mae(reconstructions, data)\n",
        "  return tf.math.less(loss, threshold)\n",
        "\n",
        "def print_stats(predictions, labels):\n",
        "  print(\"Accuracy = {}\".format(accuracy_score(labels, preds)))\n",
        "  print(\"Precision = {}\".format(precision_score(labels, preds)))\n",
        "  print(\"Recall = {}\".format(recall_score(labels, preds)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sOcfXfXq6FBd"
      },
      "outputs": [],
      "source": [
        "preds = predict(autoencoder, test_data, threshold)\n",
        "print_stats(preds, test_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrJRef8Ln945"
      },
      "source": [
        "## Следующие шаги\n",
        "\n",
        "Чтобы узнать больше об обнаружении аномалий с помощью автоэнкодеров, ознакомьтесь с этим прекрасным [интерактивным примером](https://anomagram.fastforwardlabs.com/#/), созданным Victor Dibia с помощью TensorFlow.js. \n",
        "Для практического использования вы можете узнать, как [Airbus обнаруживает аномалии в данных телеметрии МКС](https://blog.tensorflow.org/2020/04/how-airbus-detects-anomalies-iss-telemetry-data- tfx.html) с помощью TensorFlow. \n",
        "Чтобы узнать больше об основах, прочтите это [сообщение в блоге](https://blog.keras.io/building-autoencoders-in-keras.html) François Chollet. \n",
        "Для получения дополнительной информации ознакомьтесь с главой 14 из [Deep Learning](https://www.deeplearningbook.org/) Ian Goodfellow, Yoshua Bengio и Aaron Courville."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "autoencoder.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
