{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7765UFHoyGx6"
      },
      "source": [
        "##### Copyright 2019 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "KVtTDrUNyL7x"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0_fqL3ayLHX"
      },
      "source": [
        "# Gradient Boosted Trees: Понимание модели"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PS6_yKSoyLAl"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/estimator/boosted_trees_model_understanding\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />Смотреть на TensorFlow.org</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/community/site/ru/tutorials/estimator/boosted_trees_model_understanding.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Запустить в Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/community/site/ru/tutorials/estimator/boosted_trees_model_understanding.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />Смотреть исходные файлы на GitHub</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/ru/tutorials/estimator/boosted_trees_model_understanding.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Скачать ноутбук</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8a2322303a3f"
      },
      "source": [
        "Note: Вся информация в этом разделе переведена с помощью русскоговорящего Tensorflow сообщества на общественных началах. Поскольку этот перевод не является официальным, мы не гарантируем что он на 100% аккуратен и соответствует [официальной документации на английском языке](https://www.tensorflow.org/?hl=en). Если у вас есть предложение как исправить этот перевод, мы будем очень рады увидеть pull request в [tensorflow/docs](https://github.com/tensorflow/docs) репозиторий GitHub. Если вы хотите помочь сделать документацию по Tensorflow лучше (сделать сам перевод или проверить перевод подготовленный кем-то другим), напишите нам на [docs-ru@tensorflow.org list](https://groups.google.com/a/tensorflow.org/forum/#!forum/docs-ru)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dW3r7qVxzqN5"
      },
      "source": [
        "Для получения полного пошагового руководства по обучению модели градиентного бустинга обратитесь к [учебному пособию по решающим деревьям](./boosted_trees). В этом уроке вы:\n",
        "\n",
        "* Узнаете, как интерпретировать модель Boosted Trees *локально* и *глобально*\n",
        "* Получите представление о том, как модель Boosted Trees обучается на наборе данных\n",
        "\n",
        "## Как интерпретировать модели Boosted Trees локально и глобально\n",
        "\n",
        "Локальная интерпретируемость относится к пониманию предсказаний модели на уровне отдельного примера, а глобальная интерпретируемость относится к пониманию модели в целом. Такие методы могут помочь специалистам, практикующим машинное обучение(ML), обнаруживать необъективность модели и ошибки на этапе разработки модели.\n",
        "\n",
        "Для обеспечения локальной интерпретируемости вы узнаете, как создавать и визуализировать взнос каждого экземпляра модели. Чтобы отличить это от важности признаков, мы называем эти значения направленным вкладом признаков(DFC).\n",
        "\n",
        "Для глобальной интерпретируемости вы будете извлекать и визуализировать значения признаков на основе усиления, [изменение важности признаков](https://www.stat.berkeley.edu/~breiman/randomforest2001.pdf), а также показывать агрегированные DFC."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eylrTPAN3rJV"
      },
      "source": [
        "## Загрузка датасета Титаник\n",
        "Вы будете использовать набор данных пассажиров Титаника, цель которого(довольно болезненная) - предсказать выживаемость пассажиров с учетом таких характеристик, как пол, возраст, класс и т.д."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "132V3PZ8V8VA"
      },
      "outputs": [],
      "source": [
        "!pip install statsmodels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KuhAiPfZ3rJW"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from IPython.display import clear_output\n",
        "\n",
        "# Загружаем датасет.\n",
        "dftrain = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/train.csv')\n",
        "dfeval = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/eval.csv')\n",
        "y_train = dftrain.pop('survived')\n",
        "y_eval = dfeval.pop('survived')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sp1ShjJJeyH3"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "tf.random.set_seed(123)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ioodHdVJVdA"
      },
      "source": [
        "Описание признаков см. в предыдущем руководстве."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krkRHuMp3rJn"
      },
      "source": [
        "## Создание столбцов признаков, функции input_fn, и обучение оценщика"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JiJ6K3hr1lXW"
      },
      "source": [
        "### Подготовка данных"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udMytRJC05oW"
      },
      "source": [
        "Создайте столбцы признаков, используя исходные числовые столбцы как есть, а категориальные признаки преобразуйте  в one-hot-encoding столбцы."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "upaNWxcF3rJn"
      },
      "outputs": [],
      "source": [
        "fc = tf.feature_column\n",
        "CATEGORICAL_COLUMNS = ['sex', 'n_siblings_spouses', 'parch', 'class', 'deck',\n",
        "                       'embark_town', 'alone']\n",
        "NUMERIC_COLUMNS = ['age', 'fare']\n",
        "\n",
        "def one_hot_cat_column(feature_name, vocab):\n",
        "  return fc.indicator_column(\n",
        "      fc.categorical_column_with_vocabulary_list(feature_name,\n",
        "                                                 vocab))\n",
        "feature_columns = []\n",
        "for feature_name in CATEGORICAL_COLUMNS:\n",
        "  # Нужно перобразовать категориальные признаки в числовые с помощью `one-hot-encoding` метода.\n",
        "  vocabulary = dftrain[feature_name].unique()\n",
        "  feature_columns.append(one_hot_cat_column(feature_name, vocabulary))\n",
        "\n",
        "for feature_name in NUMERIC_COLUMNS:\n",
        "  feature_columns.append(fc.numeric_column(feature_name,\n",
        "                                           dtype=tf.float32))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rTefnXe1n0v"
      },
      "source": [
        "### Создание входного конвейера"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-UOlROp33rJo"
      },
      "source": [
        "Создайте функции ввода, используя метод from_tensor_slices из [`tf.data`](https://www.tensorflow.org/api_docs/python/tf/data) для чтения данных непосредственно из Pandas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9dquwCQB3rJp"
      },
      "outputs": [],
      "source": [
        "# Используйте весь пакет, так как это небольшой набор данных.\n",
        "NUM_EXAMPLES = len(y_train)\n",
        "\n",
        "def make_input_fn(X, y, n_epochs=None, shuffle=True):\n",
        "  def input_fn():\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((X.to_dict(orient='list'), y))\n",
        "    if shuffle:\n",
        "      dataset = dataset.shuffle(NUM_EXAMPLES)\n",
        "    # Для обучения повторите набор данных столько раз, сколько потребуется(n_epochs = None).\n",
        "    dataset = (dataset\n",
        "      .repeat(n_epochs)\n",
        "      .batch(NUM_EXAMPLES))\n",
        "    return dataset\n",
        "  return input_fn\n",
        "\n",
        "# Функции ввода для обучения и оценки.\n",
        "train_input_fn = make_input_fn(dftrain, y_train)\n",
        "eval_input_fn = make_input_fn(dfeval, y_eval, shuffle=False, n_epochs=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HttfNNlN3rJr"
      },
      "source": [
        "### Обучение модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tgEzMtlw3rJu"
      },
      "outputs": [],
      "source": [
        "params = {\n",
        "  'n_trees': 50,\n",
        "  'max_depth': 3,\n",
        "  'n_batches_per_layer': 1,\n",
        "  # Вы должны установить center_bias=True для получения DFC. \n",
        "  # Это заставит модель сделать первоначальный прогноз перед использованием \n",
        "  # каких-либо признаков (например, использовать среднее значение меток для регрессии,\n",
        "  # или логарифм перевесов для классификации при использовании кросс-энтропийной ф-ции потерь).\n",
        "  'center_bias': True\n",
        "}\n",
        "\n",
        "est = tf.estimator.BoostedTreesClassifier(feature_columns, **params)\n",
        "# Обучение модели\n",
        "est.train(train_input_fn, max_steps=100)\n",
        "\n",
        "# Оценка.\n",
        "results = est.evaluate(eval_input_fn)\n",
        "clear_output()\n",
        "pd.Series(results).to_frame()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgAz3jDa_tRA"
      },
      "source": [
        "Для улучшения производительности, если ваши данные умещаются в памяти, мы рекомендуем использовать функцию `boosted_trees_classifier_train_in_memory`. Однако, если время обучения не имеет значения или если у вас очень большой набор данных и вы хотите проводить распределенное обучение, используйте `tf.estimator.BoostedTrees`, показанный выше.\n",
        "При использовании этого метода не следует разделять на пакеты входные данные, поскольку метод работает со всем набором данных."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y7ztzoSk_vjY"
      },
      "outputs": [],
      "source": [
        "in_memory_params = dict(params)\n",
        "in_memory_params['n_batches_per_layer'] = 1\n",
        "# Ин-мемори input_fn не использует пакеты\n",
        "def make_inmemory_train_input_fn(X, y):\n",
        "  y = np.expand_dims(y, axis=1)\n",
        "  def input_fn():\n",
        "    return dict(X), y\n",
        "  return input_fn\n",
        "train_input_fn = make_inmemory_train_input_fn(dftrain, y_train)\n",
        "\n",
        "# Обучение модели\n",
        "est = tf.estimator.BoostedTreesClassifier(\n",
        "    feature_columns, \n",
        "    train_in_memory=True, \n",
        "    **in_memory_params)\n",
        "\n",
        "est.train(train_input_fn)\n",
        "print(est.evaluate(eval_input_fn))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSZYqNcRuczV"
      },
      "source": [
        "## Интерпритация модели и графики"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BjcfLiI3uczW"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns_colors = sns.color_palette('colorblind')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywTtbBvBuczY"
      },
      "source": [
        "## Локальная интерпритация\n",
        "Далее вы выведете DFC для объяснения индивидуальных прогнозов, используя подход, описанный в [Palczewska et al](https://arxiv.org/pdf/1312.1121.pdf) и Saabas в [Интерпретация случайных лесов]( http://blog.datadive.net/interpreting-random-forests/) (этот метод также доступен в scikit-learn для Random Forests в пакете [`treeinterpreter`](https://github.com/andosa/treeinterpreter)). \n",
        "DFC создаются с помощью:\n",
        "\n",
        "`pred_dicts = list (est.experimental_predict_with_explanations (pred_input_fn))`\n",
        "\n",
        "(Примечание: этот метод называется экспериментальным, поэтому стоит учитывать, что мы можем изменить API перед удалением экспериментального префикса.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TIL93B4sDRqE"
      },
      "outputs": [],
      "source": [
        "pred_dicts = list(est.experimental_predict_with_explanations(eval_input_fn))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tDPoRx_ZaY1E"
      },
      "outputs": [],
      "source": [
        "# Создадим DFC Pandas датафрейм.\n",
        "labels = y_eval.values\n",
        "probs = pd.Series([pred['probabilities'][1] for pred in pred_dicts])\n",
        "df_dfc = pd.DataFrame([pred['dfc'] for pred in pred_dicts])\n",
        "df_dfc.describe().T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUKSaVoraY1C"
      },
      "source": [
        "Хорошим свойством DFC является то, что сумма величин признаков + смещение равна предсказанию для данного примера."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hd9VuizRaY1H"
      },
      "outputs": [],
      "source": [
        "# сумма DFCs + bias == прогноз.\n",
        "bias = pred_dicts[0]['bias']\n",
        "dfc_prob = df_dfc.sum(axis=1) + bias\n",
        "np.testing.assert_almost_equal(dfc_prob.values,\n",
        "                               probs.values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tx5p4vEhuczg"
      },
      "source": [
        "Постройте DFC для отдельного пассажира. Давайте раскрасим график с помощью цветовой кодировки на основе DFC и добавим значения характеристик на рисунке."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6z_Tq1Pquczj"
      },
      "outputs": [],
      "source": [
        "# Код построения графика\n",
        "def _get_color(value):\n",
        "    \"\"\"To make positive DFCs plot green, negative DFCs plot red.\"\"\"\n",
        "    green, red = sns.color_palette()[2:4]\n",
        "    if value >= 0: return green\n",
        "    return red\n",
        "\n",
        "def _add_feature_values(feature_values, ax):\n",
        "    \"\"\"Display feature's values on left of plot.\"\"\"\n",
        "    x_coord = ax.get_xlim()[0]\n",
        "    OFFSET = 0.15\n",
        "    for y_coord, (feat_name, feat_val) in enumerate(feature_values.items()):\n",
        "        t = plt.text(x_coord, y_coord - OFFSET, '{}'.format(feat_val), size=12)\n",
        "        t.set_bbox(dict(facecolor='white', alpha=0.5))\n",
        "    from matplotlib.font_manager import FontProperties\n",
        "    font = FontProperties()\n",
        "    font.set_weight('bold')\n",
        "    t = plt.text(x_coord, y_coord + 1 - OFFSET, 'feature\\nvalue',\n",
        "    fontproperties=font, size=12)\n",
        "\n",
        "def plot_example(example):\n",
        "  TOP_N = 8 # Покажем топ 8 признаков.\n",
        "  sorted_ix = example.abs().sort_values()[-TOP_N:].index  # Сортируем по величине.\n",
        "  example = example[sorted_ix]\n",
        "  colors = example.map(_get_color).tolist()\n",
        "  ax = example.to_frame().plot(kind='barh',\n",
        "                          color=[colors],\n",
        "                          legend=None,\n",
        "                          alpha=0.75,\n",
        "                          figsize=(10,6))\n",
        "  ax.grid(False, axis='y')\n",
        "  ax.set_yticklabels(ax.get_yticklabels(), size=14)\n",
        "\n",
        "  # Добавим значение признаков.\n",
        "  _add_feature_values(dfeval.iloc[ID][sorted_ix], ax)\n",
        "  return ax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ht1P2-1euczk"
      },
      "outputs": [],
      "source": [
        "# График.\n",
        "ID = 182\n",
        "example = df_dfc.iloc[ID]  # Выбираем i-й пример из оценочного датасета.\n",
        "TOP_N = 8  # Показываем топ 8 признаков.\n",
        "sorted_ix = example.abs().sort_values()[-TOP_N:].index\n",
        "ax = plot_example(example)\n",
        "ax.set_title('Feature contributions for example {}\\n pred: {:1.2f}; label: {}'.format(ID, probs[ID], labels[ID]))\n",
        "ax.set_xlabel('Contribution to predicted probability', size=14)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPXgWyFcfzAc"
      },
      "source": [
        "Значения большей величины имеют большее влияние на предсказание модели. Отрицательные значения указывают на то, что значение функции для данного примера уменьшило прогноз модели, а положительные значения способствуют увеличению прогноза"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0swvlkZFaY1Z"
      },
      "source": [
        "Вы также можете построить график сравнения примеров DFC со всем распределением, используя график `voilin`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zo7rNd1v_5e2"
      },
      "outputs": [],
      "source": [
        "# Код построения графика.\n",
        "def dist_violin_plot(df_dfc, ID):\n",
        "  # Инициализируем объект графика.\n",
        "  fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
        "\n",
        "  # Создаем пример датафрейма.\n",
        "  TOP_N = 8  # Показываем топ 8 признаков.\n",
        "  example = df_dfc.iloc[ID]\n",
        "  ix = example.abs().sort_values()[-TOP_N:].index\n",
        "  example = example[ix]\n",
        "  example_df = example.to_frame(name='dfc')\n",
        "\n",
        "  # Добавляем величины полного распределния.\n",
        "  parts=ax.violinplot([df_dfc[w] for w in ix],\n",
        "                 vert=False,\n",
        "                 showextrema=False,\n",
        "                 widths=0.7,\n",
        "                 positions=np.arange(len(ix)))\n",
        "  face_color = sns_colors[0]\n",
        "  alpha = 0.15\n",
        "  for pc in parts['bodies']:\n",
        "      pc.set_facecolor(face_color)\n",
        "      pc.set_alpha(alpha)\n",
        "\n",
        "  # Добавляем значения признаков.\n",
        "  _add_feature_values(dfeval.iloc[ID][sorted_ix], ax)\n",
        "\n",
        "  # Добавляем локальные вклады.\n",
        "  ax.scatter(example,\n",
        "              np.arange(example.shape[0]),\n",
        "              color=sns.color_palette()[2],\n",
        "              s=100,\n",
        "              marker=\"s\",\n",
        "              label='contributions for example')\n",
        "\n",
        "  # Разметка\n",
        "  ax.plot([0,0], [1,1], label='eval set contributions\\ndistributions',\n",
        "          color=face_color, alpha=alpha, linewidth=10)\n",
        "  legend = ax.legend(loc='lower right', shadow=True, fontsize='x-large',\n",
        "                     frameon=True)\n",
        "  legend.get_frame().set_facecolor('white')\n",
        "\n",
        "  # Форматируем график.\n",
        "  ax.set_yticks(np.arange(example.shape[0]))\n",
        "  ax.set_yticklabels(example.index)\n",
        "  ax.grid(False, axis='y')\n",
        "  ax.set_xlabel('Contribution to predicted probability', size=14)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PiLw2tlm_9aK"
      },
      "source": [
        "Отрисуем график этого примера"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VkCqraA2uczm"
      },
      "outputs": [],
      "source": [
        "dist_violin_plot(df_dfc, ID)\n",
        "plt.title('Feature contributions for example {}\\n pred: {:1.2f}; label: {}'.format(ID, probs[ID], labels[ID]))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVJFM85SAWVq"
      },
      "source": [
        "Наконец, сторонние инструменты, такие как [LIME](https://github.com/marcotcr/lime) и [shap](https://github.com/slundberg/shap), также могут помочь понять индивидуальные прогнозы для модели."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PnNXH6mZuczr"
      },
      "source": [
        "## Глобальная важность признаков\n",
        "\n",
        "Кроме того, вы можете захотеть понять модель в целом, а не изучать отдельные прогнозы. Ниже вы будете вычислять и использовать:\n",
        "\n",
        "* Важность признаков на основании их силы влияния на прогноз с использованием `est.experimental_feature_importances`\n",
        "* Важность перестановок\n",
        "* Агрегировать DFC с помощью `est.experimental_predict_with_explanations`\n",
        "\n",
        "Важность признаков на основе силы влияния измеряет изменение потерь при разделении на конкретный объект, в то время как важность перестановки признаков вычисляется путем оценки производительности модели при оценке, установленной путем перестановки каждого признака по одному и приписывания изменения эффективности модели с перемешанным признаком.\n",
        "\n",
        "В целом, важность перестановки признаков предпочтительнее важности признаков на основании усиления, хотя оба метода могут быть ненадежными в ситуациях, когда прогнозируемые переменные различаются по шкале измерения или количеству категорий, а также когда признаки коррелированы ([источник](https://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-9-307)). Прочтите [эту статью](http://explained.ai/rf-importance/index.html), чтобы получить подробный обзор и подробное обсуждение различных типов важности признаков."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ocBcMatuczs"
      },
      "source": [
        "### Выжность признаков на основании усиления"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMaxCgPbBJ-j"
      },
      "source": [
        "Важность признаков на основе усиления встроена в оценщик TensorFlow Boosted Trees с помощью метода `est.experimental_feature_importances`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pPTxbAaeuczt"
      },
      "outputs": [],
      "source": [
        "importances = est.experimental_feature_importances(normalize=True)\n",
        "df_imp = pd.Series(importances)\n",
        "\n",
        "# Визуализируем важность признаков.\n",
        "N = 8\n",
        "ax = (df_imp.iloc[0:N][::-1]\n",
        "    .plot(kind='barh',\n",
        "          color=sns_colors[0],\n",
        "          title='Gain feature importances',\n",
        "          figsize=(10, 6)))\n",
        "ax.grid(False, axis='y')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GvfAcBeGuczw"
      },
      "source": [
        "### Средние абсолютные значения DFC\n",
        "Вы также можете усреднить абсолютные значения DFC, чтобы понять влияние на глобальном уровне."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JkvAWLWLuczx"
      },
      "outputs": [],
      "source": [
        "# График.\n",
        "dfc_mean = df_dfc.abs().mean()\n",
        "N = 8\n",
        "sorted_ix = dfc_mean.abs().sort_values()[-N:].index  # Среднее значение и сортировка по абсолютному значению.\n",
        "ax = dfc_mean[sorted_ix].plot(kind='barh',\n",
        "                       color=sns_colors[1],\n",
        "                       title='Mean |directional feature contributions|',\n",
        "                       figsize=(10, 6))\n",
        "ax.grid(False, axis='y')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0k_DvPLaY1o"
      },
      "source": [
        "Вы также можете увидеть, как DFC меняются в зависимости от значения признака."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZcIfN1IpaY1o"
      },
      "outputs": [],
      "source": [
        "FEATURE = 'fare'\n",
        "feature = pd.Series(df_dfc[FEATURE].values, index=dfeval[FEATURE].values).sort_index()\n",
        "ax = sns.regplot(feature.index.values, feature.values, lowess=True)\n",
        "ax.set_ylabel('contribution')\n",
        "ax.set_xlabel(FEATURE)\n",
        "ax.set_xlim(0, 100)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbpG72ULucz0"
      },
      "source": [
        "### Permutation feature importance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6esOw1VOucz0"
      },
      "outputs": [],
      "source": [
        "def permutation_importances(est, X_eval, y_eval, metric, features):\n",
        "    \"\"\"Столбец за столбцом, перемешивайте значения и наблюдайте \n",
        "    за влиянием на проверочный датасет.\n",
        "    source: http://explained.ai/rf-importance/index.html\n",
        "    Подобный подход можно проделать и во время тренировки. \n",
        "    См. \"Важность выпадающего столбца\" в статье выше.\"\"\"\n",
        "    baseline = metric(est, X_eval, y_eval)\n",
        "    imp = []\n",
        "    for col in features:\n",
        "        save = X_eval[col].copy()\n",
        "        X_eval[col] = np.random.permutation(X_eval[col])\n",
        "        m = metric(est, X_eval, y_eval)\n",
        "        X_eval[col] = save\n",
        "        imp.append(baseline - m)\n",
        "    return np.array(imp)\n",
        "\n",
        "def accuracy_metric(est, X, y):\n",
        "    \"\"\"Точность оценки TensorFlow.\"\"\"\n",
        "    eval_input_fn = make_input_fn(X,\n",
        "                                  y=y,\n",
        "                                  shuffle=False,\n",
        "                                  n_epochs=1)\n",
        "    return est.evaluate(input_fn=eval_input_fn)['accuracy']\n",
        "features = CATEGORICAL_COLUMNS + NUMERIC_COLUMNS\n",
        "importances = permutation_importances(est, dfeval, y_eval, accuracy_metric,\n",
        "                                      features)\n",
        "df_imp = pd.Series(importances, index=features)\n",
        "\n",
        "sorted_ix = df_imp.abs().sort_values().index\n",
        "ax = df_imp[sorted_ix][-5:].plot(kind='barh', color=sns_colors[2], figsize=(10, 6))\n",
        "ax.grid(False, axis='y')\n",
        "ax.set_title('Permutation feature importance')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E236y3pVEzHg"
      },
      "source": [
        "## Визуализация настройки модели"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TrcQ-839EzZ6"
      },
      "source": [
        "Давайте сначала смоделируем/создадим данные обучения, используя следующую формулу:\n",
        "\n",
        "\n",
        "$$z=x* e^{-x^2 - y^2}$$\n",
        "\n",
        "\n",
        "Где \\(z\\) - зависимая переменная, которую вы пытаетесь предсказать, а \\(x\\) и \\(y\\) - признаки."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e8woaj81GGE9"
      },
      "outputs": [],
      "source": [
        "from numpy.random import uniform, seed\n",
        "from scipy.interpolate import griddata\n",
        "\n",
        "# Создаем ненастоящие данные\n",
        "seed(0)\n",
        "npts = 5000\n",
        "x = uniform(-2, 2, npts)\n",
        "y = uniform(-2, 2, npts)\n",
        "z = x*np.exp(-x**2 - y**2)\n",
        "xy = np.zeros((2,np.size(x)))\n",
        "xy[0] = x\n",
        "xy[1] = y\n",
        "xy = xy.T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GRI3KHfLZsGP"
      },
      "outputs": [],
      "source": [
        "# Подготавливаем данные для обучения.\n",
        "df = pd.DataFrame({'x': x, 'y': y, 'z': z})\n",
        "\n",
        "xi = np.linspace(-2.0, 2.0, 200),\n",
        "yi = np.linspace(-2.1, 2.1, 210),\n",
        "xi,yi = np.meshgrid(xi, yi)\n",
        "\n",
        "df_predict = pd.DataFrame({\n",
        "    'x' : xi.flatten(),\n",
        "    'y' : yi.flatten(),\n",
        "})\n",
        "predict_shape = xi.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w0JnH4IhZuAb"
      },
      "outputs": [],
      "source": [
        "def plot_contour(x, y, z, **kwargs):\n",
        "  # Сетка данных.\n",
        "  plt.figure(figsize=(10, 8))\n",
        "  # Рисуем контур данных с координатной сеткой, отмечая точками неоднородные точки данных.\n",
        "  CS = plt.contour(x, y, z, 15, linewidths=0.5, colors='k')\n",
        "  CS = plt.contourf(x, y, z, 15,\n",
        "                    vmax=abs(zi).max(), vmin=-abs(zi).max(), cmap='RdBu_r')\n",
        "  plt.colorbar()  # Рисуем цветовую панель.\n",
        "  # Рисуем точки данных.\n",
        "  plt.xlim(-2, 2)\n",
        "  plt.ylim(-2, 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KF7WsIcYGF_E"
      },
      "source": [
        "Вы можете визуализировать функцию. Более темные красные цвета соответствуют бОльшим значениям функции."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WrxuqaaXGFOK"
      },
      "outputs": [],
      "source": [
        "zi = griddata(xy, z, (xi, yi), method='linear', fill_value='0')\n",
        "plot_contour(xi, yi, zi)\n",
        "plt.scatter(df.x, df.y, marker='.')\n",
        "plt.title('Contour on training data')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hoANr0f2GFrM"
      },
      "outputs": [],
      "source": [
        "fc = [tf.feature_column.numeric_column('x'),\n",
        "      tf.feature_column.numeric_column('y')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xVRWyoY3ayTK"
      },
      "outputs": [],
      "source": [
        "def predict(est):\n",
        "  \"\"\"Прогнозы переданного оценщика.\"\"\"\n",
        "  predict_input_fn = lambda: tf.data.Dataset.from_tensors(dict(df_predict))\n",
        "  preds = np.array([p['predictions'][0] for p in est.predict(predict_input_fn)])\n",
        "  return preds.reshape(predict_shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyPu5618GU7K"
      },
      "source": [
        "Сначала давайте попробуем настроить на данные линейную модель."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zUIV2IVgGVSk"
      },
      "outputs": [],
      "source": [
        "train_input_fn = make_input_fn(df, df.z)\n",
        "est = tf.estimator.LinearRegressor(fc)\n",
        "est.train(train_input_fn, max_steps=500);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_u4WAcCqfbco"
      },
      "outputs": [],
      "source": [
        "plot_contour(xi, yi, predict(est))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XD_fMAUtSCSa"
      },
      "source": [
        "Не очень хорошая настройка. Давайте попробуем модель GBDT и постараемся понять, насколько эта модель соответствует функции."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-dHlKFlFgHDQ"
      },
      "outputs": [],
      "source": [
        "n_trees = 37 #@param {type: \"slider\", min: 1, max: 80, step: 1}\n",
        "\n",
        "est = tf.estimator.BoostedTreesRegressor(fc, n_batches_per_layer=1, n_trees=n_trees)\n",
        "est.train(train_input_fn, max_steps=500)\n",
        "clear_output()\n",
        "plot_contour(xi, yi, predict(est))\n",
        "plt.text(-1.8, 2.1, '# trees: {}'.format(n_trees), color='w', backgroundcolor='black', size=20)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WcZ9fubh1wT"
      },
      "source": [
        "По мере увеличения количества деревьев прогнозы модели лучше аппроксимируют базовую функцию."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cj8u3NCG-IKX"
      },
      "source": [
        "![](https://www.tensorflow.org/images/boosted_trees/boosted_trees_ntrees.gif)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMKoEZnCdrsp"
      },
      "source": [
        "## Заключение"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSZUSrjXdw9g"
      },
      "source": [
        "В этом руководстве вы узнали, как интерпретировать модели Boosted Trees с использованием DFC и методов важности признаков. Эти методы позволяют понять, как и какие признаки влияют на прогнозы модели. Наконец, вы также получили представление о том, как модель Boosted Tree соответствует сложной функции, просмотрев результаты решений для нескольких моделей."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "boosted_trees_model_understanding.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
