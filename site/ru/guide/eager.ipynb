{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCQY7jpBfMur"
      },
      "source": [
        "##### Copyright 2018 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "z6X9omPnfO_h"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QQJJyDzqGRb"
      },
      "source": [
        "# Eager execution\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1xdylywqUSX"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/guide/eager\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />Смотрите на TensorFlow.org</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/ru/guide/eager.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Запустите в Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/ru/guide/eager.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />Изучайте код на GitHub</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/ru/guide/eager.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Скачайте ноутбук</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGjDcGxIqEfX"
      },
      "source": [
        "TensorFlow eager execution —— это императивная программная среда, которая\n",
        "вычисляет операции немедленно, без построения графов: операции возвращают\n",
        "конкретные значения вместо построения вычислительного графа для последующего запуска. Это\n",
        "облегчает начало работы с TensorFlow и отладкой моделей, а также\n",
        "шаблонный код. Чтобы следовать этому руководству, выполните приведенныее ниже примеры кода\n",
        "в интерактивном интерпретаторе `python`.\n",
        "\n",
        "Eager execution —— это гибкая платформа машинного обучения для исследований и\n",
        "экспериментов, обеспечивающая:\n",
        "\n",
        "* *Интуитивный интерфейс*—Структурируйте ваш код естественным образом и используйте\n",
        "  структуры данных Python. Быстро итерируйте по небольшим моделям и данным.\n",
        "* *Более простая отладка*—Вызывайте операции напрямую, чтобы проверять работающие модели и тестируйте\n",
        "  изменения. Используйте стандартные инструменты Python для немедленных сообщений об ошибках.\n",
        "* *Естественный порядок выполнения*—Используйте порядок выполнения Python вместо порядка выполнения\n",
        "  графа, упрощая спецификации динамических моделей.\n",
        "\n",
        "Eager execution поддерживает большинство операций TensorFlow и акселерацию GPU.\n",
        "\n",
        "Замечание: Некоторые модели могут испытывать повышенную нагрузку при включенном eager\n",
        "execution. Мы продолжаем работать над улучшением производительности, но пожалуйста\n",
        "[сообщите об ошибке](https://github.com/tensorflow/tensorflow/issues) если вы обнаружите\n",
        "проблему и поделитесь своим бенчмарком."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBAeIwOMrYk8"
      },
      "source": [
        "## Установка и базовое использование"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ByNsp4VqqEfa"
      },
      "outputs": [],
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import os\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version существует только в Colab.\n",
        "  %tensorflow_version 2.x  #gpu\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "\n",
        "import cProfile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48P3-8q4qEfe"
      },
      "source": [
        "В Tensorflow 2.0, eager execution включено по умолчанию."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7aFsD8csqEff"
      },
      "outputs": [],
      "source": [
        "tf.executing_eagerly()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_G1zZT5qEfh"
      },
      "source": [
        "Сейчас вы можете запускать операции TensorFlow и получать результаты немедленно:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9gsI54pbqEfj"
      },
      "outputs": [],
      "source": [
        "x = [[2.]]\n",
        "m = tf.matmul(x, x)\n",
        "print(\"hello, {}\".format(m))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajFn6qsdqEfl"
      },
      "source": [
        "Включение eager execution меняет поведение операций TensorFlow—сейчас они\n",
        "немедленно выполняются и возвращают свои значения в Python. Объекты `tf.Tensor`\n",
        "ссылаются на конкретные значения вместо символьных дескрипторов на узлы в вычислительном\n",
        "графе. Так как нет вычислительного графа, который нужно построить и выполнить позже\n",
        "в сессии, легко можно проверить результаты используя `print()` или отладчик. Оценка,\n",
        "печать, и проверка значений тензора не нарушают последовательность вычислений\n",
        "градиентов.\n",
        "\n",
        "Eager execution прекрасно работает с [NumPy](http://www.numpy.org/). Операции NumPy\n",
        "принимают аргументы `tf.Tensor`. Операция TensorFlow\n",
        "`tf.math` конвертирует\n",
        "объекты Python и массивы NumPy в объекты `tf.Tensor`. Метод\n",
        "`tf.Tensor.numpy` возвращает значение объекта в виде NumPy `ndarray`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sTO0_5TYqz1n"
      },
      "outputs": [],
      "source": [
        "a = tf.constant([[1, 2],\n",
        "                 [3, 4]])\n",
        "print(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dp14YT8Gq4r1"
      },
      "outputs": [],
      "source": [
        "# Поддержка трансляции\n",
        "b = tf.add(a, 1)\n",
        "print(b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "69p3waMfq8cQ"
      },
      "outputs": [],
      "source": [
        "# Поддерживается перегрузка операторов\n",
        "print(a * b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ui025t1qqEfm"
      },
      "outputs": [],
      "source": [
        "# Используем операции NumPy\n",
        "import numpy as np\n",
        "\n",
        "c = np.multiply(a, b)\n",
        "print(c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tq_aFRzWrCua"
      },
      "outputs": [],
      "source": [
        "# Получение значение numpy из тензора:\n",
        "print(a.numpy())\n",
        "# => [[1 2]\n",
        "#     [3 4]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H08f9ss9qEft"
      },
      "source": [
        "## Динамический порядок выполнения\n",
        "\n",
        "Основым преимуществом eager execution является то, что все функциональныее возможности\n",
        "основного языка доступны во время выполнения модели. Поэтому, например,\n",
        "легко написать [fizzbuzz](https://en.wikipedia.org/wiki/Fizz_buzz):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0fudRMeUqEfu"
      },
      "outputs": [],
      "source": [
        "def fizzbuzz(max_num):\n",
        "  counter = tf.constant(0)\n",
        "  max_num = tf.convert_to_tensor(max_num)\n",
        "  for num in range(1, max_num.numpy()+1):\n",
        "    num = tf.constant(num)\n",
        "    if int(num % 3) == 0 and int(num % 5) == 0:\n",
        "      print('FizzBuzz')\n",
        "    elif int(num % 3) == 0:\n",
        "      print('Fizz')\n",
        "    elif int(num % 5) == 0:\n",
        "      print('Buzz')\n",
        "    else:\n",
        "      print(num.numpy())\n",
        "    counter += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P2cKknQWrJLB"
      },
      "outputs": [],
      "source": [
        "fizzbuzz(15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kA-aC3BqEfy"
      },
      "source": [
        "Здесь есть условия зависящие от значения тензора, эти значения выводятся\n",
        "во время выполнения."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8huKpuuAwICq"
      },
      "source": [
        "## Режим обучения eager training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mp2lCCZYrxHd"
      },
      "source": [
        "### Вычисление градиентов\n",
        "\n",
        "[Автоматическое дифференцирование](https://en.wikipedia.org/wiki/Automatic_differentiation)\n",
        "полезно для реализации алгоритмов машинного обучения, таких как\n",
        "[обратное распространение](https://en.wikipedia.org/wiki/Backpropagation) для обучения\n",
        "нейронных сетей. Во время eager execution, используйте `tf.GradientTape` чтобы отслеживать\n",
        "операции для последующего вычисления градиента.\n",
        "\n",
        "Вы можете использовать `tf.GradientTape` для обучения и/или вычисления градиентов в eager. Это особенно полезно для сложных тренировочных циклов.  \n",
        "\n",
        "Поскольку во время каждого вызова могут выполняться разные операции, все\n",
        "операции прямого прохода записываются на \"ленту\". Чтобы вычислить градиент, проиграйте\n",
        "ленту назад, а затем сбросьте. A Конкретный `tf.GradientTape` может вычислить\n",
        "только один градиент; последующие вызовы выдадут runtime error."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7g1yWiSXqEf-"
      },
      "outputs": [],
      "source": [
        "w = tf.Variable([[1.0]])\n",
        "with tf.GradientTape() as tape:\n",
        "  loss = w * w\n",
        "\n",
        "grad = tape.gradient(loss, w)\n",
        "print(grad)  # => tf.Tensor([[ 2.]], shape=(1, 1), dtype=float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkHs32GqweYS"
      },
      "source": [
        "### Обучение модели\n",
        "\n",
        "В следующем примере создается многослойная модель, которая классифицирует стандартные\n",
        "рукописные цифры MNIST. В примере демонстрируется оптимизатор и API слоев для построения\n",
        "обучаемых графов в среде eager execution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "38kymXZowhhz"
      },
      "outputs": [],
      "source": [
        "# Получим и отформатируем данные mnist\n",
        "(mnist_images, mnist_labels), _ = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices(\n",
        "  (tf.cast(mnist_images[...,tf.newaxis]/255, tf.float32),\n",
        "   tf.cast(mnist_labels,tf.int64)))\n",
        "dataset = dataset.shuffle(1000).batch(32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rl1K8rOowmwT"
      },
      "outputs": [],
      "source": [
        "# Построим модель\n",
        "mnist_model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Conv2D(16,[3,3], activation='relu',\n",
        "                         input_shape=(None, None, 1)),\n",
        "  tf.keras.layers.Conv2D(16,[3,3], activation='relu'),\n",
        "  tf.keras.layers.GlobalAveragePooling2D(),\n",
        "  tf.keras.layers.Dense(10)\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvyk-HgGwxwl"
      },
      "source": [
        "Даже без обучения вызовем модель и проверим выходные данные в eager execution:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BsxystjBwxLS"
      },
      "outputs": [],
      "source": [
        "for images,labels in dataset.take(1):\n",
        "  print(\"Logits: \", mnist_model(images[0:1]).numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3PGa8G7qEgB"
      },
      "source": [
        "Хотя у моделей keras есть встроенный цикл обучения (использование метода `fit`), иногда вам нужна большая кастомизация. Вот пример цикла обучения реализованного с eager:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bzRhM7JDnaEG"
      },
      "outputs": [],
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "loss_history = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXaupYXRI2YM"
      },
      "source": [
        "Замечание: Используйте функцию assert в `tf.debugging` чтобы проверить выполнение условия. Это работает в eager и graph execution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DDHrigtiCIA4"
      },
      "outputs": [],
      "source": [
        "def train_step(images, labels):\n",
        "  with tf.GradientTape() as tape:\n",
        "    logits = mnist_model(images, training=True)\n",
        "    \n",
        "    # Добавим assert-ы для проверки размеров выходных данных.\n",
        "    tf.debugging.assert_equal(logits.shape, (32, 10))\n",
        "    \n",
        "    loss_value = loss_object(labels, logits)\n",
        "\n",
        "  loss_history.append(loss_value.numpy().mean())\n",
        "  grads = tape.gradient(loss_value, mnist_model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(grads, mnist_model.trainable_variables))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0m1xAXrmqEgJ"
      },
      "outputs": [],
      "source": [
        "def train(epochs):\n",
        "  for epoch in range(epochs):\n",
        "    for (batch, (images, labels)) in enumerate(dataset):\n",
        "      train_step(images, labels)\n",
        "    print ('Epoch {} finished'.format(epoch))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C5dGz0p_nf4W"
      },
      "outputs": [],
      "source": [
        "train(epochs = 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5vG5ql_2vYB5"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(loss_history)\n",
        "plt.xlabel('Batch #')\n",
        "plt.ylabel('Loss [entropy]')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKpOlHPLqEgl"
      },
      "source": [
        "### Переменные и оптимизаторы\n",
        "\n",
        "Объекты `tf.Variable` хранят изменяемые значения типа `tf.Tensor`, доступные во время\n",
        "обучения, чтобы упростить автомматическое дифференцирование. \n",
        "\n",
        "Наборы переменных могут быть инкапсулированы в слои или модели вместе с методами которые работают на них. См. [Кастомные слои и модели Keras](./keras/custom_layers_and_models.ipynb) для подробностей. Основная разница между слоями и моделями это то, что модели имеют такие методы как  `Model.fit`, `Model.evaluate` и `Model.save`.\n",
        "\n",
        "Например приведенный выше пример автоматического дифференцирования может быть\n",
        "переписан так:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2qXcPngYk8dN"
      },
      "outputs": [],
      "source": [
        "class Linear(tf.keras.Model):\n",
        "  def __init__(self):\n",
        "    super(Linear, self).__init__()\n",
        "    self.W = tf.Variable(5., name='weight')\n",
        "    self.B = tf.Variable(10., name='bias')\n",
        "  def call(self, inputs):\n",
        "    return inputs * self.W + self.B"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nnQLBYmEqEgm"
      },
      "outputs": [],
      "source": [
        "# Игрушечный датасет точек вокруг 3 * x + 2\n",
        "NUM_EXAMPLES = 2000\n",
        "training_inputs = tf.random.normal([NUM_EXAMPLES])\n",
        "noise = tf.random.normal([NUM_EXAMPLES])\n",
        "training_outputs = training_inputs * 3 + 2 + noise\n",
        "\n",
        "# The loss function to be optimized\n",
        "def loss(model, inputs, targets):\n",
        "  error = model(inputs) - targets\n",
        "  return tf.reduce_mean(tf.square(error))\n",
        "\n",
        "def grad(model, inputs, targets):\n",
        "  with tf.GradientTape() as tape:\n",
        "    loss_value = loss(model, inputs, targets)\n",
        "  return tape.gradient(loss_value, [model.W, model.B])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7x1CDurl3IG"
      },
      "source": [
        "Далее:\n",
        "\n",
        "1. Создание модели.\n",
        "2. Производные функции потерь относительно параметров модели.\n",
        "3. Стратегия обновления переменных, основанная на производных."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SbXJk0f2lztg"
      },
      "outputs": [],
      "source": [
        "model = Linear()\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
        "\n",
        "print(\"Initial loss: {:.3f}\".format(loss(model, training_inputs, training_outputs)))\n",
        "\n",
        "steps = 300\n",
        "for i in range(steps):\n",
        "  grads = grad(model, training_inputs, training_outputs)\n",
        "  optimizer.apply_gradients(zip(grads, [model.W, model.B]))\n",
        "  if i % 20 == 0:\n",
        "    print(\"Loss at step {:03d}: {:.3f}\".format(i, loss(model, training_inputs, training_outputs)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PV_dqer7pzSH"
      },
      "outputs": [],
      "source": [
        "print(\"Final loss: {:.3f}\".format(loss(model, training_inputs, training_outputs)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rvt_Wj3Tp0hm"
      },
      "outputs": [],
      "source": [
        "print(\"W = {}, B = {}\".format(model.W.numpy(), model.B.numpy()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPjb8nRWqEgr"
      },
      "source": [
        "Примечание: Переменные хранятся до тех пор, пока не будет удалена последняя ссылка\n",
        "на объект python, после чего удалится и переменная."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scMjg6L6qEgv"
      },
      "source": [
        "### Объектно-ориентированное сохранение\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-0ZcCcjwkux"
      },
      "source": [
        "`tf.keras.Model` включает в себя удобный метод `save_weights` позволяющий вам легко создавать чекпоинт: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oJrMX94PwD9s"
      },
      "outputs": [],
      "source": [
        "model.save_weights('weights')\n",
        "status = model.load_weights('weights')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2EfTjWV_wEng"
      },
      "source": [
        "Используя `tf.train.Checkpoint` вы можете получить полный контроль над процессом.\n",
        "\n",
        "Этот раздел является сокращенной версией [руководства чекпоинтов обучения](./checkpoint.ipynb).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7z5xRfdHzZOQ"
      },
      "outputs": [],
      "source": [
        "x = tf.Variable(10.)\n",
        "checkpoint = tf.train.Checkpoint(x=x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IffrUVG7zyVb"
      },
      "outputs": [],
      "source": [
        "x.assign(2.)   # Присвоим новое значение переменной и сохраним.\n",
        "checkpoint_path = './ckpt/'\n",
        "checkpoint.save('./ckpt/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eMT9koCoqEgw"
      },
      "outputs": [],
      "source": [
        "x.assign(11.)  # Изменим переменную после сохранения.\n",
        "\n",
        "# Восстановим значения из чекпоинта\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_path))\n",
        "\n",
        "print(x)  # => 2.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbFnP-yLqEgx"
      },
      "source": [
        "Чтобы сохранять и загружать модели `tf.train.Checkpoint` хранит внутреннее состояние объектов,\n",
        "не требуя скрытых переменных. Чтобы записать состояние модели `model`,\n",
        " `optimizer` и глобальный шаг передайте их в `tf.train.Checkpoint`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hWZHyAXMqEg0"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Conv2D(16,[3,3], activation='relu'),\n",
        "  tf.keras.layers.GlobalAveragePooling2D(),\n",
        "  tf.keras.layers.Dense(10)\n",
        "])\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "checkpoint_dir = 'path/to/model_dir'\n",
        "if not os.path.exists(checkpoint_dir):\n",
        "  os.makedirs(checkpoint_dir)\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "root = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                           model=model)\n",
        "\n",
        "root.save(checkpoint_prefix)\n",
        "root.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-ITwkBCF6GJ"
      },
      "source": [
        "Примечание: Во многих обучающих циклах переменные создаются после вызова `tf.train.Checkpoint.restore`. Эти переменные будут восстановлены сразу же после создания и проверки того, что контрольная точка была загружена полностью. Подробнее см. [руководство по чекпоинтам обучения](./checkpoint.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yoD0VJ7qEg3"
      },
      "source": [
        "### Oбъектно-ориентированные метрики\n",
        "\n",
        "`tf.keras.metrics` хранятся как объекты. Обновите метрику передав новые данные в\n",
        "вызываемый объект, и получите результат, используя метод `tf.keras.metrics.result`,\n",
        "например:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ccu0iAaqEg5"
      },
      "outputs": [],
      "source": [
        "m = tf.keras.metrics.Mean(\"loss\")\n",
        "m(0)\n",
        "m(5)\n",
        "m.result()  # => 2.5\n",
        "m([8, 9])\n",
        "m.result()  # => 5.5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aB8qWtT955pI"
      },
      "source": [
        "### Сводки и TensorBoard\n",
        "\n",
        "[TensorBoard](https://tensorflow.org/tensorboard) это инструмент визуализации для\n",
        "понимания, отладки и оптимизации процесса обучения модели. Он использует\n",
        "события summary которые записываются во время работы программы.\n",
        "\n",
        "Вы можете использовать `tf.summary` чтобы писать сводку переменной в eager execution.\n",
        "Например, чтобы записать сводные данные `loss` каждые 100 шагов обучения:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z6VInqhA6RH4"
      },
      "outputs": [],
      "source": [
        "logdir = \"./tb/\"\n",
        "writer = tf.summary.create_file_writer(logdir)\n",
        "\n",
        "steps = 1000\n",
        "with writer.as_default():  # или вызовите writer.set_as_default() перед циклом.\n",
        "  for i in range(steps):\n",
        "    step = i + 1\n",
        "    # Посчитайте потери с вашей реальной функцией обучения.\n",
        "    loss = 1 - 0.001 * step\n",
        "    if step % 100 == 0:\n",
        "      tf.summary.scalar('loss', loss, step=step)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "08QQD2j36TaI"
      },
      "outputs": [],
      "source": [
        "!ls tb/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEL4yJe5qEhD"
      },
      "source": [
        "## Продвинутые техники автоматического дифференцирования\n",
        "\n",
        "### Динамические модели\n",
        "\n",
        "`tf.GradientTape` может быть также использован в динамических моделях. Это пример для\n",
        "[backtracking line search](https://wikipedia.org/wiki/Backtracking_line_search)\n",
        "несмотря на сложный порядок выполнения, алгоритм выглядит как обычный код NumPy, за исключением того, что там есть алгоритмы и дифференцирование:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L518n5dkqEhE"
      },
      "outputs": [],
      "source": [
        "def line_search_step(fn, init_x, rate=1.0):\n",
        "  with tf.GradientTape() as tape:\n",
        "    # Переменные автоматически отслеживаются.\n",
        "    # Но чтобы посчитать градиент от тензора, вам надо его `посмотреть (watch)`.\n",
        "    tape.watch(init_x)\n",
        "    value = fn(init_x)\n",
        "  grad = tape.gradient(value, init_x)\n",
        "  grad_norm = tf.reduce_sum(grad * grad)\n",
        "  init_value = value\n",
        "  while value > init_value - rate * grad_norm:\n",
        "    x = init_x - rate * grad\n",
        "    value = fn(x)\n",
        "    rate /= 2.0\n",
        "  return x, value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gieGOf_DqEhK"
      },
      "source": [
        "### Кастомные градиенты\n",
        "\n",
        "Кастомные градиенты это простой способ переписать градиенты. В функции прямого прохода, определите градиент относительно\n",
        "входных, выходных или промежуточных результатов. Например, вот легкий способ обрезать\n",
        "градиенты в обратном распространении:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-OwwsWUAqEhK"
      },
      "outputs": [],
      "source": [
        "@tf.custom_gradient\n",
        "def clip_gradient_by_norm(x, norm):\n",
        "  y = tf.identity(x)\n",
        "  def grad_fn(dresult):\n",
        "    return [tf.clip_by_norm(dresult, norm), None]\n",
        "  return y, grad_fn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPLDHkF_qEhN"
      },
      "source": [
        "Кастомные градиенты обычно используются для обеспечения численно стабильного градиента для\n",
        "последовательности операций:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "24WiLROnqEhO"
      },
      "outputs": [],
      "source": [
        "def log1pexp(x):\n",
        "  return tf.math.log(1 + tf.exp(x))\n",
        "\n",
        "def grad_log1pexp(x):\n",
        "  with tf.GradientTape() as tape:\n",
        "    tape.watch(x)\n",
        "    value = log1pexp(x)\n",
        "  return tape.gradient(value, x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n8fq69r9-B-c"
      },
      "outputs": [],
      "source": [
        "# Вычисление градиента хорошо работает при x = 0.\n",
        "grad_log1pexp(tf.constant(0.)).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_VFSU0mG-FSp"
      },
      "outputs": [],
      "source": [
        "# Однако, x = 100 терпит неудачу из-за числовой нестабильности.\n",
        "grad_log1pexp(tf.constant(100.)).numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VcTR34rqEhQ"
      },
      "source": [
        "Здесь функция `log1pexp` может быть аналитически упрощена с помощью кастомного\n",
        "градиента. Нижеприведенная реализация переиспользует значение для `tf.exp(x)` которое\n",
        "вычисляется во время прямого прохода, делая ее эффективнее за счет исключения\n",
        "избыточных вычислений:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q7nvfx_-qEhS"
      },
      "outputs": [],
      "source": [
        "@tf.custom_gradient\n",
        "def log1pexp(x):\n",
        "  e = tf.exp(x)\n",
        "  def grad(dy):\n",
        "    return dy * (1 - 1 / (1 + e))\n",
        "  return tf.math.log(1 + e), grad\n",
        "\n",
        "def grad_log1pexp(x):\n",
        "  with tf.GradientTape() as tape:\n",
        "    tape.watch(x)\n",
        "    value = log1pexp(x)\n",
        "  return tape.gradient(value, x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5gHPKMfl-Kge"
      },
      "outputs": [],
      "source": [
        "# Как и ранее вычисление градиента работает хорошо при x = 0.\n",
        "grad_log1pexp(tf.constant(0.)).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u38MOfz3-MDE"
      },
      "outputs": [],
      "source": [
        "# И вычисление градиента также работает хорошо при x = 100.\n",
        "grad_log1pexp(tf.constant(100.)).numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rnZXjfQzqEhV"
      },
      "source": [
        "## Производительность\n",
        "\n",
        "Вычисление автоматически выгружается в GPU во время eager execution. Если вы\n",
        "хотите контролировать, где выполняется вычисление, вы можете заключить его\n",
        "в блок `tf.device('/gpu:0')` (или эквивалент для CPU):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ac9Y64H-qEhX"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "def measure(x, steps):\n",
        "  # TensorFlow инициализирует GPU при первом использовании, исключим из времени.\n",
        "  tf.matmul(x, x)\n",
        "  start = time.time()\n",
        "  for i in range(steps):\n",
        "    x = tf.matmul(x, x)\n",
        "  # tf.matmul может возвращаться до завершения умножения матрицы\n",
        "  # (например, может возвращаться после включения операции в поток CUDA).\n",
        "  # Вызов x.numpy() ниже гарантирует, что все операции в очереди \n",
        "  # были завершены (и также скопирует результат в память хоста,\n",
        "  # поэтому мы включаем немного больше, чем просто время\n",
        "  # операции matmul).\n",
        "  _ = x.numpy()\n",
        "  end = time.time()\n",
        "  return end - start\n",
        "\n",
        "shape = (1000, 1000)\n",
        "steps = 200\n",
        "print(\"Время на умножение {} матрицы на себя {} раз:\".format(shape, steps))\n",
        "\n",
        "# Выполнение на CPU:\n",
        "with tf.device(\"/cpu:0\"):\n",
        "  print(\"CPU: {} secs\".format(measure(tf.random.normal(shape), steps)))\n",
        "\n",
        "# Выполнение на GPU, если возможно:\n",
        "if tf.config.experimental.list_physical_devices(\"GPU\"):\n",
        "  with tf.device(\"/gpu:0\"):\n",
        "    print(\"GPU: {} secs\".format(measure(tf.random.normal(shape), steps)))\n",
        "else:\n",
        "  print(\"GPU: не найдено\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLw3IS7UqEhe"
      },
      "source": [
        "Объект `tf.Tensor` может быть скопирован на другое устройство для выполнения\n",
        "его операции:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ny6LX2BVqEhf"
      },
      "outputs": [],
      "source": [
        "if tf.config.experimental.list_physical_devices(\"GPU\"):\n",
        "  x = tf.random.normal([10, 10])\n",
        "\n",
        "  x_gpu0 = x.gpu()\n",
        "  x_cpu = x.cpu()\n",
        "\n",
        "  _ = tf.matmul(x_cpu, x_cpu)    # Runs on CPU\n",
        "  _ = tf.matmul(x_gpu0, x_gpu0)  # Runs on GPU:0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oA_qaII3-p6c"
      },
      "source": [
        "### Бенчмарки\n",
        "\n",
        "Для сложных вычислительных моделей, таких как\n",
        "[ResNet50](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/eager/python/examples/resnet50)\n",
        "обучение на GPU, производительность eager execution сравнима с выполнением `tf.function`.\n",
        "Но разрыв становится больше для моделей с меньшим числом вычислений и необходимо проделать работу\n",
        "по оптимизации кода для моделей с большим количеством маленьких операций.\n",
        "\n",
        "## Работа с функциями\n",
        "\n",
        "Хоть eager execution делает разработку и отладку более интерактивной,\n",
        "выполнение графа в стиле TensorFlow 1.x имеет преимущества при распределенном обучении, оптимизации\n",
        "производительности и запуске в продакшн. Чтобы преодолеть этот пробел, TensorFlow 2.0 вводит `function` посредством API `tf.function`. Для дополнительной информации, см. руководство [tf.function](./function.ipynb)."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "eager.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
