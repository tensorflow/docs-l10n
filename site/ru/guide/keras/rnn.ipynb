{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rnn.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eIrvnAbGZ1wP"
      },
      "source": [
        "##### Copyright 2019 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "colab_type": "code",
        "id": "_A4IPZ-WZ9H7",
        "colab": {}
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zfiHTzhkmNwd"
      },
      "source": [
        "# Рекуррентные нейронные сети (RNN) с Keras\n",
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/guide/keras/rnn\">\n",
        "    <img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />\n",
        "    Смотрите на TensorFlow.org</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/ru/guide/keras/rnn.ipynb\">\n",
        "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />\n",
        "    Запустите в Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/ru/guide/keras/rnn.ipynb\">\n",
        "    <img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />\n",
        "    Изучайте код на GitHub</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/ru/guide/keras/rnn.ipynb\">\n",
        "    <img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />\n",
        "    Скачайте ноутбук</a>\n",
        "  </td>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jfOdaQLhXLDR"
      },
      "source": [
        "«Рекуррентные нейронные сети (RNN) - это класс нейронных сетей, которые хороши для моделирования последовательных данных, таких как временные ряды или естественный язык.\n",
        "\n",
        "Если схематично, слой RNN использует цикл `for` для итерации по упорядоченной по времени последовательности, храня при этом во внутреннем состоянии, закодированную информацию о шагах, которые он уже видел.\n",
        "\n",
        "Keras RNN API разработан с фокусом на:\n",
        "\n",
        "- **Простоту использования**: встроенные слои `tf.keras.layers.RNN`, `tf.keras.layers.LSTM`, `tf.keras.layers.GRU` позволяют вам быстро построить рекуррентные модели без необходимости делать сложные конфигурационные настройки.\n",
        "  \n",
        "- **Простота кастомизации**: Вы можете также задать собственный слой ячеек RNN (внутреннюю часть цикла `for`) с кастомным поведением и исопльзовать его с общим слоем `tf.keras.layers.RNN` (сам цикл `for`). Это позволяет вам быстро прототипировать различные исследовательские идеи в гибкой манере с минимумом кода.\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QGJH5EKYoSHZ"
      },
      "source": [
        "## Установка"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wJEBe8hTlB6W",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import collections\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DznzjxWCilt4"
      },
      "source": [
        "## Построение простой модели\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "H5tPG7KJirBj"
      },
      "source": [
        "В Keras есть три встроенных слоя RNN:\n",
        "\n",
        "1. `tf.keras.layers.SimpleRNN`, полносвязная RNN в которой выход предыдущего временного шага должен быть передан в следующий шаг.\n",
        "\n",
        "2. `tf.keras.layers.GRU`, впервые предложено в [Изучение представлений фраз с использованием кодера-декодера RNN для статистического машинного перевода](https://arxiv.org/abs/1406.1078).\n",
        "\n",
        "3. `tf.keras.layers.LSTM`, впервые предложено в [Долгая краткосрочная память](https://www.bioinf.jku.at/publications/older/2604.pdf).\n",
        "\n",
        "В начале 2015, у Keras первые переиспользуемые реализации LSTM и GRU на Python с открытым исходным кодом.\n",
        "\n",
        "Ниже пример `Sequential` модели которая обрабатывает последовательности целых чисел, вкладывая каждое целое число в 64-мерный вектор, затем обрабатывая последовательности векторов с использованием слоя `LSTM`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QHdAFEATnFpn",
        "colab": {}
      },
      "source": [
        "model = tf.keras.Sequential()\n",
        "# Добавим слой Embedding ожидая на входе словарь размера 1000,\n",
        "# и на выходе вложение размерностью 64.\n",
        "model.add(layers.Embedding(input_dim=1000, output_dim=64))\n",
        "\n",
        "# Добавим слой LSTM с 128 внутренними узлами.\n",
        "model.add(layers.LSTM(128))\n",
        "\n",
        "# Добавим слой Dense с 10 узлами и активацией softmax.\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sVT4R7O3qDXM"
      },
      "source": [
        "## Выходы и состояния"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IOQnPR9eqLwk"
      },
      "source": [
        "По умолчанию выход слоя RNN содержит один вектор на элемент. Этот вектор является выходом последней ячейки RNN, содержащей информацию обо всей входной последовательности. Размерность этого выхода `(batch_size, units)`, где `units` соответствует аргументу `units` передаваемому конструктору слоя.\n",
        "\n",
        "Слой RNN может также возвращать всю последовательность выходных данных для каждого элемента (по одному вектору на каждый шаг), если вы укажете `return_sequences=True`. Размерность этих выходных данных равна `(batch_size, timesteps, units)`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wNlkR8oXpNEx",
        "colab": {}
      },
      "source": [
        "model = tf.keras.Sequential()\n",
        "model.add(layers.Embedding(input_dim=1000, output_dim=64))\n",
        "\n",
        "# Выходом GRU будет 3D тензор размера (batch_size, timesteps, 256)\n",
        "model.add(layers.GRU(256, return_sequences=True))\n",
        "\n",
        "# Выходом SimpleRNN будет 2D тензор размера (batch_size, 128)\n",
        "model.add(layers.SimpleRNN(128))\n",
        "\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "model.summary() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1HagyjYos5rD"
      },
      "source": [
        "Кроме того, слой RNN может вернуть свое конечное внутреннее состояние(состояния). Возвращенные состояния можно использовать позже для возобновления выполнения RNN или [для инициализации другой RNN](https://arxiv.org/abs/1409.3215). Эта настройка обыно используется в модели энкодер-декодер последовательность к последовательности, где итоговое состояние энкодера используется для начального состояния декодера.\n",
        "\n",
        "Для того чтобы слой RNN возвращал свое внутреннего состояния, установите параметр 'return_state' в значение 'True' при создании слоя. Обратите внимание, что у `LSTM` 2 тензора состояния, а у `GRU` только один.\n",
        "\n",
        "Чтобы настроить начальное состояние слоя, просто вызовите слой с дополнительным аргументом `initial_state`.\n",
        "Заметьте что размерность должна совпадать с размерностью элемента слоя, как в следующем приммере."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2_HsGBrDvaea",
        "colab": {}
      },
      "source": [
        "encoder_vocab = 1000\n",
        "decoder_vocab = 2000\n",
        "\n",
        "encoder_input = layers.Input(shape=(None, ))\n",
        "encoder_embedded = layers.Embedding(input_dim=encoder_vocab, output_dim=64)(encoder_input)\n",
        "\n",
        "# Возвращает состояния в добавление к выходным данным\n",
        "output, state_h, state_c = layers.LSTM(\n",
        "    64, return_state=True, name='encoder')(encoder_embedded)\n",
        "encoder_state = [state_h, state_c]\n",
        "\n",
        "decoder_input = layers.Input(shape=(None, ))\n",
        "decoder_embedded = layers.Embedding(input_dim=decoder_vocab, output_dim=64)(decoder_input)\n",
        "\n",
        "# Передает 2 состояния в новый слой LSTM в качестве начального состояния\n",
        "decoder_output = layers.LSTM(\n",
        "    64, name='decoder')(decoder_embedded, initial_state=encoder_state)\n",
        "output = layers.Dense(10, activation='softmax')(decoder_output)\n",
        "\n",
        "model = tf.keras.Model([encoder_input, decoder_input], output)\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kJDJSXjZ2VaY"
      },
      "source": [
        "## RNN слои и RNN ячейки"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hQRxLRSS2gDf"
      },
      "source": [
        "RNN API в дополнение к встроенным слоям RNN, также предоставляет API на уровне ячейки. В отличие от слоев RNN, которые обрабатывают целые партии входных последовательностей, ячейка RNN обрабатывает только один временной шаг.\n",
        "\n",
        "Ячейка находится внутри цикла `for` слоя RNN . Оборачивание ячейки внутри слоя`tf.keras.layers.RNN` дает вам слой способный обрабатывать пакеты последовательностей, напр. `RNN(LSTMCell(10))`.\n",
        "\n",
        "Математически, `RNN(LSTMCell(10))` дает тот же результат, что и `LSTM(10)`. Фактически, реализация этого слоя внутри TF v1.x было лишь создание соответствующей RNN ячейки и оборачивание ее в слой RNN.  Однако использование встроенных слоев `GRU` и `LSTM` позволяет использовать CuDNN что может дать лучшую производительность.\n",
        "\n",
        "Существует три встроенных ячейки RNN, каждая из которых соответствует своему слою RNN.\n",
        "\n",
        "- `tf.keras.layers.SimpleRNNCell` соответствует слою `SimpleRNN`.\n",
        "\n",
        "- `tf.keras.layers.GRUCell` соответствует слою  `GRU`.\n",
        "\n",
        "- `tf.keras.layers.LSTMCell` соответствует слою `LSTM`.\n",
        "\n",
        "Абстракция ячейки вместе с общим классом `tf.keras.layers.RNN`, позволяет очень легко реализовать кастомные RNN архитектуры для ваших исследований.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "veiCKSUU-ina",
        "colab_type": "text"
      },
      "source": [
        "## Кросс-пакетное сохранение состояния"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EvAaiMJbWR2A"
      },
      "source": [
        "При обработке длинных последовательностей (возможно бесконечных), вы можете захотеть использовать паттерн **кросс-пакетное сохранение состояния (cross-batch statefulness)**.\n",
        "\n",
        "Обычно, внутреннее состояние слоя RNN сбрасывается при каждом новом пакете данных (т.е. каждый пример который видит слой предполагается независимым от прошлого). Слой будет поддерживать состояние только на время обработки данного элемента.\n",
        "\n",
        "Однако, если у вас очень длинные последовательности, полезно разбить их на более короткие и по очереди передавать их в слой RNN без сброса состояния слоя. Таким образом, слой может сохранять информацию обо всей последовательности, хотя он будет видеть только одну подпоследовательность за раз.\n",
        "\n",
        "Вы можете сделать это установив в конструкторе `stateful=True`.\n",
        "\n",
        "Если у вас есть последовательность `s = [t0, t1, ... t1546, t1547]`, вы можете разбить ее например на\n",
        "\n",
        "```\n",
        "s1 = [t0, t1, ... t100]\n",
        "s2 = [t101, ... t201]\n",
        "...\n",
        "s16 = [t1501, ... t1547]\n",
        "```\n",
        "\n",
        "Потом вы можете обработать ее с помощью:\n",
        "\n",
        "```python\n",
        "lstm_layer = layers.LSTM(64, stateful=True)\n",
        "for s in sub_sequences:\n",
        "  output = lstm_layer(s)\n",
        "```\n",
        "\n",
        "Когда вы захотите почистить состояние, используйте `layer.reset_states()`.\n",
        "\n",
        "\n",
        "> Примечание: В этом случае, предполагается что пример `i` в данном пакете является продолжением примера `i` предыдущего пакета. Это значит, что все пакеты содержат одинаковое количество элементов (размер пакета). Например, если пакет содержит `[sequence_A_from_t0_to_t100,  sequence_B_from_t0_to_t100]`, следующий пакет должен содержать `[sequence_A_from_t101_to_t200,  sequence_B_from_t101_to_t200]`.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Вот полный пример:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "E6TsLXJ0X3Xd",
        "colab": {}
      },
      "source": [
        "paragraph1 = np.random.random((20, 10, 50)).astype(np.float32)\n",
        "paragraph2 = np.random.random((20, 10, 50)).astype(np.float32)\n",
        "paragraph3 = np.random.random((20, 10, 50)).astype(np.float32)\n",
        "\n",
        "lstm_layer = layers.LSTM(64, stateful=True)\n",
        "output = lstm_layer(paragraph1)\n",
        "output = lstm_layer(paragraph2)\n",
        "output = lstm_layer(paragraph3)\n",
        "\n",
        "# reset_states() сбосит кешированное состояние до изначального initial_state.\n",
        "# Если initial_state не было задано, по умолчанию будут использованы нулевые состояния.\n",
        "lstm_layer.reset_states()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7AtPur5BDzb4"
      },
      "source": [
        "##Двунаправленные RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OsdEIXXREL_N"
      },
      "source": [
        "For sequences other than time series (e.g. text), it is often the case that a RNN model can perform better if it not only processes sequence from start to end, but also backwards. For example, to predict the next word in a sentence, it is often useful to have the context around the word, not only just the words that come before it.\n",
        "\n",
        "Keras provides an easy API for you to build such bidirectional RNNs: the `tf.keras.layers.Bidirectional` wrapper."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MNhYIAXqYl3B",
        "colab": {}
      },
      "source": [
        "model = tf.keras.Sequential()\n",
        "\n",
        "model.add(layers.Bidirectional(layers.LSTM(64, return_sequences=True), \n",
        "                               input_shape=(5, 10)))\n",
        "model.add(layers.Bidirectional(layers.LSTM(32)))\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ThwlodTjZCU0"
      },
      "source": [
        "Under the hood, `Bidirectional` will copy the RNN layer passed in, and flip the `go_backwards` field of the newly copied layer, so that it will process the inputs in reverse order.\n",
        "\n",
        "The output of the `Bidirectional` RNN will be, by default, the sum of the forward layer output and the backward layer output. If you need a different merging behavior, e.g. concatenation, change the `merge_mode` parameter in the `Bidirectional` wrapper constructor. For more details about `Bidirectional`, please check [the API docs](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/Bidirectional)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ANGN956w6FRs"
      },
      "source": [
        "## Performance optimization and CuDNN kernels in TensorFlow 2.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "76xAs7epaX21"
      },
      "source": [
        "In TensorFlow 2.0, the built-in LSTM and GRU layers have been updated to leverage CuDNN kernels by default when a GPU is available. With this change, the prior `keras.layers.CuDNNLSTM/CuDNNGRU` layers have been deprecated, and you can build your model without worrying about the hardware it will run on.\n",
        "\n",
        "Since the CuDNN kernel is built with certain assumptions, this means the layer **will not be able to use the CuDNN kernel if you change the defaults of the built-in LSTM or GRU layers**. E.g.:\n",
        "\n",
        "- Changing the `activation` function from `tanh` to something else.\n",
        "- Changing the `recurrent_activation` function from `sigmoid` to something else.\n",
        "- Using `recurrent_dropout` > 0.\n",
        "- Setting `unroll` to True, which forces LSTM/GRU to decompose the inner `tf.while_loop` into an unrolled `for` loop.\n",
        "- Setting `use_bias` to False.\n",
        "- Using masking when the input data is not strictly right padded (if the mask corresponds to strictly right padded data, CuDNN can still be used. This is the most common case).\n",
        "\n",
        "For the detailed list of constraints, please see the documentation for the [LSTM](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/LSTM) and [GRU](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/GRU) layers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ybd73JmvqLp4"
      },
      "source": [
        "### Using CuDNN kernels when available\n",
        "\n",
        "Let's build a simple LSTM model to demonstrate the performance difference.\n",
        "\n",
        "We'll use as input sequences the sequence of rows of MNIST digits (treating each row of pixels as a timestep), and we'll predict the digit's label.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "m9kM9hwRsxMx",
        "colab": {}
      },
      "source": [
        "batch_size = 64\n",
        "# Each MNIST image batch is a tensor of shape (batch_size, 28, 28).\n",
        "# Each input sequence will be of size (28, 28) (height is treated like time).\n",
        "input_dim = 28\n",
        "\n",
        "units = 64\n",
        "output_size = 10  # labels are from 0 to 9\n",
        "\n",
        "# Build the RNN model\n",
        "def build_model(allow_cudnn_kernel=True):\n",
        "  # CuDNN is only available at the layer level, and not at the cell level.\n",
        "  # This means `LSTM(units)` will use the CuDNN kernel,\n",
        "  # while RNN(LSTMCell(units)) will run on non-CuDNN kernel.\n",
        "  if allow_cudnn_kernel:\n",
        "    # The LSTM layer with default options uses CuDNN.\n",
        "    lstm_layer = tf.keras.layers.LSTM(units, input_shape=(None, input_dim))\n",
        "  else:\n",
        "    # Wrapping a LSTMCell in a RNN layer will not use CuDNN.\n",
        "    lstm_layer = tf.keras.layers.RNN(\n",
        "        tf.keras.layers.LSTMCell(units),\n",
        "        input_shape=(None, input_dim))\n",
        "  model = tf.keras.models.Sequential([\n",
        "      lstm_layer,\n",
        "      tf.keras.layers.BatchNormalization(),\n",
        "      tf.keras.layers.Dense(output_size, activation='softmax')]\n",
        "  )\n",
        "  return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uuztNezFh0BL"
      },
      "source": [
        "### Load MNIST dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "m_kZTLDobchi",
        "colab": {}
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "sample, sample_label = x_train[0], y_train[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UXF8elCuib8k"
      },
      "source": [
        "### Create a model instance and compile it\n",
        "We choose `sparse_categorical_crossentropy` as the loss function for the model. The output of the model has shape of `[batch_size, 10]`. The target for the model is a integer vector, each of the integer is in the range of 0 to 9."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "klgv6dfK0KNb",
        "colab": {}
      },
      "source": [
        "model = build_model(allow_cudnn_kernel=True)\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', \n",
        "              optimizer='sgd',\n",
        "              metrics=['accuracy'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qzeeo65r25CU",
        "colab": {}
      },
      "source": [
        "model.fit(x_train, y_train,\n",
        "          validation_data=(x_test, y_test),\n",
        "          batch_size=batch_size,\n",
        "          epochs=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kvCWAssZjsdW"
      },
      "source": [
        "### Build a new model without CuDNN kernel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "H2JfHDOhOFtx",
        "colab": {}
      },
      "source": [
        "slow_model = build_model(allow_cudnn_kernel=False)\n",
        "slow_model.set_weights(model.get_weights())\n",
        "slow_model.compile(loss='sparse_categorical_crossentropy', \n",
        "                   optimizer='sgd', \n",
        "                   metrics=['accuracy'])\n",
        "slow_model.fit(x_train, y_train, \n",
        "               validation_data=(x_test, y_test), \n",
        "               batch_size=batch_size,\n",
        "               epochs=1)  # We only train for one epoch because it's slower."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Zx8QLf81dTVr"
      },
      "source": [
        "As you can see, the model built with CuDNN is much faster to train compared to the model that use the regular TensorFlow kernel.\n",
        "\n",
        "The same CuDNN-enabled model can also be use to run inference in a CPU-only environment. The `tf.device` annotation below is just forcing the device placement. The model will run on CPU by default if no GPU is available.\n",
        "\n",
        "You simply don't have to worry about the hardware you're running on anymore. Isn't that pretty cool?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "z_z1eRh1fMBL",
        "colab": {}
      },
      "source": [
        "with tf.device('CPU:0'):\n",
        "  cpu_model = build_model(allow_cudnn_kernel=True)\n",
        "  cpu_model.set_weights(model.get_weights())\n",
        "  result = tf.argmax(cpu_model.predict_on_batch(tf.expand_dims(sample, 0)), axis=1)\n",
        "  print('Predicted result is: %s, target result is: %s' % (result.numpy(), sample_label))\n",
        "  plt.imshow(sample, cmap=plt.get_cmap('gray'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2mCetBoTiqcB"
      },
      "source": [
        "## RNNs with list/dict inputs, or nested inputs\n",
        "\n",
        "Nested structures allow implementers to include more information within a single timestep. For example, a video frame could have audio and video input at the same time. The data shape in this case could be:\n",
        "\n",
        "`[batch, timestep, {\"video\": [height, width, channel], \"audio\": [frequency]}]`\n",
        "\n",
        "In another example, handwriting data could have both coordinates x and y for the current position of the pen, as well as pressure information. So the data representation could be:\n",
        "\n",
        "`[batch, timestep, {\"location\": [x, y], \"pressure\": [force]}]`\n",
        "\n",
        "The following code provides an example of how to build a custom RNN cell that accepts such structured inputs.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "A1IkIxWykSZQ"
      },
      "source": [
        "### Define a custom cell that support nested input/output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6yOT8nSqzp4A",
        "colab": {}
      },
      "source": [
        "NestedInput = collections.namedtuple('NestedInput', ['feature1', 'feature2'])\n",
        "NestedState = collections.namedtuple('NestedState', ['state1', 'state2'])\n",
        "\n",
        "class NestedCell(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self, unit_1, unit_2, unit_3, **kwargs):\n",
        "    self.unit_1 = unit_1\n",
        "    self.unit_2 = unit_2\n",
        "    self.unit_3 = unit_3\n",
        "    self.state_size = NestedState(state1=unit_1, \n",
        "                                  state2=tf.TensorShape([unit_2, unit_3]))\n",
        "    self.output_size = (unit_1, tf.TensorShape([unit_2, unit_3]))\n",
        "    super(NestedCell, self).__init__(**kwargs)\n",
        "\n",
        "  def build(self, input_shapes):\n",
        "    # expect input_shape to contain 2 items, [(batch, i1), (batch, i2, i3)]\n",
        "    input_1 = input_shapes.feature1[1]\n",
        "    input_2, input_3 = input_shapes.feature2[1:]\n",
        "\n",
        "    self.kernel_1 = self.add_weight(\n",
        "        shape=(input_1, self.unit_1), initializer='uniform', name='kernel_1')\n",
        "    self.kernel_2_3 = self.add_weight(\n",
        "        shape=(input_2, input_3, self.unit_2, self.unit_3),\n",
        "        initializer='uniform',\n",
        "        name='kernel_2_3')\n",
        "\n",
        "  def call(self, inputs, states):\n",
        "    # inputs should be in [(batch, input_1), (batch, input_2, input_3)]\n",
        "    # state should be in shape [(batch, unit_1), (batch, unit_2, unit_3)]\n",
        "    input_1, input_2 = tf.nest.flatten(inputs)\n",
        "    s1, s2 = states\n",
        "\n",
        "    output_1 = tf.matmul(input_1, self.kernel_1)\n",
        "    output_2_3 = tf.einsum('bij,ijkl->bkl', input_2, self.kernel_2_3)\n",
        "    state_1 = s1 + output_1\n",
        "    state_2_3 = s2 + output_2_3\n",
        "\n",
        "    output = [output_1, output_2_3]\n",
        "    new_states = NestedState(state1=state_1, state2=state_2_3)\n",
        "\n",
        "    return output, new_states"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BJHOrrybk6Zy"
      },
      "source": [
        "### Build a RNN model with nested input/output\n",
        "\n",
        "Let's build a Keras model that uses a `tf.keras.layers.RNN` layer and the custom cell we just defined."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "itrDe0Y2qPjP",
        "colab": {}
      },
      "source": [
        "unit_1 = 10\n",
        "unit_2 = 20\n",
        "unit_3 = 30\n",
        "\n",
        "input_1 = 32\n",
        "input_2 = 64\n",
        "input_3 = 32\n",
        "batch_size = 64\n",
        "num_batch = 100\n",
        "timestep = 50\n",
        "\n",
        "cell = NestedCell(unit_1, unit_2, unit_3)\n",
        "rnn = tf.keras.layers.RNN(cell)\n",
        "\n",
        "inp_1 = tf.keras.Input((None, input_1))\n",
        "inp_2 = tf.keras.Input((None, input_2, input_3))\n",
        "\n",
        "outputs = rnn(NestedInput(feature1=inp_1, feature2=inp_2))\n",
        "\n",
        "model = tf.keras.models.Model([inp_1, inp_2], outputs)\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2MaihTM2mDcp"
      },
      "source": [
        "### Train the model with randomly generated data\n",
        "\n",
        "Since there isn't a good candidate dataset for this model, we use random Numpy data for demonstration."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lN-imRqElz2S",
        "colab": {}
      },
      "source": [
        "input_1_data = np.random.random((batch_size * num_batch, timestep, input_1))\n",
        "input_2_data = np.random.random((batch_size * num_batch, timestep, input_2, input_3))\n",
        "target_1_data = np.random.random((batch_size * num_batch, unit_1))\n",
        "target_2_data = np.random.random((batch_size * num_batch, unit_2, unit_3))\n",
        "input_data = [input_1_data, input_2_data]\n",
        "target_data = [target_1_data, target_2_data]\n",
        "\n",
        "model.fit(input_data, target_data, batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oDdrwgBWnjYp"
      },
      "source": [
        "With the Keras `tf.keras.layers.RNN` layer, You are only expected to define the math logic for individual step within the sequence, and the `tf.keras.layers.RNN` layer will handle the sequence iteration for you. It's an incredibly powerful way to quickly prototype new kinds of RNNs (e.g. a LSTM variant).\n",
        "\n",
        "For more details, please visit the [API docs](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/RNN)."
      ]
    }
  ]
}
