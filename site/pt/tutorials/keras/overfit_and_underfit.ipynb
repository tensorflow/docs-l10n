{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fTFj8ft5dlbS"
      },
      "source": [
        "##### Copyright 2018 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "cellView": "form",
        "colab": {},
        "colab_type": "code",
        "id": "lzyBOpYMdp3F"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "cellView": "form",
        "colab": {},
        "colab_type": "code",
        "id": "m_x4KfSJ7Vt7"
      },
      "outputs": [],
      "source": [
        "#@title MIT License\n",
        "#\n",
        "# Copyright (c) 2017 François Chollet\n",
        "#\n",
        "# Permission is hereby granted, free of charge, to any person obtaining a\n",
        "# copy of this software and associated documentation files (the \"Software\"),\n",
        "# to deal in the Software without restriction, including without limitation\n",
        "# the rights to use, copy, modify, merge, publish, distribute, sublicense,\n",
        "# and/or sell copies of the Software, and to permit persons to whom the\n",
        "# Software is furnished to do so, subject to the following conditions:\n",
        "#\n",
        "# The above copyright notice and this permission notice shall be included in\n",
        "# all copies or substantial portions of the Software.\n",
        "#\n",
        "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n",
        "# THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n",
        "# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n",
        "# DEALINGS IN THE SOFTWARE."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "C9HmC2T4ld5B"
      },
      "source": [
        "# Overfit e underfit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kRTxFhXAlnl1"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/keras/overfit_and_underfit\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />Veja em TensorFlow.org</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/keras/overfit_and_underfit.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Execute no Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/overfit_and_underfit.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />Veja Código Fonte no GitHub</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/tutorials/keras/overfit_and_underfit.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Baixar o notebook</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "19rPukKZsPG6"
      },
      "source": [
        "Como sempre, o código neste exemplo usará a API `tf.keras`, sobre a qual você pode aprender mais no TensorFlow [guia Keras] (https://www.tensorflow.org/guide/keras).\n",
        "\n",
        "Nos dois exemplos anteriores - [classificando texto] (https://www.tensorflow.org/tutorials/keras/text_classification_with_hub) e [prevendo a eficiência de combustível] (https://www.tensorflow.org/tutorials/keras/regression ) - vimos que a precisão do nosso modelo nos dados de validação atingia o pico após o treinamento por várias épocas e, então, estagnava ou começava a diminuir.\n",
        "\n",
        "Em outras palavras, nosso modelo superajustava os dados de treinamento. Aprender a lidar com a super adaptação (overfitting) é importante. Embora muitas vezes seja possível obter alta precisão no *conjunto de treinamento*, o que realmente queremos é desenvolver modelos que generalizem bem para um *conjunto de testes* (ou dados que eles nunca viram antes).\n",
        "\n",
        "O oposto de overfitting é *underfitting*. A falta de ajuste ocorre quando ainda há espaço para melhorias nos dados de teste. Isso pode acontecer por várias razões: se o modelo não for suficientemente poderoso, for excessivamente regularizado ou simplesmente não foi treinado por tempo suficiente. Isso significa que a rede não aprendeu os padrões relevantes nos dados de treinamento.\n",
        "\n",
        "Se você treinar por muito tempo, o modelo começará a se ajustar demais e aprender padrões a partir dos dados de treinamento que não se generalizam nos dados de teste. Precisamos encontrar um equilíbrio. Entender como treinar para um número apropriado de épocas, como exploraremos a seguir, é uma habilidade útil.\n",
        "\n",
        "Para evitar o ajuste excessivo, a melhor solução é usar dados de treinamento mais completos. O conjunto de dados deve cobrir toda a gama de entradas com as quais o modelo deve lidar. Dados adicionais podem ser úteis apenas se cobrir casos novos e interessantes.\n",
        "\n",
        "Um modelo treinado em dados mais completos naturalmente se generalizará melhor. Quando isso não for mais possível, a próxima melhor solução é usar técnicas como regularização. Isso impõe restrições à quantidade e ao tipo de informação que seu modelo pode armazenar. Se uma rede puder apenas memorizar um pequeno número de padrões, o processo de otimização a forçará a se concentrar nos padrões mais importantes, com maior chance de generalizar bem.\n",
        "\n",
        "Neste notebook, exploraremos várias técnicas comuns de regularização e as usaremos para aprimorar um modelo de classificação."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WL8UoOTmGGsL"
      },
      "source": [
        "## Configuração"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9FklhSI0Gg9R"
      },
      "source": [
        "Antes de começar, é necessário importar alguns pacotes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "5pZ8A2liqvgk"
      },
      "outputs": [],
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "QnAtAjqRYVXe"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/tensorflow/docs\n",
        "\n",
        "import tensorflow_docs as tfdocs\n",
        "import tensorflow_docs.modeling\n",
        "import tensorflow_docs.plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "-pnOU-ctX27Q"
      },
      "outputs": [],
      "source": [
        "from  IPython import display\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import pathlib\n",
        "import shutil\n",
        "import tempfile\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "jj6I4dvTtbUe"
      },
      "outputs": [],
      "source": [
        "logdir = pathlib.Path(tempfile.mkdtemp())/\"tensorboard_logs\"\n",
        "shutil.rmtree(logdir, ignore_errors=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1cweoTiruj8O"
      },
      "source": [
        "\n",
        "## O conjunto de dados Higgs\n",
        "\n",
        "O objetivo deste tutorial não é fazer física de partículas; portanto, não menciona os detalhes do conjunto de dados. Ele contém 11&#x202F;000&#x202F;000 de exemplos, cada um com 28 recursos e um rótulo de classe binária."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "YPjAvwb-6dFd"
      },
      "outputs": [],
      "source": [
        "gz = tf.keras.utils.get_file('HIGGS.csv.gz', 'https://archive.ics.uci.edu/ml/machine-learning-databases/00280/HIGGS.csv.gz')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "AkiyUdaWIrww"
      },
      "outputs": [],
      "source": [
        "FEATURES = 28"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SFggl9gYKKRJ"
      },
      "source": [
        "A classe `tf.data.experimental.CsvDataset` pode ser usada para ler registros csv diretamente de um arquivo gzip sem etapa intermediária de descompressão."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "QHz4sLVQEVIU"
      },
      "outputs": [],
      "source": [
        "ds = tf.data.experimental.CsvDataset(gz,[float(),]*(FEATURES+1), compression_type=\"GZIP\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HzahEELTKlSV"
      },
      "source": [
        "Essa classe de leitor csv retorna uma lista de escalares para cada registro. A função a seguir repack essa lista de escalares em um par (feature_vector, label)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "zPD6ICDlF6Wf"
      },
      "outputs": [],
      "source": [
        "def pack_row(*row):\n",
        "  label = row[0]\n",
        "  features = tf.stack(row[1:],1)\n",
        "  return features, label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4oa8tLuwLsbO"
      },
      "source": [
        "TensorFlow is most efficient when operating on large batches of data.\n",
        "\n",
        "Portanto, em vez de reembalar cada linha individualmente, crie um novo `conjunto de dados` que use lotes de 10000 exemplos, aplique a função `pack_row` a cada lote e divida os lotes novamente em registros individuais:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "-w-VHTwwGVoZ"
      },
      "outputs": [],
      "source": [
        "packed_ds = ds.batch(10000).map(pack_row).unbatch()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lUbxc5bxNSXV"
      },
      "source": [
        "Dê uma olhada em alguns dos registros deste novo `packages_ds`.\n",
        "\n",
        "Os recursos não são perfeitamente normalizados, mas isso é suficiente para este tutorial."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "TfcXuv33Fvka"
      },
      "outputs": [],
      "source": [
        "for features,label in packed_ds.batch(1000).take(1):\n",
        "  print(features[0])\n",
        "  plt.hist(features.numpy().flatten(), bins = 101)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ICKZRY7gN-QM"
      },
      "source": [
        "Para manter este tutorial relativamente curto, use apenas as primeiras 1000 amostras para validação e as próximas 10.000 para treinamento:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "hmk49OqZIFZP"
      },
      "outputs": [],
      "source": [
        "N_VALIDATION = int(1e3)\n",
        "N_TRAIN = int(1e4)\n",
        "BUFFER_SIZE = int(1e4)\n",
        "BATCH_SIZE = 500\n",
        "STEPS_PER_EPOCH = N_TRAIN//BATCH_SIZE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FP3M9DmvON32"
      },
      "source": [
        "Os métodos `Dataset.skip` e `Dataset.take` facilitam isso.\n",
        "\n",
        "Ao mesmo tempo, use o método `Dataset.cache` para garantir que o carregador não precise reler os dados do arquivo em cada época:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "H8H_ZzpBOOk-"
      },
      "outputs": [],
      "source": [
        "validate_ds = packed_ds.take(N_VALIDATION).cache()\n",
        "train_ds = packed_ds.skip(N_VALIDATION).take(N_TRAIN).cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "9zAOqk2_Px7K"
      },
      "outputs": [],
      "source": [
        "train_ds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6PMliHoVO3OL"
      },
      "source": [
        "Esses conjuntos de dados retornam exemplos individuais. Use o método `.batch` para criar lotes de tamanho apropriado para treinamento. Antes do lote, lembre-se de `.shuffle` e `.repeat` o conjunto de treinamento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Y7I4J355O223"
      },
      "outputs": [],
      "source": [
        "validate_ds = validate_ds.batch(BATCH_SIZE)\n",
        "train_ds = train_ds.shuffle(BUFFER_SIZE).repeat().batch(BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lglk41MwvU5o"
      },
      "source": [
        "## Demonstrar sobreajuste\n",
        "\n",
        "A maneira mais simples de evitar o ajuste excessivo é começar com um modelo pequeno: um modelo com um pequeno número de parâmetros aprendíveis (que é determinado pelo número de camadas e pelo número de unidades por camada). No aprendizado profundo, o número de parâmetros aprendíveis em um modelo é frequentemente chamado de \"capacidade\" do modelo.\n",
        "\n",
        "Intuitivamente, um modelo com mais parâmetros terá mais \"capacidade de memorização\" e, portanto, poderá aprender facilmente um mapeamento perfeito como um dicionário entre amostras de treinamento e seus alvos, um mapeamento sem nenhum poder de generalização, mas isso seria inútil ao fazer previsões em dados não vistos anteriormente.\n",
        "\n",
        "Lembre-se sempre disso: os modelos de aprendizado profundo tendem a ser bons para se ajustar aos dados de treinamento, mas o verdadeiro desafio é a generalização, não é adequada.\n",
        "\n",
        "Por outro lado, se a rede tiver recursos limitados de memorização, não poderá aprender o mapeamento tão facilmente. Para minimizar sua perda, ele terá que aprender representações compactadas que têm mais poder preditivo. Ao mesmo tempo, se você tornar seu modelo muito pequeno, ele terá dificuldade em se ajustar aos dados de treinamento. Há um equilíbrio entre \"muita capacidade\" e \"capacidade insuficiente\".\n",
        "\n",
        "Infelizmente, não existe uma fórmula mágica para determinar o tamanho certo ou a arquitetura do seu modelo (em termos de número de camadas ou tamanho certo para cada camada). Você terá que experimentar usando uma série de arquiteturas diferentes.\n",
        "\n",
        "Para encontrar um tamanho de modelo apropriado, é melhor começar com relativamente poucas camadas e parâmetros e começar a aumentar o tamanho das camadas ou adicionar novas camadas até ver retornos decrescentes na perda de validação.\n",
        "\n",
        "Comece com um modelo simples usando apenas `layers.Dense` como linha de base, depois crie versões maiores e compare-as."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_ReKHdC2EgVu"
      },
      "source": [
        "### Procedimento de Treinamento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pNzkSkkXSP5l"
      },
      "source": [
        "Muitos modelos treinam melhor se você reduzir gradualmente a taxa de aprendizado durante o treinamento. Use `optimizers.schedules` para reduzir a taxa de aprendizado ao longo do tempo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "LwQp-ERhAD6F"
      },
      "outputs": [],
      "source": [
        "lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(\n",
        "  0.001,\n",
        "  decay_steps=STEPS_PER_EPOCH*1000,\n",
        "  decay_rate=1,\n",
        "  staircase=False)\n",
        "\n",
        "def get_optimizer():\n",
        "  return tf.keras.optimizers.Adam(lr_schedule)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kANLx6OYTQ8B"
      },
      "source": [
        "O código acima define um `schedule.InverseTimeDecay` para diminuir hiperbolicamente a taxa de aprendizado para 1/2 da taxa básica em 1000 épocas, 1/3 em 2000 épocas e assim por diante."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "HIo_yPjEAFgn"
      },
      "outputs": [],
      "source": [
        "step = np.linspace(0,100000)\n",
        "lr = lr_schedule(step)\n",
        "plt.figure(figsize = (8,6))\n",
        "plt.plot(step/STEPS_PER_EPOCH, lr)\n",
        "plt.ylim([0,max(plt.ylim())])\n",
        "plt.xlabel('Epoch')\n",
        "_ = plt.ylabel('Learning Rate')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ya7x7gr9UjU0"
      },
      "source": [
        "Cada modelo neste tutorial usará a mesma configuração de treinamento. Portanto, configure-os de maneira reutilizável, começando com a lista de retornos de chamada.\n",
        "\n",
        "O treinamento para este tutorial é executado por muitas épocas curtas. Para reduzir o ruído de registro, use o `tfdocs.EpochDots`, que simplesmente é um `.` para cada época e, e um conjunto completo de métricas a cada 100 épocas.\n",
        "\n",
        "Em seguida, inclua `callbacks.EarlyStopping` para evitar tempos de treinamento longos e desnecessários. Note que este retorno de chamada está configurado para monitorar o `val_binary_crossentropy`, não o `val_loss`. Essa diferença será importante mais tarde.\n",
        "\n",
        "Use `callbacks.TensorBoard` para gerar logs do TensorBoard para o treinamento.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "vSv8rfw_T85n"
      },
      "outputs": [],
      "source": [
        "def get_callbacks(name):\n",
        "  return [\n",
        "    tfdocs.modeling.EpochDots(),\n",
        "    tf.keras.callbacks.EarlyStopping(monitor='val_binary_crossentropy', patience=200),\n",
        "    tf.keras.callbacks.TensorBoard(logdir/name),\n",
        "  ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VhctzKhBWVDD"
      },
      "source": [
        "Da mesma forma, cada modelo usará as mesmas configurações `Model.compile` e` Model.fit`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "xRCGwU3YH5sT"
      },
      "outputs": [],
      "source": [
        "def compile_and_fit(model, name, optimizer=None, max_epochs=10000):\n",
        "  if optimizer is None:\n",
        "    optimizer = get_optimizer()\n",
        "  model.compile(optimizer=optimizer,\n",
        "                loss='binary_crossentropy',\n",
        "                metrics=['accuracy', 'binary_crossentropy'])\n",
        "\n",
        "  model.summary()\n",
        "\n",
        "  history = model.fit(\n",
        "    train_ds,\n",
        "    steps_per_epoch = STEPS_PER_EPOCH,\n",
        "    epochs=max_epochs,\n",
        "    validation_data=validate_ds,\n",
        "    callbacks=get_callbacks(name),\n",
        "    verbose=0)\n",
        "  return history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mxBeiLUiWHJV"
      },
      "source": [
        "### Modelo Minúsculo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "a6JDv12scLTI"
      },
      "source": [
        "Comece treinando um modelo linear:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "EZh-QFjKHb70"
      },
      "outputs": [],
      "source": [
        "tiny_model = tf.keras.Sequential([\n",
        "    layers.Dense(16, activation='elu', input_shape=(FEATURES,)),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "X72IUdWYipIS"
      },
      "outputs": [],
      "source": [
        "size_histories = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "bdOcJtPGHhJ5"
      },
      "outputs": [],
      "source": [
        "size_histories['Tiny'] = compile_and_fit(tiny_model, 'sizes/Tiny')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rS_QGT6icwdI"
      },
      "source": [
        "Agora verifique como o modelo foi:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "dkEvb2x5XsjE"
      },
      "outputs": [],
      "source": [
        "plotter = tfdocs.plots.HistoryPlotter(metric = 'binary_crossentropy', smoothing_std=10)\n",
        "plotter.plot(size_histories)\n",
        "plt.ylim([0.5, 0.7])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LGxGzh_FWOJ8"
      },
      "source": [
        "### Pequeno Modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YjMb6E72f2pN"
      },
      "source": [
        "Para ver se você consegue superar o desempenho do modelo pequeno, treine progressivamente alguns modelos maiores.\n",
        "\n",
        "Tente duas camadas ocultas com 16 unidades cada:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "QKgdXPx9usBa"
      },
      "outputs": [],
      "source": [
        "small_model = tf.keras.Sequential([\n",
        "    # `input_shape` is only required here so that `.summary` works.\n",
        "    layers.Dense(16, activation='elu', input_shape=(FEATURES,)),\n",
        "    layers.Dense(16, activation='elu'),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "LqG3MXF5xSjR"
      },
      "outputs": [],
      "source": [
        "size_histories['Small'] = compile_and_fit(small_model, 'sizes/Small')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "L-DGRBbGxI6G"
      },
      "source": [
        "### Modelo Médio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SrfoVQheYSO5"
      },
      "source": [
        "Agora tente 3 camadas ocultas com 64 unidades cada:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "jksi-XtaxDAh"
      },
      "outputs": [],
      "source": [
        "medium_model = tf.keras.Sequential([\n",
        "    layers.Dense(64, activation='elu', input_shape=(FEATURES,)),\n",
        "    layers.Dense(64, activation='elu'),\n",
        "    layers.Dense(64, activation='elu'),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jbngCZliYdma"
      },
      "source": [
        "E treine o modelo usando os mesmos dados:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Ofn1AwDhx-Fe"
      },
      "outputs": [],
      "source": [
        "size_histories['Medium']  = compile_and_fit(medium_model, \"sizes/Medium\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vIPuf23FFaVn"
      },
      "source": [
        "### Modelo grande\n",
        "\n",
        "Como exercício, você pode criar um modelo ainda maior e ver com que rapidez ele começa a se ajustar. Em seguida, vamos adicionar a esse benchmark uma rede que tem muito mais capacidade, muito mais do que o problema justificaria:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "ghQwwqwqvQM9"
      },
      "outputs": [],
      "source": [
        "large_model = tf.keras.Sequential([\n",
        "    layers.Dense(512, activation='elu', input_shape=(FEATURES,)),\n",
        "    layers.Dense(512, activation='elu'),\n",
        "    layers.Dense(512, activation='elu'),\n",
        "    layers.Dense(512, activation='elu'),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "D-d-i5DaYmr7"
      },
      "source": [
        "E, novamente, treine o modelo usando os mesmos dados:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "U1A99dhqvepf"
      },
      "outputs": [],
      "source": [
        "size_histories['large'] = compile_and_fit(large_model, \"sizes/large\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Fy3CMUZpzH3d"
      },
      "source": [
        "### Traçar as Perdas de Treinamento e Validação"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HSlo1F4xHuuM"
      },
      "source": [
        "As linhas sólidas mostram a perda de treinamento e as linhas tracejadas mostram a perda de validação (lembre-se: uma perda de validação menor indica um modelo melhor)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OLhL1AszdLfM"
      },
      "source": [
        "Embora a construção de um modelo maior ofereça mais poder, se esse poder não for restringido de alguma forma, pode facilmente se sobrepor ao conjunto de treinamento.\n",
        "\n",
        "Neste exemplo, normalmente, apenas o modelo `\" Tiny \"` consegue evitar o excesso de ajuste, e cada um dos modelos maiores superajusta os dados mais rapidamente. Isso se torna tão severo para o modelo `` grande '' que você precisa mudar o gráfico para uma escala de log para realmente ver o que está acontecendo.\n",
        "\n",
        "Isso é aparente se você plotar e comparar as métricas de validação com as métricas de treinamento.\n",
        "\n",
        "* É normal que haja uma pequena diferença.\n",
        "* Se as duas métricas estiverem se movendo na mesma direção, tudo estará bem.\n",
        "* Se a métrica de validação começar a estagnar enquanto a métrica de treinamento continuar a melhorar, você provavelmente estará com excesso de ajustes.\n",
        "* Se a métrica de validação estiver indo na direção errada, o modelo estará claramente sobregravado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "0XmKDtOWzOpk"
      },
      "outputs": [],
      "source": [
        "plotter.plot(size_histories)\n",
        "a = plt.xscale('log')\n",
        "plt.xlim([5, max(plt.xlim())])\n",
        "plt.ylim([0.5, 0.7])\n",
        "plt.xlabel(\"Epochs [Log Scale]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UekcaQdmZxnW"
      },
      "source": [
        "Nota: Todas as execuções de treinamento acima usaram o `callbacks.EarlyStopping` para finalizar o treinamento, uma vez que ficou claro que o modelo não estava progredindo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DEQNKadHA0M3"
      },
      "source": [
        "### Visualizar no TensorBoard\n",
        "\n",
        "Todos esses modelos gravaram logs do TensorBoard durante o treinamento.\n",
        "\n",
        "Para abrir um visualizador TensorBoard incorporado em um notebook, copie o seguinte em uma célula de código:\n",
        "\n",
        "```\n",
        "%tensorboard --logdir {logdir}/sizes\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fjqx3bywDPjf"
      },
      "source": [
        "Você pode visualizar os [resultados de uma execução anterior] (https://tensorboard.dev/experiment/vW7jmmF9TmKmy3rbheMQpw/#scalars&_smoothingWeight=0.97) deste notebook em [TensorBoard.dev] (https://tensorboard.dev/).\n",
        "\n",
        "O TensorBoard.dev é uma experiência gerenciada para hospedar, rastrear e compartilhar experimentos de ML com todos.\n",
        "\n",
        "Também está incluído em um `<iframe>` por conveniência:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "dX5fcgrADwym"
      },
      "outputs": [],
      "source": [
        "display.IFrame(\n",
        "    src=\"https://tensorboard.dev/experiment/vW7jmmF9TmKmy3rbheMQpw/#scalars&_smoothingWeight=0.97\",\n",
        "    width=\"100%\", height=\"800px\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RDQDBKYZBXF_"
      },
      "source": [
        "Se você deseja compartilhar os resultados do TensorBoard, pode fazer o upload dos logs para [TensorBoard.dev] (https://tensorboard.dev/), copiando o seguinte em uma célula de código.\n",
        "\n",
        "Nota: Esta etapa requer uma conta Google.\n",
        "\n",
        "```\n",
        "!tensorboard dev upload --logdir  {logdir}/sizes\n",
        "```\n",
        "\n",
        "Cuidado: Este comando não termina. Ele foi projetado para carregar continuamente os resultados de experimentos de longa duração. Após o upload dos dados, você precisa interrompê-los usando a opção \"interromper a execução\" na sua ferramenta de notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ASdv7nsgEFhx"
      },
      "source": [
        "## Estratégias para previnir o overfitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YN512ksslaxJ"
      },
      "source": [
        "Antes de entrar no conteúdo desta seção, copie os logs de treinamento do modelo ``Minúsculo`` acima, para usar como linha de base para comparação."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "40k1eBtnQzNo"
      },
      "outputs": [],
      "source": [
        "shutil.rmtree(logdir/'regularizers/Tiny', ignore_errors=True)\n",
        "shutil.copytree(logdir/'sizes/Tiny', logdir/'regularizers/Tiny')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "vFWMeFo7jLpN"
      },
      "outputs": [],
      "source": [
        "regularizer_histories = {}\n",
        "regularizer_histories['Tiny'] = size_histories['Tiny']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4rHoVWcswFLa"
      },
      "source": [
        "### Adicione Regularização do Peso\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kRxWepNawbBK"
      },
      "source": [
        "Você pode estar familiarizado com o princípio Navalha de Occam: dadas duas explicações para algo, a explicação mais provável de ser correta é a \"mais simples\", a que apresenta o menor número de suposições. Isso também se aplica aos modelos aprendidos pelas redes neurais: dados alguns dados de treinamento e uma arquitetura de rede, existem vários conjuntos de valores de pesos (vários modelos) que poderiam explicar os dados, e modelos mais simples têm menos probabilidade de se superestimar do que os complexos.\n",
        "\n",
        "Um \"modelo simples\" neste contexto é um modelo em que a distribuição dos valores dos parâmetros tem menos entropia (ou um modelo com menos parâmetros, como vimos na seção acima). Assim, uma maneira comum de mitigar o excesso de ajuste é restringir a complexidade de uma rede, forçando seus pesos apenas a aceitar valores pequenos, o que torna a distribuição dos valores de peso mais \"regular\". Isso é chamado de \"regularização de peso\" e é feito adicionando à função de perda da rede um custo associado a ter grandes pesos. Esse custo vem em dois sabores:\n",
        "\n",
        "* [Regularização L1] (https://developers.google.com/machine-learning/glossary/#L1_regularization), em que o custo adicionado é proporcional ao valor absoluto dos coeficientes de pesos (ou seja, ao que é chamado de \"norma L1 \"dos pesos).\n",
        "\n",
        "* [Regularização de L2] (https://developers.google.com/machine-learning/glossary/#L2_regularization), em que o custo adicionado é proporcional ao quadrado do valor dos coeficientes de pesos (ou seja, ao que é chamado de quadrado) \"Norma L2\" dos pesos). A regularização de L2 também é chamada de decaimento de peso no contexto de redes neurais. Não deixe que o nome diferente o confunda: a redução de peso é matematicamente a mesma que a regularização de L2.\n",
        "\n",
        "A regularização L1 empurra pesos para exatamente zero, incentivando um modelo esparso. A regularização de L2 penalizará os parâmetros de pesos sem torná-los escassos, pois a penalidade é zero para pesos pequenos. uma razão pela qual L2 é mais comum.\n",
        "\n",
        "Em `tf.keras`, a regularização de peso é adicionada passando instâncias de regularizador de peso para as camadas como argumentos de palavras-chave. Vamos adicionar a regularização de peso L2 agora."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "HFGmcwduwVyQ"
      },
      "outputs": [],
      "source": [
        "l2_model = tf.keras.Sequential([\n",
        "    layers.Dense(512, activation='elu',\n",
        "                 kernel_regularizer=regularizers.l2(0.001),\n",
        "                 input_shape=(FEATURES,)),\n",
        "    layers.Dense(512, activation='elu',\n",
        "                 kernel_regularizer=regularizers.l2(0.001)),\n",
        "    layers.Dense(512, activation='elu',\n",
        "                 kernel_regularizer=regularizers.l2(0.001)),\n",
        "    layers.Dense(512, activation='elu',\n",
        "                 kernel_regularizer=regularizers.l2(0.001)),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "regularizer_histories['l2'] = compile_and_fit(l2_model, \"regularizers/l2\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bUUHoXb7w-_C"
      },
      "source": [
        "`l2 (0,001)` significa que todo coeficiente na matriz de peso da camada adicionará `0,001 * weight_coefficient_value * 2` à **perda total** da rede.\n",
        "\n",
        "É por isso que estamos monitorando o `binary_crossentropy` diretamente. Porque ele não possui esse componente de regularização misturado.\n",
        "\n",
        "Portanto, o mesmo modelo \"Grande\" com uma penalidade de regularização `L2` tem um desempenho muito melhor:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "7wkfLyxBZdh_"
      },
      "outputs": [],
      "source": [
        "plotter.plot(regularizer_histories)\n",
        "plt.ylim([0.5, 0.7])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Kx1YHMsVxWjP"
      },
      "source": [
        "Como você pode ver, o modelo regularizado `\" L2 \"` agora é muito mais competitivo com o modelo ``Minúsculo ``. Este modelo `\" L2 \"` também é muito mais resistente à super adaptação do que o modelo `` Large`` no qual foi baseado, apesar de ter o mesmo número de parâmetros."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JheBk6f8jMQ7"
      },
      "source": [
        "#### Mais informações\n",
        "\n",
        "Há duas coisas importantes a serem observadas sobre esse tipo de regularização.\n",
        "\n",
        "**Primeiro:** se você estiver escrevendo seu próprio ciclo de treinamento, precisará solicitar ao modelo as perdas de regularização."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "apDHQNybjaML"
      },
      "outputs": [],
      "source": [
        "result = l2_model(features)\n",
        "regularization_loss = tf.add_n(l2_model.losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MLhG6fMSjE-J"
      },
      "source": [
        "**Segundo:** Essa implementação funciona adicionando as penalidades de peso à perda do modelo e aplicando um procedimento de otimização padrão depois disso.\n",
        "\n",
        "Há uma segunda abordagem que executa o otimizador apenas na perda bruta e, ao aplicar a etapa calculada, o otimizador também aplica alguma redução de peso. Este \"Decapled Weight Decay\" é visto em otimizadores como `optimizers.FTRL` e `optimizers.AdamW`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HmnBNOOVxiG8"
      },
      "source": [
        "### Adicionar dropout\n",
        "\n",
        "O abandono é uma das técnicas de regularização mais eficazes e mais usadas para redes neurais, desenvolvida por Hinton e seus alunos da Universidade de Toronto.\n",
        "\n",
        "A explicação intuitiva para o abandono é que, como nós individuais na rede não podem confiar na saída dos outros, cada nó deve gerar recursos úteis por si só.\n",
        "\n",
        "A desistência, aplicada a uma camada, consiste em \"desistir\" aleatoriamente (isto é, definido como zero) uma série de recursos de saída da camada durante o treinamento. Digamos que uma determinada camada retornaria normalmente um vetor [0,2, 0,5, 1,3, 0,8, 1,1] para uma determinada amostra de entrada durante o treinamento; depois de aplicar a desistência, esse vetor terá algumas entradas zero distribuídas aleatoriamente, por exemplo [0, 0,5,\n",
        "1,3, 0, 1,1].\n",
        "\n",
        "A \"taxa de desistência\" é a fração dos recursos que estão sendo zerados; geralmente é definido entre 0,2 e 0,5. No momento do teste, nenhuma unidade é eliminada e, em vez disso, os valores de saída da camada são reduzidos por um fator igual à taxa de desistência, de modo a equilibrar o fato de que mais unidades estão ativas do que no tempo de treinamento.\n",
        "\n",
        "No `tf.keras`, você pode introduzir dropout em uma rede através da camada Dropout, que é aplicada à saída da camada logo antes.\n",
        "\n",
        "Vamos adicionar duas camadas do Dropout em nossa rede para ver o desempenho delas na redução do overfitting:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "OFEYvtrHxSWS"
      },
      "outputs": [],
      "source": [
        "dropout_model = tf.keras.Sequential([\n",
        "    layers.Dense(512, activation='elu', input_shape=(FEATURES,)),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(512, activation='elu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(512, activation='elu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(512, activation='elu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "regularizer_histories['dropout'] = compile_and_fit(dropout_model, \"regularizers/dropout\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "SPZqwVchx5xp"
      },
      "outputs": [],
      "source": [
        "plotter.plot(regularizer_histories)\n",
        "plt.ylim([0.5, 0.7])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4zlHr4iaI1U6"
      },
      "source": [
        "Está claro neste gráfico que ambas as abordagens de regularização melhoram o comportamento do modelo `` Grande``. Mas isso ainda não supera nem a linha de base ``Tiny``.\n",
        "\n",
        "Em seguida, tente os dois juntos e veja se isso funciona melhor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "u7qMg_7Nwy5t"
      },
      "source": [
        "### Combinando L2 + dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "7zfs_qQIw1cz"
      },
      "outputs": [],
      "source": [
        "combined_model = tf.keras.Sequential([\n",
        "    layers.Dense(512, kernel_regularizer=regularizers.l2(0.0001),\n",
        "                 activation='elu', input_shape=(FEATURES,)),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(512, kernel_regularizer=regularizers.l2(0.0001),\n",
        "                 activation='elu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(512, kernel_regularizer=regularizers.l2(0.0001),\n",
        "                 activation='elu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(512, kernel_regularizer=regularizers.l2(0.0001),\n",
        "                 activation='elu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "regularizer_histories['combined'] = compile_and_fit(combined_model, \"regularizers/combined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "qDqBBxfI0Yd8"
      },
      "outputs": [],
      "source": [
        "plotter.plot(regularizer_histories)\n",
        "plt.ylim([0.5, 0.7])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tE0OoNCQNTJv"
      },
      "source": [
        "Este modelo com a regularização ``\"Combinada\"`` é obviamente o melhor até agora."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-dw23T03FEO1"
      },
      "source": [
        "### Vizualizar no TensorBoard\n",
        "\n",
        "Esses modelos também registraram logs do TensorBoard.\n",
        "\n",
        "Para abrir um visualizador de tensorboard incorporado em um notebook, copie o seguinte em uma célula de código:\n",
        "\n",
        "```\n",
        "%tensorboard --logdir {logdir}/regularizers\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KX3Voac-FEO4"
      },
      "source": [
        "Você pode visualizar os [resultados de uma execução anterior] (https://tensorboard.dev/experiment/fGInKDo8TXes1z7HQku9mw/#scalars&_smoothingWeight=0.97) deste notebook em [TensorDoard.dev] (https://tensorboard.dev/).\n",
        "\n",
        "Também está incluído em um `<iframe>` por conveniência:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "doMtyYoqFEO5"
      },
      "outputs": [],
      "source": [
        "display.IFrame(\n",
        "    src=\"https://tensorboard.dev/experiment/fGInKDo8TXes1z7HQku9mw/#scalars&_smoothingWeight=0.97\",\n",
        "    width = \"100%\",\n",
        "    height=\"800px\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mds5RXGjIcSu"
      },
      "source": [
        "Este foi enviado com:\n",
        "\n",
        "```\n",
        "!tensorboard dev upload --logdir  {logdir}/regularizers\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uXJxtwBWIhjG"
      },
      "source": [
        "## Conclusões"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gjfnkEeQyAFG"
      },
      "source": [
        "Para recapitular: aqui estão as maneiras mais comuns de evitar o ajuste excessivo nas redes neurais:\n",
        "\n",
        "* Obtenha mais dados de treinamento.\n",
        "* Reduza a capacidade da rede.\n",
        "* Adicione regularização de peso.\n",
        "* Adicione desistência.\n",
        "\n",
        "Duas abordagens importantes não abordadas neste guia são:\n",
        "\n",
        "* aumento de dados\n",
        "* normalização de lote\n",
        "\n",
        "Lembre-se de que cada método pode ajudar por si só, mas geralmente combiná-los pode ser ainda mais eficaz."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "overfit_and_underfit.ipynb",
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}