{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "text_classification_with_hub.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ic4_occAAiAT"
      },
      "source": [
        "##### Copyright 2019 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "cellView": "form",
        "colab": {},
        "colab_type": "code",
        "id": "ioaprt5q5US7"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "cellView": "form",
        "colab": {},
        "colab_type": "code",
        "id": "yCl0eTNH5RS3"
      },
      "outputs": [],
      "source": [
        "#@title MIT License\n",
        "#\n",
        "# Copyright (c) 2017 François Chollet\n",
        "#\n",
        "# Permission is hereby granted, free of charge, to any person obtaining a\n",
        "# copy of this software and associated documentation files (the \"Software\"),\n",
        "# to deal in the Software without restriction, including without limitation\n",
        "# the rights to use, copy, modify, merge, publish, distribute, sublicense,\n",
        "# and/or sell copies of the Software, and to permit persons to whom the\n",
        "# Software is furnished to do so, subject to the following conditions:\n",
        "#\n",
        "# The above copyright notice and this permission notice shall be included in\n",
        "# all copies or substantial portions of the Software.\n",
        "#\n",
        "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n",
        "# THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n",
        "# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n",
        "# DEALINGS IN THE SOFTWARE."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ItXfxkxvosLH"
      },
      "source": [
        "# Classificação de texto com o TensorFlow Hub: Críticas de filmes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hKY4XMc9o8iB"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/keras/text_classification_with_hub\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />Ver em TensorFlow.org</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/keras/text_classification_with_hub.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Executar no Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/text_classification_with_hub.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />Ver código fonte no GitHub</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/tutorials/keras/text_classification_with_hub.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Baixar notebook</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Eg62Pmz3o83v"
      },
      "source": [
        "\n",
        "Este notebook classifica as resenhas de filmes como *positivas* ou *negativas* usando o texto da resenha. Este é um exemplo de classificação *binária* - ou de duas classes -, um tipo importante e amplamente aplicável de problema de aprendizado de máquina.\n",
        "\n",
        "O tutorial demonstra a aplicação básica do aprendizado de transferência com o TensorFlow Hub e o Keras.\n",
        "\n",
        "Usaremos o [conjunto de dados IMDB] (https://www.tensorflow.org/api_docs/python/tf/keras/datasets/imdb) que contém o texto de 50.000 críticas de filmes do [Internet Movie Database] (https: //www.imdb.com/). Eles são divididos em 25.000 análises para treinamento e 25.000 análises para testes. Os conjuntos de treinamento e teste são *balanceados*, o que significa que eles contêm um número igual de análises positivas e negativas.\n",
        "\n",
        "Este notebook usa o [tf.keras] (https://www.tensorflow.org/guide/keras), uma API de alto nível para criar e treinar modelos no TensorFlow e o [TensorFlow Hub] (https: //www.tensorflow .org/hub), uma biblioteca e plataforma para transferência de aprendizado. Para um tutorial de classificação de texto mais avançado usando o `tf.keras`, consulte o [Guia de classificação de texto do MLCC] (https://developers.google.com/machine-learning/guides/text-classification/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "2ew7HTbPpCJH"
      },
      "outputs": [],
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "\n",
        "!pip install tensorflow-hub\n",
        "!pip install tensorflow-datasets\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "print(\"Version: \", tf.__version__)\n",
        "print(\"Eager mode: \", tf.executing_eagerly())\n",
        "print(\"Hub version: \", hub.__version__)\n",
        "print(\"GPU is\", \"available\" if tf.config.experimental.list_physical_devices(\"GPU\") else \"NOT AVAILABLE\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iAsKG535pHep"
      },
      "source": [
        "## Baixar o conjunto de dados IMDB\n",
        "\n",
        "O conjunto de dados IMDB está disponível em [revisões imdb] (https://www.tensorflow.org/datasets/catalog/imdb_reviews) ou em [conjuntos de dados TensorFlow] (https://www.tensorflow.org/datasets). O código a seguir baixa o conjunto de dados IMDB para sua máquina (ou em tempo de execução colab):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "zXXx5Oc3pOmN"
      },
      "outputs": [],
      "source": [
        "# Divida o conjunto de treinamento em 60% e 40%, para terminar com 15.000 exemplos\n",
        "# para treinamento, 10.000 exemplos para validação e 25.000 exemplos para teste.\n",
        "train_validation_split = tfds.Split.TRAIN.subsplit([6, 4])\n",
        "\n",
        "(train_data, validation_data), test_data = tfds.load(\n",
        "    name=\"imdb_reviews\", \n",
        "    split=(train_validation_split, tfds.Split.TEST),\n",
        "    as_supervised=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "l50X3GfjpU4r"
      },
      "source": [
        "## Explore os dados\n",
        "\n",
        "Vamos dedicar um momento para entender o formato dos dados. Cada exemplo é uma frase que representa a crítica de cinema e um rótulo correspondente. A sentença não é pré-processada de forma alguma. O rótulo é um valor inteiro de 0 ou 1, em que 0 é uma revisão negativa e 1 é uma revisão positiva.\n",
        "\n",
        "Vamos imprimir os 10 primeiros exemplos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "QtTS4kpEpjbi"
      },
      "outputs": [],
      "source": [
        "train_examples_batch, train_labels_batch = next(iter(train_data.batch(10)))\n",
        "train_examples_batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IFtaCHTdc-GY"
      },
      "source": [
        "Vamos também imprimir as 10 primeiras etiquetas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "tvAjVXOWc6Mj"
      },
      "outputs": [],
      "source": [
        "train_labels_batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LLC02j2g-llC"
      },
      "source": [
        "## Construindo o modelo\n",
        "\n",
        "A rede neural é criada empilhando camadas - isso requer três decisões arquiteturais principais:\n",
        "\n",
        "* Como representar o texto?\n",
        "* Quantas camadas usar no modelo?\n",
        "* Quantas *unidades ocultas* para usar em cada camada?\n",
        "\n",
        "Neste exemplo, os dados de entrada consistem em frases. Os rótulos a serem preditos são 0 ou 1.\n",
        "\n",
        "Uma maneira de representar o texto é converter frases em vetores de incorporação. Podemos usar uma incorporação de texto pré-treinada como a primeira camada, que terá três vantagens:\n",
        "\n",
        "* não precisamos nos preocupar com pré-processamento de texto,\n",
        "* podemos nos beneficiar da transferência de aprendizado,\n",
        "* a incorporação tem um tamanho fixo, por isso é mais simples de processar.\n",
        "\n",
        "Neste exemplo, usaremos um **modelo de incorporação de texto pré-treinado** do [TensorFlow Hub] (https://www.tensorflow.org/hub) chamado [google/tf2-preview/gnews-swivel-20dim/1 ] (https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1).\n",
        "\n",
        "Existem outros três modelos pré-treinados para testar neste tutorial:\n",
        "\n",
        "* [google/tf2-preview/gnews-swivel-20dim-with-oov/1] (https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim-with-oov/1) - o mesmo que [google/tf2-preview/gnews-swivel-20dim/1] (https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1), mas com vocabulário de 2,5% convertido em OOV buckets. Isso pode ajudar se o vocabulário da tarefa e o vocabulário do modelo não se sobrepuserem totalmente.\n",
        "* [google/tf2-preview/nnlm-en-dim50/1] (https://tfhub.dev/google/tf2-preview/nnlm-en-dim50/1) - Um modelo muito maior com ~ 1M de tamanho de vocabulário e 50 dimensões.\n",
        "* [google/tf2-preview/nnlm-en-dim128/1] (https://tfhub.dev/google/tf2-preview/nnlm-en-dim128/1) - Modelo ainda maior com ~ 1M de tamanho e 128 dimensões."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "In2nDpTLkgKa"
      },
      "source": [
        "Vamos primeiro criar uma camada Keras que use um modelo do TensorFlow Hub para incorporar as frases e testá-lo em alguns exemplos de entrada. Note que não importa o tamanho do texto de entrada, a forma de saída dos encaixes é: `(num_examples, embedding_dimension)`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "_NUbzVeYkgcO"
      },
      "outputs": [],
      "source": [
        "embedding = \"https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1\"\n",
        "hub_layer = hub.KerasLayer(embedding, input_shape=[], \n",
        "                           dtype=tf.string, trainable=True)\n",
        "hub_layer(train_examples_batch[:3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dfSbV6igl1EH"
      },
      "source": [
        "Vamos agora construir o modelo completo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "xpKOoWgu-llD"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential()\n",
        "model.add(hub_layer)\n",
        "model.add(tf.keras.layers.Dense(16, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6PbKQ6mucuKL"
      },
      "source": [
        "As camadas são empilhadas sequencialmente para criar o classificador:\n",
        "\n",
        "1. A primeira camada é uma camada do TensorFlow Hub. Essa camada usa um Modelo salvo pré-treinado para mapear uma frase em seu vetor de incorporação. O modelo de incorporação de texto pré-treinado que estamos usando ([google/tf2-preview/gnews-swivel-20dim/1] (https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1) ) divide a sentença em tokens, incorpora cada token e depois combina a incorporação. As dimensões resultantes são: `(num_examples, embedding_dimension)`.\n",
        "2. Esse vetor de saída de comprimento fixo é canalizado através de uma camada totalmente conectada (`Densa`) com 16 unidades ocultas.\n",
        "3. A última camada está densamente conectada com um único nó de saída. Usando a função de ativação `sigmoid`, esse valor é um valor flutuante entre 0 e 1, representando uma probabilidade ou nível de confiança.\n",
        "\n",
        "Vamos compilar o modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "L4EqVWg4-llM"
      },
      "source": [
        "### Função de Perda e Otimizador\n",
        "\n",
        "Um modelo precisa de uma função de perda e um otimizador para treinamento. Como esse é um problema de classificação binária e o modelo gera uma probabilidade (uma camada de unidade única com uma ativação sigmóide), usaremos a função de perda `binary_crossentropy`.\n",
        "\n",
        "Esta não é a única opção para uma função de perda; você pode, por exemplo, escolher `mean_squared_error`. Mas, geralmente, `binary_crossentropy` é melhor para lidar com probabilidades - mede a\" distância \"entre distribuições de probabilidade, ou no nosso caso, entre a distribuição da verdade da terra e as previsões.\n",
        "\n",
        "Mais tarde, quando estivermos explorando problemas de regressão (por exemplo, para prever o preço de uma casa, veremos como usar outra função de perda denominada erro quadrático médio).\n",
        "\n",
        "Agora, configure o modelo para usar um otimizador e uma função de perda:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Mr0GP-cQ-llN"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "35jv_fzP-llU"
      },
      "source": [
        "## Treinar o Modelo\n",
        "\n",
        "Treine o modelo por 20 épocas em mini-lotes de 512 amostras. São 20 iterações em todas as amostras nos tensores `x_train` e `y_train`. Durante o treinamento, monitore a perda e a precisão do modelo nas 10.000 amostras do conjunto de validação:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "tXSGrjWZ-llW"
      },
      "outputs": [],
      "source": [
        "history = model.fit(train_data.shuffle(10000).batch(512),\n",
        "                    epochs=20,\n",
        "                    validation_data=validation_data.batch(512),\n",
        "                    verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9EEGuDVuzb5r"
      },
      "source": [
        "## Avaliar o Modelo\n",
        "\n",
        "E vamos ver como o modelo funciona. Dois valores serão retornados. Perda (um número que representa nosso erro, valores mais baixos são melhores) e precisão."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "zOMKywn4zReN"
      },
      "outputs": [],
      "source": [
        "results = model.evaluate(test_data.batch(512), verbose=2)\n",
        "\n",
        "for name, value in zip(model.metrics_names, results):\n",
        "  print(\"%s: %.3f\" % (name, value))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "z1iEXVTR0Z2t"
      },
      "source": [
        "Essa abordagem bastante ingênua atinge uma precisão de cerca de 87%. Com abordagens mais avançadas, o modelo deve se aproximar de 95%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5KggXVeL-llZ"
      },
      "source": [
        "## Leitura adicional\n",
        "\n",
        "Para uma maneira mais geral de trabalhar com entradas de string e para uma análise mais detalhada do progresso da precisão e da perda durante o treinamento, dê uma olhada [aqui] (https://www.tensorflow.org/tutorials/keras/basic_text_classification)."
      ]
    }
  ]
}