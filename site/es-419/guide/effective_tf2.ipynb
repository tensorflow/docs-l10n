{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tce3stUlHN0L"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tuOe1ymfHZPu"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFdPvlXBOdUN"
      },
      "source": [
        "# Tensorflow 2 efectivo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfBg1C5NB3X0"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td><a target=\"_blank\" href=\"https://www.tensorflow.org/guide/effective_tf2\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver en TensorFlow.org</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/es-419/guide/effective_tf2.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Ejecutar en Google Colab</a></td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/es-419/guide/effective_tf2.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver en GitHub</a>\n",
        "</td>\n",
        "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/es-419/guide/effective_tf2.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Descargar bloc de notas</a>\n",
        "</td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHxb-dlhMIzW"
      },
      "source": [
        "## Descripción general\n",
        "\n",
        "En esta guía se brinda una lista de las mejores prácticas para escribir código con TensorFlow 2 (TF2). Está escrita para usuarios que han cambiado recientemente desde TensorFlow 1 (TF1) a TF2.  Para más información sobre cómo migrar código TF1 a TF2, consulte la [sección de la guía en que se trata el tema de la migración](https://tensorflow.org/guide/migrate)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUXex9ctTuDB"
      },
      "source": [
        "## Preparación\n",
        "\n",
        "Importe TensorFlow y otras dependencias para usar los ejemplos de esta guía."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IqR2PQG4ZaZ0"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ngds9zateIY8"
      },
      "source": [
        "## Recomendaciones para TensorFlow 2 idiomático"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3RdHaroMAi4"
      },
      "source": [
        "### Refactorización del código en módulos más pequeños\n",
        "\n",
        "Una buena práctica es la de refactorizar el código en funciones más pequeñas a las que llamamos cuando es necesario. Para un mejor desempeño, debería tratar de decorar los bloques de cálculo más grandes posibles en una `tf.function` (tenga en cuenta que las funciones Python anidadas llamadas por una `tf.function` no necesitan sus propias decoraciones separadas, a menos que desee usar `jit_compile` diferentes para la `tf.function`). Dependiendo de su caso de uso, podría tratarse de múltiples pasos de entrenamiento o incluso de un ciclo de entrenamiento completo. Para casos de interferencia, podría ser un solo <em>pase hacia adelante</em> del modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rua1l8et3Evd"
      },
      "source": [
        "### Ajuste de la tasa de aprendizaje predeterminada para algunos `tf.keras.optimizer`\n",
        "\n",
        "<a name=\"optimizer_defaults\"></a>\n",
        "\n",
        "Algunos optimizadores Keras tienen tasas de aprendizaje diferentes en TF2. Si nota un cambio en el comportamiento de convergencia en sus modelos, controle las tasas de aprendizaje predeterminadas.\n",
        "\n",
        "No hay cambios para `optimizers.SGD`, `optimizers.Adam` ni `optimizers.RMSprop`.\n",
        "\n",
        "Las siguientes tasas de aprendizaje han cambiado:\n",
        "\n",
        "- `optimizers.Adagrad` de `0.01` a `0.001`\n",
        "- `optimizers.Adadelta` de `1.0` a `0.001`\n",
        "- `optimizers.Adamax` de `0.002` a `0.001`\n",
        "- `optimizers.Nadam` de `0.002` a `0.001`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6LfkpsEldEV"
      },
      "source": [
        "### Use `tf.Module` y capas Keras para gestionar las variables\n",
        "\n",
        "Los `tf.Module`y las `tf.keras.layers.Layer` ofrecen propiedades convenientes en `variables` y `trainable_variables` que pueden reunir recursivamente todas las variables dependientes. Todo esto facilita la gestión de variables a nivel local a donde se están usando."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQ2U0rj1oBlc"
      },
      "source": [
        "Las capas o modelos Keras heredan de `tf.train.Checkpointable` y se integran con `@tf.function`, lo que hace posible directamente aplicar puntos de control (<em>checkpoint</em>) o exportar SavedModels de objetos Keras. No necesariamente hay que usar la API `Model.fit` de Keras para aprovechar estas integraciones.\n",
        "\n",
        "Lea la sección sobre [transferencia de aprendizaje y ajuste fino](https://www.tensorflow.org/guide/keras/transfer_learning#transfer_learning_fine-tuning_with_a_custom_training_loop) en la guía de Keras para entender cómo recopilar un subconjunto de variables relevantes con Keras."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j34MsfxWodG6"
      },
      "source": [
        "### Combinación de los `tf.data.Dataset` y la `tf.function`\n",
        "\n",
        "El paquete (`tfds`) de [conjuntos de datos de TensorFlow](https://tensorflow.org/datasets) contiene utilidades para cargar conjuntos de datos predeterminados como los objetos `tf.data.Dataset`. Para este ejemplo, puede cargar el conjunto de datos MNIST con `tfds`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BMgxaLH74_s-"
      },
      "outputs": [],
      "source": [
        "datasets, info = tfds.load(name='mnist', with_info=True, as_supervised=True)\n",
        "mnist_train, mnist_test = datasets['train'], datasets['test']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPJhEuvj5VfR"
      },
      "source": [
        "Después, prepare el conjunto de datos para entrenamiento:\n",
        "\n",
        "- Redimensione cada imagen.\n",
        "- Aleatorice el orden de los ejemplos.\n",
        "- Recolecte lotes de imágenes y etiquetas.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "StBRHtJM2S7o"
      },
      "outputs": [],
      "source": [
        "BUFFER_SIZE = 10 # Use a much larger value for real code\n",
        "BATCH_SIZE = 64\n",
        "NUM_EPOCHS = 5\n",
        "\n",
        "\n",
        "def scale(image, label):\n",
        "  image = tf.cast(image, tf.float32)\n",
        "  image /= 255\n",
        "\n",
        "  return image, label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKq14zKKFAdv"
      },
      "source": [
        "Para no hacer muy extenso el ejemplo, ajuste el conjunto de datos para que solamente devuelva 5 lotes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_J-o4YjG2mkM"
      },
      "outputs": [],
      "source": [
        "train_data = mnist_train.map(scale).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "test_data = mnist_test.map(scale).batch(BATCH_SIZE)\n",
        "\n",
        "STEPS_PER_EPOCH = 5\n",
        "\n",
        "train_data = train_data.take(STEPS_PER_EPOCH)\n",
        "test_data = test_data.take(STEPS_PER_EPOCH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XEqdkH54VM6c"
      },
      "outputs": [],
      "source": [
        "image_batch, label_batch = next(iter(train_data))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loTPH2Pz4_Oj"
      },
      "source": [
        "Use iteraciones Python regulares para iterar sobre datos de entrenamiento que entren en la memoria. De lo contrario, `tf.data.Dataset` será la mejor opción para transmitir los datos de entrenamiento desde el disco. Los conjuntos de datos son [iterables (no iteradores)](https://docs.python.org/3/glossary.html#term-iterable) y funcionan igual que los iterables de Python en ejecución <em>eager</em>. Puede utilizar por completo las funciones de preextracción o <em>streaming</em> asincrónicas de conjuntos de datos encapsulando el código en `tf.function`, que reemplaza la iteración Python con las operaciones de grafos equivalentes mediante AutoGraph.\n",
        "\n",
        "```python\n",
        "@tf.function\n",
        "def train(model, dataset, optimizer):\n",
        "  for x, y in dataset:\n",
        "    with tf.GradientTape() as tape:\n",
        "      # training=True is only needed if there are layers with different\n",
        "      # behavior during training versus inference (e.g. Dropout).\n",
        "      prediction = model(x, training=True)\n",
        "      loss = loss_fn(prediction, y)\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "```\n",
        "\n",
        "Si usa la API `Model.fit` de Keras, no tendrá que preocuparse por la iteración del conjunto de datos.\n",
        "\n",
        "```python\n",
        "model.compile(optimizer=optimizer, loss=loss_fn)\n",
        "model.fit(dataset)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSev7vZC5GJB"
      },
      "source": [
        "<a name=\"keras_training_loops\"></a>\n",
        "\n",
        "### Uso de ciclos de entrenamiento Keras\n",
        "\n",
        "Cuando no es necesario realizar un control de bajo nivel del proceso de entrenamiento, se recomienda usar los métodos integrados `fit`, `evaluate` y `predict` de Keras. Estos métodos ofrecen una interfaz uniforme para entrenar el modelo, que es independiente del tipo de implementación (secuencial, funcional o de subclase).\n",
        "\n",
        "Las ventajas que ofrecen estos métodos incluyen lo siguiente:\n",
        "\n",
        "- Aceptan arreglos Numpy, generadores de Python y `tf.data.Datasets`.\n",
        "- Aplican automáticamente regularización y pérdidas por activación.\n",
        "- Son compatibles con `tf.distribute`, donde el código de entrenamiento sigue siendo el mismo [independientemente de la configuración que tenga el hardware](distributed_training.ipynb).\n",
        "- Son compatibles con invocables arbitrarios como las pérdidas o las métricas.\n",
        "- Son compatibles con invocables como `tf.keras.callbacks.TensorBoard` y otros invocables personalizados.\n",
        "- Son ejecutantes, que usan automáticamente grafos de TensorFlow.\n",
        "\n",
        "A continuación, un ejemplo del entrenamiento de un modelo con `Dataset`. Para más detalles sobre cómo funciona, consulte los [tutoriales](https://tensorflow.org/tutorials)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uzHFCzd45Rae"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, 3, activation='relu',\n",
        "                           kernel_regularizer=tf.keras.regularizers.l2(0.02),\n",
        "                           input_shape=(28, 28, 1)),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dropout(0.1),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dense(10)\n",
        "])\n",
        "\n",
        "# Model is the full model w/o custom layers\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_data, epochs=NUM_EPOCHS)\n",
        "loss, acc = model.evaluate(test_data)\n",
        "\n",
        "print(\"Loss {}, Accuracy {}\".format(loss, acc))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQTaHTuK5S5A"
      },
      "source": [
        "<a name=\"custom_loop\"></a>\n",
        "\n",
        "### Personalización de entrenamiento y escritura del ciclo propio\n",
        "\n",
        "Si los modelos Keras le resultan útiles, pero necesita más flexibilidad y control del paso o los ciclos de entrenamiento externos, puede implementar sus propios pasos o incluso los ciclos enteros. Para más información sobre [personalización de `fit`](https://www.tensorflow.org/guide/keras/customizing_what_happens_in_fit) consulte la guía de Keras.\n",
        "\n",
        "También puede implementar muchas cosas como un `tf.keras.callbacks.Callback`.\n",
        "\n",
        "Este método tiene muchas de las ventajas que [mencionamos previamente](#keras_training_loops), pero además le permite controlar el paso de entrenamiento e incluso el ciclo externo.\n",
        "\n",
        "En un ciclo de entrenamiento estándar hay tres pasos:\n",
        "\n",
        "1. Iterar sobre un generaror Python o un `tf.data.Dataset` para obtener lotes de muestras.\n",
        "2. Usar `tf.GradientTape` para recopilar los gradientes.\n",
        "3. Usar uno de los `tf.keras.optimizers` para aplicar las actualizaciones de pesos a las variables del modelo.\n",
        "\n",
        "Recuerde:\n",
        "\n",
        "- Incluya siempre un argumento de `training` en el método `call` de los modelos y las capas en subclases.\n",
        "- Asegúrese de invocar al modelo con el argumento de `training` establecido correctamente.\n",
        "- Dependiendo del uso, las variables del modelo pueden no existir hasta que el modelo esté funcionando en un lote de datos.\n",
        "- Debe manejar manualmente algunas cosas como las pérdidas de regularización del modelo.\n",
        "\n",
        "No hay necesidad de ejecutar inicializadores variables ni de agregar dependencias de control manual. La `tf.function` se ocupa de las dependencias de control automático y de la inicialización variable en la creación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gQooejfYlQeF"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, 3, activation='relu',\n",
        "                           kernel_regularizer=tf.keras.regularizers.l2(0.02),\n",
        "                           input_shape=(28, 28, 1)),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dropout(0.1),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dense(10)\n",
        "])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(0.001)\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "@tf.function\n",
        "def train_step(inputs, labels):\n",
        "  with tf.GradientTape() as tape:\n",
        "    predictions = model(inputs, training=True)\n",
        "    regularization_loss=tf.math.add_n(model.losses)\n",
        "    pred_loss=loss_fn(labels, predictions)\n",
        "    total_loss=pred_loss + regularization_loss\n",
        "\n",
        "  gradients = tape.gradient(total_loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  for inputs, labels in train_data:\n",
        "    train_step(inputs, labels)\n",
        "  print(\"Finished epoch\", epoch)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WikxMFGgo3oZ"
      },
      "source": [
        "### Aproveche `tf.function` con el flujo de control de Python\n",
        "\n",
        "`tf.function` ofrece una forma de convertir el flujo de control dependiente de datos en equivalentes de modo grafo como `tf.cond` y `tf.while_loop`.\n",
        "\n",
        "Un lugar común donde aparece el flujo de control dependiente de datos es en los modelos secuenciales.`tf.keras.layers.RNN` encapsula una celda RNN, con lo que permite desplegar la recurrencia, ya sea de forma dinámica o estática."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n5UebfChRu4T"
      },
      "outputs": [],
      "source": [
        "class DynamicRNN(tf.keras.Model):\n",
        "\n",
        "  def __init__(self, rnn_cell):\n",
        "    super(DynamicRNN, self).__init__(self)\n",
        "    self.cell = rnn_cell\n",
        "\n",
        "  @tf.function(input_signature=[tf.TensorSpec(dtype=tf.float32, shape=[None, None, 3])])\n",
        "  def call(self, input_data):\n",
        "\n",
        "    # [batch, time, features] -> [time, batch, features]\n",
        "    input_data = tf.transpose(input_data, [1, 0, 2])\n",
        "    timesteps =  tf.shape(input_data)[0]\n",
        "    batch_size = tf.shape(input_data)[1]\n",
        "    outputs = tf.TensorArray(tf.float32, timesteps)\n",
        "    state = self.cell.get_initial_state(batch_size = batch_size, dtype=tf.float32)\n",
        "    for i in tf.range(timesteps):\n",
        "      output, state = self.cell(input_data[i], state)\n",
        "      outputs = outputs.write(i, output)\n",
        "    return tf.transpose(outputs.stack(), [1, 0, 2]), state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NhBI_SGKQVIB"
      },
      "outputs": [],
      "source": [
        "lstm_cell = tf.keras.layers.LSTMCell(units = 13)\n",
        "\n",
        "my_rnn = DynamicRNN(lstm_cell)\n",
        "outputs, state = my_rnn(tf.random.normal(shape=[10,20,3]))\n",
        "print(outputs.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "du7bn3NX7iIr"
      },
      "source": [
        "Para más información, lea la [guía `tf.function`](https://www.tensorflow.org/guide/function)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUAYhgL_NomT"
      },
      "source": [
        "### Métricas y pérdidas de estilo nuevo\n",
        "\n",
        "Tanto las métricas como las pérdidas son objetos que funcionan con ejecución <em>eager</em> y en `tf.function`.\n",
        "\n",
        "Los objetos de pérdida son invocables y esperan (`y_true` y `y_pred`) como argumentos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pf5gcwMzNs8F"
      },
      "outputs": [],
      "source": [
        "cce = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "cce([[1, 0]], [[-1.0,3.0]]).numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a89m-wRfxyfV"
      },
      "source": [
        "#### Uso de métricas para recopilar y mostrar datos\n",
        "\n",
        "Puede usar `tf.metrics` para agregar datos y `tf.summary` para registrar resúmenes y realizar la redirección a un escritor con un gestor de contexto. Los resúmenes se emiten directamente al escritor, lo que significa que debe proporcionarle el valor `step` en el sitio invocado (<em>callsite</em>).\n",
        "\n",
        "```python\n",
        "summary_writer = tf.summary.create_file_writer('/tmp/summaries')\n",
        "with summary_writer.as_default():\n",
        "  tf.summary.scalar('loss', 0.1, step=42)\n",
        "```\n",
        "\n",
        "Use `tf.metrics` para agregar datos antes de registrarlos como resúmenes. Las métricas consideran los datos con estado (stateful); acumulan valores y devuelven un resultado acumulado cuando se llama al método `result` (como `Mean.result`). Borre los valores acumulados con `Model.reset_states`.\n",
        "\n",
        "```python\n",
        "def train(model, optimizer, dataset, log_freq=10):\n",
        "  avg_loss = tf.keras.metrics.Mean(name='loss', dtype=tf.float32)\n",
        "  for images, labels in dataset:\n",
        "    loss = train_step(model, optimizer, images, labels)\n",
        "    avg_loss.update_state(loss)\n",
        "    if tf.equal(optimizer.iterations % log_freq, 0):\n",
        "      tf.summary.scalar('loss', avg_loss.result(), step=optimizer.iterations)\n",
        "      avg_loss.reset_states()\n",
        "\n",
        "def test(model, test_x, test_y, step_num):\n",
        "  # training=False is only needed if there are layers with different\n",
        "  # behavior during training versus inference (e.g. Dropout).\n",
        "  loss = loss_fn(model(test_x, training=False), test_y)\n",
        "  tf.summary.scalar('loss', loss, step=step_num)\n",
        "\n",
        "train_summary_writer = tf.summary.create_file_writer('/tmp/summaries/train')\n",
        "test_summary_writer = tf.summary.create_file_writer('/tmp/summaries/test')\n",
        "\n",
        "with train_summary_writer.as_default():\n",
        "  train(model, optimizer, dataset)\n",
        "\n",
        "with test_summary_writer.as_default():\n",
        "  test(model, test_x, test_y, optimizer.iterations)\n",
        "```\n",
        "\n",
        "Visualice los resúmenes apuntando TensorBoard al directorio de registros de resumen:\n",
        "\n",
        "```shell\n",
        "tensorboard --logdir /tmp/summaries\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tx7FyM_RHwJ"
      },
      "source": [
        "Use la API `tf.summary` para escribir los datos de resumen para la visualización en TensorBoard. Para más información, lea la <a href=\"https://www.tensorflow.org/tensorboard/migrate#in_tf_2x\" data-md-type=\"link\">guía de `tf.summary`</a>."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HAbA0fKW58CH"
      },
      "outputs": [],
      "source": [
        "# Create the metrics\n",
        "loss_metric = tf.keras.metrics.Mean(name='train_loss')\n",
        "accuracy_metric = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
        "\n",
        "@tf.function\n",
        "def train_step(inputs, labels):\n",
        "  with tf.GradientTape() as tape:\n",
        "    predictions = model(inputs, training=True)\n",
        "    regularization_loss=tf.math.add_n(model.losses)\n",
        "    pred_loss=loss_fn(labels, predictions)\n",
        "    total_loss=pred_loss + regularization_loss\n",
        "\n",
        "  gradients = tape.gradient(total_loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "  # Update the metrics\n",
        "  loss_metric.update_state(total_loss)\n",
        "  accuracy_metric.update_state(labels, predictions)\n",
        "\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  # Reset the metrics\n",
        "  loss_metric.reset_states()\n",
        "  accuracy_metric.reset_states()\n",
        "\n",
        "  for inputs, labels in train_data:\n",
        "    train_step(inputs, labels)\n",
        "  # Get the metric results\n",
        "  mean_loss=loss_metric.result()\n",
        "  mean_accuracy = accuracy_metric.result()\n",
        "\n",
        "  print('Epoch: ', epoch)\n",
        "  print('  loss:     {:.3f}'.format(mean_loss))\n",
        "  print('  accuracy: {:.3f}'.format(mean_accuracy))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bG9AaMzih3eh"
      },
      "source": [
        "#### Nombres de métricas de Keras\n",
        "\n",
        "<a name=\"keras_metric_names\"></a>\n",
        "\n",
        "Los modelos Keras conservan consistencia con respecto a la administración de los nombres de las métricas. Cuando se pasa una cadena de caracteres (string) en la lista de métricas, esa cadena *exacta* se usa como el `name` de la métrica. Estos nombres se ven en el objeto de historia que devuelve `model.fit` y en los registros pasados a `keras.callbacks`. Se establece a la cadena que se pasó en la lista de métricas. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1iODIsGDgyYd"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    optimizer = tf.keras.optimizers.Adam(0.001),\n",
        "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics = ['acc', 'accuracy', tf.keras.metrics.SparseCategoricalAccuracy(name=\"my_accuracy\")])\n",
        "history = model.fit(train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8oGzs_TlisKJ"
      },
      "outputs": [],
      "source": [
        "history.history.keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaB2z2XIyhcr"
      },
      "source": [
        "### Depuración\n",
        "\n",
        "Use la ejecución <em>eager</em> para correr el código paso a paso para inspeccionar formas, tipos de datos y valores. Ciertas API, como `tf.function`, `tf.keras`, etc. están diseñadas para usar ejecución de <em>Graph</em> (grafos) por motivos de mejor desempeño y portabilidad. Cuando realice la depuración, use `tf.config.run_functions_eagerly(True)` para aplicar la ejecución <em>eager</em> dentro de este código.\n",
        "\n",
        "Por ejemplo:\n",
        "\n",
        "```python\n",
        "@tf.function\n",
        "def f(x):\n",
        "  if x > 0:\n",
        "    import pdb\n",
        "    pdb.set_trace()\n",
        "    x = x + 1\n",
        "  return x\n",
        "\n",
        "tf.config.run_functions_eagerly(True)\n",
        "f(tf.constant(1))\n",
        "```\n",
        "\n",
        "```\n",
        ">>> f()\n",
        "-> x = x + 1\n",
        "(Pdb) l\n",
        "  6     @tf.function\n",
        "  7     def f(x):\n",
        "  8       if x > 0:\n",
        "  9         import pdb\n",
        " 10         pdb.set_trace()\n",
        " 11  ->     x = x + 1\n",
        " 12       return x\n",
        " 13\n",
        " 14     tf.config.run_functions_eagerly(True)\n",
        " 15     f(tf.constant(1))\n",
        "[EOF]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdvGF2FvbBXZ"
      },
      "source": [
        "Esto también funciona dentro de los modelos Keras y de otras API compatibles con la ejecución <em>eager</em>:\n",
        "\n",
        "```python\n",
        "class CustomModel(tf.keras.models.Model):\n",
        "\n",
        "  @tf.function\n",
        "  def call(self, input_data):\n",
        "    if tf.reduce_mean(input_data) > 0:\n",
        "      return input_data\n",
        "    else:\n",
        "      import pdb\n",
        "      pdb.set_trace()\n",
        "      return input_data // 2\n",
        "\n",
        "\n",
        "tf.config.run_functions_eagerly(True)\n",
        "model = CustomModel()\n",
        "model(tf.constant([-2, -4]))\n",
        "```\n",
        "\n",
        "```\n",
        ">>> call()\n",
        "-> return input_data // 2\n",
        "(Pdb) l\n",
        " 10         if tf.reduce_mean(input_data) > 0:\n",
        " 11           return input_data\n",
        " 12         else:\n",
        " 13           import pdb\n",
        " 14           pdb.set_trace()\n",
        " 15  ->       return input_data // 2\n",
        " 16\n",
        " 17\n",
        " 18     tf.config.run_functions_eagerly(True)\n",
        " 19     model = CustomModel()\n",
        " 20     model(tf.constant([-2, -4]))\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0-F-bvJXKD8"
      },
      "source": [
        "Notas:\n",
        "\n",
        "- Los métodos `tf.keras.Model` como `fit`, `evaluate` y `predict` ejecutan [graphs](https://www.tensorflow.org/guide/intro_to_graphs) con `tf.function` en su funcionamiento interno.\n",
        "\n",
        "- Cuando use `tf.keras.Model.compile`, establezca `run_eagerly = True` para deshabilitar que la lógica `Model` se encapsule en `tf.function`.\n",
        "\n",
        "- Use `tf.data.experimental.enable_debug_mode` para habilitar el modo de depuración para `tf.data`. Para más detalles, lea los [documentos de la API](https://www.tensorflow.org/api_docs/python/tf/data/experimental/enable_debug_mode).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxa5yKK7bym0"
      },
      "source": [
        "### No mantenga `tf.Tensors` en los objetos\n",
        "\n",
        "Estos objetos de tensores pueden crearse en un `tf.function` o en el contexto <em>eager</em>, entonces, estos tensores se comportan de un modo diferente. Siempre use los `tf.Tensor` solamente para valores intermedios.\n",
        "\n",
        "Para dar seguimiento al estado, use las `tf.Variable`, ya que siempre se pueden usar desde cualquiera de los dos contextos. Para más información, lea la <a href=\"https://www.tensorflow.org/guide/variable\" data-md-type=\"link\">guía de `tf.Variable`</a>.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FdXLLYa2uAyx"
      },
      "source": [
        "## Recursos y lecturas complementarias\n",
        "\n",
        "- Para más información sobre cómo usar TF2, lea las [guías](https://tensorflow.org/guide) y los [tutoriales](https://tensorflow.org/tutorials).\n",
        "\n",
        "- Si antes usó TF1.x, se le recomienda migrar el código a TF2. Para más detalles, lea las [guías sobre migración](https://tensorflow.org/guide/migrate)."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "effective_tf2.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
