{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tce3stUlHN0L"
      },
      "source": [
        "##### Copyright 2018 The TensorFlow Authors.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tuOe1ymfHZPu"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfBg1C5NB3X0"
      },
      "source": [
        "# Cómo utilizar TPUs\n",
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td><a target=\"_blank\" href=\"https://www.tensorflow.org/guide/tpu\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver en TensorFlow.org</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/es-419/guide/tpu.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Ejecutar en Google Colab</a></td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/es-419/guide/tpu.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver el código fuente en GitHub</a> </td>\n",
        "  <td><a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/es-419/guide/tpu.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Descargar el bloc de notas</a></td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ys81cOhXOWUP"
      },
      "source": [
        "En esta guía se muestra cómo realizar un entrenamiento básico en las [Unidades de Procesamiento de Tensores (TPUs)](https://cloud.google.com/tpu/) y TPU Pods, una colección de dispositivos TPU conectados por interfaces de red de alta velocidad especializadas, con `tf.keras` y bucles de entrenamiento personalizados.\n",
        "\n",
        "Las TPU son circuitos integrados de aplicación específica (ASIC) desarrollados a medida por Google que se utilizan para acelerar las cargas de trabajo de aprendizaje automático. Están disponibles en [Google Colab](https://colab.research.google.com/), [TPU Research Cloud](https://sites.research.google/trc/) y [Cloud TPU](https://cloud.google.com/tpu)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ek5Hop74NVKm"
      },
      "source": [
        "## Preparación"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebf7f8489bb7"
      },
      "source": [
        "Antes de ejecutar este bloc de notas de Colab, asegúrese de que su acelerador de hardware es un TPU verificando la configuración del bloc de notas: **Runtime** &gt; **Change runtime type** &gt; **Hardware accelerator** &gt; **TPU**.\n",
        "\n",
        "Importe algunas bibliotecas necesarias, incluyendo los conjuntos de datos de TensorFlow:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cw0WRaChRxTL"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import os\n",
        "import tensorflow_datasets as tfds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDWaRxSpwBN1"
      },
      "source": [
        "## Inicialización de la TPU\n",
        "\n",
        "Las TPUs normalmente son [TPUs en la nube](https://cloud.google.com/tpu/docs/) que trabajan, las cuales son diferentes del proceso local que ejecuta el programa Python del usuario. Por lo tanto, es necesario hacer algún trabajo de inicialización para conectarse al conjunto remoto e inicializar las TPUs. Tenga en cuenta que el argumento `tpu` de `tf.distribute.cluster_resolver.TPUClusterResolver` es una dirección especial sólo para Colab. Si está ejecutando su código en Google Compute Engine (GCE), debe pasar en su lugar el nombre de su TPU en la nube."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCqWMqvtwOLs"
      },
      "source": [
        "Nota: El código de inicialización del TPU tiene que estar al principio de su programa."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dKPqF8d1wJCV"
      },
      "outputs": [],
      "source": [
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "# This is the TPU initialization code that has to be at the beginning.\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "print(\"All devices: \", tf.config.list_logical_devices('TPU'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mv7kehTZ1Lq_"
      },
      "source": [
        "## Colocación manual en el dispositivo\n",
        "\n",
        "Después de inicializar la TPU, puede utilizar la colocación manual de dispositivos para situar el cálculo en un único dispositivo TPU:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XRZ4kMoxBNND"
      },
      "outputs": [],
      "source": [
        "a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
        "b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
        "\n",
        "with tf.device('/TPU:0'):\n",
        "  c = tf.matmul(a, b)\n",
        "\n",
        "print(\"c device: \", c.device)\n",
        "print(c)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_NJm-kgFO0cC"
      },
      "source": [
        "## Estrategias de distribución\n",
        "\n",
        "Normalmente, su modelo se ejecuta en múltiples TPUs de forma paralela a los datos. Para distribuir su modelo en múltiples TPUs (así como múltiples GPUs o múltiples máquinas), TensorFlow ofrece la API `tf.distribute.Strategy`. Puede reemplazar su estrategia de distribución y el modelo se ejecutará en cualquier dispositivo (TPU) dado. Obtenga más información en la guía [Entrenamiento distribuido con TensorFlow](./distributed_training.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcDPMZs-9uLJ"
      },
      "source": [
        "El uso de la opción `tf.distribute.TPUStrategy` implementa el entrenamiento distribuido sincronizado. Las TPUs proporcionan su propia implementación de operaciones eficientes de reducción total y otras operaciones colectivas entre varios núcleos de TPU, que se utilizan en `TPUStrategy`.\n",
        "\n",
        "Para demostrarlo, cree un objeto `tf.distribute.TPUStrategy`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7SO23K8oRpjI"
      },
      "outputs": [],
      "source": [
        "strategy = tf.distribute.TPUStrategy(resolver)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlaAmswWPsU6"
      },
      "source": [
        "Para replicar un cálculo de modo que pueda ejecutarse en todos los núcleos de la TPU, puede transferirlo a la API `Strategy.run`. A continuación se muestra un ejemplo en el que todos los núcleos reciben las mismas entradas `(a, b)` y realizan la multiplicación de matrices en cada núcleo de forma independiente. Las salidas serán los valores de todas las réplicas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-90CL5uFPTOa"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def matmul_fn(x, y):\n",
        "  z = tf.matmul(x, y)\n",
        "  return z\n",
        "\n",
        "z = strategy.run(matmul_fn, args=(a, b))\n",
        "print(z)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxgYl6kGHJLc"
      },
      "source": [
        "## Clasificación en TPUs\n",
        "\n",
        "Después de haber cubierto los conceptos básicos, considere un ejemplo más concreto. Esta sección muestra cómo utilizar la estrategia de distribución -`tf.distribute.TPUStrategy`- para entrenar un modelo Keras en una TPU en la nube."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKRALGgt_kCo"
      },
      "source": [
        "### Definir un modelo Keras\n",
        "\n",
        "Comenzamos con la definición de un modelo [`Sequential` de Keras](https://www.tensorflow.org/guide/keras/sequential_model) para la clasificación de imágenes en el conjunto de datos MNIST. No es diferente de lo que utilizaría si estuviera entrenando en CPUs o GPUs. Tenga en cuenta que la creación del modelo Keras tiene que estar dentro del `Strategy.scope`, por lo que las variables se pueden crear en cada dispositivo TPU. Otras partes del código no necesitan estar dentro del ámbito `Strategy`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DiBiN-Z_R7P7"
      },
      "outputs": [],
      "source": [
        "def create_model():\n",
        "  regularizer = tf.keras.regularizers.L2(1e-5)\n",
        "  return tf.keras.Sequential(\n",
        "      [tf.keras.layers.Conv2D(256, 3, input_shape=(28, 28, 1),\n",
        "                              activation='relu',\n",
        "                              kernel_regularizer=regularizer),\n",
        "       tf.keras.layers.Conv2D(256, 3,\n",
        "                              activation='relu',\n",
        "                              kernel_regularizer=regularizer),\n",
        "       tf.keras.layers.Flatten(),\n",
        "       tf.keras.layers.Dense(256,\n",
        "                             activation='relu',\n",
        "                             kernel_regularizer=regularizer),\n",
        "       tf.keras.layers.Dense(128,\n",
        "                             activation='relu',\n",
        "                             kernel_regularizer=regularizer),\n",
        "       tf.keras.layers.Dense(10,\n",
        "                             kernel_regularizer=regularizer)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-2qaXgfyONQ"
      },
      "source": [
        "Este modelo pone términos de regularización L2 en los pesos de cada capa, de modo que el bucle de entrenamiento personalizado de abajo puede mostrar cómo los recoge de `Model.losses`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYOYjYTg_31l"
      },
      "source": [
        "### Carga del conjunto de datos.\n",
        "\n",
        "El uso eficiente de la API `tf.data.Dataset` es fundamental cuando se utiliza una TPU en la nube. Puede obtener más información sobre el rendimiento de los conjuntos de datos en la [Guía de rendimiento respecto a las canalizaciones de entrada](./data_performance.ipynb).\n",
        "\n",
        "Si está utilizando [Nodos UTP](https://cloud.google.com/tpu/docs/managing-tpus-tpu-vm), necesita almacenar todos los archivos de datos leídos por el `Dataset` de TensorFlow en [cubos de Google Cloud Storage (GCS)](https://cloud.google.com/tpu/docs/storage-buckets). Si utiliza [TPU VMs](https://cloud.google.com/tpu/docs/users-guide-tpu-vm), puede almacenar los datos donde desee. Para obtener más información sobre los nodos TPU y las máquinas virtuales TPU, consulte la documentación [Arquitectura del sistema TPU](https://cloud.google.com/tpu/docs/system-architecture-tpu-vm).\n",
        "\n",
        "Para la mayoría de los casos de uso, se recomienda convertir los datos en el formato `TFRecord` y utilizar un `tf.data.TFRecordDataset` para leerlos. Consulte el tutorial [TFRecord y tf.Example](../tutorials/load_data/tfrecord.ipynb) para obtener más detalles sobre cómo hacerlo. No es un requisito obligatorio y puede utilizar otros lectores de conjuntos de datos, como `tf.data.FixedLengthRecordDataset` o `tf.data.TextLineDataset`.\n",
        "\n",
        "Puede cargar pequeños conjuntos de datos enteros en la memoria utilizando `tf.data.Dataset.cache`.\n",
        "\n",
        "Independientemente del formato de datos utilizado, se recomienda encarecidamente utilizar archivos de gran tamaño, del orden de 100 MB. Esto es particularmente importante en esta configuración en red, ya que la sobrecarga de abrir un archivo es significativamente mayor.\n",
        "\n",
        "Como se muestra en el siguiente código, debe utilizar el módulo de conjuntos de datos de Tensorflow `tfds.load` para obtener una copia de los datos de entrenamiento y prueba MNIST. Tenga en cuenta que `try_gcs` es específico para utilizar una copia que esté disponible en un bucket GCS público. Si no se especifica esto, la TPU no podrá acceder a los datos descargados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "noAd416KSCo7"
      },
      "outputs": [],
      "source": [
        "def get_dataset(batch_size, is_training=True):\n",
        "  split = 'train' if is_training else 'test'\n",
        "  dataset, info = tfds.load(name='mnist', split=split, with_info=True,\n",
        "                            as_supervised=True, try_gcs=True)\n",
        "\n",
        "  # Normalize the input data.\n",
        "  def scale(image, label):\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    image /= 255.0\n",
        "    return image, label\n",
        "\n",
        "  dataset = dataset.map(scale)\n",
        "\n",
        "  # Only shuffle and repeat the dataset in training. The advantage of having an\n",
        "  # infinite dataset for training is to avoid the potential last partial batch\n",
        "  # in each epoch, so that you don't need to think about scaling the gradients\n",
        "  # based on the actual batch size.\n",
        "  if is_training:\n",
        "    dataset = dataset.shuffle(10000)\n",
        "    dataset = dataset.repeat()\n",
        "\n",
        "  dataset = dataset.batch(batch_size)\n",
        "\n",
        "  return dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgUC6A-zCMEr"
      },
      "source": [
        "### Entrene el modelo utilizando las API de alto nivel de Keras\n",
        "\n",
        "Puede entrenar su modelo con las API de Keras `Model.fit` y `Model.compile`. . No hay nada específico de TPU en este paso: escriba el código si utiliza múltiples GPU y una `MirroredStrategy` en vez de `TPUStrategy`. Puede obtener más información en el tutorial [Entrenamiento distribuido con Keras](../tutorials/distribute/keras.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ubmDchPqSIx0"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "  model = create_model()\n",
        "  model.compile(optimizer='adam',\n",
        "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                metrics=['sparse_categorical_accuracy'])\n",
        "\n",
        "batch_size = 200\n",
        "steps_per_epoch = 60000 // batch_size\n",
        "validation_steps = 10000 // batch_size\n",
        "\n",
        "train_dataset = get_dataset(batch_size, is_training=True)\n",
        "test_dataset = get_dataset(batch_size, is_training=False)\n",
        "\n",
        "model.fit(train_dataset,\n",
        "          epochs=5,\n",
        "          steps_per_epoch=steps_per_epoch,\n",
        "          validation_data=test_dataset,\n",
        "          validation_steps=validation_steps)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hSGBIYtUugJ"
      },
      "source": [
        "Para reducir la sobrecarga de Python y maximizar el rendimiento de su TPU, pase el argumento `steps_per_execution` al comando `Model.compile` de Keras. En este ejemplo, se aumenta el rendimiento en aproximadamente un 50%:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M6e3aVVLUorL"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "  model = create_model()\n",
        "  model.compile(optimizer='adam',\n",
        "                # Anything between 2 and `steps_per_epoch` could help here.\n",
        "                steps_per_execution = 50,\n",
        "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                metrics=['sparse_categorical_accuracy'])\n",
        "\n",
        "model.fit(train_dataset,\n",
        "          epochs=5,\n",
        "          steps_per_epoch=steps_per_epoch,\n",
        "          validation_data=test_dataset,\n",
        "          validation_steps=validation_steps)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rRALBZNCO4A"
      },
      "source": [
        "### Entrene el modelo utilizando un bucle de entrenamiento personalizado\n",
        "\n",
        "También puede crear y entrenar su modelo utilizando `tf.function` y `tf.distribute` directamente. Puede utilizar la API `Strategy.experimental_distribute_datasets_from_function` para distribuir el `tf.data.Dataset` dado una función de conjunto de datos. Tenga en cuenta que en el siguiente ejemplo el tamaño del lote que se pasa al `Dataset` es el tamaño del lote por réplica en vez del tamaño del lote global. Para obtener más información, consulte el tutorial [Entrenamiento personalizado con `tf.distribute.Strategy`](../tutorials/distribute/custom_training.ipynb).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxdgXPAL6iFE"
      },
      "source": [
        "En primer lugar, cree el modelo, los conjuntos de datos y las `tf.function`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9aHhqwao2Fxi"
      },
      "outputs": [],
      "source": [
        "# Create the model, optimizer and metrics inside the `tf.distribute.Strategy`\n",
        "# scope, so that the variables can be mirrored on each device.\n",
        "with strategy.scope():\n",
        "  model = create_model()\n",
        "  optimizer = tf.keras.optimizers.Adam()\n",
        "  training_loss = tf.keras.metrics.Mean('training_loss', dtype=tf.float32)\n",
        "  training_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
        "      'training_accuracy', dtype=tf.float32)\n",
        "\n",
        "# Calculate per replica batch size, and distribute the `tf.data.Dataset`s\n",
        "# on each TPU worker.\n",
        "per_replica_batch_size = batch_size // strategy.num_replicas_in_sync\n",
        "\n",
        "train_dataset = strategy.experimental_distribute_datasets_from_function(\n",
        "    lambda _: get_dataset(per_replica_batch_size, is_training=True))\n",
        "\n",
        "@tf.function\n",
        "def train_step(iterator):\n",
        "  \"\"\"The step function for one training step.\"\"\"\n",
        "\n",
        "  def step_fn(inputs):\n",
        "    \"\"\"The computation to run on each TPU device.\"\"\"\n",
        "    images, labels = inputs\n",
        "    with tf.GradientTape() as tape:\n",
        "      logits = model(images, training=True)\n",
        "      per_example_loss = tf.keras.losses.sparse_categorical_crossentropy(\n",
        "          labels, logits, from_logits=True)\n",
        "      loss = tf.nn.compute_average_loss(per_example_loss)\n",
        "      model_losses = model.losses\n",
        "      if model_losses:\n",
        "        loss += tf.nn.scale_regularization_loss(tf.add_n(model_losses))\n",
        "\n",
        "    grads = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(list(zip(grads, model.trainable_variables)))\n",
        "    training_loss.update_state(loss * strategy.num_replicas_in_sync)\n",
        "    training_accuracy.update_state(labels, logits)\n",
        "\n",
        "  strategy.run(step_fn, args=(next(iterator),))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ibi7Z97V6xsQ"
      },
      "source": [
        "Después, ejecute el bucle de entrenamiento:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1du5cXWt6Vtw"
      },
      "outputs": [],
      "source": [
        "steps_per_eval = 10000 // batch_size\n",
        "\n",
        "train_iterator = iter(train_dataset)\n",
        "for epoch in range(5):\n",
        "  print('Epoch: {}/5'.format(epoch))\n",
        "\n",
        "  for step in range(steps_per_epoch):\n",
        "    train_step(train_iterator)\n",
        "  print('Current step: {}, training loss: {}, training accuracy: {}%'.format(\n",
        "      optimizer.iterations.numpy(),\n",
        "      round(float(training_loss.result()), 4),\n",
        "      round(float(training_accuracy.result()) * 100, 2)))\n",
        "  training_loss.reset_states()\n",
        "  training_accuracy.reset_states()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnZJUM3qIjKu"
      },
      "source": [
        "### Cómo mejorar el rendimiento con varios pasos dentro de `tf.function`\n",
        "\n",
        "Puede mejorar el rendimiento ejecutando varios pasos dentro de una `tf.function`. Esto se consigue envolviendo la llamada `Strategy.run` con un `tf.range` dentro de `tf.function`, y AutoGraph lo convertirá en un `tf.while_loop` en el trabajador de la TPU. Puede obtener más información sobre `tf.function`s en la guía <a data-md-type=\"raw_html\" href=\"./function.ipynb\">Mejorar el rendimiento con `tf.function`</a>.\n",
        "\n",
        "A pesar de mejorar el rendimiento, hay desventajas con este método en comparación con la ejecución de un solo paso dentro de un `tf.function`. Ejecutar múltiples pasos en un `tf.function` es menos flexible, no puede ejecutar cosas eagerly o un código Python arbitrario dentro de los pasos.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2grYvXLzJYkP"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def train_multiple_steps(iterator, steps):\n",
        "  \"\"\"The step function for one training step.\"\"\"\n",
        "\n",
        "  def step_fn(inputs):\n",
        "    \"\"\"The computation to run on each TPU device.\"\"\"\n",
        "    images, labels = inputs\n",
        "    with tf.GradientTape() as tape:\n",
        "      logits = model(images, training=True)\n",
        "      per_example_loss = tf.keras.losses.sparse_categorical_crossentropy(\n",
        "          labels, logits, from_logits=True)\n",
        "      loss = tf.nn.compute_average_loss(per_example_loss)\n",
        "      model_losses = model.losses\n",
        "      if model_losses:\n",
        "        loss += tf.nn.scale_regularization_loss(tf.add_n(model_losses))\n",
        "    grads = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(list(zip(grads, model.trainable_variables)))\n",
        "    training_loss.update_state(loss * strategy.num_replicas_in_sync)\n",
        "    training_accuracy.update_state(labels, logits)\n",
        "\n",
        "  for _ in tf.range(steps):\n",
        "    strategy.run(step_fn, args=(next(iterator),))\n",
        "\n",
        "# Convert `steps_per_epoch` to `tf.Tensor` so the `tf.function` won't get\n",
        "# retraced if the value changes.\n",
        "train_multiple_steps(train_iterator, tf.convert_to_tensor(steps_per_epoch))\n",
        "\n",
        "print('Current step: {}, training loss: {}, training accuracy: {}%'.format(\n",
        "      optimizer.iterations.numpy(),\n",
        "      round(float(training_loss.result()), 4),\n",
        "      round(float(training_accuracy.result()) * 100, 2)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBKVhMvWjibf"
      },
      "source": [
        "## Siguientes pasos\n",
        "\n",
        "Para obtener más información sobre las TPU en la nube y cómo utilizarlas:\n",
        "\n",
        "- [Google Cloud TPU](https://cloud.google.com/tpu): La página de inicio de Google Cloud TPU.\n",
        "- [Documentación de Google Cloud TPU](https://cloud.google.com/tpu/docs/): La documentación de Google Cloud TPU, incluye:\n",
        "    - [Introducción a las TPU en la nube](https://cloud.google.com/tpu/docs/intro-to-tpu): Una visión general del trabajo con TPUs en la nube.\n",
        "    - [Inicios rápidos de la TPU en la nube](https://cloud.google.com/tpu/docs/quick-starts): Introducciones rápidas para trabajar con máquinas virtuales de la TPU en la nube utilizando TensorFlow y otros marcos principales de aprendizaje automático.\n",
        "- [Los blocs de notas de Google Cloud TPU Colab](https://cloud.google.com/tpu/docs/colabs): Ejemplos de entrenamiento de extremo a extremo.\n",
        "- [Guía de rendimiento de Google Cloud TPU](https://cloud.google.com/tpu/docs/performance-guide): Mejore aún más el rendimiento de la TPU en la nube ajustando los parámetros de la configuración de la TPU en la nube para su aplicación.\n",
        "- [Entrenamiento distribuido con TensorFlow: Cómo utilizar estrategias de distribución, incluyendo `tf.distribute.TPUStrategy`, con ejemplos que muestran las prácticas recomendadas.](./distributed_training.ipynb)\n",
        "- Incorporaciones para la TPU: TensorFlow incluye soporte especializado para el entrenamiento de incrustaciones en las TPUs mediante `tf.tpu.experimental.embedding`. Además, [Recomendadores de TensorFlow](https://www.tensorflow.org/recommenders) tiene `tfrs.layers.embedding.TPUEmbedding`. Las incrustaciones proporcionan representaciones eficientes y densas, que capturan similitudes y relaciones complejas entre características. El soporte de incorporación específico de las TPU de TensorFlow le permite entrenar incorporaciones que son más grandes que la memoria de un solo dispositivo TPU, y utilizar entradas dispersas e irregulares en las TPU.\n",
        "- [Nube de investigación en la TPU (TRC)](https://sites.research.google/trc/about/): TRC permite a los investigadores solicitar acceso a un conjunto de más de 1,000 dispositivos de la TPU en la nube.\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [],
      "name": "tpu.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
