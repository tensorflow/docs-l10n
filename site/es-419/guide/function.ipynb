{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISubpr_SSsiM"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow Authors.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "3jTMb1dySr3V"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6DWfyNThSziV"
      },
      "source": [
        "# Mejor rendimiento con tf.function\n",
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td><a target=\"_blank\" href=\"https://www.tensorflow.org/guide/function\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver en TensorFlow.org</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/es-419/guide/function.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Ejecutar en Google Colab</a></td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/es-419/guide/function.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver fuente en GitHub</a>\n",
        "</td>\n",
        "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/es-419/guide/function.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Descargar bloc de notas</a>\n",
        "</td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J122XQYG7W6w"
      },
      "source": [
        "En TensorFlow 2, la [ejecución eager](eager.ipynb) está activada de forma predeterminada. La interfaz de usuario es intuitiva y flexible (ejecutar operaciones puntuales es mucho más fácil y rápido), pero esto puede ir en detrimento del rendimiento y la capacidad de implementación.\n",
        "\n",
        "Puede usar `tf.function` para crear grafos a partir de sus programas. Se trata de una herramienta de transformación que crea grafos de flujo de datos independientes de Python a partir de su código Python. Esto le ayudará a crear modelos portátiles y de alto rendimiento, y es necesario usar `SavedModel`.\n",
        "\n",
        "Esta guía le ayudará a conceptualizar cómo funciona `tf.function` por dentro, para que pueda usarlo con eficacia.\n",
        "\n",
        "Las principales conclusiones y recomendaciones son:\n",
        "\n",
        "- Depure en modo eager, luego decore con `@tf.function`.\n",
        "- No dependa de los efectos secundarios de Python, como la mutación de objetos o la anexión de listas.\n",
        "- `tf.function` funciona mejor con las ops de TensorFlow; las llamadas de NumPy y Python se convierten en constantes.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SjvqpgepHJPd"
      },
      "source": [
        "## Preparación"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "otIdN1TS8N7S"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0xDjO4SHLUD"
      },
      "source": [
        "Defina una función ayudante para demostrar los tipos de errores que puede encontrar:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D25apou9IOXa"
      },
      "outputs": [],
      "source": [
        "import traceback\n",
        "import contextlib\n",
        "\n",
        "# Some helper code to demonstrate the kinds of errors you might encounter.\n",
        "@contextlib.contextmanager\n",
        "def assert_raises(error_class):\n",
        "  try:\n",
        "    yield\n",
        "  except error_class as e:\n",
        "    print('Caught expected exception \\n  {}:'.format(error_class))\n",
        "    traceback.print_exc(limit=2)\n",
        "  except Exception as e:\n",
        "    raise e\n",
        "  else:\n",
        "    raise Exception('Expected {} to be raised but no error was raised!'.format(\n",
        "        error_class))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPSfepzTHThq"
      },
      "source": [
        "## Conceptos básicos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNwYTIJ8r56W"
      },
      "source": [
        "### Uso\n",
        "\n",
        "Una `Function` que usted defina (por ejemplo, aplicando el decorador `@tf.function`) es igual que una operación central de TensorFlow: Puede ejecutarse de forma eager; puede calcular gradientes; etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SbtT1-Wm70F2"
      },
      "outputs": [],
      "source": [
        "@tf.function  # The decorator converts `add` into a `Function`.\n",
        "def add(a, b):\n",
        "  return a + b\n",
        "\n",
        "add(tf.ones([2, 2]), tf.ones([2, 2]))  #  [[2., 2.], [2., 2.]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uP-zUelB8DbX"
      },
      "outputs": [],
      "source": [
        "v = tf.Variable(1.0)\n",
        "with tf.GradientTape() as tape:\n",
        "  result = add(v, 1.0)\n",
        "tape.gradient(result, v)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocWZvqrmHnmX"
      },
      "source": [
        "Puede usar `Function`s dentro de otras `Function`s."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l5qRjdbBVdU6"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def dense_layer(x, w, b):\n",
        "  return add(tf.matmul(x, w), b)\n",
        "\n",
        "dense_layer(tf.ones([3, 2]), tf.ones([2, 2]), tf.ones([2]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "piBhz7gYsHqU"
      },
      "source": [
        "`Function`s puede ser más rápido que el código eager, especialmente para grafos con muchas ops pequeñas. Pero para grafos con unas pocas ops costosas (como las convoluciones), es posible que no se vea mucho aumento de la velocidad.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zuXt4wRysI03"
      },
      "outputs": [],
      "source": [
        "import timeit\n",
        "conv_layer = tf.keras.layers.Conv2D(100, 3)\n",
        "\n",
        "@tf.function\n",
        "def conv_fn(image):\n",
        "  return conv_layer(image)\n",
        "\n",
        "image = tf.zeros([1, 200, 200, 100])\n",
        "# Warm up\n",
        "conv_layer(image); conv_fn(image)\n",
        "print(\"Eager conv:\", timeit.timeit(lambda: conv_layer(image), number=10))\n",
        "print(\"Function conv:\", timeit.timeit(lambda: conv_fn(image), number=10))\n",
        "print(\"Note how there's not much difference in performance for convolutions\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZ4Do2AV80cO"
      },
      "source": [
        "### Trazado\n",
        "\n",
        "Esta sección expone cómo `Función` funciona por dentro, incluyendo detalles de implementación *que pueden cambiar en el futuro*. De todos modos, en cuanto entienda por qué y cuándo se produce el trazado, ¡le resultará mucho más fácil usar `tf.function` con eficacia!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhpUtRqsXoyM"
      },
      "source": [
        "#### ¿Qué es el \"trazado\"?\n",
        "\n",
        "Una `Function` ejecuta su programa en un [Graph de TensorFlow](https://www.tensorflow.org/guide/intro_to_graphs#what_are_graphs). Sin embargo, un `tf.Graph` no puede representar todas las cosas que usted escribiría en un programa TensorFlow eager. Por ejemplo, Python admite el polimorfismo, pero `tf.Graph` requiere que sus entradas tengan un tipo de datos y una dimensión especificados. O puede realizar tareas secundarias como leer argumentos de la línea de comandos, lanzar un error o trabajar con un objeto Python más complejo; ninguna de estas cosas puede ejecutarse en un `tf.Graph`.\n",
        "\n",
        "`Function` cubre este vacío al separar su código en dos etapas:\n",
        "\n",
        "1. En la primera etapa, llamada \"**trazado**\", `Function` crea un nuevo `tf.Graph`. El código Python se ejecuta normalmente, pero todas las operaciones TensorFlow (como sumar dos Tensores) están *aplazadas*: son capturadas por el `tf.Graph` y no se ejecutan.\n",
        "\n",
        "2. En la segunda etapa, se ejecuta un `tf.Graph` que contiene todo lo que se aplazó en la primera etapa. Esta etapa es mucho más rápida que la etapa de trazado.\n",
        "\n",
        "Dependiendo de sus entradas, `Function` no siempre ejecutará la primera etapa cuando sea llamada. Vea más abajo las [\"Reglas de trazado\"](#rules_of_tracing) si quiere entender mejor cómo toma esa determinación. TensorFlow tiene un alto rendimiento porque se salta la primera etapa y sólo ejecuta la segunda.\n",
        "\n",
        "Cuando `Function` sí decide trazar, la etapa de trazado es seguida inmediatamente por la segunda etapa, por lo que llamar a `Function` tanto crea como ejecuta el `tf.Graph`. Más adelante verá cómo puede ejecutar sólo la etapa de trazado con [`get_concrete_function`](#obtaining_concrete_functions)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7scSzLx662f"
      },
      "source": [
        "Cuando se pasan argumentos de distinto tipo a una `Function`, se ejecutan ambas etapas:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kojmJrgq8U9v"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def double(a):\n",
        "  print(\"Tracing with\", a)\n",
        "  return a + a\n",
        "\n",
        "print(double(tf.constant(1)))\n",
        "print()\n",
        "print(double(tf.constant(1.1)))\n",
        "print()\n",
        "print(double(tf.constant(\"a\")))\n",
        "print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPfouGUQrcNb"
      },
      "source": [
        "Tenga en cuenta que si llama repetidamente a una `Function` con el mismo tipo de argumento, TensorFlow se saltará la etapa de trazado y reutilizará un grafo trazado previamente, ya que el grafo generado sería idéntico."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hFccbWFRrsBp"
      },
      "outputs": [],
      "source": [
        "# This doesn't print 'Tracing with ...'\n",
        "print(double(tf.constant(\"b\")))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgIO_XEzcB9o"
      },
      "source": [
        "Puede usar `pretty_printed_concrete_signatures()` para ver todos los trazados disponibles:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IiQc4IKAb-NX"
      },
      "outputs": [],
      "source": [
        "print(double.pretty_printed_concrete_signatures())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKQ92VEWI7n8"
      },
      "source": [
        "Hasta ahora, ha visto que `tf.function` crea una capa de envío dinámica y en caché sobre la lógica de trazado del grafo de TensorFlow. Para ser más específico sobre la terminología:\n",
        "\n",
        "- Un `tf.Graph` es la representación en bruto, agnóstica al lenguaje y portátil de un cálculo TensorFlow.\n",
        "- Una `ConcreteFunction` encapsula un `tf.Graph`.\n",
        "- Una `Function` administra una caché de `ConcreteFunction`s y elige la adecuada para sus entradas.\n",
        "- `tf.function` encapsula una función Python, devolviendo un objeto `Function`.\n",
        "- El **trazado** crea un `tf.Graph` y lo encapsula en una `ConcreteFunction`, también conocida como un **trazo**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "129-iRsPS-gY"
      },
      "source": [
        "#### Reglas de trazado\n",
        "\n",
        "Cuando se llama, una `Function` hace coincidir los argumentos de llamada con `ConcreteFunction`s existentes usando `tf.types.experimental.TraceType` de cada argumento. Si se encuentra una `ConcreteFunction` que coincida, se le envía la llamada. Si no se encuentra ninguna coincidencia, se traza una nueva `ConcreteFunction`.\n",
        "\n",
        "Si se encuentran varias coincidencias, se selecciona la firma más específica. La coincidencia se realiza mediante [subtipado](https://en.wikipedia.org/wiki/Subtyping), de forma muy parecida a las llamadas a funciones normales en C++ o Java, por ejemplo. Por ejemplo, `TensorShape([1, 2])` es un subtipo de `TensorShape([None, None])` y, por tanto, una llamada a tf.function con `TensorShape([1, 2])` puede ser enviada a la `ConcreteFunction` producida con `TensorShape([None, None])` pero si también existe una `ConcreteFunction` con `TensorShape([1, None])` entonces se le dará prioridad ya que es más específica.\n",
        "\n",
        "El `TraceType` se determina a partir de los argumentos de entrada como sigue:\n",
        "\n",
        "- Para `Tensor`, el tipo está parametrizado por los `dtype` y `shape` del `Tensor`; las formas clasificadas son un subtipo de las formas no clasificadas; las dimensiones fijas son un subtipo de las dimensiones desconocidas\n",
        "\n",
        "- Para `Variable`, el tipo es similar a `Tensor`, pero también incluye un ID de recurso único de la variable, necesario para integrar correctamente las dependencias de control.\n",
        "\n",
        "- Para los valores primitivos de Python, el tipo corresponde al propio **valor**. Por ejemplo, el `TraceType` del valor `3` es `LiteralTraceType<3>`, no `int`.\n",
        "\n",
        "- Para los contenedores ordenados de Python como `list` y `tuple`, etc., el tipo está parametrizado por los tipos de sus elementos; por ejemplo, el tipo de `[1, 2]` es `ListTraceType<LiteralTraceType<1>, LiteralTraceType<2>>` y el tipo para `[2, 1]` es `ListTraceType<LiteralTraceType<2>, LiteralTraceType<1>>` que es diferente.\n",
        "\n",
        "- Para mapeos en Python como `dict`, el tipo es también un mapeo de las mismas claves pero a los tipos de valores en lugar de a los valores reales. Por ejemplo, el tipo de `{1: 2, 3: 4}`, es `MappingTraceType<<KeyValue<1, LiteralTraceType<2>>>, <KeyValue<3, LiteralTraceType<4>>>>`. Sin embargo, a diferencia de los contenedores ordenados, `{1: 2, 3: 4}` y `{3: 4, 1: 2}` tienen tipos equivalentes.\n",
        "\n",
        "- Para los objetos Python que implementan el método `__tf_tracing_type__`, el tipo es cualquier cosa que devuelva ese método\n",
        "\n",
        "- Para cualquier otro objeto Python, el tipo es un `TraceType` genérico, su precedencia de coincidencia es:\n",
        "\n",
        "    - Primero comprueba si el objeto es el mismo que se usó en el trazo anterior (usando python `id()` o `is`). Tenga en cuenta que esto seguirá coincidiendo si el objeto ha cambiado, por lo que si usa objetos python como argumentos `tf.function` es mejor usar los *inmutables*.\n",
        "    - A continuación comprueba si el objeto es igual al objeto usado en el trazo anterior (usando python `==`).\n",
        "\n",
        "    Tenga en cuenta que este procedimiento sólo conserva una [referencia débil (weakref)](https://docs.python.org/3/library/weakref.html) al objeto y, por lo tanto, sólo funciona mientras el objeto esté en el ámbito de aplicación/no se haya eliminado).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNNN4lgRzpIs"
      },
      "source": [
        "Nota: `TraceType` se basa en los parámetros de entrada `Function` por lo que los cambios en las variables globales y [libres](https://docs.python.org/3/reference/executionmodel.html#binding-of-names) por sí solos no crearán un nuevo trazo. Consulte [esta sección](#depending_on_python_global_and_free_variables) para conocer las prácticas recomendadas al tratar con variables globales y libres de Python."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEDwbumO32Wh"
      },
      "source": [
        "### Control del retrazado\n",
        "\n",
        "El retrazado, que es cuando su `Function` crea más de un trazo, ayuda a asegurar que TensorFlow genera grafos correctos para cada conjunto de entradas. Sin embargo, ¡el trazado es una operación costosa! Si su `Function` retraza un nuevo grafo para cada llamada, se dará cuenta de que su código se ejecuta más lentamente que si no usara `tf.function`.\n",
        "\n",
        "Para controlar el comportamiento del trazado, puede usar las siguientes técnicas:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUtycWJa34TT"
      },
      "source": [
        "#### Pasar una `input_signature` fija a `tf.function`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_BDMIRmu1RGB"
      },
      "outputs": [],
      "source": [
        "@tf.function(input_signature=(tf.TensorSpec(shape=[None], dtype=tf.int32),))\n",
        "def next_collatz(x):\n",
        "  print(\"Tracing with\", x)\n",
        "  return tf.where(x % 2 == 0, x // 2, 3 * x + 1)\n",
        "\n",
        "print(next_collatz(tf.constant([1, 2])))\n",
        "# You specified a 1-D tensor in the input signature, so this should fail.\n",
        "with assert_raises(TypeError):\n",
        "  next_collatz(tf.constant([[1, 2], [3, 4]]))\n",
        "\n",
        "# You specified an int32 dtype in the input signature, so this should fail.\n",
        "with assert_raises(TypeError):\n",
        "  next_collatz(tf.constant([1.0, 2.0]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocxX-HVk7P2o"
      },
      "source": [
        "#### Usar dimensiones desconocidas para mayor flexibilidad\n",
        "\n",
        "Ya que TensorFlow hace coincidir los tensores basándose en su forma, usar una dimensión `None` como comodín permitirá a las `Function`s reutilizar trazos para entradas de tamaño variable. La entrada de tamaño variable puede ocurrir si tiene secuencias de diferente longitud, o imágenes de diferentes tamaños para cada lote (Vea los tutoriales [Transformer](../tutorials/text/transformer.ipynb) y [Deep Dream](../tutorials/generative/deepdream.ipynb) por ejemplo)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Viun7dh7PmF"
      },
      "outputs": [],
      "source": [
        "@tf.function(input_signature=(tf.TensorSpec(shape=[None], dtype=tf.int32),))\n",
        "def g(x):\n",
        "  print('Tracing with', x)\n",
        "  return x\n",
        "\n",
        "# No retrace!\n",
        "print(g(tf.constant([1, 2, 3])))\n",
        "print(g(tf.constant([1, 2, 3, 4, 5])))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AY5oiQN0XIyA"
      },
      "source": [
        "#### Pasar tensores en lugar de literales python\n",
        "\n",
        "Los argumentos de Python se usan a menudo para controlar los hiperparámetros y la construcción de grafos; por ejemplo, `num_layers=10` o `training=True` o `nonlinearity='relu'`. Por lo tanto, si el argumento Python cambia, es lógico que tenga que retrazar el grafo.\n",
        "\n",
        "Sin embargo, podría darse el caso de que no se esté usando un argumento de Python para controlar la construcción del grafo. En estos casos, un cambio en el valor de Python puede desencadenar un retrazado innecesario. Tomemos, por ejemplo, este bucle de entrenamiento, que AutoGraph desenrollará dinámicamente. A pesar de las múltiples trazas, el grafo generado es en realidad idéntico, por lo que el retrazado es innecesario."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uydzR5JYUU8H"
      },
      "outputs": [],
      "source": [
        "def train_one_step():\n",
        "  pass\n",
        "\n",
        "@tf.function\n",
        "def train(num_steps):\n",
        "  print(\"Tracing with num_steps = \", num_steps)\n",
        "  tf.print(\"Executing with num_steps = \", num_steps)\n",
        "  for _ in tf.range(num_steps):\n",
        "    train_one_step()\n",
        "\n",
        "print(\"Retracing occurs for different Python arguments.\")\n",
        "train(num_steps=10)\n",
        "train(num_steps=20)\n",
        "\n",
        "print()\n",
        "print(\"Traces are reused for Tensor arguments.\")\n",
        "train(num_steps=tf.constant(10))\n",
        "train(num_steps=tf.constant(20))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pJqkDR_Q2wz"
      },
      "source": [
        "Si necesita forzar el retrazado, cree una nueva `Function`. Se garantiza que los objetos `Function` separados no comparten trazos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uHp4ousu4DdN"
      },
      "outputs": [],
      "source": [
        "def f():\n",
        "  print('Tracing!')\n",
        "  tf.print('Executing')\n",
        "\n",
        "tf.function(f)()\n",
        "tf.function(f)()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tZoWrA6INvc"
      },
      "source": [
        "#### Usar el protocolo de trazado\n",
        "\n",
        "Siempre que sea posible, debería preferir en su lugar convertir el tipo Python en un `tf.experimental.ExtensionType`. Además, el `TraceType` de un `ExtensionType` es el `tf.TypeSpec` asociado a él. Por lo tanto, si es necesario, puede simplemente anular el `tf.TypeSpec` predeterminado para tomar el control del `Tracing Protocol` de un `ExtensionType`. Para más detalles, consulte la sección *Personalizar el TypeSpec de ExtensionType* en la guía [Tipos de extensión](extension_type.ipynb).\n",
        "\n",
        "De lo contrario, para tener un control directo sobre cuándo `Function` debe retrazar con respecto a un tipo particular de Python, puede implementar usted mismo el `Tracing Protocol` para ello."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gZkIh7UaIKc6"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def get_mixed_flavor(fruit_a, fruit_b):\n",
        "  return fruit_a.flavor + fruit_b.flavor\n",
        "\n",
        "class Fruit:\n",
        "  flavor = tf.constant([0, 0])\n",
        "\n",
        "class Apple(Fruit):\n",
        "  flavor = tf.constant([1, 2])\n",
        "\n",
        "class Mango(Fruit):\n",
        "  flavor = tf.constant([3, 4])\n",
        "\n",
        "# As described in the above rules, a generic TraceType for `Apple` and `Mango`\n",
        "# is generated (and a corresponding ConcreteFunction is traced) but it fails to\n",
        "# match the second function call since the first pair of Apple() and Mango()\n",
        "# have gone out out of scope by then and deleted.\n",
        "get_mixed_flavor(Apple(), Mango()) # Traces a new concrete function\n",
        "get_mixed_flavor(Apple(), Mango()) # Traces a new concrete function again\n",
        "\n",
        "# However, each subclass of the `Fruit` class has a fixed flavor, and you\n",
        "# can reuse an existing traced concrete function if it was the same\n",
        "# subclass. Avoiding such unnecessary tracing of concrete functions\n",
        "# can have significant performance benefits.\n",
        "\n",
        "class FruitTraceType(tf.types.experimental.TraceType):\n",
        "  def __init__(self, fruit):\n",
        "    self.fruit_type = type(fruit)\n",
        "    self.fruit_value = fruit\n",
        "\n",
        "  def is_subtype_of(self, other):\n",
        "      # True if self subtypes `other` and `other`'s type matches FruitTraceType.\n",
        "      return (type(other) is FruitTraceType and\n",
        "              self.fruit_type is other.fruit_type)\n",
        "\n",
        "  def most_specific_common_supertype(self, others):\n",
        "      # `self` is the specific common supertype if all input types match it.\n",
        "      return self if all(self == other for other in others) else None\n",
        "\n",
        "  def placeholder_value(self, placeholder_context=None):\n",
        "      # Use the fruit itself instead of the type for correct tracing.\n",
        "      return self.fruit_value\n",
        "\n",
        "  def __eq__(self, other):\n",
        "    return type(other) is FruitTraceType and self.fruit_type == other.fruit_type\n",
        "\n",
        "  def __hash__(self):\n",
        "    return hash(self.fruit_type)\n",
        "\n",
        "class FruitWithTraceType:\n",
        "\n",
        "  def __tf_tracing_type__(self, context):\n",
        "    return FruitTraceType(self)\n",
        "\n",
        "class AppleWithTraceType(FruitWithTraceType):\n",
        "  flavor = tf.constant([1, 2])\n",
        "\n",
        "class MangoWithTraceType(FruitWithTraceType):\n",
        "  flavor = tf.constant([3, 4])\n",
        "\n",
        "# Now if you try calling it again:\n",
        "get_mixed_flavor(AppleWithTraceType(), MangoWithTraceType()) # Traces a new concrete function\n",
        "get_mixed_flavor(AppleWithTraceType(), MangoWithTraceType()) # Re-uses the traced concrete function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96IxS2WR37fF"
      },
      "source": [
        "### Obtener funciones concretas\n",
        "\n",
        "Cada vez que se traza una función, se crea una nueva función concreta. Puede obtener directamente una función concreta, usando `get_concrete_function`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mHg2CGtPQ3Hz"
      },
      "outputs": [],
      "source": [
        "print(\"Obtaining concrete trace\")\n",
        "double_strings = double.get_concrete_function(tf.constant(\"a\"))\n",
        "print(\"Executing traced function\")\n",
        "print(double_strings(tf.constant(\"a\")))\n",
        "print(double_strings(a=tf.constant(\"b\")))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6IVZ-NVf9vsx"
      },
      "outputs": [],
      "source": [
        "# You can also call get_concrete_function on an InputSpec\n",
        "double_strings_from_inputspec = double.get_concrete_function(tf.TensorSpec(shape=[], dtype=tf.string))\n",
        "print(double_strings_from_inputspec(tf.constant(\"c\")))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iR4fVmG34xvF"
      },
      "source": [
        "Al imprimir una `ConcreteFunction` se muestra un resumen de sus argumentos de entrada (con tipos) y su tipo de salida."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o3-JbkIk41r8"
      },
      "outputs": [],
      "source": [
        "print(double_strings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtqfvljZeuOV"
      },
      "source": [
        "También puede recuperar directamente la firma de una función concreta."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nzbrqFABe0zG"
      },
      "outputs": [],
      "source": [
        "print(double_strings.structured_input_signature)\n",
        "print(double_strings.structured_outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lar5A_5m5IG1"
      },
      "source": [
        "Usar un trazo concreto con tipos incompatibles arrojará un error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G5eeTK-T5KYj"
      },
      "outputs": [],
      "source": [
        "with assert_raises(tf.errors.InvalidArgumentError):\n",
        "  double_strings(tf.constant(1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "st2L9VNQVtSG"
      },
      "source": [
        "Puede que haya notado que los argumentos Python reciben un tratamiento especial en la firma de entrada de una función concreta. Antes de TensorFlow 2.3, los argumentos Python eran simplemente eliminados de la firma de la función concreta. A partir de TensorFlow 2.3, los argumentos Python permanecen en la firma, pero están restringidos a tomar el valor fijado durante el trazado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U_QyPSGoaC35"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def pow(a, b):\n",
        "  return a ** b\n",
        "\n",
        "square = pow.get_concrete_function(a=tf.TensorSpec(None, tf.float32), b=2)\n",
        "print(square)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E76vIDhQbXIb"
      },
      "outputs": [],
      "source": [
        "assert square(tf.constant(10.0)) == 100\n",
        "\n",
        "with assert_raises(TypeError):\n",
        "  square(tf.constant(10.0), b=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41gJh_JGIfuA"
      },
      "source": [
        "### Obtener grafos\n",
        "\n",
        "Cada función concreta es un contenedor invocable que envuelve un `tf.Graph`. Aunque recuperar el objeto `tf.Graph` real no es algo que necesite hacer normalmente, puede hacerlo fácilmente desde cualquier función concreta."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5UENeGHfaX8g"
      },
      "outputs": [],
      "source": [
        "graph = double_strings.graph\n",
        "for node in graph.as_graph_def().node:\n",
        "  print(f'{node.input} -> {node.name}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIKkgr6qdtp4"
      },
      "source": [
        "### Depuración\n",
        "\n",
        "En general, depurar código es más fácil en modo eager que dentro de `tf.function`. Debe asegurarse de que su código se ejecuta sin errores en modo eager antes de decorar con `tf.function`. Para ayudar en el proceso de depuración, puede llamar `tf.config.run_functions_eagerly(True)` para deshabilitar y volver a habilitar globalmente `tf.function`.\n",
        "\n",
        "A continuación le ofrecemos algunos consejos para el seguimiento de los problemas que sólo aparecen dentro de `tf.function`:\n",
        "\n",
        "- Las llamadas simples `print` de Python sólo se ejecutan durante el trazado, lo que le ayuda a realizar un seguimiento de cuándo se (re)traza su función.\n",
        "- Las llamadas `tf.print` se ejecutarán cada vez, y pueden ayudarle a realizar un seguimiento de los valores intermedios durante la ejecución.\n",
        "- `tf.debugging.enable_check_numerics` es una forma sencilla de descubrir dónde se crean los NaN y los Inf.\n",
        "- `pdb` (el depurador de [Python](https://docs.python.org/3/library/pdb.html)) puede ayudarle a entender lo que ocurre durante el trazado. (Advertencia: `pdb` le llevará al código fuente transformado por AutoGraph)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5f05Vr_YBUCz"
      },
      "source": [
        "## Transformaciones de AutoGraph\n",
        "\n",
        "AutoGraph es una librería que está activada de forma predeterminada en `tf.function`, y transforma un subgrupo de código eager de Python en ops de TensorFlow compatibles con grafos. Esto incluye flujos de control como `if`, `for`, `while`.\n",
        "\n",
        "Las ops de TensorFlow como `tf.cond` y `tf.while_loop` siguen funcionando, pero el flujo de control suele ser más fácil de escribir y entender cuando se escribe en Python."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yCQTtTPTW3WF"
      },
      "outputs": [],
      "source": [
        "# A simple loop\n",
        "\n",
        "@tf.function\n",
        "def f(x):\n",
        "  while tf.reduce_sum(x) > 1:\n",
        "    tf.print(x)\n",
        "    x = tf.tanh(x)\n",
        "  return x\n",
        "\n",
        "f(tf.random.uniform([5]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxwJ8znPI0Cg"
      },
      "source": [
        "Si le interesa, puede inspeccionar el código que genera el autograph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jlQD1ffRXJhl"
      },
      "outputs": [],
      "source": [
        "print(tf.autograph.to_code(f.python_function))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgKmkrNTZSyz"
      },
      "source": [
        "### Condicionales\n",
        "\n",
        "AutoGraph convertirá algunas sentencias `if <condition>` en las llamadas `tf.cond` equivalentes. Esta sustitución se realiza si `<condition>` es un Tensor. En caso contrario, la sentencia `if` se ejecuta como un condicional de Python.\n",
        "\n",
        "Un condicional Python se ejecuta durante el trazado, por lo que se añadirá exactamente una derivación del condicional al grafo. Sin AutoGraph, este grafo trazado sería incapaz de tomar la bifurcación alternativa si existe un flujo de control dependiente de los datos.\n",
        "\n",
        "`tf.cond` traza y añade ambas bifurcaciones del condicional al grafo, seleccionando dinámicamente una derivación en el momento de la ejecución. El trazado puede tener efectos secundarios no deseados; revise [efectos del trazado de AutoGraph](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/g3doc/reference/control_flow.md#effects-of-the-tracing-process) si desea más información."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BOQl8PMq2Sf3"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def fizzbuzz(n):\n",
        "  for i in tf.range(1, n + 1):\n",
        "    print('Tracing for loop')\n",
        "    if i % 15 == 0:\n",
        "      print('Tracing fizzbuzz branch')\n",
        "      tf.print('fizzbuzz')\n",
        "    elif i % 3 == 0:\n",
        "      print('Tracing fizz branch')\n",
        "      tf.print('fizz')\n",
        "    elif i % 5 == 0:\n",
        "      print('Tracing buzz branch')\n",
        "      tf.print('buzz')\n",
        "    else:\n",
        "      print('Tracing default branch')\n",
        "      tf.print(i)\n",
        "\n",
        "fizzbuzz(tf.constant(5))\n",
        "fizzbuzz(tf.constant(20))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rBO5AQ15HVC"
      },
      "source": [
        "Si desea saber más sobre las restricciones de las sentencias if convertidas con AutoGraph, consulte la [documentación de referencia](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/g3doc/reference/control_flow.md#if-statements)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yho4J0a0ZkQS"
      },
      "source": [
        "### Bucles\n",
        "\n",
        "AutoGraph convertirá algunas sentencias `for` y `while` en las operaciones de bucle equivalentes de TensorFlow, como `tf.while_loop`. Si no se convierte, el bucle `for` o `while` se ejecuta como un bucle Python.\n",
        "\n",
        "Esta sustitución se realiza en las siguientes situaciones:\n",
        "\n",
        "- `for x in y`: si `y` es un Tensor, convierta a `tf.while_loop`. En el caso especial de que `y` sea un `tf.data.Dataset`, se genera una combinación de ops `tf.data.Dataset`.\n",
        "- `while <condición>`: si `<condition>` es un tensor, convierta a `tf.while_loop`.\n",
        "\n",
        "Un bucle Python se ejecuta durante el trazado, añadiendo ops adicionales al `tf.Graph` por cada iteración del bucle.\n",
        "\n",
        "Un bucle TensorFlow traza el cuerpo del bucle y selecciona dinámicamente cuántas iteraciones debe ejecutar en el momento de la ejecución. El cuerpo del bucle sólo aparece una vez en el `tf.Graph` generado.\n",
        "\n",
        "Si desea saber más sobre las restricciones de las sentencias `for` y `while` convertidas con AutoGraph, consulte la [documentación de referencia](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/g3doc/reference/control_flow.md#while-statements)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sp4rbIdfbM6s"
      },
      "source": [
        "#### Bucle sobre datos Python\n",
        "\n",
        "Un error común es hacer un bucle sobre los datos de Python/NumPy dentro de una `tf.function`. Este bucle se ejecutará durante el proceso de trazado, añadiendo una copia de su modelo al `tf.Graph` por cada iteración del bucle.\n",
        "\n",
        "Si desea encapsular todo el bucle de entrenamiento en `tf.function`, la forma más segura de hacerlo es encapsular sus datos como un `tf.data.Dataset` para que AutoGraph desenrede dinámicamente el bucle de entrenamiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WGZ19LspbZ27"
      },
      "outputs": [],
      "source": [
        "def measure_graph_size(f, *args):\n",
        "  g = f.get_concrete_function(*args).graph\n",
        "  print(\"{}({}) contains {} nodes in its graph\".format(\n",
        "      f.__name__, ', '.join(map(str, args)), len(g.as_graph_def().node)))\n",
        "\n",
        "@tf.function\n",
        "def train(dataset):\n",
        "  loss = tf.constant(0)\n",
        "  for x, y in dataset:\n",
        "    loss += tf.abs(y - x) # Some dummy computation.\n",
        "  return loss\n",
        "\n",
        "small_data = [(1, 1)] * 3\n",
        "big_data = [(1, 1)] * 10\n",
        "measure_graph_size(train, small_data)\n",
        "measure_graph_size(train, big_data)\n",
        "\n",
        "measure_graph_size(train, tf.data.Dataset.from_generator(\n",
        "    lambda: small_data, (tf.int32, tf.int32)))\n",
        "measure_graph_size(train, tf.data.Dataset.from_generator(\n",
        "    lambda: big_data, (tf.int32, tf.int32)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JeD2U-yrbfVb"
      },
      "source": [
        "Cuando encapsule datos Python/NumPy en un conjunto de datos, preste atención a `tf.data.Dataset.from_generator` versus `tf.data.Dataset.from_tensor_slices`. El primero conservará los datos en Python y los recuperará mediante `tf.py_function`, lo que puede tener implicaciones en el rendimiento, mientras que el segundo agrupará una copia de los datos como un gran nodo `tf.constant()` en el grafo, lo que puede tener implicaciones en la memoria.\n",
        "\n",
        "La lectura de datos de archivos a través de `TFRecordDataset`, `CsvDataset`, etc. es la forma más eficaz de consumir datos, ya que entonces el propio TensorFlow puede administrar la carga asíncrona y la preextracción de datos, sin tener que involucrar a Python. Si desea obtener más información, consulte el [`tf.data`: Construir canalizaciones de entrada de TensorFlow](../../guide/data)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyksHW9TCukR"
      },
      "source": [
        "#### Valores acumulados en un bucle\n",
        "\n",
        "Un patrón común es acumular valores intermedios de un bucle. Normalmente, esto se consigue añadiendo a una lista Python o añadiendo entradas a un diccionario Python. Sin embargo, como estos son efectos secundarios de Python, no funcionarán como se espera en un bucle desenredado dinámicamente. Use `tf.TensorArray` para acumular resultados de un bucle desenredado dinámicamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HJ3Vb3dXfefN"
      },
      "outputs": [],
      "source": [
        "batch_size = 2\n",
        "seq_len = 3\n",
        "feature_size = 4\n",
        "\n",
        "def rnn_step(inp, state):\n",
        "  return inp + state\n",
        "\n",
        "@tf.function\n",
        "def dynamic_rnn(rnn_step, input_data, initial_state):\n",
        "  # [batch, time, features] -> [time, batch, features]\n",
        "  input_data = tf.transpose(input_data, [1, 0, 2])\n",
        "  max_seq_len = input_data.shape[0]\n",
        "\n",
        "  states = tf.TensorArray(tf.float32, size=max_seq_len)\n",
        "  state = initial_state\n",
        "  for i in tf.range(max_seq_len):\n",
        "    state = rnn_step(input_data[i], state)\n",
        "    states = states.write(i, state)\n",
        "  return tf.transpose(states.stack(), [1, 0, 2])\n",
        "\n",
        "dynamic_rnn(rnn_step,\n",
        "            tf.random.uniform([batch_size, seq_len, feature_size]),\n",
        "            tf.zeros([batch_size, feature_size]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2MVoIVaNApG"
      },
      "source": [
        "## Limitaciones\n",
        "\n",
        "`Function` de TensorFlow tiene algunas limitaciones por diseño que debe conocer al convertir una función Python en una `Function`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJqHGFSVLIKl"
      },
      "source": [
        "### Efectos secundarios de la ejecución de Python\n",
        "\n",
        "Los efectos secundarios, como imprimir, anexar a listas y mutar globales, pueden comportarse de forma inesperada dentro de una `Function`, a veces ejecutándose dos veces o ninguna. Sólo ocurren la primera vez que se llama a una `Function` con un conjunto de entradas. Después, se vuelve a ejecutar el `tf. Graph` trazado, sin ejecutar el código Python.\n",
        "\n",
        "La regla general es evitar depender de los efectos secundarios de Python en su lógica y sólo usarlos para depurar sus trazados. De lo contrario, la mejor forma de asegurarse de que su código será ejecutado por el runtime de TensorFlow con cada llamada son las APIs de TensorFlow como `tf.data`, `tf.print`, `tf.summary`, `tf.Variable.assign`, y `tf.TensorArray`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w2sACuZ9TTRk"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def f(x):\n",
        "  print(\"Traced with\", x)\n",
        "  tf.print(\"Executed with\", x)\n",
        "\n",
        "f(1)\n",
        "f(1)\n",
        "f(2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1I0dPiqTV8H"
      },
      "source": [
        "Si desea ejecutar código Python durante cada invocación de una `Function`, `tf.py_function` es una solución de salida. El inconveniente de `tf.py_function` es que no es portable ni especialmente eficiente, no puede guardarse con SavedModel y no funciona bien en configuraciones distribuidas (multi-GPU, TPU). Además, dado que `tf.py_function` tiene que ser integrada en el grafo, convierte todas las entradas/salidas en tensores."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOW1v9WVKGgH"
      },
      "source": [
        "#### Cambio de variables globales y libres de Python\n",
        "\n",
        "Cambiar las variables globales y [libres](https://docs.python.org/3/reference/executionmodel.html#binding-of-names) cuenta como un efecto secundario de Python, por lo que sólo ocurre durante el trazado.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7aJD--9qTWmg"
      },
      "outputs": [],
      "source": [
        "external_list = []\n",
        "\n",
        "@tf.function\n",
        "def side_effect(x):\n",
        "  print('Python side effect')\n",
        "  external_list.append(x)\n",
        "\n",
        "side_effect(1)\n",
        "side_effect(1)\n",
        "side_effect(1)\n",
        "# The list append only happened once!\n",
        "assert len(external_list) == 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5eZTFRv_k_nR"
      },
      "source": [
        "A veces, los comportamientos inesperados son muy difíciles de notar. En el ejemplo siguiente, se pretende que el `counter` garantice el incremento de una variable. Sin embargo, debido a que es un entero python y no un objeto TensorFlow, su valor es capturado durante el primer trazado. Cuando se usa `tf.function`, `assign_add` se graba incondicionalmente en el grafo subyacente. Por lo tanto, `v` aumentará en 1, cada vez que se llame a la `tf.function`. Este problema es común entre los usuarios que intentan migrar su código Tensorflow en modo Graph a Tensorflow 2 usando decoradores `tf.function`, cuando los efectos secundarios de Python (`counter` en el ejemplo) se usan para determinar qué ops ejecutar (`assign_add` en el ejemplo). Normalmente, los usuarios se dan cuenta de esto sólo después de ver resultados numéricos sospechosos, o un rendimiento significativamente inferior al esperado (por ejemplo, si la operación vigilada es muy costosa)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5r6p7-9jk_3L"
      },
      "outputs": [],
      "source": [
        "class Model(tf.Module):\n",
        "  def __init__(self):\n",
        "    self.v = tf.Variable(0)\n",
        "    self.counter = 0\n",
        "\n",
        "  @tf.function\n",
        "  def __call__(self):\n",
        "    if self.counter == 0:\n",
        "      # A python side-effect\n",
        "      self.counter += 1\n",
        "      self.v.assign_add(1)\n",
        "\n",
        "    return self.v\n",
        "\n",
        "m = Model()\n",
        "for n in range(3):\n",
        "  print(m().numpy()) # prints 1, 2, 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXCTcHoVcxhX"
      },
      "source": [
        "Una solución para conseguir el comportamiento esperado es usar [`tf.init_scope`](https://www.tensorflow.org/api_docs/python/tf/init_scope) para elevar las operaciones fuera del grafo de funciones. Esto garantiza que el incremento de la variable sólo se realice una vez durante el tiempo de trazado. Debe tenerse en cuenta que `init_scope` tiene otros efectos secundarios, incluyendo el flujo de control despejado y la cinta de gradiente. A veces el uso de `init_scope` puede llegar a ser demasiado complejo para administrarlo de forma realista."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "An4MrIbrcvi8"
      },
      "outputs": [],
      "source": [
        "class Model(tf.Module):\n",
        "  def __init__(self):\n",
        "    self.v = tf.Variable(0)\n",
        "    self.counter = 0\n",
        "\n",
        "  @tf.function\n",
        "  def __call__(self):\n",
        "    if self.counter == 0:\n",
        "      # Lifts ops out of function-building graphs\n",
        "      with tf.init_scope():\n",
        "        self.counter += 1\n",
        "        self.v.assign_add(1)\n",
        "\n",
        "    return self.v\n",
        "\n",
        "m = Model()\n",
        "for n in range(3):\n",
        "  print(m().numpy()) # prints 1, 1, 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbFG5CX4LwQA"
      },
      "source": [
        "En resumen, como regla general, debe evitar mutar objetos python, como enteros, o contenedores, como listas, que se encuentren fuera de la `Function`. En su lugar, use argumentos y objetos TF. Por ejemplo, la sección [\"Valores acumuladors en un bucle\"](#accumulating_values_in_a_loop) tiene un ejemplo de cómo implementar operaciones tipo lista.\n",
        "\n",
        "Puede, en algunos casos, capturar y manipular el estado si es una [`tf.Variable`](https://www.tensorflow.org/guide/variable). Así es como se actualizan las ponderaciones de los modelos Keras con llamadas repetidas a la misma `ConcreteFunction`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_oNNGrAqPJ1"
      },
      "source": [
        "#### Usar iteradores y generadores de Python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "msTmv-oyUNaf"
      },
      "source": [
        "Muchas funciones de Python, como los generadores y los iteradores, dependen de que el runtime de Python lleve el control de su estado. En general, aunque estos constructos funcionan como se espera en modo eager, son ejemplos de efectos secundarios de Python y, por tanto, sólo se producen durante el trazado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FNPD4unZUedH"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def buggy_consume_next(iterator):\n",
        "  tf.print(\"Value:\", next(iterator))\n",
        "\n",
        "iterator = iter([1, 2, 3])\n",
        "buggy_consume_next(iterator)\n",
        "# This reuses the first value from the iterator, rather than consuming the next value.\n",
        "buggy_consume_next(iterator)\n",
        "buggy_consume_next(iterator)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcS3TAgCjTWR"
      },
      "source": [
        "Al igual que TensorFlow tiene un `tf.TensorArray` especializado para los constructos de lista, tiene un `tf.data.Iterator` especializado para los constructos de iteración. Consulte la sección sobre [Transformaciones AutoGraph](#autograph_transformations) para una descripción general. Además, la API [`tf.data`](https://www.tensorflow.org/guide/data) puede ayudar a implementar patrones generadores:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8D_iKetXW6VE"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def good_consume_next(iterator):\n",
        "  # This is ok, iterator is a tf.data.Iterator\n",
        "  tf.print(\"Value:\", next(iterator))\n",
        "\n",
        "ds = tf.data.Dataset.from_tensor_slices([1, 2, 3])\n",
        "iterator = iter(ds)\n",
        "good_consume_next(iterator)\n",
        "good_consume_next(iterator)\n",
        "good_consume_next(iterator)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8YAMYb6KEh4"
      },
      "source": [
        "### Todas las salidas de una función tf.deben ser valores retornados\n",
        "\n",
        "Con la excepción de `tf.Variable`s, una función tf.debe retornar todas sus salidas. Intentar acceder directamente a cualquier tensor desde una función sin pasar por los valores de retorno provoca \"fugas\".\n",
        "\n",
        "Por ejemplo, la función siguiente \"fuga\" el tensor `a` a través de la `x` global de Python:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zrdp4rjxg6jo"
      },
      "outputs": [],
      "source": [
        "x = None\n",
        "\n",
        "@tf.function\n",
        "def leaky_function(a):\n",
        "  global x\n",
        "  x = a + 1  # Bad - leaks local tensor\n",
        "  return a + 2\n",
        "\n",
        "correct_a = leaky_function(tf.constant(1))\n",
        "\n",
        "print(correct_a.numpy())  # Good - value obtained from function's returns\n",
        "try:\n",
        "  x.numpy()  # Bad - tensor leaked from inside the function, cannot be used here\n",
        "except AttributeError as expected:\n",
        "  print(expected)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-d4_J_DC5rxX"
      },
      "source": [
        "Esto es verdadero incluso si también se retorna el valor filtrado:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PrcpPB8C5s9T"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def leaky_function(a):\n",
        "  global x\n",
        "  x = a + 1  # Bad - leaks local tensor\n",
        "  return x  # Good - uses local tensor\n",
        "\n",
        "correct_a = leaky_function(tf.constant(1))\n",
        "\n",
        "print(correct_a.numpy())  # Good - value obtained from function's returns\n",
        "try:\n",
        "  x.numpy()  # Bad - tensor leaked from inside the function, cannot be used here\n",
        "except AttributeError as expected:\n",
        "  print(expected)\n",
        "\n",
        "@tf.function\n",
        "def captures_leaked_tensor(b):\n",
        "  b += x  # Bad - `x` is leaked from `leaky_function`\n",
        "  return b\n",
        "\n",
        "with assert_raises(TypeError):\n",
        "  captures_leaked_tensor(tf.constant(2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sm2ghjyy50D4"
      },
      "source": [
        "Normalmente, este tipo de fugas se producen cuando se usan sentencias o estructuras de datos de Python. Además de filtrar tensores inaccesibles, tales declaraciones también son probablemente erróneas porque cuentan como efectos secundarios de Python, y no se garantiza que se ejecuten en cada llamada de función.\n",
        "\n",
        "Entre las formas habituales de fugas de tensores locales también se incluye mutar una colección externa de Python, o un objeto:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D7bLe8y652wU"
      },
      "outputs": [],
      "source": [
        "class MyClass:\n",
        "\n",
        "  def __init__(self):\n",
        "    self.field = None\n",
        "\n",
        "external_list = []\n",
        "external_object = MyClass()\n",
        "\n",
        "def leaky_function():\n",
        "  a = tf.constant(1)\n",
        "  external_list.append(a)  # Bad - leaks tensor\n",
        "  external_object.field = a  # Bad - leaks tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-XVQcD-wf5K"
      },
      "source": [
        "### Las tf.functions recursivas no son compatibles\n",
        "\n",
        "`Function`s recursivas no son compatibles y podrían provocar bucles infinitos. Por ejemplo,"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QSN-T1m5EFcR"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def recursive_fn(n):\n",
        "  if n > 0:\n",
        "    return recursive_fn(n - 1)\n",
        "  else:\n",
        "    return 1\n",
        "\n",
        "with assert_raises(Exception):\n",
        "  recursive_fn(tf.constant(5))  # Bad - maximum recursion error."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LyRyooKGUxNV"
      },
      "source": [
        "Incluso si una `Function` recursiva parece funcionar, la función python será trazada varias veces y podría tener consecuencias para el rendimiento. Por ejemplo,"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7FlmTqfMUwmT"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def recursive_fn(n):\n",
        "  if n > 0:\n",
        "    print('tracing')\n",
        "    return recursive_fn(n - 1)\n",
        "  else:\n",
        "    return 1\n",
        "\n",
        "recursive_fn(5)  # Warning - multiple tracings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-D6nh3QirXAd"
      },
      "source": [
        "## Problemas conocidos\n",
        "\n",
        "Si su `Function` no se evalúa correctamente, el error puede explicarse debido a estos problemas conocidos que está previsto solucionar en el futuro."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZoPg5w1Pjqna"
      },
      "source": [
        "### Depender de variables globales y libres de Python\n",
        "\n",
        "`Function` crea una nueva `ConcreteFunction` cuando se llama con un nuevo valor de un argumento Python. Sin embargo, no lo hace para el cierre de Python, ni para sus globales o no locales de esa `Function`. Si su valor cambia entre llamadas a la `Function`, la `Function` seguirá usando los valores que tenían cuando fue trazada. Esto es diferente de como trabajan las funciones normales de Python.\n",
        "\n",
        "Por este motivo, debe seguir un estilo de programación funcional que use argumentos en lugar de cierre sobre nombres externos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oeJMdXd3M0cM"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def buggy_add():\n",
        "  return 1 + foo\n",
        "\n",
        "@tf.function\n",
        "def recommended_add(foo):\n",
        "  return 1 + foo\n",
        "\n",
        "foo = 1\n",
        "print(\"Buggy:\", buggy_add())\n",
        "print(\"Correct:\", recommended_add(foo))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L3q7sUJWZOSU"
      },
      "outputs": [],
      "source": [
        "print(\"Updating the value of `foo` to 100!\")\n",
        "foo = 100\n",
        "print(\"Buggy:\", buggy_add())  # Did not change!\n",
        "print(\"Correct:\", recommended_add(foo))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZoPg5w1Pjqnb"
      },
      "source": [
        "Otra forma de actualizar un valor global, es convertirlo en una `tf.Variable` y usar en su lugar el método `Variable.assign`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oeJMdXd3M0cc"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def variable_add():\n",
        "  return 1 + foo\n",
        "\n",
        "foo = tf.Variable(1)\n",
        "print(\"Variable:\", variable_add())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L3q7sUJWZOSd"
      },
      "outputs": [],
      "source": [
        "print(\"Updating the value of `foo` to 100!\")\n",
        "foo.assign(100)\n",
        "print(\"Variable:\", variable_add())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvwe9gTIWfx6"
      },
      "source": [
        "### Depender de objetos Python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJkZS-SwPvOQ"
      },
      "source": [
        "Es permitido pasar objetos Python personalizados como argumentos a `tf.function`, pero tiene ciertas limitaciones.\n",
        "\n",
        "Para obtener la máxima cobertura de funciones, considere la posibilidad de transformar los objetos en [Tipos de extensión](extension_type.ipynb) antes de pasarlos a `tf.function`. También puede usar primitivas de Python y estructuras compatibles con `tf.nest`.\n",
        "\n",
        "Sin embargo, como se explica en las [reglas de trazado](#rules_of_tracing), cuando la clase personalizada de Python no ofrece un `TraceType` personalizado, `tf.function` se ve obligada a usar la igualdad basada en instancias, lo que significa que **no creará un nuevo trazado** cuando le pase el **mismo objeto con atributos modificados**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ux8KJESVWDxX"
      },
      "outputs": [],
      "source": [
        "class SimpleModel(tf.Module):\n",
        "  def __init__(self):\n",
        "    # These values are *not* tf.Variables.\n",
        "    self.bias = 0.\n",
        "    self.weight = 2.\n",
        "\n",
        "@tf.function\n",
        "def evaluate(model, x):\n",
        "  return model.weight * x + model.bias\n",
        "\n",
        "simple_model = SimpleModel()\n",
        "x = tf.constant(10.)\n",
        "print(evaluate(simple_model, x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mUxRF4ghZZvX"
      },
      "outputs": [],
      "source": [
        "print(\"Adding bias!\")\n",
        "simple_model.bias += 5.0\n",
        "print(evaluate(simple_model, x))  # Didn't change :("
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ytcgg2qFWaBF"
      },
      "source": [
        "Usar la misma `Function` para evaluar la instancia modificada del modelo tendrá errores, ya que sigue teniendo [el mismo TraceType basado en instancias](#rules_of_tracing) que el modelo original.\n",
        "\n",
        "Por este motivo, se recomienda que escriba su `Function` para evitar depender de los atributos mutables de los objetos o que implemente el [Protocolo de trazado](#use_the_tracing_protocol) para que los objetos informen a su `Function` sobre dichos atributos.\n",
        "\n",
        "Si no es posible, una solución consiste en crear nuevas `Function` cada vez que modifique su objeto para forzar el retrazado:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pFvWmWAAQjrv"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, x):\n",
        "  return model.weight * x + model.bias\n",
        "\n",
        "new_model = SimpleModel()\n",
        "evaluate_no_bias = tf.function(evaluate).get_concrete_function(new_model, x)\n",
        "# Don't pass in `new_model`, `Function` already captured its state during tracing.\n",
        "print(evaluate_no_bias(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bdU2-jF4ZH0B"
      },
      "outputs": [],
      "source": [
        "print(\"Adding bias!\")\n",
        "new_model.bias += 5.0\n",
        "# Create new Function and ConcreteFunction since you modified new_model.\n",
        "evaluate_with_bias = tf.function(evaluate).get_concrete_function(new_model, x)\n",
        "print(evaluate_with_bias(x)) # Don't pass in `new_model`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFgEZClsZrEi"
      },
      "source": [
        "Como [el retrazado puede resultar costoso](https://www.tensorflow.org/guide/intro_to_graphs#tracing_and_performance), puede usar `tf.Variable`s como atributos de objeto, que pueden mutarse (¡ojo! pero no cambiarse) para conseguir un efecto similar sin necesidad de retrazado.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "daAP_lucwS6w"
      },
      "outputs": [],
      "source": [
        "class BetterModel:\n",
        "\n",
        "  def __init__(self):\n",
        "    self.bias = tf.Variable(0.)\n",
        "    self.weight = tf.Variable(2.)\n",
        "\n",
        "@tf.function\n",
        "def evaluate(model, x):\n",
        "  return model.weight * x + model.bias\n",
        "\n",
        "better_model = BetterModel()\n",
        "print(evaluate(better_model, x))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ktqwMJBqwTFj"
      },
      "outputs": [],
      "source": [
        "print(\"Adding bias!\")\n",
        "better_model.bias.assign_add(5.0)  # Note: instead of better_model.bias += 5\n",
        "print(evaluate(better_model, x))  # This works!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lPr_6mK_AQWL"
      },
      "source": [
        "### Crear tf.Variables\n",
        "\n",
        "`Function` sólo admite `tf.Variable`s únicos creados una vez en la primera llamada y reutilizados en las siguientes llamadas a la función. El siguiente fragmento de código crearía una nueva `tf.Variable` en cada llamada a la función, lo que resultaría en una excepción `ValueError`.\n",
        "\n",
        "Ejemplo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tx0Vvnb_9OB-"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def f(x):\n",
        "  v = tf.Variable(1.0)\n",
        "  return v\n",
        "\n",
        "with assert_raises(ValueError):\n",
        "  f(1.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYm6-5GCILXQ"
      },
      "source": [
        "Un patrón común utilizado para solucionar esta limitación es comenzar con un valor None de Python y, a continuación, crear condicionalmente la `tf.Variable` si el valor es None:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HQrG5_kOiKl_"
      },
      "outputs": [],
      "source": [
        "class Count(tf.Module):\n",
        "  def __init__(self):\n",
        "    self.count = None\n",
        "\n",
        "  @tf.function\n",
        "  def __call__(self):\n",
        "    if self.count is None:\n",
        "      self.count = tf.Variable(0)\n",
        "    return self.count.assign_add(1)\n",
        "\n",
        "c = Count()\n",
        "print(c())\n",
        "print(c())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uD6qI7aJwbR"
      },
      "source": [
        "#### Usar con múltiples optimizadores Keras\n",
        "\n",
        "Puede encontrarse con el error `ValueError: tf.function only supports singleton tf.Variables created on the first call.` al usar más de un optimizador Keras con una `tf.function`. Este error se produce porque los optimizadores crean internamente `tf.Variables` cuando aplican gradientes por primera vez."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yWQ3-r99Jvze"
      },
      "outputs": [],
      "source": [
        "opt1 = tf.keras.optimizers.Adam(learning_rate = 1e-2)\n",
        "opt2 = tf.keras.optimizers.Adam(learning_rate = 1e-3)\n",
        "\n",
        "@tf.function\n",
        "def train_step(w, x, y, optimizer):\n",
        "   with tf.GradientTape() as tape:\n",
        "       L = tf.reduce_sum(tf.square(w*x - y))\n",
        "   gradients = tape.gradient(L, [w])\n",
        "   optimizer.apply_gradients(zip(gradients, [w]))\n",
        "\n",
        "w = tf.Variable(2.)\n",
        "x = tf.constant([-1.])\n",
        "y = tf.constant([2.])\n",
        "\n",
        "train_step(w, x, y, opt1)\n",
        "print(\"Calling `train_step` with different optimizer...\")\n",
        "with assert_raises(ValueError):\n",
        "  train_step(w, x, y, opt2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Q8BRPCThTjB"
      },
      "source": [
        "Si necesita cambiar el optimizador durante el entrenamiento, una solución es crear una nueva `Function` para cada optimizador, llamando directamente a la [`ConcreteFunction`](#obtaining_concrete_functions)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YV5F2Gy9hSI3"
      },
      "outputs": [],
      "source": [
        "opt1 = tf.keras.optimizers.Adam(learning_rate = 1e-2)\n",
        "opt2 = tf.keras.optimizers.Adam(learning_rate = 1e-3)\n",
        "\n",
        "# Not a tf.function.\n",
        "def train_step(w, x, y, optimizer):\n",
        "   with tf.GradientTape() as tape:\n",
        "       L = tf.reduce_sum(tf.square(w*x - y))\n",
        "   gradients = tape.gradient(L, [w])\n",
        "   optimizer.apply_gradients(zip(gradients, [w]))\n",
        "\n",
        "w = tf.Variable(2.)\n",
        "x = tf.constant([-1.])\n",
        "y = tf.constant([2.])\n",
        "\n",
        "# Make a new Function and ConcreteFunction for each optimizer.\n",
        "train_step_1 = tf.function(train_step)\n",
        "train_step_2 = tf.function(train_step)\n",
        "for i in range(10):\n",
        "  if i % 2 == 0:\n",
        "    train_step_1(w, x, y, opt1)\n",
        "  else:\n",
        "    train_step_2(w, x, y, opt2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xjnz5CcuqQac"
      },
      "source": [
        "#### Usar múltiples modelos Keras\n",
        "\n",
        "También puede encontrarse con el error `ValueError: tf.function only supports singleton tf.Variables created on the first call.` al pasar diferentes instancias del modelo a la misma `Function`.\n",
        "\n",
        "Este error se produce porque los modelos Keras (que [no tienen definida su forma de entrada](https://www.tensorflow.org/guide/keras/custom_layers_and_models#best_practice_deferring_weight_creation_until_the_shape_of_the_inputs_is_known)) y las capas Keras crean `tf.Variables`s cuando son llamadas por primera vez. Puede que esté intentando inicializar esas variables dentro de una `Function`, que ya ha sido llamada. Para evitar este error, intente llamar a `model.build(input_shape)` para inicializar todas las ponderaciones antes de entrenar el modelo.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKyrEY5GVX3M"
      },
      "source": [
        "## Lecturas adicionales\n",
        "\n",
        "Si desea más información sobre cómo exportar y cargar una `Function`, consulte la [guía de SavedModel](../../guide/saved_model). Si desea más información sobre las optimizaciones de grafos que se realizan tras el trazado, consulte la [guía de Grappler](../../guide/graph_optimization). Si desea saber cómo optimizar su canalización de datos y perfilar su modelo, consulte la [guía de Profiler](../../guide/profiler.md)."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "function.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
