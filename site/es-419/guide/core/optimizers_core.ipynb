{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FhGuhbZ6M5tl"
      },
      "source": [
        "##### Copyright 2022 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "AwOEIRJC6Une"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIdT9iu_Z4Rb"
      },
      "source": [
        "# Optimizadores con API básicas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBIlTPscrIT9"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>     <a target=\"_blank\" href=\"https://www.tensorflow.org/guide/core/optimizers_core\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver en TensorFlow.org</a> </td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/es-419/guide/core/optimizers_core.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Ejecutar en Google Colab</a> </td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/es-419/guide/core/optimizers_core.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver el código fuente en GitHub</a> </td>\n",
        "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/es-419/guide/core/optimizers_core.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Descargar el bloc de notas</a>\n",
        "</td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SjAxxRpBzVYg"
      },
      "source": [
        "## Introducción\n",
        "\n",
        "En este bloc de notas se presenta el proceso de creación de optimizadores personalizados con las API de bajo nivel de [TensorFlow Core](https://www.tensorflow.org/guide/core). Visite el [Resumen de las API principales](https://www.tensorflow.org/guide/core) para obtener más información sobre TensorFlow Core y sus casos de uso previstos.\n",
        "\n",
        "El módulo de los [optimizadores de Keras](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers) es el kit de herramientas de optimización recomendado para muchos propósitos generales de entrenamiento. Incluye una variedad de optimizadores prediseñados, así como la función de subclasificación para la personalización. Los optimizadores de Keras también son compatibles con capas personalizadas, modelos y bucles de entrenamiento construidos con las API Core. Estos optimizadores precompilados y personalizables son adecuados para la mayoría de los casos, pero las API principales permiten un control completo sobre el proceso de optimización. Por ejemplo, técnicas como Sharpness-Aware Minimization (SAM) requieren que el modelo y el optimizador se acoplen, lo que no se ajusta a la definición tradicional de optimizadores de ML. Esta guía recorre el proceso de creación de optimizadores personalizados desde cero con las API principales, lo que le brinda el poder de tener un control total sobre la estructura, la implementación y el comportamiento de sus optimizadores."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBmqYyodNRd_"
      },
      "source": [
        "## Descripción general de los optimizadores\n",
        "\n",
        "Un optimizador es un algoritmo utilizado para minimizar una función de pérdida con respecto a los parámetros entrenables de un modelo. La técnica de optimización más sencilla es el descenso en gradiente, que actualiza de forma iterativa los parámetros de un modelo lo que da un paso en la dirección del descenso más pronunciado de su función de pérdida. Su tamaño de paso es directamente proporcional al tamaño del gradiente, lo que puede ser problemático cuando el gradiente es demasiado grande o demasiado pequeño. Hay muchos otros optimizadores basados en gradientes como Adam, Adagrad y RMSprop que aprovechan varias propiedades matemáticas de los gradientes para la eficiencia de la memoria y la convergencia rápida."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nchsZfwEVtVs"
      },
      "source": [
        "## Preparación"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d9idwpXCltUl"
      },
      "outputs": [],
      "source": [
        "import matplotlib\n",
        "from matplotlib import pyplot as plt\n",
        "# Tamaños predefinidos para figuras de Matplotlib.\n",
        "matplotlib.rcParams['figure.figsize'] = [9, 6]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9xQKvCJ85kCQ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "# establecer números aleatorios para obtener resultados reproducibles \n",
        "tf.random.set_seed(22)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UmF5aU3MnwX"
      },
      "source": [
        "## Gradiente de descenso\n",
        "\n",
        "La clase optimizadora básica debe tener un método de inicialización y una función para actualizar una lista de variables con una lista de degradados. Comience con la implementación del optimizador de degradado de gradiente básico que actualiza cada variable restando su gradiente escalado por una tasa de aprendizaje."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MWjmUmeOQFFN"
      },
      "outputs": [],
      "source": [
        "class GradientDescent(tf.Module):\n",
        "\n",
        "  def __init__(self, learning_rate=1e-3):\n",
        "    # Inicializa parámetros\n",
        "    self.learning_rate = learning_rate\n",
        "    self.title = f\"Gradient descent optimizer: learning rate={self.learning_rate}\"\n",
        "\n",
        "  def apply_gradients(self, grads, vars):\n",
        "    # Actualiza las variables\n",
        "    for grad, var in zip(grads, vars):\n",
        "      var.assign_sub(self.learning_rate*grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSekgBHDRzmp"
      },
      "source": [
        "Para probar este optimizador, cree una función de pérdida de muestreo para minimizar con respecto a una sola variable, $x$. Calcule su función de gradiente y resolución para el valor de su parámetro se reduzca al mínimo:\n",
        "\n",
        "$$L = 2x^4 + 3x^3 + 2$$\n",
        "\n",
        "$$\\frac{dL}{dx} = 8x^3 + 9x^2$$\n",
        "\n",
        "$\\frac{dL}{dx}$ es 0 en $x = 0$, que es un punto de silla y en $x = - \\frac{9}{8}$, que es el mínimo global. Por lo tanto, la función de pérdida se optimiza con $x^\\star = - \\frac{9}{8}$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VCtJaUo6Ry8V"
      },
      "outputs": [],
      "source": [
        "x_vals = tf.linspace(-2, 2, 201)\n",
        "x_vals = tf.cast(x_vals, tf.float32)\n",
        "\n",
        "def loss(x):\n",
        "  return 2*(x**4) + 3*(x**3) + 2\n",
        "\n",
        "def grad(f, x):\n",
        "  with tf.GradientTape() as tape:\n",
        "    tape.watch(x)\n",
        "    result = f(x)\n",
        "  return tape.gradient(result, x)\n",
        "\n",
        "plt.plot(x_vals, loss(x_vals), c='k', label = \"Loss function\")\n",
        "plt.plot(x_vals, grad(loss, x_vals), c='tab:blue', label = \"Gradient function\")\n",
        "plt.plot(0, loss(0),  marker=\"o\", c='g', label = \"Inflection point\")\n",
        "plt.plot(-9/8, loss(-9/8),  marker=\"o\", c='r', label = \"Global minimum\")\n",
        "plt.legend()\n",
        "plt.ylim(0,5)\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.title(\"Sample loss function and gradient\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLlIBJ9yuwhE"
      },
      "source": [
        "Escriba una función para probar la convergencia de un optimizador con una función de pérdida de una sola variable. Suponga que se alcanzó la convergencia cuando el valor del parámetro que se actualizó en el paso de tiempo $t$ es el mismo que su valor en el paso de tiempo $t-1$. Termine la prueba después de un número determinado de iteraciones y también realice un seguimiento de los gradientes de explosión durante el proceso. Con el fin de desafiar realmente el algoritmo de optimización, inicialice el parámetro pobre. En el ejemplo anterior, $x = 2$ es una buena elección, ya que implica un gradiente empinado y también conduce a un punto de inflexión."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SLQTc41ouv0F"
      },
      "outputs": [],
      "source": [
        "def convergence_test(optimizer, loss_fn, grad_fn=grad, init_val=2., max_iters=2000):\n",
        "  # Función para realizar la prueba de convergencia del optimizador\n",
        "  print(optimizer.title)\n",
        "  print(\"-------------------------------\")\n",
        "  # Inicialización de variables y estructuras\n",
        "  x_star = tf.Variable(init_val)\n",
        "  param_path = []\n",
        "  converged = False\n",
        "\n",
        "  for iter in range(1, max_iters + 1):\n",
        "    x_grad = grad_fn(loss_fn, x_star)\n",
        "\n",
        "    # Caso del gradiente explosivo\n",
        "    if tf.math.is_nan(x_grad):\n",
        "      print(f\"Gradient exploded at iteration {iter}\\n\")\n",
        "      return []\n",
        "\n",
        "    # Actualiza la variable y guarda su versión antigua\n",
        "    x_old = x_star.numpy()\n",
        "    optimizer.apply_gradients([x_grad], [x_star])\n",
        "    param_path.append(x_star.numpy())\n",
        "\n",
        "    # Verificación de la convergencia\n",
        "    if x_star == x_old:\n",
        "      print(f\"Converged in {iter} iterations\\n\")\n",
        "      converged = True\n",
        "      break\n",
        "      \n",
        "  # Imprimir mensaje de finalización anticipada\n",
        "  if not converged:\n",
        "    print(f\"Exceeded maximum of {max_iters} iterations. Test terminated.\\n\")\n",
        "  return param_path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vK-7_TsmyAgI"
      },
      "source": [
        "Pruebe la convergencia del optimizador de descenso de gradiente para las siguientes tasas de aprendizaje: 1e-3, 1e-2, 1e-1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lWRn8c91mqB0"
      },
      "outputs": [],
      "source": [
        "param_map_gd = {}\n",
        "learning_rates = [1e-3, 1e-2, 1e-1]\n",
        "for learning_rate in learning_rates:\n",
        "  param_map_gd[learning_rate] = (convergence_test(\n",
        "      GradientDescent(learning_rate=learning_rate), loss_fn=loss))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TydrGHF5y6iI"
      },
      "source": [
        "Visualice la ruta de los parámetros sobre una gráfica de contorno de la función de pérdida."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "piffzGHI_u5G"
      },
      "outputs": [],
      "source": [
        "def viz_paths(param_map, x_vals, loss_fn, title, max_iters=2000):\n",
        "  # Crear de una gráfica de contorno de la función de pérdida\n",
        "  t_vals = tf.range(1., max_iters + 100.)\n",
        "  t_grid, x_grid = tf.meshgrid(t_vals, x_vals)\n",
        "  loss_grid = tf.math.log(loss_fn(x_grid))\n",
        "  plt.pcolormesh(t_vals, x_vals, loss_grid, vmin=0, shading='nearest')\n",
        "  colors = ['r', 'w', 'c']\n",
        "  # Graficar las trayectorias de los parámetros sobre la gráfica de contorno\n",
        "  for i, learning_rate in enumerate(param_map):\n",
        "    param_path = param_map[learning_rate]\n",
        "    if len(param_path) > 0:\n",
        "      x_star = param_path[-1]\n",
        "      plt.plot(t_vals[:len(param_path)], param_path, c=colors[i])\n",
        "      plt.plot(len(param_path), x_star, marker='o', c=colors[i], \n",
        "              label = f\"x*: learning rate={learning_rate}\")\n",
        "  plt.xlabel(\"Iterations\")\n",
        "  plt.ylabel(\"Parameter value\")\n",
        "  plt.legend()\n",
        "  plt.title(f\"{title} parameter paths\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ssyj2sO4BcNY"
      },
      "outputs": [],
      "source": [
        "viz_paths(param_map_gd, x_vals, loss, \"Gradient descent\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmM-5eDLFnmC"
      },
      "source": [
        "El descenso del gradiente parece atascarse en el punto de inflexión cuando se usan tasas de aprendizaje más pequeñas. El aumento de la tasa de aprendizaje puede fomentar un movimiento más rápido alrededor de la región de la meseta debido a un tamaño de paso más grande; sin embargo, esto conlleva el riesgo de tener gradientes explosivos en las primeras iteraciones cuando la función de pérdida es extremadamente pronunciada."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5CDeXN8S1SF"
      },
      "source": [
        "## Descenso del gradiente con impulso\n",
        "\n",
        "El descenso del gradiente con impulso no solo utiliza el gradiente para actualizar una variable, sino que también implica el cambio de posición de una variable basado en su actualización anterior. El parámetro de impulso determina el nivel de influencia que la actualización en timestep $t-1$ tiene en la actualización en timestep $t$. La acumulación de impulso ayuda a mover las variables más allá de las regiones plataeu más rápido que el descenso de gradiente básico. La regla de actualización del impulso es la siguiente:\n",
        "\n",
        "$$\\Delta_x^{[t]} = lr \\cdot L^\\prime(x^{[t-1]}) + p \\cdot \\Delta_x^{[t-1]}$$\n",
        "\n",
        "$$x^{[t]} = x^{[t-1]} - \\Delta_x^{[t]}$$\n",
        "\n",
        "donde:\n",
        "\n",
        "- $x$: la variable que se está optimizando\n",
        "- $\\Delta_x$: change in $x$\n",
        "- $lr$: tasa de aprendizaje\n",
        "- $L^\\prime(x)$: gradiente de la función de pérdida con respecto a x\n",
        "- $p$: parámetro de impulso"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rOBY8Tz4S0dX"
      },
      "outputs": [],
      "source": [
        "class Momentum(tf.Module):\n",
        "\n",
        "  def __init__(self, learning_rate=1e-3, momentum=0.7):\n",
        "    # Inicializar parámetros\n",
        "    self.learning_rate = learning_rate\n",
        "    self.momentum = momentum\n",
        "    self.change = 0.\n",
        "    self.title = f\"Gradient descent optimizer: learning rate={self.learning_rate}\"\n",
        "\n",
        "  def apply_gradients(self, grads, vars):\n",
        "    # Actualizar variables \n",
        "    for grad, var in zip(grads, vars):\n",
        "      curr_change = self.learning_rate*grad + self.momentum*self.change\n",
        "      var.assign_sub(curr_change)\n",
        "      self.change = curr_change"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_nDu38gW6Fu"
      },
      "source": [
        "Pruebe la convergencia del optimizador de impulso para las siguientes tasas de aprendizaje: 1e-3, 1e-2, 1e-1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tA6oQL-sW2xg"
      },
      "outputs": [],
      "source": [
        "param_map_mtm = {}\n",
        "learning_rates = [1e-3, 1e-2, 1e-1]\n",
        "for learning_rate in learning_rates:\n",
        "  param_map_mtm[learning_rate] = (convergence_test(\n",
        "      Momentum(learning_rate=learning_rate),\n",
        "      loss_fn=loss, grad_fn=grad))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wz_LV0EPYE6k"
      },
      "source": [
        "Visualice la ruta de los parámetros sobre una gráfica de contorno de la función de pérdida."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qbW1eEKaX3T9"
      },
      "outputs": [],
      "source": [
        "viz_paths(param_map_mtm, x_vals, loss, \"Momentum\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bEFnhPRTBXh"
      },
      "source": [
        "## Estimación del impulso adaptativo (Adam)\n",
        "\n",
        "El Algoritmo de estimación de impulso adaptativo (Adam) es una técnica de optimización eficiente y altamente generalizable que aprovecha dos metodologías clave de descenso de gradiente: impulso y propagación cuadrática media (RMSP). El impulso ayuda a acelerar el descenso de gradiente utilizando el primer impulso (suma de gradientes) junto con un parámetro de caída. RMSP es similar; sin embargo, aprovecha el segundo impulso (suma de gradientes al cuadrado).\n",
        "\n",
        "El algoritmo de Adam combina el primer y el segundo impulso para proporcionar una regla de actualización más generalizable. El signo de una variable, $x$, puede determinarse al calcular $\\frac{x}{\\sqrt{x^2}}$. El optimizador Adam utiliza este hecho para calcular un paso en la actualización que efectivamente es un signo suavizado. En vez de calcular $\\frac{x}{\\sqrt{x^2}}$, el optimizador calcula una versión suavizada de $x$ (primer impulso) y $x^2$ (segundo impulso) para cada actualización de la variable.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WjgyqRiZ7XhA"
      },
      "source": [
        "**Algoritmo Adam**\n",
        "\n",
        "$\\beta_1 \\gets 0.9 ; \\triangleright \\text{literature value}$\n",
        "\n",
        "$\\beta_2 \\gets 0.999 ; \\triangleright \\text{literature value}$\n",
        "\n",
        "$lr \\gets \\text{1e-3} ; \\triangleright \\text{configurable learning rate}$\n",
        "\n",
        "$\\epsilon \\gets \\text{1e-7} ; \\triangleright \\text{prevents divide by 0 error}$\n",
        "\n",
        "$V_{dv} \\gets \\vec {\\underset{n\\times1}{0}} ;\\triangleright \\text{stores momentum updates for each variable}$\n",
        "\n",
        "$S_{dv} \\gets \\vec {\\underset{n\\times1}{0}} ; \\triangleright \\text{stores RMSP updates for each variable}$\n",
        "\n",
        "$t \\gets 1$\n",
        "\n",
        "$\\text{On iteration } t:$\n",
        "\n",
        "$;;;; \\text{For} (\\frac{dL}{dv}, v) \\text{ in gradient variable pairs}:$\n",
        "\n",
        "$;;;;;;;; V_{dv_i} = \\beta_1V_{dv_i} + (1 - \\beta_1)\\frac{dL}{dv} ; \\triangleright \\text{momentum update}$\n",
        "\n",
        "$;;;;;;;; S_{dv_i} = \\beta_2V_{dv_i} + (1 - \\beta_2)(\\frac{dL}{dv})^2 ; \\triangleright \\text{RMSP update}$\n",
        "\n",
        "$;;;;;;;; v_{dv}^{bc} = \\frac{V_{dv_i}}{(1-\\beta_1)^t} ; \\triangleright \\text{momentum bias correction}$\n",
        "\n",
        "$;;;;;;;; s_{dv}^{bc} = \\frac{S_{dv_i}}{(1-\\beta_2)^t} ; \\triangleright \\text{RMSP bias correction}$\n",
        "\n",
        "$;;;;;;;; v = v - lr\\frac{v_{dv}^{bc}}{\\sqrt{s_{dv}^{bc}} + \\epsilon} ; \\triangleright \\text{parameter update}$\n",
        "\n",
        "$;;;;;;;; t = t + 1$\n",
        "\n",
        "**Final del algoritmo**\n",
        "\n",
        "Debido a que $V_{dv}$ y $S_{dv}$ se inicializan en 0 y a que $\\beta_1$ y $\\beta_2$ se aproximan a 1, las actualizaciones del impulso y del RMSP están sesgadas de forma natural hacia 0; por lo tanto, las variables pueden beneficiarse de la corrección del sesgo. La corrección del sesgo también ayuda a controlar la osccilación de las ponderaciones conforme se aproximan al mínimo global."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hm5vffRJRsEc"
      },
      "outputs": [],
      "source": [
        "class Adam(tf.Module):\n",
        "  \n",
        "    def __init__(self, learning_rate=1e-3, beta_1=0.9, beta_2=0.999, ep=1e-7):\n",
        "      # Inicializar los parámetros de Adam\n",
        "      self.beta_1 = beta_1\n",
        "      self.beta_2 = beta_2\n",
        "      self.learning_rate = learning_rate\n",
        "      self.ep = ep\n",
        "      self.t = 1.\n",
        "      self.v_dvar, self.s_dvar = [], []\n",
        "      self.title = f\"Adam: learning rate={self.learning_rate}\"\n",
        "      self.built = False\n",
        "\n",
        "    def apply_gradients(self, grads, vars):\n",
        "      # Establecer las ranuras para los impulsos y RMSprop de cada variable en la primera llamada\n",
        "      if not self.built:\n",
        "        for var in vars:\n",
        "          v = tf.Variable(tf.zeros(shape=var.shape))\n",
        "          s = tf.Variable(tf.zeros(shape=var.shape))\n",
        "          self.v_dvar.append(v)\n",
        "          self.s_dvar.append(s)\n",
        "        self.built = True\n",
        "      # Realizar actualizaciones en Adam\n",
        "      for i, (d_var, var) in enumerate(zip(grads, vars)):\n",
        "        # Cálculo del impulso\n",
        "        self.v_dvar[i] = self.beta_1*self.v_dvar[i] + (1-self.beta_1)*d_var\n",
        "        # Cálculo de RMSprop\n",
        "        self.s_dvar[i] = self.beta_2*self.s_dvar[i] + (1-self.beta_2)*tf.square(d_var)\n",
        "        # Corrección de los sesgos\n",
        "        v_dvar_bc = self.v_dvar[i]/(1-(self.beta_1**self.t))\n",
        "        s_dvar_bc = self.s_dvar[i]/(1-(self.beta_2**self.t))\n",
        "        # Actualizar las variables del modelo\n",
        "        var.assign_sub(self.learning_rate*(v_dvar_bc/(tf.sqrt(s_dvar_bc) + self.ep)))\n",
        "      # Incrementar el contador de iteraciones\n",
        "      self.t += 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWN4Qus7flUO"
      },
      "source": [
        "Pruebe el rendimiento del optimizador Adam con las mismas tasas de aprendizaje utilizadas en los ejemplos de descenso de gradiente. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GXHCxtemFBpR"
      },
      "outputs": [],
      "source": [
        "param_map_adam = {}\n",
        "learning_rates = [1e-3, 1e-2, 1e-1]\n",
        "for learning_rate in learning_rates:\n",
        "  param_map_adam[learning_rate] = (convergence_test(\n",
        "      Adam(learning_rate=learning_rate), loss_fn=loss))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgpUcs_xXEjX"
      },
      "source": [
        "Visualice la ruta de los parámetros sobre una gráfica de contorno de la función de pérdida."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ctvOUmlzFK8s"
      },
      "outputs": [],
      "source": [
        "viz_paths(param_map_adam, x_vals, loss, \"Adam\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_oGScF8zJcY4"
      },
      "source": [
        "En este ejemplo en particular, el optimizador Adam registra una convergencia más lenta en comparación con el descenso por gradiente tradicional cuando se utilizan tasas de aprendizaje pequeñas. Sin embargo, el algoritmo supera satisfactoriamente la región de plataeu y converge al mínimo global con una tasa de aprendizaje mayor. Los gradientes explosivos dejan de ser un problema gracias al escalado dinámico de las tasas de aprendizaje de Adam cuando se encuentran gradientes grandes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFLfEH4ManbW"
      },
      "source": [
        "## Conclusión\n",
        "\n",
        "En este bloc de notas se presentaron los conceptos básicos de la escritura y la comparación de los optimizadores con las [API de TensorFlow Core](https://www.tensorflow.org/guide/core). Aunque los optimizadores predeterminados como Adam son generalizables, no siempre son la mejor opción para cada modelo o conjunto de datos. Tener un control preciso sobre el proceso de optimización puede ayudar a agilizar los flujos de trabajo de entrenamiento de ML y mejorar el rendimiento general. Consulte la siguiente documentación para consultar más ejemplos de optimizadores personalizados:\n",
        "\n",
        "- Este optimizador Adam se utiliza en el tutorial [Perceptrones multicapa](https://www.tensorflow.org/guide/core/mlp_core) y en el [Entrenamiento distribuido]()\n",
        "- [Model Garden](https://blog.tensorflow.org/2020/03/introducing-model-garden-for-tensorflow-2.html) tiene una gran variedad de [optimizadores personalizados](https://github.com/tensorflow/models/tree/master/official/modeling/optimization) escritos con las Core API.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "optimizers_core.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
