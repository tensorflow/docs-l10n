{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rX8mhOLljYeM"
      },
      "source": [
        "##### Copyright 2022 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "BZSlp3DAjdYf"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wF5wszaj97Y"
      },
      "source": [
        "# Inicio rápido de las API de TensorFlow Core"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUNzJc4jTj6G"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td><a target=\"_blank\" href=\"https://www.tensorflow.org/guide/core/quickstart_core\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver en TensorFlow.org</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/es-419/guide/core/quickstart_core.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Ejecutar en Google Colab</a></td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/es-419/guide/core/quickstart_core.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver el código fuente en GitHub</a> </td>\n",
        "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/es-419/guide/core/quickstart_core.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Descargar el bloc de notas</a> </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04QgGZc9bF5D"
      },
      "source": [
        "En este tutorial de inicio rápido se muestra cómo utilizar las API de bajo nivel de [TensorFlow Core](https://www.tensorflow.org/guide/core) para crear y entrenar un modelo de regresión lineal múltiple que prediga la eficiencia del combustible. Para ello, se utiliza el conjunto de datos [Auto MPG](https://archive.ics.uci.edu/ml/datasets/auto+mpg){::.external} que contiene datos de eficiencia del combustible para automóviles de finales de la década de 1970 y principios de la década de 1980.\n",
        "\n",
        "Seguirá las etapas típicas de un proceso de aprendizaje automático:\n",
        "\n",
        "1. Carga el conjunto de datos.\n",
        "2. Construye una [tubería de entrada.](../data.ipynb).\n",
        "3. Crea un modelo de [regresión lineal](https://developers.google.com/machine-learning/glossary#linear-regression){:.external} múltiple.\n",
        "4. Evalúe el rendimiento del modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnrWf3PCEzXL"
      },
      "source": [
        "## Preparación\n",
        "\n",
        "Importe TensorFlow y otras bibliotecas necesarias para comenzar:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0trJmd6DjqBZ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import matplotlib\n",
        "from matplotlib import pyplot as plt\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "# Set a random seed for reproducible results \n",
        "tf.random.set_seed(22)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NAbSZiaoJ4z"
      },
      "source": [
        "## Cargar y preprocesar el conjunto de datos\n",
        "\n",
        "A continuación, deberá cargar y preprocesar el conjunto de datos [Auto MPG](https://archive.ics.uci.edu/ml/datasets/auto+mpg){:.external} del [Repositorio de aprendizaje automático de la UCI](https://archive.ics.uci.edu/ml/){:.external}. Este conjunto de datos utiliza una serie de características cuantitativas y cualitativas, como cilindros, desplazamiento, caballos de fuerza y peso, para predecir la eficiencia del combustible de los automóviles a finales de la década de 1970 y principios de la década de 1980.\n",
        "\n",
        "El conjunto de datos contiene algunos valores desconocidos. Asegúrese de eliminar cualquier valor que falte con `pandas.DataFrame.dropna`, y convierta el conjunto de datos a un tipo de tensor `tf.float32` con las funciones `tf.convert_to_tensor` y `tf.cast`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HglhDsUfrJ98"
      },
      "outputs": [],
      "source": [
        "url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data'\n",
        "column_names = ['MPG', 'Cylinders', 'Displacement', 'Horsepower', 'Weight',\n",
        "                'Acceleration', 'Model Year', 'Origin']\n",
        "\n",
        "dataset = pd.read_csv(url, names=column_names, na_values='?', comment='\\t',\n",
        "                          sep=' ', skipinitialspace=True)\n",
        "\n",
        "dataset = dataset.dropna()\n",
        "dataset_tf = tf.convert_to_tensor(dataset, dtype=tf.float32)\n",
        "dataset.tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vgoDL3hYesB"
      },
      "source": [
        "Después, divida el conjunto de datos en conjuntos de entrenamiento y de prueba. Asegúrese de mezclar el conjunto de datos con `tf.random.shuffle` para evitar divisiones sesgadas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0mJU4kt6YiAp"
      },
      "outputs": [],
      "source": [
        "dataset_shuffled = tf.random.shuffle(dataset_tf, seed=22)\n",
        "train_data, test_data = dataset_shuffled[100:], dataset_shuffled[:100]\n",
        "x_train, y_train = train_data[:, 1:], train_data[:, 0]\n",
        "x_test, y_test = test_data[:, 1:], test_data[:, 0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bscb2Vsbi3TE"
      },
      "source": [
        "Ejecute la ingeniería básica de características mediante la encriptación de una sola vez de la característica `\"Origin\"`. La función `tf.one_hot` es útil para transformar esta columna de categorías en 3 columnas binarias separadas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_B8N9IV1i6IV"
      },
      "outputs": [],
      "source": [
        "def onehot_origin(x):\n",
        "  origin = tf.cast(x[:, -1], tf.int32)\n",
        "  # Use `origin - 1` to account for 1-indexed feature\n",
        "  origin_oh = tf.one_hot(origin - 1, 3)\n",
        "  x_ohe = tf.concat([x[:, :-1], origin_oh], axis = 1)\n",
        "  return x_ohe\n",
        "\n",
        "x_train_ohe, x_test_ohe = onehot_origin(x_train), onehot_origin(x_test)\n",
        "x_train_ohe.numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnoCDzzedite"
      },
      "source": [
        "En este ejemplo se muestra un problema de regresión múltiple con predictores o características en escalas muy diferentes. Por lo tanto, es beneficioso estandarizar los datos para que cada característica tenga un promedio cero y una varianza por unidad. Utilice las funciones `tf.reduce_mean` y `tf.math.reduce_std` para la estandarización. La predicción del modelo de regresión puede entonces desestandarizarse para obtener su valor en términos de las unidades originales."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dJJFdvqydhyp"
      },
      "outputs": [],
      "source": [
        "class Normalize(tf.Module):\n",
        "  def __init__(self, x):\n",
        "    # Inicializa el promedio y la desviación estándar para la normalización\n",
        "    self.mean = tf.math.reduce_mean(x, axis=0)\n",
        "    self.std = tf.math.reduce_std(x, axis=0)\n",
        "\n",
        "  def norm(self, x):\n",
        "    # Normaliza la entrada\n",
        "    return (x - self.mean)/self.std\n",
        "\n",
        "  def unnorm(self, x):\n",
        "    # Anula la normalización de la entrada\n",
        "    return (x * self.std) + self.mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5BONV6fYYwZb"
      },
      "outputs": [],
      "source": [
        "norm_x = Normalize(x_train_ohe)\n",
        "norm_y = Normalize(y_train)\n",
        "x_train_norm, y_train_norm = norm_x.norm(x_train_ohe), norm_y.norm(y_train)\n",
        "x_test_norm, y_test_norm = norm_x.norm(x_test_ohe), norm_y.norm(y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPZ68wASog_I"
      },
      "source": [
        "## Cree un modelo de aprendizaje automático\n",
        "\n",
        "Cree un modelo de regresión lineal con las API de TensorFlow Core. A continuación encontrará la ecuación para la regresión lineal múltiple:\n",
        "\n",
        "$${\\mathrm{Y}} = {\\mathrm{X}}w + b$$\n",
        "\n",
        "donde:\n",
        "\n",
        "- $\\underset{m\\times 1}{\\mathrm{Y}}$: vector objetivo\n",
        "- $\\underset{m\\times n}{\\mathrm{X}}$: matriz de características\n",
        "- $\\underset{n\\times 1}w$: vector de ponderación\n",
        "- $b$: sesgo\n",
        "\n",
        "Al utilizar el decorador `@tf.function`, se rastrea el código Python correspondiente para generar una gráfica de TensorFlow que se pueda llamar. Este enfoque es beneficioso para guardar y cargar el modelo después del entrenamiento. También puede mejorar el rendimiento de los modelos con muchas capas y operaciones complejas. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h3IKyzTCDNGo"
      },
      "outputs": [],
      "source": [
        "class LinearRegression(tf.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    self.built = False\n",
        "\n",
        "  @tf.function\n",
        "  def __call__(self, x):\n",
        "    # Inicializa los parámetros del modelo en la primera llamada\n",
        "    if not self.built:\n",
        "      # Genera aleatoriamente el vector de ponderación y el término del sesgo\n",
        "      rand_w = tf.random.uniform(shape=[x.shape[-1], 1])\n",
        "      rand_b = tf.random.uniform(shape=[])\n",
        "      self.w = tf.Variable(rand_w)\n",
        "      self.b = tf.Variable(rand_b)\n",
        "      self.built = True\n",
        "    y = tf.add(tf.matmul(x, self.w), self.b)\n",
        "    return tf.squeeze(y, axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2hiez2eIUz8"
      },
      "source": [
        "Para cada ejemplo, el modelo ofrece una predicción de las MPG del automóvil de entrada al calcular la suma ponderada de sus características más un término del sesgo. Esta predicción puede desestandarizarse para obtener su valor en términos de las unidades originales."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OeOrNdnkEEcR"
      },
      "outputs": [],
      "source": [
        "lin_reg = LinearRegression()\n",
        "prediction = lin_reg(x_train_norm[:1])\n",
        "prediction_unnorm = norm_y.unnorm(prediction)\n",
        "prediction_unnorm.numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIHANxNSvWr9"
      },
      "source": [
        "## Defina una función de pérdida\n",
        "\n",
        "Ahora, defina una función de pérdida para evaluar el rendimiento del modelo durante el proceso de entrenamiento.\n",
        "\n",
        "Dado que los problemas de regresión utilizan resultados continuos, el error cuadrático medio (ECM) es una opción ideal para la función de pérdida. El MSE se define mediante la siguiente ecuación:\n",
        "\n",
        "$$MSE = \\frac{1}{m}\\sum_{i=1}^{m}(\\hat{y}_i -y_i)^2$$\n",
        "\n",
        "donde:\n",
        "\n",
        "- $\\hat{y}$: vector de predicciones\n",
        "- $y$: vector de objetivos verdaderos\n",
        "\n",
        "El objetivo de este problema de regresión es encontrar el vector de ponderación óptimo, $w$, y el sesgo, $b$, que minimice la función de pérdida MSE. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8tYNVUkmw35s"
      },
      "outputs": [],
      "source": [
        "def mse_loss(y_pred, y):\n",
        "  return tf.reduce_mean(tf.square(y_pred - y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htI-7aJPqclK"
      },
      "source": [
        "## Entrene y evalúe su modelo\n",
        "\n",
        "El uso de minilotes para el entrenamiento proporciona eficiencia de memoria y una convergencia más rápida. La API `tf.data.Dataset` tiene funciones útiles para el procesamiento por lotes y la mezcla. La API le permite construir complejas tuberías de entrada a partir de piezas simples y reutilizables. Obtenga más información sobre la construcción de tuberías de entrada de TensorFlow en [esta guía](https://www.tensorflow.org/guide/data)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kxST2w_Nq0C5"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train_norm, y_train_norm))\n",
        "train_dataset = train_dataset.shuffle(buffer_size=x_train.shape[0]).batch(batch_size)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((x_test_norm, y_test_norm))\n",
        "test_dataset = test_dataset.shuffle(buffer_size=x_test.shape[0]).batch(batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9haUW8Yq3xD"
      },
      "source": [
        "A continuación, escriba un bucle de entrenamiento para actualizar de forma iterativa los parámetros de su modelo haciendo uso de la función de pérdida MSE y sus gradientes con respecto a los parámetros de entrada.\n",
        "\n",
        "Este método iterativo se denomina [descenso de gradiente](https://developers.google.com/machine-learning/glossary#gradient-descent){:.external}. En cada iteración, los parámetros del modelo se actualizan al dar un paso en la dirección opuesta de sus gradientes calculados. El tamaño de este paso se determina por la tasa de aprendizaje, la cual es un hiperparámetro que se puede configurar. Recordemos que el gradiente de una función indica la dirección de su ascenso más pronunciado; por lo tanto, dar un paso en la dirección opuesta indica la dirección de descenso más pronunciado, lo que en última instancia ayuda a minimizar la función de pérdida MSE."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y7suUbJXVLqP"
      },
      "outputs": [],
      "source": [
        "# Establece los parámetros del entrenamiento\n",
        "epochs = 100\n",
        "learning_rate = 0.01\n",
        "train_losses, test_losses = [], []\n",
        "\n",
        "# Bucle de entrenamiento de formato\n",
        "for epoch in range(epochs):\n",
        "  batch_losses_train, batch_losses_test = [], []\n",
        "\n",
        "  # Itera mediante los datos de entrenamiento\n",
        "  for x_batch, y_batch in train_dataset:\n",
        "    with tf.GradientTape() as tape:\n",
        "      y_pred_batch = lin_reg(x_batch)\n",
        "      batch_loss = mse_loss(y_pred_batch, y_batch)\n",
        "    # Actualiza parámetros con respecto a los cálculos de gradiente\n",
        "    grads = tape.gradient(batch_loss, lin_reg.variables)\n",
        "    for g,v in zip(grads, lin_reg.variables):\n",
        "      v.assign_sub(learning_rate * g)\n",
        "    # Realiza un seguimiento del rendimiento del entrenamiento a nivel de lote \n",
        "    batch_losses_train.append(batch_loss)\n",
        "  \n",
        "  # Itera mediante los datos de la prueba\n",
        "  for x_batch, y_batch in test_dataset:\n",
        "    y_pred_batch = lin_reg(x_batch)\n",
        "    batch_loss = mse_loss(y_pred_batch, y_batch)\n",
        "    # Mantiene un registro del rendimiento de las pruebas a nivel de lote \n",
        "    batch_losses_test.append(batch_loss)\n",
        "\n",
        "  # Mantiene un registro del rendimiento del modelo a nivel de época\n",
        "  train_loss = tf.reduce_mean(batch_losses_train)\n",
        "  test_loss = tf.reduce_mean(batch_losses_test)\n",
        "  train_losses.append(train_loss)\n",
        "  test_losses.append(test_loss)\n",
        "  if epoch % 10 == 0:\n",
        "    print(f'Mean squared error for step {epoch}: {train_loss.numpy():0.3f}')\n",
        "\n",
        "# Pérdidas finales de la salida\n",
        "print(f\"\\nFinal train loss: {train_loss:0.3f}\")\n",
        "print(f\"Final test loss: {test_loss:0.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mDAAPFqVVgn"
      },
      "source": [
        "Grafique los cambios en la pérdida de MSE a lo largo del tiempo. Calcule las métricas de rendimiento en un [conjunto de validación](https://developers.google.com/machine-learning/glossary#validation-set){:. external} designado o un [conjunto de prueba](https://developers.google.com/machine-learning/glossary#test-set){:. external} y asegure que el modelo no se desborda en el conjunto de datos de entrenamiento y puede generalizar bien a los datos invisibles."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F7dTAzgHDUh7"
      },
      "outputs": [],
      "source": [
        "matplotlib.rcParams['figure.figsize'] = [9, 6]\n",
        "\n",
        "plt.plot(range(epochs), train_losses, label = \"Training loss\")\n",
        "plt.plot(range(epochs), test_losses, label = \"Testing loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Mean squared error loss\")\n",
        "plt.legend()\n",
        "plt.title(\"MSE loss vs training iterations\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aj8NrlzlJqDG"
      },
      "source": [
        "Parece que el modelo hace un buen trabajo al ajustar los datos de entrenamiento y al mismo tiempo generalizar los datos de prueba invisibles."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUNIPubuPYDR"
      },
      "source": [
        "## Guardar y cargar el modelo\n",
        "\n",
        "Comience por crear un módulo de exportación que reciba los datos sin procesar y realice las siguientes operaciones:\n",
        "\n",
        "- Extracción de características\n",
        "- Normalización\n",
        "- Predicción\n",
        "- Desnormalización"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g-uOrGa9ZehG"
      },
      "outputs": [],
      "source": [
        "class ExportModule(tf.Module):\n",
        "  def __init__(self, model, extract_features, norm_x, norm_y):\n",
        "    # Inicializa las funciones de pre y postprocesamiento\n",
        "    self.model = model\n",
        "    self.extract_features = extract_features\n",
        "    self.norm_x = norm_x\n",
        "    self.norm_y = norm_y\n",
        "\n",
        "  @tf.function(input_signature=[tf.TensorSpec(shape=[None, None], dtype=tf.float32)]) \n",
        "  def __call__(self, x):\n",
        "    # Ejecuta ExportModule para nuevos puntos de datos\n",
        "    x = self.extract_features(x)\n",
        "    x = self.norm_x.norm(x)\n",
        "    y = self.model(x)\n",
        "    y = self.norm_y.unnorm(y)\n",
        "    return y "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YPYYLQ8EZiU8"
      },
      "outputs": [],
      "source": [
        "lin_reg_export = ExportModule(model=lin_reg,\n",
        "                              extract_features=onehot_origin,\n",
        "                              norm_x=norm_x,\n",
        "                              norm_y=norm_y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6v8xi06XZWiC"
      },
      "source": [
        "Si desea guardar el modelo en su estado actual, utilice la función `tf.saved_model.save`. Para cargar un modelo guardado para hacer predicciones, utilice la función `tf.saved_model.load`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K1IvMoHbptht"
      },
      "outputs": [],
      "source": [
        "import tempfile\n",
        "import os\n",
        "\n",
        "models = tempfile.mkdtemp()\n",
        "save_path = os.path.join(models, 'lin_reg_export')\n",
        "tf.saved_model.save(lin_reg_export, save_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rYb6DrEH0GMv"
      },
      "outputs": [],
      "source": [
        "lin_reg_loaded = tf.saved_model.load(save_path)\n",
        "test_preds = lin_reg_loaded(x_test)\n",
        "test_preds[:10].numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-47O6_GLdRuT"
      },
      "source": [
        "## Conclusión\n",
        "\n",
        "¡Felicidades! Entrenó un modelo de regresión usando las API de bajo nivel de TensorFlow Core.\n",
        "\n",
        "Para obtener más ejemplos de uso de las API de TensorFlow Core, consulte las siguientes guías:\n",
        "\n",
        "- [Regresión logística](./logistic_regression_core.ipynb) para la clasificación binaria\n",
        "- [Perceptrones multicapa](./mlp_core.ipynb) para el reconocimiento de dígitos escritos a mano\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "rX8mhOLljYeM"
      ],
      "name": "quickstart_core.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
