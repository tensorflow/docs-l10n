{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FhGuhbZ6M5tl"
      },
      "source": [
        "##### Copyright 2022 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "AwOEIRJC6Une"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIdT9iu_Z4Rb"
      },
      "source": [
        "# Aproximación de matrices con Core API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBIlTPscrIT9"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>     <a target=\"_blank\" href=\"https://www.tensorflow.org/guide/core/matrix_core\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver en TensorFlow.org</a> </td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/es-419/guide/core/matrix_core.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Ejecutar en Google Colab</a> </td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/es-419/guide/core/matrix_core.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver el código fuente en GitHub</a> </td>\n",
        "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/es-419/guide/core/matrix_core.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Descargar el bloc de notas</a> </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGw8TF2vtzru"
      },
      "source": [
        "## Introducción\n",
        "\n",
        "Este bloc de notas utiliza las API de [bajo nivel de TensorFlow Core](https://www.tensorflow.org/guide/core) para mostrar las funciones de TensorFlow como plataforma de computación científica de alto rendimiento. Visite la [Descripción general de las API del núcleo](https://www.tensorflow.org/guide/core) para obtener más información sobre TensorFlow Core y sus casos de uso específicos.\n",
        "\n",
        "Este tutorial explora la técnica de [descomposición de valor singular](https://developers.google.com/machine-learning/recommendation/collaborative/matrix) (SVD) y sus aplicaciones para problemas de aproximación de bajo rango. La SVD se utiliza para factorizar matrices reales o complejas y tiene diversos usos en la ciencia de datos, como la compresión de imágenes. Las imágenes para este tutorial provienen del proyecto [Imagen](https://imagen.research.google/) de Google Brain. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_FdwaovEkCC"
      },
      "source": [
        "> ![svd_intro](http://tensorflow.org/images/core/svd_intro.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nchsZfwEVtVs"
      },
      "source": [
        "## Preparación"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1rRo8oNqZ-Rj"
      },
      "outputs": [],
      "source": [
        "import matplotlib\n",
        "from matplotlib.image import imread\n",
        "from matplotlib import pyplot as plt\n",
        "import requests\n",
        "# Tamaños de figuras de Matplotlib preestablecidos.\n",
        "matplotlib.rcParams['figure.figsize'] = [16, 9]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9xQKvCJ85kCQ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "so_ewq3gAoEI"
      },
      "source": [
        "## Fundamentos de la SVD\n",
        "\n",
        "La descomposición en valores singulares de una matriz, ${\\mathrm{A}}$, se determina por la siguiente factorización:\n",
        "\n",
        "$${\\mathrm{A}} = {\\mathrm{U}} \\Sigma {\\mathrm{V}}^T$$\n",
        "\n",
        "donde:\n",
        "\n",
        "- $\\underset{m \\times n}{\\mathrm{A}}$: matriz de entrada donde $m \\geq n$\n",
        "- $\\underset{m \\times n}{\\mathrm{U}}$: matriz ortogonal, ${\\mathrm{U}}^T{\\mathrm{U}} = {\\mathrm{I}}$, con cada columna, $u_i$, que denota un vector singular izquierdo de ${\\mathrm{A}}$\n",
        "- $\\underset{n \\times n}{\\Sigma}$: matriz diagonal con cada entrada diagonal, $\\sigma_i$, que denota un valor singular de ${\\mathrm{A}}$\n",
        "- $\\underset{n \\times n}{{\\mathrm{V}}^T}$: matriz ortogonal, ${\\mathrm{V}}^T{\\mathrm{V}} = {\\mathrm{I}}$, con cada fila, $v_i$, que denota un vector recto singular de ${\\mathrm{A}}$\n",
        "\n",
        "Cuando tanto $m < n$, ${\\mathrm{U}}$ como $\\Sigma$ tienen dimensión $(m \\times m)$, y ${\\mathrm{V}}^T$ tiene la dimensión $(m \\times n)$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enGGGXCQKNv8"
      },
      "source": [
        "> ![svd_full](http://tensorflow.org/images/core/svd_full.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NlP-cBdSKLtc"
      },
      "source": [
        "El paquete de álgebra lineal de TensorFlow tiene una función, `tf.linalg.svd`, que se puede utilizar para calcular la descomposición del valor singular de una o más matrices. Comience por definir una matriz simple y calcular su factorización SVD.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C3QAcgyoeIpv"
      },
      "outputs": [],
      "source": [
        "A = tf.random.uniform(shape=[40,30])\n",
        "# Calcula la factorización SVD\n",
        "s, U, V = tf.linalg.svd(A)\n",
        "# Define Sigma y V Transpose\n",
        "S = tf.linalg.diag(s)\n",
        "V_T = tf.transpose(V)\n",
        "# Reconstruye la matriz original\n",
        "A_svd = U@S@V_T\n",
        "# Visualizar \n",
        "plt.bar(range(len(s)), s);\n",
        "plt.xlabel(\"Singular value rank\")\n",
        "plt.ylabel(\"Singular value\")\n",
        "plt.title(\"Bar graph of singular values\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6H_C9WhFACm4"
      },
      "source": [
        "La función `tf.einsum` puede utilizarse para calcular directamente la reconstrucción de la matriz a partir de las salidas de `tf.linalg.svd`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TPE6QeMtADUn"
      },
      "outputs": [],
      "source": [
        "A_svd = tf.einsum('s,us,vs -> uv',s,U,V)\n",
        "print('\\nReconstructed Matrix, A_svd', A_svd)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1m6JIsM9DLP"
      },
      "source": [
        "## Aproximación de bajo rango con la SVD\n",
        "\n",
        "El rango de una matriz, ${\\mathrm{A}}$, se determina por la dimensión del espacio vectorial que abarcan sus columnas. La SVD puede utilizarse para aproximar una matriz con un rango inferior, lo que en última instancia disminuye la dimensionalidad de los datos necesarios para almacenar la información que representa la matriz.\n",
        "\n",
        "La aproximación de rango-r de ${\\mathrm{A}}$ en términos de la SVD se define por la fórmula:\n",
        "\n",
        "$${\\mathrm{A_r}} = {\\mathrm{U_r}} \\Sigma_r {\\mathrm{V_r}}^T$$\n",
        "\n",
        "donde:\n",
        "\n",
        "- $\\underset{m \\times r}{\\mathrm{U_r}}$: es una matriz formada por las primeras $r$ columnas de ${\\mathrm{U}}$\n",
        "- $\\underset{r \\times r}{\\Sigma_r}$: es una matriz diagonal formada por los primeros $r$ valores singulares en $\\Sigma$\n",
        "- $\\underset{r \\times n}{\\mathrm{V_r}}^T$: es una matriz formada por las primeras $r$ filas de ${\\mathrm{V}}^T$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJWMJu36QyUV"
      },
      "source": [
        "> ![svd_approx](http://tensorflow.org/images/core/svd_approx.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkiVUxeaQybq"
      },
      "source": [
        "Comience a escribir una función para calcular la aproximación de rango-r de una matriz dada. Este procedimiento de aproximación de bajo rango se utiliza para la compresión de imágenes; por lo tanto, también es útil calcular el tamaño físico de los datos para cada aproximación. Para simplificar, supongamos que el tamaño de los datos para una matriz aproximada de rango-r es igual al número total de elementos necesarios para calcular la aproximación. A continuación, escriba una función para visualizar la matriz original, $\\mathrm{A}$ su aproximación de rango-r, $\\mathrm{A}_r$ y la matriz de error, $||mathrm{A} - \\mathrm{A}_r|$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2oY3pMPagJrO"
      },
      "outputs": [],
      "source": [
        "def rank_r_approx(s, U, V, r, verbose=False):\n",
        "  # Calcula las matrices necesarias para una aproximación rank-r\n",
        "  s_r, U_r, V_r = s[..., :r], U[..., :, :r], V[..., :, :r] # ... implica cualquier número de ejes de lotes extra\n",
        "  # Calcular la aproximación de bajo rango y su tamaño\n",
        "  A_r = tf.einsum('...s,...us,...vs->...uv',s_r,U_r,V_r)\n",
        "  A_r_size = tf.size(U_r) + tf.size(s_r) + tf.size(V_r)\n",
        "  if verbose:\n",
        "    print(f\"Approximation Size: {A_r_size}\")\n",
        "  return A_r, A_r_size\n",
        "\n",
        "def viz_approx(A, A_r):\n",
        "# Grafica A, A_r, y A - A_r\n",
        "  vmin, vmax = 0, tf.reduce_max(A)\n",
        "  fig, ax = plt.subplots(1,3)\n",
        "  mats = [A, A_r, abs(A - A_r)]\n",
        "  titles = ['Original A', 'Approximated A_r', 'Error |A - A_r|']\n",
        "  for i, (mat, title) in enumerate(zip(mats, titles)):\n",
        "    ax[i].pcolormesh(mat, vmin=vmin, vmax=vmax)\n",
        "    ax[i].set_title(title)\n",
        "    ax[i].axis('off')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O3ZRkYCkX2FQ"
      },
      "outputs": [],
      "source": [
        "print(f\"Original Size of A: {tf.size(A)}\")\n",
        "s, U, V = tf.linalg.svd(A)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S1DR83VMX4cM"
      },
      "outputs": [],
      "source": [
        "# Aproximación de rango-15\n",
        "A_15, A_15_size = rank_r_approx(s, U, V, 15, verbose = True)\n",
        "viz_approx(A, A_15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KgFT70XFX57E"
      },
      "outputs": [],
      "source": [
        "# Aproximación de rango-3\n",
        "A_3, A_3_size = rank_r_approx(s, U, V, 3, verbose = True)\n",
        "viz_approx(A, A_3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DS4XoSlTJgX0"
      },
      "source": [
        "Como era de suponer, el uso de rangos más bajos produce aproximaciones menos precisas. Sin embargo, la calidad de estas aproximaciones de bajo rango a menudo es suficientemente buena en situaciones reales. También hay se debe tener en cuenta que el objetivo principal de la aproximación de bajo rango con SVD es reducir la dimensionalidad de los datos, pero no reducir el espacio en disco de los propios datos. Sin embargo, conforme las matrices de entrada adquieren mayor dimensionalidad, muchas aproximaciones de bajo rango también acaban beneficiándose de la reducción del tamaño de los datos. Este beneficio de reducción es la razón por la que el proceso es útil para los problemas de compresión de imágenes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IhsaiOnnZs6M"
      },
      "source": [
        "## Cargando imágenes\n",
        "\n",
        "La siguiente imagen está disponible en la página de inicio de [Imagen](https://imagen.research.google/). Imagen es un modelo de difusión de texto a imagen desarrollado por el equipo Brain de Google Research. Una IA creó esta imagen a partir de la pregunta: \"Una foto de un perro Corgi montando en bicicleta en Times Square. Lleva gafas de sol y un sombrero de playa\". ¡Qué maravilla! También puedes cambiar la url que aparece a continuación por cualquier enlace .jpg para cargar una imagen personalizada de tu elección.\n",
        "\n",
        "Comienza leyendo y visualizando la imagen. Después de leer un archivo JPEG, Matplotlib produce una matriz, ${\\mathrm{I}}$, de forma $(m \\times n \\times 3)$ que representa una imagen bidimensional con 3 canales de color para el rojo, verde y azul respectivamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OVsZOQUAZ2C7"
      },
      "outputs": [],
      "source": [
        "img_link = \"https://imagen.research.google/main_gallery_images/a-photo-of-a-corgi-dog-riding-a-bike-in-times-square.jpg\"\n",
        "img_path = requests.get(img_link, stream=True).raw\n",
        "I = imread(img_path, 0)\n",
        "print(\"Input Image Shape:\", I.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qvs7uftcZ54x"
      },
      "outputs": [],
      "source": [
        "def show_img(I):\n",
        "  # Muestra la imagen en matplotlib\n",
        "  img = plt.imshow(I)\n",
        "  plt.axis('off')\n",
        "  return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZbesXO3HZ6Qs"
      },
      "outputs": [],
      "source": [
        "show_img(I)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdnUBVg_JoOa"
      },
      "source": [
        "## El algoritmo de compresión de imágenes\n",
        "\n",
        "Ahora, utilice la SVD para calcular aproximaciones de bajo rango para la imagen de muestra. Recuerde que la imagen es de forma $(1024 \\times 1024 \\times 3)$ y que la teoría SVD solo se aplica para matrices bidimensionales. Esto significa que la imagen de muestra debe dividirse en 3 matrices del mismo tamaño para cada uno de los 3 canales de color. Esto se puede hacer mediante la transposición de la matriz para que tenga la forma $(3 \\times 1024 \\times 1024)$. Con el fin de visualizar claramente el error de aproximación, reescalar los valores RGB de la imagen de $[0,255]$ a $[0,1]$. Recuerde que debe recortar los valores aproximados para que caigan dentro de este intervalo antes de visualizarlos. La función `tf.clip_by_value` es útil para este propósito."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i7DDp0h7oSIk"
      },
      "outputs": [],
      "source": [
        "def compress_image(I, r, verbose=False):\n",
        "# Comprime una imagen con la SVD con un rango determinado \n",
        "  I_size = tf.size(I)\n",
        "  print(f\"Original size of image: {I_size}\")\n",
        "  # Compute SVD of image\n",
        "  I = tf.convert_to_tensor(I)/255\n",
        "  I_batched = tf.transpose(I, [2, 0, 1]) # einops.rearrange(I, 'h w c -> c h w')\n",
        "  s, U, V = tf.linalg.svd(I_batched)\n",
        "  # Calcula la aproximación de bajo rango de la imagen en cada canal RGB\n",
        "  I_r, I_r_size = rank_r_approx(s, U, V, r)\n",
        "  I_r = tf.transpose(I_r, [1, 2, 0]) # einops.rearrange(I_r, 'c h w -> h w c')\n",
        "  I_r_prop = (I_r_size / I_size)\n",
        "  if verbose:\n",
        "# Muestra la imagen comprimida y sus atributos\n",
        "    print(f\"Number of singular values used in compression: {r}\")\n",
        "    print(f\"Compressed image size: {I_r_size}\")\n",
        "    print(f\"Proportion of original size: {I_r_prop:.3f}\")\n",
        "    ax_1 = plt.subplot(1,2,1)\n",
        "    show_img(tf.clip_by_value(I_r,0.,1.))\n",
        "    ax_1.set_title(\"Approximated image\")\n",
        "    ax_2 = plt.subplot(1,2,2)\n",
        "    show_img(tf.clip_by_value(0.5+abs(I-I_r),0.,1.))\n",
        "    ax_2.set_title(\"Error\")\n",
        "  return I_r, I_r_prop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGQ_rTyKDX9F"
      },
      "source": [
        "Ahora, calcule aproximaciones de rango-r para los siguientes rangos: 100, 50, 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7GlKkVLGDjre"
      },
      "outputs": [],
      "source": [
        "I_100, I_100_prop = compress_image(I, 100, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XdvUkF5_E75D"
      },
      "outputs": [],
      "source": [
        "I_50, I_50_prop = compress_image(I, 50, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MsCNZ8416Sbk"
      },
      "outputs": [],
      "source": [
        "I_10, I_10_prop = compress_image(I, 10, verbose=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfYYBhcuNkvH"
      },
      "source": [
        "## Evaluación de las aproximaciones\n",
        "\n",
        "Hay una variedad de métodos interesantes para medir la eficacia y tener más control sobre las aproximaciones de las matrices."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2Lotde9Zg7v"
      },
      "source": [
        "### Factor de compresión vs rango\n",
        "\n",
        "Para cada una de las aproximaciones anteriores, observe cómo cambia el tamaño de los datos en función del rango."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O1ariNQe6Wbl"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(11,6))\n",
        "plt.plot([100, 50, 10], [I_100_prop, I_50_prop, I_10_prop])\n",
        "plt.xlabel(\"Rank\")\n",
        "plt.ylabel(\"Proportion of original image size\")\n",
        "plt.title(\"Compression factor vs rank\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvHcLRj2QoDg"
      },
      "source": [
        "Según este gráfico, hay una relación lineal entre el factor de compresión de una imagen aproximada y su rango. Para profundizar en este tema, recordemos que el tamaño de los datos de una matriz aproximada, ${mathrm{A}}_r$, se define como el número de elementos totales necesarios para calcularla. Las siguientes ecuaciones se pueden utilizar para encontrar la relación entre el factor de compresión y el rango:\n",
        "\n",
        "$$x = (m \\times r) + r + (r \\times n) = r \\times (m + n + 1)$$\n",
        "\n",
        "$$c = \\large \\frac{x}{y} = \\frac{r \\times (m + n + 1)}{m \\times n}$$\n",
        "\n",
        "donde:\n",
        "\n",
        "- $x$: tamaño de ${\\mathrm{A_r}}$\n",
        "- $y$: tamaño de ${\\mathrm{A}}$\n",
        "- $c = \\frac{x}{y}$: factor de compresión\n",
        "- $r$: rango de la aproximación\n",
        "- $m$ y $n$: dimensiones de la fila y la columna de ${\\mathrm{A}}$\n",
        "\n",
        "Para encontrar el rango, $r$, que es necesario para comprimir una imagen en un factor deseado, $c$, la ecuación anterior se puede reorganizar para solucionar $r$:\n",
        "\n",
        "$$r = ⌊{\\large\\frac{c \\times m \\times n}{m + n + 1}}⌋$$\n",
        "\n",
        "Tenga en cuenta que esta fórmula es independiente del canal de color, ya que cada una de las aproximaciones RGB no se modifican entre sí. Ahora, escriba una función para comprimir una imagen de entrada dada por un factor de compresión deseado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "viVO-I60QynI"
      },
      "outputs": [],
      "source": [
        "def compress_image_with_factor(I, compression_factor, verbose=False):\n",
        "  # Devuelve una imagen comprimida basada en un factor de compresión deseado\n",
        "  m,n,o = I.shape\n",
        "  r = int((compression_factor * m * n)/(m + n + 1))\n",
        "  I_r, I_r_prop = compress_image(I, r, verbose=verbose)\n",
        "  return I_r"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWSv58J6LSRQ"
      },
      "source": [
        "Comprima una imagen hasta un 15% de su tamaño original."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HVeeloIwQ1b6"
      },
      "outputs": [],
      "source": [
        "compression_factor = 0.15\n",
        "I_r_img = compress_image_with_factor(I, compression_factor, verbose=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LkeRyms7jZMd"
      },
      "source": [
        "### Suma acumulada de valores únicos\n",
        "\n",
        "La suma acumulada de valores únicos puede ser un indicador útil para la cantidad de energía capturada por una aproximación rank-r. Visualice la proporción acumulada promedio de valores únicos RGB en la imagen de muestra. La función `tf.cumsum` puede ser útil para esto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CteJ6VbKlndu"
      },
      "outputs": [],
      "source": [
        "def viz_energy(I):\n",
        "# Visualice la energía capturada basada en el rango\n",
        "# Cálculo de la SVD\n",
        "  I = tf.convert_to_tensor(I)/255\n",
        "  I_batched = tf.transpose(I, [2, 0, 1]) \n",
        "  s, U, V = tf.linalg.svd(I_batched)\n",
        "# Graficar la proporción promedio mediante los canales RGB \n",
        "  props_rgb = tf.map_fn(lambda x: tf.cumsum(x)/tf.reduce_sum(x), s)\n",
        "  props_rgb_mean = tf.reduce_mean(props_rgb, axis=0)\n",
        "  plt.figure(figsize=(11,6))\n",
        "  plt.plot(range(len(I)), props_rgb_mean, color='k')\n",
        "  plt.xlabel(\"Rank / singular value number\")\n",
        "  plt.ylabel(\"Cumulative proportion of singular values\")\n",
        "  plt.title(\"RGB-averaged proportion of energy captured by the first 'r' singular values\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vl9PKow-GgCp"
      },
      "outputs": [],
      "source": [
        "viz_energy(I)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQtwimKuQP19"
      },
      "source": [
        "Parece que más del 90% de la energía de esta imagen se captura dentro de los 100 primeros valores únicos. Ahora, escriba una función para comprimir una imagen de entrada con el factor de retención de energía que desee."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fum5Cvm7R5vH"
      },
      "outputs": [],
      "source": [
        "def compress_image_with_energy(I, energy_factor, verbose=False):\n",
        "  # Devuelve una imagen comprimida basada en un factor de energía deseado\n",
        "# Calcula la SVD\n",
        "  I_rescaled = tf.convert_to_tensor(I)/255\n",
        "  I_batched = tf.transpose(I_rescaled, [2, 0, 1]) \n",
        "  s, U, V = tf.linalg.svd(I_batched)\n",
        "# Extracción de valores únicos\n",
        "  props_rgb = tf.map_fn(lambda x: tf.cumsum(x)/tf.reduce_sum(x), s)\n",
        "  props_rgb_mean = tf.reduce_mean(props_rgb, axis=0)\n",
        "# Encuentra la r más cercana que corresponde al factor de energía\n",
        "  r = tf.argmin(tf.abs(props_rgb_mean - energy_factor)) + 1\n",
        "  actual_ef = props_rgb_mean[r]\n",
        "  I_r, I_r_prop = compress_image(I, r, verbose=verbose)\n",
        "  print(f\"Proportion of energy captured by the first {r} singular values: {actual_ef:.3f}\")\n",
        "  return I_r"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_rChG0OLby1"
      },
      "source": [
        "Comprime una imagen para retener el 75% de su energía."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xDXBaZQ4c5jF"
      },
      "outputs": [],
      "source": [
        "energy_factor = 0.75\n",
        "I_r_img = compress_image_with_energy(I, energy_factor, verbose=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tmqTW0CYX-v"
      },
      "source": [
        "### Error y valores únicos\n",
        "\n",
        "También hay una relación interesante entre el error de aproximación y los valores únicos. Resulta que la norma de Frobenius al cuadrado de la aproximación es igual a la suma de los cuadrados de sus valores únicos excluidos:\n",
        "\n",
        "$${||A - A_r||}^2 = \\sum_{i=r+1}^{R}σ_i^2$$\n",
        "\n",
        "Pruebe esta relación con una aproximación de rango 10 de la matriz de ejemplo que aparece al principio de este tutorial."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hctOvN8BckiS"
      },
      "outputs": [],
      "source": [
        "s, U, V = tf.linalg.svd(A)\n",
        "A_10, A_10_size = rank_r_approx(s, U, V, 10)\n",
        "squared_norm = tf.norm(A - A_10)**2\n",
        "s_squared_sum = tf.reduce_sum(s[10:]**2)\n",
        "print(f\"Squared Frobenius norm: {squared_norm:.3f}\")\n",
        "print(f\"Sum of squared singular values left out: {s_squared_sum:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgGQuV-yqYZH"
      },
      "source": [
        "## Conclusión\n",
        "\n",
        "En este bloc de notas se introdujo el proceso de implementación de la descomposición de valor único con TensorFlow y su aplicación para escribir un algoritmo de compresión de imágenes. Aquí encontrará algunos consejos adicionales que pueden ser útiles:\n",
        "\n",
        "- Las [API de TensorFlow Core](https://www.tensorflow.org/guide/core) se pueden utilizar para resolver una gran variedad de casos de computación científica de alto rendimiento.\n",
        "- Para obtener más información sobre las funciones de álgebra lineal de TensorFlow, visite la documentación del [módulo linalg](https://www.tensorflow.org/api_docs/python/tf/linalg).\n",
        "- La SVD también puede aplicarse para crear [sistemas de recomendación](https://developers.google.com/machine-learning/recommendation/labs/movie-rec-programming-exercise).\n",
        "\n",
        "Para obtener más ejemplos sobre el uso de las API de TensorFlow Core, consulte la [guía](https://www.tensorflow.org/guide/core). Si desea obtener más información sobre la carga y preparación de datos, consulte los tutoriales sobre la [carga de datos de imagen](https://www.tensorflow.org/tutorials/load_data/images) o la [carga de datos CSV](https://www.tensorflow.org/tutorials/load_data/csv)."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "matrix_core.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
