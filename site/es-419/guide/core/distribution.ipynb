{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FhGuhbZ6M5tl"
      },
      "source": [
        "##### Copyright 2022 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "AwOEIRJC6Une"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIdT9iu_Z4Rb"
      },
      "source": [
        "# Entrenamiento distribuido con las API del núcleo y DTensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBIlTPscrIT9"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td><a target=\"_blank\" href=\"https://www.tensorflow.org/guide/core/distribution\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver en TensorFlow.org</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/es-419/guide/core/distribution.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Ejecutar en Google Colab</a></td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/es-419/guide/core/distribution.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver el código fuente en GitHub</a> </td>\n",
        "  <td><a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/es-419/guide/core/distribution.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Descargar el bloc de notas</a></td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SjAxxRpBzVYg"
      },
      "source": [
        "## Introducción\n",
        "\n",
        "Este bloc de notas utiliza las API de bajo nivel [TensorFlow Core](https://www.tensorflow.org/guide/core) y [DTensor](https://www.tensorflow.org/guide/dtensor_overview) para demostrar un ejemplo de entrenamiento distribuido paralelo de datos. Visite la sección [Descripción general de las API Core](https://www.tensorflow.org/guide/core) para obtener más información sobre TensorFlow Core y sus casos de uso previstos. Consulte la guía [Descripción general de DTensor](https://www.tensorflow.org/guide/dtensor_overview) y el tutorial [Entrenamiento distribuido con DTensors](https://www.tensorflow.org/tutorials/distribute/dtensor_ml_tutorial) para obtener más información sobre DTensor.\n",
        "\n",
        "En este ejemplo se utiliza el mismo modelo y optimizador que se mostró en el tutorial [perceptrones multicapa](https://www.tensorflow.org/guide/core/mlp_core). Vea este tutorial primero para familiarizarse con la escritura del flujo de trabajo para aprendizaje automático de extremo a extremo con las API Core.\n",
        "\n",
        "Nota: DTensor todavía es una API experimental de TensorFlow, lo cual significa que sus funciones están disponibles para pruebas, y su uso está previsto únicamente en entornos de prueba."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_OFkG0dyWCp"
      },
      "source": [
        "## Descripción general del entrenamiento paralelo de datos con DTensor\n",
        "\n",
        "Antes de construir un MLP que admita la distribución, tómese un momento para explorar los fundamentos de DTensor para el entrenamiento paralelo de datos.\n",
        "\n",
        "DTensor permite ejecutar entrenamientos distribuidos por medio de dispositivos para mejorar la eficiencia, la confiabilidad y la escalabilidad. DTensor distribuye el programa y los tensores de acuerdo con las directivas de fragmentación mediante un procedimiento denominado Expansión de programa único, datos múltiples (SPMD). Una variable de una capa consciente de `DTensor` se crea como `dtensor.DVariable`, y los constructores de objetos de capa conscientes de `DTensor` toman entradas adicionales `Layout` además de los parámetros habituales de la capa.\n",
        "\n",
        "Las ideas principales para el entrenamiento paralelo de datos son las siguientes:\n",
        "\n",
        "- Las variables del modelo se reproducen en N dispositivos cada una.\n",
        "- Un lote global se divide en N lotes por réplica.\n",
        "- Cada lote por réplica se entrena en el dispositivo de réplica.\n",
        "- El gradiente se reduce antes de que la ponderación de los datos se realice colectivamente en todas las réplicas.\n",
        "- El entrenamiento paralelo de datos ofrece una aceleración casi lineal con respecto al número de dispositivos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nchsZfwEVtVs"
      },
      "source": [
        "## Preparación\n",
        "\n",
        "DTensor forma parte de la versión 2.9.0 de TensorFlow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "latuqlI_Yvoo"
      },
      "outputs": [],
      "source": [
        "#!pip install --quiet --upgrade --pre tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1rRo8oNqZ-Rj"
      },
      "outputs": [],
      "source": [
        "import matplotlib\n",
        "from matplotlib import pyplot as plt\n",
        "# Preset Matplotlib figure sizes.\n",
        "matplotlib.rcParams['figure.figsize'] = [9, 6]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9xQKvCJ85kCQ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.experimental import dtensor\n",
        "print(tf.__version__)\n",
        "# Set random seed for reproducible results \n",
        "tf.random.set_seed(22)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDH9-sy4sfPf"
      },
      "source": [
        "Configure 8 CPUs virtuales para este experimento. DTensor también se puede utilizar con dispositivos GPU o TPU. Dado que este bloc de notas utiliza dispositivos virtuales, el aumento de la velocidad obtenido del entrenamiento distribuido no es perceptible. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H2iM-6J4s2D6"
      },
      "outputs": [],
      "source": [
        "def configure_virtual_cpus(ncpu):\n",
        "  phy_devices = tf.config.list_physical_devices('CPU')\n",
        "  tf.config.set_logical_device_configuration(phy_devices[0], [\n",
        "        tf.config.LogicalDeviceConfiguration(),\n",
        "    ] * ncpu)\n",
        "\n",
        "configure_virtual_cpus(8)\n",
        "\n",
        "DEVICES = [f'CPU:{i}' for i in range(8)]\n",
        "devices = tf.config.list_logical_devices('CPU')\n",
        "device_names = [d.name for d in devices]\n",
        "device_names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_72b0LCNbjx"
      },
      "source": [
        "## El conjunto de datos MNIST\n",
        "\n",
        "El conjunto de datos está disponible en [TensorFlow Datasets](https://www.tensorflow.org/datasets/catalog/mnist). Divida los datos en conjuntos de entrenamiento y prueba. Utilice solo 5,000 ejemplos para el entrenamiento y las pruebas, esto le permitirá ahorrar tiempo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8h4fV_JCfPIX"
      },
      "outputs": [],
      "source": [
        "train_data, test_data = tfds.load(\"mnist\", split=['train[:5000]', 'test[:5000]'], batch_size=128, as_supervised=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twkJ35YB6tSi"
      },
      "source": [
        "### Preprocesamiento de los datos\n",
        "\n",
        "Preprocese los datos dándoles forma bidimensional y reescalándolos para que se ajusten al intervalo unitario [0,1]."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Cmjhg0xCqbz"
      },
      "outputs": [],
      "source": [
        "def preprocess(x, y):\n",
        "  # Reshaping the data\n",
        "  x = tf.reshape(x, shape=[-1, 784])\n",
        "  # Rescaling the data\n",
        "  x = x/255\n",
        "  return x, y\n",
        "\n",
        "train_data, test_data = train_data.map(preprocess), test_data.map(preprocess)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6o3CrycBXA2s"
      },
      "source": [
        "## Cree la MLP\n",
        "\n",
        "Construya un modelo MLP con capas conscientes del DTensor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHW6Yvg2yS6H"
      },
      "source": [
        "### La capa densa\n",
        "\n",
        "Comience por crear un módulo de capa densa que soporte DTensor. La función `dtensor.call_with_layout` se puede utilizar para llamar a una función que toma una entrada DTensor y produce una salida DTensor. Esto es útil para inicializar una variable DTensor, `dtensor.DVariable`, con una función soportada por TensorFlow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IM0yJos25FG5"
      },
      "outputs": [],
      "source": [
        "class DenseLayer(tf.Module):\n",
        "\n",
        "  def __init__(self, in_dim, out_dim, weight_layout, activation=tf.identity):\n",
        "    super().__init__()\n",
        "    # Initialize dimensions and the activation function\n",
        "    self.in_dim, self.out_dim = in_dim, out_dim\n",
        "    self.activation = activation\n",
        "\n",
        "    # Initialize the DTensor weights using the Xavier scheme\n",
        "    uniform_initializer = tf.function(tf.random.stateless_uniform)\n",
        "    xavier_lim = tf.sqrt(6.)/tf.sqrt(tf.cast(self.in_dim + self.out_dim, tf.float32))\n",
        "    self.w = dtensor.DVariable(\n",
        "      dtensor.call_with_layout(\n",
        "          uniform_initializer, weight_layout,\n",
        "          shape=(self.in_dim, self.out_dim), seed=(22, 23),\n",
        "          minval=-xavier_lim, maxval=xavier_lim))\n",
        "        \n",
        "    # Initialize the bias with the zeros\n",
        "    bias_layout = weight_layout.delete([0])\n",
        "    self.b = dtensor.DVariable(\n",
        "      dtensor.call_with_layout(tf.zeros, bias_layout, shape=[out_dim]))\n",
        "\n",
        "  def __call__(self, x):\n",
        "    # Compute the forward pass\n",
        "    z = tf.add(tf.matmul(x, self.w), self.b)\n",
        "    return self.activation(z)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-7MzpjgyHg6"
      },
      "source": [
        "### <a>El modelo secuencial de MLP</a>\n",
        "\n",
        "Ahora cree un módulo MLP que ejecute las capas densas secuencialmente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6XisRWiCyHAb"
      },
      "outputs": [],
      "source": [
        "class MLP(tf.Module):\n",
        "\n",
        "  def __init__(self, layers):\n",
        "    self.layers = layers\n",
        "   \n",
        "  def __call__(self, x, preds=False): \n",
        "    # Execute the model's layers sequentially\n",
        "    for layer in self.layers:\n",
        "      x = layer(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5HZJ0kv-V3v"
      },
      "source": [
        "Realizar un entrenamiento \"data-parallel\" con DTensor es equivalente a `tf.distribute.MirroredStrategy`. Para ello cada dispositivo ejecutará el mismo modelo en un fragmento del lote de datos. Así que necesitará lo siguiente:\n",
        "\n",
        "- Un `dtensor.Mesh` con una única dimensión `\"\"batch\"`\n",
        "- Un `dtensor.Layout` para todos los pesos que los replica en toda la malla (usando `dtensor.UNSHARDED` para cada eje)\n",
        "- Un `dtensor.Layout` para los datos que dividen la dimensión del lote a lo largo de la malla\n",
        "\n",
        "Cree una malla DTensor que consista en una única dimensión de lote, donde cada dispositivo se convierte en una réplica que recibe un fragmento del lote global. Utilice esta malla para instanciar un modo MLP con la siguiente arquitectura:\n",
        "\n",
        "Siguiente paso: ReLU (784 x 700) x ReLU (700 x 500) x Softmax (500 x 10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VmlACuki3oPi"
      },
      "outputs": [],
      "source": [
        "mesh = dtensor.create_mesh([(\"batch\", 8)], devices=DEVICES)\n",
        "weight_layout = dtensor.Layout([dtensor.UNSHARDED, dtensor.UNSHARDED], mesh)\n",
        "\n",
        "input_size = 784\n",
        "hidden_layer_1_size = 700\n",
        "hidden_layer_2_size = 500\n",
        "hidden_layer_2_size = 10\n",
        "\n",
        "mlp_model = MLP([\n",
        "    DenseLayer(in_dim=input_size, out_dim=hidden_layer_1_size, \n",
        "               weight_layout=weight_layout,\n",
        "               activation=tf.nn.relu),\n",
        "    DenseLayer(in_dim=hidden_layer_1_size , out_dim=hidden_layer_2_size,\n",
        "               weight_layout=weight_layout,\n",
        "               activation=tf.nn.relu),\n",
        "    DenseLayer(in_dim=hidden_layer_2_size, out_dim=hidden_layer_2_size, \n",
        "               weight_layout=weight_layout)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyBATDoRmDkg"
      },
      "source": [
        "### Métricas de entrenamiento\n",
        "\n",
        "Utilice la función de pérdida de entropía cruzada y la métrica de precisión para realizar el entrenamiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rskOYA7FVCwg"
      },
      "outputs": [],
      "source": [
        "def cross_entropy_loss(y_pred, y):\n",
        "  # Compute cross entropy loss with a sparse operation\n",
        "  sparse_ce = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=y_pred)\n",
        "  return tf.reduce_mean(sparse_ce)\n",
        "\n",
        "def accuracy(y_pred, y):\n",
        "  # Compute accuracy after extracting class predictions\n",
        "  class_preds = tf.argmax(y_pred, axis=1)\n",
        "  is_equal = tf.equal(y, class_preds)\n",
        "  return tf.reduce_mean(tf.cast(is_equal, tf.float32))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSiNRhTOnKZr"
      },
      "source": [
        "### Optimizador\n",
        "\n",
        "El uso de un optimizador puede resultar en una convergencia significativamente más rápida en comparación con el descenso del gradiente estándar. El optimizador Adam se implementa a continuación y se configuró para que sea compatible con DTensor. Para utilizar optimizadores de Keras con DTensor, consulte el módulo experimental`tf.keras.dtensor.experimental.optimizers`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-9kIAI_lfXDS"
      },
      "outputs": [],
      "source": [
        "class Adam(tf.Module):\n",
        "\n",
        "    def __init__(self, model_vars, learning_rate=1e-3, beta_1=0.9, beta_2=0.999, ep=1e-7):\n",
        "      # Initialize optimizer parameters and variable slots\n",
        "      self.model_vars = model_vars\n",
        "      self.beta_1 = beta_1\n",
        "      self.beta_2 = beta_2\n",
        "      self.learning_rate = learning_rate\n",
        "      self.ep = ep\n",
        "      self.t = 1.\n",
        "      self.v_dvar, self.s_dvar = [], []\n",
        "      # Initialize optimizer variable slots\n",
        "      for var in model_vars:\n",
        "        v = dtensor.DVariable(dtensor.call_with_layout(tf.zeros, var.layout, shape=var.shape))\n",
        "        s = dtensor.DVariable(dtensor.call_with_layout(tf.zeros, var.layout, shape=var.shape))\n",
        "        self.v_dvar.append(v)\n",
        "        self.s_dvar.append(s)\n",
        "\n",
        "    def apply_gradients(self, grads):\n",
        "      # Update the model variables given their gradients\n",
        "      for i, (d_var, var) in enumerate(zip(grads, self.model_vars)):\n",
        "        self.v_dvar[i].assign(self.beta_1*self.v_dvar[i] + (1-self.beta_1)*d_var)\n",
        "        self.s_dvar[i].assign(self.beta_2*self.s_dvar[i] + (1-self.beta_2)*tf.square(d_var))\n",
        "        v_dvar_bc = self.v_dvar[i]/(1-(self.beta_1**self.t))\n",
        "        s_dvar_bc = self.s_dvar[i]/(1-(self.beta_2**self.t))\n",
        "        var.assign_sub(self.learning_rate*(v_dvar_bc/(tf.sqrt(s_dvar_bc) + self.ep)))\n",
        "      self.t += 1.\n",
        "      return "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w54b7GtLfn1j"
      },
      "source": [
        "### Empaquetado de datos\n",
        "\n",
        "Comience escribiendo una función de ayuda para transferir datos al dispositivo. Esta función debería usar `dtensor.pack` para enviar (y sólo enviar) el fragmento del lote global que está destinado para una réplica al dispositivo que respalda la réplica. Para simplificar, supongamos una aplicación de un solo cliente.\n",
        "\n",
        "Después, escriba una función que la utilice para empaquetar los lotes de datos de entrenamiento en DTensors fragmentados a lo largo del eje del lote (primero). Esto garantizará que DTensor distribuya uniformemente los datos del entrenamiento en la dimensión de la malla del \"lote\". Tenga en cuenta que en DTensor, el tamaño del lote siempre se refiere al tamaño global del lote; por lo tanto, el tamaño del lote debe ser elegido de tal manera que pueda ser dividido uniformemente por el tamaño de la dimensión de la malla del lote. Se están planeando APIs de DTensor adicionales para simplificar la integración de `tf.data`, así que permanezca atento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Rx82djZ6ITm"
      },
      "outputs": [],
      "source": [
        "def repack_local_tensor(x, layout):\n",
        "  # Repacks a local Tensor-like to a DTensor with layout\n",
        "  # This function assumes a single-client application\n",
        "  x = tf.convert_to_tensor(x)\n",
        "  sharded_dims = []\n",
        "\n",
        "  # For every sharded dimension, use tf.split to split the along the dimension.\n",
        "  # The result is a nested list of split-tensors in queue[0].\n",
        "  queue = [x]\n",
        "  for axis, dim in enumerate(layout.sharding_specs):\n",
        "    if dim == dtensor.UNSHARDED:\n",
        "      continue\n",
        "    num_splits = layout.shape[axis]\n",
        "    queue = tf.nest.map_structure(lambda x: tf.split(x, num_splits, axis=axis), queue)\n",
        "    sharded_dims.append(dim)\n",
        "\n",
        "  # Now you can build the list of component tensors by looking up the location in\n",
        "  # the nested list of split-tensors created in queue[0].\n",
        "  components = []\n",
        "  for locations in layout.mesh.local_device_locations():\n",
        "    t = queue[0]\n",
        "    for dim in sharded_dims:\n",
        "      split_index = locations[dim]  # Only valid on single-client mesh.\n",
        "      t = t[split_index]\n",
        "    components.append(t)\n",
        "\n",
        "  return dtensor.pack(components, layout)\n",
        "\n",
        "def repack_batch(x, y, mesh):\n",
        "  # Pack training data batches into DTensors along the batch axis\n",
        "  x = repack_local_tensor(x, layout=dtensor.Layout(['batch', dtensor.UNSHARDED], mesh))\n",
        "  y = repack_local_tensor(y, layout=dtensor.Layout(['batch'], mesh))\n",
        "  return x, y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osEK3rqpYfKd"
      },
      "source": [
        "### Entrenamiento\n",
        "\n",
        "Escribe una función rastreable que ejecute un único paso de entrenamiento dado un lote de datos. Esta función no requiere ninguna anotación de DTensor especial. También escriba una función que ejecute un paso de prueba y devuelva las métricas de rendimiento apropiadas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZICEsDGuSbDD"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def train_step(model, x_batch, y_batch, loss, metric, optimizer):\n",
        "  # Execute a single training step\n",
        "  with tf.GradientTape() as tape:\n",
        "    y_pred = model(x_batch)\n",
        "    batch_loss = loss(y_pred, y_batch)\n",
        "  # Compute gradients and update the model's parameters\n",
        "  grads = tape.gradient(batch_loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(grads)\n",
        "  # Return batch loss and accuracy\n",
        "  batch_acc = metric(y_pred, y_batch)\n",
        "  return batch_loss, batch_acc\n",
        "\n",
        "@tf.function\n",
        "def test_step(model, x_batch, y_batch, loss, metric):\n",
        "  # Execute a single testing step\n",
        "  y_pred = model(x_batch)\n",
        "  batch_loss = loss(y_pred, y_batch)\n",
        "  batch_acc = metric(y_pred, y_batch)\n",
        "  return batch_loss, batch_acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjIDVTwwX-Mr"
      },
      "source": [
        "Ahora, entrene el modelo MLP durante 3 épocas con un tamaño de lote de 128."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oC85kuZgmh3q"
      },
      "outputs": [],
      "source": [
        "# Initialize the training loop parameters and structures\n",
        "epochs = 3\n",
        "batch_size = 128\n",
        "train_losses, test_losses = [], []\n",
        "train_accs, test_accs = [], []\n",
        "optimizer = Adam(mlp_model.trainable_variables)\n",
        "\n",
        "# Format training loop\n",
        "for epoch in range(epochs):\n",
        "  batch_losses_train, batch_accs_train = [], []\n",
        "  batch_losses_test, batch_accs_test = [], []\n",
        "\n",
        "  # Iterate through training data\n",
        "  for x_batch, y_batch in train_data:\n",
        "    x_batch, y_batch = repack_batch(x_batch, y_batch, mesh)\n",
        "    batch_loss, batch_acc = train_step(mlp_model, x_batch, y_batch, cross_entropy_loss, accuracy, optimizer)\n",
        "   # Keep track of batch-level training performance\n",
        "    batch_losses_train.append(batch_loss)\n",
        "    batch_accs_train.append(batch_acc)\n",
        "\n",
        "  # Iterate through testing data\n",
        "  for x_batch, y_batch in test_data:\n",
        "    x_batch, y_batch = repack_batch(x_batch, y_batch, mesh)\n",
        "    batch_loss, batch_acc = test_step(mlp_model, x_batch, y_batch, cross_entropy_loss, accuracy)\n",
        "    # Keep track of batch-level testing\n",
        "    batch_losses_test.append(batch_loss)\n",
        "    batch_accs_test.append(batch_acc)\n",
        "\n",
        "# Keep track of epoch-level model performance\n",
        "  train_loss, train_acc = tf.reduce_mean(batch_losses_train), tf.reduce_mean(batch_accs_train)\n",
        "  test_loss, test_acc = tf.reduce_mean(batch_losses_test), tf.reduce_mean(batch_accs_test)\n",
        "  train_losses.append(train_loss)\n",
        "  train_accs.append(train_acc)\n",
        "  test_losses.append(test_loss)\n",
        "  test_accs.append(test_acc)\n",
        "  print(f\"Epoch: {epoch}\")\n",
        "  print(f\"Training loss: {train_loss.numpy():.3f}, Training accuracy: {train_acc.numpy():.3f}\")\n",
        "  print(f\"Testing loss: {test_loss.numpy():.3f}, Testing accuracy: {test_acc.numpy():.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_RVmt43G12R"
      },
      "source": [
        "### Evaluación del desempeño\n",
        "\n",
        "Empiece por escribir una función para visualizar las pérdidas y la precisión del modelo durante el entrenamiento. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VXTCYVtNDjAM"
      },
      "outputs": [],
      "source": [
        "def plot_metrics(train_metric, test_metric, metric_type):\n",
        "  # Visualize metrics vs training Epochs\n",
        "  plt.figure()\n",
        "  plt.plot(range(len(train_metric)), train_metric, label = f\"Training {metric_type}\")\n",
        "  plt.plot(range(len(test_metric)), test_metric, label = f\"Testing {metric_type}\")\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(metric_type)\n",
        "  plt.legend()\n",
        "  plt.title(f\"{metric_type} vs Training Epochs\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "407qok7q2JIO"
      },
      "outputs": [],
      "source": [
        "plot_metrics(train_losses, test_losses, \"Cross entropy loss\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8H_TgxV92NfX"
      },
      "outputs": [],
      "source": [
        "plot_metrics(train_accs, test_accs, \"Accuracy\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHO_u-3w4YRF"
      },
      "source": [
        "## Guarde su modelo\n",
        "\n",
        "La integración de `tf.saved_model` y DTensor está todavía en desarrollo. A partir de TensorFlow 2.9.0, tf.saved_model sólo acepta modelos de DTensor con variables totalmente replicadas. Como una solución, se puede convertir un modelo de DTensor a uno totalmente replicado mediante la recarga de un punto de control. Sin embargo, después de guardar un modelo, todas las anotaciones de DTensor se pierden y las firmas guardadas sólo se pueden utilizar con tensores normales. Este tutorial se actualizará para mostrar la integración una vez que se solidifique.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFLfEH4ManbW"
      },
      "source": [
        "## Conclusión\n",
        "\n",
        "Este bloc de notas proporciona una visión general de la formación distribuida con DTensor y las APIs de TensorFlow Core. Aquí hay algunos consejos más que pueden ayudar:\n",
        "\n",
        "- Las [APIs de TensorFlow Core](https://www.tensorflow.org/guide/core) pueden utilizarse para construir flujos de trabajo de aprendizaje automático altamente configurables con soporte para el entrenamiento distribuido.\n",
        "- La guía de los [conceptos de DTensor](https://www.tensorflow.org/guide/dtensor_overview) y el tutorial de [Entrenamiento distribuido con DTensors](https://www.tensorflow.org/tutorials/distribute/dtensor_ml_tutorial) que contienen la información más actualizada sobre DTensor y sus integraciones.\n",
        "\n",
        "Para obtener más ejemplos sobre el uso de las API de TensorFlow Core, consulte la [guía](https://www.tensorflow.org/guide/core). Si desea obtener más información sobre la carga y preparación de datos, consulte los tutoriales sobre la [carga de datos de imagen](https://www.tensorflow.org/tutorials/load_data/images) o la [carga de datos CSV](https://www.tensorflow.org/tutorials/load_data/csv)."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "FhGuhbZ6M5tl"
      ],
      "name": "distribution.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
