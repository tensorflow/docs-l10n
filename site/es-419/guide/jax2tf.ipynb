{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckM5wJMsNTYL"
      },
      "source": [
        "##### Copyright 2023 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "NKvERjPVNWxu"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqePLdDjNhNk"
      },
      "source": [
        "# Cómo importar un modelo JAX mediante JAX2TF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gw3w46yhNiK_"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td><a target=\"_blank\" href=\"https://www.tensorflow.org/guide/jax2tf\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver en TensorFlow.org</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/es-419/guide/jax2tf.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Ejecutar en Google Colab</a></td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/es-419/guide/jax2tf.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver el código fuente en GitHub</a> </td>\n",
        "  <td><a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/es-419/guide/jax2tf.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Descargar el bloc de notas</a></td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IyrsY3uTOmPY"
      },
      "source": [
        "Este bloc de notas proporciona un ejemplo completo y ejecutable para crear un modelo usando [JAX](https://jax.readthedocs.io/en/latest/) y trasladarlo a TensorFlow con el fin de continuar el entrenamiento. Esto es posible gracias a [JAX2TF](https://github.com/google/jax/tree/main/jax/experimental/jax2tf), una API ligera que proporciona un medio para pasar del ecosistema JAX al ecosistema de TensorFlow.\n",
        "\n",
        "JAX es una biblioteca de computación de arreglos de alto rendimiento. Para crear el modelo, este bloc de notas utiliza [Flax](https://flax.readthedocs.io/en/latest/), una biblioteca de redes neuronales para JAX. Para entrenarlo, utiliza [Optax](https://optax.readthedocs.io), una biblioteca de optimización para JAX.\n",
        "\n",
        "Si eres un investigador que utiliza JAX, JAX2TF te ofrece un camino hacia la producción utilizando las herramientas ya demostradas de TensorFlow.\n",
        "\n",
        "Esto puede ser útil de muchas maneras, aquí le presentamos algunas:\n",
        "\n",
        "- Inferencia: Tomar un modelo escrito para JAX e implementarlo en un servidor mediante TF Serving, en un dispositivo mediante TFLite o en la web mediante TensorFlow.js.\n",
        "\n",
        "- Ajuste fino: A partir de un modelo entrenado con JAX, puede llevar sus componentes a TF con JAX2TF y seguir entrenándolo en TensorFlow con los datos de entrenamiento y la configuración actuales.\n",
        "\n",
        "- Fusión: La combinación de partes de modelos que fueron entrenados usando JAX con los entrenados usando TensorFlow, para obtener la máxima flexibilidad.\n",
        "\n",
        "La clave para permitir este tipo de interoperación entre JAX y TensorFlow es `jax2tf.convert`, que toma componentes del modelo creados sobre JAX (su función de pérdida, función de predicción, etc) y crea representaciones equivalentes de ellos como funciones de TensorFlow, que luego se pueden exportar como un TensorFlow SavedModel."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6rtu96yOepm"
      },
      "source": [
        "## Preparación\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9yqxfHzr0LPF"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import flax\n",
        "import optax\n",
        "import os\n",
        "from matplotlib import pyplot as plt\n",
        "from jax.experimental import jax2tf\n",
        "from threading import Lock # Only used in the visualization utility.\n",
        "from functools import partial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SDnTaZO0r872"
      },
      "outputs": [],
      "source": [
        "# Needed for TensorFlow and JAX to coexist in GPU memory.\n",
        "os.environ['XLA_PYTHON_CLIENT_PREALLOCATE'] = \"false\"\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "  try:\n",
        "    for gpu in gpus:\n",
        "      tf.config.experimental.set_memory_growth(gpu, True)\n",
        "  except RuntimeError as e:\n",
        "    # Memory growth must be set before GPUs have been initialized.\n",
        "    print(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "BXOjCNJxDLil"
      },
      "outputs": [],
      "source": [
        "#@title Visualization utilities\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (20,8)\n",
        "\n",
        "# The utility for displaying training and validation curves.\n",
        "def display_train_curves(loss, avg_loss, eval_loss, eval_accuracy, epochs, steps_per_epochs, ignore_first_n=10):\n",
        "\n",
        "  ignore_first_n_epochs = int(ignore_first_n/steps_per_epochs)\n",
        "\n",
        "  # The losses.\n",
        "  ax = plt.subplot(121)\n",
        "  if loss is not None:\n",
        "    x = np.arange(len(loss)) / steps_per_epochs #* epochs\n",
        "    ax.plot(x, loss)\n",
        "  ax.plot(range(1, epochs+1), avg_loss, \"-o\", linewidth=3)\n",
        "  ax.plot(range(1, epochs+1), eval_loss, \"-o\", linewidth=3)\n",
        "  ax.set_title('Loss')\n",
        "  ax.set_ylabel('loss')\n",
        "  ax.set_xlabel('epoch')\n",
        "  if loss is not None:\n",
        "    ax.set_ylim(0, np.max(loss[ignore_first_n:]))\n",
        "    ax.legend(['train', 'avg train', 'eval'])\n",
        "  else:\n",
        "    ymin = np.min(avg_loss[ignore_first_n_epochs:])\n",
        "    ymax = np.max(avg_loss[ignore_first_n_epochs:])\n",
        "    ax.set_ylim(ymin-(ymax-ymin)/10, ymax+(ymax-ymin)/10)\n",
        "    ax.legend(['avg train', 'eval'])\n",
        "\n",
        "  # The accuracy.\n",
        "  ax = plt.subplot(122)\n",
        "  ax.set_title('Eval Accuracy')\n",
        "  ax.set_ylabel('accuracy')\n",
        "  ax.set_xlabel('epoch')\n",
        "  ymin = np.min(eval_accuracy[ignore_first_n_epochs:])\n",
        "  ymax = np.max(eval_accuracy[ignore_first_n_epochs:])\n",
        "  ax.set_ylim(ymin-(ymax-ymin)/10, ymax+(ymax-ymin)/10)\n",
        "  ax.plot(range(1, epochs+1), eval_accuracy, \"-o\", linewidth=3)\n",
        "\n",
        "class Progress:\n",
        "    \"\"\"Text mode progress bar.\n",
        "    Usage:\n",
        "            p = Progress(30)\n",
        "            p.step()\n",
        "            p.step()\n",
        "            p.step(reset=True) # to restart form 0%\n",
        "    The progress bar displays a new header at each restart.\"\"\"\n",
        "    def __init__(self, maxi, size=100, msg=\"\"):\n",
        "        \"\"\"\n",
        "        :param maxi: the number of steps required to reach 100%\n",
        "        :param size: the number of characters taken on the screen by the progress bar\n",
        "        :param msg: the message displayed in the header of the progress bar\n",
        "        \"\"\"\n",
        "        self.maxi = maxi\n",
        "        self.p = self.__start_progress(maxi)()  # `()`: to get the iterator from the generator.\n",
        "        self.header_printed = False\n",
        "        self.msg = msg\n",
        "        self.size = size\n",
        "        self.lock = Lock()\n",
        "\n",
        "    def step(self, reset=False):\n",
        "        with self.lock:\n",
        "            if reset:\n",
        "                self.__init__(self.maxi, self.size, self.msg)\n",
        "            if not self.header_printed:\n",
        "                self.__print_header()\n",
        "            next(self.p)\n",
        "\n",
        "    def __print_header(self):\n",
        "        print()\n",
        "        format_string = \"0%{: ^\" + str(self.size - 6) + \"}100%\"\n",
        "        print(format_string.format(self.msg))\n",
        "        self.header_printed = True\n",
        "\n",
        "    def __start_progress(self, maxi):\n",
        "        def print_progress():\n",
        "            # Bresenham's algorithm. Yields the number of dots printed.\n",
        "            # This will always print 100 dots in max invocations.\n",
        "            dx = maxi\n",
        "            dy = self.size\n",
        "            d = dy - dx\n",
        "            for x in range(maxi):\n",
        "                k = 0\n",
        "                while d >= 0:\n",
        "                    print('=', end=\"\", flush=True)\n",
        "                    k += 1\n",
        "                    d -= dx\n",
        "                d += dy\n",
        "                yield k\n",
        "            # Keep yielding the last result if there are too many steps.\n",
        "            while True:\n",
        "              yield k\n",
        "\n",
        "        return print_progress"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xgS_8nDDIu8"
      },
      "source": [
        "## Descargue y prepare el conjunto de datos MNIST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nbN7rmuF0VFB"
      },
      "outputs": [],
      "source": [
        "(x_train, train_labels), (x_test, test_labels) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "train_data = tf.data.Dataset.from_tensor_slices((x_train, train_labels))\n",
        "train_data = train_data.map(lambda x,y: (tf.expand_dims(tf.cast(x, tf.float32)/255.0, axis=-1),\n",
        "                                         tf.one_hot(y, depth=10)))\n",
        "\n",
        "BATCH_SIZE = 256\n",
        "train_data = train_data.batch(BATCH_SIZE, drop_remainder=True)\n",
        "train_data = train_data.cache()\n",
        "train_data = train_data.shuffle(5000, reshuffle_each_iteration=True)\n",
        "\n",
        "test_data = tf.data.Dataset.from_tensor_slices((x_test, test_labels))\n",
        "test_data = test_data.map(lambda x,y: (tf.expand_dims(tf.cast(x, tf.float32)/255.0, axis=-1),\n",
        "                                         tf.one_hot(y, depth=10)))\n",
        "test_data = test_data.batch(10000)\n",
        "test_data = test_data.cache()\n",
        "\n",
        "(one_batch, one_batch_labels) = next(iter(train_data)) # just one batch\n",
        "(all_test_data, all_test_labels) = next(iter(test_data)) # all in one batch since batch size is 10000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LuZTo7SM3W_n"
      },
      "source": [
        "## Configurar el entrenamiento\n",
        "\n",
        "Este bloc de notas creará y entrenará un modelo sencillo con fines de demostración."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3vbKB4yZ3aTL"
      },
      "outputs": [],
      "source": [
        "# Training hyperparameters.\n",
        "JAX_EPOCHS = 3\n",
        "TF_EPOCHS = 7\n",
        "STEPS_PER_EPOCH = len(train_labels)//BATCH_SIZE\n",
        "LEARNING_RATE = 0.01\n",
        "LEARNING_RATE_EXP_DECAY = 0.6\n",
        "\n",
        "# The learning rate schedule for JAX (with Optax).\n",
        "jlr_decay = optax.exponential_decay(LEARNING_RATE, transition_steps=STEPS_PER_EPOCH, decay_rate=LEARNING_RATE_EXP_DECAY, staircase=True)\n",
        "\n",
        "# THe learning rate schedule for TensorFlow.\n",
        "tflr_decay = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=LEARNING_RATE, decay_steps=STEPS_PER_EPOCH, decay_rate=LEARNING_RATE_EXP_DECAY, staircase=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Od3sMwQxtC34"
      },
      "source": [
        "## Crear el modelo utilizando Flax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ybqQF2zd2QX"
      },
      "outputs": [],
      "source": [
        "class ConvModel(flax.linen.Module):\n",
        "\n",
        "  @flax.linen.compact\n",
        "  def __call__(self, x, train):\n",
        "    x = flax.linen.Conv(features=12, kernel_size=(3,3), padding=\"SAME\", use_bias=False)(x)\n",
        "    x = flax.linen.BatchNorm(use_running_average=not train, use_scale=False, use_bias=True)(x)\n",
        "    x = x.reshape((x.shape[0], -1))  # flatten\n",
        "    x = flax.linen.Dense(features=200, use_bias=True)(x)\n",
        "    x = flax.linen.BatchNorm(use_running_average=not train, use_scale=False, use_bias=True)(x)\n",
        "    x = flax.linen.Dropout(rate=0.3, deterministic=not train)(x)\n",
        "    x = flax.linen.relu(x)\n",
        "    x = flax.linen.Dense(features=10)(x)\n",
        "    #x = flax.linen.log_softmax(x)\n",
        "    return x\n",
        "\n",
        "  # JAX differentiation requires a function `f(params, other_state, data, labels)` -> `loss` (as a single number).\n",
        "  # `jax.grad` will differentiate it against the fist argument.\n",
        "  # The user must split trainable and non-trainable variables into `params` and `other_state`.\n",
        "  # Must pass a different RNG key each time for the dropout mask to be different.\n",
        "  def loss(self, params, other_state, rng, data, labels, train):\n",
        "    logits, batch_stats = self.apply({'params': params, **other_state},\n",
        "                                     data,\n",
        "                                     mutable=['batch_stats'],\n",
        "                                     rngs={'dropout': rng},\n",
        "                                     train=train)\n",
        "    # The loss averaged across the batch dimension.\n",
        "    loss = optax.softmax_cross_entropy(logits, labels).mean()\n",
        "    return loss, batch_stats\n",
        "\n",
        "  def predict(self, state, data):\n",
        "    logits = self.apply(state, data, train=False) # predict and accuracy disable dropout and use accumulated batch norm stats (train=False)\n",
        "    probabilities = flax.linen.log_softmax(logits)\n",
        "    return probabilities\n",
        "\n",
        "  def accuracy(self, state, data, labels):\n",
        "    probabilities = self.predict(state, data)\n",
        "    predictions = jnp.argmax(probabilities, axis=-1)\n",
        "    dense_labels = jnp.argmax(labels, axis=-1)\n",
        "    accuracy = jnp.equal(predictions, dense_labels).mean()\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Cr0FRNFtHN4"
      },
      "source": [
        "## Escriba la función de escalón del entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tmDwApcpgZzw"
      },
      "outputs": [],
      "source": [
        "# The training step.\n",
        "@partial(jax.jit, static_argnums=[0]) # this forces jax.jit to recompile for every new model\n",
        "def train_step(model, state, optimizer_state, rng, data, labels):\n",
        "\n",
        "  other_state, params = state.pop('params') # differentiate only against 'params' which represents trainable variables\n",
        "  (loss, batch_stats), grads = jax.value_and_grad(model.loss, has_aux=True)(params, other_state, rng, data, labels, train=True)\n",
        "\n",
        "  updates, optimizer_state = optimizer.update(grads, optimizer_state)\n",
        "  params = optax.apply_updates(params, updates)\n",
        "  new_state = state.copy(add_or_replace={**batch_stats, 'params': params})\n",
        "\n",
        "  rng, _ = jax.random.split(rng)\n",
        "\n",
        "  return new_state, optimizer_state, rng, loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zr16g6NzV4O9"
      },
      "source": [
        "## Escriba el bucle del entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zbl5w-KUV7Qw"
      },
      "outputs": [],
      "source": [
        "def train(model, state, optimizer_state, train_data, epochs, losses, avg_losses, eval_losses, eval_accuracies):\n",
        "  p = Progress(STEPS_PER_EPOCH)\n",
        "  rng = jax.random.PRNGKey(0)\n",
        "  for epoch in range(epochs):\n",
        "\n",
        "    # This is where the learning rate schedule state is stored in the optimizer state.\n",
        "    optimizer_step = optimizer_state[1].count\n",
        "\n",
        "    # Run an epoch of training.\n",
        "    for step, (data, labels) in enumerate(train_data):\n",
        "      p.step(reset=(step==0))\n",
        "      state, optimizer_state, rng, loss = train_step(model, state, optimizer_state, rng, data.numpy(), labels.numpy())\n",
        "      losses.append(loss)\n",
        "    avg_loss = np.mean(losses[-step:])\n",
        "    avg_losses.append(avg_loss)\n",
        "\n",
        "    # Run one epoch of evals (10,000 test images in a single batch).\n",
        "    other_state, params = state.pop('params')\n",
        "    # Gotcha: must discard modified batch_stats here\n",
        "    eval_loss, _ = model.loss(params, other_state, rng, all_test_data.numpy(), all_test_labels.numpy(), train=False)\n",
        "    eval_losses.append(eval_loss)\n",
        "    eval_accuracy = model.accuracy(state, all_test_data.numpy(), all_test_labels.numpy())\n",
        "    eval_accuracies.append(eval_accuracy)\n",
        "\n",
        "    print(\"\\nEpoch\", epoch, \"train loss:\", avg_loss, \"eval loss:\", eval_loss, \"eval accuracy\", eval_accuracy, \"lr:\", jlr_decay(optimizer_step))\n",
        "\n",
        "  return state, optimizer_state"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGB3W5g0Wt1H"
      },
      "source": [
        "## Cree el modelo y el optimizador (con Optax)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mW5mkmCWtN8W"
      },
      "outputs": [],
      "source": [
        "# The model.\n",
        "model = ConvModel()\n",
        "state = model.init({'params':jax.random.PRNGKey(0), 'dropout':jax.random.PRNGKey(0)}, one_batch, train=True) # Flax allows a separate RNG for \"dropout\"\n",
        "\n",
        "# The optimizer.\n",
        "optimizer = optax.adam(learning_rate=jlr_decay) # Gotcha: it does not seem to be possible to pass just a callable as LR, must be an Optax Schedule\n",
        "optimizer_state = optimizer.init(state['params'])\n",
        "\n",
        "losses=[]\n",
        "avg_losses=[]\n",
        "eval_losses=[]\n",
        "eval_accuracies=[]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJdsKghBNF"
      },
      "source": [
        "## Entrenar al modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nmcofTTBZSIb"
      },
      "outputs": [],
      "source": [
        "new_state, new_optimizer_state = train(model, state, optimizer_state, train_data, JAX_EPOCHS+TF_EPOCHS, losses, avg_losses, eval_losses, eval_accuracies)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n_20vgvDXB5r"
      },
      "outputs": [],
      "source": [
        "display_train_curves(losses, avg_losses, eval_losses, eval_accuracies, len(eval_losses), STEPS_PER_EPOCH, ignore_first_n=1*STEPS_PER_EPOCH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lT3cdENCBzL"
      },
      "source": [
        "## Entrene parcialmente al modelo\n",
        "\n",
        "Continuará entrenando el modelo en TensorFlow enseguida."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KT-xqj5N7C6L"
      },
      "outputs": [],
      "source": [
        "model = ConvModel()\n",
        "state = model.init({'params':jax.random.PRNGKey(0), 'dropout':jax.random.PRNGKey(0)}, one_batch, train=True) # Flax allows a separate RNG for \"dropout\"\n",
        "\n",
        "# The optimizer.\n",
        "optimizer = optax.adam(learning_rate=jlr_decay) # LR must be an Optax LR Schedule\n",
        "optimizer_state = optimizer.init(state['params'])\n",
        "\n",
        "losses, avg_losses, eval_losses, eval_accuracies = [], [], [], []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oa362HMDbzDE"
      },
      "outputs": [],
      "source": [
        "state, optimizer_state = train(model, state, optimizer_state, train_data, JAX_EPOCHS, losses, avg_losses, eval_losses, eval_accuracies)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0IyZtUPPCt0y"
      },
      "outputs": [],
      "source": [
        "display_train_curves(losses, avg_losses, eval_losses, eval_accuracies, len(eval_losses), STEPS_PER_EPOCH, ignore_first_n=1*STEPS_PER_EPOCH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNtlSaOCCumB"
      },
      "source": [
        "## Guarde lo justo para realizar inferencias\n",
        "\n",
        "Si su objetivo es implementar su modelo JAX (para poder ejecutar la inferencia utilizando `model.predict()`), basta con exportarlo a [SavedModel](https://www.tensorflow.org/guide/saved_model). Esta sección muestra cómo hacerlo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O653B3-5H8FL"
      },
      "outputs": [],
      "source": [
        "# Test data with a different batch size to test polymorphic shapes.\n",
        "x, y = next(iter(train_data.unbatch().batch(13)))\n",
        "\n",
        "m = tf.Module()\n",
        "# Wrap the JAX state in `tf.Variable` (needed when calling the converted JAX function.\n",
        "state_vars = tf.nest.map_structure(tf.Variable, state)\n",
        "# Keep the wrapped state as flat list (needed in TensorFlow fine-tuning).\n",
        "m.vars = tf.nest.flatten(state_vars)\n",
        "# Convert the desired JAX function (`model.predict`).\n",
        "predict_fn = jax2tf.convert(model.predict, polymorphic_shapes=[\"...\", \"(b, 28, 28, 1)\"])\n",
        "# Wrap the converted function in `tf.function` with the correct `tf.TensorSpec` (necessary for dynamic shapes to work).\n",
        "@tf.function(autograph=False, input_signature=[tf.TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32)])\n",
        "def predict(data):\n",
        "    return predict_fn(state_vars, data)\n",
        "m.predict = predict\n",
        "tf.saved_model.save(m, \"./\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8HFx67zStgvo"
      },
      "outputs": [],
      "source": [
        "# Test the converted function.\n",
        "print(\"Converted function predictions:\", np.argmax(m.predict(x).numpy(), axis=-1))\n",
        "# Reload the model.\n",
        "reloaded_model = tf.saved_model.load(\"./\")\n",
        "# Test the reloaded converted function (the result should be the same).\n",
        "print(\"Reloaded  function predictions:\", np.argmax(reloaded_model.predict(x).numpy(), axis=-1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEk8wv4HJu94"
      },
      "source": [
        "## Guarde todo\n",
        "\n",
        "Si tu objetivo es una llevar a cabo una exportación completa (útil si planea introducir el modelo en TensorFlow para su ajuste, fusión, etc.), esta sección muestra cómo guardar el modelo para que pueda acceder a métodos como:\n",
        "\n",
        "- model.predict\n",
        "- model.accuracy\n",
        "- model.loss (incluye bool train=True/False, RNG para realizar actualizaciones de estado en dropout y BatchNorm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9mty52pmvDDp"
      },
      "outputs": [],
      "source": [
        "from collections import abc\n",
        "\n",
        "def _fix_frozen(d):\n",
        "  \"\"\"Changes any mappings (e.g. frozendict) back to dict.\"\"\"\n",
        "  if isinstance(d, list):\n",
        "    return [_fix_frozen(v) for v in d]\n",
        "  elif isinstance(d, tuple):\n",
        "    return tuple(_fix_frozen(v) for v in d)\n",
        "  elif not isinstance(d, abc.Mapping):\n",
        "    return d\n",
        "  d = dict(d)\n",
        "  for k, v in d.items():\n",
        "    d[k] = _fix_frozen(v)\n",
        "  return d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3HEsKNXbCwXw"
      },
      "outputs": [],
      "source": [
        "class TFModel(tf.Module):\n",
        "  def __init__(self, state, model):\n",
        "    super().__init__()\n",
        "\n",
        "    # Special care needed for the train=True/False parameter in the loss\n",
        "    @jax.jit\n",
        "    def loss_with_train_bool(state, rng, data, labels, train):\n",
        "      other_state, params = state.pop('params')\n",
        "      loss, batch_stats = jax.lax.cond(train,\n",
        "                                       lambda state, data, labels: model.loss(params, other_state, rng, data, labels, train=True),\n",
        "                                       lambda state, data, labels: model.loss(params, other_state, rng, data, labels, train=False),\n",
        "                                       state, data, labels)\n",
        "      # must use JAX to split the RNG, therefore, must do it in a @jax.jit function\n",
        "      new_rng, _ = jax.random.split(rng)\n",
        "      return loss, batch_stats, new_rng\n",
        "\n",
        "    self.state_vars = tf.nest.map_structure(tf.Variable, state)\n",
        "    self.vars = tf.nest.flatten(self.state_vars)\n",
        "    self.jax_rng = tf.Variable(jax.random.PRNGKey(0))\n",
        "\n",
        "    self.loss_fn = jax2tf.convert(loss_with_train_bool, polymorphic_shapes=[\"...\", \"...\", \"(b, 28, 28, 1)\", \"(b, 10)\", \"...\"])\n",
        "    self.accuracy_fn = jax2tf.convert(model.accuracy, polymorphic_shapes=[\"...\", \"(b, 28, 28, 1)\", \"(b, 10)\"])\n",
        "    self.predict_fn = jax2tf.convert(model.predict, polymorphic_shapes=[\"...\", \"(b, 28, 28, 1)\"])\n",
        "\n",
        "  # Must specify TensorSpec manually for variable batch size to work\n",
        "  @tf.function(autograph=False, input_signature=[tf.TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32)])\n",
        "  def predict(self, data):\n",
        "    # Make sure the TfModel.predict function implicitly use self.state_vars and not the JAX state directly\n",
        "    # otherwise, all model weights would be embedded in the TF graph as constants.\n",
        "    return self.predict_fn(self.state_vars, data)\n",
        "\n",
        "  @tf.function(input_signature=[tf.TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32),\n",
        "                                tf.TensorSpec(shape=(None, 10), dtype=tf.float32)],\n",
        "               autograph=False)\n",
        "  def train_loss(self, data, labels):\n",
        "      loss, batch_stats, new_rng = self.loss_fn(self.state_vars, self.jax_rng, data, labels, True)\n",
        "      # update batch norm stats\n",
        "      flat_vars = tf.nest.flatten(self.state_vars['batch_stats'])\n",
        "      flat_values = tf.nest.flatten(batch_stats['batch_stats'])\n",
        "      for var, val in zip(flat_vars, flat_values):\n",
        "        var.assign(val)\n",
        "      # update RNG\n",
        "      self.jax_rng.assign(new_rng)\n",
        "      return loss\n",
        "\n",
        "  @tf.function(input_signature=[tf.TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32),\n",
        "                                tf.TensorSpec(shape=(None, 10), dtype=tf.float32)],\n",
        "               autograph=False)\n",
        "  def eval_loss(self, data, labels):\n",
        "      loss, batch_stats, new_rng = self.loss_fn(self.state_vars, self.jax_rng, data, labels, False)\n",
        "      return loss\n",
        "\n",
        "  @tf.function(input_signature=[tf.TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32),\n",
        "                                tf.TensorSpec(shape=(None, 10), dtype=tf.float32)],\n",
        "               autograph=False)\n",
        "  def accuracy(self, data, labels):\n",
        "    return self.accuracy_fn(self.state_vars, data, labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "znJrAVpcxO9u"
      },
      "outputs": [],
      "source": [
        "# Instantiate the model.\n",
        "tf_model = TFModel(state, model)\n",
        "\n",
        "# Save the model.\n",
        "tf.saved_model.save(tf_model, \"./\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y02DHEwTjNzV"
      },
      "source": [
        "## Volver a cargar el modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i75yS3v2jPpM"
      },
      "outputs": [],
      "source": [
        "reloaded_model = tf.saved_model.load(\"./\")\n",
        "\n",
        "# Test if it works and that the batch size is indeed variable.\n",
        "x,y = next(iter(train_data.unbatch().batch(13)))\n",
        "print(np.argmax(reloaded_model.predict(x).numpy(), axis=-1))\n",
        "x,y = next(iter(train_data.unbatch().batch(20)))\n",
        "print(np.argmax(reloaded_model.predict(x).numpy(), axis=-1))\n",
        "\n",
        "print(reloaded_model.accuracy(one_batch, one_batch_labels))\n",
        "print(reloaded_model.accuracy(all_test_data, all_test_labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DiwEAwQmlx1x"
      },
      "source": [
        "## Continúe entrenando el modelo JAX convertido en TensorFlow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MubFcO_jl2vE"
      },
      "outputs": [],
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate=tflr_decay)\n",
        "\n",
        "# Set the iteration step for the learning rate to resume from where it left off in JAX.\n",
        "optimizer.iterations.assign(len(eval_losses)*STEPS_PER_EPOCH)\n",
        "\n",
        "p = Progress(STEPS_PER_EPOCH)\n",
        "\n",
        "for epoch in range(JAX_EPOCHS, JAX_EPOCHS+TF_EPOCHS):\n",
        "\n",
        "  # This is where the learning rate schedule state is stored in the optimizer state.\n",
        "  optimizer_step = optimizer.iterations\n",
        "\n",
        "  for step, (data, labels) in enumerate(train_data):\n",
        "    p.step(reset=(step==0))\n",
        "    with tf.GradientTape() as tape:\n",
        "      #loss = reloaded_model.loss(data, labels, True)\n",
        "      loss = reloaded_model.train_loss(data, labels)\n",
        "      grads = tape.gradient(loss, reloaded_model.vars)\n",
        "      optimizer.apply_gradients(zip(grads, reloaded_model.vars))\n",
        "      losses.append(loss)\n",
        "  avg_loss = np.mean(losses[-step:])\n",
        "  avg_losses.append(avg_loss)\n",
        "\n",
        "  eval_loss = reloaded_model.eval_loss(all_test_data.numpy(), all_test_labels.numpy()).numpy()\n",
        "  eval_losses.append(eval_loss)\n",
        "  eval_accuracy = reloaded_model.accuracy(all_test_data.numpy(), all_test_labels.numpy()).numpy()\n",
        "  eval_accuracies.append(eval_accuracy)\n",
        "\n",
        "  print(\"\\nEpoch\", epoch, \"train loss:\", avg_loss, \"eval loss:\", eval_loss, \"eval accuracy\", eval_accuracy, \"lr:\", tflr_decay(optimizer.iterations).numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "50V1FSmI6UTk"
      },
      "outputs": [],
      "source": [
        "display_train_curves(losses, avg_losses, eval_losses, eval_accuracies, len(eval_losses), STEPS_PER_EPOCH, ignore_first_n=2*STEPS_PER_EPOCH)\n",
        "\n",
        "# The loss takes a hit when the training restarts, but does not go back to random levels.\n",
        "# This is likely caused by the optimizer momentum being reinitialized."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7lSziW0K0ny"
      },
      "source": [
        "## Siguientes pasos\n",
        "\n",
        "Puede obtener más información sobre [JAX](https://jax.readthedocs.io/en/latest/index.html) y [Flax](https://flax.readthedocs.io/en/latest) en sus sitios web de la documentación que contienen guías detalladas y ejemplos. Si es nuevo en JAX, asegúrese de explorar los tutoriales [JAX 101](https://jax.readthedocs.io/en/latest/jax-101/index.html), y consulte [Flax quickstart](https://flax.readthedocs.io/en/latest/getting_started.html). Para obtener más información sobre la conversión de modelos JAX a formato TensorFlow, consulte la utilidad [jax2tf](https://github.com/google/jax/tree/main/jax/experimental/jax2tf) en GitHub. Si está interesado en convertir modelos JAX para ejecutarlos en el navegador con TensorFlow.js, visite [JAX en la web con TensorFlow.js](https://blog.tensorflow.org/2022/08/jax-on-web-with-tensorflowjs.html). Si desea preparar modelos JAX para ejecutarlos en TensorFLow Lite, visite la guía [Conversión de modelos JAX para TFLite](https://www.tensorflow.org/lite/examples/jax_conversion/overview)."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "jax2tf.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
