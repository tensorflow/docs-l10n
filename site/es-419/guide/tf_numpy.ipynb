{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjN_IJ8mhJ-4"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "sY3Ffd83hK3b"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03Pw58e6mTHI"
      },
      "source": [
        "# API NumPy en TensorFlow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WpGysDJmZsg"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td><a target=\"_blank\" href=\"https://www.tensorflow.org/guide/tf_numpy\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver en TensorFlow.org</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/es-419/guide/tf_numpy.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Ejecutar en Google Colab</a></td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/es-419/guide/tf_numpy.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver código fuente en GitHub</a>\n",
        "</td>\n",
        "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/es-419/guide/tf_numpy.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Descargar el bloc de notas</a>\n",
        "</td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2enCDi_FvCR"
      },
      "source": [
        "## Descripción general\n",
        "\n",
        "TensorFlow implementa un subconjunto de la [API NumPy](https://numpy.org/doc/stable/index.html), disponible como `tf.experimental.numpy`. Esto permite ejecutar código NumPy, acelerado por TensorFlow, y al mismo tiempo permite el acceso a todas las API de TensorFlow."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ob1HNwUmYR5b"
      },
      "source": [
        "## Preparación\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AJR558zjAZQu"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow.experimental.numpy as tnp\n",
        "import timeit\n",
        "\n",
        "print(\"Using TensorFlow version %s\" % tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6tacoy0DU6e"
      },
      "source": [
        "### Habilitar el comportamiento NumPy\n",
        "\n",
        "Para utilizar `tnp` como NumPy, habilite el comportamiento de NumPy para TensorFlow:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TfCyofpFDQxm"
      },
      "outputs": [],
      "source": [
        "tnp.experimental_enable_numpy_behavior()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "et9D5wq0D1H2"
      },
      "source": [
        "Esta llamada habilita la promoción de tipos en TensorFlow y también cambia la inferencia de tipos, al convertir literales en tensores, para seguir más estrictamente el estándar NumPy.\n",
        "\n",
        "Nota: Esta llamada cambiará el comportamiento de todo TensorFlow, no solo el módulo `tf.experimental.numpy`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yh2BwqUzH3C3"
      },
      "source": [
        "## Arreglo NumPy ND de TensorFlow\n",
        "\n",
        "Una instancia de `tf.experimental.numpy.ndarray`, que se llama **arreglo ND**, representa un arreglo denso multidimensional de un `dtype` determinado en un determinado dispositivo. Es un alias de `tf.Tensor`. Consulte la clase de arreglo ND para conocer métodos útiles como `ndarray.T`, `ndarray.reshape`, `ndarray.ravel` y otros.\n",
        "\n",
        "Primero cree un objeto de arreglo ND y luego invoque diferentes métodos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-BHJjxigJ2H1"
      },
      "outputs": [],
      "source": [
        "# Create an ND array and check out different attributes.\n",
        "ones = tnp.ones([5, 3], dtype=tnp.float32)\n",
        "print(\"Created ND array with shape = %s, rank = %s, \"\n",
        "      \"dtype = %s on device = %s\\n\" % (\n",
        "          ones.shape, ones.ndim, ones.dtype, ones.device))\n",
        "\n",
        "# `ndarray` is just an alias to `tf.Tensor`.\n",
        "print(\"Is `ones` an instance of tf.Tensor: %s\\n\" % isinstance(ones, tf.Tensor))\n",
        "\n",
        "# Try commonly used member functions.\n",
        "print(\"ndarray.T has shape %s\" % str(ones.T.shape))\n",
        "print(\"narray.reshape(-1) has shape %s\" % ones.reshape(-1).shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BOY8CGRKEhE"
      },
      "source": [
        "### Promoción de tipos\n",
        "\n",
        "Hay 4 opciones de promoción de tipos en TensorFlow.\n",
        "\n",
        "- Por defecto, TensorFlow arroja errores en vez de promover tipos para operaciones de tipo mezclado.\n",
        "- Al ejecutar `tf.numpy.experimental_enable_numpy_behavior()`, TensorFlow cambia y usa reglas de promoción de tipos `NumPy`.\n",
        "- Después de TensorFlow 2.15, hay dos opciones nuevas (consulte [Promoción de tipo TF NumPy](tf_numpy_type_promotion.ipynb) para obtener más detalles):\n",
        "    - `tf.numpy.experimental_enable_numpy_behavior()` usa reglas de promoción de tipo Jax\n",
        "    - `tf.numpy.experimental_enable_numpy_behavior(dtype_conversion_mode=\"safe\")` usa reglas de promoción de tipo Jax, pero no permite ciertas promociones que no son seguras."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXskSHrX5J45"
      },
      "source": [
        "#### Promoción de tipo NumPy\n",
        "\n",
        "Las API de TensorFlow NumPy tienen una semántica bien definida para convertir literales a arreglos ND, así como para realizar promoción de tipos en entradas de arreglos ND. Consulte[`np.result_type`](https://numpy.org/doc/1.16/reference/generated/numpy.result_type.html) para obtener más detalles."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcRznNaMj27J"
      },
      "source": [
        "Las API de TensorFlow no hacen cambios en las entradas `tf.Tensor` y no realizan promoción de tipos en ellas, mientras que las API de TensorFlow NumPy promueven todas las entradas de acuerdo con las reglas de promoción de tipos de NumPy. En el siguiente ejemplo, realizará una promoción de tipo. Primero, ejecute la suma en entradas de arreglo ND de diferentes tipos y observe los tipos de salida. Las API de TensorFlow no permitirían ninguna promoción de este tipo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uHmBi4KZI2t1"
      },
      "outputs": [],
      "source": [
        "print(\"Type promotion for operations\")\n",
        "values = [tnp.asarray(1, dtype=d) for d in\n",
        "          (tnp.int32, tnp.int64, tnp.float32, tnp.float64)]\n",
        "for i, v1 in enumerate(values):\n",
        "  for v2 in values[i + 1:]:\n",
        "    print(\"%s + %s => %s\" %\n",
        "          (v1.dtype.name, v2.dtype.name, (v1 + v2).dtype.name))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrpIoOc7oqox"
      },
      "source": [
        "Por último, convierta literales a un arreglo ND con `ndarray.asarray` y observe el tipo que resulta."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1m1cp8_VooNk"
      },
      "outputs": [],
      "source": [
        "print(\"Type inference during array creation\")\n",
        "print(\"tnp.asarray(1).dtype == tnp.%s\" % tnp.asarray(1).dtype.name)\n",
        "print(\"tnp.asarray(1.).dtype == tnp.%s\\n\" % tnp.asarray(1.).dtype.name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kd-_iccXoRL8"
      },
      "source": [
        "Al convertir literales a arreglos ND, NumPy prefiere tipos anchos como `tnp.int64` y `tnp.float64`. Por el contrario, `tf.convert_to_tensor` prefiere los tipos `tf.int32` y `tf.float32` para convertir constantes a `tf.Tensor`. Las API de TensorFlow NumPy se adhieren al comportamiento de NumPy para números enteros. En cuanto a los flotadores, el argumento `prefer_float32` de `experimental_enable_numpy_behavior` le permite controlar si prefiere `tf.float32` sobre `tf.float64` (el valor predeterminado es `False`). Por ejemplo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4gKasnH0j84C"
      },
      "outputs": [],
      "source": [
        "tnp.experimental_enable_numpy_behavior(prefer_float32=True)\n",
        "print(\"When prefer_float32 is True:\")\n",
        "print(\"tnp.asarray(1.).dtype == tnp.%s\" % tnp.asarray(1.).dtype.name)\n",
        "print(\"tnp.add(1., 2.).dtype == tnp.%s\" % tnp.add(1., 2.).dtype.name)\n",
        "\n",
        "tnp.experimental_enable_numpy_behavior(prefer_float32=False)\n",
        "print(\"When prefer_float32 is False:\")\n",
        "print(\"tnp.asarray(1.).dtype == tnp.%s\" % tnp.asarray(1.).dtype.name)\n",
        "print(\"tnp.add(1., 2.).dtype == tnp.%s\" % tnp.add(1., 2.).dtype.name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwCCDxSZOfA1"
      },
      "source": [
        "### Transmisión\n",
        "\n",
        "Al igual que TensorFlow, NumPy define una semántica rica para valores de \"difusión\". Puede consultar la [guía de transmisión de NumPy](https://numpy.org/doc/1.16/user/basics.broadcasting.html) para obtener más información y compararla con [la semántica de transmisión de TensorFlow](https://www.tensorflow.org/guide/tensor#broadcasting)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qlyOShxIO0s2"
      },
      "outputs": [],
      "source": [
        "x = tnp.ones([2, 3])\n",
        "y = tnp.ones([3])\n",
        "z = tnp.ones([1, 2, 1])\n",
        "print(\"Broadcasting shapes %s, %s and %s gives shape %s\" % (\n",
        "    x.shape, y.shape, z.shape, (x + y + z).shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEVr4ctRPrqR"
      },
      "source": [
        "### Indexación\n",
        "\n",
        "NumPy define reglas de indexación muy sofisticadas. Consulte la [guía de indexación de NumPy](https://numpy.org/doc/1.16/reference/arrays.indexing.html). Observe el uso de arreglos ND como índices a continuación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lRsrtnd3YyMj"
      },
      "outputs": [],
      "source": [
        "x = tnp.arange(24).reshape(2, 3, 4)\n",
        "\n",
        "print(\"Basic indexing\")\n",
        "print(x[1, tnp.newaxis, 1:3, ...], \"\\n\")\n",
        "\n",
        "print(\"Boolean indexing\")\n",
        "print(x[:, (True, False, True)], \"\\n\")\n",
        "\n",
        "print(\"Advanced indexing\")\n",
        "print(x[1, (0, 0, 1), tnp.asarray([0, 1, 1])])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yRAaiGhlaNw7"
      },
      "outputs": [],
      "source": [
        "# Mutation is currently not supported\n",
        "try:\n",
        "  tnp.arange(6)[1] = -1\n",
        "except TypeError:\n",
        "  print(\"Currently, TensorFlow NumPy does not support mutation.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XfJ602j-GVD"
      },
      "source": [
        "### Modelo de ejemplo\n",
        "\n",
        "A continuación, puede ver cómo crear un modelo y ejecutar inferencias sobre él. Este modelo simple aplica una capa relu seguida de una proyección lineal. En las secciones posteriores se mostrará cómo calcular gradientes para este modelo con `GradientTape` de TensorFlow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kR_KCh4kYEhm"
      },
      "outputs": [],
      "source": [
        "class Model(object):\n",
        "  \"\"\"Model with a dense and a linear layer.\"\"\"\n",
        "\n",
        "  def __init__(self):\n",
        "    self.weights = None\n",
        "\n",
        "  def predict(self, inputs):\n",
        "    if self.weights is None:\n",
        "      size = inputs.shape[1]\n",
        "      # Note that type `tnp.float32` is used for performance.\n",
        "      stddev = tnp.sqrt(size).astype(tnp.float32)\n",
        "      w1 = tnp.random.randn(size, 64).astype(tnp.float32) / stddev\n",
        "      bias = tnp.random.randn(64).astype(tnp.float32)\n",
        "      w2 = tnp.random.randn(64, 2).astype(tnp.float32) / 8\n",
        "      self.weights = (w1, bias, w2)\n",
        "    else:\n",
        "      w1, bias, w2 = self.weights\n",
        "    y = tnp.matmul(inputs, w1) + bias\n",
        "    y = tnp.maximum(y, 0)  # Relu\n",
        "    return tnp.matmul(y, w2)  # Linear projection\n",
        "\n",
        "model = Model()\n",
        "# Create input data and compute predictions.\n",
        "print(model.predict(tnp.ones([2, 32], dtype=tnp.float32)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSR7Ou5YcS38"
      },
      "source": [
        "## TensorFlow NumPy y NumPy\n",
        "\n",
        "TensorFlow NumPy implementa un subconjunto de la especificación NumPy completa. Si bien se agregarán más símbolos con el tiempo, hay funciones sistemáticas que no se admitirán en un futuro próximo. Entre ellos se incluyen la compatibilidad con NumPy C API, la integración de Swig, el orden de almacenamiento de Fortran, las vistas y `stride_tricks` y algunos `dtype` (como `np.recarray` y `np.object`). Para obtener más detalles, consulte la [documentación de la API TensorFlow NumPy](https://www.tensorflow.org/api_docs/python/tf/experimental/numpy).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jb1KXak2YlNN"
      },
      "source": [
        "### Interoperabilidad numérica\n",
        "\n",
        "Los arreglos TensorFlow ND pueden interoperar con funciones NumPy. Estos objetos implementan la interfaz `__array__`. NumPy usa esta interfaz para convertir argumentos de función a valores `np.ndarray` antes de procesarlos.\n",
        "\n",
        "De manera similar, las funciones de TensorFlow NumPy pueden aceptar entradas de diferentes tipos, incluido `np.ndarray`. Estas entradas se convierten en un arreglo ND al llamar a `ndarray.asarray`.\n",
        "\n",
        "La conversión del arreglo ND hacia y desde `np.ndarray` puede generar copias de datos reales. Consulte la sección sobre [copias en búfer](#buffer-copies) para obtener más detalles."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cMOCgzQmeXRU"
      },
      "outputs": [],
      "source": [
        "# ND array passed into NumPy function.\n",
        "np_sum = np.sum(tnp.ones([2, 3]))\n",
        "print(\"sum = %s. Class: %s\" % (float(np_sum), np_sum.__class__))\n",
        "\n",
        "# `np.ndarray` passed into TensorFlow NumPy function.\n",
        "tnp_sum = tnp.sum(np.ones([2, 3]))\n",
        "print(\"sum = %s. Class: %s\" % (float(tnp_sum), tnp_sum.__class__))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZaLPjzxft780"
      },
      "outputs": [],
      "source": [
        "# It is easy to plot ND arrays, given the __array__ interface.\n",
        "labels = 15 + 2 * tnp.random.randn(1, 1000)\n",
        "_ = plt.hist(labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kF-Xyw3XWKqJ"
      },
      "source": [
        "### Copias de búfer\n",
        "\n",
        "Mezclar TensorFlow NumPy con código NumPy puede desencadenar copias de datos. Esto se debe a que TensorFlow NumPy tiene requisitos de alineación de memoria más estrictos que los de NumPy.\n",
        "\n",
        "Cuando se pasa un `np.ndarray` a TensorFlow NumPy, se comprobarán los requisitos de alineación y se activará una copia si es necesario. Al pasar un búfer de CPU de arreglo ND a NumPy, por lo general, el búfer cumplirá los requisitos de alineación y NumPy no necesitará crear una copia.\n",
        "\n",
        "Los arreglos ND pueden hacer referencia a búferes ubicados en dispositivos distintos de la memoria de la CPU local. En tales casos, llamar a una función NumPy activará copias en la red o en los dispositivo según sea necesario.\n",
        "\n",
        "Por esto, la mezcla con llamadas a la API de NumPy generalmente deben realizarse con precaución y el usuario debe tener cuidado con los gastos generales de copia de datos. Generalmente, intercalar llamadas de TensorFlow NumPy con llamadas de TensorFlow es seguro y evita la copia de datos. Consulte la sección sobre [interoperabilidad de TensorFlow](#tensorflow-interoperability) para obtener más detalles."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RwljbqkBc7Ro"
      },
      "source": [
        "### Prioridad del operador\n",
        "\n",
        "TensorFlow NumPy define una `__array_priority__` mayor que la de NumPy. Esto significa que para los operadores que involucran tanto un arreglo ND como `np.ndarray`, el primero tendrá prioridad, es decir, la entrada de `np.ndarray` se convertirá en un arreglo ND y se llamará a la implementación TensorFlow NumPy del operador."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cbw8a3G_WUO7"
      },
      "outputs": [],
      "source": [
        "x = tnp.ones([2]) + np.ones([2])\n",
        "print(\"x = %s\\nclass = %s\" % (x, x.__class__))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNEab_Ctky83"
      },
      "source": [
        "## TF NumPy y TensorFlow\n",
        "\n",
        "TensorFlow NumPy está construido sobre TensorFlow y, por lo tanto, interopera perfectamente con TensorFlow."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fCcfgrlOnAhQ"
      },
      "source": [
        "### `tf.Tensor` y arreglo ND\n",
        "\n",
        "El arreglo ND es un alias de `tf.Tensor`, por lo que obviamente se pueden mezclar sin activar copias de datos reales."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BkHVauKwnky_"
      },
      "outputs": [],
      "source": [
        "x = tf.constant([1, 2])\n",
        "print(x)\n",
        "\n",
        "# `asarray` and `convert_to_tensor` here are no-ops.\n",
        "tnp_x = tnp.asarray(x)\n",
        "print(tnp_x)\n",
        "print(tf.convert_to_tensor(tnp_x))\n",
        "\n",
        "# Note that tf.Tensor.numpy() will continue to return `np.ndarray`.\n",
        "print(x.numpy(), x.numpy().__class__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_151HQVBooxG"
      },
      "source": [
        "### Interoperabilidad de TensorFlow\n",
        "\n",
        "Se puede pasar un arreglo ND a las API de TensorFlow, ya que el arreglo ND es solo un alias de `tf.Tensor`. Como se mencionó anteriormente, dicha interoperación no realiza copias de datos, ni siquiera de datos ubicados en aceleradores ni dispositivos remotos.\n",
        "\n",
        "Por el contrario, los objetos `tf.Tensor` se pueden pasar a las API `tf.experimental.numpy` sin realizar copias de datos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-QvxNhrFoz09"
      },
      "outputs": [],
      "source": [
        "# ND array passed into TensorFlow function.\n",
        "tf_sum = tf.reduce_sum(tnp.ones([2, 3], tnp.float32))\n",
        "print(\"Output = %s\" % tf_sum)\n",
        "\n",
        "# `tf.Tensor` passed into TensorFlow NumPy function.\n",
        "tnp_sum = tnp.sum(tf.ones([2, 3]))\n",
        "print(\"Output = %s\" % tnp_sum)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1b4HeAkhprF_"
      },
      "source": [
        "### Gradientes y jacobianos: tf.GradientTape\n",
        "\n",
        "GradientTape de TensorFlow se puede usar para la retropropagación a través del código de TensorFlow y TensorFlow NumPy.\n",
        "\n",
        "Use el modelo creado en la sección [Modelo de ejemplo](#example-model) y calcule gradientes y jacobianos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T47C9KS8pbsP"
      },
      "outputs": [],
      "source": [
        "def create_batch(batch_size=32):\n",
        "  \"\"\"Creates a batch of input and labels.\"\"\"\n",
        "  return (tnp.random.randn(batch_size, 32).astype(tnp.float32),\n",
        "          tnp.random.randn(batch_size, 2).astype(tnp.float32))\n",
        "\n",
        "def compute_gradients(model, inputs, labels):\n",
        "  \"\"\"Computes gradients of squared loss between model prediction and labels.\"\"\"\n",
        "  with tf.GradientTape() as tape:\n",
        "    assert model.weights is not None\n",
        "    # Note that `model.weights` need to be explicitly watched since they\n",
        "    # are not tf.Variables.\n",
        "    tape.watch(model.weights)\n",
        "    # Compute prediction and loss\n",
        "    prediction = model.predict(inputs)\n",
        "    loss = tnp.sum(tnp.square(prediction - labels))\n",
        "  # This call computes the gradient through the computation above.\n",
        "  return tape.gradient(loss, model.weights)\n",
        "\n",
        "inputs, labels = create_batch()\n",
        "gradients = compute_gradients(model, inputs, labels)\n",
        "\n",
        "# Inspect the shapes of returned gradients to verify they match the\n",
        "# parameter shapes.\n",
        "print(\"Parameter shapes:\", [w.shape for w in model.weights])\n",
        "print(\"Gradient shapes:\", [g.shape for g in gradients])\n",
        "# Verify that gradients are of type ND array.\n",
        "assert isinstance(gradients[0], tnp.ndarray)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TujVPDFwrdqp"
      },
      "outputs": [],
      "source": [
        "# Computes a batch of jacobians. Each row is the jacobian of an element in the\n",
        "# batch of outputs w.r.t. the corresponding input batch element.\n",
        "def prediction_batch_jacobian(inputs):\n",
        "  with tf.GradientTape() as tape:\n",
        "    tape.watch(inputs)\n",
        "    prediction = model.predict(inputs)\n",
        "  return prediction, tape.batch_jacobian(prediction, inputs)\n",
        "\n",
        "inp_batch = tnp.ones([16, 32], tnp.float32)\n",
        "output, batch_jacobian = prediction_batch_jacobian(inp_batch)\n",
        "# Note how the batch jacobian shape relates to the input and output shapes.\n",
        "print(\"Output shape: %s, input shape: %s\" % (output.shape, inp_batch.shape))\n",
        "print(\"Batch jacobian shape:\", batch_jacobian.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYq9wxfc1Dv_"
      },
      "source": [
        "### Compilación de trazado: tf.function\n",
        "\n",
        "`tf.function` de TensorFlow funciona mediante la \"compilación de trazado\" del código y luego optimiza estos trazados para un rendimiento mucho más rápido. Consulte la [Introducción a gráficos y funciones](./intro_to_graphs.ipynb).\n",
        "\n",
        "`tf.function` también se puede usar para optimizar el código de TensorFlow NumPy. Aquí hay un ejemplo simple para demostrar las aceleraciones. Tenga en cuenta que el cuerpo del código `tf.function` incluye llamadas a las API de TensorFlow NumPy.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "05SrUulm1OlL"
      },
      "outputs": [],
      "source": [
        "inputs, labels = create_batch(512)\n",
        "print(\"Eager performance\")\n",
        "compute_gradients(model, inputs, labels)\n",
        "print(timeit.timeit(lambda: compute_gradients(model, inputs, labels),\n",
        "                    number=10) * 100, \"ms\")\n",
        "\n",
        "print(\"\\ntf.function compiled performance\")\n",
        "compiled_compute_gradients = tf.function(compute_gradients)\n",
        "compiled_compute_gradients(model, inputs, labels)  # warmup\n",
        "print(timeit.timeit(lambda: compiled_compute_gradients(model, inputs, labels),\n",
        "                    number=10) * 100, \"ms\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5w8YxR6ELmo1"
      },
      "source": [
        "### Vectorización: tf.vectorized_map\n",
        "\n",
        "TensorFlow tiene soporte incorporado para vectorizar bucles paralelos, lo que permite aceleraciones de uno a dos órdenes de magnitud. Se puede acceder a estas aceleraciones a través de la API `tf.vectorized_map` y también se aplican al código TensorFlow NumPy.\n",
        "\n",
        "A veces es útil calcular el gradiente de cada salida en un lote con respecto al elemento del lote de entrada correspondiente. Dicho cálculo se puede realizar de manera eficiente con `tf.vectorized_map` como se muestra a continuación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PemSIrs5L-VJ"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def vectorized_per_example_gradients(inputs, labels):\n",
        "  def single_example_gradient(arg):\n",
        "    inp, label = arg\n",
        "    return compute_gradients(model,\n",
        "                             tnp.expand_dims(inp, 0),\n",
        "                             tnp.expand_dims(label, 0))\n",
        "  # Note that a call to `tf.vectorized_map` semantically maps\n",
        "  # `single_example_gradient` over each row of `inputs` and `labels`.\n",
        "  # The interface is similar to `tf.map_fn`.\n",
        "  # The underlying machinery vectorizes away this map loop which gives\n",
        "  # nice speedups.\n",
        "  return tf.vectorized_map(single_example_gradient, (inputs, labels))\n",
        "\n",
        "batch_size = 128\n",
        "inputs, labels = create_batch(batch_size)\n",
        "\n",
        "per_example_gradients = vectorized_per_example_gradients(inputs, labels)\n",
        "for w, p in zip(model.weights, per_example_gradients):\n",
        "  print(\"Weight shape: %s, batch size: %s, per example gradient shape: %s \" % (\n",
        "      w.shape, batch_size, p.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_QZ5BjJmRAlG"
      },
      "outputs": [],
      "source": [
        "# Benchmark the vectorized computation above and compare with\n",
        "# unvectorized sequential computation using `tf.map_fn`.\n",
        "@tf.function\n",
        "def unvectorized_per_example_gradients(inputs, labels):\n",
        "  def single_example_gradient(arg):\n",
        "    inp, label = arg\n",
        "    return compute_gradients(model,\n",
        "                             tnp.expand_dims(inp, 0),\n",
        "                             tnp.expand_dims(label, 0))\n",
        "\n",
        "  return tf.map_fn(single_example_gradient, (inputs, labels),\n",
        "                   fn_output_signature=(tf.float32, tf.float32, tf.float32))\n",
        "\n",
        "print(\"Running vectorized computation\")\n",
        "print(timeit.timeit(lambda: vectorized_per_example_gradients(inputs, labels),\n",
        "                    number=10) * 100, \"ms\")\n",
        "\n",
        "print(\"\\nRunning unvectorized computation\")\n",
        "per_example_gradients = unvectorized_per_example_gradients(inputs, labels)\n",
        "print(timeit.timeit(lambda: unvectorized_per_example_gradients(inputs, labels),\n",
        "                    number=10) * 100, \"ms\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOTh-nkzaJd9"
      },
      "source": [
        "### Colocación del dispositivo\n",
        "\n",
        "TensorFlow NumPy puede realizar operaciones en CPU, GPU, TPU y dispositivos remotos. Usa mecanismos estándar de TensorFlow para la colocación del dispositivo. A continuación, un ejemplo simple muestra cómo enumerar todos los dispositivos y luego realizar algunos cálculos en un dispositivo en particular.\n",
        "\n",
        "TensorFlow también tiene API para replicar cálculos entre dispositivos y realizar reducciones colectivas que no trataremos aquí."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0gHrwYYaTCE"
      },
      "source": [
        "#### Listar dispositivos\n",
        "\n",
        "`tf.config.list_logical_devices` y `tf.config.list_physical_devices` se pueden usar para encontrar qué dispositivos usar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NDEAd9m9aemS"
      },
      "outputs": [],
      "source": [
        "print(\"All logical devices:\", tf.config.list_logical_devices())\n",
        "print(\"All physical devices:\", tf.config.list_physical_devices())\n",
        "\n",
        "# Try to get the GPU device. If unavailable, fallback to CPU.\n",
        "try:\n",
        "  device = tf.config.list_logical_devices(device_type=\"GPU\")[0]\n",
        "except IndexError:\n",
        "  device = \"/device:CPU:0\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fihgfF_tahVx"
      },
      "source": [
        "#### Operaciones de apartado: **`tf.device`**\n",
        "\n",
        "Se pueden apartar las operaciones en un dispositivo al llamarlo en un alcance `tf.device`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c7ELvLmnazfV"
      },
      "outputs": [],
      "source": [
        "print(\"Using device: %s\" % str(device))\n",
        "# Run operations in the `tf.device` scope.\n",
        "# If a GPU is available, these operations execute on the GPU and outputs are\n",
        "# placed on the GPU memory.\n",
        "with tf.device(device):\n",
        "  prediction = model.predict(create_batch(5)[0])\n",
        "\n",
        "print(\"prediction is placed on %s\" % prediction.device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-LK6wsHbBiM"
      },
      "source": [
        "#### Copiar arreglos ND entre dispositivos: **`tnp.copy`**\n",
        "\n",
        "Una llamada a `tnp.copy`, apartada en un determinado alcance de dispositivo, copiará los datos a ese dispositivo, a menos que los datos ya estén en ese dispositivo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CCesyidaa-UT"
      },
      "outputs": [],
      "source": [
        "with tf.device(\"/device:CPU:0\"):\n",
        "  prediction_cpu = tnp.copy(prediction)\n",
        "print(prediction.device)\n",
        "print(prediction_cpu.device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AiYzRDOtKzAH"
      },
      "source": [
        "## Comparaciones de rendimiento\n",
        "\n",
        "TensorFlow NumPy usa núcleos de TensorFlow altamente optimizados que se pueden distribuir en CPU, GPU y TPU. TensorFlow también realiza muchas optimizaciones del compilador, como la fusión de operaciones, que se traducen en mejoras de rendimiento y memoria. Consulte [Optimización de gráficos de TensorFlow con Grappler](./graph_optimization.ipynb) para obtener más información.\n",
        "\n",
        "Sin embargo, TensorFlow tiene mayores gastos generales para las operaciones de envío en comparación con NumPy. Para cargas de trabajo compuestas por operaciones pequeñas (menos de aproximadamente 10 microsegundos), estos gastos generales pueden dominar el tiempo de ejecución y NumPy podría proporcionar un mejor rendimiento. Para otros casos, TensorFlow generalmente debería proporcionar un mejor rendimiento.\n",
        "\n",
        "Ejecute el siguiente punto de referencia para comparar el rendimiento de NumPy y TensorFlow NumPy para diferentes tamaños de entrada."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "code",
        "id": "RExwjI9_pJG0"
      },
      "outputs": [],
      "source": [
        "def benchmark(f, inputs, number=30, force_gpu_sync=False):\n",
        "  \"\"\"Utility to benchmark `f` on each value in `inputs`.\"\"\"\n",
        "  times = []\n",
        "  for inp in inputs:\n",
        "    def _g():\n",
        "      if force_gpu_sync:\n",
        "        one = tnp.asarray(1)\n",
        "      f(inp)\n",
        "      if force_gpu_sync:\n",
        "        with tf.device(\"CPU:0\"):\n",
        "          tnp.copy(one)  # Force a sync for GPU case\n",
        "\n",
        "    _g()  # warmup\n",
        "    t = timeit.timeit(_g, number=number)\n",
        "    times.append(t * 1000. / number)\n",
        "  return times\n",
        "\n",
        "\n",
        "def plot(np_times, tnp_times, compiled_tnp_times, has_gpu, tnp_times_gpu):\n",
        "  \"\"\"Plot the different runtimes.\"\"\"\n",
        "  plt.xlabel(\"size\")\n",
        "  plt.ylabel(\"time (ms)\")\n",
        "  plt.title(\"Sigmoid benchmark: TF NumPy vs NumPy\")\n",
        "  plt.plot(sizes, np_times, label=\"NumPy\")\n",
        "  plt.plot(sizes, tnp_times, label=\"TF NumPy (CPU)\")\n",
        "  plt.plot(sizes, compiled_tnp_times, label=\"Compiled TF NumPy (CPU)\")\n",
        "  if has_gpu:\n",
        "    plt.plot(sizes, tnp_times_gpu, label=\"TF NumPy (GPU)\")\n",
        "  plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p-fs_H1lkLfV"
      },
      "outputs": [],
      "source": [
        "# Define a simple implementation of `sigmoid`, and benchmark it using\n",
        "# NumPy and TensorFlow NumPy for different input sizes.\n",
        "\n",
        "def np_sigmoid(y):\n",
        "  return 1. / (1. + np.exp(-y))\n",
        "\n",
        "def tnp_sigmoid(y):\n",
        "  return 1. / (1. + tnp.exp(-y))\n",
        "\n",
        "@tf.function\n",
        "def compiled_tnp_sigmoid(y):\n",
        "  return tnp_sigmoid(y)\n",
        "\n",
        "sizes = (2 ** 0, 2 ** 5, 2 ** 10, 2 ** 15, 2 ** 20)\n",
        "np_inputs = [np.random.randn(size).astype(np.float32) for size in sizes]\n",
        "np_times = benchmark(np_sigmoid, np_inputs)\n",
        "\n",
        "with tf.device(\"/device:CPU:0\"):\n",
        "  tnp_inputs = [tnp.random.randn(size).astype(np.float32) for size in sizes]\n",
        "  tnp_times = benchmark(tnp_sigmoid, tnp_inputs)\n",
        "  compiled_tnp_times = benchmark(compiled_tnp_sigmoid, tnp_inputs)\n",
        "\n",
        "has_gpu = len(tf.config.list_logical_devices(\"GPU\"))\n",
        "if has_gpu:\n",
        "  with tf.device(\"/device:GPU:0\"):\n",
        "    tnp_inputs = [tnp.random.randn(size).astype(np.float32) for size in sizes]\n",
        "    tnp_times_gpu = benchmark(compiled_tnp_sigmoid, tnp_inputs, 100, True)\n",
        "else:\n",
        "  tnp_times_gpu = None\n",
        "plot(np_times, tnp_times, compiled_tnp_times, has_gpu, tnp_times_gpu)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ReK_9k5D8BZQ"
      },
      "source": [
        "## Otras lecturas\n",
        "\n",
        "- [TensorFlow NumPy: Tutorial de clasificación de imágenes distribuidas](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/numpy_ops/g3doc/TensorFlow_Numpy_Distributed_Image_Classification.ipynb)\n",
        "- [TensorFlow NumPy: Keras y estrategia de distribución](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/numpy_ops/g3doc/TensorFlow_NumPy_Keras_and_Distribution_Strategy.ipynb)\n",
        "- [Análisis de sentimiento con Trax y TensorFlow NumPy](https://github.com/google/trax/blob/master/trax/tf_numpy_and_keras.ipynb)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "tf_numpy.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
