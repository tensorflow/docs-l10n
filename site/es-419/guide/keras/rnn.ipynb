{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b518b04cbfe0"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "906e07f6e562"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ca65cda94c8"
      },
      "source": [
        "# Redes neuronales recurrentes (RNN) con Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1e4938db0e55"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>     <a target=\"_blank\" href=\"https://www.tensorflow.org/guide/keras/rnn\">     <img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">     Ver en TensorFlow.org</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/es-419/guide/keras/rnn.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Ejecutar en Google Colab</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/es-419/guide/keras/rnn.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver el código fuente en GitHub</a>\n",
        "</td>\n",
        "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/es-419/guide/keras/rnn.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Descargar el bloc de notas</a>\n",
        "</td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6873211b02d4"
      },
      "source": [
        "## Introducción\n",
        "\n",
        "Las redes neuronales recurrentes (RNN) son una clase de redes neuronales potentes para modelar datos secuenciales, como series temporales o lenguaje natural.\n",
        "\n",
        "En términos esquemáticos, una capa RNN utiliza un bucle `for` para iterar sobre los pasos de tiempo de una secuencia, mientras mantiene un estado interno que codifica la información sobre los pasos de tiempo que ha visto hasta el momento.\n",
        "\n",
        "La API Keras RNN está diseñada con un enfoque en:\n",
        "\n",
        "- **Facilidad de uso**: las capas incorporadas `keras.layers.RNN`, `keras.layers.LSTM`, `keras.layers.GRU` permiten construir rápidamente modelos recurrentes sin tener que tomar decisiones difíciles sobre la configuración.\n",
        "\n",
        "- **Facilidad de personalización**: También puede definir su propia capa de celdas RNN (la parte interna del bucle `for`) con un comportamiento personalizado, y utilizarla con la capa genérica `keras.layers.RNN` (el propio bucle `for`). Esto le permite crear rápidamente prototipos de diferentes ideas de investigación de una manera flexible con un código mínimo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3600ee25c8e"
      },
      "source": [
        "## Preparación"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "71c626bbac35"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4041a2e9b310"
      },
      "source": [
        "## Capas RNN integradas: un ejemplo simple"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98e0c38cf95d"
      },
      "source": [
        "Hay tres capas RNN integradas en Keras:\n",
        "\n",
        "1. `keras.layers.SimpleRNN`, una RNN completamente conectada en la que la salida del paso de tiempo anterior debe alimentar el siguiente paso de tiempo.\n",
        "\n",
        "2. `keras.layers.GRU`, propuesto por primera vez en [Cho et al., 2014](https://arxiv.org/abs/1406.1078).\n",
        "\n",
        "3. `keras.layers.LSTM`, propuesto por primera vez en [Hochreiter &amp; Schmidhuber, 1997](https://www.bioinf.jku.at/publications/older/2604.pdf).\n",
        "\n",
        "A principios del 2015, Keras tuvo las primeras implementaciones reutilizables de código abierto en Python de LSTM y GRU.\n",
        "\n",
        "Este es un ejemplo sencillo de un modelo de `Sequential` que procesa secuencias de números enteros, incrusta cada número entero en un vector de 64 dimensiones y, a continuación, procesa la secuencia de vectores utilizando una capa `LSTM`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a5617759e54e"
      },
      "outputs": [],
      "source": [
        "model = keras.Sequential()\n",
        "# Add an Embedding layer expecting input vocab of size 1000, and\n",
        "# output embedding dimension of size 64.\n",
        "model.add(layers.Embedding(input_dim=1000, output_dim=64))\n",
        "\n",
        "# Add a LSTM layer with 128 internal units.\n",
        "model.add(layers.LSTM(128))\n",
        "\n",
        "# Add a Dense layer with 10 units.\n",
        "model.add(layers.Dense(10))\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cb8ef33660a0"
      },
      "source": [
        "Las RNN integradas admiten varias funciones útiles:\n",
        "\n",
        "- Abandono recurrente, mediante los argumentos `dropout` y `recurrent_dropout`.\n",
        "- Capacidad para procesar una secuencia de entrada en sentido inverso, mediante el argumento `go_backwards`.\n",
        "- Desenrollar bucles (que puede suponer un gran aumento de velocidad al procesar secuencias cortas en el CPU), mediante el argumento `unroll`.\n",
        "- ...y mucho más.\n",
        "\n",
        "Para obtener más información, consulte la [Documentación de la API RNN](https://keras.io/api/layers/recurrent_layers/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43aa4e4f344d"
      },
      "source": [
        "## Salidas y estados\n",
        "\n",
        "De forma predeterminada, la salida de una capa RNN contiene un único vector por muestra. Este vector es la salida de la célula RNN correspondiente al último paso de tiempo, que contiene información sobre toda la secuencia de entrada. La forma de esta salida es `(batch_size, units)` donde `units` corresponde al argumento `units` pasado al constructor de la capa.\n",
        "\n",
        "Una capa RNN también puede devolver la secuencia completa de salidas para cada muestra (un vector por paso de tiempo por muestra), si se establece `return_sequences=True`. La forma de esta salida es `(batch_size, timesteps, units)`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3294dec91e4"
      },
      "outputs": [],
      "source": [
        "model = keras.Sequential()\n",
        "model.add(layers.Embedding(input_dim=1000, output_dim=64))\n",
        "\n",
        "# The output of GRU will be a 3D tensor of shape (batch_size, timesteps, 256)\n",
        "model.add(layers.GRU(256, return_sequences=True))\n",
        "\n",
        "# The output of SimpleRNN will be a 2D tensor of shape (batch_size, 128)\n",
        "model.add(layers.SimpleRNN(128))\n",
        "\n",
        "model.add(layers.Dense(10))\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "266812a04bb2"
      },
      "source": [
        "Además, una capa RNN puede devolver su estados internos finales. Los estados devueltos pueden utilizarse para reanudar la ejecución de la RNN más tarde, o [para inicializar otra RNN](https://arxiv.org/abs/1409.3215). Esta configuración se utiliza comúnmente en el modelo secuencia-a-secuencia codificador-decodificador, donde el estado final del codificador se utiliza como estado inicial del decodificador.\n",
        "\n",
        "Para configurar una capa RNN para que devuelva su estado interno, establezca el parámetro `return_state` en `True` al crear la capa. Tenga en cuenta que `LSTM` tiene 2 tensores de estado, pero `GRU` solo tiene uno.\n",
        "\n",
        "Para configurar el estado inicial de la capa, basta con llamar a la capa con el argumento adicional `initial_state`. Tenga en cuenta que la forma del estado debe coincidir con el tamaño de la unidad de la capa, como en el siguiente ejemplo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ece412e6afbe"
      },
      "outputs": [],
      "source": [
        "encoder_vocab = 1000\n",
        "decoder_vocab = 2000\n",
        "\n",
        "encoder_input = layers.Input(shape=(None,))\n",
        "encoder_embedded = layers.Embedding(input_dim=encoder_vocab, output_dim=64)(\n",
        "    encoder_input\n",
        ")\n",
        "\n",
        "# Return states in addition to output\n",
        "output, state_h, state_c = layers.LSTM(64, return_state=True, name=\"encoder\")(\n",
        "    encoder_embedded\n",
        ")\n",
        "encoder_state = [state_h, state_c]\n",
        "\n",
        "decoder_input = layers.Input(shape=(None,))\n",
        "decoder_embedded = layers.Embedding(input_dim=decoder_vocab, output_dim=64)(\n",
        "    decoder_input\n",
        ")\n",
        "\n",
        "# Pass the 2 states to a new LSTM layer, as initial state\n",
        "decoder_output = layers.LSTM(64, name=\"decoder\")(\n",
        "    decoder_embedded, initial_state=encoder_state\n",
        ")\n",
        "output = layers.Dense(10)(decoder_output)\n",
        "\n",
        "model = keras.Model([encoder_input, decoder_input], output)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e97a845a372a"
      },
      "source": [
        "## Capas RNN y celdas RNN\n",
        "\n",
        "Además de las capas RNN integradas, la API RNN también proporciona APIs a nivel de celda. A diferencia de las capas RNN, que procesan lotes enteros de secuencias de entrada, la celda RNN solo procesa un único paso temporal.\n",
        "\n",
        "La celda es el interior del bucle `for` de una capa RNN. Al envolver una celda dentro de una capa `keras.layers.RNN` se obtiene una capa capaz de procesar lotes de secuencias, por ejemplo `RNN(LSTMCell(10))`.\n",
        "\n",
        "Matemáticamente, `RNN(LSTMCell(10))` produce el mismo resultado que `LSTM(10)`. De hecho, la implementación de esta capa en TF v1.x era simplemente crear la celda RNN correspondiente y envolverla en una capa RNN.  Sin embargo, el uso de las capas integradas `GRU` y `LSTM` permite el uso de CuDNN y se puede ver un mejor rendimiento.\n",
        "\n",
        "Hay tres celdas RNN integradas, cada una de las cuales corresponde a la capa RNN correspondiente.\n",
        "\n",
        "- `keras.layers.SimpleRNNCell` corresponde a la capa `SimpleRNN`.\n",
        "\n",
        "- `keras.layers.GRUCell` corresponde a la capa `GRU`.\n",
        "\n",
        "- `keras.layers.LSTMCell` corresponde a la capa `LSTM`.\n",
        "\n",
        "La abstracción de celdas, junto con la clase genérica `keras.layers.RNN`, hacen que sea muy fácil implementar arquitecturas RNN personalizadas para su investigación."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60b3b721d500"
      },
      "source": [
        "## Estado de los lotes cruzados\n",
        "\n",
        "Al procesar secuencias muy largas (posiblemente infinitas), es posible que desee utilizar el patrón de **estado de los lotes cruzados**.\n",
        "\n",
        "Normalmente, el estado interno de una capa RNN se restablece cada vez que ve un nuevo lote (es decir, se supone que cada muestra vista por la capa es independiente del pasado). La capa solo mantendrá un estado mientras procesa una muestra determinada.\n",
        "\n",
        "Sin embargo, si tiene secuencias muy largas, es útil dividirlas en secuencias más cortas y alimentar estas secuencias más cortas secuencialmente en una capa RNN sin restablecer el estado de la capa. De este modo, la capa puede retener información sobre toda la secuencia, aunque solo vea una subsecuencia cada vez.\n",
        "\n",
        "Puede hacerlo estableciendo `stateful=True` en el constructor.\n",
        "\n",
        "Si tiene una secuencia `s = [t0, t1, ... t1546, t1547]`, la dividiría, por ejemplo, en:\n",
        "\n",
        "```\n",
        "s1 = [t0, t1, ... t100]\n",
        "s2 = [t101, ... t201]\n",
        "...\n",
        "s16 = [t1501, ... t1547]\n",
        "```\n",
        "\n",
        "Entonces lo procesaría a través de:\n",
        "\n",
        "```python\n",
        "lstm_layer = layers.LSTM(64, stateful=True)\n",
        "for s in sub_sequences:\n",
        "  output = lstm_layer(s)\n",
        "```\n",
        "\n",
        "Cuando desee borrar el estado, puede utilizar `layer.reset_states()`.\n",
        "\n",
        "> Nota: En esta configuración, se supone que la muestra `i` de un lote determinado es la continuación de la muestra `i` del lote anterior. Esto significa que todos los lotes deben contener el mismo número de muestras (tamaño del lote). Por ejemplo, si un lote contiene `[sequence_A_from_t0_to_t100,  sequence_B_from_t0_to_t100]`, el siguiente lote debería contener `[sequence_A_from_t101_to_t200,  sequence_B_from_t101_to_t200]`.\n",
        "\n",
        "Este es un ejemplo completo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "19e72be49a42"
      },
      "outputs": [],
      "source": [
        "paragraph1 = np.random.random((20, 10, 50)).astype(np.float32)\n",
        "paragraph2 = np.random.random((20, 10, 50)).astype(np.float32)\n",
        "paragraph3 = np.random.random((20, 10, 50)).astype(np.float32)\n",
        "\n",
        "lstm_layer = layers.LSTM(64, stateful=True)\n",
        "output = lstm_layer(paragraph1)\n",
        "output = lstm_layer(paragraph2)\n",
        "output = lstm_layer(paragraph3)\n",
        "\n",
        "# reset_states() will reset the cached state to the original initial_state.\n",
        "# If no initial_state was provided, zero-states will be used by default.\n",
        "lstm_layer.reset_states()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ec7c316b19a1"
      },
      "source": [
        "### Reutilización del estado RNN\n",
        "\n",
        "<a id=\"rnn_state_reuse\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cb7a8ac464a"
      },
      "source": [
        "Los estados registrados de la capa RNN no se incluyen en `layer.weights()`. Si desea reutilizar el estado de una capa RNN, puede recuperar el valor de los estados mediante `layer.states` y utilizarlo como estado inicial para una nueva capa mediante la API funcional de Keras como `new_layer(inputs, initial_state=layer.states)`, o la subclase de modelos.\n",
        "\n",
        "Tenga en cuenta también que el modelo sequential no se puede utilizar en este caso, ya que solo admite capas con una entrada y una salida, y la entrada adicional del estado inicial hace que sea imposible utilizarlo aquí."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "009c5b393adf"
      },
      "outputs": [],
      "source": [
        "paragraph1 = np.random.random((20, 10, 50)).astype(np.float32)\n",
        "paragraph2 = np.random.random((20, 10, 50)).astype(np.float32)\n",
        "paragraph3 = np.random.random((20, 10, 50)).astype(np.float32)\n",
        "\n",
        "lstm_layer = layers.LSTM(64, stateful=True)\n",
        "output = lstm_layer(paragraph1)\n",
        "output = lstm_layer(paragraph2)\n",
        "\n",
        "existing_state = lstm_layer.states\n",
        "\n",
        "new_lstm_layer = layers.LSTM(64)\n",
        "new_output = new_lstm_layer(paragraph3, initial_state=existing_state)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66c1d7f1ccba"
      },
      "source": [
        "## RNNs bidireccionales\n",
        "\n",
        "Para secuencias que no sean series temporales (por ejemplo, texto), suele ocurrir que un modelo RNN puede funcionar mejor si no solo procesa la secuencia de principio a fin, sino también hacia atrás. Por ejemplo, para predecir la siguiente palabra de una frase, suele ser útil disponer del contexto que rodea a la palabra, no únicamente de las palabras que la preceden.\n",
        "\n",
        "Keras proporciona una API sencilla para construir RNNs bidireccionales: el envoltorio `keras.layers.Bidirectional`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8cea1781a0c2"
      },
      "outputs": [],
      "source": [
        "model = keras.Sequential()\n",
        "\n",
        "model.add(\n",
        "    layers.Bidirectional(layers.LSTM(64, return_sequences=True), input_shape=(5, 10))\n",
        ")\n",
        "model.add(layers.Bidirectional(layers.LSTM(32)))\n",
        "model.add(layers.Dense(10))\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dab57c97a566"
      },
      "source": [
        "En este caso, `Bidirectional` copiará la capa RNN introducida e invertirá el campo `go_backwards` de la nueva capa copiada, de forma que procesará las entradas en orden inverso.\n",
        "\n",
        "La salida de la RNN `Bidirectional` será, de forma predeterminada, la concatenación de la salida de la capa hacia adelante y la salida de la capa hacia atrás. Si necesita un comportamiento de fusión diferente, por ejemplo, que una concatenación, cambie el parámetro `merge_mode` en el constructor de la envoltura `Bidirectional`. Para obtener más información sobre `Bidirectional`, consulte [la documentación de la API](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Bidirectional/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18a254dfaa73"
      },
      "source": [
        "## Optimización del rendimiento y kernels CuDNN\n",
        "\n",
        "En TensorFlow 2.0, las capas LSTM y GRU incorporadas se actualizaron para aprovechar los núcleos CuDNN de forma predeterminada cuando está disponible una GPU. Con este cambio, las capas anteriores `keras.layers.CuDNNLSTM/CuDNNGRU` quedaron obsoletas, y podrá construir su modelo sin preocuparse por el hardware en el que se ejecutará.\n",
        "\n",
        "Dado que el kernel CuDNN se construye con ciertas suposiciones, esto significa que la capa **no podrá utilizar el kernel CuDNN si cambia los valores predeterminados de las capas incorporadas LSTM o GRU**. Por ejemplo:\n",
        "\n",
        "- Cambiar la función `activation` de `tanh` a algo distinto.\n",
        "- Cambiar la función `recurrent_activation` de `sigmoide` a algo diferente.\n",
        "- Usar `recurrent_dropout` &gt; 0.\n",
        "- Establecer `unroll` en True, lo que obligará a LSTM/GRU a descomponer el bucle `tf.while_loop` interno en un bucle `for` desenrollado.\n",
        "- Establecer `use_bias` en False.\n",
        "- Utilizar el enmascaramiento cuando los datos de entrada no están estrictamente rellenados a la derecha (si la máscara corresponde a datos estrictamente rellenados a la derecha, CuDNN puede seguir utilizándose. Este es el caso más común).\n",
        "\n",
        "Para obtener la lista detallada de restricciones, consulte la documentación de las capas [LSTM](https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM/) y [GRU](https://www.tensorflow.org/api_docs/python/tf/keras/layers/GRU/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fb8de09c4343"
      },
      "source": [
        "### Cómo utilizar los kernels CuDNN cuando estén disponibles\n",
        "\n",
        "Construyamos un modelo LSTM sencillo para demostrar la diferencia de rendimiento.\n",
        "\n",
        "Utilizaremos como secuencias de entrada la secuencia de filas de dígitos MNIST (tratando cada fila de pixeles como un paso de tiempo), y predeciremos la etiqueta del dígito."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e88aab9e73c7"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "# Each MNIST image batch is a tensor of shape (batch_size, 28, 28).\n",
        "# Each input sequence will be of size (28, 28) (height is treated like time).\n",
        "input_dim = 28\n",
        "\n",
        "units = 64\n",
        "output_size = 10  # labels are from 0 to 9\n",
        "\n",
        "# Build the RNN model\n",
        "def build_model(allow_cudnn_kernel=True):\n",
        "    # CuDNN is only available at the layer level, and not at the cell level.\n",
        "    # This means `LSTM(units)` will use the CuDNN kernel,\n",
        "    # while RNN(LSTMCell(units)) will run on non-CuDNN kernel.\n",
        "    if allow_cudnn_kernel:\n",
        "        # The LSTM layer with default options uses CuDNN.\n",
        "        lstm_layer = keras.layers.LSTM(units, input_shape=(None, input_dim))\n",
        "    else:\n",
        "        # Wrapping a LSTMCell in a RNN layer will not use CuDNN.\n",
        "        lstm_layer = keras.layers.RNN(\n",
        "            keras.layers.LSTMCell(units), input_shape=(None, input_dim)\n",
        "        )\n",
        "    model = keras.models.Sequential(\n",
        "        [\n",
        "            lstm_layer,\n",
        "            keras.layers.BatchNormalization(),\n",
        "            keras.layers.Dense(output_size),\n",
        "        ]\n",
        "    )\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcde82cb14d6"
      },
      "source": [
        "Carguemos el conjunto de datos MNIST:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "98292f8e71a9"
      },
      "outputs": [],
      "source": [
        "mnist = keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "sample, sample_label = x_train[0], y_train[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "443e5458284f"
      },
      "source": [
        "Creemos una instancia del modelo y vamos a entrenarla.\n",
        "\n",
        "Elegimos `sparse_categorical_crossentropy` como función de pérdida para el modelo. La salida del modelo tiene forma de `[batch_size, 10]`. El objetivo para el modelo es un vector entero, cada uno de los enteros está en el rango de 0 a 9."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f85b57b010e5"
      },
      "outputs": [],
      "source": [
        "model = build_model(allow_cudnn_kernel=True)\n",
        "\n",
        "model.compile(\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    optimizer=\"sgd\",\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "\n",
        "model.fit(\n",
        "    x_train, y_train, validation_data=(x_test, y_test), batch_size=batch_size, epochs=1\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99ea5495e375"
      },
      "source": [
        "Ahora, comparemos con un modelo que no utiliza el kernel CuDNN:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d4bdff02e617"
      },
      "outputs": [],
      "source": [
        "noncudnn_model = build_model(allow_cudnn_kernel=False)\n",
        "noncudnn_model.set_weights(model.get_weights())\n",
        "noncudnn_model.compile(\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    optimizer=\"sgd\",\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "noncudnn_model.fit(\n",
        "    x_train, y_train, validation_data=(x_test, y_test), batch_size=batch_size, epochs=1\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90fc64fbd4ea"
      },
      "source": [
        "Cuando se ejecuta en una máquina con una GPU NVIDIA y CuDNN instalada, el modelo construido con CuDNN es mucho más rápido de entrenar en comparación con el modelo que utiliza el kernel TensorFlow normal.\n",
        "\n",
        "El mismo modelo CuDNN habilitado también se puede utilizar para ejecutar la inferencia en un entorno basado únicamente en el CPU. La anotación `tf.device` de abajo solo está forzando la colocación del dispositivo. El modelo se ejecutará en la CPU de forma predeterminada si no hay una GPU disponible.\n",
        "\n",
        "Ya no tendrá que preocuparse por el hardware que utiliza. ¿No es genial?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7e33c62b6029"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "with tf.device(\"CPU:0\"):\n",
        "    cpu_model = build_model(allow_cudnn_kernel=True)\n",
        "    cpu_model.set_weights(model.get_weights())\n",
        "    result = tf.argmax(cpu_model.predict_on_batch(tf.expand_dims(sample, 0)), axis=1)\n",
        "    print(\n",
        "        \"Predicted result is: %s, target result is: %s\" % (result.numpy(), sample_label)\n",
        "    )\n",
        "    plt.imshow(sample, cmap=plt.get_cmap(\"gray\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2f940b73a2a6"
      },
      "source": [
        "## RNNs con entradas de lista/dict, o entradas anidadas\n",
        "\n",
        "Las estructuras anidadas permiten a los programadores incluir más información en un solo paso de tiempo. Por ejemplo, un fotograma de video podría tener entrada de audio y video al mismo tiempo. La forma de los datos en este caso podría ser:\n",
        "\n",
        "`[batch, timestep, {\"video\": [height, width, channel], \"audio\": [frequency]}]`\n",
        "\n",
        "En otro ejemplo, los datos de escritura manual podrían tener coordenadas x y y para la posición actual del bolígrafo, así como información sobre la presión. Así que la representación de los datos podría ser la siguiente:\n",
        "\n",
        "`[batch, timestep, {\"location\": [x, y], \"pressure\": [force]}]`\n",
        "\n",
        "El siguiente código proporciona un ejemplo de cómo construir una celda RNN personalizada que acepte tales entradas estructuradas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f78dc4c1c516"
      },
      "source": [
        "### Cómo definir una celda personalizada que admita entradas/salidas anidadas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "199faf57f0c5"
      },
      "source": [
        "Consulte [Creación de nuevas capas y modelos mediante subclases](https://www.tensorflow.org/guide/keras/custom_layers_and_models/) para obtener más información sobre cómo crear sus propias capas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "451cfd5f0cc4"
      },
      "outputs": [],
      "source": [
        "class NestedCell(keras.layers.Layer):\n",
        "    def __init__(self, unit_1, unit_2, unit_3, **kwargs):\n",
        "        self.unit_1 = unit_1\n",
        "        self.unit_2 = unit_2\n",
        "        self.unit_3 = unit_3\n",
        "        self.state_size = [tf.TensorShape([unit_1]), tf.TensorShape([unit_2, unit_3])]\n",
        "        self.output_size = [tf.TensorShape([unit_1]), tf.TensorShape([unit_2, unit_3])]\n",
        "        super(NestedCell, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shapes):\n",
        "        # expect input_shape to contain 2 items, [(batch, i1), (batch, i2, i3)]\n",
        "        i1 = input_shapes[0][1]\n",
        "        i2 = input_shapes[1][1]\n",
        "        i3 = input_shapes[1][2]\n",
        "\n",
        "        self.kernel_1 = self.add_weight(\n",
        "            shape=(i1, self.unit_1), initializer=\"uniform\", name=\"kernel_1\"\n",
        "        )\n",
        "        self.kernel_2_3 = self.add_weight(\n",
        "            shape=(i2, i3, self.unit_2, self.unit_3),\n",
        "            initializer=\"uniform\",\n",
        "            name=\"kernel_2_3\",\n",
        "        )\n",
        "\n",
        "    def call(self, inputs, states):\n",
        "        # inputs should be in [(batch, input_1), (batch, input_2, input_3)]\n",
        "        # state should be in shape [(batch, unit_1), (batch, unit_2, unit_3)]\n",
        "        input_1, input_2 = tf.nest.flatten(inputs)\n",
        "        s1, s2 = states\n",
        "\n",
        "        output_1 = tf.matmul(input_1, self.kernel_1)\n",
        "        output_2_3 = tf.einsum(\"bij,ijkl->bkl\", input_2, self.kernel_2_3)\n",
        "        state_1 = s1 + output_1\n",
        "        state_2_3 = s2 + output_2_3\n",
        "\n",
        "        output = (output_1, output_2_3)\n",
        "        new_states = (state_1, state_2_3)\n",
        "\n",
        "        return output, new_states\n",
        "\n",
        "    def get_config(self):\n",
        "        return {\"unit_1\": self.unit_1, \"unit_2\": unit_2, \"unit_3\": self.unit_3}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51355b4089d2"
      },
      "source": [
        "### Cómo construir un modelo RNN con entrada/salida anidada\n",
        "\n",
        "Vamos a construir un modelo Keras que utilice una capa `keras.layers.RNN` y la celda personalizada que acabamos de definir."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b2eba7a248eb"
      },
      "outputs": [],
      "source": [
        "unit_1 = 10\n",
        "unit_2 = 20\n",
        "unit_3 = 30\n",
        "\n",
        "i1 = 32\n",
        "i2 = 64\n",
        "i3 = 32\n",
        "batch_size = 64\n",
        "num_batches = 10\n",
        "timestep = 50\n",
        "\n",
        "cell = NestedCell(unit_1, unit_2, unit_3)\n",
        "rnn = keras.layers.RNN(cell)\n",
        "\n",
        "input_1 = keras.Input((None, i1))\n",
        "input_2 = keras.Input((None, i2, i3))\n",
        "\n",
        "outputs = rnn((input_1, input_2))\n",
        "\n",
        "model = keras.models.Model([input_1, input_2], outputs)\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "452a99c63b7c"
      },
      "source": [
        "### Entrene el modelo con datos generados aleatoriamente\n",
        "\n",
        "Dado que no existe un buen conjunto de datos para este modelo, utilizaremos datos aleatorios de Numpy para realizar la demostración."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3987993cb7be"
      },
      "outputs": [],
      "source": [
        "input_1_data = np.random.random((batch_size * num_batches, timestep, i1))\n",
        "input_2_data = np.random.random((batch_size * num_batches, timestep, i2, i3))\n",
        "target_1_data = np.random.random((batch_size * num_batches, unit_1))\n",
        "target_2_data = np.random.random((batch_size * num_batches, unit_2, unit_3))\n",
        "input_data = [input_1_data, input_2_data]\n",
        "target_data = [target_1_data, target_2_data]\n",
        "\n",
        "model.fit(input_data, target_data, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b51e87780b0f"
      },
      "source": [
        "Con la capa `keras.layers.RNN` de Keras, solo se espera que defina la lógica matemática para un paso individual dentro de la secuencia, y la capa `keras.layers.RNN` administrará la iteración de la secuencia por usted. Es una forma increíblemente potente de crear rápidamente prototipos de nuevos tipos de RNN (por ejemplo, una variante de LSTM).\n",
        "\n",
        "Para obtener más información, visite los [documentos de la API](https://https://www.tensorflow.org/api_docs/python/tf/keras/layers/RNN/)."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "rnn.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
