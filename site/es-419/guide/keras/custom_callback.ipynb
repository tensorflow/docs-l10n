{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b518b04cbfe0"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "906e07f6e562"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d201e826ab29"
      },
      "source": [
        "# Cómo escribir sus propias retrollamadas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71699af85d2d"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>     <a target=\"_blank\" href=\"https://www.tensorflow.org/guide/keras/custom_callback\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver en TensorFlow.org</a> </td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/es-419/guide/keras/custom_callback.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Ejecutar en Google Colab</a> </td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/es-419/guide/keras/custom_callback.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver el código fuente en GitHub</a> </td>\n",
        "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/es-419/guide/keras/custom_callback.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Descargar bloc de notas</a> </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d75eb2e25f36"
      },
      "source": [
        "## Introducción\n",
        "\n",
        "Una retrollamada es una poderosa herramienta que permite personalizar el comportamiento de un modelo Keras durante el entrenamiento, la evaluación o la inferencia. Los ejemplos incluyen `tf.keras.callbacks.TensorBoard` para visualizar el progreso del entrenamiento y los resultados con TensorBoard, o `tf.keras.callbacks.ModelCheckpoint` para guardar periódicamente su modelo durante el entrenamiento.\n",
        "\n",
        "En esta guía, aprenderá qué es una retrollamada de Keras, qué puede hacer y cómo puede crear la suya propia. Le ofrecemos algunas demostraciones de aplicaciones de retrollamadas sencillas para que pueda familiarizarse con ellas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3600ee25c8e"
      },
      "source": [
        "## Preparación"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4dadb6688663"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42676f705fc8"
      },
      "source": [
        "## Resumen de retrollamadas de Keras\n",
        "\n",
        "Todas las retrollamadas subclasifican la clase `keras.callbacks.Callback`, y anulan un conjunto de métodos llamados en varias etapas del entrenamiento, la prueba y la predicción. Las retrollamadas son útiles para obtener una visión de los estados internos y las estadísticas del modelo durante el entrenamiento.\n",
        "\n",
        "Puede transferir una lista de retrollamadas (como argumento de palabra clave `callbacks`) a los siguientes métodos del modelo:\n",
        "\n",
        "- `keras.Model.fit()`\n",
        "- `keras.Model.evaluate()`\n",
        "- `keras.Model.predict()`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46945bdf5056"
      },
      "source": [
        "## Un resumen de los métodos de retrollamadas\n",
        "\n",
        "### Métodos globales\n",
        "\n",
        "#### `on_(train|test|predict)_begin(self, logs=None)`\n",
        "\n",
        "Se llama al principio de `fit`/`evaluate`/`predict`.\n",
        "\n",
        "#### `on_(train|test|predict)_end(self, logs=None)`\n",
        "\n",
        "Se llama al final de `fit`/`evaluate`/`predict`.\n",
        "\n",
        "### Métodos de entrenamiento, prueba y predicción por lotes\n",
        "\n",
        "#### `on_(train|test|predict)_batch_begin(self, batch, logs=None)`\n",
        "\n",
        "Se llama justo antes de procesar un lote durante el entrenamiento/prueba/predicción.\n",
        "\n",
        "#### `on_(train|test|predict)_batch_end(self, batch, logs=None)`\n",
        "\n",
        "Se llama al final del entrenamiento/prueba/predicción de un lote. Dentro de este método, `logs` es un dict que contiene los resultados de las métricas.\n",
        "\n",
        "### Métodos a nivel de época (solo para entrenamiento)\n",
        "\n",
        "#### `on_epoch_begin(self, epoch, logs=None)`\n",
        "\n",
        "Se llama al principio de una época durante el entrenamiento.\n",
        "\n",
        "#### `on_epoch_end(self, epoch, logs=None)`\n",
        "\n",
        "Se llama al final de una época durante el entrenamiento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82f2370418a1"
      },
      "source": [
        "## Un ejemplo básico\n",
        "\n",
        "Veamos un ejemplo concreto. Para comenzar, vamos a importar tensorflow y definir un modelo Keras secuencial simple:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7350ea602e50"
      },
      "outputs": [],
      "source": [
        "# Define el modelo de Keras sobre el que desea agregar retrollamadas\n",
        "def get_model():\n",
        "    model = keras.Sequential()\n",
        "    model.add(keras.layers.Dense(1, input_dim=784))\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.RMSprop(learning_rate=0.1),\n",
        "        loss=\"mean_squared_error\",\n",
        "        metrics=[\"mean_absolute_error\"],\n",
        "    )\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "044db5f2dc6f"
      },
      "source": [
        "A continuación, suba los datos MNIST para el entrenamiento y las pruebas desde la API de los conjuntos de datos de Keras:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f8826736a184"
      },
      "outputs": [],
      "source": [
        "# Sube datos MNIST de ejemplo y preprocesarlos\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "x_train = x_train.reshape(-1, 784).astype(\"float32\") / 255.0\n",
        "x_test = x_test.reshape(-1, 784).astype(\"float32\") / 255.0\n",
        "\n",
        "# Limita los datos a 1,000 muestras\n",
        "x_train = x_train[:1000]\n",
        "y_train = y_train[:1000]\n",
        "x_test = x_test[:1000]\n",
        "y_test = y_test[:1000]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9acd50b2215"
      },
      "source": [
        "Ahora, defina una simple retrollamada personalizada que registre:\n",
        "\n",
        "- Cuándo `fit`/`evaluate`/`predict` comienza y termina\n",
        "- Cuándo comienza y termina cada época\n",
        "- Cuándo comienza y termina cada lote de entrenamiento\n",
        "- Cuándo comienza y termina cada lote de evaluación (prueba)\n",
        "- Cuándo comienza y termina cada lote de inferencia (predicción)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cc9888d28e79"
      },
      "outputs": [],
      "source": [
        "class CustomCallback(keras.callbacks.Callback):\n",
        "    def on_train_begin(self, logs=None):\n",
        "        keys = list(logs.keys())\n",
        "        print(\"Starting training; got log keys: {}\".format(keys))\n",
        "\n",
        "    def on_train_end(self, logs=None):\n",
        "        keys = list(logs.keys())\n",
        "        print(\"Stop training; got log keys: {}\".format(keys))\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs=None):\n",
        "        keys = list(logs.keys())\n",
        "        print(\"Start epoch {} of training; got log keys: {}\".format(epoch, keys))\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        keys = list(logs.keys())\n",
        "        print(\"End epoch {} of training; got log keys: {}\".format(epoch, keys))\n",
        "\n",
        "    def on_test_begin(self, logs=None):\n",
        "        keys = list(logs.keys())\n",
        "        print(\"Start testing; got log keys: {}\".format(keys))\n",
        "\n",
        "    def on_test_end(self, logs=None):\n",
        "        keys = list(logs.keys())\n",
        "        print(\"Stop testing; got log keys: {}\".format(keys))\n",
        "\n",
        "    def on_predict_begin(self, logs=None):\n",
        "        keys = list(logs.keys())\n",
        "        print(\"Start predicting; got log keys: {}\".format(keys))\n",
        "\n",
        "    def on_predict_end(self, logs=None):\n",
        "        keys = list(logs.keys())\n",
        "        print(\"Stop predicting; got log keys: {}\".format(keys))\n",
        "\n",
        "    def on_train_batch_begin(self, batch, logs=None):\n",
        "        keys = list(logs.keys())\n",
        "        print(\"...Training: start of batch {}; got log keys: {}\".format(batch, keys))\n",
        "\n",
        "    def on_train_batch_end(self, batch, logs=None):\n",
        "        keys = list(logs.keys())\n",
        "        print(\"...Training: end of batch {}; got log keys: {}\".format(batch, keys))\n",
        "\n",
        "    def on_test_batch_begin(self, batch, logs=None):\n",
        "        keys = list(logs.keys())\n",
        "        print(\"...Evaluating: start of batch {}; got log keys: {}\".format(batch, keys))\n",
        "\n",
        "    def on_test_batch_end(self, batch, logs=None):\n",
        "        keys = list(logs.keys())\n",
        "        print(\"...Evaluating: end of batch {}; got log keys: {}\".format(batch, keys))\n",
        "\n",
        "    def on_predict_batch_begin(self, batch, logs=None):\n",
        "        keys = list(logs.keys())\n",
        "        print(\"...Predicting: start of batch {}; got log keys: {}\".format(batch, keys))\n",
        "\n",
        "    def on_predict_batch_end(self, batch, logs=None):\n",
        "        keys = list(logs.keys())\n",
        "        print(\"...Predicting: end of batch {}; got log keys: {}\".format(batch, keys))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8184bd3a76c2"
      },
      "source": [
        "Vamos a probarlo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "75f7aa1edac6"
      },
      "outputs": [],
      "source": [
        "model = get_model()\n",
        "model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    batch_size=128,\n",
        "    epochs=1,\n",
        "    verbose=0,\n",
        "    validation_split=0.5,\n",
        "    callbacks=[CustomCallback()],\n",
        ")\n",
        "\n",
        "res = model.evaluate(\n",
        "    x_test, y_test, batch_size=128, verbose=0, callbacks=[CustomCallback()]\n",
        ")\n",
        "\n",
        "res = model.predict(x_test, batch_size=128, callbacks=[CustomCallback()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02113b8677eb"
      },
      "source": [
        "### Uso del dict `logs`\n",
        "\n",
        "El dict `logs` contiene el valor de la pérdida, y todas las métricas al final de un lote o época. El ejemplo incluye la pérdida y el error promedio absoluto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "629bc145eb84"
      },
      "outputs": [],
      "source": [
        "class LossAndErrorPrintingCallback(keras.callbacks.Callback):\n",
        "    def on_train_batch_end(self, batch, logs=None):\n",
        "        print(\n",
        "            \"Up to batch {}, the average loss is {:7.2f}.\".format(batch, logs[\"loss\"])\n",
        "        )\n",
        "\n",
        "    def on_test_batch_end(self, batch, logs=None):\n",
        "        print(\n",
        "            \"Up to batch {}, the average loss is {:7.2f}.\".format(batch, logs[\"loss\"])\n",
        "        )\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        print(\n",
        "            \"The average loss for epoch {} is {:7.2f} \"\n",
        "            \"and mean absolute error is {:7.2f}.\".format(\n",
        "                epoch, logs[\"loss\"], logs[\"mean_absolute_error\"]\n",
        "            )\n",
        "        )\n",
        "\n",
        "\n",
        "model = get_model()\n",
        "model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    batch_size=128,\n",
        "    epochs=2,\n",
        "    verbose=0,\n",
        "    callbacks=[LossAndErrorPrintingCallback()],\n",
        ")\n",
        "\n",
        "res = model.evaluate(\n",
        "    x_test,\n",
        "    y_test,\n",
        "    batch_size=128,\n",
        "    verbose=0,\n",
        "    callbacks=[LossAndErrorPrintingCallback()],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "742d62e5394a"
      },
      "source": [
        "## Uso del atributo `self.model`\n",
        "\n",
        "Además de recibir información de registro cuando se llama a uno de sus métodos, las retrollamadas tienen acceso al modelo asociado con la ronda actual de entrenamiento/evaluación/inferencia: `self.model`.\n",
        "\n",
        "Estas son algunas de las cosas que puede hacer con `self.model` en una retrollamada:\n",
        "\n",
        "- Establece `self.model.stop_training = True` para interrumpir inmediatamente el entrenamiento.\n",
        "- Mute los hiperparámetros del optimizador (disponible como `self.model.optimizer`), como `self.model.optimizer.learning_rate`.\n",
        "- Guarde el modelo en intervalos periódicos.\n",
        "- Registre la salida de `model.predict()` sobre algunas muestras de la prueba al final de cada época, para utilizarla como una verificación de sensatez durante el entrenamiento.\n",
        "- Extraer visualizaciones de características intermedias al final de cada época, para controlar lo que el modelo está aprendiendo con el tiempo.\n",
        "- etc.\n",
        "\n",
        "Vamos a ver esto en acción en un par de ejemplos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7eb29d3ed752"
      },
      "source": [
        "## Ejemplos de aplicaciones de retrollamadas de Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2d1d29d99fa5"
      },
      "source": [
        "### Parada anticipada con pérdidas mínimas\n",
        "\n",
        "Este primer ejemplo muestra cómo se crea una `Callback` que detiene el entrenamiento cuando se alcanza el mínimo de pérdida, mediante el atributo `self.model.stop_training` (booleano). De forma opcional, se puede proporcionar un argumento `patience` para especificar cuántas épocas debemos esperar antes de detenernos después de haber alcanzado un mínimo local.\n",
        "\n",
        "`tf.keras.callbacks.EarlyStopping` proporciona una implementación más completa y general."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5d2acd79cecd"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "class EarlyStoppingAtMinLoss(keras.callbacks.Callback):\n",
        "    \"\"\"Stop training when the loss is at its min, i.e. the loss stops decreasing.\n",
        "\n",
        "  Arguments:\n",
        "      patience: Number of epochs to wait after min has been hit. After this\n",
        "      number of no improvement, training stops.\n",
        "  \"\"\"\n",
        "\n",
        "    def __init__(self, patience=0):\n",
        "        super(EarlyStoppingAtMinLoss, self).__init__()\n",
        "        self.patience = patience\n",
        "        # best_weights para almacenar las ponderaciones en las que se produce la pérdida mínima.\n",
        "        self.best_weights = None\n",
        "\n",
        "    def on_train_begin(self, logs=None):\n",
        "        # El número de épocas que esperó cuando la pérdida dejó de ser mínima.\n",
        "        self.wait = 0\n",
        "        # La época en que se detiene el entrenamiento.\n",
        "        self.stopped_epoch = 0\n",
        "        # Inicializa the best como infinity.\n",
        "        self.best = np.Inf\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        current = logs.get(\"loss\")\n",
        "        if np.less(current, self.best):\n",
        "            self.best = current\n",
        "            self.wait = 0\n",
        "            # Registra las mejores ponderaciones si los resultados actuales son mejores (menos).\n",
        "            self.best_weights = self.model.get_weights()\n",
        "        else:\n",
        "            self.wait += 1\n",
        "            if self.wait >= self.patience:\n",
        "                self.stopped_epoch = epoch\n",
        "                self.model.stop_training = True\n",
        "                print(\"Restoring model weights from the end of the best epoch.\")\n",
        "                self.model.set_weights(self.best_weights)\n",
        "\n",
        "    def on_train_end(self, logs=None):\n",
        "        if self.stopped_epoch > 0:\n",
        "            print(\"Epoch %05d: early stopping\" % (self.stopped_epoch + 1))\n",
        "\n",
        "\n",
        "model = get_model()\n",
        "model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    batch_size=64,\n",
        "    steps_per_epoch=5,\n",
        "    epochs=30,\n",
        "    verbose=0,\n",
        "    callbacks=[LossAndErrorPrintingCallback(), EarlyStoppingAtMinLoss()],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "939ecfbe0383"
      },
      "source": [
        "### Programación de la tasa de aprendizaje\n",
        "\n",
        "En este ejemplo, se muestra cómo se puede utilizar una retrollamada personalizada para cambiar dinámicamente la tasa de aprendizaje del optimizador durante el transcurso del entrenamiento.\n",
        "\n",
        "Consulte `callbacks.LearningRateScheduler` para obtener una implementación más general."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "71c752b248c0"
      },
      "outputs": [],
      "source": [
        "class CustomLearningRateScheduler(keras.callbacks.Callback):\n",
        "    \"\"\"Learning rate scheduler which sets the learning rate according to schedule.\n",
        "\n",
        "  Arguments:\n",
        "      schedule: a function that takes an epoch index\n",
        "          (integer, indexed from 0) and current learning rate\n",
        "          as inputs and returns a new learning rate as output (float).\n",
        "  \"\"\"\n",
        "\n",
        "    def __init__(self, schedule):\n",
        "        super(CustomLearningRateScheduler, self).__init__()\n",
        "        self.schedule = schedule\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs=None):\n",
        "        if not hasattr(self.model.optimizer, \"lr\"):\n",
        "            raise ValueError('Optimizer must have a \"lr\" attribute.')\n",
        "        # Obtiene la tasa de aprendizaje actual del optimizador del modelo.\n",
        "        lr = float(tf.keras.backend.get_value(self.model.optimizer.learning_rate))\n",
        "        # Llame a la función de programación para obtener la tasa de aprendizaje programada.\n",
        "        scheduled_lr = self.schedule(epoch, lr)\n",
        "        # Devuelva el valor al optimizador antes de que comience esta época\n",
        "        tf.keras.backend.set_value(self.model.optimizer.lr, scheduled_lr)\n",
        "        print(\"\\nEpoch %05d: Learning rate is %6.4f.\" % (epoch, scheduled_lr))\n",
        "\n",
        "\n",
        "LR_SCHEDULE = [\n",
        "    # (epoch to start, learning rate) tuples\n",
        "    (3, 0.05),\n",
        "    (6, 0.01),\n",
        "    (9, 0.005),\n",
        "    (12, 0.001),\n",
        "]\n",
        "\n",
        "\n",
        "def lr_schedule(epoch, lr):\n",
        "    \"\"\"Helper function to retrieve the scheduled learning rate based on epoch.\"\"\"\n",
        "    if epoch < LR_SCHEDULE[0][0] or epoch > LR_SCHEDULE[-1][0]:\n",
        "        return lr\n",
        "    for i in range(len(LR_SCHEDULE)):\n",
        "        if epoch == LR_SCHEDULE[i][0]:\n",
        "            return LR_SCHEDULE[i][1]\n",
        "    return lr\n",
        "\n",
        "\n",
        "model = get_model()\n",
        "model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    batch_size=64,\n",
        "    steps_per_epoch=5,\n",
        "    epochs=15,\n",
        "    verbose=0,\n",
        "    callbacks=[\n",
        "        LossAndErrorPrintingCallback(),\n",
        "        CustomLearningRateScheduler(lr_schedule),\n",
        "    ],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9be225b57f1"
      },
      "source": [
        "### Retrollamadas de Keras integradas\n",
        "\n",
        "Asegúrese de revisar las retrollamadas actuales de Keras leyendo la [API docs](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/). Las aplicaciones incluyen el registro en CSV, guardar el modelo, visualizar métricas en TensorBoard, ¡y mucho más!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "custom_callback.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
