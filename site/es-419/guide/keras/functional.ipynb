{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b518b04cbfe0"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "906e07f6e562"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "da6087fbd570"
      },
      "source": [
        "# La API funcional"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d169f4a559d5"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>     <a target=\"_blank\" href=\"https://www.tensorflow.org/guide/keras/functional\">     <img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">     Ver en TensorFlow.org</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/es-419/guide/keras/functional.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Run in Google Colab</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/es-419/guide/keras/functional.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver el código fuente en GitHub</a>\n",
        "</td>\n",
        "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/es-419/guide/keras/functional.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Descargar el bloc de notas</a>\n",
        "</td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8d4ac441b1fc"
      },
      "source": [
        "## Preparación"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ec52be14e686"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "871fbb54ea07"
      },
      "source": [
        "## Introducción\n",
        "\n",
        "La *API funcional* de Keras es una forma de crear modelos más flexibles que la API `tf.keras.Sequential` API. La API funcional puede administrar modelos con topología no lineal, capas compartidas e incluso entradas o salidas múltiples.\n",
        "\n",
        "La idea principal es que un modelo de aprendizaje profundo suele ser un grafo acíclico dirigido (DAG) de capas. Así que la API funcional es una manera de construir *grafos de capas*.\n",
        "\n",
        "Considere el siguiente modelo:\n",
        "\n",
        "```\n",
        "(input: 784-dimensional vectors)\n",
        "       ↧\n",
        "[Dense (64 units, relu activation)]\n",
        "       ↧\n",
        "[Dense (64 units, relu activation)]\n",
        "       ↧\n",
        "[Dense (10 units, softmax activation)]\n",
        "       ↧\n",
        "(output: logits of a probability distribution over 10 classes)\n",
        "```\n",
        "\n",
        "Se trata de un grafo básico con tres capas. Para construir este modelo mediante la API funcional, empiece por crear un nodo de entrada:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8d477c91955a"
      },
      "outputs": [],
      "source": [
        "inputs = keras.Input(shape=(784,))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13c14d993620"
      },
      "source": [
        "La forma de los datos se establece como un vector de 784 dimensiones. El tamaño del lote siempre se omite, ya que solo se especifica la forma de cada muestra.\n",
        "\n",
        "Si, por ejemplo, tiene una entrada de imagen con el formato `(32, 32, 3)`, utilizaría:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e4732e8e279b"
      },
      "outputs": [],
      "source": [
        "# Just for demonstration purposes.\n",
        "img_inputs = keras.Input(shape=(32, 32, 3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "971bf8b5588f"
      },
      "source": [
        "El `inputs` que se devuelve contiene información sobre la forma y el `dtype` de los datos de entrada que se introducen en el modelo. Aquí se muestra la forma:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ee96c179846a"
      },
      "outputs": [],
      "source": [
        "inputs.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "866eee86d63e"
      },
      "source": [
        "Este es el dtype:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "480be92067f3"
      },
      "outputs": [],
      "source": [
        "inputs.dtype"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6c93172cdfba"
      },
      "source": [
        "Se crea un nuevo nodo en el grafo de capas que llama a una capa en este objeto `inputs`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b50da8b1c28d"
      },
      "outputs": [],
      "source": [
        "dense = layers.Dense(64, activation=\"relu\")\n",
        "x = dense(inputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0f36afe42ff3"
      },
      "source": [
        "La acción \"llamar capa\" es como trazar una flecha desde las \"entradas\" a esta capa que creó. Está \"pasando\" las entradas a la capa `dense`, y obtiene `x` como salida.\n",
        "\n",
        "Agreguemos algunas capas más al grafo de capas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "463d5cd0c484"
      },
      "outputs": [],
      "source": [
        "x = layers.Dense(64, activation=\"relu\")(x)\n",
        "outputs = layers.Dense(10)(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e379f089b044"
      },
      "source": [
        "En este punto, puede crear un `Model` al especificar sus entradas y salidas en el grafo de capas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7820cc2209a6"
      },
      "outputs": [],
      "source": [
        "model = keras.Model(inputs=inputs, outputs=outputs, name=\"mnist_model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9aa111852d3"
      },
      "source": [
        "Echemos un vistazo al resumen del modelo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4949ab8242e8"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99ab8535d6c3"
      },
      "source": [
        "También puede representar el modelo en forma de grafo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6872f1b1b8b8"
      },
      "outputs": [],
      "source": [
        "keras.utils.plot_model(model, \"my_first_model.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6d9880136879"
      },
      "source": [
        "Y, opcionalmente, mostrar las formas de entrada y salida de cada capa en el grafo representado:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aa14046d3388"
      },
      "outputs": [],
      "source": [
        "keras.utils.plot_model(model, \"my_first_model_with_shape_info.png\", show_shapes=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71969f9c91bb"
      },
      "source": [
        "Esta figura y el código son casi idénticos. En la versión del código, las flechas de conexión se sustituyen por la operación de llamada.\n",
        "\n",
        "Un \"grafo de capas\" es una imagen mental intuitiva para un modelo de aprendizaje profundo, y la API funcional es una forma de crear modelos que lo reflejen a la perfección."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "775b997c8c28"
      },
      "source": [
        "## Entrenamiento, evaluación e inferencia\n",
        "\n",
        "El entrenamiento, la evaluación y la inferencia funcionan exactamente de la misma manera para los modelos creados utilizando la API funcional así como para los modelos `Sequential`.\n",
        "\n",
        "La clase `Model` ofrece un bucle de entrenamiento integrado (el método `fit()`) y un bucle de evaluación integrado (el método `evaluate()`). Tenga en cuenta que puede [personalizar fácilmente estos bucles](https://www.tensorflow.org/guide/keras/customizing_what_happens_in_fit/) para implementar rutinas de entrenamiento más allá del aprendizaje supervisado (por ejemplo, [GANs](/examples/generative/dcgan_overriding_train_step/)).\n",
        "\n",
        "En este caso, se cargan los datos de la imagen MNIST, se remodelan en vectores, se ajusta el modelo a los datos (mientras se supervisa el rendimiento en una división de validación) y, a continuación, se evalúa el modelo con los datos de prueba:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e61366d54487"
      },
      "outputs": [],
      "source": [
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "x_train = x_train.reshape(60000, 784).astype(\"float32\") / 255\n",
        "x_test = x_test.reshape(10000, 784).astype(\"float32\") / 255\n",
        "\n",
        "model.compile(\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    optimizer=keras.optimizers.RMSprop(),\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "history = model.fit(x_train, y_train, batch_size=64, epochs=2, validation_split=0.2)\n",
        "\n",
        "test_scores = model.evaluate(x_test, y_test, verbose=2)\n",
        "print(\"Test loss:\", test_scores[0])\n",
        "print(\"Test accuracy:\", test_scores[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2e13d7168c86"
      },
      "source": [
        "Para obtener más información, consulte la guía de [formación y evaluación](https://www.tensorflow.org/guide/keras/train_and_evaluate/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26991ef4dbbb"
      },
      "source": [
        "## Guardar y serializar\n",
        "\n",
        "Guardar el modelo y la serialización funcionan de la misma manera para los modelos construidos utilizando la API funcional que para los modelos `Sequential`. La forma estándar de guardar un modelo funcional es llamar a `model.save()` para guardar todo el modelo como un único archivo. Más tarde se puede volver a crear el mismo modelo a partir de este archivo, incluso si el código que construyó el modelo ya no está disponible.\n",
        "\n",
        "Este archivo guardado incluye:\n",
        "\n",
        "- arquitectura modelo\n",
        "- valores de peso del modelo ( que se aprendieron durante el entrenamiento)\n",
        "- configuración de entrenamiento del modelo, si existe (tal como se pasó a `compile`)\n",
        "- optimizador y su estado, si lo hay (para reiniciar el entrenamiento donde lo dejó)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7e5e48669225"
      },
      "outputs": [],
      "source": [
        "model.save(\"path_to_my_model\")\n",
        "del model\n",
        "# Recreate the exact same model purely from the file:\n",
        "model = keras.models.load_model(\"path_to_my_model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfe2a761139b"
      },
      "source": [
        "Para obtener más información, lea la guía del modelo [serialización y guardado](https://www.tensorflow.org/guide/keras/save_and_serialize/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b747517364a9"
      },
      "source": [
        "## Utilice el mismo grafo de capas para definir varios modelos\n",
        "\n",
        "En la API funcional, los modelos se crean especificando sus entradas y salidas en un grafo de capas. Esto significa que un solo grafo de capas puede utilizarse para generar múltiples modelos.\n",
        "\n",
        "En el siguiente ejemplo, se utiliza la misma pila de capas para instanciar dos modelos: un modelo `encoder` que convierte las entradas de imagen en vectores de 16 dimensiones, y un modelo `autoencoder` de extremo a extremo para el entrenamiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f9924d8c9ed3"
      },
      "outputs": [],
      "source": [
        "encoder_input = keras.Input(shape=(28, 28, 1), name=\"img\")\n",
        "x = layers.Conv2D(16, 3, activation=\"relu\")(encoder_input)\n",
        "x = layers.Conv2D(32, 3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(3)(x)\n",
        "x = layers.Conv2D(32, 3, activation=\"relu\")(x)\n",
        "x = layers.Conv2D(16, 3, activation=\"relu\")(x)\n",
        "encoder_output = layers.GlobalMaxPooling2D()(x)\n",
        "\n",
        "encoder = keras.Model(encoder_input, encoder_output, name=\"encoder\")\n",
        "encoder.summary()\n",
        "\n",
        "x = layers.Reshape((4, 4, 1))(encoder_output)\n",
        "x = layers.Conv2DTranspose(16, 3, activation=\"relu\")(x)\n",
        "x = layers.Conv2DTranspose(32, 3, activation=\"relu\")(x)\n",
        "x = layers.UpSampling2D(3)(x)\n",
        "x = layers.Conv2DTranspose(16, 3, activation=\"relu\")(x)\n",
        "decoder_output = layers.Conv2DTranspose(1, 3, activation=\"relu\")(x)\n",
        "\n",
        "autoencoder = keras.Model(encoder_input, decoder_output, name=\"autoencoder\")\n",
        "autoencoder.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e87d4185b652"
      },
      "source": [
        "Aquí, la arquitectura de descodificación es estrictamente simétrica a la arquitectura de codificación, por lo que la forma de salida es la misma que la forma de entrada `(28, 28, 1)`.\n",
        "\n",
        "El reverso de una capa `Conv2D` es una capa `Conv2DTranspose`, y el reverso de una capa `MaxPooling2D` es una capa `UpSampling2D`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9c746c1a0b79"
      },
      "source": [
        "## Todos los modelos se pueden llamar, al igual que las capas\n",
        "\n",
        "Puedes tratar cualquier modelo como si fuera una capa llamándolo sobre un `Input` o sobre la salida de otra capa. Al llamar a un modelo no solo estás reutilizando la arquitectura del modelo, también estás reutilizando sus pesos.\n",
        "\n",
        "To see this in action, here's a different take on the autoencoder example that creates an encoder model, a decoder model, and chains them in two calls to obtain the autoencoder model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "862ac58e928b"
      },
      "outputs": [],
      "source": [
        "encoder_input = keras.Input(shape=(28, 28, 1), name=\"original_img\")\n",
        "x = layers.Conv2D(16, 3, activation=\"relu\")(encoder_input)\n",
        "x = layers.Conv2D(32, 3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(3)(x)\n",
        "x = layers.Conv2D(32, 3, activation=\"relu\")(x)\n",
        "x = layers.Conv2D(16, 3, activation=\"relu\")(x)\n",
        "encoder_output = layers.GlobalMaxPooling2D()(x)\n",
        "\n",
        "encoder = keras.Model(encoder_input, encoder_output, name=\"encoder\")\n",
        "encoder.summary()\n",
        "\n",
        "decoder_input = keras.Input(shape=(16,), name=\"encoded_img\")\n",
        "x = layers.Reshape((4, 4, 1))(decoder_input)\n",
        "x = layers.Conv2DTranspose(16, 3, activation=\"relu\")(x)\n",
        "x = layers.Conv2DTranspose(32, 3, activation=\"relu\")(x)\n",
        "x = layers.UpSampling2D(3)(x)\n",
        "x = layers.Conv2DTranspose(16, 3, activation=\"relu\")(x)\n",
        "decoder_output = layers.Conv2DTranspose(1, 3, activation=\"relu\")(x)\n",
        "\n",
        "decoder = keras.Model(decoder_input, decoder_output, name=\"decoder\")\n",
        "decoder.summary()\n",
        "\n",
        "autoencoder_input = keras.Input(shape=(28, 28, 1), name=\"img\")\n",
        "encoded_img = encoder(autoencoder_input)\n",
        "decoded_img = decoder(encoded_img)\n",
        "autoencoder = keras.Model(autoencoder_input, decoded_img, name=\"autoencoder\")\n",
        "autoencoder.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0f77623d9cd5"
      },
      "source": [
        "Como puede ver, el modelo puede anidarse: un modelo puede contener submodelos (ya que un modelo es como una capa). Un caso de uso común para el anidamiento de modelos es *ensembling*.. Por ejemplo, a continuación se muestra cómo ensamblar un conjunto de modelos en un único modelo que promedia sus predicciones:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3bb36b630e5d"
      },
      "outputs": [],
      "source": [
        "def get_model():\n",
        "    inputs = keras.Input(shape=(128,))\n",
        "    outputs = layers.Dense(1)(inputs)\n",
        "    return keras.Model(inputs, outputs)\n",
        "\n",
        "\n",
        "model1 = get_model()\n",
        "model2 = get_model()\n",
        "model3 = get_model()\n",
        "\n",
        "inputs = keras.Input(shape=(128,))\n",
        "y1 = model1(inputs)\n",
        "y2 = model2(inputs)\n",
        "y3 = model3(inputs)\n",
        "outputs = layers.average([y1, y2, y3])\n",
        "ensemble_model = keras.Model(inputs=inputs, outputs=outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "447a319b73a6"
      },
      "source": [
        "## Cómo manipular topologías de grafos complejos\n",
        "\n",
        "### Modelos con múltiples entradas y salidas\n",
        "\n",
        "La API funcional facilita la manipulación de múltiples entradas y salidas. Esto no se puede manejar con la API `Sequential`.\n",
        "\n",
        "Por ejemplo, si está creando un sistema para clasificar las incidencias de los clientes por prioridad y dirigirlas al departamento adecuado, el modelo tendrá tres entradas:\n",
        "\n",
        "- el título del billete (entrada de texto),\n",
        "- el cuerpo del texto del billete (entrada de texto), y\n",
        "- cualquier etiqueta que agregue el usuario (entrada categórica)\n",
        "\n",
        "Este modelo tendrá dos resultados:\n",
        "\n",
        "- la puntuación de prioridad entre 0 y 1 (salida sigmoide escalar), y\n",
        "- el departamento que debe administrar el ticket (salida softmax sobre el conjunto de departamentos).\n",
        "\n",
        "Puede crear este modelo en unas pocas líneas con la API funcional:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "49009e53da63"
      },
      "outputs": [],
      "source": [
        "num_tags = 12  # Number of unique issue tags\n",
        "num_words = 10000  # Size of vocabulary obtained when preprocessing text data\n",
        "num_departments = 4  # Number of departments for predictions\n",
        "\n",
        "title_input = keras.Input(\n",
        "    shape=(None,), name=\"title\"\n",
        ")  # Variable-length sequence of ints\n",
        "body_input = keras.Input(shape=(None,), name=\"body\")  # Variable-length sequence of ints\n",
        "tags_input = keras.Input(\n",
        "    shape=(num_tags,), name=\"tags\"\n",
        ")  # Binary vectors of size `num_tags`\n",
        "\n",
        "# Embed each word in the title into a 64-dimensional vector\n",
        "title_features = layers.Embedding(num_words, 64)(title_input)\n",
        "# Embed each word in the text into a 64-dimensional vector\n",
        "body_features = layers.Embedding(num_words, 64)(body_input)\n",
        "\n",
        "# Reduce sequence of embedded words in the title into a single 128-dimensional vector\n",
        "title_features = layers.LSTM(128)(title_features)\n",
        "# Reduce sequence of embedded words in the body into a single 32-dimensional vector\n",
        "body_features = layers.LSTM(32)(body_features)\n",
        "\n",
        "# Merge all available features into a single large vector via concatenation\n",
        "x = layers.concatenate([title_features, body_features, tags_input])\n",
        "\n",
        "# Stick a logistic regression for priority prediction on top of the features\n",
        "priority_pred = layers.Dense(1, name=\"priority\")(x)\n",
        "# Stick a department classifier on top of the features\n",
        "department_pred = layers.Dense(num_departments, name=\"department\")(x)\n",
        "\n",
        "# Instantiate an end-to-end model predicting both priority and department\n",
        "model = keras.Model(\n",
        "    inputs=[title_input, body_input, tags_input],\n",
        "    outputs=[priority_pred, department_pred],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ee2735b3eff1"
      },
      "source": [
        "Ahora grafica el modelo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "52c4dc6fd93e"
      },
      "outputs": [],
      "source": [
        "keras.utils.plot_model(model, \"multi_input_and_output_model.png\", show_shapes=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "907c119d04a4"
      },
      "source": [
        "Al compilar este modelo, puede asignar diferentes pérdidas a cada salida. Incluso puede asignar distintos pesos a cada pérdida, para modular su contribución a la pérdida total del entrenamiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3e1acef07668"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    optimizer=keras.optimizers.RMSprop(1e-3),\n",
        "    loss=[\n",
        "        keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "        keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "    ],\n",
        "    loss_weights=[1.0, 0.2],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4bd84048d41"
      },
      "source": [
        "Dado que las capas de salida tienen nombres diferentes, también puede especificar las pérdidas y los pesos de pérdida con los nombres de capa correspondientes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "37a6af4b30c8"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    optimizer=keras.optimizers.RMSprop(1e-3),\n",
        "    loss={\n",
        "        \"priority\": keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "        \"department\": keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "    },\n",
        "    loss_weights={\"priority\": 1.0, \"department\": 0.2},\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "845b20ca3c9d"
      },
      "source": [
        "Entrena el modelo pasando listas de matrices NumPy de entradas y objetivos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ae5ff9364b19"
      },
      "outputs": [],
      "source": [
        "# Dummy input data\n",
        "title_data = np.random.randint(num_words, size=(1280, 10))\n",
        "body_data = np.random.randint(num_words, size=(1280, 100))\n",
        "tags_data = np.random.randint(2, size=(1280, num_tags)).astype(\"float32\")\n",
        "\n",
        "# Dummy target data\n",
        "priority_targets = np.random.random(size=(1280, 1))\n",
        "dept_targets = np.random.randint(2, size=(1280, num_departments))\n",
        "\n",
        "model.fit(\n",
        "    {\"title\": title_data, \"body\": body_data, \"tags\": tags_data},\n",
        "    {\"priority\": priority_targets, \"department\": dept_targets},\n",
        "    epochs=2,\n",
        "    batch_size=32,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3c87f1fbe7aa"
      },
      "source": [
        "Cuando se llama a fit con un objeto `Dataset`, debería producir una tupla de listas como `([title_data, body_data, tags_data], [priority_targets, dept_targets])` o una tupla de diccionarios como `({'title': title_data, 'body': body_data, 'tags': tags_data}, {'priority': priority_targets, 'department': dept_targets})`.\n",
        "\n",
        "Para obtener una explicación más detallada, consulte la guía de [entrenamiento y evaluación](https://www.tensorflow.org/guide/keras/train_and_evaluate/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64ada3f80484"
      },
      "source": [
        "### Un modelo ResNet de prueba\n",
        "\n",
        "Además de los modelos con múltiples entradas y salidas, la API funcional facilita la manipulación de topologías de conectividad no lineales, es decir, modelos con capas que no están conectadas secuencialmente, que la API `Sequential` no puede administrar.\n",
        "\n",
        "Un caso de uso común para esto son las conexiones residuales. Vamos a construir un modelo ResNet de prueba para CIFAR10 para demostrarlo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bfa8b7503813"
      },
      "outputs": [],
      "source": [
        "inputs = keras.Input(shape=(32, 32, 3), name=\"img\")\n",
        "x = layers.Conv2D(32, 3, activation=\"relu\")(inputs)\n",
        "x = layers.Conv2D(64, 3, activation=\"relu\")(x)\n",
        "block_1_output = layers.MaxPooling2D(3)(x)\n",
        "\n",
        "x = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(block_1_output)\n",
        "x = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "block_2_output = layers.add([x, block_1_output])\n",
        "\n",
        "x = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(block_2_output)\n",
        "x = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "block_3_output = layers.add([x, block_2_output])\n",
        "\n",
        "x = layers.Conv2D(64, 3, activation=\"relu\")(block_3_output)\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "x = layers.Dense(256, activation=\"relu\")(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(10)(x)\n",
        "\n",
        "model = keras.Model(inputs, outputs, name=\"toy_resnet\")\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05aefc66c54f"
      },
      "source": [
        "Grafica el modelo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ef7ac19c83be"
      },
      "outputs": [],
      "source": [
        "keras.utils.plot_model(model, \"mini_resnet.png\", show_shapes=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4f0883eae520"
      },
      "source": [
        "Ahora entrene el modelo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4e1c7b530071"
      },
      "outputs": [],
      "source": [
        "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
        "\n",
        "x_train = x_train.astype(\"float32\") / 255.0\n",
        "x_test = x_test.astype(\"float32\") / 255.0\n",
        "y_train = keras.utils.to_categorical(y_train, 10)\n",
        "y_test = keras.utils.to_categorical(y_test, 10)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.RMSprop(1e-3),\n",
        "    loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[\"acc\"],\n",
        ")\n",
        "# We restrict the data to the first 1000 samples so as to limit execution time\n",
        "# on Colab. Try to train on the entire dataset until convergence!\n",
        "model.fit(x_train[:1000], y_train[:1000], batch_size=64, epochs=1, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7f35a9a1061"
      },
      "source": [
        "## Capas compartidas\n",
        "\n",
        "Otro buen uso de la API funcional son los modelos que utilizan *capas compartidas*. Las capas compartidas son instancias de capas que se reutilizan varias veces en el mismo modelo: aprenden características que corresponden a varias rutas en el grafo de capas.\n",
        "\n",
        "Las capas compartidas se utilizan frecuentemente para codificar entradas de espacios similares (por ejemplo, dos textos diferentes con un vocabulario similar). Permiten compartir la información entre las distintas entradas y entrenar el modelo con menos datos. Si una palabra determinada aparece en una de las entradas, eso beneficiará al procesamiento de todas las entradas que pasen por la capa compartida.\n",
        "\n",
        "Para compartir una capa en la API funcional, llame a la misma instancia de capa varias veces. Por ejemplo, aquí hay una capa `Embedding` compartida en dos entradas de texto diferentes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4b8e6a4f3e88"
      },
      "outputs": [],
      "source": [
        "# Embedding for 1000 unique words mapped to 128-dimensional vectors\n",
        "shared_embedding = layers.Embedding(1000, 128)\n",
        "\n",
        "# Variable-length sequence of integers\n",
        "text_input_a = keras.Input(shape=(None,), dtype=\"int32\")\n",
        "\n",
        "# Variable-length sequence of integers\n",
        "text_input_b = keras.Input(shape=(None,), dtype=\"int32\")\n",
        "\n",
        "# Reuse the same layer to encode both inputs\n",
        "encoded_input_a = shared_embedding(text_input_a)\n",
        "encoded_input_b = shared_embedding(text_input_b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4f193a74581"
      },
      "source": [
        "## Cómo extraer y reutilizar nodos en el grafo de capas\n",
        "\n",
        "Dado que el grafo de capas que está manipulando una estructura de datos estática, se puede acceder a ella e inspeccionarla. Y así es como se pueden graficar modelos funcionales como imágenes.\n",
        "\n",
        "Esto también significa que puede acceder a las activaciones de las capas intermedias (\"nodos\" en el grafo) y reutilizarlas en otro lugar, lo que resulta muy útil para algo como la extracción de características.\n",
        "\n",
        "Echemos un vistazo a un ejemplo. Se trata de un modelo VGG19 con pesos preentrenados en ImageNet:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8bdaa209ccbe"
      },
      "outputs": [],
      "source": [
        "vgg19 = tf.keras.applications.VGG19()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "874ef4b4de49"
      },
      "source": [
        "Y estas son las activaciones intermedias del modelo, obtenidas mediante la consulta de la estructura de datos del grafo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "391817839937"
      },
      "outputs": [],
      "source": [
        "features_list = [layer.output for layer in vgg19.layers]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e91a9dc2f5b0"
      },
      "source": [
        "Utiliza estas características para crear un nuevo modelo de extracción de características que devuelva los valores de las activaciones de las capas intermedias:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "36a450517b63"
      },
      "outputs": [],
      "source": [
        "feat_extraction_model = keras.Model(inputs=vgg19.input, outputs=features_list)\n",
        "\n",
        "img = np.random.random((1, 224, 224, 3)).astype(\"float32\")\n",
        "extracted_features = feat_extraction_model(img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2ac248fe202"
      },
      "source": [
        "Esto resulta útil para tareas como la [transferencia de estilo neural](https://keras.io/examples/generative/neural_style_transfer/), entre otras cosas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c894ba891064"
      },
      "source": [
        "## Cómo ampliar la API mediante capas personalizadas\n",
        "\n",
        "`tf.keras` incluye una amplia gama de capas incorporadas, por ejemplo:\n",
        "\n",
        "- Capas convolucionales: `Conv1D`, `Conv2D`, `Conv3D`, `Conv2DTranspose`\n",
        "- Capas de agrupamiento: `MaxPooling1D`, `MaxPooling2D`, `MaxPooling3D`, `AveragePooling1D`\n",
        "- Capas RNN: `GRU`, `LSTM`, `ConvLSTM2D`\n",
        "- `BatchNormalization`, `Dropout`, `Embedding`, etc.\n",
        "\n",
        "Pero si no encuentra lo que necesita, es fácil ampliar la API creando sus propias capas. Todas las capas subclasifican la clase `Layer` e implementan:\n",
        "\n",
        "- `call` método, que especifica el cálculo realizado por la capa.\n",
        "- `build`, que crea los pesos de la capa (esto es solo una convención de estilo, ya que también se pueden crear pesos en `__init__`).\n",
        "\n",
        "Para obtener más información sobre la creación de capas desde cero, lea la guía [capas y modelos personalizados](https://www.tensorflow.org/guide/keras/custom_layers_and_models).\n",
        "\n",
        "La siguiente es una implementación básica de `tf.keras.layers.Dense`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1d9faf1f622a"
      },
      "outputs": [],
      "source": [
        "class CustomDense(layers.Layer):\n",
        "    def __init__(self, units=32):\n",
        "        super(CustomDense, self).__init__()\n",
        "        self.units = units\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.w = self.add_weight(\n",
        "            shape=(input_shape[-1], self.units),\n",
        "            initializer=\"random_normal\",\n",
        "            trainable=True,\n",
        "        )\n",
        "        self.b = self.add_weight(\n",
        "            shape=(self.units,), initializer=\"random_normal\", trainable=True\n",
        "        )\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return tf.matmul(inputs, self.w) + self.b\n",
        "\n",
        "\n",
        "inputs = keras.Input((4,))\n",
        "outputs = CustomDense(10)(inputs)\n",
        "\n",
        "model = keras.Model(inputs, outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8933568358c"
      },
      "source": [
        "Para admitir la serialización en su capa personalizada, defina un método `get_config` que devuelva los argumentos del constructor de la instancia de la capa:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b22a134918a2"
      },
      "outputs": [],
      "source": [
        "class CustomDense(layers.Layer):\n",
        "    def __init__(self, units=32):\n",
        "        super(CustomDense, self).__init__()\n",
        "        self.units = units\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.w = self.add_weight(\n",
        "            shape=(input_shape[-1], self.units),\n",
        "            initializer=\"random_normal\",\n",
        "            trainable=True,\n",
        "        )\n",
        "        self.b = self.add_weight(\n",
        "            shape=(self.units,), initializer=\"random_normal\", trainable=True\n",
        "        )\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return tf.matmul(inputs, self.w) + self.b\n",
        "\n",
        "    def get_config(self):\n",
        "        return {\"units\": self.units}\n",
        "\n",
        "\n",
        "inputs = keras.Input((4,))\n",
        "outputs = CustomDense(10)(inputs)\n",
        "\n",
        "model = keras.Model(inputs, outputs)\n",
        "config = model.get_config()\n",
        "\n",
        "new_model = keras.Model.from_config(config, custom_objects={\"CustomDense\": CustomDense})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "015abf7d0508"
      },
      "source": [
        "Opcionalmente, implemente el método de clase `from_config(cls, config)` que se utiliza para recrear una instancia de capa dado su diccionario config. La implementación predeterminada de `from_config` es:\n",
        "\n",
        "```python\n",
        "def from_config(cls, config):\n",
        "  return cls(**config)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4ead34e01dd"
      },
      "source": [
        "## Cuándo utilizar la API funcional\n",
        "\n",
        "¿Debería utilizar la API funcional de Keras para crear un nuevo modelo, o simplemente subclasificar la clase `Model` directamente? En general, la API funcional es de más alto nivel, más fácil y más segura, y tiene una serie de características que los modelos subclasificados no admiten.\n",
        "\n",
        "Sin embargo, la subclase de modelos proporciona una mayor flexibilidad cuando se construyen modelos que no se expresan fácilmente como grafos acíclicos dirigidas por capas. Por ejemplo, no se podría implementar una Tree-RNN con la API funcional y se debería subclasificar `Model` de forma directa.\n",
        "\n",
        "Para profundizar en las diferencias entre la API funcional y la subclase de modelos, lea [¿Qué son las API Symbolic e Imperative en TensorFlow 2.0?](https://blog.tensorflow.org/2019/01/what-are-symbolic-and-imperative-apis.html).\n",
        "\n",
        "### Fortalezas funcionales de la API:\n",
        "\n",
        "Las siguientes propiedades también son válidas para los modelos secuenciales (que también son estructuras de datos), pero no para los modelos subclasificados (que son código de bytes de Python, pero no estructuras de datos).\n",
        "\n",
        "#### Menos verborrea\n",
        "\n",
        "No hay `super(MyClass, self).__init__(...)`, no hay `def call(self, ...):`, etc.\n",
        "\n",
        "Comparar:\n",
        "\n",
        "```python\n",
        "inputs = keras.Input(shape=(32,))\n",
        "x = layers.Dense(64, activation='relu')(inputs)\n",
        "outputs = layers.Dense(10)(x)\n",
        "mlp = keras.Model(inputs, outputs)\n",
        "```\n",
        "\n",
        "Con la versión subclasificada:\n",
        "\n",
        "```python\n",
        "class MLP(keras.Model):\n",
        "\n",
        "  def __init__(self, **kwargs):\n",
        "    super(MLP, self).__init__(**kwargs)\n",
        "    self.dense_1 = layers.Dense(64, activation='relu')\n",
        "    self.dense_2 = layers.Dense(10)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    x = self.dense_1(inputs)\n",
        "    return self.dense_2(x)\n",
        "\n",
        "# Instantiate the model.\n",
        "mlp = MLP()\n",
        "# Necessary to create the model's state.\n",
        "# The model doesn't have a state until it's called at least once.\n",
        "_ = mlp(tf.zeros((1, 32)))\n",
        "```\n",
        "\n",
        "#### Validación del modelo mientras se define su grafo de conectividad\n",
        "\n",
        "En la API funcional, la especificación de entrada (forma y tipo) se crea por adelantado (utilizando `Input`). Cada vez que se llama a una capa, ésta comprueba que la especificación que se ha recibido coincide con sus suposiciones y, en caso contrario, mostrará un mensaje de error.\n",
        "\n",
        "Esto garantiza que cualquier modelo que puedas construir con la API funcional se ejecutará. Toda la depuración, excepto la relacionada con la convergencia, se realiza estáticamente durante la construcción del modelo y no en tiempo de ejecución. Esto es similar a la verificación de tipos en un compilador.\n",
        "\n",
        "#### Un modelo funcional se puede graficar e inspeccionar\n",
        "\n",
        "Puede representar el modelo como un grafo, y puede acceder fácilmente a los nodos intermedios de este grafo. Por ejemplo, para extraer y reutilizar las activaciones de las capas intermedias (como se vio en un ejemplo anterior):\n",
        "\n",
        "```python\n",
        "features_list = [layer.output for layer in vgg19.layers]\n",
        "feat_extraction_model = keras.Model(inputs=vgg19.input, outputs=features_list)\n",
        "```\n",
        "\n",
        "#### Un modelo funcional puede serializarse o clonarse\n",
        "\n",
        "Debido a que un modelo funcional es una estructura de datos en vez de un fragmento de código, es serializable de forma segura y puede guardarse como un único archivo que le permite recrear exactamente el mismo modelo sin tener acceso a nada del código original. Consulte la [guía de serialización y guardado](https://www.tensorflow.org/guide/keras/save_and_serialize/).\n",
        "\n",
        "Para serializar un modelo de una subclase, es necesario que el implementador especifique un método `get_config()` y `from_config()` a nivel de modelo.\n",
        "\n",
        "### Debilidad funcional de la API:\n",
        "\n",
        "#### No es compatible con arquitecturas dinámicas\n",
        "\n",
        "La API funcional considera los modelos como DAGs de capas. Esto es cierto para la mayoría de las arquitecturas de aprendizaje profundo, pero no para todas; por ejemplo, las redes recursivas o las RNN de árbol no siguen este supuesto y no pueden implementarse en la API funcional."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72992d4ed462"
      },
      "source": [
        "## Mezclar y combinar estilos de la API\n",
        "\n",
        "Elegir entre la API funcional o la subclase Model no es una decisión binaria que te restrinja a una categoría de los modelos. Todos los modelos de la API `tf.keras` API pueden interactuar entre sí, ya sean modelos `Sequential`, modelos funcionales o modelos subclasificados escritos desde cero.\n",
        "\n",
        "Siempre se puede utilizar un modelo funcional o `Sequential` como parte de un modelo o capa subclase:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3c6221508766"
      },
      "outputs": [],
      "source": [
        "units = 32\n",
        "timesteps = 10\n",
        "input_dim = 5\n",
        "\n",
        "# Define a Functional model\n",
        "inputs = keras.Input((None, units))\n",
        "x = layers.GlobalAveragePooling1D()(inputs)\n",
        "outputs = layers.Dense(1)(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "\n",
        "class CustomRNN(layers.Layer):\n",
        "    def __init__(self):\n",
        "        super(CustomRNN, self).__init__()\n",
        "        self.units = units\n",
        "        self.projection_1 = layers.Dense(units=units, activation=\"tanh\")\n",
        "        self.projection_2 = layers.Dense(units=units, activation=\"tanh\")\n",
        "        # Our previously-defined Functional model\n",
        "        self.classifier = model\n",
        "\n",
        "    def call(self, inputs):\n",
        "        outputs = []\n",
        "        state = tf.zeros(shape=(inputs.shape[0], self.units))\n",
        "        for t in range(inputs.shape[1]):\n",
        "            x = inputs[:, t, :]\n",
        "            h = self.projection_1(x)\n",
        "            y = h + self.projection_2(state)\n",
        "            state = y\n",
        "            outputs.append(y)\n",
        "        features = tf.stack(outputs, axis=1)\n",
        "        print(features.shape)\n",
        "        return self.classifier(features)\n",
        "\n",
        "\n",
        "rnn_model = CustomRNN()\n",
        "_ = rnn_model(tf.zeros((1, timesteps, input_dim)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41f42eb2a9c0"
      },
      "source": [
        "Puede utilizar cualquier capa o modelo subclasificado en la API funcional siempre que implemente un método `call` que siga uno de los siguientes patrones:\n",
        "\n",
        "- `call(self, inputs, **kwargs)` -- Donde `inputs` es un tensor o una estructura anidada de tensores (por ejemplo, una lista de tensores), y donde `**kwargs` son argumentos que no son tensores (que no son entradas).\n",
        "- `call(self, inputs, training=None, **kwargs)` -- Donde `training` es un booleano que indica si la capa debe comportarse en modo entrenamiento y en modo inferencia.\n",
        "- `call(self, inputs, mask=None, **kwargs)` -- Donde `mask` es un tensor booleano de máscaras (por ejemplo, es muy útil para RNNs).\n",
        "- `call(self, inputs, training=None, mask=None, **kwargs)` -- Por supuesto, puede tener un comportamiento específico de enmascaramiento y entrenamiento al mismo tiempo.\n",
        "\n",
        "Además, si implementa el método `get_config` en su capa o modelo personalizado, los modelos funcionales que cree seguirán siendo serializables y clonables.\n",
        "\n",
        "A continuación se muestra un ejemplo rápido de una RNN personalizada, escrita desde cero, que se utiliza en un modelo funcional:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3deb90222d05"
      },
      "outputs": [],
      "source": [
        "units = 32\n",
        "timesteps = 10\n",
        "input_dim = 5\n",
        "batch_size = 16\n",
        "\n",
        "\n",
        "class CustomRNN(layers.Layer):\n",
        "    def __init__(self):\n",
        "        super(CustomRNN, self).__init__()\n",
        "        self.units = units\n",
        "        self.projection_1 = layers.Dense(units=units, activation=\"tanh\")\n",
        "        self.projection_2 = layers.Dense(units=units, activation=\"tanh\")\n",
        "        self.classifier = layers.Dense(1)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        outputs = []\n",
        "        state = tf.zeros(shape=(inputs.shape[0], self.units))\n",
        "        for t in range(inputs.shape[1]):\n",
        "            x = inputs[:, t, :]\n",
        "            h = self.projection_1(x)\n",
        "            y = h + self.projection_2(state)\n",
        "            state = y\n",
        "            outputs.append(y)\n",
        "        features = tf.stack(outputs, axis=1)\n",
        "        return self.classifier(features)\n",
        "\n",
        "\n",
        "# Note that you specify a static batch size for the inputs with the `batch_shape`\n",
        "# arg, because the inner computation of `CustomRNN` requires a static batch size\n",
        "# (when you create the `state` zeros tensor).\n",
        "inputs = keras.Input(batch_shape=(batch_size, timesteps, input_dim))\n",
        "x = layers.Conv1D(32, 3)(inputs)\n",
        "outputs = CustomRNN()(x)\n",
        "\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "rnn_model = CustomRNN()\n",
        "_ = rnn_model(tf.zeros((1, 10, 5)))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "functional.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
