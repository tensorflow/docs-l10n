{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bYaCABobL5q"
      },
      "source": [
        "##### Copyright 2018 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "FlUw7tSKbtg4"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xc1srSc51n_4"
      },
      "source": [
        "# Uso del formato SavedModel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nBUqG2rchGH"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td><a target=\"_blank\" href=\"https://www.tensorflow.org/guide/saved_model\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver en TensorFlow.org</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/es-419/guide/saved_model.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Ejecutar en Google Colab</a></td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/es-419/guide/saved_model.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver fuente en GitHub</a>\n",
        "</td>\n",
        "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/es-419/guide/saved_model.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Descargar bloc de notas</a>\n",
        "</td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPE-fshLTsXU"
      },
      "source": [
        "Un SavedModel contiene un programa completo de TensorFlow, que incluye los parámetros entrenados (es decir, las `tf.Variable`) y los cálculos. No requiere del código con el que se creó el modelo original para ejecutarse. Esta virtud hace que resulte útil compartirlo o implementarlo con [TFLite](https://tensorflow.org/lite), [TensorFlow.js](https://js.tensorflow.org/), [TensorFlow Serving](https://www.tensorflow.org/tfx/serving/tutorials/Serving_REST_simple) o [TensorFlow Hub](https://tensorflow.org/hub).\n",
        "\n",
        "Un modelo se puede guardar y cargar en el formato SavedModel con las siguientes API:\n",
        "\n",
        "- La API `tf.saved_model` de bajo nivel. En este documento se describe en detalle cómo usar esta API.\n",
        "    - Guardar: `tf.saved_model.save(model, path_to_dir)`\n",
        "    - Cargar: `model = tf.saved_model.load(path_to_dir)`\n",
        "- API `tf.keras.Model` de alto nivel. Consulte la [guía sobre el guardado y serializado con keras](https://www.tensorflow.org/guide/keras/save_and_serialize).\n",
        "- Si simplemente desea guardar o cargar pesos durante el entrenamiento, consulte la [guía sobre puntos de verificación](./checkpoint.ipynb).\n",
        "\n",
        "Advertencia: Los modelos TensorFlow son código y hay que tener cuidado con que dicho código no sea confiable. Aprenda más en la sección sobre [cómo usar TensorFlow de forma segura](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9SuIC7FiI9g8"
      },
      "source": [
        "## Creación de un SavedModel con Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtSmftAvhJvE"
      },
      "source": [
        "Obsoleto: Para los objetos Keras, se recomienda usar el nuevo formato de alto nivel `.keras` y `tf.keras.Model.export`, como se demuestra en la guía [aquí](https://www.tensorflow.org/guide/keras/save_and_serialize). El formato SavedModel de bajo nivel sigue siendo compatible con el código existente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLSOptpYhJvE"
      },
      "source": [
        "A modo de introducción breve, en esta sección se exporta un modelo keras previamente entrenado y se realizan solicitudes de clasificación con él. En el resto de la guía se completan los detalles y se analizan otras formas de crear SavedModels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Le5OB-fBHHW7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tempfile\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "tmpdir = tempfile.mkdtemp()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wlho4HEWoHUT"
      },
      "outputs": [],
      "source": [
        "physical_devices = tf.config.list_physical_devices('GPU')\n",
        "for device in physical_devices:\n",
        "  tf.config.experimental.set_memory_growth(device, True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SofdPKo0G8Lb"
      },
      "outputs": [],
      "source": [
        "file = tf.keras.utils.get_file(\n",
        "    \"grace_hopper.jpg\",\n",
        "    \"https://storage.googleapis.com/download.tensorflow.org/example_images/grace_hopper.jpg\")\n",
        "img = tf.keras.utils.load_img(file, target_size=[224, 224])\n",
        "plt.imshow(img)\n",
        "plt.axis('off')\n",
        "x = tf.keras.utils.img_to_array(img)\n",
        "x = tf.keras.applications.mobilenet.preprocess_input(\n",
        "    x[tf.newaxis,...])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqVcFL10JkF0"
      },
      "source": [
        "Usaremos una imagen de Grace Hopper como ejemplo y un modelo de clasificación previamente entrenado de Keras, ya que es fácil de usar. Los modelos personalizados también funcionan; hablaremos en detalle sobre ellos más adelante."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JhVecdzJTsKE"
      },
      "outputs": [],
      "source": [
        "labels_path = tf.keras.utils.get_file(\n",
        "    'ImageNetLabels.txt',\n",
        "    'https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt')\n",
        "imagenet_labels = np.array(open(labels_path).read().splitlines())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aEHSYjW6JZHV"
      },
      "outputs": [],
      "source": [
        "pretrained_model = tf.keras.applications.MobileNet()\n",
        "result_before_save = pretrained_model(x)\n",
        "\n",
        "decoded = imagenet_labels[np.argsort(result_before_save)[0,::-1][:5]+1]\n",
        "\n",
        "print(\"Result before saving:\\n\", decoded)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4KIsQDZJ5PS"
      },
      "source": [
        "La principal predicción para esta imagen es el \"uniforme militar\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8nfznDmHCW6F"
      },
      "outputs": [],
      "source": [
        "mobilenet_save_path = os.path.join(tmpdir, \"mobilenet/1/\")\n",
        "tf.saved_model.save(pretrained_model, mobilenet_save_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pyX-ETE3wX63"
      },
      "source": [
        "La ruta de guardado sigue una convención usada por TensorFlow Serving donde el último componente de la ruta (aquí `1/`) es un número de versión para su modelo. Permite usar herramientas como TensorFlow Serving para razonar sobre la frescura relativa.\n",
        "\n",
        "El SavedModel se puede volver a cargar en Python con `tf.saved_model.load` y, entonces, ver cómo se clasifica la imagen de la almirante Hopper."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NP2UpVFRV7N_"
      },
      "outputs": [],
      "source": [
        "loaded = tf.saved_model.load(mobilenet_save_path)\n",
        "print(list(loaded.signatures.keys()))  # [\"serving_default\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5srGzowfWff"
      },
      "source": [
        "Las firmas importadas siempre devuelven diccionarios. Para personalizar los nombres y las claves del diccionario de salida, consulte [Especificación de las firmas durante la exportación](#specifying_signatures_during_export)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ChFLpegYfQGR"
      },
      "outputs": [],
      "source": [
        "infer = loaded.signatures[\"serving_default\"]\n",
        "print(infer.structured_outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJYyZnptfuru"
      },
      "source": [
        "Al ejecutar la inferencia del SavedModel se obtiene el mismo resultado del modelo original."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9WjGEaS3XfX7"
      },
      "outputs": [],
      "source": [
        "labeling = infer(tf.constant(x))[pretrained_model.output_names[0]]\n",
        "\n",
        "decoded = imagenet_labels[np.argsort(labeling)[0,::-1][:5]+1]\n",
        "\n",
        "print(\"Result after saving and loading:\\n\", decoded)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJEkdXjTWbtl"
      },
      "source": [
        "## Ejecución de SavedModel en TensorFlow Serving\n",
        "\n",
        "Los SavedModel se pueden usar desde Python (más adelante se brindan más detalles), pero los entornos de producción normalmente usan un servicio exclusivo para la inferencia sin ejecutar código Python. Se configura con facilidad a partir de un SavedModel con TensorFlow Serving.\n",
        "\n",
        "Para conocer un ejemplo completo de servicio de TensorFlow, consulte [Entrene y sirva un modelo de TensorFlow con TensorFlow Serving](https://www.tensorflow.org/tfx/tutorials/serving/rest_simple)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bi0ILzu1XdWw"
      },
      "source": [
        "## El formato SavedModel en disco\n",
        "\n",
        "Un SavedModel es un directorio que contiene firmas serializadas y el estado necesita ejecutarlas, incluidos los valores de variables y vocabularios.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6u3YZuYZXyTO"
      },
      "outputs": [],
      "source": [
        "!ls {mobilenet_save_path}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ple4X5utX8ue"
      },
      "source": [
        "El archivo `saved_model.pb` almacena el programa de TensorFlow real, o el modelo, y configura un conjunto de firmas con nombre. Con cada una de ellas se identifica una función que acepta las entradas del tensor y produce las salidas de tensor.\n",
        "\n",
        "Los SavedModels pueden contener múltiples variantes del modelo (múltiples `v1.MetaGraphDefs`, identificados con la etiqueta `--tag_set` para `saved_model_cli`), pero no es lo más común. Las API que crean múltiples variantes de un modelo incluyen [`tf.Estimator.experimental_export_all_saved_models`](https://www.tensorflow.org/api_docs/python/tf/estimator/Estimator#experimental_export_all_saved_models) y en TensorFlow, 1.x `tf.saved_model.Builder`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pus0dOYTYXbI"
      },
      "outputs": [],
      "source": [
        "!saved_model_cli show --dir {mobilenet_save_path} --tag_set serve"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eALHpGvRZOhk"
      },
      "source": [
        "El directorio de `variables` contiene un punto de verificación de entrenamiento estándar (consulte la [guía para entrenamiento de puntos de verificación](./checkpoint.ipynb))."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EDYqhDlNZAC2"
      },
      "outputs": [],
      "source": [
        "!ls {mobilenet_save_path}/variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKmaZQpHahGh"
      },
      "source": [
        "El directorio `assets` contiene archivos que usa el grafo de TensorFlow; por ejemplo, los archivos de texto que se usan para inicializar las tablas de vocabulario. No se usa en este ejemplo.\n",
        "\n",
        "SavedModels puede tener un directorio `assets.extra` para cualquier archivo que no use el grafo de TensorFlow. Por ejemplo, la información para consumidores sobre qué hacer con el SavedModel. TensorFlow mismo no usa este directorio.\n",
        "\n",
        "El archivo `fingerprint.pb` contiene la [huella digital](https://en.wikipedia.org/wiki/Fingerprint_(computing)) de un SavedModel, que está compuesta de varias funciones <em>hash</em> de 64 bits que identifican de forma única el contenido del SavedModel. La API de huella, por el momento, es experimental, pero `tf.saved_model.experimental.read_fingerprint` se puede usar para leer la huella digital de SavedModel en un objeto `tf.saved_model.experimental.Fingerprint`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIceoF_CYmaF"
      },
      "source": [
        "## Guardado de un modelo personalizado\n",
        "\n",
        "`tf.saved_model.save` permite guardar objetos `tf.Module` y sus subclases, como `tf.keras.Layer` y `tf.keras.Model`.\n",
        "\n",
        "Observemos un ejemplo en el que se muestra cómo guardar y restaurar un `tf.Module`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6EPvKiqXMm3d"
      },
      "outputs": [],
      "source": [
        "class CustomModule(tf.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(CustomModule, self).__init__()\n",
        "    self.v = tf.Variable(1.)\n",
        "\n",
        "  @tf.function\n",
        "  def __call__(self, x):\n",
        "    print('Tracing with', x)\n",
        "    return x * self.v\n",
        "\n",
        "  @tf.function(input_signature=[tf.TensorSpec([], tf.float32)])\n",
        "  def mutate(self, new_v):\n",
        "    self.v.assign(new_v)\n",
        "\n",
        "module = CustomModule()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4FcP-Co3Fnw"
      },
      "source": [
        "Cuando guarda un tf.Module, también se guarda cualquier atributo tf.Variable o método decorado por tf.function y tf.Modules que se hallen a través de recorridos recursivos. (Para más información sobre los recorridos recursivos, consulte el tutorial sobre [ puntos de verificación](./checkpoint.ipynb)). Sin embargo, se pierden cualquiera de las funciones, los datos y los atributos Python. Significa que cuando se guarda una `tf.function`, no se guarda ningún código de Python.\n",
        "\n",
        "Si no se guarda ningún código Python, ¿cómo sabe el SavedModel qué tiene que hacer para restaurar la función?\n",
        "\n",
        "En resumen, `tf.function` funciona rastreando el código Python para generar una función concreta (<em>ConcreteFunction</em>) (un encrustamiento invocable en torno a `tf.Graph`). Al guardar la `tf.function`, en realidad, se guarda el caché de la `tf.function` de las funciones concretas.\n",
        "\n",
        "Para más información sobre la relación entre `tf.function` y las funciones concretas, consulte la [guía sobre tf.function](function.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "85PUO9iWH7xn"
      },
      "outputs": [],
      "source": [
        "module_no_signatures_path = os.path.join(tmpdir, 'module_no_signatures')\n",
        "module(tf.constant(0.))\n",
        "print('Saving model...')\n",
        "tf.saved_model.save(module, module_no_signatures_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ujwmMQg7OUo"
      },
      "source": [
        "## Carga y uso de un modelo personalizado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpxQy5Eb77qJ"
      },
      "source": [
        "Cuando carga un SavedModel en Python, todos los atributos de `tf.Variable`, los métodos decorados por `tf.function` y los `tf.Module` se restauran con la misma estructura de objeto del `tf.Module`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EMASjADPxPso"
      },
      "outputs": [],
      "source": [
        "imported = tf.saved_model.load(module_no_signatures_path)\n",
        "assert imported(tf.constant(3.)).numpy() == 3\n",
        "imported.mutate(tf.constant(2.))\n",
        "assert imported(tf.constant(3.)).numpy() == 6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDiauvb_99uk"
      },
      "source": [
        "Como no se guarda ningún código Python, si se invoca una `tf.function` con una firma de entrada nueva, fallará:\n",
        "\n",
        "```python\n",
        "imported(tf.constant([3.]))\n",
        "```\n",
        "\n",
        "<pre>ValueError: Could not find matching function to call for canonicalized inputs ((&lt;tf.Tensor 'args_0:0' shape=(1,) dtype=float32&gt;,), {}). Only existing signatures are [((TensorSpec(shape=(), dtype=tf.float32, name=u'x'),), {})].\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Vsva3UZ-2sf"
      },
      "source": [
        "### Ajuste fino básico\n",
        "\n",
        "Hay objetos variables disponibles y es posible propagar hacia atrás (<em>backprop</em>) mediante funciones importadas. Esto es suficiente como para aplicar el ajuste fino (es decir, como para retener) un SavedModel en casos simples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PEkQNarJ-7nT"
      },
      "outputs": [],
      "source": [
        "optimizer = tf.keras.optimizers.SGD(0.05)\n",
        "\n",
        "def train_step():\n",
        "  with tf.GradientTape() as tape:\n",
        "    loss = (10. - imported(tf.constant(2.))) ** 2\n",
        "  variables = tape.watched_variables()\n",
        "  grads = tape.gradient(loss, variables)\n",
        "  optimizer.apply_gradients(zip(grads, variables))\n",
        "  return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p41NM6fF---3"
      },
      "outputs": [],
      "source": [
        "for _ in range(10):\n",
        "  # \"v\" approaches 5, \"loss\" approaches 0\n",
        "  print(\"loss={:.2f} v={:.2f}\".format(train_step(), imported.v.numpy()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuXtkHSD_KSW"
      },
      "source": [
        "### Ajuste fino general\n",
        "\n",
        "Un SavedModel de Keras aporta [más detalles](https://github.com/tensorflow/community/blob/master/rfcs/20190509-keras-saved-model.md#serialization-details) que una `__call__` simple para abordar casos más avanzados de ajuste fino. TensorFlow Hub recomienda proporcionar, en caso de ser posible, lo siguiente en los SavedModels compartidos para ajuste fino:\n",
        "\n",
        "- Si el modelo usa la técnica de abandono (<em>dropout</em>) u alguna otra en que el pase hacia adelante difiere entre entrenamiento e inferencia (como la normalización por lotes), el método `__call__` toma un argumento opcional de `training=` valuado por Python, que por defecto es `False` pero que se puede establecer como `True`.\n",
        "- Junto al atributo `__call__`, hay atributos `.variable` y `.trainable_variable` con las correspondientes listas de variables. De `.trainable_variables` se omite una variable que originalmente era entrenable, pero que esta prevista para quedar congelada durante el ajuste fino.\n",
        "- Para satisfacer los esquemas como Keras que representan regularizadores de peso, como atributos de capas o submodelos; también puede haber un atributo `.regularization_losses`. Este contiene una lista de las funciones de argumento cero cuyos valores fueron previstos para sumarlos a la pérdida total.\n",
        "\n",
        "Si volvemos al ejemplo original de MobileNet, veremos a algunos en acción:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y6EUFdY8_PRD"
      },
      "outputs": [],
      "source": [
        "loaded = tf.saved_model.load(mobilenet_save_path)\n",
        "print(\"MobileNet has {} trainable variables: {}, ...\".format(\n",
        "          len(loaded.trainable_variables),\n",
        "          \", \".join([v.name for v in loaded.trainable_variables[:5]])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B-mQJ8iP_R0h"
      },
      "outputs": [],
      "source": [
        "trainable_variable_ids = {id(v) for v in loaded.trainable_variables}\n",
        "non_trainable_variables = [v for v in loaded.variables\n",
        "                           if id(v) not in trainable_variable_ids]\n",
        "print(\"MobileNet also has {} non-trainable variables: {}, ...\".format(\n",
        "          len(non_trainable_variables),\n",
        "          \", \".join([v.name for v in non_trainable_variables[:3]])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGlHlbd3_eyO"
      },
      "source": [
        "## Especificación de firmas durante la exportación\n",
        "\n",
        "Las herramientas como TensorFlow Serving y `saved_model_cli` pueden interactuar con SavedModels. Para ayudar a esas herramientas a determinar qué funciones concretas usar, se deberán especificar las firmas de servicio (<em>serving</em>). Los `tf.keras.Model` especifican automáticamente las firmas de servicio, pero habrá que declarar explícitamente una firma de servicio para los módulos personalizados.\n",
        "\n",
        "IMPORTANTE: A menos que necesite exportar su modelo a un entorno diferente de TensorFlow 2.x con Python, es probable que no haga falta exportar explícitamente las firmas. Si lo que busca es una forma de forzar una firma de entrada para una función específica, analice el argumento [`input_signature`](https://www.tensorflow.org/api_docs/python/tf/function#args_1) para `tf.function`.\n",
        "\n",
        "Por defecto, en un `tf.Module` personalizado no se declaran las firmas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h-IB5Xa0NxLa"
      },
      "outputs": [],
      "source": [
        "assert len(imported.signatures) == 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BiNtaMZSI8Tb"
      },
      "source": [
        "Para declarar una firma de servicio, especifique una función concreta con los <em>kwarg</em> de las `signatures`. Cuando especifique una firma sola, la clave de esa firma será '`'serving_default'`', que se guarda como la constante de `tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_pAdgIORR2yH"
      },
      "outputs": [],
      "source": [
        "module_with_signature_path = os.path.join(tmpdir, 'module_with_signature')\n",
        "call = module.__call__.get_concrete_function(tf.TensorSpec(None, tf.float32))\n",
        "tf.saved_model.save(module, module_with_signature_path, signatures=call)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nAzRHR0UT4hv"
      },
      "outputs": [],
      "source": [
        "imported_with_signatures = tf.saved_model.load(module_with_signature_path)\n",
        "list(imported_with_signatures.signatures.keys())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_gH91j1IR4tq"
      },
      "source": [
        "Para exportar múltiples firmas, pase un diccionario de claves de firmas a funciones concretas. Cada clave de firma corresponde a una función concreta."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6VYAiQmLUiox"
      },
      "outputs": [],
      "source": [
        "module_multiple_signatures_path = os.path.join(tmpdir, 'module_with_multiple_signatures')\n",
        "signatures = {\"serving_default\": call,\n",
        "              \"array_input\": module.__call__.get_concrete_function(tf.TensorSpec([None], tf.float32))}\n",
        "\n",
        "tf.saved_model.save(module, module_multiple_signatures_path, signatures=signatures)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8IPx_0RWEx07"
      },
      "outputs": [],
      "source": [
        "imported_with_multiple_signatures = tf.saved_model.load(module_multiple_signatures_path)\n",
        "list(imported_with_multiple_signatures.signatures.keys())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43_Qv2W_DJZZ"
      },
      "source": [
        "Por defecto, los nombres del tensor de salida son bastante genéricos, como `output_0`. Para controlar los nombres de las salidas, modifique la `tf.function` para devolver un diccionario que mapee los nombres de las salidas con las salidas mismas. Los nombres de las entradas derivan de los nombres de los argumentos de las funciones de Python."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ACKPl1X8G1gw"
      },
      "outputs": [],
      "source": [
        "class CustomModuleWithOutputName(tf.Module):\n",
        "  def __init__(self):\n",
        "    super(CustomModuleWithOutputName, self).__init__()\n",
        "    self.v = tf.Variable(1.)\n",
        "\n",
        "  @tf.function(input_signature=[tf.TensorSpec(None, tf.float32)])\n",
        "  def __call__(self, x):\n",
        "    return {'custom_output_name': x * self.v}\n",
        "\n",
        "module_output = CustomModuleWithOutputName()\n",
        "call_output = module_output.__call__.get_concrete_function(tf.TensorSpec(None, tf.float32))\n",
        "module_output_path = os.path.join(tmpdir, 'module_with_output_name')\n",
        "tf.saved_model.save(module_output, module_output_path,\n",
        "                    signatures={'serving_default': call_output})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1yGVy4MuH-V0"
      },
      "outputs": [],
      "source": [
        "imported_with_output_name = tf.saved_model.load(module_output_path)\n",
        "imported_with_output_name.signatures['serving_default'].structured_outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4bCK55x1IBW"
      },
      "source": [
        "## División de protoclase\n",
        "\n",
        "Nota: esta función será parte del lanzamiento de TensorFlow 2.15. En este momento, está disponible en la versión \"nocturna\", que se puede instalar con `pip install tf-nightly`.\n",
        "\n",
        "Debido a los límites de la implementación del <em>protobuf</em> (búfer de protocolo), los tamaños de las protoclases no deben exceder los 2GB. De lo contrario puede causar los siguientes errores cuando intente guardar modelos muy grandes:\n",
        "\n",
        "```\n",
        "ValueError: Message tensorflow.SavedModel exceeds maximum protobuf size of 2GB: ...\n",
        "```\n",
        "\n",
        "```\n",
        "google.protobuf.message.DecodeError: Error parsing message as the message exceeded the protobuf limit with type 'tensorflow.GraphDef'\n",
        "```\n",
        "\n",
        "Si desea guardar modelos que excedan el límite de 2GB, deberá guardarlos con una nueva opción de división de protoclase:\n",
        "\n",
        "```python\n",
        "tf.saved_model.save(\n",
        "  ...,\n",
        "  options=tf.saved_model.SaveOptions(experimental_image_format=True)\n",
        ")\n",
        "```\n",
        "\n",
        "Acceda a más información en la [guía sobre divisor de protoclase / biblioteca de fusión](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/proto_splitter/in-depth-guide.md)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Co6fDbzw_UnD"
      },
      "source": [
        "## Carga de un SavedModel en C++\n",
        "\n",
        "La versión C++ del [cargador](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/cc/saved_model/loader.h) de SavedModel proporciona una API para cargar un SavedModel con una ruta y, a la vez, admite SessionOptions y RunOptions. Hay que especificar las etiquetas asociadas con el grafo que se cargará. A la versión cargada de SavedModel se la conoce como SavedModelBundle y contiene el MetaGraphDef y la sesión dentro de la que se carga.\n",
        "\n",
        "```C++\n",
        "const string export_dir = ...\n",
        "SavedModelBundle bundle;\n",
        "...\n",
        "LoadSavedModel(session_options, run_options, export_dir, {kSavedModelTagTrain},\n",
        "               &bundle);\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b33KuyEuAO3Z"
      },
      "source": [
        "<a id=\"saved_model_cli\"></a>\n",
        "\n",
        "## Detalles de la interfaz de línea de comandos de SavedModel\n",
        "\n",
        "La interfaz de línea de comandos (CLI) de SavedModel se puede usar para inspeccionar y ejecutar un SavedModel. Por ejemplo, puede usar una interfaz de línea de comandos para inspeccionar las `SignatureDef` del modelo. La interfaz de línea de comandos le permitirá confirmar rápidamente el tensor de tipo d de entrada y la coincidencia de la forma del modelo. Además, si desea probar el modelo, puede usar la interfaz de línea de comandos para hacer una prueba de cordura (<em>sanity check</em>) mediante el pase de entradas en varios formatos (por ejemplo, en expresiones Python) y después una extracción de la salida.\n",
        "\n",
        "### Instalación de la interfaz de línea de comandos de SavedModel\n",
        "\n",
        "En términos generales, TensorFlow se puede instalar de alguna de las siguientes dos maneras:\n",
        "\n",
        "- Mediante la instalación de un TensorFlow binario preconfigurado.\n",
        "- Mediante la creación de TensorFlow a partir de código fuente.\n",
        "\n",
        "Si instaló TensorFlow con TensorFlow binario preconfigurado, entonces, la interfaz de línea de comandos del SavedModel ya está instalada en su sistema, en `bin/saved_model_cli`.\n",
        "\n",
        "Si creó TensorFlow con código fuente, debe ejecutar el siguiente comando adicional para crear `saved_model_cli`:\n",
        "\n",
        "```\n",
        "$ bazel build //tensorflow/python/tools:saved_model_cli\n",
        "```\n",
        "\n",
        "### Descripción general de los comandos\n",
        "\n",
        "La interfaz de línea de comandos de SavedModel admite los siguientes dos comandos en un SavedModel:\n",
        "\n",
        "- `show`, que muestra los cálculos disponibles para SavedModel.\n",
        "- `run`, que ejecuta un cálculo de un SavedModel.\n",
        "\n",
        "### Comando `show`\n",
        "\n",
        "Un SavedModel contiene una o más variantes del modelo (técnicamente, son `v1.MetaGraphDef`), identificadas por sus conjuntos de etiquetas. Se preguntará cuál es el tipo de `SignatureDef` de cada variante del modelo y cuáles son sus entradas y salidas, para servir al modelo. El comando `show` permite examinar el contenido de SavedModel en orden jerárquico. A continuación, la sintaxis:\n",
        "\n",
        "```\n",
        "usage: saved_model_cli show [-h] --dir DIR [--all]\n",
        "[--tag_set TAG_SET] [--signature_def SIGNATURE_DEF_KEY]\n",
        "```\n",
        "\n",
        "Por ejemplo, el siguiente comando muestra todos los conjuntos de etiquetas disponibles en el SavedModel:\n",
        "\n",
        "```\n",
        "$ saved_model_cli show --dir /tmp/saved_model_dir\n",
        "The given SavedModel contains the following tag-sets:\n",
        "serve\n",
        "serve, gpu\n",
        "```\n",
        "\n",
        "El siguiente comando muestra todas las claves de `SignatureDef` disponibles para un conjunto de etiquetas:\n",
        "\n",
        "```\n",
        "$ saved_model_cli show --dir /tmp/saved_model_dir --tag_set serve\n",
        "The given SavedModel `MetaGraphDef` contains `SignatureDefs` with the\n",
        "following keys:\n",
        "SignatureDef key: \"classify_x2_to_y3\"\n",
        "SignatureDef key: \"classify_x_to_y\"\n",
        "SignatureDef key: \"regress_x2_to_y3\"\n",
        "SignatureDef key: \"regress_x_to_y\"\n",
        "SignatureDef key: \"regress_x_to_y2\"\n",
        "SignatureDef key: \"serving_default\"\n",
        "```\n",
        "\n",
        "Si hay *múltiples* etiquetas en el conjunto de etiquetas, deberá especificarlas a todas, cada una por separado con una coma. Por ejemplo:\n",
        "\n",
        "<pre>$ saved_model_cli show --dir /tmp/saved_model_dir --tag_set serve,gpu\n",
        "</pre>\n",
        "\n",
        "Para mostrar todas las entradas y salidas de TensorInfo para una `SignatureDef` específica, pase la clave de `SignatureDef` a la opción `signature_def`. Esta acción resulta muy útil cuando lo que se desea es conocer el valor de la clave del tensor, el tipo d y la forma de los tensores de entrada para ejecutar más adelante los grafos de cálculo. Por ejemplo:\n",
        "\n",
        "```\n",
        "$ saved_model_cli show --dir \\\n",
        "/tmp/saved_model_dir --tag_set serve --signature_def serving_default\n",
        "The given SavedModel SignatureDef contains the following input(s):\n",
        "  inputs['x'] tensor_info:\n",
        "      dtype: DT_FLOAT\n",
        "      shape: (-1, 1)\n",
        "      name: x:0\n",
        "The given SavedModel SignatureDef contains the following output(s):\n",
        "  outputs['y'] tensor_info:\n",
        "      dtype: DT_FLOAT\n",
        "      shape: (-1, 1)\n",
        "      name: y:0\n",
        "Method name is: tensorflow/serving/predict\n",
        "```\n",
        "\n",
        "Para mostrar toda la información disponible en el SavedModel, use la opción `--all`. Por ejemplo:\n",
        "\n",
        "<pre>$ saved_model_cli show --dir /tmp/saved_model_dir --all\n",
        "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n",
        "\n",
        "signature_def['classify_x2_to_y3']:\n",
        "  The given SavedModel SignatureDef contains the following input(s):\n",
        "    inputs['inputs'] tensor_info:\n",
        "        dtype: DT_FLOAT\n",
        "        shape: (-1, 1)\n",
        "        name: x2:0\n",
        "  The given SavedModel SignatureDef contains the following output(s):\n",
        "    outputs['scores'] tensor_info:\n",
        "        dtype: DT_FLOAT\n",
        "        shape: (-1, 1)\n",
        "        name: y3:0\n",
        "  Method name is: tensorflow/serving/classify\n",
        "\n",
        "...\n",
        "\n",
        "signature_def['serving_default']:\n",
        "  The given SavedModel SignatureDef contains the following input(s):\n",
        "    inputs['x'] tensor_info:\n",
        "        dtype: DT_FLOAT\n",
        "        shape: (-1, 1)\n",
        "        name: x:0\n",
        "  The given SavedModel SignatureDef contains the following output(s):\n",
        "    outputs['y'] tensor_info:\n",
        "        dtype: DT_FLOAT\n",
        "        shape: (-1, 1)\n",
        "        name: y:0\n",
        "  Method name is: tensorflow/serving/predict\n",
        "</pre>\n",
        "\n",
        "### Comando `run`\n",
        "\n",
        "Invoque el comando `run` para ejecutar el cálculo de un grafo, el paso de entradas y para después, mostrar (y, opcionalmente, guardar) las salidas. A continuación, la sintaxis:\n",
        "\n",
        "```\n",
        "usage: saved_model_cli run [-h] --dir DIR --tag_set TAG_SET --signature_def\n",
        "                           SIGNATURE_DEF_KEY [--inputs INPUTS]\n",
        "                           [--input_exprs INPUT_EXPRS]\n",
        "                           [--input_examples INPUT_EXAMPLES] [--outdir OUTDIR]\n",
        "                           [--overwrite] [--tf_debug]\n",
        "```\n",
        "\n",
        "El comando `run` ofrece las siguientes tres formas de pasar entradas al modelo:\n",
        "\n",
        "- La opción de `--inputs` le permitirá pasar <em>ndarray de numpy</em> en archivos.\n",
        "- La opción `--input_exprs` le permitirá pasar las expresiones de Python.\n",
        "- La opción `--input_examples` le permitirá pasar `tf.train.Example`.\n",
        "\n",
        "#### `--inputs`\n",
        "\n",
        "Para pasar archivos de datos de entrada, especifique la opción `--inputs`, que toma el siguiente formato general:\n",
        "\n",
        "```bsh\n",
        "--inputs <INPUTS>\n",
        "```\n",
        "\n",
        "donde *INPUTS* (entradas) tiene alguno de los siguientes formatos:\n",
        "\n",
        "- `<input_key>=<filename>`\n",
        "- `<input_key>=<filename>[<variable_name>]`\n",
        "\n",
        "Se pueden pasar múltiples *INPUTS*. Si lo hace, use un punto y coma para separarlos.\n",
        "\n",
        "`saved_model_cli` usa `numpy.load` para cargar el *nombre de archivo*. El *nombre de archivo* se puede encontrar en cualquiera de los siguientes formatos:\n",
        "\n",
        "- `.npy`\n",
        "- `.npz`\n",
        "- formato <em>pickle</em>\n",
        "\n",
        "Un archivo `.npy` siempre contiene un ndarray (arrglo nd) de numpy. Por lo tanto, cuando se carga un archivo `.npy`, el contenido se asignará directamente al tensor de entrada especificado. Si especifica un *variable_name* con ese archivo `.npy`, el *variable_name* se ignorará y se emitirá una advertencia.\n",
        "\n",
        "Cuando haga una carga de un archivo `.npz` (zip), tendrá la opción de especificar un *variable_name* (nombre de variable) para identificar la variable dentro del archivo zip para cargar la clave del tensor de entrada. Si no especifica el *variable_name*, la interfaz de línea de comandos de SavedModel solamente controlará que el zip contenga un solo archivo y lo cargará para la clave del tensor de entrada especificado.\n",
        "\n",
        "Cuando cargue de un archivo <em>pickle</em>, si no se especifica ningún `variable_name` entre los corchetes rectos, lo que esté dentro del archivo <em>pickle</em> pasará a la clave del tensor de entrada especificado. De lo contrario la interfaz de línea de comandos de SavedModel supondrá que se almacena un diccionario en el archivo <em>pickle</em> y que se usará el valor correspondiente al *variable_name*.\n",
        "\n",
        "#### `--input_exprs`\n",
        "\n",
        "Para pasar entradas a través de expresiones Python, especifique la opción `--input_exprs`. Esto puede resultar útil para cuando no se tienen archivos de datos cerca, pero aún se desea hacer el <em>sanity check</em> del modelo con algunas entradas simples que coincidan con el tipo d y la forma de las `SignatureDef` del modelo. Por ejemplo:\n",
        "\n",
        "```bsh\n",
        "`<input_key>=[[1],[2],[3]]`\n",
        "```\n",
        "\n",
        "Además de expresiones de Python, también podría pasar funciones numpy. Por ejemplo:\n",
        "\n",
        "```bsh\n",
        "`<input_key>=np.ones((32,32,3))`\n",
        "```\n",
        "\n",
        "(Tenga en cuenta que el módulo `numpy` ya está disponible como `np`.)\n",
        "\n",
        "#### `--input_examples`\n",
        "\n",
        "Para pasar `tf.train.Example` como entradas, especifique la opción `--input_examples`. Para cada clave de entrada, toma una lista de diccionario, donde cada diccionario es una instancia de `tf.train.Example`. Las claves de diccionario son las características, y los valores son las listas de valores de cada característica. Por ejemplo:\n",
        "\n",
        "```bsh\n",
        "`<input_key>=[{\"age\":[22,24],\"education\":[\"BS\",\"MS\"]}]`\n",
        "```\n",
        "\n",
        "#### Guardado de salidas\n",
        "\n",
        "Por defecto, la interfaz de línea de comandos de SavedModel escribe salidas a <em>stdout</em>. Si un directorio se pasa a la opción `--outdir`, las salidas se guardarán como archivos `.npy` con los nombres de las claves del tensor de salida del mismo directorio.\n",
        "\n",
        "Use `--overwrite` para sobrescribir los archivos de salida existentes.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "saved_model.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
