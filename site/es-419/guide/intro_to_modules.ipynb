{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISubpr_SSsiM"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow Authors.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "3jTMb1dySr3V"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6DWfyNThSziV"
      },
      "source": [
        "# Introducción a módulos, capas y modelos\n",
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td><a target=\"_blank\" href=\"https://www.tensorflow.org/guide/intro_to_modules\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver en TensorFlow.org</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/es-419/guide/intro_to_modules.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Ejecutar en Google Colab</a></td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/es-419/guide/intro_to_modules.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver código fuente en GitHub</a>\n",
        "</td>\n",
        "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/es-419/guide/intro_to_modules.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Descargar el bloc de notas</a>\n",
        "</td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0DdlfacAdTZ"
      },
      "source": [
        "Para usar TensorFlow para aprendizaje automático, es probable que deba definir, guardar y restaurar un modelo.\n",
        "\n",
        "Un modelo es, de forma abstracta:\n",
        "\n",
        "- Una función que calcula algo con tensores (un **siguiente paso**)\n",
        "- Algunas variables que pueden actualizarse según el entrenamiento.\n",
        "\n",
        "En esta guía, aprenderá sobre Keras en profundidad para ver cómo se definen los modelos de TensorFlow. Veremos cómo TensorFlow recopila variables y modelos, y también cómo se guardan y restauran.\n",
        "\n",
        "Nota: Si quiere empezar con Keras directamente, consulte [la colección de guías de Keras](./keras/).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VSa6ayJmfZxZ"
      },
      "source": [
        "## Preparación"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "goZwOXp_xyQj"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from datetime import datetime\n",
        "\n",
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yt5HEbsYAbw1"
      },
      "source": [
        "## Módulos de TensorFlow\n",
        "\n",
        "La mayoría de los modelos tienen capas. Las capas son funciones con una estructura matemática que puede reutilizarse y tiene variables entrenables. En TensorFlow, las implementaciones de nivel superior de capas y modelos, como Keras o [Sonnet](https://github.com/deepmind/sonnet), están construidas en la misma clase fundacional: `tf.Module`.\n",
        "\n",
        "### Construir módulos\n",
        "\n",
        "Aquí tiene un ejemplo de un `tf.Module` muy simple que opera en un tensor escalar:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "alhYPVEtAiSy"
      },
      "outputs": [],
      "source": [
        "class SimpleModule(tf.Module):\n",
        "  def __init__(self, name=None):\n",
        "    super().__init__(name=name)\n",
        "    self.a_variable = tf.Variable(5.0, name=\"train_me\")\n",
        "    self.non_trainable_variable = tf.Variable(5.0, trainable=False, name=\"do_not_train_me\")\n",
        "  def __call__(self, x):\n",
        "    return self.a_variable * x + self.non_trainable_variable\n",
        "\n",
        "simple_module = SimpleModule(name=\"simple\")\n",
        "\n",
        "simple_module(tf.constant(5.0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwMc_zu5Ant8"
      },
      "source": [
        "Los módulos y, por extensión, las capas son terminología de aprendizaje automático para \"objetos\": tienen un estado interno y métodos que usan ese estado.\n",
        "\n",
        "Los `__call__` no tienen nada en especial, excepto comportarse como un [invocable de Python](https://stackoverflow.com/questions/111234/what-is-a-callable); puede llamar sus modelos con cualquier función.\n",
        "\n",
        "Puede activar o desactivar la entrenabilidad de las variables por cualquier motivo, incluso puede congelar capas y variables durante los ajustes.\n",
        "\n",
        "Nota: `tf.Module` es la clase base de `tf.keras.layers.Layer` y `tf.keras.Model`, por eso todo lo que se menciona aquí aplica a Keras. Por motivos de compatibilidad histórica, las capas de Keras no recopilan variables de los módulos, así que sus modelos deberían usar solo módulos o solo capas de Keras. Sin embargo, los métodos que se muestran a continuación para inspeccionar variables son los mismos en cualquiera de los casos.\n",
        "\n",
        "Al subclasificar `tf.Module`, cualquier instancia de `tf.Variable` o `tf.Module` que se asigne a las propiedades de este objeto se recopilan automáticamente. Esto le permite ahorrar y cargar variables, así como también crear colecciones de `tf.Module`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CyzYy4A_CbVf"
      },
      "outputs": [],
      "source": [
        "# All trainable variables\n",
        "print(\"trainable variables:\", simple_module.trainable_variables)\n",
        "# Every variable\n",
        "print(\"all variables:\", simple_module.variables)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nuSFrRUNCaaW"
      },
      "source": [
        "Este es un ejemplo de un modelo líneal de dos capas hecho de módulos.\n",
        "\n",
        "Primero una capa densa (lineal):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Efb2p2bzAn-V"
      },
      "outputs": [],
      "source": [
        "class Dense(tf.Module):\n",
        "  def __init__(self, in_features, out_features, name=None):\n",
        "    super().__init__(name=name)\n",
        "    self.w = tf.Variable(\n",
        "      tf.random.normal([in_features, out_features]), name='w')\n",
        "    self.b = tf.Variable(tf.zeros([out_features]), name='b')\n",
        "  def __call__(self, x):\n",
        "    y = tf.matmul(x, self.w) + self.b\n",
        "    return tf.nn.relu(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAhMuC-UpnhX"
      },
      "source": [
        "Y luego se completa el modelo, que hace instancias de dos capas y las aplica:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QQ7qQf-DFw74"
      },
      "outputs": [],
      "source": [
        "class SequentialModule(tf.Module):\n",
        "  def __init__(self, name=None):\n",
        "    super().__init__(name=name)\n",
        "\n",
        "    self.dense_1 = Dense(in_features=3, out_features=3)\n",
        "    self.dense_2 = Dense(in_features=3, out_features=2)\n",
        "\n",
        "  def __call__(self, x):\n",
        "    x = self.dense_1(x)\n",
        "    return self.dense_2(x)\n",
        "\n",
        "# You have made a model!\n",
        "my_model = SequentialModule(name=\"the_model\")\n",
        "\n",
        "# Call it, with random results\n",
        "print(\"Model results:\", my_model(tf.constant([[2.0, 2.0, 2.0]])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1oUzasJHHXf"
      },
      "source": [
        "Las instancias `tf.Module` recopilarán automáticamente, de forma recursiva, cualquier instancia de `tf.Variable` o `tf.Module` asignada. Esto le permite gestionar las colecciones de los `tf.Module` con una instancia de modelo simple y guardar y cargar modelos completos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JLFA5_PEGb6C"
      },
      "outputs": [],
      "source": [
        "print(\"Submodules:\", my_model.submodules)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6lzoB8pcRN12"
      },
      "outputs": [],
      "source": [
        "for var in my_model.variables:\n",
        "  print(var, \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hoaxL3zzm0vK"
      },
      "source": [
        "### Esperar para crear variables\n",
        "\n",
        "Tal vez se dió cuenta que aquí se deben definir los tamaños de entrada y de salida en la capa. Esto es para que la variable `w` tenga una forma reconocida y que pueda ser asignada.\n",
        "\n",
        "Al aplazar la creación de la variable a la primera vez, se llama al módulo con una forma de entrada específica, no hace falta especificar el tamaño de la entrada desde el principio."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XsGCLFXlnPum"
      },
      "outputs": [],
      "source": [
        "class FlexibleDenseModule(tf.Module):\n",
        "  # Note: No need for `in_features`\n",
        "  def __init__(self, out_features, name=None):\n",
        "    super().__init__(name=name)\n",
        "    self.is_built = False\n",
        "    self.out_features = out_features\n",
        "\n",
        "  def __call__(self, x):\n",
        "    # Create variables on first call.\n",
        "    if not self.is_built:\n",
        "      self.w = tf.Variable(\n",
        "        tf.random.normal([x.shape[-1], self.out_features]), name='w')\n",
        "      self.b = tf.Variable(tf.zeros([self.out_features]), name='b')\n",
        "      self.is_built = True\n",
        "\n",
        "    y = tf.matmul(x, self.w) + self.b\n",
        "    return tf.nn.relu(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8bjOWax9LOkP"
      },
      "outputs": [],
      "source": [
        "# Used in a module\n",
        "class MySequentialModule(tf.Module):\n",
        "  def __init__(self, name=None):\n",
        "    super().__init__(name=name)\n",
        "\n",
        "    self.dense_1 = FlexibleDenseModule(out_features=3)\n",
        "    self.dense_2 = FlexibleDenseModule(out_features=2)\n",
        "\n",
        "  def __call__(self, x):\n",
        "    x = self.dense_1(x)\n",
        "    return self.dense_2(x)\n",
        "\n",
        "my_model = MySequentialModule(name=\"the_model\")\n",
        "print(\"Model results:\", my_model(tf.constant([[2.0, 2.0, 2.0]])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49JfbhVrpOLH"
      },
      "source": [
        "Esta flexibilidad es lo que hace que las capas de TensorFlow solo necesitan que se especifique la forma de sus salidas, así como en `tf.keras.layers.Dense`, en vez de tener que definir el tamaño de entrada y de salida."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOLVVBT8J_dl"
      },
      "source": [
        "### Guardar pesos\n",
        "\n",
        "Puede guardar un `tf.Module` de las dos formas, como [punto de verificación](./checkpoint.ipynb) y como [SavedModel](./saved_model.ipynb).\n",
        "\n",
        "Los puntos de verificación son los pesos (es decir, los valores del conjunto de variables en el módulo y sus submódulos):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pHXKRDk7OLHA"
      },
      "outputs": [],
      "source": [
        "chkp_path = \"my_checkpoint\"\n",
        "checkpoint = tf.train.Checkpoint(model=my_model)\n",
        "checkpoint.write(chkp_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXOPMBR4T4ZR"
      },
      "source": [
        "Los puntos de verificación consisten en dos tipos de archivos: los datos en sí y un archivo de índice para los metadatos. El archivo de índice hace el seguimiento de lo que se guarda en realidad y enumera los puntos de verificación Los datos del punto de verificación contienen los valores de la variable y sus rutas de acceso de búsqueda de atributo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jBV3fprlTWqJ"
      },
      "outputs": [],
      "source": [
        "!ls my_checkpoint*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CowCuBTvXgUu"
      },
      "source": [
        "Puede revisar el punto de verificación para asegurarse de que se guarde toda la colección de variables, ordenadas según el objeto de Python que las contiene."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o2QAdfpvS8tB"
      },
      "outputs": [],
      "source": [
        "tf.train.list_variables(chkp_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4eGaNiQWcK4j"
      },
      "source": [
        "Durante el entrenamiento distribuido (de varios modelos) pueden particionarse, es por eso que se enumeran (e.g., '00000-oe-00001'). Pero en este caso, solo hay una partición.\n",
        "\n",
        "Cuando vuelve a cargar modelos, se sobrescriben los valores en su objeto de Python."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UV8rdDzcwVVg"
      },
      "outputs": [],
      "source": [
        "new_model = MySequentialModule()\n",
        "new_checkpoint = tf.train.Checkpoint(model=new_model)\n",
        "new_checkpoint.restore(\"my_checkpoint\")\n",
        "\n",
        "# Should be the same result as above\n",
        "new_model(tf.constant([[2.0, 2.0, 2.0]]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnPwDRwamdfq"
      },
      "source": [
        "Nota: Ya que los puntos de verificación son el centro de los flujos de entrenamiento largos, `tf.checkpoint.CheckpointManager` es una clase de ayuda que hace que sea más fácil gestionar los puntos de verificación. Consulte la [Guía de entrenamiento de puntos de verificación](./checkpoint.ipynb) para obtener más detalles."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSZebVuWxDXu"
      },
      "source": [
        "### Guardar funciones\n",
        "\n",
        "TensorFlow puede ejecutar modelos sin los objetos originales de Python, como se muestra en [TensorFlow Serving](https://tensorflow.org/tfx) y [TensorFlow Lite](https://tensorflow.org/lite), incluso cuando se descarga un modelo entrenado desde [TensorFlow Hub](https://tensorflow.org/hub).\n",
        "\n",
        "TensorFlow necesita saber cómo hacer los cálculos descritos en Python, pero **sin el código original**. Para eso, puede hacer un **gráfico**, que se explica en la [guía de Introducción a gráficos y funciones](./intro_to_graphs.ipynb).\n",
        "\n",
        "Este gráfico contiene operaciones, o *ops*, que implementan la función.\n",
        "\n",
        "Puede definir un gráfico en el modelo anterior al agregar el decorador `@tf.function` para indicar que el código debe ejecutarse como un gráfico."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WQTvkapUh7lk"
      },
      "outputs": [],
      "source": [
        "class MySequentialModule(tf.Module):\n",
        "  def __init__(self, name=None):\n",
        "    super().__init__(name=name)\n",
        "\n",
        "    self.dense_1 = Dense(in_features=3, out_features=3)\n",
        "    self.dense_2 = Dense(in_features=3, out_features=2)\n",
        "\n",
        "  @tf.function\n",
        "  def __call__(self, x):\n",
        "    x = self.dense_1(x)\n",
        "    return self.dense_2(x)\n",
        "\n",
        "# You have made a model with a graph!\n",
        "my_model = MySequentialModule(name=\"the_model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hW66YXBziLo9"
      },
      "source": [
        "El módulo que creó funciona exactamente de la misma forma que antes. Cada signatura única que se pasa en la función crea un gráfico diferente. Échele un vistazo a la [guía de Introducción a gráficos y funciones](./intro_to_graphs.ipynb) para obtener más detalles."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H5zUfti3iR52"
      },
      "outputs": [],
      "source": [
        "print(my_model([[2.0, 2.0, 2.0]]))\n",
        "print(my_model([[[2.0, 2.0, 2.0], [2.0, 2.0, 2.0]]]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbGlU1kgyDo7"
      },
      "source": [
        "Puede visualizar el gráfico al trazarlo en el resúmen de TensorBoard."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zmy-T67zhp-S"
      },
      "outputs": [],
      "source": [
        "# Set up logging.\n",
        "stamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "logdir = \"logs/func/%s\" % stamp\n",
        "writer = tf.summary.create_file_writer(logdir)\n",
        "\n",
        "# Create a new model to get a fresh trace\n",
        "# Otherwise the summary will not see the graph.\n",
        "new_model = MySequentialModule()\n",
        "\n",
        "# Bracket the function call with\n",
        "# tf.summary.trace_on() and tf.summary.trace_export().\n",
        "tf.summary.trace_on(graph=True)\n",
        "tf.profiler.experimental.start(logdir)\n",
        "# Call only one tf.function when tracing.\n",
        "z = print(new_model(tf.constant([[2.0, 2.0, 2.0]])))\n",
        "with writer.as_default():\n",
        "  tf.summary.trace_export(\n",
        "      name=\"my_func_trace\",\n",
        "      step=0,\n",
        "      profiler_outdir=logdir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gz4lwNZ9hR79"
      },
      "source": [
        "Inicie TensorBoard para ver el trazado resultante:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V4MXDbgBnkJu"
      },
      "outputs": [],
      "source": [
        "#docs_infra: no_execute\n",
        "%tensorboard --logdir logs/func"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gjattu0AhYUl"
      },
      "source": [
        "![Una captura de pantalla del gráfico en TensorBoard](images/tensorboard_graph.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQu3TVZecmL7"
      },
      "source": [
        "### Crear un `SavedModel`\n",
        "\n",
        "Lo que se recomienda para compartir modelos entrenados es usar `SavedModel`.  `SavedModel` contiene una colección de funciones y una colección de pesos.\n",
        "\n",
        "Puede guardar el modelo que acaba de entrenar de la siguiente manera:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Awv_Tw__WK7a"
      },
      "outputs": [],
      "source": [
        "tf.saved_model.save(my_model, \"the_saved_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SXv3mEKsefGj"
      },
      "outputs": [],
      "source": [
        "# Inspect the SavedModel in the directory\n",
        "!ls -l the_saved_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vQQ3hEvHYdoR"
      },
      "outputs": [],
      "source": [
        "# The variables/ directory contains a checkpoint of the variables \n",
        "!ls -l the_saved_model/variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBqPop7ZesBU"
      },
      "source": [
        "El archivo `saved_model.pb` es un [búfer de protocolo](https://developers.google.com/protocol-buffers) que describe un `tf.Graph` funcional.\n",
        "\n",
        "Se pueden cargar los modelos y las capas desde esta representación sin realmente hacer un instancia de la clase que lo creó. Esto es ideal en situaciones donde se tiene (o quiere) un intérprete de Python, como servir a escala o en un dispositivo perimetral o en situaciones donde el código de Python original no esté disponible o no se pueda usar.\n",
        "\n",
        "Puede cargar un modelo como un objeto nuevo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zRFcA5wIefv4"
      },
      "outputs": [],
      "source": [
        "new_model = tf.saved_model.load(\"the_saved_model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9EF3mT7i3qN"
      },
      "source": [
        "`new_model`, creado desde un modelo guardado, es un objeto de usuario interno de TensorFlow sin el conocimiento de la clase. No es un tipo `SequentialModule`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EC_eQj7yi54G"
      },
      "outputs": [],
      "source": [
        "isinstance(new_model, SequentialModule)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OrOX1zxiyhR"
      },
      "source": [
        "Este modelo nuevo funciona en signaturas de entrada que ya están definidas. No se puede agregar signaturas a modelos restaurados como este."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_23BYYBWfKnc"
      },
      "outputs": [],
      "source": [
        "print(my_model([[2.0, 2.0, 2.0]]))\n",
        "print(my_model([[[2.0, 2.0, 2.0], [2.0, 2.0, 2.0]]]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSFhoMtTjSR6"
      },
      "source": [
        "Por lo tanto, al usar `SavedModel`, podrá guardar los pesos y gráficos de TensorFlow con `tf.Module`, y luego cargarlos de nuevo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rb9IdN7hlUZK"
      },
      "source": [
        "## Modelos y capas de Keras\n",
        "\n",
        "Note cómo no mencionamos Keras todavía. Puede construir su propio API de nivel superior además del  `tf.Module`, y la gente lo ha hecho.\n",
        "\n",
        "En esta sección, examinaremos cómo es que Keras usa `tf.Module`. Puede encontrar la guía de usuario completa de los modelos de Keras en la [guía de Keras](https://www.tensorflow.org/guide/keras/sequential_model).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ds08u3touwe4t"
      },
      "source": [
        "Las capas y modelo de Keras tienen muchas más características, entre ellas:\n",
        "\n",
        "- Pérdidas opcionales\n",
        "- Soporte para [métricas](https://keras.io/api/layers/base_layer/#add_metric-method)\n",
        "- Soporte integrado para un argumento de `training` opcional para diferenciar entre el uso de entrenamiento y de inferencia\n",
        "- Guardar y restaurar objetos de Python en vez desolo funciones de caja negra\n",
        "- Los métodos `get_config` y `from_config` que le permiten guardar configuraciones con precisión para permitir la clonación de modelos en Python.\n",
        "\n",
        "Estas características permiten modelos mucho más complejos mediante la subclasificación, tales como los modelos GAN y el Autocodificador variacional (VAE, por sus siglas en inglés). Puede leer más sobre estos modelos en la [guía completa](./keras/custom_layers_and_models.ipynb) para personalizar capas y modelos\n",
        "\n",
        "Los modelos de Keras también tienen una funcionalidad adicional que facilita el entrenamiento, la evaluación, la carga, el almacenamiento e incluso el entrenamiento de varios modelos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uigsVGPreE-D"
      },
      "source": [
        "### Capas de Keras\n",
        "\n",
        "La clase `tf.keras.layers.Layer` es la clase fundamental de todas las capas de Keras y hereda de `tf.Module`.\n",
        "\n",
        "Puede convertir un módulo en una capa de Keras con tan solo intercambiar el elemento primario y luego cambiar `__call__` a `call`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "88YOGquhnQRd"
      },
      "outputs": [],
      "source": [
        "class MyDense(tf.keras.layers.Layer):\n",
        "  # Adding **kwargs to support base Keras layer arguments\n",
        "  def __init__(self, in_features, out_features, **kwargs):\n",
        "    super().__init__(**kwargs)\n",
        "\n",
        "    # This will soon move to the build step; see below\n",
        "    self.w = tf.Variable(\n",
        "      tf.random.normal([in_features, out_features]), name='w')\n",
        "    self.b = tf.Variable(tf.zeros([out_features]), name='b')\n",
        "  def call(self, x):\n",
        "    y = tf.matmul(x, self.w) + self.b\n",
        "    return tf.nn.relu(y)\n",
        "\n",
        "simple_layer = MyDense(name=\"simple\", in_features=3, out_features=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYGmAsPrws--"
      },
      "source": [
        "Las capas de Keras tienen su propio `__call__` que realiza parte de la contabilización que se describe en la siguiente sección y luego llama a `call()`. No se debería notar ningún cambio en la funcionalidad."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nIqE8wOznYKG"
      },
      "outputs": [],
      "source": [
        "simple_layer([[2.0, 2.0, 2.0]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmN5vb1K18U1"
      },
      "source": [
        "### El paso `build`\n",
        "\n",
        "Como ya mencionamos, en muchos casos es conveniente esperar a crear las variables hasta saber la forma de la entrada.\n",
        "\n",
        "Las capas de Keras vienen con un paso de ciclo de vida adicional que permite más flexibilidad al definir sus capas. Esto se define en la función `build`.\n",
        "\n",
        "Se llama a la función `build` exactamente una vez y se la llama con la forma de la entrada. Suele usarse para crear variables (pesos).\n",
        "\n",
        "Puede reescribir la capa `MyDense` anterior para ser flexible con respecto al tamaño de las entradas.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4YTfrlgdsURp"
      },
      "outputs": [],
      "source": [
        "class FlexibleDense(tf.keras.layers.Layer):\n",
        "  # Note the added `**kwargs`, as Keras supports many arguments\n",
        "  def __init__(self, out_features, **kwargs):\n",
        "    super().__init__(**kwargs)\n",
        "    self.out_features = out_features\n",
        "\n",
        "  def build(self, input_shape):  # Create the state of the layer (weights)\n",
        "    self.w = tf.Variable(\n",
        "      tf.random.normal([input_shape[-1], self.out_features]), name='w')\n",
        "    self.b = tf.Variable(tf.zeros([self.out_features]), name='b')\n",
        "\n",
        "  def call(self, inputs):  # Defines the computation from inputs to outputs\n",
        "    return tf.matmul(inputs, self.w) + self.b\n",
        "\n",
        "# Create the instance of the layer\n",
        "flexible_dense = FlexibleDense(out_features=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Koc_uSqt2PRh"
      },
      "source": [
        "Hasta este punto, el modelo todavía no está construido por lo tanto no hay variables:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DgyTyUD32Ln4"
      },
      "outputs": [],
      "source": [
        "flexible_dense.variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KdamIVl2W8Y"
      },
      "source": [
        "Cuando se llama a la función se asignan las variables con el tamaño adecuado:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IkLyEx7uAoTK"
      },
      "outputs": [],
      "source": [
        "# Call it, with predictably random results\n",
        "print(\"Model results:\", flexible_dense(tf.constant([[2.0, 2.0, 2.0], [3.0, 3.0, 3.0]])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Swofpkrd2YDd"
      },
      "outputs": [],
      "source": [
        "flexible_dense.variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PuNUnf0OIpF"
      },
      "source": [
        "Dado que `build` solo se llama una vez, se rechazarán las entradas si el tamaño no es compatible con las variables de la capa:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "caYWDrHSAy_j"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  print(\"Model results:\", flexible_dense(tf.constant([[2.0, 2.0, 2.0, 2.0]])))\n",
        "except tf.errors.InvalidArgumentError as e:\n",
        "  print(\"Failed:\", e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2kds2IHw2KD"
      },
      "source": [
        "### Modelos de Keras\n",
        "\n",
        "Puede definir su modelo como capas de Keras anidadas.\n",
        "\n",
        "Sin embargo, Keras también proporciona una clase de modelo con todas las características llamado `tf.keras.Model`. Este hereda de `tf.keras.layers.Layer`, por eso se puede usar y anidar un modelo de Keras de la misma forma que las capas de Keras. Los modelos de Keras vienen con una funcionalidad adicional que facilita el entrenamiento, la evaluación, la carga, el almacenamiento e incluso el entrenamiento de varios modelos.\n",
        "\n",
        "Puede definir el `SequentialModule` de arriba con un código casi idéntico, volver a convertir `__call__` a `call()` y cambiar el elemento primario:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hqjo1DiyrHrn"
      },
      "outputs": [],
      "source": [
        "class MySequentialModel(tf.keras.Model):\n",
        "  def __init__(self, name=None, **kwargs):\n",
        "    super().__init__(**kwargs)\n",
        "\n",
        "    self.dense_1 = FlexibleDense(out_features=3)\n",
        "    self.dense_2 = FlexibleDense(out_features=2)\n",
        "  def call(self, x):\n",
        "    x = self.dense_1(x)\n",
        "    return self.dense_2(x)\n",
        "\n",
        "# You have made a Keras model!\n",
        "my_sequential_model = MySequentialModel(name=\"the_model\")\n",
        "\n",
        "# Call it on a tensor, with random results\n",
        "print(\"Model results:\", my_sequential_model(tf.constant([[2.0, 2.0, 2.0]])))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8i-CR_h2xw3z"
      },
      "source": [
        "Todas las mismas características están disponibles, incluso el seguimiento de variables y de submodelos.\n",
        "\n",
        "Nota: las variables de un `tf.Module` sin procesar, anidado dentro de la capa o modelo de Keras no sé recopilarán para entrenamiento ni almacenamiento. Mejor anide las capas de Keras dentro de las capas de Keras."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hdLQFNdMsOz1"
      },
      "outputs": [],
      "source": [
        "my_sequential_model.variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JjVAMrAJsQ7G"
      },
      "outputs": [],
      "source": [
        "my_sequential_model.submodules"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FhP8EItC4oac"
      },
      "source": [
        "Reemplazar `tf.keras.Model` es un enfoque típico de Python para construir modelos de TensorFlow. Si migra modelos desde otros frameworks, esto puede ser muy simple.\n",
        "\n",
        " Si construye modelos que son simplemente agrupaciones de capas y entradas existentes, puede ahorrar tiempo y espacio con la [API funcional](./keras/functional.ipynb), que viene con características adicionales sobre la reconstrucción y arquitectura del modelo .\n",
        "\n",
        "Este es el mismo modelo con la API funcional:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jJiZZiJ0fyqQ"
      },
      "outputs": [],
      "source": [
        "inputs = tf.keras.Input(shape=[3,])\n",
        "\n",
        "x = FlexibleDense(3)(inputs)\n",
        "x = FlexibleDense(2)(x)\n",
        "\n",
        "my_functional_model = tf.keras.Model(inputs=inputs, outputs=x)\n",
        "\n",
        "my_functional_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kg-xAZw5gaG6"
      },
      "outputs": [],
      "source": [
        "my_functional_model(tf.constant([[2.0, 2.0, 2.0]]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_BK9XH5q9cq"
      },
      "source": [
        "La diferencia más importante es que la forma de entrada se especifica desde el inicio como parte del proceso de construcción funcional. En este caso, no hace falta especificar el argumento `input_shape`; puede marcar algunas dimensiones como `None`.\n",
        "\n",
        "Nota: No hace falta especificar la `input_shape` o la `InputLayer` en un modelo subclasificado; los argumentos y las capas serán ignorados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qI9aXLnaHEFF"
      },
      "source": [
        "### Guardar los modelos de Keras\n",
        "\n",
        "Los modelos de Keras tienen su propio formato de guardado especializado de archivo ZIP, que se marca con la extensión `.keras`. Al llamar `tf.keras.Model.save`, agregue la extensión `.keras` en el nombre de archivo. Por ejemplo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SAz-KVZlzAJu"
      },
      "outputs": [],
      "source": [
        "my_sequential_model.save(\"exname_of_file.keras\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2urAeR-omns"
      },
      "source": [
        "Y así de fácil, también se pueden volver a cargar:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wj5DW-LCopry"
      },
      "outputs": [],
      "source": [
        "reconstructed_model = tf.keras.models.load_model(\"exname_of_file.keras\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EA7P_MNvpviZ"
      },
      "source": [
        "Los archivos archivados en ZIP de Keras, `.keras`, guardan los estados de las métricas, de las pérdidas y de los optimizadores.\n",
        "\n",
        "Se puede usar este modelo reconstruido, y producirá el mismo resultado al llamarlo con los mismos datos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P_wGfQo5pe6T"
      },
      "outputs": [],
      "source": [
        "reconstructed_model(tf.constant([[2.0, 2.0, 2.0]]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seLIUG2354s"
      },
      "source": [
        "###  Guardar puntos de verificación de los modelos de Keras\n",
        "\n",
        "También se pueden guardar los puntos de verificación de los modelos de Keras y se vería igual que un `tf.Module`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKyjlkceqjwD"
      },
      "source": [
        "Hay más cosas para aprender sobre el guardado y la serialización de los modelos de Keras, por ejemplo proporcionar métodos de configuración para capas personalizadas que sean compatibles con funciones. Échele un vistazo a la [guía de guardado y serialización](https://www.tensorflow.org/guide/keras/save_and_serialize)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcdMMPYv7Krz"
      },
      "source": [
        "# Siguientes pasos\n",
        "\n",
        "Si quiere obtener más detalles sobre Keras, puede ver las guías actuales de Keras [aquí](./keras/).\n",
        "\n",
        "Otro ejemplo de una API de nivel superior construida en `tf.module` es Sonnet de DeepMind, que se explica en [su sitio web](https://github.com/deepmind/sonnet)."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "ISubpr_SSsiM"
      ],
      "name": "intro_to_modules.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
