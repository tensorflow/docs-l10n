{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tce3stUlHN0L"
      },
      "source": [
        "##### Copyright 2019 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tuOe1ymfHZPu"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFdPvlXBOdUN"
      },
      "source": [
        "# Mejor rendimiento con la API tf.data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfBg1C5NB3X0"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td data-parent-segment-id=\"13650222\" data-segment-approved=\"false\"><a target=\"_blank\" href=\"https://www.tensorflow.org/guide/data_performance\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver en TensorFlow.org</a></td>\n",
        "  <td data-parent-segment-id=\"13650223\" data-segment-approved=\"false\"><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/es-419/guide/data_performance.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Ejecutar en Google Colab</a></td>\n",
        "  <td data-parent-segment-id=\"13650224\" data-segment-approved=\"false\">     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/es-419/guide/data_performance.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver código fuente en GitHub</a>\n",
        "</td>\n",
        "  <td data-parent-segment-id=\"13650225\" data-segment-approved=\"false\">     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/es-419/guide/data_performance.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Descargar bloc de notas</a>\n",
        "</td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHxb-dlhMIzW"
      },
      "source": [
        "## Visión general\n",
        "\n",
        "Las GPU y las TPU pueden reducir radicalmente el tiempo necesario para ejecutar un solo paso de entrenamiento. Alcanzar el máximo rendimiento requiere un canal de entrada eficiente que proporcione datos para el siguiente paso antes de que el paso actual haya finalizado. La API `tf.data` ayuda a construir canalizaciones de entrada flexibles y eficientes. Este documento muestra cómo usar la API `tf.data` API para construir canalizaciones de entrada TensorFlow de alto rendimiento.\n",
        "\n",
        "Antes de continuar, consulte la guía [Construir canalizaciones de entrada de TensorFlow](./data.ipynb) para aprender a usar la API `tf.data`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhNtHfuxCGVy"
      },
      "source": [
        "## Recursos\n",
        "\n",
        "- [Construir canalizaciones de entrada TensorFlow](./data.ipynb)\n",
        "- API `tf.data.Dataset`\n",
        "- [Analizar el rendimiento de `tf.data` con el TF Profiler](./data_performance_analysis.md)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUXex9ctTuDB"
      },
      "source": [
        "## Preparación"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IqR2PQG4ZaZ0"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QthTHCKF-jKD"
      },
      "source": [
        "A lo largo de esta guía, iterará sobre un conjunto de datos y medirá el rendimiento. La realización de pruebas de rendimiento reproducibles puede resultar difícil. Entre los distintos factores que afectan a la reproducibilidad se incluyen:\n",
        "\n",
        "- La carga actual de la CPU\n",
        "- El tráfico de red\n",
        "- Mecanismos complejos, como la caché\n",
        "\n",
        "Para obtener un punto de referencia reproducible, construirá un ejemplo artificial."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bU5gsSI-jKF"
      },
      "source": [
        "### El conjunto de datos\n",
        "\n",
        "Primero, defina una clase que herede de `tf.data.Dataset` llamada `ArtificialDataset`. Este conjunto de datos:\n",
        "\n",
        "- Genera `num_samples` muestreos (predeterminado 3)\n",
        "- Se duerme durante algún tiempo antes del primer artículo para simular la apertura de un archivo\n",
        "- Duerme durante algún tiempo antes de producir cada artículo para simular la lectura de datos de un archivo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zUQv4kCd-jKH"
      },
      "outputs": [],
      "source": [
        "class ArtificialDataset(tf.data.Dataset):\n",
        "    def _generator(num_samples):\n",
        "        # Opening the file\n",
        "        time.sleep(0.03)\n",
        "        \n",
        "        for sample_idx in range(num_samples):\n",
        "            # Reading data (line, record) from the file\n",
        "            time.sleep(0.015)\n",
        "            \n",
        "            yield (sample_idx,)\n",
        "    \n",
        "    def __new__(cls, num_samples=3):\n",
        "        return tf.data.Dataset.from_generator(\n",
        "            cls._generator,\n",
        "            output_signature = tf.TensorSpec(shape = (1,), dtype = tf.int64),\n",
        "            args=(num_samples,)\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9y1WjNv-jKL"
      },
      "source": [
        "Este conjunto de datos es similar al de `tf.data.Dataset.range`, añadiendo un retraso fijo al principio y entre cada muestreo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGK1Y4jn-jKM"
      },
      "source": [
        "### El bucle de entrenamiento\n",
        "\n",
        "Después, escriba un bucle de entrenamiento simulado que mida el tiempo que se tarda en iterar sobre un conjunto de datos. El tiempo de entrenamiento es simulado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MIaM3u00-jKP"
      },
      "outputs": [],
      "source": [
        "def benchmark(dataset, num_epochs=2):\n",
        "    start_time = time.perf_counter()\n",
        "    for epoch_num in range(num_epochs):\n",
        "        for sample in dataset:\n",
        "            # Performing a training step\n",
        "            time.sleep(0.01)\n",
        "    print(\"Execution time:\", time.perf_counter() - start_time)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KK58SuXS-jKT"
      },
      "source": [
        "## Optimizar el rendimiento\n",
        "\n",
        "Para mostrar cómo se puede optimizar el rendimiento, mejorará el rendimiento del `ArtificialDataset`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xi8t26y7-jKV"
      },
      "source": [
        "### El acercamiento ingenuo\n",
        "\n",
        "Comience con una canalización ingenua sin usar trucos, iterando sobre el conjunto de datos tal cual."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_gP7J1y4-jKY"
      },
      "outputs": [],
      "source": [
        "benchmark(ArtificialDataset())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lxeat5dH-jKf"
      },
      "source": [
        "En el fondo, así es como se empleó su tiempo de ejecución:\n",
        "\n",
        "![Gráfico de tiempo de ejecución de datos: método ingenuo](https://www.tensorflow.org/guide/images/data_performance/naive.svg)\n",
        "\n",
        "El gráfico muestra que realizar un paso de entrenamiento implica:\n",
        "\n",
        "- Abrir un archivo si aún no se ha abierto\n",
        "- Extraer una entrada de datos del archivo\n",
        "- Usar los datos para el entrenamiento\n",
        "\n",
        "Sin embargo, en una implementación síncrona ingenua como ésta, mientras su canalización extrae los datos, su modelo permanece inactivo. A la inversa, mientras su modelo se está entrenando, la canalización de entrada está inactiva. El tiempo del paso de entrenamiento es, por tanto, la suma de los tiempos de apertura, lectura y entrenamiento.\n",
        "\n",
        "Las siguientes secciones desarrollan esta canalización de entrada, ilustrando las prácticas recomendadas de diseño de canalizaciones de entrada TensorFlow de alto rendimiento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfukBGNz-jKh"
      },
      "source": [
        "### Preextracción\n",
        "\n",
        "La preextracción se superpone al preprocesamiento y a la ejecución del modelo de un paso de entrenamiento. Mientras el modelo ejecuta el paso de entrenamiento `s`, la canalización de entrada lee los datos para el paso `s+1`. De este modo se reduce el tiempo del paso al máximo (en lugar de la suma) entre el entrenamiento y el tiempo que se tarda en extraer los datos.\n",
        "\n",
        "La API `tf.data` ofrece la transformación `tf.data.Dataset.prefetch`. Puede usarse para desacoplar el tiempo en que se producen los datos del tiempo en que se consumen. En concreto, la transformación usa un subproceso en segundo plano y un búfer interno para preextraer elementos del conjunto de datos de entrada antes de que se soliciten. El número de elementos a preextraer debe ser igual (o posiblemente mayor) que el número de lotes consumidos por un único paso de entrenamiento. Puede ajustar este valor manualmente o configurarlo como `tf.data.AUTOTUNE`, lo que solicitará al runtime de `tf.data` que ajuste el valor dinámicamente en tiempo de ejecución.\n",
        "\n",
        "Tenga en cuenta que la transformación de preextracción ofrece beneficios siempre que exista la oportunidad de superponer el trabajo de un \"productor\" con el de un \"consumidor\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DHpUVqH1-jKi"
      },
      "outputs": [],
      "source": [
        "benchmark(\n",
        "    ArtificialDataset()\n",
        "    .prefetch(tf.data.AUTOTUNE)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7z_kzo--jKn"
      },
      "source": [
        "![Gráfico de tiempo de ejecución de datos: método de preextracción](https://www.tensorflow.org/guide/images/data_performance/prefetched.svg)\n",
        "\n",
        "Ahora, como muestra el gráfico de tiempo de ejecución de datos, mientras se realiza el paso de entrenamiento para la muestra 0, la canalización de entrada está leyendo los datos de la muestra 1, y así sucesivamente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52QMKfaY-jKq"
      },
      "source": [
        "### Paralelización de la extracción de datos\n",
        "\n",
        "En un entorno real, los datos de entrada pueden almacenarse de forma remota (por ejemplo, en Google Cloud Storage o HDFS). Una canalización de conjuntos de datos que funciona bien cuando lee los datos localmente podría sufrir cuellos de botella en la E/S al leer datos remotamente debido a las siguientes diferencias entre el almacenamiento local y el remoto:\n",
        "\n",
        "- **Tiempo hasta el primer byte**: La lectura del primer byte de un archivo desde un almacenamiento remoto puede tardar órdenes de magnitud más que desde un almacenamiento local.\n",
        "- **Rendimiento de lectura**: Aunque el almacenamiento remoto suele ofrecer un gran ancho de banda agregado, es posible que la lectura de un único archivo sólo pueda utilizar una pequeña fracción de este ancho de banda.\n",
        "\n",
        "Además, una vez que los bytes en bruto se cargan en la memoria, también puede ser necesario deserializar y/o descifrar los datos (por ejemplo, [protobuf](https://developers.google.com/protocol-buffers/)), lo que requiere un cálculo adicional. Esta carga se produce tanto si los datos se almacenan local como remotamente, pero puede ser peor en el caso remoto si los datos no se preextraen de forma eficaz.\n",
        "\n",
        "Para mitigar el impacto de los diversos gastos generales de la extracción de datos, se puede usar la transformación `tf.data.Dataset.interleave` para paralelizar el paso de carga de datos, intercalando el contenido de otros conjuntos de datos (como los lectores de archivos de datos). El número de conjuntos de datos a superponer puede especificarse mediante el argumento `cycle_length`, mientras que el nivel de paralelismo puede especificarse mediante el argumento `num_parallel_calls`. Parecida a la transformación `prefetch`, la transformación `interleave` admite `tf.data.AUTOTUNE`, que delegará la decisión sobre qué nivel de paralelismo usar al runtime de `tf.data`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gs8O8Vbu-jKu"
      },
      "source": [
        "#### Intercalación secuencial\n",
        "\n",
        "Los argumentos predeterminados de la transformación `tf.data.Dataset.interleave` hacen que intercalen muestras individuales de dos conjuntos de datos de forma secuencial."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fDH12GiK-jKw"
      },
      "outputs": [],
      "source": [
        "benchmark(\n",
        "    tf.data.Dataset.range(2)\n",
        "    .interleave(lambda _: ArtificialDataset())\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78CsSOnf-jK0"
      },
      "source": [
        "![Data execution time plot - sequential interleave](https://www.tensorflow.org/guide/images/data_performance/sequential_interleave.svg)\n",
        "\n",
        "Este gráfico de tiempo de ejecución de datos permite exhibir el comportamiento de la transformación `interleave`, extrayendo muestreos alternativamente de los dos conjuntos de datos disponibles. Sin embargo, no supone ninguna mejora del rendimiento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3cqqmYl-jK2"
      },
      "source": [
        "#### Intercalado paralelo\n",
        "\n",
        "Ahora, use el argumento `num_parallel_calls` de la transformación `interleave`. Esto carga varios conjuntos de datos en paralelo, reduciendo el tiempo de espera para la apertura de los archivos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a3FQcTPY-jK4"
      },
      "outputs": [],
      "source": [
        "benchmark(\n",
        "    tf.data.Dataset.range(2)\n",
        "    .interleave(\n",
        "        lambda _: ArtificialDataset(),\n",
        "        num_parallel_calls=tf.data.AUTOTUNE\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RxRLPB6C-jLA"
      },
      "source": [
        "![Gráfico de tiempo de ejecución de datos: método de intercalado paralelo](https://www.tensorflow.org/guide/images/data_performance/parallel_interleave.svg)\n",
        "\n",
        "Esta vez, como se ve en el gráfico de tiempo de ejecución de datos, la lectura de los dos conjuntos de datos se realiza en paralelo, lo que reduce el tiempo de procesamiento global de los datos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ZCLFWyv-jLB"
      },
      "source": [
        "### Paralelización de la transformación de datos\n",
        "\n",
        "Al preparar los datos, puede ser necesario preprocesar los elementos de entrada. Para ello, la API `tf.data` ofrece la transformación `tf.data.Dataset.map`, que aplica una función definida por el usuario a cada elemento del conjunto de datos de entrada. Dado que los elementos de entrada son independientes entre sí, el preprocesamiento puede paralelizarse en varios núcleos de CPU. Para que ello sea posible, análogamente a las transformaciones `prefetch` e `interleave`, la transformación `map` facilita el argumento `num_parallel_calls` para especificar el nivel de paralelismo.\n",
        "\n",
        "Elegir el mejor valor para el argumento `num_parallel_calls` depende de su hardware, de las características de sus datos de entrenamiento (como su tamaño y forma), del costo de su función de mapeo y de qué otros procesos están teniendo lugar en la CPU al mismo tiempo. Una heurística sencilla es usar el número de núcleos de CPU disponibles. Sin embargo, al igual que para la transformación `prefetch` e `interleave`, la transformación `map` admite `tf.data.AUTOTUNE` que delegará la decisión sobre qué nivel de paralelismo usar al runtime de `tf.data`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GSkKetpx-jLD"
      },
      "outputs": [],
      "source": [
        "def mapped_function(s):\n",
        "    # Do some hard pre-processing\n",
        "    tf.py_function(lambda: time.sleep(0.03), [], ())\n",
        "    return s"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wiU7W_QC-jLI"
      },
      "source": [
        "#### Mapeo secuencial\n",
        "\n",
        "Empiece usando la transformación `map` sin paralelismo como ejemplo de línea de referencia."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZSBvDpJG-jLL"
      },
      "outputs": [],
      "source": [
        "benchmark(\n",
        "    ArtificialDataset()\n",
        "    .map(mapped_function)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngwMTDb6-jLR"
      },
      "source": [
        "![Gráfico de tiempo de ejecución de datos: método ingenuo](https://www.tensorflow.org/guide/images/data_performance/sequential_map.svg)\n",
        "\n",
        "En cuanto al enfoque [ingenuo](#The-naive-approach), aquí, como muestra el gráfico, los tiempos empleados en los pasos de apertura, lectura, preprocesamiento (mapeado) y entrenamiento se suman para una única iteración."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-10PE1D-jLU"
      },
      "source": [
        "#### Mapeo paralelo\n",
        "\n",
        "Ahora, use la misma función de preprocesamiento pero aplíquela en paralelo en varias muestras."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F8AYLZbg-jLV"
      },
      "outputs": [],
      "source": [
        "benchmark(\n",
        "    ArtificialDataset()\n",
        "    .map(\n",
        "        mapped_function,\n",
        "        num_parallel_calls=tf.data.AUTOTUNE\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MoJklzP-jLe"
      },
      "source": [
        "![Tiempo de ejecución de datos: mapeo paralelo](https://www.tensorflow.org/guide/images/data_performance/parallel_map.svg)\n",
        "\n",
        "Como demuestra el gráfico de datos, los pasos de preprocesamiento se superponen, lo que reduce el tiempo total de una sola iteración."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY1Q9kJO-jLh"
      },
      "source": [
        "### Almacenamiento en caché\n",
        "\n",
        "La transformación `tf.data.Dataset.cache` puede almacenar en caché un conjunto de datos, ya sea en memoria o en almacenamiento local. Esto evitará que algunas operaciones (como la apertura de archivos y la lectura de datos) se ejecuten durante cada época."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xieLApaI-jLi"
      },
      "outputs": [],
      "source": [
        "benchmark(\n",
        "    ArtificialDataset()\n",
        "    .map(  # Apply time consuming operations before cache\n",
        "        mapped_function\n",
        "    ).cache(\n",
        "    ),\n",
        "    5\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeMgW9XI-jLn"
      },
      "source": [
        "![Tiempo de ejecución de los datos: método de conjunto de datos en caché](https://www.tensorflow.org/guide/images/data_performance/cached_dataset.svg)\n",
        "\n",
        "Aquí, el gráfico del tiempo de ejecución de los datos muestra que cuando se almacena en caché un conjunto de datos, las transformaciones anteriores a la de `cache` (como la apertura del archivo y la lectura de los datos) se ejecutan sólo durante la primera época. Las épocas siguientes reutilizarán los datos almacenados en caché por la transformación `cache`.\n",
        "\n",
        "Si la función definida por el usuario que se pasa a la transformación `map` es costosa, aplique la transformación `cache` después de la transformación `map` siempre que el conjunto de datos resultante aún pueda caber en la memoria o en el almacenamiento local. Si la función definida por el usuario aumenta el espacio necesario para almacenar el conjunto de datos más allá de la capacidad de la caché, aplíquela después de la transformación `cache` o considere la posibilidad de preprocesar sus datos antes del trabajo de entrenamiento para reducir el uso de recursos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3NtGI3r-jLp"
      },
      "source": [
        "### Mapeo vectorizante\n",
        "\n",
        "Invocar una función definida por el usuario pasada a la transformación `map` tiene sobrecarga relacionada con la programación y ejecución de la función definida por el usuario. Vectorice la función definida por el usuario (es decir, haga que opere sobre un lote de entradas a la vez) y aplique la transformación `batch` *antes* de la transformación `map`.\n",
        "\n",
        "Para ilustrar esta práctica recomendada, no es adecuado su conjunto de datos artificial. El retraso de planificación es de unos 10 microsegundos (10e-6 segundos), mucho menos que las decenas de milisegundos usadas en el `ArtificialDataset`, por lo que su impacto es difícil de ver.\n",
        "\n",
        "Para este ejemplo, use la función base `tf.data.Dataset.range` y simplifique el bucle de entrenamiento a su forma más simple."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xqtiYPmb-jLt"
      },
      "outputs": [],
      "source": [
        "fast_dataset = tf.data.Dataset.range(10000)\n",
        "\n",
        "def fast_benchmark(dataset, num_epochs=2):\n",
        "    start_time = time.perf_counter()\n",
        "    for _ in tf.data.Dataset.range(num_epochs):\n",
        "        for _ in dataset:\n",
        "            pass\n",
        "    tf.print(\"Execution time:\", time.perf_counter() - start_time)\n",
        "    \n",
        "def increment(x):\n",
        "    return x+1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fj2gmsMT-jL5"
      },
      "source": [
        "#### Mapeo escalar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Imn3SslJ-jMA"
      },
      "outputs": [],
      "source": [
        "fast_benchmark(\n",
        "    fast_dataset\n",
        "    # Apply function one item at a time\n",
        "    .map(increment)\n",
        "    # Batch\n",
        "    .batch(256)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWUNbPqv-jMF"
      },
      "source": [
        "![Tiempo de ejecución de datos: método de mapeo escalar](https://www.tensorflow.org/guide/images/data_performance/scalar_map.svg)\n",
        "\n",
        "El gráfico anterior ilustra lo que ocurre (con menos muestras) usando el método de mapeo escalar. Muestra que la función mapeada se aplica a cada muestra. Aunque esta función es muy rápida, tiene algunos gastos generales que repercuten en el rendimiento temporal."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDVSM0A--jMG"
      },
      "source": [
        "#### Mapeado vectorizado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nAw1mDLw-jMI"
      },
      "outputs": [],
      "source": [
        "fast_benchmark(\n",
        "    fast_dataset\n",
        "    .batch(256)\n",
        "    # Apply function on a batch of items\n",
        "    # The tf.Tensor.__add__ method already handle batches\n",
        "    .map(increment)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbMteMY9-jMO"
      },
      "source": [
        "![Tiempo de ejecución de datos: método de mapeo vectorizado](https://www.tensorflow.org/guide/images/data_performance/vectorized_map.svg)\n",
        "\n",
        "Esta vez, la función mapeada se llama una vez y se aplica a un lote de muestra. El gráfico de tiempo de ejecución de datos muestra que, aunque la función puede tardar más tiempo en ejecutarse, la sobrecarga sólo aparece una vez, lo que mejora el rendimiento global del tiempo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfueG0Wj-jMR"
      },
      "source": [
        "### Reducir el espacio requerido en memoria\n",
        "\n",
        "Una serie de transformaciones, incluyendo `interleave`, `prefetch`, y `shuffle`, mantienen un búfer interno de elementos. Si la función definida por el usuario que se pasa a la transformación `map` cambia el tamaño de los elementos, entonces el orden de la transformación map y de las transformaciones que almacenan elementos en búfer afecta al uso de la memoria. En general, elija el orden que resulte en un menor consumo de memoria, a menos que por rendimiento convenga un orden diferente.\n",
        "\n",
        "#### Almacenamiento en caché de cómputos parciales\n",
        "\n",
        "Se recomienda almacenar en caché el conjunto de datos después de la transformación `map` excepto si esta transformación hace que los datos sean demasiado grandes para caber en la memoria. Se puede compensar si su función mapeada se puede dividir en dos partes: una que consuma tiempo y otra que consuma memoria. En este caso, puede encadenar sus transformaciones como se indica a continuación:\n",
        "\n",
        "```python\n",
        "dataset.map(time_consuming_mapping).cache().map(memory_consuming_mapping)\n",
        "```\n",
        "\n",
        "De esta forma, la parte que consume más tiempo sólo se ejecuta durante la primera época, y se evita usar demasiado espacio de la caché."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYOHG69M-jMT"
      },
      "source": [
        "## Resumen de prácticas recomendadas\n",
        "\n",
        "Aquí va un resumen de las prácticas recomendadas para diseñar canalizaciones de entrada TensorFlow de alto rendimiento:\n",
        "\n",
        "- [Utilice la transformación `prefetch`](#Pipelining) para superponer el trabajo de un productor y un consumidor.\n",
        "- [Paralelice la transformación de lectura de datos](#Parallelizing-data-extraction) usando la transformación `interleave`.\n",
        "- [Paralelice la transformación `map`](#Parallelizing-data-transformation) configurando el argumento `num_parallel_calls`.\n",
        "- [Use la transformación `cache`](#Caching) para almacenar en caché los datos en memoria durante la primera época.\n",
        "- [Vectorice las funciones definidas por el usuario](#Map-and-batch) pasadas a la transformación `map`.\n",
        "- [Reduzca el uso de memoria](#Reducing-memory-footprint) al aplicar las transformaciones `interleave`, `prefetch` y `shuffle`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mP_EMFsQ-jMU"
      },
      "source": [
        "## Reproducir las figuras\n",
        "\n",
        "Nota: El resto de este bloc de notas trata sobre cómo reproducir las figuras anteriores. Siéntase libre de jugar con este código, pero entenderlo no es una parte esencial de este tutorial.\n",
        "\n",
        "Para profundizar en la API `tf.data.Dataset`, puede jugar con sus propias canalizaciones. A continuación se muestra el código usado para trazar las imágenes de esta guía. Puede ser un buen punto de partida, mostrando algunas soluciones para dificultades comunes como:\n",
        "\n",
        "- Reproducibilidad en tiempo de ejecución\n",
        "- Eager execution de funciones mapeadas\n",
        "- Transformación `interleave` invocable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7M_jFLer-jMV"
      },
      "outputs": [],
      "source": [
        "import itertools\n",
        "from collections import defaultdict\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3pjnxtK-jMa"
      },
      "source": [
        "### El conjunto de datos\n",
        "\n",
        "Igual que con `ArtificialDataset`, puede construir un conjunto de datos que devuelva el tiempo empleado en cada paso."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OgGl4U7t-jMc"
      },
      "outputs": [],
      "source": [
        "class TimeMeasuredDataset(tf.data.Dataset):\n",
        "    # OUTPUT: (steps, timings, counters)\n",
        "    OUTPUT_TYPES = (tf.dtypes.string, tf.dtypes.float32, tf.dtypes.int32)\n",
        "    OUTPUT_SHAPES = ((2, 1), (2, 2), (2, 3))\n",
        "    \n",
        "    _INSTANCES_COUNTER = itertools.count()  # Number of datasets generated\n",
        "    _EPOCHS_COUNTER = defaultdict(itertools.count)  # Number of epochs done for each dataset\n",
        "    \n",
        "    def _generator(instance_idx, num_samples):\n",
        "        epoch_idx = next(TimeMeasuredDataset._EPOCHS_COUNTER[instance_idx])\n",
        "        \n",
        "        # Opening the file\n",
        "        open_enter = time.perf_counter()\n",
        "        time.sleep(0.03)\n",
        "        open_elapsed = time.perf_counter() - open_enter\n",
        "        \n",
        "        for sample_idx in range(num_samples):\n",
        "            # Reading data (line, record) from the file\n",
        "            read_enter = time.perf_counter()\n",
        "            time.sleep(0.015)\n",
        "            read_elapsed = time.perf_counter() - read_enter\n",
        "            \n",
        "            yield (\n",
        "                [(\"Open\",), (\"Read\",)],\n",
        "                [(open_enter, open_elapsed), (read_enter, read_elapsed)],\n",
        "                [(instance_idx, epoch_idx, -1), (instance_idx, epoch_idx, sample_idx)]\n",
        "            )\n",
        "            open_enter, open_elapsed = -1., -1.  # Negative values will be filtered\n",
        "            \n",
        "    \n",
        "    def __new__(cls, num_samples=3):\n",
        "        return tf.data.Dataset.from_generator(\n",
        "            cls._generator,\n",
        "            output_types=cls.OUTPUT_TYPES,\n",
        "            output_shapes=cls.OUTPUT_SHAPES,\n",
        "            args=(next(cls._INSTANCES_COUNTER), num_samples)\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQqDP4jk-jMj"
      },
      "source": [
        "Este conjunto de datos aporta muestreos de forma `[[2, 1], [2, 2], [2, 3]]` y de tipo `[tf.dtypes.string, tf.dtypes.float32, tf.dtypes.int32]`. Cada muestreo es:\n",
        "\n",
        "```\n",
        "(\n",
        "  [(\"Open\"), (\"Read\")],\n",
        "  [(t0, d), (t0, d)],\n",
        "  [(i, e, -1), (i, e, s)]\n",
        ")\n",
        "```\n",
        "\n",
        "Donde:\n",
        "\n",
        "- `Open` y `Read` son identificadores de pasos\n",
        "- `t0` es la marca de tiempo en la que se inició el paso correspondiente\n",
        "- `d` es el tiempo empleado en el paso correspondiente\n",
        "- `i` es el índice de instancia\n",
        "- `e` es el índice de época (número de veces que se ha iterado el conjunto de datos)\n",
        "- `s` es el índice de muestras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQK913bB-jMm"
      },
      "source": [
        "### El bucle de iteración\n",
        "\n",
        "Haga el bucle de iteración un poco más complicado para agregar todos los tiempos. Esto sólo funcionará con conjuntos de datos que generen muestreos como se detalla más arriba."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zAy-K_Cq-jMn"
      },
      "outputs": [],
      "source": [
        "def timelined_benchmark(dataset, num_epochs=2):\n",
        "    # Initialize accumulators\n",
        "    steps_acc = tf.zeros([0, 1], dtype=tf.dtypes.string)\n",
        "    times_acc = tf.zeros([0, 2], dtype=tf.dtypes.float32)\n",
        "    values_acc = tf.zeros([0, 3], dtype=tf.dtypes.int32)\n",
        "    \n",
        "    start_time = time.perf_counter()\n",
        "    for epoch_num in range(num_epochs):\n",
        "        epoch_enter = time.perf_counter()\n",
        "        for (steps, times, values) in dataset:\n",
        "            # Record dataset preparation informations\n",
        "            steps_acc = tf.concat((steps_acc, steps), axis=0)\n",
        "            times_acc = tf.concat((times_acc, times), axis=0)\n",
        "            values_acc = tf.concat((values_acc, values), axis=0)\n",
        "            \n",
        "            # Simulate training time\n",
        "            train_enter = time.perf_counter()\n",
        "            time.sleep(0.01)\n",
        "            train_elapsed = time.perf_counter() - train_enter\n",
        "            \n",
        "            # Record training informations\n",
        "            steps_acc = tf.concat((steps_acc, [[\"Train\"]]), axis=0)\n",
        "            times_acc = tf.concat((times_acc, [(train_enter, train_elapsed)]), axis=0)\n",
        "            values_acc = tf.concat((values_acc, [values[-1]]), axis=0)\n",
        "        \n",
        "        epoch_elapsed = time.perf_counter() - epoch_enter\n",
        "        # Record epoch informations\n",
        "        steps_acc = tf.concat((steps_acc, [[\"Epoch\"]]), axis=0)\n",
        "        times_acc = tf.concat((times_acc, [(epoch_enter, epoch_elapsed)]), axis=0)\n",
        "        values_acc = tf.concat((values_acc, [[-1, epoch_num, -1]]), axis=0)\n",
        "        time.sleep(0.001)\n",
        "    \n",
        "    tf.print(\"Execution time:\", time.perf_counter() - start_time)\n",
        "    return {\"steps\": steps_acc, \"times\": times_acc, \"values\": values_acc}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jw_WSQC8-jMs"
      },
      "source": [
        "### El método de graficado\n",
        "\n",
        "Por último, defina una función capaz de trazar una línea de tiempo dados los valores devueltos por la función `timelined_benchmark`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1j73RxiP-jMw"
      },
      "outputs": [],
      "source": [
        "def draw_timeline(timeline, title, width=0.5, annotate=False, save=False):\n",
        "    # Remove invalid entries (negative times, or empty steps) from the timelines\n",
        "    invalid_mask = np.logical_and(timeline['times'] > 0, timeline['steps'] != b'')[:,0]\n",
        "    steps = timeline['steps'][invalid_mask].numpy()\n",
        "    times = timeline['times'][invalid_mask].numpy()\n",
        "    values = timeline['values'][invalid_mask].numpy()\n",
        "    \n",
        "    # Get a set of different steps, ordered by the first time they are encountered\n",
        "    step_ids, indices = np.stack(np.unique(steps, return_index=True))\n",
        "    step_ids = step_ids[np.argsort(indices)]\n",
        "\n",
        "    # Shift the starting time to 0 and compute the maximal time value\n",
        "    min_time = times[:,0].min()\n",
        "    times[:,0] = (times[:,0] - min_time)\n",
        "    end = max(width, (times[:,0]+times[:,1]).max() + 0.01)\n",
        "    \n",
        "    cmap = mpl.cm.get_cmap(\"plasma\")\n",
        "    plt.close()\n",
        "    fig, axs = plt.subplots(len(step_ids), sharex=True, gridspec_kw={'hspace': 0})\n",
        "    fig.suptitle(title)\n",
        "    fig.set_size_inches(17.0, len(step_ids))\n",
        "    plt.xlim(-0.01, end)\n",
        "    \n",
        "    for i, step in enumerate(step_ids):\n",
        "        step_name = step.decode()\n",
        "        ax = axs[i]\n",
        "        ax.set_ylabel(step_name)\n",
        "        ax.set_ylim(0, 1)\n",
        "        ax.set_yticks([])\n",
        "        ax.set_xlabel(\"time (s)\")\n",
        "        ax.set_xticklabels([])\n",
        "        ax.grid(which=\"both\", axis=\"x\", color=\"k\", linestyle=\":\")\n",
        "        \n",
        "        # Get timings and annotation for the given step\n",
        "        entries_mask = np.squeeze(steps==step)\n",
        "        serie = np.unique(times[entries_mask], axis=0)\n",
        "        annotations = values[entries_mask]\n",
        "        \n",
        "        ax.broken_barh(serie, (0, 1), color=cmap(i / len(step_ids)), linewidth=1, alpha=0.66)\n",
        "        if annotate:\n",
        "            for j, (start, width) in enumerate(serie):\n",
        "                annotation = \"\\n\".join([f\"{l}: {v}\" for l,v in zip((\"i\", \"e\", \"s\"), annotations[j])])\n",
        "                ax.text(start + 0.001 + (0.001 * (j % 2)), 0.55 - (0.1 * (j % 2)), annotation,\n",
        "                        horizontalalignment='left', verticalalignment='center')\n",
        "    if save:\n",
        "        plt.savefig(title.lower().translate(str.maketrans(\" \", \"_\")) + \".svg\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xto6GNdO-jM1"
      },
      "source": [
        "### Usar contenedores para la función mapeada\n",
        "\n",
        "Para ejecutar la función mapeada en un contexto eager, debe contenerlas dentro de una llamada `tf.py_function`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "39v7JD4L-jM2"
      },
      "outputs": [],
      "source": [
        "def map_decorator(func):\n",
        "    def wrapper(steps, times, values):\n",
        "        # Use a tf.py_function to prevent auto-graph from compiling the method\n",
        "        return tf.py_function(\n",
        "            func,\n",
        "            inp=(steps, times, values),\n",
        "            Tout=(steps.dtype, times.dtype, values.dtype)\n",
        "        )\n",
        "    return wrapper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7eJRCinb-jM5"
      },
      "source": [
        "### Comparación de canalizaciones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YwX4ndHE-jM6"
      },
      "outputs": [],
      "source": [
        "_batch_map_num_items = 50\n",
        "\n",
        "def dataset_generator_fun(*args):\n",
        "    return TimeMeasuredDataset(num_samples=_batch_map_num_items)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwxJT2aR-jNA"
      },
      "source": [
        "#### Ingénuo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wLKgurx_-jNC"
      },
      "outputs": [],
      "source": [
        "@map_decorator\n",
        "def naive_map(steps, times, values):\n",
        "    map_enter = time.perf_counter()\n",
        "    time.sleep(0.001)  # Time consuming step\n",
        "    time.sleep(0.0001)  # Memory consuming step\n",
        "    map_elapsed = time.perf_counter() - map_enter\n",
        "\n",
        "    return (\n",
        "        tf.concat((steps, [[\"Map\"]]), axis=0),\n",
        "        tf.concat((times, [[map_enter, map_elapsed]]), axis=0),\n",
        "        tf.concat((values, [values[-1]]), axis=0)\n",
        "    )\n",
        "\n",
        "naive_timeline = timelined_benchmark(\n",
        "    tf.data.Dataset.range(2)\n",
        "    .flat_map(dataset_generator_fun)\n",
        "    .map(naive_map)\n",
        "    .batch(_batch_map_num_items, drop_remainder=True)\n",
        "    .unbatch(),\n",
        "    5\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJqUMDsO-jNG"
      },
      "source": [
        "### Optimizado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HYHcwabr-jNH"
      },
      "outputs": [],
      "source": [
        "@map_decorator\n",
        "def time_consuming_map(steps, times, values):\n",
        "    map_enter = time.perf_counter()\n",
        "    time.sleep(0.001 * values.shape[0])  # Time consuming step\n",
        "    map_elapsed = time.perf_counter() - map_enter\n",
        "\n",
        "    return (\n",
        "        tf.concat((steps, tf.tile([[[\"1st map\"]]], [steps.shape[0], 1, 1])), axis=1),\n",
        "        tf.concat((times, tf.tile([[[map_enter, map_elapsed]]], [times.shape[0], 1, 1])), axis=1),\n",
        "        tf.concat((values, tf.tile([[values[:][-1][0]]], [values.shape[0], 1, 1])), axis=1)\n",
        "    )\n",
        "\n",
        "\n",
        "@map_decorator\n",
        "def memory_consuming_map(steps, times, values):\n",
        "    map_enter = time.perf_counter()\n",
        "    time.sleep(0.0001 * values.shape[0])  # Memory consuming step\n",
        "    map_elapsed = time.perf_counter() - map_enter\n",
        "\n",
        "    # Use tf.tile to handle batch dimension\n",
        "    return (\n",
        "        tf.concat((steps, tf.tile([[[\"2nd map\"]]], [steps.shape[0], 1, 1])), axis=1),\n",
        "        tf.concat((times, tf.tile([[[map_enter, map_elapsed]]], [times.shape[0], 1, 1])), axis=1),\n",
        "        tf.concat((values, tf.tile([[values[:][-1][0]]], [values.shape[0], 1, 1])), axis=1)\n",
        "    )\n",
        "\n",
        "\n",
        "optimized_timeline = timelined_benchmark(\n",
        "    tf.data.Dataset.range(2)\n",
        "    .interleave(  # Parallelize data reading\n",
        "        dataset_generator_fun,\n",
        "        num_parallel_calls=tf.data.AUTOTUNE\n",
        "    )\n",
        "    .batch(  # Vectorize your mapped function\n",
        "        _batch_map_num_items,\n",
        "        drop_remainder=True)\n",
        "    .map(  # Parallelize map transformation\n",
        "        time_consuming_map,\n",
        "        num_parallel_calls=tf.data.AUTOTUNE\n",
        "    )\n",
        "    .cache()  # Cache data\n",
        "    .map(  # Reduce memory usage\n",
        "        memory_consuming_map,\n",
        "        num_parallel_calls=tf.data.AUTOTUNE\n",
        "    )\n",
        "    .prefetch(  # Overlap producer and consumer works\n",
        "        tf.data.AUTOTUNE\n",
        "    )\n",
        "    .unbatch(),\n",
        "    5\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b_CSUbxL-jNK"
      },
      "outputs": [],
      "source": [
        "draw_timeline(naive_timeline, \"Naive\", 15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DoovY7qr-jNR"
      },
      "outputs": [],
      "source": [
        "draw_timeline(optimized_timeline, \"Optimized\", 15)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "data_performance.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
