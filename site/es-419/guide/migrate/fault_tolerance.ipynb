{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJcYs_ERTnnI"
      },
      "source": [
        "##### Copyright 2021 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "HMUDt0CiUJk9"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77z2OchJTk0l"
      },
      "source": [
        "# Cómo migrar el mecanismo de tolerancia ante errores\n",
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>     <a target=\"_blank\" href=\"https://www.tensorflow.org/guide/migrate/fault_tolerance\">     <img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">     Ver en TensorFlow.org</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/es-419/guide/migrate/fault_tolerance.ipynb\">     <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">     Ejecutar en Google Colab</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/es-419/guide/migrate/fault_tolerance.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver código fuente en GitHub</a>\n",
        "</td>\n",
        "  <td><a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/es-419/guide/migrate/fault_tolerance.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Descargar bloc de notas</a></td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4O6fPyYTxZv"
      },
      "source": [
        "La tolerancia ante errores se refiere a un mecanismo de guardado periódico de los estados de objetos rastreables, como parámetros y modelos. Esto permite recuperarlos en caso de que falle el programa o la máquina durante el entrenamiento.\n",
        "\n",
        "En esta guía primero se muestra cómo incorporar la tolerancia ante errores al entrenamiento con `tf.estimator.Estimator` en TensorFlow 1 especificando el ahorro de métricas con `tf.estimator.RunConfig`. Después, aprenderá a implementar la tolerancia ante errores para el entrenamiento en TensorFlow 2 de dos maneras:\n",
        "\n",
        "- Si utiliza la API de Keras `Model.fit`, puede transferirle la retrollamada con `tf.keras.callbacks.BackupAndRestore`.\n",
        "- Si utiliza un bucle de entrenamiento personalizado (con `tf.GradientTape`), puede guardar arbitrariamente los puntos de verificación utilizando las API `tf.train.Checkpoint` y `tf.train.CheckpointManager`.\n",
        "\n",
        "Ambos métodos harán una copia de seguridad y restaurarán los estados de entrenamiento en los archivos de [puntos de verificación](../../guide/checkpoint.ipynb).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHJfmkCFUhQf"
      },
      "source": [
        "## Preparación"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOVQubuDzdmA"
      },
      "source": [
        "Instale `tf-nightly`, ya que la frecuencia de guardado de puntos de verificación en un paso concreto con el argumento `save_freq` en `tf.keras.callbacks.BackupAndRestore` se introduce a partir de TensorFlow 2.10:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pGW0XhXkxY_q"
      },
      "outputs": [],
      "source": [
        "!pip install tf-nightly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VXnPvQi8Ui1F"
      },
      "outputs": [],
      "source": [
        "import tensorflow.compat.v1 as tf1\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import tempfile\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tww-uIoiUlsT"
      },
      "outputs": [],
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TtlucRG_Uro_"
      },
      "source": [
        "## TensorFlow 1: Guardar los puntos de verificación con `tf.estimator.RunConfig`\n",
        "\n",
        "En TensorFlow 1, puede configurar un `tf.estimator` para guardar puntos de verificación en cada paso configurando `tf.estimator.RunConfig`.\n",
        "\n",
        "En este ejemplo, comience escribiendo un hook que arroje artificialmente un error durante el quinto punto de verificación:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q8shCkV2jKcc"
      },
      "outputs": [],
      "source": [
        "class InterruptHook(tf1.train.SessionRunHook):\n",
        "  # A hook for artificially interrupting training.\n",
        "  def begin(self):\n",
        "    self._step = -1\n",
        "\n",
        "  def before_run(self, run_context):\n",
        "    self._step += 1\n",
        "\n",
        "  def after_run(self, run_context, run_values):\n",
        "    if self._step == 5:\n",
        "      raise RuntimeError('Interruption')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXbQ6cFlkoIM"
      },
      "source": [
        "A continuación, configure `tf.estimator.Estimator` para guardar cada punto de verificación y utilice el conjunto de datos MNIST:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1EKXzi4Qj2Eb"
      },
      "outputs": [],
      "source": [
        "feature_columns = [tf1.feature_column.numeric_column(\"x\", shape=[28, 28])]\n",
        "config = tf1.estimator.RunConfig(save_summary_steps=1,\n",
        "                                 save_checkpoints_steps=1)\n",
        "\n",
        "path = tempfile.mkdtemp()\n",
        "\n",
        "classifier = tf1.estimator.DNNClassifier(\n",
        "    feature_columns=feature_columns,\n",
        "    hidden_units=[256, 32],\n",
        "    optimizer=tf1.train.AdamOptimizer(0.001),\n",
        "    n_classes=10,\n",
        "    dropout=0.2,\n",
        "    model_dir=path,\n",
        "    config = config\n",
        ")\n",
        "\n",
        "train_input_fn = tf1.estimator.inputs.numpy_input_fn(\n",
        "    x={\"x\": x_train},\n",
        "    y=y_train.astype(np.int32),\n",
        "    num_epochs=10,\n",
        "    batch_size=50,\n",
        "    shuffle=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGP7Nyenk1gr"
      },
      "source": [
        "Comience a entrenar el modelo. Se producirá una excepción artificial mediante el hook que definió anteriormente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xWKMsmt6jYSL"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  classifier.train(input_fn=train_input_fn,\n",
        "                   hooks=[InterruptHook()],\n",
        "                   max_steps=10)\n",
        "except Exception as e:\n",
        "  print(f'{type(e).__name__}:{e}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DekxJkgWk-4N"
      },
      "source": [
        "Vuelva a construir el `tf.estimator.Estimator` utilizando el último punto de verificación guardado y continúe con el entrenamiento:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vqMVTiJMjcH7"
      },
      "outputs": [],
      "source": [
        "classifier = tf1.estimator.DNNClassifier(\n",
        "    feature_columns=feature_columns,\n",
        "    hidden_units=[256, 32],\n",
        "    optimizer=tf1.train.AdamOptimizer(0.001),\n",
        "    n_classes=10,\n",
        "    dropout=0.2,\n",
        "    model_dir=path,\n",
        "    config = config\n",
        ")\n",
        "classifier.train(input_fn=train_input_fn,\n",
        "                   max_steps = 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5LtVtmvYx7J"
      },
      "source": [
        "## TensorFlow 2: Copia de seguridad y restauración con una retrollamada y `Model.fit`\n",
        "\n",
        "En TensorFlow 2, si utiliza la API Keras `Model.fit` para el entrenamiento, puede proporcionar la retrollamada `tf.keras.callbacks.BackupAndRestore` para incorporar la funcionalidad de tolerancia ante errores.\n",
        "\n",
        "Para ayudar a demostrar esto, en primer lugar comience por definir una clase de la `Callback` de Keras que produzca artificialmente un error durante el cuarto punto de verificación de la época:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ci3yB6A5lwJu"
      },
      "outputs": [],
      "source": [
        "class InterruptAtEpoch(tf.keras.callbacks.Callback):\n",
        "  # A callback for artificially interrupting training.\n",
        "  def __init__(self, interrupting_epoch=3):\n",
        "    self.interrupting_epoch = interrupting_epoch\n",
        "\n",
        "  def on_epoch_end(self, epoch, log=None):\n",
        "    if epoch == self.interrupting_epoch:\n",
        "      raise RuntimeError('Interruption')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhU3VTYZoDh-"
      },
      "source": [
        "A continuación, defina y cree una instancia de un modelo simple de Keras, defina la función de pérdida, llame a `Model.compile`, y configure una retrollamada `tf.keras.callbacks.BackupAndRestore` que guardará los puntos de verificación en un directorio temporal en los límites de las épocas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1VOQLDNkl2bl"
      },
      "outputs": [],
      "source": [
        "def create_model():\n",
        "  return tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(10)\n",
        "  ])\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "model = create_model()\n",
        "model.compile(optimizer='adam',\n",
        "              loss=loss,\n",
        "              metrics=['accuracy'])\n",
        "log_dir = tempfile.mkdtemp()\n",
        "backup_restore_callback = tf.keras.callbacks.BackupAndRestore(\n",
        "    backup_dir = log_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRRWmZqsvMrq"
      },
      "source": [
        "Comience a entrenar el modelo con `Model.fit`. Durante el entrenamiento, los puntos de verificación se guardarán gracias a `tf.keras.callbacks.BackupAndRestore` creado anteriormente, mientras que la clase `InterruptAtEpoch` generará una excepción artificial para simular un error después de la cuarta época."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8bVO79qWl4Uv"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  model.fit(x=x_train,\n",
        "            y=y_train,\n",
        "            epochs=10,\n",
        "            steps_per_epoch=100,\n",
        "            validation_data=(x_test, y_test),\n",
        "            callbacks=[backup_restore_callback, InterruptAtEpoch()])\n",
        "except Exception as e:\n",
        "  print(f'{type(e).__name__}:{e}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWidh234vcRf"
      },
      "source": [
        "Luego, cree una instancia del modelo Keras, llame a `Model.compile`, y continúe entrenando el modelo con `Model.fit` desde un punto de verificación guardado previamente:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3IWPH0Cmn2wi"
      },
      "outputs": [],
      "source": [
        "model = create_model()\n",
        "model.compile(optimizer='adam',\n",
        "              loss=loss,\n",
        "              metrics=['accuracy'],\n",
        "              steps_per_execution=10)\n",
        "model.fit(x=x_train,\n",
        "            y=y_train,\n",
        "            epochs=10,\n",
        "            steps_per_epoch=100,\n",
        "            validation_data=(x_test, y_test),\n",
        "            callbacks=[backup_restore_callback])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nP2dnpMPxtYj"
      },
      "source": [
        "Defina otra clase de la `Callback` que produzca artificialmente un error durante el paso 140:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YardkAaBxr-c"
      },
      "outputs": [],
      "source": [
        "class InterruptAtStep(tf.keras.callbacks.Callback):\n",
        "  # A callback for artificially interrupting training.\n",
        "  def __init__(self, interrupting_step=140):\n",
        "    self.total_step_count = 0\n",
        "    self.interrupting_step = interrupting_step\n",
        "\n",
        "  def on_batch_begin(self, batch, logs=None):\n",
        "    self.total_step_count += 1\n",
        "\n",
        "  def on_batch_end(self, batch, logs=None):\n",
        "    if self.total_step_count == self.interrupting_step:\n",
        "      print(\"\\nInterrupting at step count\", self.total_step_count)\n",
        "      raise RuntimeError('Interruption')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Af3VpehxyTpb"
      },
      "source": [
        "Nota: En esta sección se utilizan funciones que solo están disponibles en `tf-nightly` hasta que se publique Tensorflow 2.10.\n",
        "\n",
        "Para asegurarse de que los puntos de verificación se guardan cada 30 pasos, establezca `save_freq` en `BackupAndRestore` de la retrollamada a `30`. El `InterruptAtStep` producirá una excepción artificial para simular un error en la época 1 y el paso 40 (número total de pasos 140). El punto de verificación se guardaría por última vez en la época 1 y el paso 20."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dHHCENDPyUHS"
      },
      "outputs": [],
      "source": [
        "log_dir_2 = tempfile.mkdtemp()\n",
        "\n",
        "backup_restore_callback = tf.keras.callbacks.BackupAndRestore(\n",
        "    backup_dir = log_dir_2, save_freq=30\n",
        ")\n",
        "model = create_model()\n",
        "model.compile(optimizer='adam',\n",
        "              loss=loss,\n",
        "              metrics=['accuracy'])\n",
        "try:\n",
        "  model.fit(x=x_train,\n",
        "            y=y_train,\n",
        "            epochs=10,\n",
        "            steps_per_epoch=100,\n",
        "            validation_data=(x_test, y_test),\n",
        "            callbacks=[backup_restore_callback, InterruptAtStep()])\n",
        "except Exception as e:\n",
        "  print(f'{type(e).__name__}:{e}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-ggMFEHynMR"
      },
      "source": [
        "Posteriormente, cree una instancia del modelo de Keras, llame a `Model.compile`, y continúe entrenando el modelo con `Model.fit` desde un punto de verificación guardado previamente. Observe que el entrenamiento inicia desde la época 2 y el paso 21."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vT7Kx30NEqly"
      },
      "outputs": [],
      "source": [
        "model = create_model()\n",
        "model.compile(optimizer='adam',\n",
        "              loss=loss,\n",
        "              metrics=['accuracy'],\n",
        "              steps_per_execution=10)\n",
        "model.fit(x=x_train,\n",
        "            y=y_train,\n",
        "            epochs=10,\n",
        "            steps_per_epoch=100,\n",
        "            validation_data=(x_test, y_test),\n",
        "            callbacks=[backup_restore_callback])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdWexHUUaEB6"
      },
      "source": [
        "## TensorFlow 2: Escribiendo puntos de verificación manuales con un bucle de entrenamiento personalizado\n",
        "\n",
        "Si utiliza un bucle de entrenamiento personalizado en TensorFlow 2, puede implementar un mecanismo de tolerancia ante errores con las API `tf.train.Checkpoint` y `tf.train.CheckpointManager`.\n",
        "\n",
        "En este ejemplo se muestra cómo hacerlo:\n",
        "\n",
        "- Utilice un objeto `tf.train.Checkpoint` para crear manualmente un punto de verificación, donde los objetos rastreables que desea guardar se establezcan como atributos.\n",
        "- Utilice un `tf.train.CheckpointManager` para administrar varios puntos de verificación.\n",
        "\n",
        "Comience por definir y crear instancias del modelo Keras, el optimizador y la función de pérdida. Después, cree un `Checkpoint` que administre dos objetos con estados rastreables (el modelo y el optimizador), así como un `CheckpointManager` para registrar y mantener varios puntos de verificación en un directorio temporal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hPnIRKC8aDwE"
      },
      "outputs": [],
      "source": [
        "model = create_model()\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=0.001)\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "log_dir = tempfile.mkdtemp()\n",
        "epochs = 5\n",
        "steps_per_epoch = 5\n",
        "\n",
        "checkpoint = tf.train.Checkpoint(model=model, optimizer=optimizer)\n",
        "checkpoint_manager = tf.train.CheckpointManager(\n",
        "            checkpoint, log_dir, max_to_keep=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2tK4fm6xNkJ"
      },
      "source": [
        "Ahora, implemente un bucle de entrenamiento personalizado donde después de la primera época cada vez que comienza una nueva época se cargará el último punto de verificación:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GhQphF5jxPWU"
      },
      "outputs": [],
      "source": [
        "for epoch in range(epochs):\n",
        "  if epoch > 0:\n",
        "      tf.train.load_checkpoint(save_path)\n",
        "  print(f\"\\nStart of epoch {epoch}\")\n",
        "\n",
        "  for step in range(steps_per_epoch):\n",
        "    with tf.GradientTape() as tape:\n",
        "\n",
        "      logits = model(x_train, training=True)\n",
        "      loss_value = loss_fn(y_train, logits)\n",
        "\n",
        "      grads = tape.gradient(loss_value, model.trainable_weights)\n",
        "      optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
        "\n",
        "    save_path = checkpoint_manager.save()\n",
        "    print(f\"Checkpoint saved to {save_path}\")\n",
        "    print(f\"Training loss at step {step}: {loss_value}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQUS8nO9FZlH"
      },
      "source": [
        "## Siguientes pasos\n",
        "\n",
        "Para obtener más información sobre la tolerancia ante errores y la verificación de puntos en TensorFlow 2, consulte la siguiente documentación:\n",
        "\n",
        "- La documentación de la API de retrollamadas `tf.keras.callbacks.BackupAndRestore`.\n",
        "- La documentación de las API `tf.train.Checkpoint` y `tf.train.CheckpointManager`.\n",
        "- La guía [Puntos de verificación del entrenamiento](../../guide/checkpoint.ipynb), incluyendo la sección *Puntos de verificación de la escritura*.\n",
        "\n",
        "También podrá encontrar útil el siguiente material relacionado con el [entrenamiento distribuido](../..guide/distributed_training.ipynb):\n",
        "\n",
        "- La sección *Tolerancia ante errores* del tutorial [Entrenamiento multi-trabajador con Keras](../../tutorials/distribute/multi_worker_with_keras.ipynb).\n",
        "- La sección *Error de la tarea* en el tutorial [Entrenamiento del servidor de parámetros](../../tutorials/distribute/parameter_server_training.ipynb)."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "fault_tolerance.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
