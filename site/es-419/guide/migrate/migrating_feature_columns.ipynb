{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-23gBrt4x2B"
      },
      "source": [
        "##### Copyright 2021 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "HMUDt0CiUJk9"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77z2OchJTk0l"
      },
      "source": [
        "# Migrar `tf.feature_column` a capas de preprocesamiento Keras\n",
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td><a target=\"_blank\" href=\"https://www.tensorflow.org/guide/migrate/migrating_feature_columns\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver en TensorFlow.org</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/es-419/guide/migrate/migrating_feature_columns.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Ejecutar en Google Colab</a></td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/es-419/guide/migrate/migrating_feature_columns.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver código fuente en GitHub</a>\n",
        "</td>\n",
        "  <td><a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/es-419/guide/migrate/migrating_feature_columns.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Descargar bloc de notas</a></td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5jGPDA2PDPI"
      },
      "source": [
        "El entrenamiento de un modelo suele ir acompañado de una cierta cantidad de preprocesamiento de características, sobre todo cuando se trata de datos estructurados. Cuando se entrena un `tf.estimator.Estimator` en TensorFlow 1, normalmente se realiza el preprocesamiento de características con la API `tf.feature_column`. En TensorFlow 2, puede hacerlo directamente con las capas de preprocesamiento de Keras.\n",
        "\n",
        "Esta guía de migración demuestra las transformaciones comunes de las características usando ambas columnas de características y capas de preprocesamiento, seguidas del entrenamiento de un modelo completo con ambas API.\n",
        "\n",
        "En primer lugar, comience con un par de imports necesarios:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iE0vSfMXumKI"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.compat.v1 as tf1\n",
        "import math"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVPYTQAWtDwH"
      },
      "source": [
        "A continuación, añada una función de servicio para llamar a una columna de características para demostración:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LAaifuuytJjM"
      },
      "outputs": [],
      "source": [
        "def call_feature_columns(feature_columns, inputs):\n",
        "  # This is a convenient way to call a `feature_column` outside of an estimator\n",
        "  # to display its output.\n",
        "  feature_layer = tf1.keras.layers.DenseFeatures(feature_columns)\n",
        "  return feature_layer(inputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJnw07hYDGYt"
      },
      "source": [
        "## Manejo de entradas\n",
        "\n",
        "Para usar columnas de características con un estimador, siempre se espera que las entradas del modelo sean un diccionario de tensores:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y0WUpQxsKEzf"
      },
      "outputs": [],
      "source": [
        "input_dict = {\n",
        "  'foo': tf.constant([1]),\n",
        "  'bar': tf.constant([0]),\n",
        "  'baz': tf.constant([-1])\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYsC6H_BJ8l3"
      },
      "source": [
        "Cada columna de características debe crearse con una clave para indexarla en los datos de origen. La salida de todas las columnas de características se concatena y es usada por el modelo de estimación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3fvIe3V8Ffjt"
      },
      "outputs": [],
      "source": [
        "columns = [\n",
        "  tf1.feature_column.numeric_column('foo'),\n",
        "  tf1.feature_column.numeric_column('bar'),\n",
        "  tf1.feature_column.numeric_column('baz'),\n",
        "]\n",
        "call_feature_columns(columns, input_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvPfCK2XGTyl"
      },
      "source": [
        "En Keras, la entrada del modelo es mucho más flexible. Un `tf.keras.Model` puede manejar una única entrada de tensor, una lista de características de tensor o un diccionario de características de tensor. Usted puede manejar la entrada de diccionario pasando un diccionario de `tf.keras.Input` en la creación del modelo. Las entradas no se concatenarán automáticamente, lo que permite usarlas de formas mucho más flexibles. Pueden concatenarse con `tf.keras.layers.Concatenate`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5sYWENkgLWJ2"
      },
      "outputs": [],
      "source": [
        "inputs = {\n",
        "  'foo': tf.keras.Input(shape=()),\n",
        "  'bar': tf.keras.Input(shape=()),\n",
        "  'baz': tf.keras.Input(shape=()),\n",
        "}\n",
        "# Inputs are typically transformed by preprocessing layers before concatenation.\n",
        "outputs = tf.keras.layers.Concatenate()(inputs.values())\n",
        "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "model(input_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXkmiuwXTS-B"
      },
      "source": [
        "## Codificación de un solo paso de ID enteros\n",
        "\n",
        "Una transformación de características común es la codificación de un solo paso de entradas enteras de un rango conocido. He aquí un ejemplo usando columnas de características:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XasXzOgatgRF"
      },
      "outputs": [],
      "source": [
        "categorical_col = tf1.feature_column.categorical_column_with_identity(\n",
        "    'type', num_buckets=3)\n",
        "indicator_col = tf1.feature_column.indicator_column(categorical_col)\n",
        "call_feature_columns(indicator_col, {'type': [0, 1, 2]})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSCkJEQ6U-ru"
      },
      "source": [
        "Usando capas de preprocesamiento Keras, estas columnas pueden ser sustituidas por una única capa `tf.keras.layers.CategoryEncoding` con `output_mode` configurado como `'one_hot'`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "799lbMNNuAVz"
      },
      "outputs": [],
      "source": [
        "one_hot_layer = tf.keras.layers.CategoryEncoding(\n",
        "    num_tokens=3, output_mode='one_hot')\n",
        "one_hot_layer([0, 1, 2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNzRtESU7tga"
      },
      "source": [
        "Nota: Para codificaciones grandes de un solo paso, es mucho más eficiente usar una representación sparse de la salida. Si pasa `sparse=True` a la capa `CategoryEncoding`, la salida de la capa será un `tf.sparse.SparseTensor`, que puede manejarse eficientemente como entrada a una capa `tf.keras.layers.Dense`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zf7kjhTiAErK"
      },
      "source": [
        "## Normalización de características numéricas\n",
        "\n",
        "Cuando maneje características continuas de punto flotante con columnas de características, deberá usar una `tf.feature_column.numeric_column`. En caso de que la entrada ya esté normalizada, convertir esto en Keras es trivial. Puede simplemente usar un `tf.keras.Input` directamente en su modelo, como se muestra arriba.\n",
        "\n",
        "También se puede usar una `numeric_column` para normalizar la entrada:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HbTMGB9XctGx"
      },
      "outputs": [],
      "source": [
        "def normalize(x):\n",
        "  mean, variance = (2.0, 1.0)\n",
        "  return (x - mean) / math.sqrt(variance)\n",
        "numeric_col = tf1.feature_column.numeric_column('col', normalizer_fn=normalize)\n",
        "call_feature_columns(numeric_col, {'col': tf.constant([[0.], [1.], [2.]])})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9cyhPR_drOz"
      },
      "source": [
        "En cambio, con Keras, esta normalización puede realizarse con `tf.keras.layers.Normalization`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8bcgG-yOdqUH"
      },
      "outputs": [],
      "source": [
        "normalization_layer = tf.keras.layers.Normalization(mean=2.0, variance=1.0)\n",
        "normalization_layer(tf.constant([[0.], [1.], [2.]]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1InD_4QLKU-"
      },
      "source": [
        "## Cubicación y codificación de características numéricas en un solo paso"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5e0b8iOLRzd"
      },
      "source": [
        "Otra transformación común de entradas continuas en punto flotante es cubicarlas a continuación a enteros de un rango fijo.\n",
        "\n",
        "En las columnas de características, esto puede lograrse con una `tf.feature_column.bucketized_column`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_rbx6qQ-LQx7"
      },
      "outputs": [],
      "source": [
        "numeric_col = tf1.feature_column.numeric_column('col')\n",
        "bucketized_col = tf1.feature_column.bucketized_column(numeric_col, [1, 4, 5])\n",
        "call_feature_columns(bucketized_col, {'col': tf.constant([1., 2., 3., 4., 5.])})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCYu-XtwXahx"
      },
      "source": [
        "En Keras, esto puede ser sustituido por `tf.keras.layers.Discretization`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QK1WOG2uVVsL"
      },
      "outputs": [],
      "source": [
        "discretization_layer = tf.keras.layers.Discretization(bin_boundaries=[1, 4, 5])\n",
        "one_hot_layer = tf.keras.layers.CategoryEncoding(\n",
        "    num_tokens=4, output_mode='one_hot')\n",
        "one_hot_layer(discretization_layer([1., 2., 3., 4., 5.]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bm9tJZAgpt4"
      },
      "source": [
        "## Codificación de un solo paso para datos de cadena con un vocabulario\n",
        "\n",
        "El manejo de características de cadena a menudo requiere una búsqueda de vocabulario para traducir las cadenas en índices. Aquí tiene un ejemplo en el que se usan columnas de características para buscar cadenas y luego codificar los índices de un solo paso:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3fG_igjhukCO"
      },
      "outputs": [],
      "source": [
        "vocab_col = tf1.feature_column.categorical_column_with_vocabulary_list(\n",
        "    'sizes',\n",
        "    vocabulary_list=['small', 'medium', 'large'],\n",
        "    num_oov_buckets=0)\n",
        "indicator_col = tf1.feature_column.indicator_column(vocab_col)\n",
        "call_feature_columns(indicator_col, {'sizes': ['small', 'medium', 'large']})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rBgllRtY738"
      },
      "source": [
        "Usando capas de preprocesamiento Keras, use la capa `tf.keras.layers.StringLookup` con `output_mode` configurado a `'one_hot'`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "arnPlSrWvDMe"
      },
      "outputs": [],
      "source": [
        "string_lookup_layer = tf.keras.layers.StringLookup(\n",
        "    vocabulary=['small', 'medium', 'large'],\n",
        "    num_oov_indices=0,\n",
        "    output_mode='one_hot')\n",
        "string_lookup_layer(['small', 'medium', 'large'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f76MVVYO8LB5"
      },
      "source": [
        "Nota: Para codificaciones grandes de un solo paso, es mucho más eficiente usar una representación dispersa de la salida. Si pasa `sparse=True` a la capa `StringLookup`, la salida de la capa será un `tf.sparse.SparseTensor`, que puede manejarse eficientemente como entrada a una capa `tf.keras.layers.Dense`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1CmfSXQZHE5"
      },
      "source": [
        "## Incorporación de datos de cadena con un vocabulario\n",
        "\n",
        "En el caso de vocabularios más extensos, suele ser necesaria una incorporación para obtener un buen rendimiento. Aquí tiene un ejemplo de incorporación de una característica de cadena usando columnas de características:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C3RK4HFazxlU"
      },
      "outputs": [],
      "source": [
        "vocab_col = tf1.feature_column.categorical_column_with_vocabulary_list(\n",
        "    'col',\n",
        "    vocabulary_list=['small', 'medium', 'large'],\n",
        "    num_oov_buckets=0)\n",
        "embedding_col = tf1.feature_column.embedding_column(vocab_col, 4)\n",
        "call_feature_columns(embedding_col, {'col': ['small', 'medium', 'large']})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3aTRVJ6qZZH0"
      },
      "source": [
        "Usando capas de preprocesamiento Keras, esto se puede conseguir combinando una capa `tf.keras.layers.StringLookup` y una capa `tf.keras.layers.Embedding`. La salida por default de la capa `StringLookup` serán índices enteros que pueden introducirse directamente en una incorporación.\n",
        "\n",
        "Nota: La capa `Embedding` contiene parámetros entrenables. Mientras que la capa `StringLookup` puede aplicarse a datos dentro o fuera de un modelo, la capa `Embedding` siempre debe formar parte de un modelo Keras entrenable a fin de entrenar correctamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8resGZPo0Fho"
      },
      "outputs": [],
      "source": [
        "string_lookup_layer = tf.keras.layers.StringLookup(\n",
        "    vocabulary=['small', 'medium', 'large'], num_oov_indices=0)\n",
        "embedding = tf.keras.layers.Embedding(3, 4)\n",
        "embedding(string_lookup_layer(['small', 'medium', 'large']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwqvADV6HRdC"
      },
      "source": [
        "## Suma de datos categóricos ponderados\n",
        "\n",
        "En algunos casos, es necesario tratar datos categóricos en los que cada aparición de una categoría lleva asociada una ponderación. En las columnas de características, esto se gestiona con `tf.feature_column.weighted_categorical_column`. Cuando se combina con una `indicator_column`, tiene el efecto de sumar las ponderaciones por categoría."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "02HqjPLMRxWn"
      },
      "outputs": [],
      "source": [
        "ids = tf.constant([[5, 11, 5, 17, 17]])\n",
        "weights = tf.constant([[0.5, 1.5, 0.7, 1.8, 0.2]])\n",
        "\n",
        "categorical_col = tf1.feature_column.categorical_column_with_identity(\n",
        "    'ids', num_buckets=20)\n",
        "weighted_categorical_col = tf1.feature_column.weighted_categorical_column(\n",
        "    categorical_col, 'weights')\n",
        "indicator_col = tf1.feature_column.indicator_column(weighted_categorical_col)\n",
        "call_feature_columns(indicator_col, {'ids': ids, 'weights': weights})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98jaq7Q3S9aG"
      },
      "source": [
        "En Keras, esto puede hacerse pasando una entrada `count_weights` a `tf.keras.layers.CategoryEncoding` con `output_mode='count'`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JsoYUUgRS7hu"
      },
      "outputs": [],
      "source": [
        "ids = tf.constant([[5, 11, 5, 17, 17]])\n",
        "weights = tf.constant([[0.5, 1.5, 0.7, 1.8, 0.2]])\n",
        "\n",
        "# Using sparse output is more efficient when `num_tokens` is large.\n",
        "count_layer = tf.keras.layers.CategoryEncoding(\n",
        "    num_tokens=20, output_mode='count', sparse=True)\n",
        "tf.sparse.to_dense(count_layer(ids, count_weights=weights))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBJxb6y2GasI"
      },
      "source": [
        "## Incorporación de datos categóricos ponderados\n",
        "\n",
        "Es posible que, alternativamente, desee incorporar entradas categóricas ponderadas. En las columnas de características, la `embedding_column` contiene un argumento `combiner`. Si algún muestreo contiene varias entradas para una categoría, se combinarán según lo establecido en el argumento (por defecto `'mean'`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AjOt1wgmT5mM"
      },
      "outputs": [],
      "source": [
        "ids = tf.constant([[5, 11, 5, 17, 17]])\n",
        "weights = tf.constant([[0.5, 1.5, 0.7, 1.8, 0.2]])\n",
        "\n",
        "categorical_col = tf1.feature_column.categorical_column_with_identity(\n",
        "    'ids', num_buckets=20)\n",
        "weighted_categorical_col = tf1.feature_column.weighted_categorical_column(\n",
        "    categorical_col, 'weights')\n",
        "embedding_col = tf1.feature_column.embedding_column(\n",
        "    weighted_categorical_col, 4, combiner='mean')\n",
        "call_feature_columns(embedding_col, {'ids': ids, 'weights': weights})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fd6eluARXndC"
      },
      "source": [
        "En Keras, no existe la opción `combiner` para `tf.keras.layers.Embedding`, pero puede conseguir el mismo efecto con `tf.keras.layers.Dense`. La `embedding_column` anterior es simplemente la combinación lineal de vectores de incorporación según la ponderación de la categoría. Aunque no resulte obvio a primera vista, es exactamente equivalente a representar sus entradas categóricas como un vector de ponderación disperso de tamaño `(num_tokens)`, y multiplicarlos por un kernel `Dense` de forma `(embedding_size, num_tokens)`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y-vZvPyiYilE"
      },
      "outputs": [],
      "source": [
        "ids = tf.constant([[5, 11, 5, 17, 17]])\n",
        "weights = tf.constant([[0.5, 1.5, 0.7, 1.8, 0.2]])\n",
        "\n",
        "# For `combiner='mean'`, normalize your weights to sum to 1. Removing this line\n",
        "# would be equivalent to an `embedding_column` with `combiner='sum'`.\n",
        "weights = weights / tf.reduce_sum(weights, axis=-1, keepdims=True)\n",
        "\n",
        "count_layer = tf.keras.layers.CategoryEncoding(\n",
        "    num_tokens=20, output_mode='count', sparse=True)\n",
        "embedding_layer = tf.keras.layers.Dense(4, use_bias=False)\n",
        "embedding_layer(count_layer(ids, count_weights=weights))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3I5loEx80MVm"
      },
      "source": [
        "## Ejemplo de entrenamiento completo\n",
        "\n",
        "Para mostrar un flujo de trabajo de entrenamiento completo, prepare primero algunos datos con tres características de distintos tipos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D_7nyBee0ZBV"
      },
      "outputs": [],
      "source": [
        "features = {\n",
        "    'type': [0, 1, 1],\n",
        "    'size': ['small', 'small', 'medium'],\n",
        "    'weight': [2.7, 1.8, 1.6],\n",
        "}\n",
        "labels = [1, 1, 0]\n",
        "predict_features = {'type': [0], 'size': ['foo'], 'weight': [-0.7]}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_4Xx2c37lqD"
      },
      "source": [
        "Defina algunas constantes comunes para los flujos de trabajo TensorFlow 1 y TensorFlow 2:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3cyfQZ7z8jZh"
      },
      "outputs": [],
      "source": [
        "vocab = ['small', 'medium', 'large']\n",
        "one_hot_dims = 3\n",
        "embedding_dims = 4\n",
        "weight_mean = 2.0\n",
        "weight_variance = 1.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywCgU7CMIfTH"
      },
      "source": [
        "### Con columnas de características\n",
        "\n",
        "Las columnas de características deben pasarse como una lista al estimador en el momento de la creación, y se llamarán implícitamente durante el entrenamiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wsdhlm-uipr1"
      },
      "outputs": [],
      "source": [
        "categorical_col = tf1.feature_column.categorical_column_with_identity(\n",
        "    'type', num_buckets=one_hot_dims)\n",
        "# Convert index to one-hot; e.g. [2] -> [0,0,1].\n",
        "indicator_col = tf1.feature_column.indicator_column(categorical_col)\n",
        "\n",
        "# Convert strings to indices; e.g. ['small'] -> [1].\n",
        "vocab_col = tf1.feature_column.categorical_column_with_vocabulary_list(\n",
        "    'size', vocabulary_list=vocab, num_oov_buckets=1)\n",
        "# Embed the indices.\n",
        "embedding_col = tf1.feature_column.embedding_column(vocab_col, embedding_dims)\n",
        "\n",
        "normalizer_fn = lambda x: (x - weight_mean) / math.sqrt(weight_variance)\n",
        "# Normalize the numeric inputs; e.g. [2.0] -> [0.0].\n",
        "numeric_col = tf1.feature_column.numeric_column(\n",
        "    'weight', normalizer_fn=normalizer_fn)\n",
        "\n",
        "estimator = tf1.estimator.DNNClassifier(\n",
        "    feature_columns=[indicator_col, embedding_col, numeric_col],\n",
        "    hidden_units=[1])\n",
        "\n",
        "def _input_fn():\n",
        "  return tf1.data.Dataset.from_tensor_slices((features, labels)).batch(1)\n",
        "\n",
        "estimator.train(_input_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPIeG_YtfNV1"
      },
      "source": [
        "Las columnas de características también se usarán para transformar los datos de entrada cuando se ejecute la inferencia en el modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-AIIB8CfSqt"
      },
      "outputs": [],
      "source": [
        "def _predict_fn():\n",
        "  return tf1.data.Dataset.from_tensor_slices(predict_features).batch(1)\n",
        "\n",
        "next(estimator.predict(_predict_fn))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baMA01cBIivo"
      },
      "source": [
        "### Con las capas de preprocesamiento Keras\n",
        "\n",
        "Las capas Keras de preprocesamiento son más flexibles en cuanto a dónde pueden ser llamadas. Una capa puede aplicarse directamente a los tensores, usarse dentro de una canalización de entrada `tf.data`, o integrarse directamente en un modelo Keras entrenable.\n",
        "\n",
        " En este ejemplo, aplicará capas de preprocesamiento dentro de una canalización de entrada `tf.data`. Para ello, puede definir un `tf.keras.Model` separado para preprocesar sus características de entrada. Este modelo no es entrenable, pero es una forma conveniente de agrupar las capas de preprocesamiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NMz8RfMQdCZf"
      },
      "outputs": [],
      "source": [
        "inputs = {\n",
        "  'type': tf.keras.Input(shape=(), dtype='int64'),\n",
        "  'size': tf.keras.Input(shape=(), dtype='string'),\n",
        "  'weight': tf.keras.Input(shape=(), dtype='float32'),\n",
        "}\n",
        "# Convert index to one-hot; e.g. [2] -> [0,0,1].\n",
        "type_output = tf.keras.layers.CategoryEncoding(\n",
        "      one_hot_dims, output_mode='one_hot')(inputs['type'])\n",
        "# Convert size strings to indices; e.g. ['small'] -> [1].\n",
        "size_output = tf.keras.layers.StringLookup(vocabulary=vocab)(inputs['size'])\n",
        "# Normalize the numeric inputs; e.g. [2.0] -> [0.0].\n",
        "weight_output = tf.keras.layers.Normalization(\n",
        "      axis=None, mean=weight_mean, variance=weight_variance)(inputs['weight'])\n",
        "outputs = {\n",
        "  'type': type_output,\n",
        "  'size': size_output,\n",
        "  'weight': weight_output,\n",
        "}\n",
        "preprocessing_model = tf.keras.Model(inputs, outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRfISnj3NGlW"
      },
      "source": [
        "Nota: Como alternativa a suministrar un vocabulario y estadísticas de normalización en la creación de capas, muchas capas de preprocesamiento ofrecen un método `adapt()` para aprender el estado de la capa directamente a partir de los datos de entrada. Consulte la [guía de preprocesamiento](https://www.tensorflow.org/guide/keras/preprocessing_layers#the_adapt_method) para más detalles.\n",
        "\n",
        "Ahora puede aplicar este modelo dentro de una llamada a `tf.data.Dataset.map`. Tenga en cuenta que la función pasada a `map` se convertirá automáticamente en una `tf.function`, y se aplicarán las advertencias habituales para escribir código `tf.function` (sin efectos secundarios)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c_6xAUnbNREh"
      },
      "outputs": [],
      "source": [
        "# Apply the preprocessing in tf.data.Dataset.map.\n",
        "dataset = tf.data.Dataset.from_tensor_slices((features, labels)).batch(1)\n",
        "dataset = dataset.map(lambda x, y: (preprocessing_model(x), y),\n",
        "                      num_parallel_calls=tf.data.AUTOTUNE)\n",
        "# Display a preprocessed input sample.\n",
        "next(dataset.take(1).as_numpy_iterator())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_4u3J4NdJ8R"
      },
      "source": [
        "A continuación, puede definir un `Model` independiente que contenga las capas entrenables. Tenga en cuenta cómo las entradas a este modelo reflejan ahora los tipos de características y formas preprocesadas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kC9OZO5ldmP-"
      },
      "outputs": [],
      "source": [
        "inputs = {\n",
        "  'type': tf.keras.Input(shape=(one_hot_dims,), dtype='float32'),\n",
        "  'size': tf.keras.Input(shape=(), dtype='int64'),\n",
        "  'weight': tf.keras.Input(shape=(), dtype='float32'),\n",
        "}\n",
        "# Since the embedding is trainable, it needs to be part of the training model.\n",
        "embedding = tf.keras.layers.Embedding(len(vocab), embedding_dims)\n",
        "outputs = tf.keras.layers.Concatenate()([\n",
        "  inputs['type'],\n",
        "  embedding(inputs['size']),\n",
        "  tf.expand_dims(inputs['weight'], -1),\n",
        "])\n",
        "outputs = tf.keras.layers.Dense(1)(outputs)\n",
        "training_model = tf.keras.Model(inputs, outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ir-cn2H_d5R7"
      },
      "source": [
        "Ahora puede entrenar el `training_model` con `tf.keras.Model.fit`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6TS3YJ2vnvlW"
      },
      "outputs": [],
      "source": [
        "# Train on the preprocessed data.\n",
        "training_model.compile(\n",
        "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True))\n",
        "training_model.fit(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSaEbOE4ecsy"
      },
      "source": [
        "Por último, en el momento de la inferencia, puede ser útil combinar estas etapas separadas en un único modelo que maneje las entradas de características brutas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QHjbIZYneboO"
      },
      "outputs": [],
      "source": [
        "inputs = preprocessing_model.input\n",
        "outputs = training_model(preprocessing_model(inputs))\n",
        "inference_model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "predict_dataset = tf.data.Dataset.from_tensor_slices(predict_features).batch(1)\n",
        "inference_model.predict(predict_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O01VQIxCWBxU"
      },
      "source": [
        "Este modelo compuesto puede guardarse como archivo `.keras` para usarlo posteriormente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6tsyVZgh7Pve"
      },
      "outputs": [],
      "source": [
        "inference_model.save('model.keras')\n",
        "restored_model = tf.keras.models.load_model('model.keras')\n",
        "restored_model.predict(predict_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXMBwzggwUjI"
      },
      "source": [
        "Nota: Las capas de preprocesamiento no son entrenables, lo que le permite aplicarlas *asincrónicamente* usando `tf.data`. Esto tiene beneficios para el rendimiento, ya que puede preextraer lotes preprocesados y liberar cualquier acelerador para que se enfoque en las partes diferenciables de un modelo (más información en la sección *Preextracción* de la guía <a href=\"../data_performance.ipynb\" data-md-type=\"link\"> Mejor rendimiento con la API `tf.data`</a>). Como muestra esta guía, separar el preprocesamiento durante el entrenamiento y componerlo durante la inferencia es una forma flexible de aprovechar estas ganancias de rendimiento. Sin embargo, si su modelo es pequeño o el tiempo de preprocesamiento es insignificante, puede ser más sencillo construir el preprocesamiento en un modelo completo desde el principio. Para ello, puede construir un modelo único que comience con `tf.keras.Input`, seguido de las capas de preprocesamiento, seguidas de las capas entrenables."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pjp7Z18gRCQ"
      },
      "source": [
        "## Tabla de equivalencias de columnas de características\n",
        "\n",
        "A modo de referencia, he aquí una correspondencia aproximada entre las columnas de características y las capas de preprocesamiento de Keras:\n",
        "\n",
        "<table>\n",
        "<div>  <tr>\n",
        "    <th>Columna de características</th>\n",
        "    <th>Capas Keras</th>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>`tf.feature_column.bucketized_column`</td>\n",
        "    <td>`tf.keras.layers.Discretization`</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>`tf.feature_column.categorical_column_with_hash_bucket`</td>\n",
        "    <td>`tf.keras.layers.Hashing`</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>`tf.feature_column.categorical_column_with_identity`</td>\n",
        "    <td>`tf.keras.layers.CategoryEncoding`</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>`tf.feature_column.categorical_column_with_vocabulary_file`</td>\n",
        "    <td>`tf.keras.layers.StringLookup` o `tf.keras.layers.IntegerLookup`</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>`tf.feature_column.categorical_column_with_vocabulary_list`</td>\n",
        "    <td>`tf.keras.layers.StringLookup` o `tf.keras.layers.IntegerLookup`</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>`tf.feature_column.crossed_column`</td>\n",
        "    <td>`tf.keras.layers.experimental.preprocessing.HashedCrossing`</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>`tf.feature_column.embedding_column`</td>\n",
        "    <td>`tf.keras.layers.Embedding`</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>`tf.feature_column.indicator_column`</td>\n",
        "    <td>`output_mode='one_hot'` o `output_mode='multi_hot'`*</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>`tf.feature_column.numeric_column`</td>\n",
        "    <td>`tf.keras.layers.Normalization`</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>`tf.feature_column.sequence_categorical_column_with_hash_bucket`</td>\n",
        "    <td>`tf.keras.layers.Hashing`</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>`tf.feature_column.sequence_categorical_column_with_identity`</td>\n",
        "    <td>`tf.keras.layers.CategoryEncoding`</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>`tf.feature_column.sequence_categorical_column_with_vocabulary_file`</td>\n",
        "    <td>`tf.keras.layers.StringLookup`, `tf.keras.layers.IntegerLookup`, o `tf.keras.layer.TextVectorization`†</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>`tf.feature_column.sequence_categorical_column_with_vocabulary_list`</td>\n",
        "    <td>`tf.keras.layers.StringLookup`, `tf.keras.layers.IntegerLookup`, o `tf.keras.layer.TextVectorization`†</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>`tf.feature_column.sequence_numeric_column`</td>\n",
        "    <td>`tf.keras.layers.Normalization`</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>`tf.feature_column.weighted_categorical_column`</td>\n",
        "    <td>`tf.keras.layers.CategoryEncoding`</td>\n",
        "  </tr>\n",
        "</div>\n",
        "</table>\n",
        "\n",
        "* El `output_mode` puede pasarse a `tf.keras.layers.CategoryEncoding`, `tf.keras.layers.StringLookup`, `tf.keras.layers.IntegerLookup`, y `tf.keras.layers.TextVectorization`.\n",
        "\n",
        "† `tf.keras.layers.TextVectorization` puede manejar directamente la entrada de texto de forma libre (por ejemplo, frases o párrafos enteros). Esto no es un reemplazo uno-a-uno para el manejo de secuencias categóricas en TensorFlow 1, pero puede ofrecer un reemplazo conveniente para el preprocesamiento de texto ad-hoc.\n",
        "\n",
        "Nota: Los estimadores lineales, como `tf.estimator.LinearClassifier`, pueden manejar entradas categóricas directas (índices enteros) sin una `embedding_column` o `indicator_column`. Sin embargo, los índices enteros no pueden pasarse directamente a `tf.keras.layers.Dense` o `tf.keras.experimental.LinearModel`. Estas entradas deben codificarse primero con `tf.layers.CategoryEncoding` con `output_mode='count'` (y `sparse=True` si el tamaño de las categorías es grande) antes de llamar a `Dense` o `LinearModel`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQCJ6lM3YDq_"
      },
      "source": [
        "## Siguientes pasos\n",
        "\n",
        "- Para obtener más información sobre las capas de preprocesamiento de Keras, consulte la guía [Trabajar con capas de preprocesamiento](https://www.tensorflow.org/guide/keras/preprocessing_layers).\n",
        "- Para ver un ejemplo más detallado de cómo aplicar capas de preprocesamiento a datos estructurados, consulte el tutorial [Clasificar datos estructurados utilizando capas de preprocesamiento Keras](../../tutorials/structured_data/preprocessing_layers.ipynb)."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "migrating_feature_columns.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
