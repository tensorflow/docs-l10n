{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FEL3NlTTDlSX"
      },
      "source": [
        "##### Copyright 2021 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "FlUw7tSKbtg4"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77z2OchJTk0l"
      },
      "source": [
        "# Depurar una canalización de entrenamiento migrada de TensorFlow 2\n",
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td><a target=\"_blank\" href=\"https://www.tensorflow.org/guide/migrate/migration_debugging\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver en TensorFlow.org</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/es-419/guide/migrate/migration_debugging.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Ejecutar en Google Colab</a></td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/es-419/guide/migrate/migration_debugging.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver código fuente en GitHub</a>\n",
        "</td>\n",
        "  <td><a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/es-419/guide/migrate/migration_debugging.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Descargar bloc de notas</a></td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTwPu-w6M5sz"
      },
      "source": [
        "Este bloc de notas muestra cómo depurar una canalización de entrenamiento al migrar a TensorFlow 2 (TF2). Consta de los siguientes componentes:\n",
        "\n",
        "1. Pasos sugeridos y muestras de código para depurar la canalización del entrenamiento\n",
        "2. Herramientas para la depuración\n",
        "3. Otros recursos relacionados\n",
        "\n",
        "Una premisa es que usted tiene el código en TensorFlow 1 (TF1.x) y los modelos entrenados para su comparación, y desea construir un modelo TF2 que alcance una precisión de validación similar.\n",
        "\n",
        "Este bloc de notas **NO** cubre la depuración de problemas de rendimiento para la velocidad de entrenamiento/inferencia o el uso de memoria."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKm9R4CtOAP3"
      },
      "source": [
        "## Depuración del flujo de trabajo\n",
        "\n",
        "Más abajo encontrará un flujo de trabajo general para depurar sus canalizaciones de entrenamiento en TF2. Tenga en cuenta que no es necesario que siga estos pasos en orden. También puede usar un enfoque de búsqueda binaria en el que pruebe el modelo en un paso intermedio y reduzca el alcance de la depuración.\n",
        "\n",
        "1. Corregir errores de compilación y runtime\n",
        "\n",
        "2. Validación de una sola pasada hacia delante (en una [guía](./validate_correctness.ipynb) por separado)\n",
        "\n",
        "    a. En un dispositivo con una sola CPU\n",
        "\n",
        "    - Verificar que las variables se crean una sola vez\n",
        "    - Compruebe que los recuentos, nombres y formas de las variables coinciden\n",
        "    - Restablecer todas las variables, comprobar la equivalencia numérica con toda la aleatoriedad desactivada\n",
        "    - Alinear la generación de números aleatorios, comprobar la equivalencia numérica en la inferencia\n",
        "    - (Opcional) Los puntos de verificación se cargan correctamente y los modelos TF1.x/TF2 generan una salida idéntica\n",
        "\n",
        "    b. En un único dispositivo GPU/TPU\n",
        "\n",
        "    c. Con estrategias multidispositivo\n",
        "\n",
        "3. Modelar el entrenamiento de validación de equivalencia numérica para unos pocos pasos (ejemplos de código disponibles a continuación)\n",
        "\n",
        "    a. Validación de un solo paso de entrenamiento usando datos pequeños y fijos en un solo dispositivo con CPU. Específicamente, compruebe la equivalencia numérica para los siguientes componentes\n",
        "\n",
        "    - computación de pérdidas\n",
        "    - métricas\n",
        "    - tasa de aprendizaje\n",
        "    - cálculo y actualización del gradiente\n",
        "\n",
        "    b. Compruebe las estadísticas después del entrenamiento de 3 o más pasos para verificar los comportamientos del optimizador como el impulso, aún con datos fijos en un solo dispositivo de CPU.\n",
        "\n",
        "    c. En un único dispositivo GPU/TPU\n",
        "\n",
        "    d. Con estrategias multidispositivo (consulte la introducción de [MultiProcessRunner](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/distribute/multi_process_runner.py#L108) en la parte inferior)\n",
        "\n",
        "4. Pruebas de convergencia de principio a fin en un conjunto de datos reales\n",
        "\n",
        "    a. Comprobar los comportamientos de entrenamiento con TensorBoard\n",
        "\n",
        "    - use optimizadores sencillos, por ejemplo SGD, y estrategias de distribución sencillas, por ejemplo `tf.distribute.OneDeviceStrategy` primero\n",
        "    - métricas de entrenamiento\n",
        "    - métricas de evaluación\n",
        "    - averiguar cuál es la tolerancia razonable para la aleatoriedad inherente\n",
        "\n",
        "    b. Comprobar la equivalencia con optimizador avanzado/programador de tasa de aprendizaje/estrategias de distribución\n",
        "\n",
        "    c. Comprobar la equivalencia al usar precisión mixta\n",
        "\n",
        "5. Puntos de referencia adicionales del producto"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKakQBI9-FLb"
      },
      "source": [
        "## Preparación"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i1ghHyXl-Oqd"
      },
      "outputs": [],
      "source": [
        "# The `DeterministicRandomTestTool` is only available from Tensorflow 2.8:\n",
        "!pip install -q \"tensorflow==2.9.*\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usyRSlIRl3r2"
      },
      "source": [
        "### Validación de una sola pasada hacia delante\n",
        "\n",
        "La validación de una sola pasada, incluida la carga de puntos de verificación, se trata en otro [colab](./validate_correctness.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HVBQbsZeVL_V"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import unittest\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.compat.v1 as v1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4M104dt7m5cC"
      },
      "source": [
        "### Validación de la equivalencia numérica del entrenamiento del modelo por unos pocos pasos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2Nz2Ni1EkMz"
      },
      "source": [
        "Ajuste la configuración del modelo y prepare un conjunto de datos falso."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hUxXadzKU9rT"
      },
      "outputs": [],
      "source": [
        "params = {\n",
        "    'input_size': 3,\n",
        "    'num_classes': 3,\n",
        "    'layer_1_size': 2,\n",
        "    'layer_2_size': 2,\n",
        "    'num_train_steps': 100,\n",
        "    'init_lr': 1e-3,\n",
        "    'end_lr': 0.0,\n",
        "    'decay_steps': 1000,\n",
        "    'lr_power': 1.0,\n",
        "}\n",
        "\n",
        "# make a small fixed dataset\n",
        "fake_x = np.ones((2, params['input_size']), dtype=np.float32)\n",
        "fake_y = np.zeros((2, params['num_classes']), dtype=np.int32)\n",
        "fake_y[0][0] = 1\n",
        "fake_y[1][1] = 1\n",
        "\n",
        "step_num = 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lV_n3Ukmz4Un"
      },
      "source": [
        "Defina el modelo TF1.x."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ATa5fzL8mAwl"
      },
      "outputs": [],
      "source": [
        "# Assume there is an existing TF1.x model using estimator API\n",
        "# Wrap the model_fn to log necessary tensors for result comparison\n",
        "class SimpleModelWrapper():\n",
        "  def __init__(self):\n",
        "    self.logged_ops = {}\n",
        "    self.logs = {\n",
        "        'step': [],\n",
        "        'lr': [],\n",
        "        'loss': [],\n",
        "        'grads_and_vars': [],\n",
        "        'layer_out': []}\n",
        "     \n",
        "  def model_fn(self, features, labels, mode, params):\n",
        "      out_1 = tf.compat.v1.layers.dense(features, units=params['layer_1_size'])\n",
        "      out_2 = tf.compat.v1.layers.dense(out_1, units=params['layer_2_size'])\n",
        "      logits = tf.compat.v1.layers.dense(out_2, units=params['num_classes'])\n",
        "      loss = tf.compat.v1.losses.softmax_cross_entropy(labels, logits)\n",
        "\n",
        "      # skip EstimatorSpec details for prediction and evaluation \n",
        "      if mode == tf.estimator.ModeKeys.PREDICT:\n",
        "          pass\n",
        "      if mode == tf.estimator.ModeKeys.EVAL:\n",
        "          pass\n",
        "      assert mode == tf.estimator.ModeKeys.TRAIN\n",
        "\n",
        "      global_step = tf.compat.v1.train.get_or_create_global_step()\n",
        "      lr = tf.compat.v1.train.polynomial_decay(\n",
        "        learning_rate=params['init_lr'],\n",
        "        global_step=global_step,\n",
        "        decay_steps=params['decay_steps'],\n",
        "        end_learning_rate=params['end_lr'],\n",
        "        power=params['lr_power'])\n",
        "      \n",
        "      optmizer = tf.compat.v1.train.GradientDescentOptimizer(lr)\n",
        "      grads_and_vars = optmizer.compute_gradients(\n",
        "          loss=loss,\n",
        "          var_list=graph.get_collection(\n",
        "              tf.compat.v1.GraphKeys.TRAINABLE_VARIABLES))\n",
        "      train_op = optmizer.apply_gradients(\n",
        "          grads_and_vars,\n",
        "          global_step=global_step)\n",
        "      \n",
        "      # log tensors\n",
        "      self.logged_ops['step'] = global_step\n",
        "      self.logged_ops['lr'] = lr\n",
        "      self.logged_ops['loss'] = loss\n",
        "      self.logged_ops['grads_and_vars'] = grads_and_vars\n",
        "      self.logged_ops['layer_out'] = {\n",
        "          'layer_1': out_1,\n",
        "          'layer_2': out_2,\n",
        "          'logits': logits}\n",
        "\n",
        "      return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)\n",
        "\n",
        "  def update_logs(self, logs):\n",
        "    for key in logs.keys():\n",
        "      model_tf1.logs[key].append(logs[key])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kki9yILSKS7f"
      },
      "source": [
        "La siguiente clase [`v1.keras.utils.DeterministicRandomTestTool`](https://www.tensorflow.org/api_docs/python/tf/compat/v1/keras/utils/DeterministicRandomTestTool) ofrece un administrador de contexto `scope()` que puede hacer que las operaciones aleatorias con estado usen la misma semilla en ambos grafos/sesiones TF1 y ejecución eager,\n",
        "\n",
        "La herramienta ofrece dos modos de prueba:\n",
        "\n",
        "1. `constant` que usa la misma semilla para cada operación sin importar cuántas veces haya sido llamada y,\n",
        "2. `num_random_ops` que usa el número de operaciones aleatorias con estado observadas previamente como semilla de operación.\n",
        "\n",
        "Esto se aplica tanto a las operaciones aleatorias con estado usadas para crear e inicializar variables, como a las operaciones aleatorias con estado usadas en el cálculo (como para las capas abandonadas)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X6Y3RWMoKOl8"
      },
      "outputs": [],
      "source": [
        "random_tool = v1.keras.utils.DeterministicRandomTestTool(mode='num_random_ops')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mk5-ZzxcErX5"
      },
      "source": [
        "Ejecute el modelo TF1.x en modo grafo. Recopile las estadísticas de los 3 primeros pasos de entrenamiento para comparar la equivalencia numérica."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r5zhJHvsWA24"
      },
      "outputs": [],
      "source": [
        "with random_tool.scope():\n",
        "  graph = tf.Graph()\n",
        "  with graph.as_default(), tf.compat.v1.Session(graph=graph) as sess:\n",
        "    model_tf1 = SimpleModelWrapper()\n",
        "    # build the model\n",
        "    inputs = tf.compat.v1.placeholder(tf.float32, shape=(None, params['input_size']))\n",
        "    labels = tf.compat.v1.placeholder(tf.float32, shape=(None, params['num_classes']))\n",
        "    spec = model_tf1.model_fn(inputs, labels, tf.estimator.ModeKeys.TRAIN, params)\n",
        "    train_op = spec.train_op\n",
        "\n",
        "    sess.run(tf.compat.v1.global_variables_initializer())\n",
        "    for step in range(step_num):\n",
        "      # log everything and update the model for one step\n",
        "      logs, _ = sess.run(\n",
        "          [model_tf1.logged_ops, train_op],\n",
        "          feed_dict={inputs: fake_x, labels: fake_y})\n",
        "      model_tf1.update_logs(logs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZxjI8Nxz9Ea"
      },
      "source": [
        "Defina el modelo TF2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AA67rh2TkS1M"
      },
      "outputs": [],
      "source": [
        "class SimpleModel(tf.keras.Model):\n",
        "  def __init__(self, params, *args, **kwargs):\n",
        "    super(SimpleModel, self).__init__(*args, **kwargs)\n",
        "    # define the model\n",
        "    self.dense_1 = tf.keras.layers.Dense(params['layer_1_size'])\n",
        "    self.dense_2 = tf.keras.layers.Dense(params['layer_2_size'])\n",
        "    self.out = tf.keras.layers.Dense(params['num_classes'])\n",
        "    learning_rate_fn = tf.keras.optimizers.schedules.PolynomialDecay(\n",
        "      initial_learning_rate=params['init_lr'],\n",
        "      decay_steps=params['decay_steps'],\n",
        "      end_learning_rate=params['end_lr'],\n",
        "      power=params['lr_power'])  \n",
        "    self.optimizer = tf.keras.optimizers.legacy.SGD(learning_rate_fn)\n",
        "    self.compiled_loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "    self.logs = {\n",
        "        'lr': [],\n",
        "        'loss': [],\n",
        "        'grads': [],\n",
        "        'weights': [],\n",
        "        'layer_out': []}\n",
        "\n",
        "  def call(self, inputs):\n",
        "    out_1 = self.dense_1(inputs)\n",
        "    out_2 = self.dense_2(out_1)\n",
        "    logits = self.out(out_2)\n",
        "    # log output features for every layer for comparison\n",
        "    layer_wise_out = {\n",
        "        'layer_1': out_1,\n",
        "        'layer_2': out_2,\n",
        "        'logits': logits}\n",
        "    self.logs['layer_out'].append(layer_wise_out)\n",
        "    return logits\n",
        "\n",
        "  def train_step(self, data):\n",
        "    x, y = data\n",
        "    with tf.GradientTape() as tape:\n",
        "      logits = self(x)\n",
        "      loss = self.compiled_loss(y, logits)\n",
        "    grads = tape.gradient(loss, self.trainable_weights)\n",
        "    # log training statistics\n",
        "    step = self.optimizer.iterations.numpy()\n",
        "    self.logs['lr'].append(self.optimizer.learning_rate(step).numpy())\n",
        "    self.logs['loss'].append(loss.numpy())\n",
        "    self.logs['grads'].append(grads)\n",
        "    self.logs['weights'].append(self.trainable_weights)\n",
        "    # update model\n",
        "    self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
        "    return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5smAcaEE8nX"
      },
      "source": [
        "Ejecute el modelo TF2 en modo eager. Recopile las estadísticas de los 3 primeros pasos de entrenamiento para comparar la equivalencia numérica."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q0AbXF_eE8cS"
      },
      "outputs": [],
      "source": [
        "random_tool = v1.keras.utils.DeterministicRandomTestTool(mode='num_random_ops')\n",
        "with random_tool.scope():\n",
        "  model_tf2 = SimpleModel(params)\n",
        "  for step in range(step_num):\n",
        "    model_tf2.train_step([fake_x, fake_y])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjJDjLcAz_gU"
      },
      "source": [
        "Compare la equivalencia numérica de los primeros pasos del entrenamiento.\n",
        "\n",
        "También puede consultar el [bloc de notas Validación de la corrección y equivalencia numérica](./validate_correctness.ipynb) si desea consejos adicionales para la equivalencia numérica."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6CbCUbsCiabC"
      },
      "outputs": [],
      "source": [
        "np.testing.assert_allclose(model_tf1.logs['lr'], model_tf2.logs['lr'])\n",
        "np.testing.assert_allclose(model_tf1.logs['loss'], model_tf2.logs['loss'])\n",
        "for step in range(step_num):\n",
        "  for name in model_tf1.logs['layer_out'][step]:\n",
        "    np.testing.assert_allclose(\n",
        "        model_tf1.logs['layer_out'][step][name],\n",
        "        model_tf2.logs['layer_out'][step][name])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhVuuciimLIY"
      },
      "source": [
        "#### Pruebas de unidad"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXZYFC6Hhqeb"
      },
      "source": [
        "Existen algunos tipos de pruebas de unidad que pueden ayudar a depurar su código de migración.\n",
        "\n",
        "1. Validación de una sola pasada hacia delante\n",
        "2. Validación de la equivalencia numérica del entrenamiento del modelo por unos pocos pasos\n",
        "3. Comparar los resultados del rendimiento de inferencia\n",
        "4. El modelo entrenado realiza predicciones correctas sobre puntos de datos fijos y simples\n",
        "\n",
        "Puede usar `@parameterized.parameters` para probar modelos con diferentes configuraciones. [Detalles con muestra de código](https://github.com/abseil/abseil-py/blob/master/absl/testing/parameterized.py).\n",
        "\n",
        "Tenga en cuenta que es posible ejecutar APIs de sesión y ejecución eager en el mismo caso de prueba. Los fragmentos de código a continuación muestran cómo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CdHqkgPPM2Bj"
      },
      "outputs": [],
      "source": [
        "import unittest\n",
        "\n",
        "class TestNumericalEquivalence(unittest.TestCase):\n",
        "\n",
        "  # copied from code samples above\n",
        "  def setup(self):\n",
        "    # record statistics for 100 training steps\n",
        "    step_num = 100\n",
        "\n",
        "    # setup TF 1 model\n",
        "    random_tool = v1.keras.utils.DeterministicRandomTestTool(mode='num_random_ops')\n",
        "    with random_tool.scope():\n",
        "      # run TF1.x code in graph mode with context management\n",
        "      graph = tf.Graph()\n",
        "      with graph.as_default(), tf.compat.v1.Session(graph=graph) as sess:\n",
        "        self.model_tf1 = SimpleModelWrapper()\n",
        "        # build the model\n",
        "        inputs = tf.compat.v1.placeholder(tf.float32, shape=(None, params['input_size']))\n",
        "        labels = tf.compat.v1.placeholder(tf.float32, shape=(None, params['num_classes']))\n",
        "        spec = self.model_tf1.model_fn(inputs, labels, tf.estimator.ModeKeys.TRAIN, params)\n",
        "        train_op = spec.train_op\n",
        "\n",
        "        sess.run(tf.compat.v1.global_variables_initializer())\n",
        "        for step in range(step_num):\n",
        "          # log everything and update the model for one step\n",
        "          logs, _ = sess.run(\n",
        "              [self.model_tf1.logged_ops, train_op],\n",
        "              feed_dict={inputs: fake_x, labels: fake_y})\n",
        "          self.model_tf1.update_logs(logs)\n",
        "\n",
        "    # setup TF2 model\n",
        "    random_tool = v1.keras.utils.DeterministicRandomTestTool(mode='num_random_ops')\n",
        "    with random_tool.scope():\n",
        "      self.model_tf2 = SimpleModel(params)\n",
        "      for step in range(step_num):\n",
        "        self.model_tf2.train_step([fake_x, fake_y])\n",
        "  \n",
        "  def test_learning_rate(self):\n",
        "    np.testing.assert_allclose(\n",
        "        self.model_tf1.logs['lr'],\n",
        "        self.model_tf2.logs['lr'])\n",
        "\n",
        "  def test_training_loss(self):\n",
        "    # adopt different tolerance strategies before and after 10 steps\n",
        "    first_n_step = 10\n",
        "\n",
        "    # absolute difference is limited below 1e-5\n",
        "    # set `equal_nan` to be False to detect potential NaN loss issues\n",
        "    abosolute_tolerance = 1e-5\n",
        "    np.testing.assert_allclose(\n",
        "        actual=self.model_tf1.logs['loss'][:first_n_step],\n",
        "        desired=self.model_tf2.logs['loss'][:first_n_step],\n",
        "        atol=abosolute_tolerance,\n",
        "        equal_nan=False)\n",
        "    \n",
        "    # relative difference is limited below 5%\n",
        "    relative_tolerance = 0.05\n",
        "    np.testing.assert_allclose(self.model_tf1.logs['loss'][first_n_step:],\n",
        "                               self.model_tf2.logs['loss'][first_n_step:],\n",
        "                               rtol=relative_tolerance,\n",
        "                               equal_nan=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gshSQdKIddpZ"
      },
      "source": [
        "## Herramientas de depuración"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkMfCaJRclKv"
      },
      "source": [
        "### tf.print\n",
        "\n",
        "tf.print vs print/logging.info\n",
        "\n",
        "- Con argumentos configurables, `tf.print` puede mostrar recursivamente los primeros y últimos elementos de cada dimensión para los tensores impresos. Consulte la [documentación de la API](https://www.tensorflow.org/api_docs/python/tf/print) para más detalles.\n",
        "- Para la ejecución eager, tanto `print` como `tf.print` imprimen el valor del tensor. Pero `print` puede suponer una copia de dispositivo a host, lo que potencialmente puede ralentizar su código.\n",
        "- Para el modo gráfico, incluyendo el uso dentro de `tf.function`, necesita usar `tf.print` para imprimir el valor real del tensor. `tf.print` se compila en una op en el grafo, mientras que `print` y `logging.info` sólo hacen registros en el tiempo de seguimiento, que a menudo no es lo que usted desea.\n",
        "- `tf.print` también permite imprimir tensores compuestos como `tf.RaggedTensor` y `tf.sparse.SparseTensor`.\n",
        "- También puede usar una retrollamada para monitorear métricas y variables. Consulte cómo usar retrollamadas personalizadas con [diccionarios de registros](https://www.tensorflow.org/guide/keras/custom_callback#usage_of_logs_dict) y [atributo self.model](https://www.tensorflow.org/guide/keras/custom_callback#usage_of_selfmodel_attribute)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-5h3cX8Dc50"
      },
      "source": [
        "tf.print vs print dentro de tf.function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gRED9FMyDKih"
      },
      "outputs": [],
      "source": [
        "# `print` prints info of tensor object\n",
        "# `tf.print` prints the tensor value\n",
        "@tf.function\n",
        "def dummy_func(num):\n",
        "  num += 1\n",
        "  print(num)\n",
        "  tf.print(num)\n",
        "  return num\n",
        "\n",
        "_ = dummy_func(tf.constant([1.0]))\n",
        "\n",
        "# Output:\n",
        "# Tensor(\"add:0\", shape=(1,), dtype=float32)\n",
        "# [2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3QroLA_zDK2w"
      },
      "source": [
        "tf.distribute.Strategy\n",
        "\n",
        "- Si el `tf.function` que contiene `tf.print` se ejecuta en los trabajadores, por ejemplo al usar `TPUStrategy` o `ParameterServerStrategy`, tiene que comprobar los registros del servidor de trabajadores/parámetros para encontrar los valores impresos.\n",
        "- Para `print` o `logging.info`, los registros se imprimirán en el coordinador cuando se use `ParameterServerStrategy`, y los registros se imprimirán en STDOUT en worker0 cuando se usen TPUs.\n",
        "\n",
        "tf.keras.Model\n",
        "\n",
        "- Al usar modelos API secuenciales y funcionales, si desea imprimir valores, por ejemplo, entradas del modelo o características intermedias después de algunas capas, tiene las siguientes opciones.\n",
        "    1. [Escriba una capa personalizada](https://www.tensorflow.org/guide/keras/custom_layers_and_models) que imprima por `tf.print` las entradas.\n",
        "    2. Incluya las salidas intermedias que desee inspeccionar en las salidas del modelo.\n",
        "- `tf.keras.layers.Lambda` las capas tienen limitaciones de (de)serialización. Para evitar problemas de carga de puntos de verificación, escriba en su lugar una capa personalizada de subclases. Consulte la [documentación de API](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Lambda) para más detalles.\n",
        "- No puede imprimir por `tf.print` salidas intermedias en una retrollamada `tf.keras.callbacks.LambdaCallback` si no tiene acceso a los valores reales, sino sólo a los objetos tensores simbólicos de Keras.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKazGTr1ZUMG"
      },
      "source": [
        "Opción 1: escriba una capa personalizada"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8w4aY7wO0B4W"
      },
      "outputs": [],
      "source": [
        "class PrintLayer(tf.keras.layers.Layer):\n",
        "  def call(self, inputs):\n",
        "    tf.print(inputs)\n",
        "    return inputs\n",
        "\n",
        "def get_model():\n",
        "  inputs = tf.keras.layers.Input(shape=(1,))\n",
        "  out_1 = tf.keras.layers.Dense(4)(inputs)\n",
        "  out_2 = tf.keras.layers.Dense(1)(out_1)\n",
        "  # use custom layer to tf.print intermediate features\n",
        "  out_3 = PrintLayer()(out_2)\n",
        "  model = tf.keras.Model(inputs=inputs, outputs=out_3)\n",
        "  return model\n",
        "\n",
        "model = get_model()\n",
        "model.compile(optimizer=\"adam\", loss=\"mse\")\n",
        "model.fit([1, 2, 3], [0.0, 0.0, 1.0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNESOatq7iM9"
      },
      "source": [
        "Opción 2: incluya las salidas intermedias que desee inspeccionar en las salidas del modelo.\n",
        "\n",
        "Tenga en cuenta que, en tal caso, puede necesitar algunas [personalizaciones](https://www.tensorflow.org/guide/keras/customizing_what_happens_in_fit) para usar `Model.fit`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MiifvdLk7g9J"
      },
      "outputs": [],
      "source": [
        "def get_model():\n",
        "  inputs = tf.keras.layers.Input(shape=(1,))\n",
        "  out_1 = tf.keras.layers.Dense(4)(inputs)\n",
        "  out_2 = tf.keras.layers.Dense(1)(out_1)\n",
        "  # include intermediate values in model outputs\n",
        "  model = tf.keras.Model(\n",
        "      inputs=inputs,\n",
        "      outputs={\n",
        "          'inputs': inputs,\n",
        "          'out_1': out_1,\n",
        "          'out_2': out_2})\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvIKDZpHSLmQ"
      },
      "source": [
        "### pdb\n",
        "\n",
        "Puede usar [pdb](https://docs.python.org/3/library/pdb.html) tanto en el terminal como en Colab para inspeccionar los valores intermedios para depuración.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qu0n4O2umyT7"
      },
      "source": [
        "### Visualizar grafo con TensorBoard\n",
        "\n",
        "Puede [examinar el grafo TensorFlow con TensorBoard](https://www.tensorflow.org/tensorboard/graphs). TensorBoard también [está soportado en colab](https://www.tensorflow.org/tensorboard/tensorboard_in_notebooks). TensorBoard es una gran herramienta para visualizar sumarios. Puede usarlo para comparar el ritmo de aprendizaje, las ponderaciones del modelo, la escala de gradiente, las métricas de entrenamiento/validación o incluso las salidas intermedias del modelo entre el modelo TF1.x y el modelo TF2 migrado a través del proceso de entrenamiento y ver si los valores son los esperados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBnxB6_xzlnT"
      },
      "source": [
        "### TensorFlow Profiler\n",
        "\n",
        "[TensorFlow Profiler](https://www.tensorflow.org/guide/profiler) puede ayudarle a visualizar la línea de tiempo de ejecución en GPUs/TPUs. Puede consultar esta [Demo de Colab](https://www.tensorflow.org/tensorboard/tensorboard_profiling_keras) para ver su uso básico."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wNmCSHBpiGM"
      },
      "source": [
        "### MultiProcessRunner\n",
        "\n",
        "[MultiProcessRunner](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/distribute/multi_process_runner.py#L108) es una herramienta útil a la hora de depurar con MultiWorkerMirroredStrategy y ParameterServerStrategy. Puede echar un vistazo a [este ejemplo concreto](https://github.com/keras-team/keras/blob/master/keras/integration_test/mwms_multi_process_runner_test.py) para ver su uso.\n",
        "\n",
        "Específicamente para los casos de estas dos estrategias, se recomienda 1) no sólo tener pruebas de unidad para cubrir su flujo, 2) sino también intentar reproducir fallos usándolo en pruebas de unidad para evitar lanzar un trabajo real distribuido cada vez que se intente una reparación."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "migration_debugging.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
