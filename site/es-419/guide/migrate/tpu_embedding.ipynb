{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJcYs_ERTnnI"
      },
      "source": [
        "##### Copyright 2021 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "HMUDt0CiUJk9"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77z2OchJTk0l"
      },
      "source": [
        "# Migrar de TPU embedding_columns a capa TPUEmbedding\n",
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td><a target=\"_blank\" href=\"https://www.tensorflow.org/guide/migrate/tpu_embedding\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver en TensorFlow.org</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/es-419/guide/migrate/tpu_embedding.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Ejecutar en Google Colab</a></td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/es-419/guide/migrate/tpu_embedding.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver código fuente en GitHub</a>\n",
        "</td>\n",
        "  <td><a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/es-419/guide/migrate/tpu_embedding.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Descargar bloc de notas</a></td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "meUTrR4I6m1C"
      },
      "source": [
        "Esta guía demuestra cómo migrar el entrenamiento de incorporación en [TPUs](../../guide/tpu.ipynb) de la API `embedding_column` de TensorFlow 1 con `TPUEstimator` a la API de la capa `TPUEmbedding` de TensorFlow 2 con `TPUStrategy`.\n",
        "\n",
        "Las incorporaciones son matrices (grandes). Son tablas de búsqueda que mapean a partir de un espacio de características disperso a vectores densas. Las incorporaciones ofrecen representaciones eficientes y densas que captan las similitudes y relaciones complejas entre las características.\n",
        "\n",
        "TensorFlow incluye soporte especializado para el entrenamiento de incorporaciones en TPUs. Este soporte de incorporación específico de TPU le permite entrenar incorporaciones que son más grandes que la memoria de un solo dispositivo TPU, y usar entradas dispersas y desiguales en TPUs.\n",
        "\n",
        "- En TensorFlow 1, `tf.compat.v1.estimator.tpu.TPUEstimator` es una API de alto nivel que encapsula el entrenamiento, la evaluación, la predicción y la exportación para su servicio con TPUs. Tiene un soporte especial para `tf.compat.v1.tpu.experimental.embedding_column`.\n",
        "- Para implementarlo en TensorFlow 2, use la capa `tfrs.layers.embedding.TPUEmbedding` de TensorFlow Recommenders. Para el entrenamiento y la evaluación, use una estrategia de distribución TPU (`tf.distribute.TPUStrategy`) que sea compatible con las API de Keras para, por ejemplo, la construcción de modelos (`tf.keras. Model`), optimizadores (`tf.keras.optimizers.Optimizer`), y entrenamiento con `Model.fit` o un bucle de entrenamiento personalizado con `tf.function` y `tf.GradientTape`.\n",
        "\n",
        "Para más información, consulte la documentación de la API de la capa `tfrs.layers.embedding.TPUEmbedding`, así como los documentos de `tf.tpu.experimental.embedding.TableConfig` y `tf.tpu.experimental.embedding.FeatureConfig`. Para una visión general de `tf.distribute.TPUStrategy`, consulte la guía [Entrenamiento distribuido](../../guide/distributed_training.ipynb) y la guía [Utilizar TPUs](../../guide/tpu.ipynb). Si está migrando de `TPUEstimator` a `TPUStrategy`, consulte [la guía de migración de TPU](tpu_estimator.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdZSoIXEbhg-"
      },
      "source": [
        "## Preparación\n",
        "\n",
        "Comience instalando [TensorFlow Recommenders](https://www.tensorflow.org/recommenders) e importando algunos paquetes necesarios:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tYE3RnRN2jNu"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow-recommenders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iE0vSfMXumKI"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.compat.v1 as tf1\n",
        "\n",
        "# TPUEmbedding layer is not part of TensorFlow.\n",
        "import tensorflow_recommenders as tfrs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jsm9Rxx7s1OZ"
      },
      "source": [
        "Y prepare un conjunto de datos sencillo para fines de demostración:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m7rnGxsXtDkV"
      },
      "outputs": [],
      "source": [
        "features = [[1., 1.5]]\n",
        "embedding_features_indices = [[0, 0], [0, 1]]\n",
        "embedding_features_values = [0, 5]\n",
        "labels = [[0.3]]\n",
        "eval_features = [[4., 4.5]]\n",
        "eval_embedding_features_indices = [[0, 0], [0, 1]]\n",
        "eval_embedding_features_values = [4, 3]\n",
        "eval_labels = [[0.8]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4uXff1BEssdE"
      },
      "source": [
        "## TensorFlow 1: Entrene incorporaciones en TPUs con TPUEstimator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pc-WSeYG2oje"
      },
      "source": [
        "En TensorFlow 1, se preparan incorporaciones TPU usando la API `tf.compat.v1.tpu.experimental.embedding_column` y entrene/evalúe el modelo sobre TPUs con `tf.compat.v1.estimator.tpu.TPUEstimator`.\n",
        "\n",
        "Las entradas son números enteros que van de cero al tamaño del vocabulario para la tabla de incorporación TPU. Comience por codificar las entradas en ID categórica con `tf.feature_column.categorical_column_with_identity`. Use `\"sparse_feature\"` para el parámetro `key`, ya que las características de entrada son de valor entero, mientras que `num_buckets` es el tamaño del vocabulario para la tabla de incorporación (`10`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sO_y-IRT3dcM"
      },
      "outputs": [],
      "source": [
        "embedding_id_column = (\n",
        "      tf1.feature_column.categorical_column_with_identity(\n",
        "          key=\"sparse_feature\", num_buckets=10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57e2dec8ed4a"
      },
      "source": [
        "A continuación, convierta las entradas categóricas dispersas en una representación densa con `tpu.experimental.embedding_column`, donde `dimension` es la anchura de la tabla de incorporación. Almacenará un vector de incorporación para cada uno de los `num_buckets`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6d61c855011f"
      },
      "outputs": [],
      "source": [
        "embedding_column = tf1.tpu.experimental.embedding_column(\n",
        "    embedding_id_column, dimension=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6061452ee5a"
      },
      "source": [
        "Ahora, defina la configuración de incorporación específica de la TPU mediante `tf.estimator.tpu.experimental.EmbeddingConfigSpec`. Más tarde se la pasará a `tf.estimator.tpu.TPUEstimator` como parámetro `embedding_config_spec`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6abbf967fc82"
      },
      "outputs": [],
      "source": [
        "embedding_config_spec = tf1.estimator.tpu.experimental.EmbeddingConfigSpec(\n",
        "    feature_columns=(embedding_column,),\n",
        "    optimization_parameters=(\n",
        "        tf1.tpu.experimental.AdagradParameters(0.05)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVWHEQj5a7rN"
      },
      "source": [
        "A continuación, para usar un `TPUEstimator`, defina:\n",
        "\n",
        "- Una función de entrada para los datos de entrenamiento\n",
        "- Una función de entrada de evaluación para los datos de evaluación\n",
        "- Una función modelo para dar instrucciones al `TPUEstimator` sobre cómo se define la op de entrenamiento con las características y las etiquetas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lqe9obf7suIj"
      },
      "outputs": [],
      "source": [
        "def _input_fn(params):\n",
        "  dataset = tf1.data.Dataset.from_tensor_slices((\n",
        "      {\"dense_feature\": features,\n",
        "       \"sparse_feature\": tf1.SparseTensor(\n",
        "           embedding_features_indices,\n",
        "           embedding_features_values, [1, 2])},\n",
        "           labels))\n",
        "  dataset = dataset.repeat()\n",
        "  return dataset.batch(params['batch_size'], drop_remainder=True)\n",
        "\n",
        "def _eval_input_fn(params):\n",
        "  dataset = tf1.data.Dataset.from_tensor_slices((\n",
        "      {\"dense_feature\": eval_features,\n",
        "       \"sparse_feature\": tf1.SparseTensor(\n",
        "           eval_embedding_features_indices,\n",
        "           eval_embedding_features_values, [1, 2])},\n",
        "           eval_labels))\n",
        "  dataset = dataset.repeat()\n",
        "  return dataset.batch(params['batch_size'], drop_remainder=True)\n",
        "\n",
        "def _model_fn(features, labels, mode, params):\n",
        "  embedding_features = tf1.keras.layers.DenseFeatures(embedding_column)(features)\n",
        "  concatenated_features = tf1.keras.layers.Concatenate(axis=1)(\n",
        "      [embedding_features, features[\"dense_feature\"]])\n",
        "  logits = tf1.layers.Dense(1)(concatenated_features)\n",
        "  loss = tf1.losses.mean_squared_error(labels=labels, predictions=logits)\n",
        "  optimizer = tf1.train.AdagradOptimizer(0.05)\n",
        "  optimizer = tf1.tpu.CrossShardOptimizer(optimizer)\n",
        "  train_op = optimizer.minimize(loss, global_step=tf1.train.get_global_step())\n",
        "  return tf1.estimator.tpu.TPUEstimatorSpec(mode, loss=loss, train_op=train_op)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYnP3Dszc-2R"
      },
      "source": [
        "Con esas funciones definidas, cree un objeto `tf.distribute.cluster_resolver.TPUClusterResolver` que ofrezca la información del clúster, y un objeto `tf.compat.v1.estimator.tpu.RunConfig`.\n",
        "\n",
        "Junto con la función modelo que ha definido, ahora puede crear un `TPUEstimator`. Aquí, simplificará el flujo omitiendo el ahorro de puntos de verificación. A continuación, especificará el tamaño del lote tanto para el entrenamiento como en la evaluación para el `TPUEstimator`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WAqyqawemlcl"
      },
      "outputs": [],
      "source": [
        "cluster_resolver = tf1.distribute.cluster_resolver.TPUClusterResolver(tpu='')\n",
        "print(\"All devices: \", tf1.config.list_logical_devices('TPU'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HsOpjW5plH9Q"
      },
      "outputs": [],
      "source": [
        "tpu_config = tf1.estimator.tpu.TPUConfig(\n",
        "    iterations_per_loop=10,\n",
        "    per_host_input_for_training=tf1.estimator.tpu.InputPipelineConfig\n",
        "          .PER_HOST_V2)\n",
        "config = tf1.estimator.tpu.RunConfig(\n",
        "    cluster=cluster_resolver,\n",
        "    save_checkpoints_steps=None,\n",
        "    tpu_config=tpu_config)\n",
        "estimator = tf1.estimator.tpu.TPUEstimator(\n",
        "    model_fn=_model_fn, config=config, train_batch_size=8, eval_batch_size=8,\n",
        "    embedding_config_spec=embedding_config_spec)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uxw7tWrcepaZ"
      },
      "source": [
        "Llame a `TPUEstimator.train` para comenzar el entrenamiento del modelo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZPKFOMAcyrP"
      },
      "outputs": [],
      "source": [
        "estimator.train(_input_fn, steps=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ev1vjIz9euIw"
      },
      "source": [
        "Luego, llame a `TPUEstimator.evaluate` para evaluar el modelo usando los datos de evaluación:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bqiKRiwWc0cz"
      },
      "outputs": [],
      "source": [
        "estimator.evaluate(_eval_input_fn, steps=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEmzBjfnsxwT"
      },
      "source": [
        "## TensorFlow 2: Entrene incorporaciones en TPUs con TPUStrategy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UesuXNbShrbi"
      },
      "source": [
        "En TensorFlow 2, para entrenar sobre los trabajadores TPU, use `tf.distribute.TPUStrategy` junto con las APIs de Keras para la definición y entrenamiento / evaluación del modelo (consulte la guía [Utilizar TPU](https://render.githubusercontent.com/guide/tpu.ipynb) para ver más ejemplos de entrenamiento con Model.fit de Keras y un bucle de entrenamiento personalizado (con `tf.function` y `tf.GradientTape`)).\n",
        "\n",
        "Dado que necesita realizar algún trabajo de inicialización para conectarse al cluster remoto e inicializar los trabajadores de la TPU, comience creando un `TPUClusterResolver` para proveer la información del cluster y conectarse al mismo. Puede aprender más en la sección *Inicialización de TPU* de la guía [Utilizar TPUs](../../guide/tpu.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_TgdPNgXoS63"
      },
      "outputs": [],
      "source": [
        "cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\n",
        "tf.config.experimental_connect_to_cluster(cluster_resolver)\n",
        "tf.tpu.experimental.initialize_tpu_system(cluster_resolver)\n",
        "print(\"All devices: \", tf.config.list_logical_devices('TPU'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94JBD0HxmdPI"
      },
      "source": [
        "A continuación, prepare sus datos. Esta operación es similar a cómo creó un conjunto de datos en el ejemplo de TensorFlow 1, excepto que ahora se pasa a la función del conjunto de datos un objeto `tf.distribute.InputContext` en lugar de un dict `params`. Puede usar este objeto para determinar el tamaño del lote local (y para qué host es esta canalización, de modo que pueda particionar adecuadamente sus datos).\n",
        "\n",
        "- Al usar la API `tfrs.layers.embedding.TPUEmbedding`, es importante incluir la opción `drop_remainder=True` al procesar por lotes el conjunto de datos con `Dataset.batch`, ya que `TPUEmbedding` requiere un tamaño de lote fijo.\n",
        "- Además, debe usarse el mismo tamaño de lote para la evaluación y el entrenamiento si tienen lugar en el mismo conjunto de dispositivos.\n",
        "- Por último, debe usar `tf.keras.utils.experimental.DatasetCreator` junto con la opción de entrada especial (`experimental_fetch_to_device=False`) en `tf.distribute.InputOptions` (que alberga configuraciones específicas de la estrategia). Esto se demuestra a continuación:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9NTruOw6mcy9"
      },
      "outputs": [],
      "source": [
        "global_batch_size = 8\n",
        "\n",
        "def _input_dataset(context: tf.distribute.InputContext):\n",
        "  dataset = tf.data.Dataset.from_tensor_slices((\n",
        "      {\"dense_feature\": features,\n",
        "       \"sparse_feature\": tf.SparseTensor(\n",
        "           embedding_features_indices,\n",
        "           embedding_features_values, [1, 2])},\n",
        "           labels))\n",
        "  dataset = dataset.shuffle(10).repeat()\n",
        "  dataset = dataset.batch(\n",
        "      context.get_per_replica_batch_size(global_batch_size),\n",
        "      drop_remainder=True)\n",
        "  return dataset.prefetch(2)\n",
        "\n",
        "def _eval_dataset(context: tf.distribute.InputContext):\n",
        "  dataset = tf.data.Dataset.from_tensor_slices((\n",
        "      {\"dense_feature\": eval_features,\n",
        "       \"sparse_feature\": tf.SparseTensor(\n",
        "           eval_embedding_features_indices,\n",
        "           eval_embedding_features_values, [1, 2])},\n",
        "           eval_labels))\n",
        "  dataset = dataset.repeat()\n",
        "  dataset = dataset.batch(\n",
        "      context.get_per_replica_batch_size(global_batch_size),\n",
        "      drop_remainder=True)\n",
        "  return dataset.prefetch(2)\n",
        "\n",
        "input_options = tf.distribute.InputOptions(\n",
        "    experimental_fetch_to_device=False)\n",
        "\n",
        "input_dataset = tf.keras.utils.experimental.DatasetCreator(\n",
        "    _input_dataset, input_options=input_options)\n",
        "\n",
        "eval_dataset = tf.keras.utils.experimental.DatasetCreator(\n",
        "    _eval_dataset, input_options=input_options)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4EHXhN3CVmo"
      },
      "source": [
        "Después, una vez preparados los datos, creará una `TPUStrategy`, y definirá un modelo, métricas y un optimizador bajo el ámbito de esta estrategia (`Strategy.scope`).\n",
        "\n",
        "Debería elegir un número para `steps_per_execution` en `Model.compile` ya que especifica el número de lotes a ejecutar durante cada llamada a `tf.function`, y es crítico para el rendimiento. Este argumento es similar a `iterations_per_loop` usado en `TPUEstimator`.\n",
        "\n",
        "Las características y la configuración de la tabla que se especificaron en TensorFlow 1 a través de `tf.tpu.experimental.embedding_column` (y `tf.tpu.experimental.shared_embedding_column`) pueden especificarse directamente en TensorFlow 2 a través de un par de objetos de configuración:\n",
        "\n",
        "- `tf.tpu.experimental.embedding.FeatureConfig`\n",
        "- `tf.tpu.experimental.embedding.TableConfig`\n",
        "\n",
        "(Consulte la documentación de la API asociada para ver más detalles)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "atVciNgPs0fw"
      },
      "outputs": [],
      "source": [
        "strategy = tf.distribute.TPUStrategy(cluster_resolver)\n",
        "with strategy.scope():\n",
        "  if hasattr(tf.keras.optimizers, \"legacy\"):\n",
        "    optimizer = tf.keras.optimizers.legacy.Adagrad(learning_rate=0.05)\n",
        "  else:\n",
        "    optimizer = tf.keras.optimizers.Adagrad(learning_rate=0.05)\n",
        "  dense_input = tf.keras.Input(shape=(2,), dtype=tf.float32, batch_size=global_batch_size)\n",
        "  sparse_input = tf.keras.Input(shape=(), dtype=tf.int32, batch_size=global_batch_size)\n",
        "  embedded_input = tfrs.layers.embedding.TPUEmbedding(\n",
        "      feature_config=tf.tpu.experimental.embedding.FeatureConfig(\n",
        "          table=tf.tpu.experimental.embedding.TableConfig(\n",
        "              vocabulary_size=10,\n",
        "              dim=5,\n",
        "              initializer=tf.initializers.TruncatedNormal(mean=0.0, stddev=1)),\n",
        "          name=\"sparse_input\"),\n",
        "      optimizer=optimizer)(sparse_input)\n",
        "  input = tf.keras.layers.Concatenate(axis=1)([dense_input, embedded_input])\n",
        "  result = tf.keras.layers.Dense(1)(input)\n",
        "  model = tf.keras.Model(inputs={\"dense_feature\": dense_input, \"sparse_feature\": sparse_input}, outputs=result)\n",
        "  model.compile(optimizer, \"mse\", steps_per_execution=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkM2VZyni98F"
      },
      "source": [
        "Una vez hecho esto, ya está listo para entrenar el modelo con el conjunto de datos de entrenamiento:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kip65sYBlKiu"
      },
      "outputs": [],
      "source": [
        "model.fit(input_dataset, epochs=5, steps_per_epoch=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0AEK8sNjLOj"
      },
      "source": [
        "Por último, evalúe el modelo usando el conjunto de datos de evaluación:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6tMRkyfKhqSL"
      },
      "outputs": [],
      "source": [
        "model.evaluate(eval_dataset, steps=1, return_dict=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a97b888c1911"
      },
      "source": [
        "## Siguientes pasos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHx_RUL8xcJ3"
      },
      "source": [
        "Encontrará más información sobre cómo configurar las incorporaciones específicas de TPU en los documentos de la API:\n",
        "\n",
        "- `tfrs.layers.embedding.TPUEmbedding` : particularmente sobre la configuración de funciones y tablas, configuración del optimizador, creación de un modelo (usando la API [funcional](https://www.tensorflow.org/guide/keras/functional) de Keras o mediante [subclases](../..guide/keras/custom_layers_and_models.ipynb) `tf.keras.Model`), entrenamiento/evaluación y entrega de modelos con `tf.saved_model`\n",
        "- `tf.tpu.experimental.embedding.TableConfig`\n",
        "- `tf.tpu.experimental.embedding.FeatureConfig`\n",
        "\n",
        "Para más información sobre `TPUStrategy` en TensorFlow 2, considere los siguientes recursos:\n",
        "\n",
        "- Guía: [Utilizar TPUs](../../guide/tpu.ipynb) (que cubre el entrenamiento con Keras `Model.fit`/un bucle de entrenamiento personalizado con `tf.distribute.TPUStrategy`, así como consejos para mejorar el rendimiento con `tf.function`)\n",
        "- Guía: [Entrenamiento distribuido con TensorFlow](../../guide/distributed_training.ipynb)\n",
        "- Guía: [Migrar de TPUEstimator a TPUStrategy](tpu_estimator.ipynb)\n",
        "\n",
        "Para saber más sobre cómo personalizar su entrenamiento, consulte:\n",
        "\n",
        "- Guía: [Personalice lo que ocurre en Model.fit](../..guide/keras/customizing_what_happens_in_fit.ipynb)\n",
        "- Guía: [Escribir un bucle de entrenamiento desde cero](https://www.tensorflow.org/guide/keras/writing_a_training_loop_from_scratch)\n",
        "\n",
        "Las TPU (ASIC especializadas de Google para el aprendizaje automático) están disponibles a través de [Google Colab](https://colab.research.google.com/), la [Cloud TPU Research Cloud](https://sites.research.google/trc/) y [Cloud TPU](https://cloud.google.com/tpu)."
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [],
      "name": "tpu_embedding.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
