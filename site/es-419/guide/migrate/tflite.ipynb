{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJcYs_ERTnnI"
      },
      "source": [
        "##### Copyright 2021 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "HMUDt0CiUJk9"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77z2OchJTk0l"
      },
      "source": [
        "# Migrar su código TFLite a TF2\n",
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td><a target=\"_blank\" href=\"https://www.tensorflow.org/guide/migrate/tflite\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver en TensorFlow.org</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/es-419/guide/migrate/tflite.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Ejecutar en Google Colab</a></td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/es-419/guide/migrate/tflite.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver código fuente en GitHub</a>\n",
        "</td>\n",
        "  <td><a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/es-419/guide/migrate/tflite.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Descargar bloc de notas</a></td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "meUTrR4I6m1C"
      },
      "source": [
        "[TensorFlow Lite](https://www.tensorflow.org/lite/guide) (TFLite) es un conjunto de herramientas que ayuda a los desarrolladores a correr inferencia ML sobre dispositivos (móviles, embebidos y dispositivos IoT). El conversor [TFLite](https://www.tensorflow.org/lite/convert) es una de esas herramientas que convierte los modelos TF existentes en un formato de modelo TFLite optimizado que puede ejecutarse de forma eficiente en el dispositivo.\n",
        "\n",
        "En este documento, aprenderá qué cambios debe realizar en su código de conversión de TF a TFLite, seguido de algunos ejemplos que hacen lo mismo.\n",
        "\n",
        "## Cambios en su código de conversión de TF a TFLite\n",
        "\n",
        "- Si está usando un formato de modelo TF1 heredado (como un archivo Keras, GraphDef congelado, puntos de verificación, tf.Session), actualícelo a TF1/TF2 SavedModel y use la API del conversor TF2 `tf.lite.TFLiteConverter.from_saved_model(...)` para convertirlo en un modelo TFLite (consulte la Tabla 1).\n",
        "\n",
        "- Actualice los indicadores de la API del convertidor (consulte la tabla 2).\n",
        "\n",
        "- Elimine las API heredadas como `tf.lite.constants`. (por ejemplo: Reemplace `tf.lite.constants.INT8` por `tf.int8`)\n",
        "\n",
        "// Tabla 1 // Actualización de la API del conversor Python TFLite\n",
        "\n",
        "API TF1 | API TF2\n",
        "--- | ---\n",
        "`tf.lite.TFLiteConverter.from_saved_model('saved_model/',..)` | *admitida*\n",
        "`tf.lite.TFLiteConverter.from_keras_model_file('model.h5',..)` | *retirada (actualización al formato SavedModel)*\n",
        "`tf.lite.TFLiteConverter.from_frozen_graph('model.pb',..)` | *retirada (actualización al formato SavedModel)*\n",
        "`tf.lite.TFLiteConverter.from_session(sess,...)` | *retirada (actualización al formato SavedModel)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rf75rjeedigq"
      },
      "source": [
        "&lt;style&gt;   .table {margin-left: 0 !important;} &lt;/style&gt;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbVlZNizW1-Y"
      },
      "source": [
        "// Tabla 2 // Actualización de indicadores de la API del conversor TFLite Python\n",
        "\n",
        "API TF1 | API TF2\n",
        "--- | ---\n",
        "`allow_custom_ops`<br>`optimizations`<br> `representative_dataset`<br>`target_spec` <br>`inference_input_type`<br>`inference_output_type`<br>`experimental_new_converter`<br> `experimental_new_quantizer` | *admitidas* <br><br><br><br><br><br><br><br>\n",
        "`input_tensors`<br>`output_tensors`<br>`input_arrays_with_shape`<br>`output_arrays`<br>`experimental_debug_info_func` | *retiradas (argumentos de la API del convertidor no admitidos)*<br><br><br><br><br>\n",
        "`change_concat_input_ranges`<br>`default_ranges_stats`<br>`get_input_arrays()`<br>`inference_type`<br>`quantized_input_stats`<br> `reorder_across_fake_quant` | *retiradas (flujos de trabajo de cuantización no admitidos)*<br><br><br><br><br><br>\n",
        "`conversion_summary_dir`<br>`dump_graphviz_dir`<br>`dump_graphviz_video` | *retiradas (en su lugar, visualice los modelos usando [Netron](https://lutzroeder.github.io/netron/) o [visualize.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/tools/visualize.py))*<br><br><br>\n",
        "`output_format`<br>`drop_control_dependency` | *retiradas (características no soportadas en TF2)*<br><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdZSoIXEbhg-"
      },
      "source": [
        "## Ejemplos\n",
        "\n",
        "Ahora verá algunos ejemplos para convertir modelos heredados de TF1 en TF1/TF2 SavedModels y luego convertirlos en modelos TF2 TFLite.\n",
        "\n",
        "### Preparación\n",
        "\n",
        "Comience con las importaciones necesarias de TensorFlow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iE0vSfMXumKI"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.compat.v1 as tf1\n",
        "import numpy as np\n",
        "\n",
        "import logging\n",
        "logger = tf.get_logger()\n",
        "logger.setLevel(logging.ERROR)\n",
        "\n",
        "import shutil\n",
        "def remove_dir(path):\n",
        "  try:\n",
        "    shutil.rmtree(path)\n",
        "  except:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89VllCprnFto"
      },
      "source": [
        "Cree todos los formatos de modelo TF1 necesarios."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bwq8EFiwjzjx"
      },
      "outputs": [],
      "source": [
        "# Create a TF1 SavedModel\n",
        "SAVED_MODEL_DIR = \"tf_saved_model/\"\n",
        "remove_dir(SAVED_MODEL_DIR)\n",
        "with tf1.Graph().as_default() as g:\n",
        "  with tf1.Session() as sess:\n",
        "    input = tf1.placeholder(tf.float32, shape=(3,), name='input')\n",
        "    output = input + 2\n",
        "    # print(\"result: \", sess.run(output, {input: [0., 2., 4.]}))\n",
        "    tf1.saved_model.simple_save(\n",
        "        sess, SAVED_MODEL_DIR,\n",
        "        inputs={'input': input}, \n",
        "        outputs={'output': output})\n",
        "print(\"TF1 SavedModel path: \", SAVED_MODEL_DIR)\n",
        "\n",
        "# Create a TF1 Keras model\n",
        "KERAS_MODEL_PATH = 'tf_keras_model.h5'\n",
        "model = tf1.keras.models.Sequential([\n",
        "    tf1.keras.layers.InputLayer(input_shape=(128, 128, 3,), name='input'),\n",
        "    tf1.keras.layers.Dense(units=16, input_shape=(128, 128, 3,), activation='relu'),\n",
        "    tf1.keras.layers.Dense(units=1, name='output')\n",
        "])\n",
        "model.save(KERAS_MODEL_PATH, save_format='h5')\n",
        "print(\"TF1 Keras Model path: \", KERAS_MODEL_PATH)\n",
        "\n",
        "# Create a TF1 frozen GraphDef model\n",
        "GRAPH_DEF_MODEL_PATH = tf.keras.utils.get_file(\n",
        "    'mobilenet_v1_0.25_128',\n",
        "    origin='https://storage.googleapis.com/download.tensorflow.org/models/mobilenet_v1_0.25_128_frozen.tgz',\n",
        "    untar=True,\n",
        ") + '/frozen_graph.pb'\n",
        "\n",
        "print(\"TF1 frozen GraphDef path: \", GRAPH_DEF_MODEL_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzMBpG5rdt-7"
      },
      "source": [
        "### 1. Convierta un TF1 SavedModel en un modelo TFLite\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFWIlVridt_F"
      },
      "source": [
        "#### Antes: Conversión con TF1\n",
        "\n",
        "Este es el código típico para la conversión TFlite estilo TF1.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dzXHHBQRdt_F"
      },
      "outputs": [],
      "source": [
        "converter = tf1.lite.TFLiteConverter.from_saved_model(\n",
        "    saved_model_dir=SAVED_MODEL_DIR,\n",
        "    input_arrays=['input'],\n",
        "    input_shapes={'input' : [3]}\n",
        ")\n",
        "converter.optimizations = {tf.lite.Optimize.DEFAULT}\n",
        "converter.change_concat_input_ranges = True\n",
        "tflite_model = converter.convert()\n",
        "# Ignore warning: \"Use '@tf.function' or '@defun' to decorate the function.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUptsxK_MUy2"
      },
      "source": [
        "#### Después: Conversión con TF2\n",
        "\n",
        "Convierte directamente el TF1 SavedModel en un modelo TFLite, estableciendo unos indicadores de conversión v2 más pequeños."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0OyBjZ6Kdt_F"
      },
      "outputs": [],
      "source": [
        "# Convert TF1 SavedModel to a TFLite model.\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir=SAVED_MODEL_DIR)\n",
        "converter.optimizations = {tf.lite.Optimize.DEFAULT}\n",
        "tflite_model = converter.convert()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yiwu3sso__fH"
      },
      "source": [
        "### 2. Convierta un archivo de modelo Keras TF1 en un modelo TFLite"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WTPvPih__fR"
      },
      "source": [
        "#### Antes: Conversión con TF1\n",
        "\n",
        "Este es el código típico para la conversión TFlite estilo TF1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9EXO0xYq__fR"
      },
      "outputs": [],
      "source": [
        "converter = tf1.lite.TFLiteConverter.from_keras_model_file(model_file=KERAS_MODEL_PATH)\n",
        "converter.optimizations = {tf.lite.Optimize.DEFAULT}\n",
        "converter.change_concat_input_ranges = True\n",
        "tflite_model = converter.convert()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9l6ppTtTZ5Bz"
      },
      "source": [
        "#### Después: Conversión con TF2\n",
        "\n",
        "Primero, convierta el archivo del modelo Keras TF1 en un SavedModel TF2 y, a continuación, conviértalo en un modelo TFLite, estableciendo unos indicadores de conversión v2 más pequeños."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IGB5ZMGl__fR"
      },
      "outputs": [],
      "source": [
        "# Convert TF1 Keras model file to TF2 SavedModel.\n",
        "model = tf.keras.models.load_model(KERAS_MODEL_PATH)\n",
        "model.save(filepath='saved_model_2/')\n",
        "\n",
        "# Convert TF2 SavedModel to a TFLite model.\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir='saved_model_2/')\n",
        "tflite_model = converter.convert()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5Zf6G4M-sZz"
      },
      "source": [
        "### 3. Convertir un GraphDef congelado TF1 en un modelo TFLite\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzCJOV7AUlGZ"
      },
      "source": [
        "#### Antes: Conversión con TF1\n",
        "\n",
        "Este es el código típico para la conversión TFlite estilo TF1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r7RvcdRv6lll"
      },
      "outputs": [],
      "source": [
        "converter = tf1.lite.TFLiteConverter.from_frozen_graph(\n",
        "    graph_def_file=GRAPH_DEF_MODEL_PATH,\n",
        "    input_arrays=['input'],\n",
        "    input_shapes={'input' : [1, 128, 128, 3]},\n",
        "    output_arrays=['MobilenetV1/Predictions/Softmax'],\n",
        ")\n",
        "converter.optimizations = {tf.lite.Optimize.DEFAULT}\n",
        "converter.change_concat_input_ranges = True\n",
        "tflite_model = converter.convert()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdIogJsKaMNH"
      },
      "source": [
        "#### Después: Conversión con TF2\n",
        "\n",
        "Primero, convierta el GraphDef congelado TF1 en un SavedModel TF1 y, a continuación, conviértalo en un modelo TFLite, con unos indicadores de convertidor v2 más pequeños configurados.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oigap0TZxjWG"
      },
      "outputs": [],
      "source": [
        "## Convert TF1 frozen Graph to TF1 SavedModel.\n",
        "\n",
        "# Load the graph as a v1.GraphDef\n",
        "import pathlib\n",
        "gdef = tf.compat.v1.GraphDef()\n",
        "gdef.ParseFromString(pathlib.Path(GRAPH_DEF_MODEL_PATH).read_bytes())\n",
        "\n",
        "# Convert the GraphDef to a tf.Graph\n",
        "with tf.Graph().as_default() as g:\n",
        "  tf.graph_util.import_graph_def(gdef, name=\"\")\n",
        "\n",
        "# Look up the input and output tensors.\n",
        "input_tensor = g.get_tensor_by_name('input:0') \n",
        "output_tensor = g.get_tensor_by_name('MobilenetV1/Predictions/Softmax:0')\n",
        "\n",
        "# Save the graph as a TF1 Savedmodel\n",
        "remove_dir('saved_model_3/')\n",
        "with tf.compat.v1.Session(graph=g) as s:\n",
        "  tf.compat.v1.saved_model.simple_save(\n",
        "      session=s,\n",
        "      export_dir='saved_model_3/',\n",
        "      inputs={'input':input_tensor},\n",
        "      outputs={'output':output_tensor})\n",
        "\n",
        "# Convert TF1 SavedModel to a TFLite model.\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir='saved_model_3/')\n",
        "converter.optimizations = {tf.lite.Optimize.DEFAULT}\n",
        "tflite_model = converter.convert()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFbsddkOw4Wl"
      },
      "source": [
        "# Lecturas adicionales\n",
        "\n",
        "- Consulte la [Guía de TFLite](https://www.tensorflow.org/lite/guide) para saber más sobre los flujos de trabajo y las funciones más recientes.\n",
        "- Si está usando código TF1 o formatos de modelos TF1 heredados (archivos Keras `.h5`, GraphDef `.pb` congelados, etc.), actualice su código y migre sus modelos al formato [TF2 SavedModel](https://www.tensorflow.org/guide/saved_model).\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "tflite.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
