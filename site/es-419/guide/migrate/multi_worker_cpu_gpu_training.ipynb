{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJcYs_ERTnnI"
      },
      "source": [
        "##### Copyright 2021 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "HMUDt0CiUJk9"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77z2OchJTk0l"
      },
      "source": [
        "# Migrar el entrenamiento multitrabajador con CPU/GPU\n",
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td><a target=\"_blank\" href=\"https://www.tensorflow.org/guide/migrate/multi_worker_cpu_gpu_training\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver en TensorFlow.org</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/es-419/guide/migrate/multi_worker_cpu_gpu_training.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Ejecutar en Google Colab</a></td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/es-419/guide/migrate/multi_worker_cpu_gpu_training.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver código fuente en GitHub</a>\n",
        "</td>\n",
        "  <td><a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/es-419/guide/migrate/multi_worker_cpu_gpu_training.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Descargar bloc de notas</a></td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "meUTrR4I6m1C"
      },
      "source": [
        "Esta guía demuestra cómo migrar su flujo de trabajo de entrenamiento distribuido multitrabajador de TensorFlow 1 a TensorFlow 2.\n",
        "\n",
        "Para realizar un entrenamiento multitrabajador con CPUs/GPUs:\n",
        "\n",
        "- En TensorFlow 1, usted usa tradicionalmente las APIs `tf.estimator.train_and_evaluate` y `tf.estimator.Estimator`.\n",
        "- En TensorFlow 2, use las API de Keras para escribir el modelo, la función de pérdida, el optimizador y las métricas. Luego, distribuya el entrenamiento con la API `Model.fit` de Keras o un bucle de entrenamiento personalizado (con `tf.GradientTape`) entre múltiples trabajadores con `tf.distribute.experimental.ParameterServerStrategy` o `tf.distribute.MultiWorkerMirroredStrategy`. Para más detalles, consulte los siguientes tutoriales:\n",
        "    - [Entrenamiento distribuido con TensorFlow](../../guide/distributed_training.ipynb)\n",
        "    - [Entrenamiento del servidor de parámetros con Model.fit de Keras/un bucle de entrenamiento personalizado](../../tutorials/distribute/parameter_server_training.ipynb)\n",
        "    - [MultiWorkerMirroredStrategy con Model.fit de Keras](../../tutorials/distribute/multi_worker_with_keras.ipynb)\n",
        "    - [MultiWorkerMirroredStrategy con un bucle de entrenamiento personalizado](../../tutorials/distribute/multi_worker_with_ctl.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdZSoIXEbhg-"
      },
      "source": [
        "## Preparación"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28f46832b54d"
      },
      "source": [
        "Comience con algunas importaciones necesarias y un conjunto de datos sencillo a modo de demostración:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iE0vSfMXumKI"
      },
      "outputs": [],
      "source": [
        "# The notebook uses a dataset instance for `Model.fit` with\n",
        "# `ParameterServerStrategy`, which depends on symbols in TF 2.7.\n",
        "# Install a utility needed for this demonstration\n",
        "!pip install portpicker\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.compat.v1 as tf1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m7rnGxsXtDkV"
      },
      "outputs": [],
      "source": [
        "features = [[1., 1.5], [2., 2.5], [3., 3.5]]\n",
        "labels = [[0.3], [0.5], [0.7]]\n",
        "eval_features = [[4., 4.5], [5., 5.5], [6., 6.5]]\n",
        "eval_labels = [[0.8], [0.9], [1.]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2uaw9QaDM_X"
      },
      "source": [
        "Necesitará la variable de entorno de configuración `'TF_CONFIG'` para entrenar en múltiples máquinas en TensorFlow. Use `'TF_CONFIG'` para especificar las direcciones del `'cluster'` y de las `'task'`s. (Más información en la guía [Entrenamiento distribuido](../...guide/distributed_training.ipynb))."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4OUzwoQgXgkG"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "tf_config = {\n",
        "    'cluster': {\n",
        "        'chief': ['localhost:11111'],\n",
        "        'worker': ['localhost:12345', 'localhost:23456', 'localhost:21212'],\n",
        "        'ps': ['localhost:12121', 'localhost:13131'],\n",
        "    },\n",
        "    'task': {'type': 'chief', 'index': 0}\n",
        "}\n",
        "\n",
        "os.environ['TF_CONFIG'] = json.dumps(tf_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbeoSbbmDdc0"
      },
      "source": [
        "Nota: Desafortunadamente, ya que el entrenamiento multitrabajador con las APIs `tf.estimator` en TensorFlow 1 requiere múltiples clientes (lo que sería especialmente difícil de hacer aquí en este bloc de notas Colab), hará que el bloc de notas sea ejecutable sin una variable de entorno `'TF_CONFIG'`, así que vuelve a caer en el entrenamiento local (más información en la sección <em data-md-type=\"emphasis\">Cómo establecer la variable de entorno `'TF_CONFIG'`</em> de la guía [Entrenamiento distribuido con TensorFlow](../../guide/distributed_training.ipynb)).\n",
        "\n",
        "Use la sentencia `del` para eliminar la variable (pero en el entrenamiento multitrabajador del mundo real en TensorFlow 1, no tendrá que hacerlo):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AHuynAR5D8sU"
      },
      "outputs": [],
      "source": [
        "del os.environ['TF_CONFIG']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4uXff1BEssdE"
      },
      "source": [
        "## TensorFlow 1: Entrenamiento distribuido multitrabajador con APIs tf.estimator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpyINdiLEN3c"
      },
      "source": [
        "El siguiente fragmento de código demuestra el flujo de trabajo canónico del entrenamiento multitrabajador en TF1: usará un `tf.estimator.Estimator`, un `tf.estimator.TrainSpec`, un `tf.estimator.EvalSpec`, y la API `tf.estimator.train_and_evaluate` para distribuir el entrenamiento:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lqe9obf7suIj"
      },
      "outputs": [],
      "source": [
        "def _input_fn():\n",
        "  return tf1.data.Dataset.from_tensor_slices((features, labels)).batch(1)\n",
        "\n",
        "def _eval_input_fn():\n",
        "  return tf1.data.Dataset.from_tensor_slices(\n",
        "      (eval_features, eval_labels)).batch(1)\n",
        "\n",
        "def _model_fn(features, labels, mode):\n",
        "  logits = tf1.layers.Dense(1)(features)\n",
        "  loss = tf1.losses.mean_squared_error(labels=labels, predictions=logits)\n",
        "  optimizer = tf1.train.AdagradOptimizer(0.05)\n",
        "  train_op = optimizer.minimize(loss, global_step=tf1.train.get_global_step())\n",
        "  return tf1.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)\n",
        "\n",
        "estimator = tf1.estimator.Estimator(model_fn=_model_fn)\n",
        "train_spec = tf1.estimator.TrainSpec(input_fn=_input_fn)\n",
        "eval_spec = tf1.estimator.EvalSpec(input_fn=_eval_input_fn)\n",
        "tf1.estimator.train_and_evaluate(estimator, train_spec, eval_spec)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEmzBjfnsxwT"
      },
      "source": [
        "## TensorFlow 2: Entrenamiento multitrabajador con estrategias de distribución"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Syb66qsbEp1x"
      },
      "source": [
        "En TensorFlow 2, el entrenamiento distribuido entre varios trabajadores con CPU, GPU y TPU se realiza a través de `tf.distribute.Strategy`s.\n",
        "\n",
        "El siguiente ejemplo demuestra cómo usar dos estrategias de este tipo: `tf.distribute.experimental.ParameterServerStrategy` y `tf.distribute.MultiWorkerMirroredStrategy`, ambas diseñadas para el entrenamiento de CPU/GPU con múltiples trabajadores.\n",
        "\n",
        "`ParameterServerStrategy` emplea un *coordinador* (`'chiel'`), que lo hace más amigable con el entorno de este bloc de notas Colab. Aquí usará algunas utilidades para configurar los elementos de apoyo esenciales para una experiencia ejecutable: creará un *cluster interno del proceso*, en el que se usarán hilos para simular los servidores de parámetros (`'ps'`) y los trabajadores (`'worker'`). Para más información sobre el entrenamiento de servidores de parámetros, consulte el tutorial [Entrenamiento de servidores de parámetros con ParameterServerStrategy](../../tutorials/distribute/parameter_server_training.ipynb).\n",
        "\n",
        "En este ejemplo, defina primero la variable de entorno `'TF_CONFIG'` con un `tf.distribute.cluster_resolver.TFConfigClusterResolver` para ofrecer la información del clúster. Si utiliza un sistema de gestión de clústeres para su entrenamiento distribuido, compruebe si ya suministra `'TF_CONFIG'` para usted, en cuyo caso no necesitará establecer explícitamente esta variable de entorno (más información en la sección <em data-md-type=\"emphasis\">Cómo configurar la variable de entorno `'TF_CONFIG'`</em> de la guía [Entrenamiento distribuido con TensorFlow](../../guide/distributed_training.ipynb))."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rp-gFY0H5rF-"
      },
      "outputs": [],
      "source": [
        "# Find ports that are available for the `'chief'` (the coordinator),\n",
        "# `'worker'`s, and `'ps'` (parameter servers).\n",
        "import portpicker\n",
        "\n",
        "chief_port = portpicker.pick_unused_port()\n",
        "worker_ports = [portpicker.pick_unused_port() for _ in range(3)]\n",
        "ps_ports = [portpicker.pick_unused_port() for _ in range(2)]\n",
        "\n",
        "# Dump the cluster information to `'TF_CONFIG'`.\n",
        "tf_config = {\n",
        "    'cluster': {\n",
        "        'chief': [\"localhost:%s\" % chief_port],\n",
        "        'worker': [\"localhost:%s\" % port for port in worker_ports],\n",
        "        'ps':  [\"localhost:%s\" % port for port in ps_ports],\n",
        "    },\n",
        "    'task': {'type': 'chief', 'index': 0}\n",
        "}\n",
        "os.environ['TF_CONFIG'] = json.dumps(tf_config)\n",
        "\n",
        "# Use a cluster resolver to bridge the information to the strategy created below.\n",
        "cluster_resolver = tf.distribute.cluster_resolver.TFConfigClusterResolver()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_8uVvJb6dqq"
      },
      "source": [
        "Después, cree `tf.distribute.Server`s para los trabajadores y servidores de parámetros uno a uno:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJopinmG6b2z"
      },
      "outputs": [],
      "source": [
        "# Workers need some inter_ops threads to work properly.\n",
        "# This is only needed for this notebook to demo. Real servers\n",
        "# should not need this.\n",
        "worker_config = tf.compat.v1.ConfigProto()\n",
        "worker_config.inter_op_parallelism_threads = 4\n",
        "\n",
        "for i in range(3):\n",
        "  tf.distribute.Server(\n",
        "      cluster_resolver.cluster_spec(),\n",
        "      job_name=\"worker\",\n",
        "      task_index=i,\n",
        "      config=worker_config)\n",
        "\n",
        "for i in range(2):\n",
        "  tf.distribute.Server(\n",
        "      cluster_resolver.cluster_spec(),\n",
        "      job_name=\"ps\",\n",
        "      task_index=i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IpfCcF0g6Ao8"
      },
      "source": [
        "En el entrenamiento distribuido en el mundo real, en lugar de iniciar todos los `tf.distribute.Server`s en el coordinador, usará múltiples máquinas, y las que se designen como `\"worker\"`s y `\"ps\"` (servidores de parámetros) ejecutarán cada una un `tf.distribute.Server`. Consulte la sección *Clusters en el mundo real* del tutorial [Servidor de parámetros](../../tutorials/distribute/parameter_server_training.ipynb) para obtener más detalles.\n",
        "\n",
        "Con todo listo, cree el objeto `ParameterServerStrategy`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t45iQeBT7Us_"
      },
      "outputs": [],
      "source": [
        "strategy = tf.distribute.experimental.ParameterServerStrategy(cluster_resolver)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "diNsps1MGRS6"
      },
      "source": [
        "Una vez que haya creado un objeto de estrategia, defina el modelo, el optimizador y otras variables, y llame al `Model.compile` de Keras dentro de la API `Strategy.scope` para distribuir el entrenamiento (consulte la documentación de la API `Strategy.scope` para obtener más información).\n",
        "\n",
        "Si prefiere personalizar su entrenamiento definiendo, por ejemplo, las pasadas hacia delante y hacia atrás, consulte la sección *Entrenamiento con un bucle de entrenamiento personalizado* del tutorial [Entrenamiento de servidor de parámetros](../../tutorials/distribute/parameter_server_training.ipynb) para saber más."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "atVciNgPs0fw"
      },
      "outputs": [],
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices(\n",
        "      (features, labels)).shuffle(10).repeat().batch(64)\n",
        "\n",
        "eval_dataset = tf.data.Dataset.from_tensor_slices(\n",
        "      (eval_features, eval_labels)).repeat().batch(1)\n",
        "\n",
        "with strategy.scope():\n",
        "  model = tf.keras.models.Sequential([tf.keras.layers.Dense(1)])\n",
        "  optimizer = tf.keras.optimizers.legacy.Adagrad(learning_rate=0.05)\n",
        "  model.compile(optimizer, \"mse\")\n",
        "\n",
        "model.fit(dataset, epochs=5, steps_per_epoch=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "akZ0aaaS1vA9"
      },
      "outputs": [],
      "source": [
        "model.evaluate(eval_dataset, steps=10, return_dict=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXbS71XmMSoO"
      },
      "source": [
        "> **Particionadores (`tf.distribute.experimental.partitioners`)**\n",
        ">\n",
        "> `ParameterServerStrategy` en TensorFlow 2 es compatible con la partición de variables y ofrece los mismos particionadores que TensorFlow 1, con nombres menos confusos:\n",
        ">\n",
        "> - `tf.compat.v1.variable_axis_size_partitioner` -&gt; `tf.distribute.experimental.partitioners.MaxSizePartitioner`: un particionador que conserva los fragmentos por debajo de un tamaño máximo).\n",
        "> - `tf.compat.v1.min_max_variable_partitioner` -&gt; `tf.distribute.experimental.partitioners.MinSizePartitioner`: un particionador que asigna un tamaño mínimo por fragmento.\n",
        "> - `tf.compat.v1.fixed_size_partitioner` -&gt; `tf.distribute.experimental.partitioners.FixedShardsPartitioner`: un particionador que asigna un número fijo de fragmentos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ig0-uCUbGprd"
      },
      "source": [
        "Como alternativa, puede usar un objeto `MultiWorkerMirroredStrategy`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xHXP8bOBGtXL"
      },
      "outputs": [],
      "source": [
        "# To clean up the `TF_CONFIG` used for `ParameterServerStrategy`.\n",
        "del os.environ['TF_CONFIG']\n",
        "strategy = tf.distribute.MultiWorkerMirroredStrategy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOsmqefTGwUf"
      },
      "source": [
        "Puede reemplazar la estrategia utilizada anteriormente por un objeto `MultiWorkerMirroredStrategy` para realizar el entrenamiento con esta estrategia.\n",
        "\n",
        "Al igual que con las APIs `tf.estimator`, dado que `MultiWorkerMirroredStrategy` es una estrategia multicliente, no existe una forma sencilla de ejecutar un entrenamiento distribuido en este bloc de notas Colab. Por lo tanto, si se sustituye el código anterior por esta estrategia, se acabará ejecutando todo localmente. Los tutoriales Entrenamiento multitrabajador [con Model.fit de Keras](../../tutorials/distribute/multi_worker_with_keras.ipynb)/[un bucle de entrenamiento personalizado](../../tutorials/distribute/multi_worker_with_ctl.ipynb) demuestran cómo ejecutar un entrenamiento multitrabajador con la variable `'TF_CONFIG'` configurada, con dos trabajadores en un localhost en Colab. En la práctica, usted crearía múltiples trabajadores en direcciones IP/puertos externos, y usaría la variable `'TF_CONFIG'` para especificar la configuración del cluster para cada trabajador."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "917ef6135660"
      },
      "source": [
        "## Siguientes pasos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e76fd9d5c98c"
      },
      "source": [
        "Para saber más sobre el entrenamiento distribuido multitrabajador con `tf.distribute.experimental.ParameterServerStrategy` y `tf.distribute.MultiWorkerMirroredStrategy` en TensorFlow 2, tenga en cuenta los siguientes recursos:\n",
        "\n",
        "- Tutorial: [Entrenamiento del servidor de parámetros con ParameterServerStrategy y Model.fit de Keras/bucle de entrenamiento personalizado](../../tutorials/distribute/parameter_server_training.ipynb)\n",
        "- Tutorial: [Entrenamiento multitrabajador con MultiWorkerMirroredStrategy y Model.fit de Keras](../../tutorials/distribute/multi_worker_with_keras.ipynb)\n",
        "- Tutorial: [Entrenamiento multitrabajador con MultiWorkerMirroredStrategy y un bucle de entrenamiento personalizado](../../tutorials/distribute/multi_worker_with_ctl.ipynb)\n",
        "- Guía: [Entrenamiento distribuido con TensorFlow](../../guide/distributed_training.ipynb)\n",
        "- Guía: [Optimice el rendimiento de la GPU de TensorFlow con TensorFlow Profiler](../../guide/gpu_performance_analysis.ipynb)\n",
        "- Guía: [Cómo utilizar una GPU](../../guide/gpu.ipynb) (la sección Utilizar varias GPU)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "multi_worker_cpu_gpu_training.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
