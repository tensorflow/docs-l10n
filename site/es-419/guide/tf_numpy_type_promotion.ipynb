{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjN_IJ8mhJ-4"
      },
      "source": [
        "##### Copyright 2023 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "sY3Ffd83hK3b"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03Pw58e6mTHI"
      },
      "source": [
        "# Promoción de tipos TF-NumPy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9nPKvxK-_pM"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td><a target=\"_blank\" href=\"https://www.tensorflow.org/guide/tf_numpy_type_promotion\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver en TensorFlow.org</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/es-419/guide/tf_numpy_type_promotion.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Ejecutar en Google Colab</a></td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/es-419/guide/tf_numpy_type_promotion.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver fuente en GitHub</a>\n",
        "</td>\n",
        "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/es-419/guide/tf_numpy_type_promotion.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Descargar bloc de notas</a>\n",
        "</td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uma-W5v__DYh"
      },
      "source": [
        "## Descripción general\n",
        "\n",
        "Hay 4 opciones de promoción de tipos en TensorFlow.\n",
        "\n",
        "- Por defecto, TensorFlow arroja errores en vez de promover tipos para operaciones de tipo mezclado.\n",
        "- Al ejecutar `tf.numpy.experimental_enable_numpy_behavior()`, TensorFlow cambia y usa [reglas de promoción de tipos NumPy](https://www.tensorflow.org/guide/tf_numpy#type_promotion).\n",
        "- En **este documento** se describen dos opciones nuevas que estarán disponibles en TensorFlow 2.15 (o que ya se encuentran en `tf-nightly`):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vMvEKDFOsau7"
      },
      "outputs": [],
      "source": [
        "!pip install -q tf_nightly"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6hOFBfPsd3y"
      },
      "source": [
        "**Nota**: `experimental_enable_numpy_behavior` cambia el comportamiento de todo lo de TensorFlow."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ob1HNwUmYR5b"
      },
      "source": [
        "## Preparación"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AJR558zjAZQu"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow.experimental.numpy as tnp\n",
        "\n",
        "print(\"Using TensorFlow version %s\" % tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6tacoy0DU6e"
      },
      "source": [
        "### Habilitación de la nueva promoción de tipos\n",
        "\n",
        "A fin de usar la [promoción de tipos como JAX](https://jax.readthedocs.io/en/latest/type_promotion.html) en TF-Numpy, especifique `'all'` o `'safe'` como modos de conversión de tipo d al habilitar el comportamiento NumPy para TensorFlow.\n",
        "\n",
        "Este sistema nuevo (con `dtype_conversion_mode=\"all\"`) es asociativo, conmutativo y facilita el control del ancho del flotante que se termina aplicando (no convierte automáticamente a flotantes más anchos). Lo que sí hace es presentar algunos riesgos de desbordamiento o de pérdida de precisión, pero `dtype_conversion_mode=\"safe\"` lo forzará a ocuparse de esos casos explícitamente. Ambos modos se explican con más detalle en la [próxima sección](#two_modes)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TfCyofpFDQxm"
      },
      "outputs": [],
      "source": [
        "tnp.experimental_enable_numpy_behavior(dtype_conversion_mode=\"all\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEMXK8-ZWMun"
      },
      "source": [
        "<a name=\"two_modes\">\n",
        "</a>\n",
        "\n",
        "## Dos modos: modo ALL vs. modo SAFE\n",
        "\n",
        "Con el sistema de promoción de tipos nueva, presentamos dos modos: el modo `ALL` y el modo `SAFE`. El modo `SAFE` se usa para mitigar las posibles promociones \"riesgosas\" que podrían resultar a partir de la pérdida de precisión o de la ampliación en bits."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ULvTWj_KnHU"
      },
      "source": [
        "### Tipos d\n",
        "\n",
        "Para no extendernos, usaremos las siguientes abreviaturas.\n",
        "\n",
        "- `b` significa `tf.bool`\n",
        "- `u8` significa `tf.uint8`\n",
        "- `i16` significa `tf.int16`\n",
        "- `i32` significa `tf.int32`\n",
        "- `bf16` significa `tf.bfloat16`\n",
        "- `f32` significa `tf.float32`\n",
        "- `f64` significa `tf.float64`\n",
        "- `i32*` significa `int` en Python o `i32` débilmente tipado.\n",
        "- `f32*` significa `float` en Python o `f32` débilmente tipado.\n",
        "- `c128*` significa `complex` en Python o `c128` débilmente tipado.\n",
        "\n",
        "El asterisco (*) denota que el tipo correspondiente es \"débil\", como un tipo d que el sistema infiere temporalmente y podría diferir a otros tipos d. Este concepto se explica más en detalle [aquí](#weak_tensor)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXZxLCkuzzq3"
      },
      "source": [
        "### Ejemplo de operaciones de pérdida de precisión\n",
        "\n",
        "En el siguiente ejemplo, `i32` + `f32` se admite en el modo `ALL` pero no en el modo `SAFE` debido al riesgo de pérdida de precisión."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y-yeIvstWStL"
      },
      "outputs": [],
      "source": [
        "# i32 + f32 returns a f32 result in ALL mode.\n",
        "tnp.experimental_enable_numpy_behavior(dtype_conversion_mode=\"all\")\n",
        "a = tf.constant(10, dtype = tf.int32)\n",
        "b = tf.constant(5.0, dtype = tf.float32)\n",
        "a + b  # <tf.Tensor: shape=(), dtype=float32, numpy=15.0>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JNNmZow2WY3G"
      },
      "outputs": [],
      "source": [
        "# This promotion is not allowed in SAFE mode.\n",
        "tnp.experimental_enable_numpy_behavior(dtype_conversion_mode=\"safe\")\n",
        "a = tf.constant(10, dtype = tf.int32)\n",
        "b = tf.constant(5.0, dtype = tf.float32)\n",
        "try:\n",
        "  a + b\n",
        "except TypeError as e:\n",
        "   print(f'{type(e)}: {e}')  # TypeError: explicitly specify the dtype or switch to ALL mode."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0x4Qhff0AKS"
      },
      "source": [
        "### Ejemplo de operaciones de ampliación de bits\n",
        "\n",
        "En el siguiente ejemplo, `i8` + `u32` se admite en el modo `ALL`, pero no en el modo `SAFE` debido a la ampliación de bits, que implica usar más bits de los que hay en las entradas. Tenga en cuenta que la semántica de la promoción de tipos nueva solamente permite la ampliación de bits necesaria."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Etbv-WoWzUXf"
      },
      "outputs": [],
      "source": [
        "# i8 + u32 returns an i64 result in ALL mode.\n",
        "tnp.experimental_enable_numpy_behavior(dtype_conversion_mode=\"all\")\n",
        "a = tf.constant(10, dtype = tf.int8)\n",
        "b = tf.constant(5, dtype = tf.uint32)\n",
        "a + b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yKRdvtvw0Lvt"
      },
      "outputs": [],
      "source": [
        "# This promotion is not allowed in SAFE mode.\n",
        "tnp.experimental_enable_numpy_behavior(dtype_conversion_mode=\"safe\")\n",
        "a = tf.constant(10, dtype = tf.int8)\n",
        "b = tf.constant(5, dtype = tf.uint32)\n",
        "try:\n",
        "  a + b\n",
        "except TypeError as e:\n",
        "   print(f'{type(e)}: {e}')  # TypeError: explicitly specify the dtype or switch to ALL mode."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yh2BwqUzH3C3"
      },
      "source": [
        "## Un sistema basado en retículo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHUnfTPiYVN5"
      },
      "source": [
        "### Promoción de tipos basada en retículo\n",
        "\n",
        "El comportamiento de la promoción de tipos nueva se determina a través de la siguiente promoción de tipos basada en retículo (<em>lattice</em>):\n",
        "\n",
        "![Promoción de tipo basada en retículo](https://tensorflow.org/guide/images/new_type_promotion/type_promotion_lattice.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QykluwRyDDle"
      },
      "source": [
        "Para ser más específicos, la promoción entre dos tipos cualquiera está determinada por encontrar el primer hijo común de los dos nodos (incluidos los mismos nodos).\n",
        "\n",
        "Por ejemplo, en el diagrama anterior, el primer hijo común de `i8` e `i32` es `i32` porque la intersección de los dos nodos se produce por primera vez en `i32`, cuando se sigue la dirección de las flechas.\n",
        "\n",
        "De un modo similar, como en otro ejemplo, el resultado de la promoción de tipos entre `u64` y `f16` sería `f16`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nthziRHaDAUY"
      },
      "source": [
        "<a name=\"promotion_table\">\n",
        "</a>\n",
        "\n",
        "### Tabla de promoción de tipos\n",
        "\n",
        "Después de la promoción basada en retículo se genera la tabla de promoción binaria que se encuentra a continuación:\n",
        "\n",
        "**Nota**: el modo `SAFE` rechaza las celdas destacadas. El modo `ALL` admite todos los casos.\n",
        "\n",
        "![Tabla de promoción de tipo](https://tensorflow.org/guide/images/new_type_promotion/type_promotion_table.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPDt5QTkucSC"
      },
      "source": [
        "## Ventajas de la promoción de tipos nueva\n",
        "\n",
        "Adoptamos un sistema basado en retículo como JAX para nuestra promoción de tipos nueva, que ofrece las siguientes ventajas:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUS_b13nue1p"
      },
      "source": [
        "<a name=\"lattice_system_design\">\n",
        "</a>\n",
        "\n",
        "#### Ventajas del sistema basado en retículo\n",
        "\n",
        "Primero, al usar un sistema basado en retículo se garantizan tres propiedades importantes:\n",
        "\n",
        "- Existencia: Hay un único resultado de la promoción de tipos independientemente de las combinaciones de tipo que se hagan.\n",
        "- Conmutabilidad: `a + b = b + a`\n",
        "- Asociatividad: `a + (b + c) = (a + b) = c`\n",
        "\n",
        "Estas tres propiedades son críticas para construir una semántica para la promoción de tipos que sea consistente y predecible."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sz88hRR6uhls"
      },
      "source": [
        "#### Ventajas del sistema basado en retículo en JAX o bibliotecas similares\n",
        "\n",
        "Otra ventaja crucial del sistema basado en retículo en JAX o bibliotecas similares es que fuera de los enteros sin asignar, evita todas las promociones que sean más amplias de lo necesario. Significa que no es posible obtener resultados de 64 bits sin entradas de 64 bits. Esto es particularmente beneficioso para trabajar con aceleradores, ya que evita valores de 64 bits innecesarios, algo que se producía frecuentemente con el tipo anterior de promoción."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlylb7ieOVbJ"
      },
      "source": [
        "Sin embargo, viene con una contrapartida: la promoción de enteros/flotantes combinada es muy propensa a la pérdida de precisión. Observemos, en el ejemplo a continuación, el resultado de `i64` + `f16` es la promoción de `i64` a `f16`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "abqIkV02OXEF"
      },
      "outputs": [],
      "source": [
        "# The first input is promoted to f16 in ALL mode.\n",
        "tnp.experimental_enable_numpy_behavior(dtype_conversion_mode=\"all\")\n",
        "tf.constant(1, tf.int64) + tf.constant(3.2, tf.float16)  # <tf.Tensor: shape=(), dtype=float16, numpy=4.2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYnh1gZdObfI"
      },
      "source": [
        "Para mitigar este problema, presentamos un modo `SAFE` que rechazará estas promociones \"riesgosas\".\n",
        "\n",
        "**Nota**: Para conocer más acerca de las consideraciones relacionadas con el diseño en la construcción del sistema basado en retículo, consulte la información sobre el [diseño de la semántica de promoción de tipos para JAX](https://jax.readthedocs.io/en/latest/jep/9407-type-promotion.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAc7LFV0S2dP"
      },
      "source": [
        "<a name=\"weak_tensor\">\n",
        "</a>\n",
        "\n",
        "## WeakTensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olQ2gsFlS9BH"
      },
      "source": [
        "### Descripción general\n",
        "\n",
        "Los *tensores débiles* son tensores que están \"débilmente tipados\", similares a un [concepto en JAX](https://jax.readthedocs.io/en/latest/type_promotion.html#weakly-typed-values-in-jax).\n",
        "\n",
        "El sistema infiere temporalmente el tipo d de `WeakTensor` y podría delegar a otros tipos d. Este concepto se introduce en la nueva promoción de tipos para evitar la promoción de tipos no deseados dentro de operaciones binarias entre valores TF y valores con tipos con usuarios especificados no explícitos, como los escalares literales en Python."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYmoFIqZTFtw"
      },
      "source": [
        "Observemos, en el ejemplo a continuación, `tf.constant(1.2)` es considerada \"débil\" porque no tiene un tipo d específico. Por lo tanto, `tf.constant(1.2)` delega al tipo `tf.constant(3.1, tf.float16)`, dando como resultado una salida `f16`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eSBv_mzyTE97"
      },
      "outputs": [],
      "source": [
        "tf.constant(1.2) + tf.constant(3.1, tf.float16)  # <tf.Tensor: shape=(), dtype=float16, numpy=4.3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxuqBIFuTm5Z"
      },
      "source": [
        "### Construcción de tensores débiles\n",
        "\n",
        "Los tensores débiles (WeakTensor) se generan a partir de la creación de un tensor sin especificar el tipo d. En esos casos, el resultado es un WeakTensor. Se puede comprobar si un tensor es \"débil\" (<em>weak</em>) o no, controlando el atributo al final de la representación de la <em>string</em> del tensor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7UmunnJ8Tru3"
      },
      "source": [
        "**Primer caso**: cuando `tf.constant` se invoca con una entrada de tipo d sin usuario especificado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fLEtMluNTsI5"
      },
      "outputs": [],
      "source": [
        "tf.constant(5)  # <tf.Tensor: shape=(), dtype=int32, numpy=5, weak=True>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZQX6MBWHTt__"
      },
      "outputs": [],
      "source": [
        "tf.constant([5.0, 10.0, 3])  # <tf.Tensor: shape=(3,), dtype=float32, numpy=array([ 5., 10.,  3.], dtype=float32), weak=True>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ftsKSC5BTweP"
      },
      "outputs": [],
      "source": [
        "# A normal Tensor is created when dtype arg is specified.\n",
        "tf.constant(5, tf.int32)  # <tf.Tensor: shape=(), dtype=int32, numpy=5>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqhoRy5iTyag"
      },
      "source": [
        "**Segundo caso**: cuando una entrada tipo d sin usuario especificado se pasa a una [API compatible con WeakTensor](#weak_tensor_apis)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DuwpgoQJTzE-"
      },
      "outputs": [],
      "source": [
        "tf.math.abs([100.0, 4.0])  # <tf.Tensor: shape=(2,), dtype=float32, numpy=array([100., 4.], dtype=float32), weak=True>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTcoR1xvR39k"
      },
      "source": [
        "##Efectos de activar la nueva promoción de tipos\n",
        "\n",
        "A continuación, hay una lista no exhaustiva de los cambios que resultan de la activación de la promoción de tipos nueva.\n",
        "\n",
        "- Resultados de promoción más consistentes y predecibles.\n",
        "- Riesgo reducido de ampliación de bits.\n",
        "- Los métodos mágicos (<em>dunder</em>) de `tf.Tensor` usan la promoción de tipos nueva.\n",
        "- `tf.constant` puede devolver `WeakTensor`.\n",
        "- `tf.constant` permite conversiones implícitas cuando una entrada de tensor se pasa con un tipo d diferente del argumento `dtype`.\n",
        "- Las operaciones (ops) `tf.Variable` en el lugar (`assign`, `assign-add`, `assign-sub`) permiten conversiones implícitas.\n",
        "- `tnp.array(1)` y `tnp.array(1.0)` devuelve WeakTensor de 32 bits.\n",
        "- Los `WeakTensor` se crearán y usarán para las [API unarias y binarias de WeakTensor](#weak_tensor_apis).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KyvonwYcsFX2"
      },
      "source": [
        "### Resultados de promoción más consistentes y predecibles\n",
        "\n",
        "Usar un [sistema basado en retículo (lattice)](#lattice_system_design) permite que la promoción de tipos nueva produzca resultados de promoción de tipos que son consistentes y predecibles."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0Z1njfb7lRa"
      },
      "source": [
        "#### Promoción de tipos anterior\n",
        "\n",
        "Con la promoción de tipos anterior, al cambiar el orden de las operaciones se producen resultados inconsistentes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M1Ca9v4m7z8e"
      },
      "outputs": [],
      "source": [
        "# Setup\n",
        "tnp.experimental_enable_numpy_behavior(dtype_conversion_mode=\"legacy\")\n",
        "a = np.array(1, dtype=np.int8)\n",
        "b = tf.constant(1)\n",
        "c = np.array(1, dtype=np.float16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WwhTzJ-a4rTc"
      },
      "outputs": [],
      "source": [
        "# (a + b) + c throws an InvalidArgumentError.\n",
        "try:\n",
        "  tf.add(tf.add(a, b), c)\n",
        "except tf.errors.InvalidArgumentError as e:\n",
        "  print(f'{type(e)}: {e}')  # InvalidArgumentError"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d3qDgVYn7ezT"
      },
      "outputs": [],
      "source": [
        "# (b + a) + c returns an i32 result.\n",
        "tf.add(tf.add(b, a), c)  # <tf.Tensor: shape=(), dtype=int32, numpy=3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMH1skEs7oI5"
      },
      "source": [
        "#### Promoción de tipos nueva\n",
        "\n",
        "La promoción de tipos nueva produce resultados consistentes independientemente del orden."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BOHyJJ8z8uCN"
      },
      "outputs": [],
      "source": [
        "tnp.experimental_enable_numpy_behavior(dtype_conversion_mode=\"all\")\n",
        "a = np.array(1, dtype=np.int8)\n",
        "b = tf.constant(1)\n",
        "c = np.array(1, dtype=np.float16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZUKU70jf7E1l"
      },
      "outputs": [],
      "source": [
        "# (a + b) + c returns a f16 result.\n",
        "tf.add(tf.add(a, b), c)  # <tf.Tensor: shape=(), dtype=float16, numpy=3.0>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YOEycjFx7qDn"
      },
      "outputs": [],
      "source": [
        "# (b + a) + c also returns a f16 result.\n",
        "tf.add(tf.add(b, a), c)  # <tf.Tensor: shape=(), dtype=float16, numpy=3.0>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpGMkm6aJsn6"
      },
      "source": [
        "### Riesgo reducido de ampliación de bits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxV2AL-U9Grg"
      },
      "source": [
        "#### Promoción de tipos anterior\n",
        "\n",
        "La promoción de tipos anterior, con frecuencia, producía resultados en 64 bits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7L1pxyvn9MlP"
      },
      "outputs": [],
      "source": [
        "tnp.experimental_enable_numpy_behavior(dtype_conversion_mode=\"legacy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zMJVFdWf4XHp"
      },
      "outputs": [],
      "source": [
        "np.array(3.2, np.float16) + tf.constant(1, tf.int8) + tf.constant(50)  # <tf.Tensor: shape=(), dtype=float64, numpy=54.19921875>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBhUH_wD9Is7"
      },
      "source": [
        "#### Promoción de tipos nueva\n",
        "\n",
        "La promoción de tipos nueva devuelve resultados con el número mínimo de bits necesario."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aJsj2ZyI9T9Y"
      },
      "outputs": [],
      "source": [
        "tnp.experimental_enable_numpy_behavior(dtype_conversion_mode=\"all\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jj0N_Plp4X9l"
      },
      "outputs": [],
      "source": [
        "np.array(3.2, np.float16) + tf.constant(1, tf.int8) + tf.constant(50)  # <tf.Tensor: shape=(), dtype=float16, numpy=54.2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKUx7xe-KZ5O"
      },
      "source": [
        "### Los métodos mágicos (dunder) matemáticos en tf.Tensor\n",
        "\n",
        "Todos los métodos mágicos (dunder) matemáticos en `tf.Tensor` seguirán la misma promoción de tipos nueva."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2c3icBUX4wNl"
      },
      "outputs": [],
      "source": [
        "-tf.constant(5)  # <tf.Tensor: shape=(), dtype=int32, numpy=-5, weak=True>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ydJHQjid45s7"
      },
      "outputs": [],
      "source": [
        "tf.constant(5, tf.int16) - tf.constant(1, tf.float32)  # <tf.Tensor: shape=(), dtype=float32, numpy=4.0>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLbIjIvbKqcU"
      },
      "source": [
        "### Operaciones en el lugar con tf.Variable\n",
        "\n",
        "Las conversiones implícitas se podrán hacer en operaciones en el lugar con `tf.Variable`.\n",
        "\n",
        "**Nota**: no se permitirá ninguna promoción que dé como resultado un tipo d que sea diferente del tipo d original de la variable. El motivo es que `tf.Variable` no puede cambiar su tipo d."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QsXhyK1h-i5S"
      },
      "outputs": [],
      "source": [
        "tnp.experimental_enable_numpy_behavior(dtype_conversion_mode=\"all\")\n",
        "a = tf.Variable(10, tf.int32)\n",
        "a.assign_add(tf.constant(5, tf.int16))  # <tf.Variable shape=() dtype=int32, numpy=15>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PiA4H-otLDit"
      },
      "source": [
        "### Conversiones implícitas con tf.constant\n",
        "\n",
        "En la promoción de tipos anterior, para `tf.constant` se requería un tensor de entrada que tuviera el mismo tipo d del argumento. Sin embargo, en la promoción de tipos nueva, convertimos implícitamente al tensor al tipo d especificado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ArrQ9Dj0_OR8"
      },
      "outputs": [],
      "source": [
        "tnp.experimental_enable_numpy_behavior(dtype_conversion_mode=\"all\")\n",
        "a = tf.constant(10, tf.int16)\n",
        "tf.constant(a, tf.float32)  # <tf.Tensor: shape=(), dtype=float32, numpy=10.0>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAcK_-XnLWaP"
      },
      "source": [
        "### Arreglo TF-NumPy\n",
        "\n",
        "`tnp.array` propone por defecto `i32*` y `f32*` para las entradas de Python con la promoción de tipos nueva."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K1pZnYNh_ahm"
      },
      "outputs": [],
      "source": [
        "tnp.array(1)  # <tf.Tensor: shape=(), dtype=int32, numpy=1, weak=True>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QoQl2PYP_fMT"
      },
      "outputs": [],
      "source": [
        "tnp.array(1.0)  # <tf.Tensor: shape=(), dtype=int32, numpy=1, weak=True>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wK5DpQ3Pz3k5"
      },
      "source": [
        "##Inferencia de tipo de entrada\n",
        "\n",
        "Así es como los diferentes tipos de entradas se infieren con la promoción de tipos nueva.\n",
        "\n",
        "- `tf.Tensor`: como `tf.Tensor` tiene una propiedad de tipo d, no hacemos más inferencias.\n",
        "- Tipos NumPy: incluye los tipos como `np.array(1)`, `np.int16(1)` y `np.float`. Como las entradas NumPy tienen una propiedad de tipo d, tomamos la propiedad de tipo d como el tipo de inferencia de resultado. Tenga en cuenta que NumPy propone por defecto `i64` y `f64`.\n",
        "- Los tipos escalares o anidados de Python: incluye tipos como `1`, `[1, 2, 3]` y `(1.0, 2.0)`.\n",
        "    - `int` de Python se infiere como `i32*`.\n",
        "    - `float` de Python se infiere como `f32*`.\n",
        "    - `complex` de Python se infiere como `c128*`.\n",
        "- Si la entrada no cae en ninguna de las categorías anteriores sino que tiene una propiedad de tipo d, tomamos la propiedad de tipo d como el tipo de inferencia resultante."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_SPfalfSPgg"
      },
      "source": [
        "# Lecturas adicionales\n",
        "\n",
        "La promoción de tipos nueva se parece mucho a la promoción de tipos de JAX-NumPy. Si desea conocer más detalles acerca de la promoción de tipos nueva y de las opciones de diseño, consulte los recursos que se encuentran a continuación.\n",
        "\n",
        "- [Semántica de la promoción de tipos en JAX](https://jax.readthedocs.io/en/latest/type_promotion.html)\n",
        "- [Diseño de la semántica de la promoción de tipos para JAX](https://jax.readthedocs.io/en/latest/jep/9407-type-promotion.html)\n",
        "- [Semántica de la promoción de tipos en TF-NumPy anterior](https://www.tensorflow.org/guide/tf_numpy#type_promotion)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qg5xBbImT31S"
      },
      "source": [
        "# Referencias"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjB0CVhVXBfW"
      },
      "source": [
        "<a name=\"weak_tensor_apis\">\n",
        "</a>\n",
        "\n",
        "## API compatibles con WeakTensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GVbqlN9aBS2"
      },
      "source": [
        "A continuación, se encuentra una lista de las API compatibles con `WeakTensor`.\n",
        "\n",
        "Para una op (operación) unaria, significa que si se pasa una entrada con tipo de usuario no especificado, devolverá un `WeakTensor`.\n",
        "\n",
        "Para una op binaria, se seguirá la tabla de promociones que se encuentra [aquí](#promotion_table). Puede devolver un `WeakTensor` o no hacerlo, dependiendo del resultado de la promoción de las dos entradas.\n",
        "\n",
        "**Nota**: se admiten todas las operaciones matemáticas (`+`, `-`, `*`, ...)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gi-G68Z8WN2P"
      },
      "source": [
        "- `tf.bitwise.invert`\n",
        "- `tf.clip_by_value`\n",
        "- `tf.debugging.check_numerics`\n",
        "- `tf.expand_dims`\n",
        "- `tf.identity`\n",
        "- `tf.image.adjust_brightness`\n",
        "- `tf.image.adjust_gamma`\n",
        "- `tf.image.extract_patches`\n",
        "- `tf.image.random_brightness`\n",
        "- `tf.image.stateless_random_brightness`\n",
        "- `tf.linalg.diag`\n",
        "- `tf.linalg.diag_part`\n",
        "- `tf.linalg.matmul`\n",
        "- `tf.linalg.matrix_transpose`\n",
        "- `tf.linalg.tensor_diag_part`\n",
        "- `tf.linalg.trace`\n",
        "- `tf.math.abs`\n",
        "- `tf.math.acos`\n",
        "- `tf.math.acosh`\n",
        "- `tf.math.add`\n",
        "- `tf.math.angle`\n",
        "- `tf.math.asin`\n",
        "- `tf.math.asinh`\n",
        "- `tf.math.atan`\n",
        "- `tf.math.atanh`\n",
        "- `tf.math.ceil`\n",
        "- `tf.math.conj`\n",
        "- `tf.math.cos`\n",
        "- `tf.math.cosh`\n",
        "- `tf.math.digamma`\n",
        "- `tf.math.divide_no_nan`\n",
        "- `tf.math.divide`\n",
        "- `tf.math.erf`\n",
        "- `tf.math.erfc`\n",
        "- `tf.math.erfcinv`\n",
        "- `tf.math.erfinv`\n",
        "- `tf.math.exp`\n",
        "- `tf.math.expm1`\n",
        "- `tf.math.floor`\n",
        "- `tf.math.floordiv`\n",
        "- `tf.math.floormod`\n",
        "- `tf.math.imag`\n",
        "- `tf.math.lgamma`\n",
        "- `tf.math.log1p`\n",
        "- `tf.math.log_sigmoid`\n",
        "- `tf.math.log`\n",
        "- `tf.math.multiply_no_nan`\n",
        "- `tf.math.multiply`\n",
        "- `tf.math.ndtri`\n",
        "- `tf.math.negative`\n",
        "- `tf.math.pow`\n",
        "- `tf.math.real`\n",
        "- `tf.math.real`\n",
        "- `tf.math.reciprocal_no_nan`\n",
        "- `tf.math.reciprocal`\n",
        "- `tf.math.reduce_euclidean_norm`\n",
        "- `tf.math.reduce_logsumexp`\n",
        "- `tf.math.reduce_max`\n",
        "- `tf.math.reduce_mean`\n",
        "- `tf.math.reduce_min`\n",
        "- `tf.math.reduce_prod`\n",
        "- `tf.math.reduce_std`\n",
        "- `tf.math.reduce_sum`\n",
        "- `tf.math.reduce_variance`\n",
        "- `tf.math.rint`\n",
        "- `tf.math.round`\n",
        "- `tf.math.rsqrt`\n",
        "- `tf.math.scalar_mul`\n",
        "- `tf.math.sigmoid`\n",
        "- `tf.math.sign`\n",
        "- `tf.math.sin`\n",
        "- `tf.math.sinh`\n",
        "- `tf.math.softplus`\n",
        "- `tf.math.special.bessel_i0`\n",
        "- `tf.math.special.bessel_i0e`\n",
        "- `tf.math.special.bessel_i1`\n",
        "- `tf.math.special.bessel_i1e`\n",
        "- `tf.math.special.bessel_j0`\n",
        "- `tf.math.special.bessel_j1`\n",
        "- `tf.math.special.bessel_k0`\n",
        "- `tf.math.special.bessel_k0e`\n",
        "- `tf.math.special.bessel_k1`\n",
        "- `tf.math.special.bessel_k1e`\n",
        "- `tf.math.special.bessel_y0`\n",
        "- `tf.math.special.bessel_y1`\n",
        "- `tf.math.special.dawsn`\n",
        "- `tf.math.special.expint`\n",
        "- `tf.math.special.fresnel_cos`\n",
        "- `tf.math.special.fresnel_sin`\n",
        "- `tf.math.special.spence`\n",
        "- `tf.math.sqrt`\n",
        "- `tf.math.square`\n",
        "- `tf.math.subtract`\n",
        "- `tf.math.tan`\n",
        "- `tf.math.tanh`\n",
        "- `tf.nn.depth_to_space`\n",
        "- `tf.nn.elu`\n",
        "- `tf.nn.gelu`\n",
        "- `tf.nn.leaky_relu`\n",
        "- `tf.nn.log_softmax`\n",
        "- `tf.nn.relu6`\n",
        "- `tf.nn.relu`\n",
        "- `tf.nn.selu`\n",
        "- `tf.nn.softsign`\n",
        "- `tf.nn.space_to_depth`\n",
        "- `tf.nn.swish`\n",
        "- `tf.ones_like`\n",
        "- `tf.realdiv`\n",
        "- `tf.reshape`\n",
        "- `tf.squeeze`\n",
        "- `tf.stop_gradient`\n",
        "- `tf.transpose`\n",
        "- `tf.truncatediv`\n",
        "- `tf.truncatemod`\n",
        "- `tf.zeros_like`\n",
        "- `tf.experimental.numpy.abs`\n",
        "- `tf.experimental.numpy.absolute`\n",
        "- `tf.experimental.numpy.amax`\n",
        "- `tf.experimental.numpy.amin`\n",
        "- `tf.experimental.numpy.angle`\n",
        "- `tf.experimental.numpy.arange`\n",
        "- `tf.experimental.numpy.arccos`\n",
        "- `tf.experimental.numpy.arccosh`\n",
        "- `tf.experimental.numpy.arcsin`\n",
        "- `tf.experimental.numpy.arcsinh`\n",
        "- `tf.experimental.numpy.arctan`\n",
        "- `tf.experimental.numpy.arctanh`\n",
        "- `tf.experimental.numpy.around`\n",
        "- `tf.experimental.numpy.array`\n",
        "- `tf.experimental.numpy.asanyarray`\n",
        "- `tf.experimental.numpy.asarray`\n",
        "- `tf.experimental.numpy.ascontiguousarray`\n",
        "- `tf.experimental.numpy.average`\n",
        "- `tf.experimental.numpy.bitwise_not`\n",
        "- `tf.experimental.numpy.cbrt`\n",
        "- `tf.experimental.numpy.ceil`\n",
        "- `tf.experimental.numpy.conj`\n",
        "- `tf.experimental.numpy.conjugate`\n",
        "- `tf.experimental.numpy.copy`\n",
        "- `tf.experimental.numpy.cos`\n",
        "- `tf.experimental.numpy.cosh`\n",
        "- `tf.experimental.numpy.cumprod`\n",
        "- `tf.experimental.numpy.cumsum`\n",
        "- `tf.experimental.numpy.deg2rad`\n",
        "- `tf.experimental.numpy.diag`\n",
        "- `tf.experimental.numpy.diagflat`\n",
        "- `tf.experimental.numpy.diagonal`\n",
        "- `tf.experimental.numpy.diff`\n",
        "- `tf.experimental.numpy.empty_like`\n",
        "- `tf.experimental.numpy.exp2`\n",
        "- `tf.experimental.numpy.exp`\n",
        "- `tf.experimental.numpy.expand_dims`\n",
        "- `tf.experimental.numpy.expm1`\n",
        "- `tf.experimental.numpy.fabs`\n",
        "- `tf.experimental.numpy.fix`\n",
        "- `tf.experimental.numpy.flatten`\n",
        "- `tf.experimental.numpy.flip`\n",
        "- `tf.experimental.numpy.fliplr`\n",
        "- `tf.experimental.numpy.flipud`\n",
        "- `tf.experimental.numpy.floor`\n",
        "- `tf.experimental.numpy.full_like`\n",
        "- `tf.experimental.numpy.imag`\n",
        "- `tf.experimental.numpy.log10`\n",
        "- `tf.experimental.numpy.log1p`\n",
        "- `tf.experimental.numpy.log2`\n",
        "- `tf.experimental.numpy.log`\n",
        "- `tf.experimental.numpy.max`\n",
        "- `tf.experimental.numpy.mean`\n",
        "- `tf.experimental.numpy.min`\n",
        "- `tf.experimental.numpy.moveaxis`\n",
        "- `tf.experimental.numpy.nanmean`\n",
        "- `tf.experimental.numpy.negative`\n",
        "- `tf.experimental.numpy.ones_like`\n",
        "- `tf.experimental.numpy.positive`\n",
        "- `tf.experimental.numpy.prod`\n",
        "- `tf.experimental.numpy.rad2deg`\n",
        "- `tf.experimental.numpy.ravel`\n",
        "- `tf.experimental.numpy.real`\n",
        "- `tf.experimental.numpy.reciprocal`\n",
        "- `tf.experimental.numpy.repeat`\n",
        "- `tf.experimental.numpy.reshape`\n",
        "- `tf.experimental.numpy.rot90`\n",
        "- `tf.experimental.numpy.round`\n",
        "- `tf.experimental.numpy.signbit`\n",
        "- `tf.experimental.numpy.sin`\n",
        "- `tf.experimental.numpy.sinc`\n",
        "- `tf.experimental.numpy.sinh`\n",
        "- `tf.experimental.numpy.sort`\n",
        "- `tf.experimental.numpy.sqrt`\n",
        "- `tf.experimental.numpy.square`\n",
        "- `tf.experimental.numpy.squeeze`\n",
        "- `tf.experimental.numpy.std`\n",
        "- `tf.experimental.numpy.sum`\n",
        "- `tf.experimental.numpy.swapaxes`\n",
        "- `tf.experimental.numpy.tan`\n",
        "- `tf.experimental.numpy.tanh`\n",
        "- `tf.experimental.numpy.trace`\n",
        "- `tf.experimental.numpy.transpose`\n",
        "- `tf.experimental.numpy.triu`\n",
        "- `tf.experimental.numpy.vander`\n",
        "- `tf.experimental.numpy.var`\n",
        "- `tf.experimental.numpy.zeros_like`"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "tf_numpy_type_promotion.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
