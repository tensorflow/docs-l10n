{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tghWegsjhpkt"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "rSGJWC5biBiG"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YuSYVbwEYNHw"
      },
      "source": [
        "# TensorFlow Data Validation\n",
        "\n",
        "***Un ejemplo de un componente clave de TensorFlow Extended***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLsMb4vqY244"
      },
      "source": [
        "Nota: Puede ejecutar este ejemplo ahora mismo en un bloc de notas estilo Jupyter, ¡no es necesario configurarlo! Simplemente haga clic en \"Ejecutar en Google Colab\"\n",
        "\n",
        "<div class=\"devsite-table-wrapper\"><table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "<td><a target=\"_blank\" href=\"https://www.tensorflow.org/tfx/tutorials/data_validation/tfdv_basic\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver en TensorFlow.org</a></td>\n",
        "<td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/es-419/tfx/tutorials/data_validation/tfdv_basic.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Ejecutar en Google Colab</a></td>\n",
        "<td><a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/es-419/tfx/tutorials/data_validation/tfdv_basic.ipynb\"><img width=\"32px\" src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver fuente en GitHub</a></td>\n",
        "<td><a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/es-419/tfx/tutorials/data_validation/tfdv_basic.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Descargar el bloc de notas</a></td>\n",
        "</table></div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPt5BHTwy_0F"
      },
      "source": [
        "Este bloc de notas de Colab de ejemplo ilustra cómo se puede usar TensorFlow Data Validation (TFDV) para investigar y visualizar su conjunto de datos. Eso incluye observar estadísticas descriptivas, inferir un esquema, verificar y corregir anomalías, y verificar desviaciones y sesgos en nuestro conjunto de datos. Es importante comprender las características de su conjunto de datos, incluido cómo podría cambiar con el tiempo en su canalización de producción. También es importante buscar anomalías en sus datos y comparar sus conjuntos de datos de entrenamiento, evaluación y servicio para asegurarse de que sean consistentes.\n",
        "\n",
        "Usaremos datos del [conjunto de datos Taxi Trips](https://data.cityofchicago.org/Transportation/Taxi-Trips/wrvz-psew) publicado por la ciudad de Chicago.\n",
        "\n",
        "Nota: Este sitio ofrece aplicaciones que usan datos que fueron modificados para su uso desde su fuente original, www.cityofchicago.org, el sitio web oficial de la ciudad de Chicago. La ciudad de Chicago no garantiza el contenido, la exactitud, la puntualidad o la integridad de ninguno de los datos que se proporcionan en este sitio. Los datos proporcionados en este sitio están sujetos a cambios en cualquier momento. Se entiende que los datos proporcionados en este sitio se usan bajo su propia responsabilidad.\n",
        "\n",
        "[Más información](https://cloud.google.com/bigquery/public-data/chicago-taxi) sobre el conjunto de datos en [Google BigQuery](https://cloud.google.com/bigquery/). Explore el conjunto de datos completo en la [interfaz de usuario de BigQuery](https://bigquery.cloud.google.com/dataset/bigquery-public-data:chicago_taxi_trips).\n",
        "\n",
        "Punto clave: Como modelador y desarrollador, piense en cómo se usan estos datos y los posibles beneficios y daños que pueden causar las predicciones de un modelo. Un modelo como este podría reforzar los prejuicios y las disparidades sociales. ¿Es una característica relevante para el problema que desea resolver o introducirá un sesgo? Para obtener más información, lea sobre [la equidad del aprendizaje automático](https://developers.google.com/machine-learning/fairness-overview/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fnm6Mj3vTGLm"
      },
      "source": [
        "Las columnas del conjunto de datos son las siguientes:\n",
        "\n",
        "<table>\n",
        "<tr>\n",
        "<td>pickup_community_area</td>\n",
        "<td>fare</td>\n",
        "<td>trip_start_month</td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>trip_start_hour</td>\n",
        "<td>trip_start_day</td>\n",
        "<td>trip_start_timestamp</td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>pickup_latitude</td>\n",
        "<td>pickup_longitude</td>\n",
        "<td>dropoff_latitude</td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>dropoff_longitude</td>\n",
        "<td>trip_miles</td>\n",
        "<td>pickup_census_tract</td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>dropoff_census_tract</td>\n",
        "<td>payment_type</td>\n",
        "<td>company</td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>trip_seconds</td>\n",
        "<td>dropoff_community_area</td>\n",
        "<td>tips</td>\n",
        "</tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsYC3O-DnYro"
      },
      "source": [
        "## Instalación e importación de paquetes\n",
        "\n",
        "Instale los paquetes para TensorFlow Data Validation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATF_g5c2g2Ha"
      },
      "source": [
        "### Actualización de pip\n",
        "\n",
        "Para evitar actualizar Pip en un sistema cuando se ejecuta localmente, verifique que se esté ejecutando en Colab. Por supuesto, los sistemas locales se pueden actualizar por separado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b0ISmRq3nY3-"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  import colab\n",
        "  !pip install --upgrade pip\n",
        "except:\n",
        "  pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qBFH1ARcSNk"
      },
      "source": [
        "### Instalación de paquetes de Data Validation\n",
        "\n",
        "Instale los paquetes y las dependencias de TensorFlow Data Validation, lo que demora unos minutos. Es posible que vea advertencias y errores relacionados con versiones de dependencias incompatibles, que se resolverá en la siguiente sección."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hPJsE5Gkdp8m"
      },
      "outputs": [],
      "source": [
        "print('Installing TensorFlow Data Validation')\n",
        "!pip install --upgrade 'tensorflow_data_validation[visualization]<2'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_NXX5GaSiZx"
      },
      "source": [
        "### Importación de TensorFlow y recarga de paquetes actualizados\n",
        "\n",
        "En el paso anterior se actualizan los paquetes predeterminados en el entorno de Gooogle Colab, por lo que se deben recargar los recursos del paquete para resolver las nuevas dependencias.\n",
        "\n",
        "Nota: En este paso se resuelve el error de dependencia de la instalación. Si sigue teniendo problemas de ejecución de código después de ejecutar este código, reinicie el tiempo de ejecución (Tiempo de ejecución &gt; Reiniciar tiempo de ejecución...)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E2j9VD9HbGWw"
      },
      "outputs": [],
      "source": [
        "import pkg_resources\n",
        "import importlib\n",
        "importlib.reload(pkg_resources)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFXK2AdpSpv0"
      },
      "source": [
        "Verifique las versiones de TensorFlow y Data Validation antes de continuar. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F5rPatTDSCHB"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_data_validation as tfdv\n",
        "print('TF version:', tf.__version__)\n",
        "print('TFDV version:', tfdv.version.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5MizoHg1DRlK"
      },
      "source": [
        "## Carga del conjunto de datos\n",
        "\n",
        "Descargaremos nuestro conjunto de datos de Google Cloud Storage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x5gfFiTeDa6Y"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tempfile, urllib, zipfile\n",
        "\n",
        "# Set up some globals for our file paths\n",
        "BASE_DIR = tempfile.mkdtemp()\n",
        "DATA_DIR = os.path.join(BASE_DIR, 'data')\n",
        "OUTPUT_DIR = os.path.join(BASE_DIR, 'chicago_taxi_output')\n",
        "TRAIN_DATA = os.path.join(DATA_DIR, 'train', 'data.csv')\n",
        "EVAL_DATA = os.path.join(DATA_DIR, 'eval', 'data.csv')\n",
        "SERVING_DATA = os.path.join(DATA_DIR, 'serving', 'data.csv')\n",
        "\n",
        "# Download the zip file from GCP and unzip it\n",
        "zip, headers = urllib.request.urlretrieve('https://storage.googleapis.com/artifacts.tfx-oss-public.appspot.com/datasets/chicago_data.zip')\n",
        "zipfile.ZipFile(zip).extractall(BASE_DIR)\n",
        "zipfile.ZipFile(zip).close()\n",
        "\n",
        "print(\"Here's what we downloaded:\")\n",
        "!ls -R {os.path.join(BASE_DIR, 'data')}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0sFmiTbT8-x"
      },
      "source": [
        "## Cálculo y visualización de estadísticas\n",
        "\n",
        "Primero usaremos [`tfdv.generate_statistics_from_csv`](https://www.tensorflow.org/tfx/data_validation/api_docs/python/tfdv/generate_statistics_from_csv) para calcular estadísticas para nuestros datos de entrenamiento. (Ignore las breves advertencias)\n",
        "\n",
        "TFDV puede calcular [estadísticas](https://github.com/tensorflow/metadata/blob/v0.6.0/tensorflow_metadata/proto/v0/statistics.proto) descriptivas que brindan una descripción general rápida de los datos en términos de las características presentes y las formas de sus distribuciones de valores.\n",
        "\n",
        "Internamente, TFDV usa el marco de procesamiento de datos paralelo de [Apache Beam](https://beam.apache.org/) para escalar el cálculo de estadísticas en grandes conjuntos de datos. Para las aplicaciones que desean una integración más profunda con TFDV (por ejemplo, adjuntar la generación de estadísticas al final de una canalización de generación de datos), la API también expone un Beam PTransform para la generación de estadísticas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EE481oMbT-H0"
      },
      "outputs": [],
      "source": [
        "train_stats = tfdv.generate_statistics_from_csv(data_location=TRAIN_DATA)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhXQSxJ2dB_6"
      },
      "source": [
        "Ahora usemos [`tfdv.visualize_statistics`](https://www.tensorflow.org/tfx/data_validation/api_docs/python/tfdv/visualize_statistics), que usa [Facets](https://pair-code.github.io/facets/) para crear una visualización concisa de nuestros datos de entrenamiento:\n",
        "\n",
        "- Tenga en cuenta que las características numéricas y las características categóricas se visualizan por separado y que se muestran gráficos donde se representan las distribuciones de cada característica.\n",
        "- Tenga en cuenta que las características con valores faltantes o cero muestran un porcentaje en rojo como indicador visual de que puede haber problemas con los ejemplos de esas características. El porcentaje es el porcentaje de ejemplos a los que les faltan valores o tienen valores cero para esa característica.\n",
        "- Tenga en cuenta que no hay ejemplos con valores para `pickup_census_tract`. ¡Esta es una oportunidad para reducir la dimensionalidad!\n",
        "- Intente hacer clic en \"expandir\", ubicado arriba de los gráficos, para cambiar la visualización.\n",
        "- Pruebe pasar el cursor sobre las barras en los gráficos para que se muestren los rangos y los recuentos de los cubos.\n",
        "- Pruebe cambiar entre las escalas logarítmica y lineal y observe cómo la escala logarítmica revela muchos más detalles sobre la característica categórica `payment_type`\n",
        "- Intente seleccionar \"cuantiles\" en el menú \"Gráfico para mostrar\" y coloque el cursor sobre los marcadores para ver los porcentajes de cuantiles."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U3tUKgh7Up3x"
      },
      "outputs": [],
      "source": [
        "# docs-infra: no-execute\n",
        "tfdv.visualize_statistics(train_stats)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xoc0ijE5LYeQ"
      },
      "source": [
        "<!-- <img class=\"tfo-display-only-on-site\" src=\"images/statistics.png\"/> -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVR02-y4V0uM"
      },
      "source": [
        "## Inferencia de un esquema\n",
        "\n",
        "Ahora usemos [`tfdv.infer_schema`](https://www.tensorflow.org/tfx/data_validation/api_docs/python/tfdv/infer_schema) para crear un esquema para nuestros datos. Un esquema define restricciones para los datos que son relevantes para el aprendizaje automático. Las restricciones de ejemplo incluyen el tipo de datos de cada característica, ya sea numérica o categórica, o la frecuencia de su presencia en los datos. Para características categóricas, el esquema también define el dominio: la lista de valores aceptables. Dado que escribir un esquema puede ser una tarea tediosa, especialmente para conjuntos de datos con muchas características, TFDV proporciona un método para generar una versión inicial del esquema basada en estadísticas descriptivas.\n",
        "\n",
        "Es importante que el esquema sea correcto porque el resto de la cadena de producción dependerá de que el esquema generado por TFDV lo sea.  El esquema también aporta documentación para los datos, por lo que es útil cuando diferentes desarrolladores trabajan con los mismos datos. Usemos [`tfdv.display_schema`](https://www.tensorflow.org/tfx/data_validation/api_docs/python/tfdv/display_schema) para mostrar el esquema inferido y poder revisarlo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6LLkRJThVr9m"
      },
      "outputs": [],
      "source": [
        "schema = tfdv.infer_schema(statistics=train_stats)\n",
        "tfdv.display_schema(schema=schema)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVa3EXE8WEDE"
      },
      "source": [
        "## Verificación de los datos de evaluación para detectar errores\n",
        "\n",
        "Hasta ahora, solo analizamos los datos de entrenamiento.  Es importante que nuestros datos de evaluación sean coherentes con nuestros datos de entrenamiento, y que utilicen el mismo esquema.  También es importante que los datos de evaluación incluyan ejemplos de aproximadamente los mismos rangos de valores para nuestras características numéricas que nuestros datos de entrenamiento, para que nuestra cobertura de la superficie de pérdida durante la evaluación sea aproximadamente la misma que durante el entrenamiento.  Lo mismo ocurre con las características categóricas. De lo contrario, podríamos tener problemas de entrenamiento que no se identifican durante la evaluación, porque no evaluamos parte de nuestra superficie de pérdidas.\n",
        "\n",
        "- Observe que cada característica ahora incluye estadísticas para los conjuntos de datos de entrenamiento y evaluación.\n",
        "- Observe que los gráficos ahora tienen los conjuntos de datos de entrenamiento y evaluación que se superponen, lo que facilita su comparación.\n",
        "- Observe que los gráficos ahora incluyen una vista de porcentajes, que se puede combinar con escalas logarítmicas o lineales predeterminadas.\n",
        "- Observe que la media y la mediana de `trip_miles` son diferentes para los conjuntos de datos de entrenamiento y de evaluación. ¿Eso causará problemas?\n",
        "- Bueno, los valores `tips` máximos son muy diferentes para los conjuntos de datos de entrenamiento y de evaluación. ¿Eso causará problemas?\n",
        "- Haga clic en expandir en el gráfico Características numéricas y seleccione la escala logarítmica. Revise la característica `trip_seconds` y observe la diferencia en el máximo. ¿La evaluación no tendrá en cuenta partes de la superficie de pérdida?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j_P0RLYlV6XG"
      },
      "outputs": [],
      "source": [
        "# Compute stats for evaluation data\n",
        "eval_stats = tfdv.generate_statistics_from_csv(data_location=EVAL_DATA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qn-3fQWJLimn"
      },
      "outputs": [],
      "source": [
        "# docs-infra: no-execute\n",
        "# Compare evaluation data with training data\n",
        "tfdv.visualize_statistics(lhs_statistics=eval_stats, rhs_statistics=train_stats,\n",
        "                          lhs_name='EVAL_DATASET', rhs_name='TRAIN_DATASET')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MS4u82lzLeRh"
      },
      "source": [
        "<!-- <img class=\"tfo-display-only-on-site\" src=\"images/statistics_eval.png\"/> -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycRRa4leHp84"
      },
      "source": [
        "## Verificación de anomalías en la evaluación\n",
        "\n",
        "¿El conjunto de datos de evaluación coincide con el esquema del conjunto de datos de entrenamiento?  Esto es especialmente importante para las características categóricas, en las que queremos identificar el rango de valores aceptables.\n",
        "\n",
        "Punto clave: ¿Qué pasaría si intentáramos usar datos con valores de características categóricas que no estuvieran en nuestro conjunto de datos de entrenamiento para ejecutar la evaluación? ¿Qué pasa con las características numéricas que están fuera de los rangos de nuestro conjunto de datos de entrenamiento?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T7uGVeL2WOam"
      },
      "outputs": [],
      "source": [
        "# Check eval data for errors by validating the eval data stats using the previously inferred schema.\n",
        "anomalies = tfdv.validate_statistics(statistics=eval_stats, schema=schema)\n",
        "tfdv.display_anomalies(anomalies)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzxx1gBpJIBa"
      },
      "source": [
        "## Corrección de anomalías de evaluación en el esquema\n",
        "\n",
        "¡Ups! Parece que hay algunos valores nuevos para `company` en nuestros datos de evaluación, que no teníamos en nuestros datos de entrenamiento. También tenemos un nuevo valor para `payment_type`. Éstas deben considerarse anomalías, pero lo que decidamos hacer al respecto depende de nuestro conocimiento de los datos. Si una anomalía realmente indica un error de datos, entonces los datos subyacentes deben corregirse. De lo contrario, simplemente podemos actualizar el esquema para incluir los valores en el conjunto de datos de evaluación.\n",
        "\n",
        "Punto clave: Si no solucionáramos estos problemas, ¿cómo se verían afectados los resultados de la evaluación?\n",
        "\n",
        "A menos que cambiemos nuestro conjunto de datos de evaluación, no podemos arreglarlo todo, pero podemos arreglar algunas cosas en el esquema que nos resultan cómodas de aceptar. Eso incluye flexibilizar nuestra visión de lo que es y lo que no es una anomalía en determinadas características, así como actualizar nuestro esquema para que incluya valores faltantes en las características categóricas. TFDV nos permite detectar lo que debemos arreglar.\n",
        "\n",
        "Hagamos esas correcciones ahora y luego repasemos una vez más."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "legN2nXLWZAc"
      },
      "outputs": [],
      "source": [
        "# Relax the minimum fraction of values that must come from the domain for feature company.\n",
        "company = tfdv.get_feature(schema, 'company')\n",
        "company.distribution_constraints.min_domain_mass = 0.9\n",
        "\n",
        "# Add new value to the domain of feature payment_type.\n",
        "payment_type_domain = tfdv.get_domain(schema, 'payment_type')\n",
        "payment_type_domain.value.append('Prcard')\n",
        "\n",
        "# Validate eval stats after updating the schema \n",
        "updated_anomalies = tfdv.validate_statistics(eval_stats, schema)\n",
        "tfdv.display_anomalies(updated_anomalies)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNo72YP9LN98"
      },
      "source": [
        "¡Miren eso! ¡Verificamos que los datos de entrenamiento y evaluación ahora son coherentes! Gracias, TFDV ;)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZ1P4ucHJj5o"
      },
      "source": [
        "## Entornos de esquema"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qb179jczJppA"
      },
      "source": [
        "También dividimos un conjunto de datos de \"servicio\" para este ejemplo, por lo que también deberíamos verificarlo. De forma predeterminada, todos los conjuntos de datos de una canalización deben usar el mismo esquema, pero suele haber excepciones. Por ejemplo, en el aprendizaje supervisado tenemos que incluir etiquetas en nuestro conjunto de datos, pero cuando servimos el modelo para inferencia, no se incluyen las etiquetas. En algunos casos es necesario introducir ligeras variaciones en el esquema.\n",
        "\n",
        "Los **entornos** se pueden usar para expresar dichos requisitos. En particular, las características del esquema se pueden asociar a un conjunto de entornos a través de `default_environment`, `in_environment` y `not_in_environment`.\n",
        "\n",
        "Por ejemplo, en este conjunto de datos, la característica `tips` se incluye como etiqueta para el entrenamiento, pero falta en los datos de servicio. Sin que se especifique un entorno, se mostrará como una anomalía."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wSZfbnifJuTA"
      },
      "outputs": [],
      "source": [
        "serving_stats = tfdv.generate_statistics_from_csv(SERVING_DATA)\n",
        "serving_anomalies = tfdv.validate_statistics(serving_stats, schema)\n",
        "\n",
        "tfdv.display_anomalies(serving_anomalies)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDYHvZ09LfkT"
      },
      "source": [
        "Nos ocuparemos de la característica `tips` más adelante. También tenemos un valor INT en nuestros segundos de viaje, donde nuestro esquema esperaba un FLOAT. Al notar esa diferencia, TFDV ayuda a descubrir inconsistencias en la forma en que se generan los datos para el entrenamiento y el servicio. Es muy fácil no darse cuenta de problemas como ese hasta que el rendimiento del modelo se ve afectado, a veces de forma catastrófica. Puede que se trate de un problema importante o puede que no, pero en cualquier caso se debería investigar más detenidamente.\n",
        "\n",
        "En este caso, podemos convertir de forma segura valores INT a FLOAT, por lo que queremos decirle a TFDV que use nuestro esquema para inferir el tipo. Hagámoslo ahora."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OhtYF8aAczpd"
      },
      "outputs": [],
      "source": [
        "options = tfdv.StatsOptions(schema=schema, infer_type_from_schema=True)\n",
        "serving_stats = tfdv.generate_statistics_from_csv(SERVING_DATA, stats_options=options)\n",
        "serving_anomalies = tfdv.validate_statistics(serving_stats, schema)\n",
        "\n",
        "tfdv.display_anomalies(serving_anomalies)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJjh5rigc5xy"
      },
      "source": [
        "Ahora solo tenemos la característica `tips` (que es nuestra etiqueta) que aparece como una anomalía (\"Columna eliminada\"). Por supuesto, no esperamos tener etiquetas en nuestros datos de servicio, así que digámosle a TFDV que las ignore."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bnbnw8H6Lp2M"
      },
      "outputs": [],
      "source": [
        "# All features are by default in both TRAINING and SERVING environments.\n",
        "schema.default_environment.append('TRAINING')\n",
        "schema.default_environment.append('SERVING')\n",
        "\n",
        "# Specify that 'tips' feature is not in SERVING environment.\n",
        "tfdv.get_feature(schema, 'tips').not_in_environment.append('SERVING')\n",
        "\n",
        "serving_anomalies_with_env = tfdv.validate_statistics(\n",
        "    serving_stats, schema, environment='SERVING')\n",
        "\n",
        "tfdv.display_anomalies(serving_anomalies_with_env)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yteMr3AGMYEp"
      },
      "source": [
        "## Verificación de la presencia de desviaciones y sesgos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Ftd5k6AMkPV"
      },
      "source": [
        "Además de comprobar si un conjunto de datos se ajusta a las expectativas establecidas en el esquema, TFDV también ofrece funciones que permiten detectar la desviación y el sesgo. TFDV ejecuta esta comprobación al comparar las estadísticas de los distintos conjuntos de datos basándose en los comparadores de desviación/sesgo especificados en el esquema.\n",
        "\n",
        "### Desviación\n",
        "\n",
        "La detección de desviaciones se admite para características categóricas y entre intervalos de datos consecutivos (es decir, entre el intervalo N y el intervalo N+1), como entre diferentes días de datos de entrenamiento. Expresamos la desviación en términos de [distancia L-infinito](https://en.wikipedia.org/wiki/Chebyshev_distance) y puede establecer la distancia al umbral para recibir advertencias cuando la desviación sea mayor de lo aceptable. Establecer la distancia correcta suele ser un proceso iterativo que requiere experimentación y conocimiento del dominio."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBFuLpXb6qSp"
      },
      "source": [
        "### Sesgo\n",
        "\n",
        "TFDV puede detectar tres tipos diferentes de sesgo en sus datos: sesgo de esquema, sesgo de características y sesgo de distribución.\n",
        "\n",
        "#### Sesgo de esquema\n",
        "\n",
        "El sesgo de esquema ocurre cuando los datos de entrenamiento y servicio no se ajustan al mismo esquema. Se espera que tanto los datos de entrenamiento como los de servicio sigan el mismo esquema. Cualquier desviación esperada entre los dos (como que la característica de la etiqueta solo esté presente en los datos de entrenamiento, pero no en los de servicio) debe especificarse a través del campo de entornos en el esquema.\n",
        "\n",
        "#### Sesgo de características\n",
        "\n",
        "El sesgo de características ocurre cuando los valores de características con los que se entrena un modelo son diferentes de los valores de características que se ven en el momento del servicio. Por ejemplo, esto puede suceder en los siguientes escenarios:\n",
        "\n",
        "- Una fuente de datos que proporciona algunos valores de características se modifica entre el tiempo de entrenamiento y de servicio.\n",
        "- Existe una lógica diferente para generar características entre el entrenamiento y el servicio. Por ejemplo, si aplica alguna transformación solo en una de las dos rutas de código.\n",
        "\n",
        "#### Sesgo de distribución\n",
        "\n",
        "El sesgo de distribución ocurre cuando la distribución del conjunto de datos de entrenamiento es significativamente diferente de la distribución del conjunto de datos de servicio. Una de las causas clave del sesgo en la distribución es el uso de código diferente o de diferentes fuentes de datos para generar el conjunto de datos de entrenamiento. Otra razón es un mecanismo de muestreo defectuoso que elige una submuestra no representativa de los datos de servicio para entrenar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wEUsZm_rOd1Q"
      },
      "outputs": [],
      "source": [
        "# Add skew comparator for 'payment_type' feature.\n",
        "payment_type = tfdv.get_feature(schema, 'payment_type')\n",
        "payment_type.skew_comparator.infinity_norm.threshold = 0.01\n",
        "\n",
        "# Add drift comparator for 'company' feature.\n",
        "company=tfdv.get_feature(schema, 'company')\n",
        "company.drift_comparator.infinity_norm.threshold = 0.001\n",
        "\n",
        "skew_anomalies = tfdv.validate_statistics(train_stats, schema,\n",
        "                                          previous_statistics=eval_stats,\n",
        "                                          serving_statistics=serving_stats)\n",
        "\n",
        "tfdv.display_anomalies(skew_anomalies)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GzbbsPgf0Bg"
      },
      "source": [
        "En este ejemplo, vemos cierta desviación, pero está muy por debajo del umbral que establecimos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJ5saC9eWvHx"
      },
      "source": [
        "## Cómo congelar el esquema\n",
        "\n",
        "Ahora que revisamos y seleccionamso el esquema, lo almacenaremos en un archivo para reflejar su estado \"congelado\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ydkL4DkIWn18"
      },
      "outputs": [],
      "source": [
        "from tensorflow.python.lib.io import file_io\n",
        "from google.protobuf import text_format\n",
        "\n",
        "file_io.recursive_create_dir(OUTPUT_DIR)\n",
        "schema_file = os.path.join(OUTPUT_DIR, 'schema.pbtxt')\n",
        "tfdv.write_schema_text(schema, schema_file)\n",
        "\n",
        "!cat {schema_file}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8eC59yISdGB"
      },
      "source": [
        "## Cuando usar TFDV\n",
        "\n",
        "Es fácil pensar que TFDV solo se aplica al inicio de su canalización de entrenamiento, como hicimos aquí, pero en realidad tiene muchos usos. Aquí hay algunos más:\n",
        "\n",
        "- Validación de nuevos datos para inferencias con el fin de asegurarse de que no haya empezado a recibir características erróneas de repente.\n",
        "- Validación de nuevos datos para la inferencia para asegurarse de que el modelo se haya entrenado en esa parte de la superficie de decisión.\n",
        "- Validación de los datos después de haberlos transformado y haber realizado ingeniería de características (probablemente con [TensorFlow Transform](https://www.tensorflow.org/tfx/transform/get_started)) para comprobar que todo se haya ejecutado correctamente."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "tghWegsjhpkt"
      ],
      "name": "tfdv_basic.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
