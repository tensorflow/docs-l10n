{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjUA6S30k52h"
      },
      "source": [
        "##### Copyright 2021 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "SpNWyqewk8fE"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6x1ypzczQCwy"
      },
      "source": [
        "# Análisis de modelos mediante canalizaciones de TFX y TensorFlow Model Analysis\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HU9YYythm0dx"
      },
      "source": [
        "Nota: Recomendamos ejecutar este tutorial en un bloc de notas de Colab, ¡no es necesario configurarlo! Simplemente haga clic en \"Ejecutar en Google Colab\".\n",
        "\n",
        "<div class=\"devsite-table-wrapper\"><table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "<td><a target=\"_blank\" href=\"https://www.tensorflow.org/tfx/tutorials/tfx/penguin_tfma\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver en TensorFlow.org</a></td>\n",
        "<td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/es-419/tfx/tutorials/tfx/penguin_tfma.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Ejecutar en Google Colab</a></td>\n",
        "<td><a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/es-419/tfx/tutorials/tfx/penguin_tfma.ipynb\"><img width=\"32px\" src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver fuente en GitHub</a></td>\n",
        "<td><a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/es-419/tfx/tutorials/tfx/penguin_tfma.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Descargar el bloc de notas</a></td>\n",
        "</table></div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_VuwrlnvQJ5k"
      },
      "source": [
        "En este tutorial basado en un bloc de notas, crearemos y ejecutaremos una canalización de TFX que crea un modelo de clasificación simple y analiza su rendimiento en múltiples ejecuciones. Este bloc de notas se basa en la canalización de TFX que creamos en el [Tutorial de canalizaciones simples de TFX](https://www.tensorflow.org/tfx/tutorials/tfx/penguin_simple). Si aún no ha leído ese tutorial, debe leerlo antes de continuar con este bloc de notas.\n",
        "\n",
        "A medida que modifica su modelo o lo entrena con un nuevo conjunto de datos, debe verificar si su modelo ha mejorado o empeorado. Tal vez limitarse a comprobar métricas de alto nivel, como la precisión, no sea suficiente. Cada modelo entrenado debe evaluarse antes de insertarse en producción.\n",
        "\n",
        "Agregaremos un componente `Evaluator` a la canalización creada en el tutorial anterior. El componente Evaluator realiza un análisis profundo de sus modelos y compara el nuevo modelo con una línea base para determinar que sean \"lo suficientemente buenos\". Se implementa utilizando la biblioteca [TensorFlow Model Analysis](https://www.tensorflow.org/tfx/guide/tfma).\n",
        "\n",
        "Consulte [Explicación de las canalizaciones de TFX](https://www.tensorflow.org/tfx/guide/understanding_tfx_pipelines) para obtener más información sobre varios conceptos en TFX."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fmgi8ZvQkScg"
      },
      "source": [
        "## Preparación\n",
        "\n",
        "El proceso de configuración es el mismo que el del tutorial anterior.\n",
        "\n",
        "Primero tenemos que instalar el paquete de Python para TFX y descargar el conjunto de datos que usaremos para nuestro modelo.\n",
        "\n",
        "### Actualización de pip\n",
        "\n",
        "Para evitar actualizar Pip en un sistema cuando se ejecuta localmente, verifique que se esté ejecutando en Colab. Por supuesto, los sistemas locales se pueden actualizar por separado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "as4OTe2ukSqm"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  import colab\n",
        "  !pip install --upgrade pip\n",
        "except:\n",
        "  pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZOYTt1RW4TK"
      },
      "source": [
        "### Instalación de TFX\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iyQtljP-qPHY"
      },
      "outputs": [],
      "source": [
        "!pip install -U tfx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfT4ubk9_dJy"
      },
      "source": [
        "### Desinstalación de shapely\n",
        "\n",
        "TODO(b/263441833) Esta es una solución temporal para evitar un ImportError. En última instancia, debería solucionarse admitiendo una versión reciente de Bigquery, en lugar de desinstalar otras dependencias adicionales."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RhieH4y1_d3n"
      },
      "outputs": [],
      "source": [
        "!pip uninstall shapely -y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwT0nov5QO1M"
      },
      "source": [
        "### ¿Reinició el tiempo de ejecución?\n",
        "\n",
        "Si está usando Google Colab, la primera vez que ejecute la celda anterior, debe hacer clic en el botón \"REINICIAR TIEMPO DE EJECUCIÓN\" o usar el menú \"Tiempo de ejecución &gt; Reiniciar tiempo de ejecución ...\" para reiniciar el tiempo de ejecución. Esto se debe a la forma en que Colab carga los paquetes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDnPgN8UJtzN"
      },
      "source": [
        "Verifique las versiones de TensorFlow y TFX."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6jh7vKSRqPHb"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "print('TensorFlow version: {}'.format(tf.__version__))\n",
        "from tfx import v1 as tfx\n",
        "print('TFX version: {}'.format(tfx.__version__))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDtLdSkvqPHe"
      },
      "source": [
        "### Configuración de variables\n",
        "\n",
        "Hay algunas variables que se utilizan para definir una canalización. Puede personalizar estas variables como desee. De forma predeterminada, todas las salidas de la canalización se generarán en el directorio actual."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EcUseqJaE2XN"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "PIPELINE_NAME = \"penguin-tfma\"\n",
        "\n",
        "# Output directory to store artifacts generated from the pipeline.\n",
        "PIPELINE_ROOT = os.path.join('pipelines', PIPELINE_NAME)\n",
        "# Path to a SQLite DB file to use as an MLMD storage.\n",
        "METADATA_PATH = os.path.join('metadata', PIPELINE_NAME, 'metadata.db')\n",
        "# Output directory where created models from the pipeline will be exported.\n",
        "SERVING_MODEL_DIR = os.path.join('serving_model', PIPELINE_NAME)\n",
        "\n",
        "from absl import logging\n",
        "logging.set_verbosity(logging.INFO)  # Set default logging level."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8F2SRwRLSYGa"
      },
      "source": [
        "### Preparación de datos de ejemplo\n",
        "\n",
        "Usaremos el mismo [conjunto de datos de Palmer Penguins](https://allisonhorst.github.io/palmerpenguins/articles/intro.html).\n",
        "\n",
        "Hay cuatro características numéricas en este conjunto de datos que ya fueron normalizadas para tener un rango [0,1]. Compilaremos un modelo de clasificación que prediga las `species` de pingüinos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11J7XiCq6AFP"
      },
      "source": [
        "Debido a que TFX ExampleGen lee entradas de un directorio, tenemos que crear un directorio y copiar el conjunto de datos en él."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4fxMs6u86acP"
      },
      "outputs": [],
      "source": [
        "import urllib.request\n",
        "import tempfile\n",
        "\n",
        "DATA_ROOT = tempfile.mkdtemp(prefix='tfx-data')  # Create a temporary directory.\n",
        "_data_url = 'https://raw.githubusercontent.com/tensorflow/tfx/master/tfx/examples/penguin/data/labelled/penguins_processed.csv'\n",
        "_data_filepath = os.path.join(DATA_ROOT, \"data.csv\")\n",
        "urllib.request.urlretrieve(_data_url, _data_filepath)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nH6gizcpSwWV"
      },
      "source": [
        "## Cómo crear una canalización\n",
        "\n",
        "Agregaremos un componente [`Evaluator`](https://www.tensorflow.org/tfx/guide/evaluator) a la canalización que creamos en el [Tutorial de canalizaciones simples de TFX](https://www.tensorflow.org/tfx/tutorials/tfx/penguin_simple).\n",
        "\n",
        "Un componente Evaluator requiere datos de entrada de un componente `ExampleGen` y un modelo de un componente `Trainer` y un objeto [`tfma.EvalConfig`](https://www.tensorflow.org/tfx/model_analysis/api_docs/python/tfma/EvalConfig). Opcionalmente, podemos proporcionar un modelo de referencia que se puede utilizar para comparar métricas con el modelo recién entrenado.\n",
        "\n",
        "Un evaluador crea dos tipos de artefactos de salida, `ModelEvaluation` y `ModelBlessing`. ModelEvaluation contiene la salida de la evaluación detallada que se puede investigar y visualizar más a fondo con la biblioteca TFMA. ModelBlessing contiene una salida booleana que indica si el modelo pasó los criterios establecidos y puede usarse como señal en componentes posteriores, como un Pusher.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOjDv93eS5xV"
      },
      "source": [
        "### Cómo escribir un código de entrenamiento modelo\n",
        "\n",
        "Usaremos el mismo código de modelo que en el [Tutorial de canalizaciones simples de TFX](https://www.tensorflow.org/tfx/tutorials/tfx/penguin_simple)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aES7Hv5QTDK3"
      },
      "outputs": [],
      "source": [
        "_trainer_module_file = 'penguin_trainer.py'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gnc67uQNTDfW"
      },
      "outputs": [],
      "source": [
        "%%writefile {_trainer_module_file}\n",
        "\n",
        "# Copied from https://www.tensorflow.org/tfx/tutorials/tfx/penguin_simple\n",
        "\n",
        "from typing import List\n",
        "from absl import logging\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow_transform.tf_metadata import schema_utils\n",
        "\n",
        "from tfx.components.trainer.executor import TrainerFnArgs\n",
        "from tfx.components.trainer.fn_args_utils import DataAccessor\n",
        "from tfx_bsl.tfxio import dataset_options\n",
        "from tensorflow_metadata.proto.v0 import schema_pb2\n",
        "\n",
        "_FEATURE_KEYS = [\n",
        "    'culmen_length_mm', 'culmen_depth_mm', 'flipper_length_mm', 'body_mass_g'\n",
        "]\n",
        "_LABEL_KEY = 'species'\n",
        "\n",
        "_TRAIN_BATCH_SIZE = 20\n",
        "_EVAL_BATCH_SIZE = 10\n",
        "\n",
        "# Since we're not generating or creating a schema, we will instead create\n",
        "# a feature spec.  Since there are a fairly small number of features this is\n",
        "# manageable for this dataset.\n",
        "_FEATURE_SPEC = {\n",
        "    **{\n",
        "        feature: tf.io.FixedLenFeature(shape=[1], dtype=tf.float32)\n",
        "           for feature in _FEATURE_KEYS\n",
        "       },\n",
        "    _LABEL_KEY: tf.io.FixedLenFeature(shape=[1], dtype=tf.int64)\n",
        "}\n",
        "\n",
        "\n",
        "def _input_fn(file_pattern: List[str],\n",
        "              data_accessor: DataAccessor,\n",
        "              schema: schema_pb2.Schema,\n",
        "              batch_size: int = 200) -> tf.data.Dataset:\n",
        "  \"\"\"Generates features and label for training.\n",
        "\n",
        "  Args:\n",
        "    file_pattern: List of paths or patterns of input tfrecord files.\n",
        "    data_accessor: DataAccessor for converting input to RecordBatch.\n",
        "    schema: schema of the input data.\n",
        "    batch_size: representing the number of consecutive elements of returned\n",
        "      dataset to combine in a single batch\n",
        "\n",
        "  Returns:\n",
        "    A dataset that contains (features, indices) tuple where features is a\n",
        "      dictionary of Tensors, and indices is a single Tensor of label indices.\n",
        "  \"\"\"\n",
        "  return data_accessor.tf_dataset_factory(\n",
        "      file_pattern,\n",
        "      dataset_options.TensorFlowDatasetOptions(\n",
        "          batch_size=batch_size, label_key=_LABEL_KEY),\n",
        "      schema=schema).repeat()\n",
        "\n",
        "\n",
        "def _build_keras_model() -> tf.keras.Model:\n",
        "  \"\"\"Creates a DNN Keras model for classifying penguin data.\n",
        "\n",
        "  Returns:\n",
        "    A Keras Model.\n",
        "  \"\"\"\n",
        "  # The model below is built with Functional API, please refer to\n",
        "  # https://www.tensorflow.org/guide/keras/overview for all API options.\n",
        "  inputs = [keras.layers.Input(shape=(1,), name=f) for f in _FEATURE_KEYS]\n",
        "  d = keras.layers.concatenate(inputs)\n",
        "  for _ in range(2):\n",
        "    d = keras.layers.Dense(8, activation='relu')(d)\n",
        "  outputs = keras.layers.Dense(3)(d)\n",
        "\n",
        "  model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "  model.compile(\n",
        "      optimizer=keras.optimizers.Adam(1e-2),\n",
        "      loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "      metrics=[keras.metrics.SparseCategoricalAccuracy()])\n",
        "\n",
        "  model.summary(print_fn=logging.info)\n",
        "  return model\n",
        "\n",
        "\n",
        "# TFX Trainer will call this function.\n",
        "def run_fn(fn_args: TrainerFnArgs):\n",
        "  \"\"\"Train the model based on given args.\n",
        "\n",
        "  Args:\n",
        "    fn_args: Holds args used to train the model as name/value pairs.\n",
        "  \"\"\"\n",
        "\n",
        "  # This schema is usually either an output of SchemaGen or a manually-curated\n",
        "  # version provided by pipeline author. A schema can also derived from TFT\n",
        "  # graph if a Transform component is used. In the case when either is missing,\n",
        "  # `schema_from_feature_spec` could be used to generate schema from very simple\n",
        "  # feature_spec, but the schema returned would be very primitive.\n",
        "  schema = schema_utils.schema_from_feature_spec(_FEATURE_SPEC)\n",
        "\n",
        "  train_dataset = _input_fn(\n",
        "      fn_args.train_files,\n",
        "      fn_args.data_accessor,\n",
        "      schema,\n",
        "      batch_size=_TRAIN_BATCH_SIZE)\n",
        "  eval_dataset = _input_fn(\n",
        "      fn_args.eval_files,\n",
        "      fn_args.data_accessor,\n",
        "      schema,\n",
        "      batch_size=_EVAL_BATCH_SIZE)\n",
        "\n",
        "  model = _build_keras_model()\n",
        "  model.fit(\n",
        "      train_dataset,\n",
        "      steps_per_epoch=fn_args.train_steps,\n",
        "      validation_data=eval_dataset,\n",
        "      validation_steps=fn_args.eval_steps)\n",
        "\n",
        "  # The result of the training should be saved in `fn_args.serving_model_dir`\n",
        "  # directory.\n",
        "  model.save(fn_args.serving_model_dir, save_format='tf')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3OkNz3gTLwM"
      },
      "source": [
        "### Cómo escribir una definición de canalización\n",
        "\n",
        "Definiremos una función para crear una canalización de TFX. Además del componente Evaluator que mencionamos anteriormente, agregaremos un nodo más llamado [`Resolver`](https://www.tensorflow.org/tfx/api_docs/python/tfx/v1/dsl/Resolver). Para comprobar que un nuevo modelo es mejor que el modelo anterior, debemos compararlo con un modelo publicado anteriormente, conocido como línea base. [ML Metadata (MLMD)](https://www.tensorflow.org/tfx/guide/mlmd) rastrea todos los artefactos anteriores de la canalización y `Resolver` puede encontrar cuál fue el último modelo *con visto bueno* (un modelo aprobado con éxito por Evaluator) de MLMD con una clase de estrategia llamada `LatestBlessedModelStrategy`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M49yYVNBTPd4"
      },
      "outputs": [],
      "source": [
        "import tensorflow_model_analysis as tfma\n",
        "\n",
        "def _create_pipeline(pipeline_name: str, pipeline_root: str, data_root: str,\n",
        "                     module_file: str, serving_model_dir: str,\n",
        "                     metadata_path: str) -> tfx.dsl.Pipeline:\n",
        "  \"\"\"Creates a three component penguin pipeline with TFX.\"\"\"\n",
        "  # Brings data into the pipeline.\n",
        "  example_gen = tfx.components.CsvExampleGen(input_base=data_root)\n",
        "\n",
        "  # Uses user-provided Python function that trains a model.\n",
        "  trainer = tfx.components.Trainer(\n",
        "      module_file=module_file,\n",
        "      examples=example_gen.outputs['examples'],\n",
        "      train_args=tfx.proto.TrainArgs(num_steps=100),\n",
        "      eval_args=tfx.proto.EvalArgs(num_steps=5))\n",
        "\n",
        "  # NEW: Get the latest blessed model for Evaluator.\n",
        "  model_resolver = tfx.dsl.Resolver(\n",
        "      strategy_class=tfx.dsl.experimental.LatestBlessedModelStrategy,\n",
        "      model=tfx.dsl.Channel(type=tfx.types.standard_artifacts.Model),\n",
        "      model_blessing=tfx.dsl.Channel(\n",
        "          type=tfx.types.standard_artifacts.ModelBlessing)).with_id(\n",
        "              'latest_blessed_model_resolver')\n",
        "\n",
        "  # NEW: Uses TFMA to compute evaluation statistics over features of a model and\n",
        "  #   perform quality validation of a candidate model (compared to a baseline).\n",
        "\n",
        "  eval_config = tfma.EvalConfig(\n",
        "      model_specs=[tfma.ModelSpec(label_key='species')],\n",
        "      slicing_specs=[\n",
        "          # An empty slice spec means the overall slice, i.e. the whole dataset.\n",
        "          tfma.SlicingSpec(),\n",
        "          # Calculate metrics for each penguin species.\n",
        "          tfma.SlicingSpec(feature_keys=['species']),\n",
        "          ],\n",
        "      metrics_specs=[\n",
        "          tfma.MetricsSpec(per_slice_thresholds={\n",
        "              'sparse_categorical_accuracy':\n",
        "                  tfma.PerSliceMetricThresholds(thresholds=[\n",
        "                      tfma.PerSliceMetricThreshold(\n",
        "                          slicing_specs=[tfma.SlicingSpec()],\n",
        "                          threshold=tfma.MetricThreshold(\n",
        "                              value_threshold=tfma.GenericValueThreshold(\n",
        "                                   lower_bound={'value': 0.6}),\n",
        "                              # Change threshold will be ignored if there is no\n",
        "                              # baseline model resolved from MLMD (first run).\n",
        "                              change_threshold=tfma.GenericChangeThreshold(\n",
        "                                  direction=tfma.MetricDirection.HIGHER_IS_BETTER,\n",
        "                                  absolute={'value': -1e-10}))\n",
        "                       )]),\n",
        "          })],\n",
        "      )\n",
        "  evaluator = tfx.components.Evaluator(\n",
        "      examples=example_gen.outputs['examples'],\n",
        "      model=trainer.outputs['model'],\n",
        "      baseline_model=model_resolver.outputs['model'],\n",
        "      eval_config=eval_config)\n",
        "\n",
        "  # Checks whether the model passed the validation steps and pushes the model\n",
        "  # to a file destination if check passed.\n",
        "  pusher = tfx.components.Pusher(\n",
        "      model=trainer.outputs['model'],\n",
        "      model_blessing=evaluator.outputs['blessing'], # Pass an evaluation result.\n",
        "      push_destination=tfx.proto.PushDestination(\n",
        "          filesystem=tfx.proto.PushDestination.Filesystem(\n",
        "              base_directory=serving_model_dir)))\n",
        "\n",
        "  components = [\n",
        "      example_gen,\n",
        "      trainer,\n",
        "\n",
        "      # Following two components were added to the pipeline.\n",
        "      model_resolver,\n",
        "      evaluator,\n",
        "\n",
        "      pusher,\n",
        "  ]\n",
        "\n",
        "  return tfx.dsl.Pipeline(\n",
        "      pipeline_name=pipeline_name,\n",
        "      pipeline_root=pipeline_root,\n",
        "      metadata_connection_config=tfx.orchestration.metadata\n",
        "      .sqlite_metadata_connection_config(metadata_path),\n",
        "      components=components)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIcu1LeeQbMt"
      },
      "source": [
        "Necesitamos proporcionar la siguiente información a Evaluator a través de `eval_config`:\n",
        "\n",
        "- Métricas adicionales para configurar (si desea más métricas que las definidas en el modelo).\n",
        "- Segmentos para configurar\n",
        "- Umbrales de validaciones del modelo para verificar si se incluirá la validación\n",
        "\n",
        "Como `SparseCategoricalAccuracy` ya estaba incluido en la llamada `model.compile()`, se incluirá en el análisis automáticamente. Por lo tanto, no agregamos ninguna métrica adicional aquí. `SparseCategoricalAccuracy` se usará para decidir si el modelo también es lo suficientemente bueno.\n",
        "\n",
        "Calculamos las métricas para todo el conjunto de datos y para cada especie de pingüino. `SlicingSpec` especifica cómo se agregan las métricas declaradas.\n",
        "\n",
        "Hay dos umbrales que debe superar un nuevo modelo, uno es un umbral absoluto de 0,6 y el otro es un umbral relativo que debe ser más alto que el modelo de línea base. Cuando ejecute la canalización por primera vez, se ignorará `change_threshold` y solo se comprobará value_threshold. Si ejecuta la canalización más de una vez, `Resolver` encontrará un modelo de la ejecución anterior y lo usará como modelo de línea base para la comparación.\n",
        "\n",
        "Consulte la [guía del componente Evaluator](https://www.tensorflow.org/tfx/guide/evaluator#using_the_evaluator_component) para obtener más información."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJbq07THU2GV"
      },
      "source": [
        "## Cómo ejecutar la canalización\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mp0AkmrPdUb"
      },
      "source": [
        "Usaremos `LocalDagRunner` como en el tutorial anterior."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fAtfOZTYWJu-"
      },
      "outputs": [],
      "source": [
        "tfx.orchestration.LocalDagRunner().run(\n",
        "  _create_pipeline(\n",
        "      pipeline_name=PIPELINE_NAME,\n",
        "      pipeline_root=PIPELINE_ROOT,\n",
        "      data_root=DATA_ROOT,\n",
        "      module_file=_trainer_module_file,\n",
        "      serving_model_dir=SERVING_MODEL_DIR,\n",
        "      metadata_path=METADATA_PATH))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppERq0Mj6xvW"
      },
      "source": [
        "Cuando se complete la canalización, debería poder ver algo como lo siguiente:\n",
        "\n",
        "```\n",
        "INFO:absl:Blessing result True written to pipelines/penguin-tfma/Evaluator/blessing/4.\n",
        "```\n",
        "\n",
        "O también puede verificar manualmente el directorio de salida donde se almacenan los artefactos generados. Si visita `pipelines/penguin-tfma/Evaluator/blessing/` con un navegador de archivos, puede ver un archivo con un nombre `BLESSED` o `NOT_BLESSED` según el resultado de la evaluación.\n",
        "\n",
        "Si el resultado de la aprobación es `False`, Pusher se negará a insertar el modelo a `serving_model_dir` porque el modelo no es lo suficientemente bueno para usarlo en producción."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zR9HcqMSTizW"
      },
      "source": [
        "Puede ejecutar la canalización nuevamente, posiblemente con diferentes configuraciones de evaluación. Incluso si ejecuta la canalización con exactamente la misma configuración y conjunto de datos, el modelo entrenado puede ser ligeramente diferente debido a la aleatoriedad inherente del entrenamiento del modelo que puede conducir a un modelo `NOT_BLESSED`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWcBI-bjoVTO"
      },
      "source": [
        "### Análisis de salidas de la canalización\n",
        "\n",
        "Puede usar TFMA para investigar y visualizar el resultado de la evaluación en el artefacto ModelEvaluation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXZ0N5GHm_tX"
      },
      "source": [
        "> **NOTA: Si no está en Colab, instale las extensiones de Jupyter.** Necesita una extensión de TensorFlow Model Analysis para ver la visualización de TFMA. Esta extensión ya está instalada en Google Colab, pero es posible que deba instalarla si ejecuta este bloc de notas en otros entornos. Consulte la dirección de instalación de la extensión de Jupyter en la [Guía de instalación](https://github.com/tensorflow/model-analysis#installation).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VIWOBq0opag"
      },
      "source": [
        "#### Obtención del resultado del análisis de los artefactos de salida\n",
        "\n",
        "Puede utilizar las API de MLMD para localizar estas salidas mediante programación. Primero, definiremos algunas funciones de utilidad para buscar artefactos de salida que se acaban de producir."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aiK6zbeAg3X5"
      },
      "outputs": [],
      "source": [
        "from ml_metadata.proto import metadata_store_pb2\n",
        "# Non-public APIs, just for showcase.\n",
        "from tfx.orchestration.portable.mlmd import execution_lib\n",
        "\n",
        "# TODO(b/171447278): Move these functions into the TFX library.\n",
        "\n",
        "def get_latest_artifacts(metadata, pipeline_name, component_id):\n",
        "  \"\"\"Output artifacts of the latest run of the component.\"\"\"\n",
        "  context = metadata.store.get_context_by_type_and_name(\n",
        "      'node', f'{pipeline_name}.{component_id}')\n",
        "  executions = metadata.store.get_executions_by_context(context.id)\n",
        "  latest_execution = max(executions,\n",
        "                         key=lambda e:e.last_update_time_since_epoch)\n",
        "  return execution_lib.get_output_artifacts(metadata, latest_execution.id)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tujLG8sTGZiv"
      },
      "source": [
        "Podemos encontrar la última ejecución del componente `Evaluator` y obtener artefactos de salida de él."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4FOo6PV5g5Mm"
      },
      "outputs": [],
      "source": [
        "# Non-public APIs, just for showcase.\n",
        "from tfx.orchestration.metadata import Metadata\n",
        "from tfx.types import standard_component_specs\n",
        "\n",
        "metadata_connection_config = tfx.orchestration.metadata.sqlite_metadata_connection_config(\n",
        "    METADATA_PATH)\n",
        "\n",
        "with Metadata(metadata_connection_config) as metadata_handler:\n",
        "  # Find output artifacts from MLMD.\n",
        "  evaluator_output = get_latest_artifacts(metadata_handler, PIPELINE_NAME,\n",
        "                                          'Evaluator')\n",
        "  eval_artifact = evaluator_output[standard_component_specs.EVALUATION_KEY][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXIJR840GpEq"
      },
      "source": [
        "`Evaluator` siempre devuelve un artefacto de evaluación y podemos visualizarlo usando la biblioteca TensorFlow Model Analysis. Por ejemplo, el siguiente código mostrará las métricas de precisión para cada especie de pingüino."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wTaKoEHrj0Gs"
      },
      "outputs": [],
      "source": [
        "import tensorflow_model_analysis as tfma\n",
        "\n",
        "eval_result = tfma.load_eval_result(eval_artifact.uri)\n",
        "tfma.view.render_slicing_metrics(eval_result, slicing_column='species')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSwaiRQ0JYMZ"
      },
      "source": [
        "Si elige 'sparse_categorical_accuracy' en la lista desplegable `Show`, podrá ver los valores de precisión por especie. Tal vez le convenga agregar más segmentos y verificar si su modelo es bueno para todas las distribuciones y si existe algún posible sesgo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08R8qvweThRf"
      },
      "source": [
        "## Siguientes pasos\n",
        "\n",
        "Obtenga más información sobre el análisis de modelos en el [tutorial de la biblioteca TensorFlow Model Analysis](https://www.tensorflow.org/tfx/tutorials/model_analysis/tfma_basic).\n",
        "\n",
        "Puede encontrar más recursos en https://www.tensorflow.org/tfx/tutorials.\n",
        "\n",
        "Consulte [Explicación de las canalizaciones de TFX](https://www.tensorflow.org/tfx/guide/understanding_tfx_pipelines) para obtener más información sobre varios conceptos en TFX.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "DjUA6S30k52h",
        "lOjDv93eS5xV"
      ],
      "name": "penguin_tfma.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
