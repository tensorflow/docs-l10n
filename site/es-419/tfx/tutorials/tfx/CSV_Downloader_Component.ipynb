{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nl4XCJN9g8Bc"
      },
      "source": [
        "Copyright 2023 The TensorFlow Authors.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dIUc9Zh3hM6H"
      },
      "outputs": [],
      "source": [
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wU-hMBZVmyCo"
      },
      "source": [
        "# Tutorial de TFX Pipeline para un modelo de lenguaje colosal con el conjunto de datos diario de CNN\n",
        "\n",
        "En este codelab, usamos KerasNLP para cargar un modelo de lenguaje colosal (LLM) previamente entrenado (modelo GPT-2) y ajustarlo a un conjunto de datos. El conjunto de datos que se usa en esta demostración es el conjunto de datos diario de CNN. Tenga en cuenta que GPT-2 se usa aquí sólo para demostrar el proceso de un extremo a otro; las técnicas y las herramientas introducidas en este codelab son potencialmente transferibles a otros modelos de lenguaje generativo como Google T5."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJAp-HxKiKsE"
      },
      "source": [
        "<div class=\"devsite-table-wrapper\"><table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "<td><a target=\"_blank\" href=\"https://www.tensorflow.org/tfx/tutorials/tfx/CSV_Downloader_Component\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver en TensorFlow.org</a></td>\n",
        "<td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/es-419/tfx/tutorials/tfx/CSV_Downloader_Component.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Ejecutar en Google Colab</a></td>\n",
        "<td><a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/es-419/tfx/tutorials/tfx/CSV_Downloader_Component.ipynb\"><img width=\"32px\" src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver fuente en GitHub</a></td>\n",
        "<td><a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/es-419/tfx/tutorials/tfx/CSV_Downloader_Component.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Descargar el bloc de notas</a></td>\n",
        "</table></div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MK3ryPikKtj"
      },
      "source": [
        "# Antes de empezar\n",
        "\n",
        "Colab ofrece diferentes tipos de tiempos de ejecución. Asegúrese de ir a **Tiempo de ejecución -&gt; Cambiar tipo de tiempo de ejecución** y elija el tiempo de ejecución del Acelerador de hardware de GPU (que debe tener &gt;12G de RAM del sistema y ~15G de RAM de GPU), ya que ajustará el modelo GPT-2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMmMNdV1jZAS"
      },
      "source": [
        "# Preparación\n",
        "\n",
        "En primer lugar, tenemos que instalar el paquete de Python para TFX."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C23ItymvmVth"
      },
      "source": [
        "## Actualización de pip\n",
        "\n",
        "Para evitar actualizar Pip en un sistema cuando se ejecuta localmente, verifique que se esté ejecutando en Colab. Por supuesto, los sistemas locales se pueden actualizar por separado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cfSG5IFamUq7"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  import colab\n",
        "  !pip install --upgrade pip\n",
        "except:\n",
        "  pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "te56mTWomdLq"
      },
      "source": [
        "## Instalación de TFX\n",
        "\n",
        "TFX actualmente está experimentando problemas con Python 3.10 en Colab. Por lo tanto, si solo ejecuta el siguiente comando\n",
        "\n",
        "```\n",
        "!pip install -U tfx\n",
        "```\n",
        "\n",
        "para instalar tfx, **obtendrá un error**. Por lo tanto, siga el código a continuación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TGlfiX4PmcjZ"
      },
      "outputs": [],
      "source": [
        "%%shell\n",
        "update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.8 3\n",
        "curl -O https://bootstrap.pypa.io/get-pip.py\n",
        "python get-pip.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nYHRZQjQEcS7"
      },
      "outputs": [],
      "source": [
        "# 1) TFX relies on an old version of google-api-core so we let google-auth float\n",
        "# for the install. We grep it out below:\n",
        "!grep -v google-auth /etc/requirements.core.in > requirements.txt\n",
        "\n",
        "# 2) httplib2 should be included in /etc/requirements.core.in but it's not for\n",
        "# reasons. We ensure it's included:\n",
        "!grep httplib2 /etc/requirements.user.in >> requirements.txt\n",
        "\n",
        "# 3) google.colab package is not available as a wheel. We symlink that in so\n",
        "# it's on the sys.path of Python 3.8:\n",
        "!mkdir /usr/local/lib/python3.8/dist-packages/google\n",
        "!ln -s /usr/local/lib/python3.10/dist-packages/google/colab /usr/local/lib/python3.8/dist-packages/google/colab\n",
        "\n",
        "# Now with those pre-requisites out of the way:\n",
        "!pip install tfx==1.13.0 -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5MiV2iFkiqbL"
      },
      "outputs": [],
      "source": [
        "!pip install keras_nlp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZo6NOYQEcS7"
      },
      "source": [
        "# Importaciones\n",
        "\n",
        "Primero, eliminemos nuestras importaciones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VDhX6vgUEcS7"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tfx.types import Channel\n",
        "from tfx.orchestration.experimental.interactive.interactive_context import InteractiveContext"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVMFdYDtmgPX"
      },
      "source": [
        "## Desinstalación de shapely\n",
        "\n",
        "TODO(b/263441833) Esta es una solución temporal para evitar un ImportError. En última instancia, debería solucionarse admitiendo una versión reciente de Bigquery, en lugar de desinstalar otras dependencias adicionales.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K4AKpWUiEcS7"
      },
      "outputs": [],
      "source": [
        "!pip uninstall shapely -y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJaN_u_8tEwi"
      },
      "source": [
        "## ¿Reinició el tiempo de ejecución?\n",
        "\n",
        "Si está usando Google Colab, la primera vez que ejecute la celda anterior, debe hacer clic en el botón \"REINICIAR TIEMPO DE EJECUCIÓN\" o usar el menú \"Tiempo de ejecución &gt; Reiniciar tiempo de ejecución ...\" para reiniciar el tiempo de ejecución. Esto se debe a la forma en que Colab carga los paquetes.\n",
        "\n",
        "Verifique las versiones de TensorFlow y TFX."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fac1XkwrnXW6"
      },
      "source": [
        "Revisemos las versiones de la biblioteca."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VNwD6G4TXrlq"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "print('TensorFlow version: {}'.format(tf.__version__))\n",
        "from tfx import v1 as tfx\n",
        "print('TFX version: {}'.format(tfx.__version__))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LnvgEYNwtMhJ"
      },
      "source": [
        "## Configuración de variables\n",
        "\n",
        "Hay algunas variables que se utilizan para definir una canalización. Puede personalizar estas variables como desee. De forma predeterminada, todos los resultados de la canalización se generarán en el directorio actual."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVFcsQhWkbkw"
      },
      "source": [
        "# Descargador de CSV\n",
        "\n",
        "Para que la canalización sea más eficiente y para que sea posible la automatización, es útil tener un componente que incluya un enlace de descarga al archivo CSV que se descargará. Además, un objetivo importante de la canalización de ML de producción de TFX es recopilar metadatos que contengan información sobre los componentes de la canalización, sus ejecuciones y los artefactos resultantes. En otras palabras, el propósito de los metadatos es analizar el linaje de los componentes de la canalización y los problemas de depuración, y el componente de descarga CSV ayudaría a los usuarios a registrar y hacer un seguimiento de la información sobre la fuente de los datos y los pasos de preprocesamiento que los datos han experimentado antes de entrar a la canalización. En esta sección, declaramos un nuevo artefacto llamado CSVdoc y desarrollamos un componente personalizado, CSV Downloader, que almacena información sobre el conjunto de datos y descarga el archivo CSV en el URI del artefacto CSVdoc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jc1JTbjjo0bd"
      },
      "outputs": [],
      "source": [
        "from tfx.types import artifact\n",
        "from tfx import types\n",
        "\n",
        "Property = artifact.Property\n",
        "PropertyType = artifact.PropertyType\n",
        "\n",
        "URL_PROPERTY = Property(type=PropertyType.STRING)\n",
        "PATH_PROPERTY = Property(type=PropertyType.STRING)\n",
        "\n",
        "class CsvDoc(types.Artifact):\n",
        "  \"\"\" Artifact that contains the CSV dataset.\n",
        "\n",
        "     - 'url' : saves the source of the original data.\n",
        "     - 'path': saves the path to the CSV file.\n",
        "  \"\"\"\n",
        "\n",
        "  TYPE_NAME = 'CsvDoc'\n",
        "  PROPERTIES = {\n",
        "      'url' : URL_PROPERTY,\n",
        "      'path': PATH_PROPERTY,\n",
        "  }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Qks2al5X1Us"
      },
      "outputs": [],
      "source": [
        "from absl import logging\n",
        "import requests\n",
        "import os\n",
        "import tfx.v1 as tfx\n",
        "from tfx.dsl.component.experimental.decorators import component\n",
        "\n",
        "@tfx.dsl.components.component\n",
        "def CsvDownloaderComponent(\n",
        "    url: tfx.dsl.components.Parameter[str],\n",
        "    file_name: tfx.dsl.components.Parameter[str],\n",
        "    saved_file: tfx.dsl.components.OutputArtifact[CsvDoc],\n",
        ") -> None:\n",
        "  response = requests.get(url)\n",
        "  saved_file.url = url\n",
        "  if response.status_code == 200:\n",
        "    file_path = os.path.join(saved_file.uri, file_name)\n",
        "    saved_file.path = file_path\n",
        "    url_content = response.content\n",
        "    with open(file_path, 'wb') as csv_file:\n",
        "      csv_file.write(url_content)\n",
        "    logging.info(f\"CSV file saved successfully at {file_path}\")\n",
        "  else:\n",
        "    raise Exception(\"CSV file failed to be saved.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3D3O4L6hYBBt"
      },
      "outputs": [],
      "source": [
        "downloader = CsvDownloaderComponent(\n",
        "  url = 'https://drive.google.com/uc?id=1YdZsJlRafqxiNSl0nHQkwR7rzrNlN9LI&export=download', file_name ='testing_doc.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fGm5cG6cYE10"
      },
      "outputs": [],
      "source": [
        "from tfx.orchestration.experimental.interactive.interactive_context import InteractiveContext\n",
        "context = InteractiveContext()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SHpBtrduYG7U"
      },
      "outputs": [],
      "source": [
        "context.run(downloader, enable_cache = False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "CSV_Downloader_Component.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
