{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjUA6S30k52h"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "SpNWyqewk8fE"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TyrY7lV0oke"
      },
      "source": [
        "# Cómo crear una canalización de TFX usando plantillas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wD2KOXlZuAOj"
      },
      "source": [
        "Nota: Recomendamos ejecutar este tutorial en Google Cloud Vertex AI Workbench. [Inicie este bloc de notas en Vertex AI Workbench](https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?q=download_url%3Dhttps%253A%252F%252Fraw.githubusercontent.com%252Ftensorflow%252Ftfx%252Fmaster%252Fdocs%252Ftutorials%252Ftfx%252Ftemplate.ipynb).\n",
        "\n",
        "<div class=\"devsite-table-wrapper\"><table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "<td><a target=\"_blank\" href=\"https://www.tensorflow.org/tfx/tutorials/tfx/template\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver en TensorFlow.org</a></td>\n",
        "<td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/es-419/tfx/tutorials/tfx/template.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Ejecutar en Google Colab</a></td>\n",
        "<td><a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/es-419/tfx/tutorials/tfx/template.ipynb\"><img width=\"32px\" src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver fuente en GitHub</a></td>\n",
        "<td><a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/es-419/tfx/tutorials/tfx/template.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Descargar el bloc de notas</a></td>\n",
        "</table></div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLYriYe10okf"
      },
      "source": [
        "## Introducción\n",
        "\n",
        "Este documento proporcionará instrucciones para crear una canalización de TensorFlow Extended (TFX) utilizando las *plantillas* que se proporcionan con el paquete de Python para TFX. Muchas de las instrucciones son comandos de shell de Linux, que se ejecutarán en una instancia de AI Platform Notebooks. Se proporcionan las correspondientes celdas de código de Jupyter Notebook que invocan esos comandos usando `!`.\n",
        "\n",
        "Compilará una canalización mediante el uso del [conjunto de datos Taxi Trips](https://data.cityofchicago.org/Transportation/Taxi-Trips/wrvz-psew) publicado por la ciudad de Chicago. Le recomendamos que use esta canalización como punto de referencia para intentar compilar su propia canalización con su conjunto de datos.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxPMeugQ0okg"
      },
      "source": [
        "## Paso 1. Configure su entorno\n",
        "\n",
        "AI Platform Pipelines preparará un entorno de desarrollo para compilar una canalización y un clúster de Kubeflow Pipeline para ejecutar la canalización recién compilada.\n",
        "\n",
        "**NOTA:** Para seleccionar una versión particular de TensorFlow o seleccionar una instancia de GPU, cree una instancia preinstalada de TensorFlow en AI Platform Notebooks.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-am1yWXt0okh"
      },
      "source": [
        "Instale el paquete de python para `tfx` con el requisito adicional `kfp`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XNiqq_kN0okj"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "# Use the latest version of pip.\n",
        "!pip install --upgrade pip\n",
        "# Install tfx and kfp Python packages.\n",
        "!pip install --upgrade \"tfx[kfp]<2\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hX1rqpbQ0okp"
      },
      "source": [
        "Revisemos las versiones de TFX."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XAIoKMNG0okq"
      },
      "outputs": [],
      "source": [
        "!python3 -c \"from tfx import version ; print('TFX version: {}'.format(version.__version__))\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7JLpaXT0okv"
      },
      "source": [
        "En AI Platform Pipelines, TFX se ejecuta en un entorno de Kubernetes alojado mediante [Kubeflow Pipelines](https://www.kubeflow.org/docs/pipelines/overview/pipelines-overview/).\n",
        "\n",
        "Configuremos algunas variables de entorno para usar Kubeflow Pipelines.\n",
        "\n",
        "Primero, obtenga el ID de su proyecto de GCP."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hw3nsooU0okv"
      },
      "outputs": [],
      "source": [
        "# Read GCP project id from env.\n",
        "shell_output=!gcloud config list --format 'value(core.project)' 2>/dev/null\n",
        "GOOGLE_CLOUD_PROJECT=shell_output[0]\n",
        "%env GOOGLE_CLOUD_PROJECT={GOOGLE_CLOUD_PROJECT}\n",
        "print(\"GCP project ID:\" + GOOGLE_CLOUD_PROJECT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_6r4uzE0oky"
      },
      "source": [
        "También tenemos que acceder a su clúster KFP. Puede acceder a él en su Consola de Google Cloud en el menú \"AI Platform &gt; Canalización\". El \"punto de conexión\" del clúster de KFP se puede encontrar en la URL del panel de canalizaciones, o puede obtenerlo en la URL de la página de introducción donde inició este bloc de ntoas. Creemos una variable de entorno `ENDPOINT` y configurémosla en el punto de conexión del clúster KFP. **ENDPOINT debe contener solo la parte del nombre de host de la URL.** Por ejemplo, si la URL del panel de KFP es `https://1e9deb537390ca22-dot-asia-east1.pipelines.googleusercontent.com/#/start` , el valor de ENDPOINT se convierte en `1e9deb537390ca22-dot-asia-east1.pipelines.googleusercontent.com`.\n",
        "\n",
        "> **NOTA: A continuación, DEBE establecer el valor de su PUNTO DE CONEXIÓN.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AzqEQORV0oky"
      },
      "outputs": [],
      "source": [
        "# This refers to the KFP cluster endpoint\n",
        "ENDPOINT='' # Enter your ENDPOINT here.\n",
        "if not ENDPOINT:\n",
        "    from absl import logging\n",
        "    logging.error('Set your ENDPOINT in this cell.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6T-KXeA0ok3"
      },
      "source": [
        "Establezca el nombre de la imagen como `tfx-pipeline` en el proyecto GCP actual."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ztxXOVD0ok4"
      },
      "outputs": [],
      "source": [
        "# Docker image name for the pipeline image.\n",
        "CUSTOM_TFX_IMAGE='gcr.io/' + GOOGLE_CLOUD_PROJECT + '/tfx-pipeline'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOsQbkky0ok7"
      },
      "source": [
        "Y ya está. Estamos listos para crear una canalización."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cxlbi1QM0ok8"
      },
      "source": [
        "## Paso 2. Copie la plantilla predefinida al directorio de su proyecto\n",
        "\n",
        "En este paso, crearemos un directorio y archivos de proyecto de canalización de trabajo copiando archivos adicionales de una plantilla predefinida.\n",
        "\n",
        "Puede cambiar el nombre de su canalización si cambia el valor de `PIPELINE_NAME` a continuación. Este también se convertirá en el nombre del directorio del proyecto donde se colocarán sus archivos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cIPlt-700ok-"
      },
      "outputs": [],
      "source": [
        "PIPELINE_NAME=\"my_pipeline\"\n",
        "import os\n",
        "PROJECT_DIR=os.path.join(os.path.expanduser(\"~\"),\"imported\",PIPELINE_NAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozHIomcd0olB"
      },
      "source": [
        "TFX incluye la plantilla <code>taxi</code> con el paquete de Python para TFX. Si planea resolver un problema de predicción puntual, que incluye clasificación y regresión, esta plantilla podría usarse como punto de partida.\n",
        "\n",
        "El comando CLI `tfx template copy` copia archivos de plantilla predefinidos al directorio de su proyecto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VLXpTTjU0olD"
      },
      "outputs": [],
      "source": [
        "!tfx template copy \\\n",
        "  --pipeline-name={PIPELINE_NAME} \\\n",
        "  --destination-path={PROJECT_DIR} \\\n",
        "  --model=taxi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxOT19QS0olH"
      },
      "source": [
        "Cambie el contexto del directorio de trabajo en este bloc de notas al directorio del proyecto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6P-HljcU0olI"
      },
      "outputs": [],
      "source": [
        "%cd {PROJECT_DIR}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1tEYUQxH0olO"
      },
      "source": [
        "> NOTA: Recuerde que debe cambiar el directorio en `File Browser` a la izquierda haciendo clic en el directorio del proyecto una vez que lo haya creado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzT2PFrN0olQ"
      },
      "source": [
        "## Paso 3. Explore sus archivos fuente copiados\n",
        "\n",
        "La plantilla de TFX proporciona archivos de estructura básicos para compilar una canalización, incluido el código fuente de Python, datos de muestra y bloc de notas Jupyter para analizar la salida de la canalización. La plantilla `taxi` utiliza el mismo conjunto de datos *Chicago Taxi* y el mismo modelo de ML que el [Tutorial de Airflow](https://www.tensorflow.org/tfx/tutorials/tfx/airflow_workshop).\n",
        "\n",
        "Esta es una breve introducción a cada uno de los archivos de Python.\n",
        "\n",
        "- `pipeline`: este directorio contiene la definición de la canalización.\n",
        "    - `configs.py`: define constantes comunes para los ejecutores de la canalización\n",
        "    - `pipeline.py`: define los componentes de TFX y una canalización\n",
        "- `models`: este directorio contiene definiciones de modelos de ML.\n",
        "    - `features.py`, `features_test.py`: define características para el modelo\n",
        "    - `preprocessing.py`, `preprocessing_test.py`: define trabajos de preprocesamiento con ayuda de `tf::Transform`\n",
        "    - `estimator`: este directorio contiene un modelo basado en Estimator.\n",
        "        - `constants.py`: define las constantes del modelo\n",
        "        - `model.py`, `model_test.py`: define el modelo DNN utilizando el estimador TF\n",
        "    - `keras`: este directorio contiene un modelo basado en Keras.\n",
        "        - `constants.py`: define las constantes del modelo\n",
        "        - `model.py`, `model_test.py`: define el modelo DNN usando Keras\n",
        "- `local_runner.py`, `kubeflow_runner.py`: define ejecutores para cada motor de orquestación\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROwHAsDK0olT"
      },
      "source": [
        "Quizás note que hay algunos archivos con `_test.py` en su nombre. Estas son pruebas unitarias de la canalización y se recomienda agregar más pruebas unitarias a medida que implemente sus propias canalizaciones. Puede ejecutar pruebas unitarias si proporciona el nombre del módulo de los archivos de prueba con la marca `-m`. Generalmente puede obtener el nombre de un módulo al eliminar la extensión `.py` y reemplazarla por `/` con `.`. Por ejemplo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M0cMdE2Z0olU"
      },
      "outputs": [],
      "source": [
        "!{sys.executable} -m models.features_test\n",
        "!{sys.executable} -m models.keras.model_test\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tO9Jhplo0olX"
      },
      "source": [
        "## Paso 4. Ejecute su primera canalización de TFX\n",
        "\n",
        "Los componentes en la canalización de TFX generarán salidas para cada ejecución como [artefactos de metadatos de ML](https://www.tensorflow.org/tfx/guide/mlmd) y deben almacenarse en algún lugar. Puede utilizar cualquier almacenamiento al que pueda acceder el clúster de KFP y, para este ejemplo, utilizaremos Google Cloud Storage (GCS). Se debería haber creado automáticamente un depósito de GCS predeterminado. Su nombre será `<your-project-id>-kubeflowpipelines-default`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zr-RjyPWTHdH"
      },
      "source": [
        "Carguemos nuestros datos de muestra en el depósito de GCS para que podamos usarlos en nuestra canalización más adelante."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gW-dSHW-TSdc"
      },
      "outputs": [],
      "source": [
        "!gsutil cp data/data.csv gs://{GOOGLE_CLOUD_PROJECT}-kubeflowpipelines-default/tfx-template/data/taxi/data.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wc54hDZu0ole"
      },
      "source": [
        "Creemos una canalización de TFX a partir del comando `tfx pipeline create`.\n",
        "\n",
        "> Nota: Al crear una canalización para KFP, necesitamos una imagen de contenedor que se utilizará para ejecutar nuestra canalización. Y `skaffold` compilará la imagen para nosotros. Debido a que skaffold extrae imágenes base del Docker Hub, tomará entre 5 y 10 minutos cuando compilemos la imagen por primera vez, pero tomará mucho menos tiempo desde la segunda compilación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kOU7zQof0olf"
      },
      "outputs": [],
      "source": [
        "!tfx pipeline create  --pipeline-path=kubeflow_runner.py --endpoint={ENDPOINT} \\\n",
        "--build-image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmA6___Y0olh"
      },
      "source": [
        "Mientras se crea una canalización, se generará `Dockerfile` para compilar una imagen de Docker. No olvide agregarlo al sistema de control de código fuente (por ejemplo, git) junto con otros archivos fuente.\n",
        "\n",
        "NOTA: `kubeflow` se seleccionará automáticamente como motor de orquestación si `airflow` no está instalado y no se especifica `--engine`.\n",
        "\n",
        "Ahora inicie una ejecución con la canalización recién creada con ayuda del comando `tfx run create`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cKSjVVsa0oli"
      },
      "outputs": [],
      "source": [
        "!tfx run create --pipeline-name={PIPELINE_NAME} --endpoint={ENDPOINT}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pg0VxvUC0olk"
      },
      "source": [
        "O también puede ejecutar la canalización en el panel de KFP. La nueva ejecución aparecerá en Experimentos en el Panel de de KFP. Al hacer clic en el experimento, podrá monitorear el progreso y visualizar los artefactos creados durante la ejecución."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLN4ges90oll"
      },
      "source": [
        "Sin embargo, recomendamos visitar el Panel de KFP. Puede acceder al panel de KFP desde el menú de Cloud AI Platform Pipelines en la Consola de Google Cloud. Una vez que visite el panel, podrá encontrar la canalización y acceder a una gran cantidad de información sobre esta. Por ejemplo, puede encontrar sus ejecuciones en el menú *Experimentos* y, cuando abre su ejecución en Experimentos, puede encontrar todos sus artefactos de la canalización en el menú *Artefactos*.\n",
        "\n",
        "> Nota: Si la ejecución de su canalización falla, puede ver registros detallados para cada componente de TFX en la pestaña Experimentos en el Panel de KFP.\n",
        "\n",
        "Una de las principales fuentes de error son los problemas relacionados con los permisos. Asegúrese de que su clúster de KFP tenga permisos para acceder a las API de Google Cloud. Esto se puede configurar [al momento de crear un clúster de KFP en GCP](https://cloud.google.com/ai-platform/pipelines/docs/setting-up) o bien puede consultar el [documento de solución de problemas en GCP](https://cloud.google.com/ai-platform/pipelines/docs/troubleshooting)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYH8Y2KB0olm"
      },
      "source": [
        "## Paso 5. Agregue componentes para la validación de datos\n",
        "\n",
        "En este paso, agregará componentes para la validación de datos, incluidos `StatisticsGen`, `SchemaGen` y `ExampleValidator`. Si está interesado en la validación de datos, consulte [Introducción a Tensorflow Data Validation](https://www.tensorflow.org/tfx/data_validation/get_started).\n",
        "\n",
        "> **Haga doble clic para cambiar el directorio a `pipeline` y haga doble clic nuevamente para abrir `pipeline.py`**. Busque y descomente las 3 líneas que agregan `StatisticsGen`, `SchemaGen` y `ExampleValidator` a la canalización. (Consejo: busque comentarios que contengan `TODO(step 5):` :). Asegúrese de guardar `pipeline.py` después de editarlo.\n",
        "\n",
        "Ahora debe actualizar la canalización existente con la definición de canalización modificada. Utilice el comando `tfx pipeline update` para actualizar su canalización, seguido del comando `tfx run create` para crear una nueva ejecución de su canalización actualizada.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VE-Pqvto0olm"
      },
      "outputs": [],
      "source": [
        "# Update the pipeline\n",
        "!tfx pipeline update \\\n",
        "--pipeline-path=kubeflow_runner.py \\\n",
        "--endpoint={ENDPOINT}\n",
        "# You can run the pipeline the same way.\n",
        "!tfx run create --pipeline-name {PIPELINE_NAME} --endpoint={ENDPOINT}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8q1ZYEHX0olo"
      },
      "source": [
        "### Verifique las salidas de la canalización\n",
        "\n",
        "Visite el panel de KFP para buscar salidas de canalización en la página para la ejecución de su canalización. Haga clic en la pestaña \"Experimentos\" a la izquierda y en \"Todas las ejecuciones\" en la página Experimentos. Debería poder encontrar la ejecución con el nombre de su canalización."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWMBXU510olp"
      },
      "source": [
        "## Paso 6. Agregue componentes para el entrenamiento\n",
        "\n",
        "En este paso, agregará componentes para el entrenamiento y la validación del modelo, incluidos `Transform`, `Trainer`, `Resolver`, `Evaluator` y `Pusher`.\n",
        "\n",
        "> **Haga doble clic para abrir `pipeline.py`**. Busque y descomente las 5 líneas que agregan `Transform`, `Trainer`, `Resolver`, `Evaluator` y `Pusher` a la canalización. (Consejo: busque `TODO(step 6):`\n",
        "\n",
        "Como hizo antes, ahora necesita actualizar la canalización existente con la definición de canalización modificada. Las instrucciones son las mismas que las del Paso 5. Actualice la canalización con ayuda de `tfx pipeline update` y use `tfx run create` para crear una ejecución.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VQDNitkH0olq"
      },
      "outputs": [],
      "source": [
        "!tfx pipeline update \\\n",
        "--pipeline-path=kubeflow_runner.py \\\n",
        "--endpoint={ENDPOINT}\n",
        "!tfx run create --pipeline-name {PIPELINE_NAME} --endpoint={ENDPOINT}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksWfVQUnMYCX"
      },
      "source": [
        "Cuando esta ejecución finalice correctamente, habrá creado y ejecutado su primera canalización de TFX en AI Platform Pipelines.\n",
        "\n",
        "**NOTA:** Si cambiamos algo en el código del modelo, también tenemos que volver a compilar la imagen del contenedor. Podemos activar la reconstrucción usando la marca `--build-image` en el comando `pipeline update`.\n",
        "\n",
        "**NOTA:** Es posible que haya notado que cada vez que creamos una ejecución de canalización, cada componente se ejecuta una y otra vez aunque la entrada y los parámetros no hayan cambiado. Es una pérdida de tiempo y recursos, y puede omitir esas ejecuciones con el almacenamiento en caché de la canalización. Puede habilitar el almacenamiento en caché si especifica `enable_cache=True` para el objeto `Pipeline` en `pipeline.py`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkF7klWi0ols"
      },
      "source": [
        "## Paso 7. (*Opcional*) Pruebe BigQueryExampleGen\n",
        "\n",
        "[BigQuery](https://cloud.google.com/bigquery) es un almacén de datos en la nube sin servidor, altamente escalable y rentable. BigQuery sirve como fuente de ejemplos de entrenamiento en TFX. En este paso, agregaremos `BigQueryExampleGen` a la canalización.\n",
        "\n",
        "> **Haga doble clic para abrir `pipeline.py`**. Comente `CsvExampleGen` y descomente la línea que crea una instancia de `BigQueryExampleGen`. También se debe descomentar el argumento `query` de la función `create_pipeline`.\n",
        "\n",
        "Tenemos que especificar qué proyecto de GCP se usará para BigQuery, y para hacer esto hay que configurar `--project` en `beam_pipeline_args` cuando se crea una canalización.\n",
        "\n",
        "> **Haga doble clic para abrir `configs.py`**. Descomente la definición de `GOOGLE_CLOUD_REGION`, `BIG_QUERY_WITH_DIRECT_RUNNER_BEAM_PIPELINE_ARGS` y `BIG_QUERY_QUERY`. Debe reemplazar el valor de la región en este archivo con los valores correctos para su proyecto de GCP.\n",
        "\n",
        "> **Nota: DEBE configurar su región GCP en el archivo `configs.py` antes de continuar.**\n",
        "\n",
        "> **Cambie el directorio un nivel hacia arriba.** Haga clic en el nombre del directorio encima de la lista de archivos. El nombre del directorio es el nombre de la canalización, que es `my_pipeline` si no lo cambió.\n",
        "\n",
        "> **Haga doble clic para abrir `kubeflow_runner.py`**. Descomente dos argumentos, `query` y `beam_pipeline_args`, para la función `create_pipeline`.\n",
        "\n",
        "Ahora la canalización está lista para usar BigQuery como fuente de ejemplo. Actualice la canalización como antes y cree una nueva ejecución como lo hicimos en los pasos 5 y 6."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1sD3NxB60olt"
      },
      "outputs": [],
      "source": [
        "!tfx pipeline update \\\n",
        "--pipeline-path=kubeflow_runner.py \\\n",
        "--endpoint={ENDPOINT}\n",
        "!tfx run create --pipeline-name {PIPELINE_NAME} --endpoint={ENDPOINT}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LpA2R6Lu0olv"
      },
      "source": [
        "## Paso 8. (*Opcional*) Pruebe Dataflow con KFP\n",
        "\n",
        "Varios [componentes de TFX usan Apache Beam](https://www.tensorflow.org/tfx/guide/beam) para implementar canalizaciones de datos paralelas, lo que significa que puede distribuir cargas de trabajo de procesamiento de datos mediante [Google Cloud Dataflow](https://cloud.google.com/dataflow/). En este paso, configuraremos el orquestador de Kubeflow para que use Dataflow como backend de procesamiento de datos para Apache Beam.\n",
        "\n",
        "> **Haga doble clic en `pipeline` para cambiar de directorio y haga doble clic para abrir `configs.py`**. Descomente la definición de `GOOGLE_CLOUD_REGION` y `DATAFLOW_BEAM_PIPELINE_ARGS`.\n",
        "\n",
        "> **Cambie el directorio un nivel hacia arriba.** Haga clic en el nombre del directorio encima de la lista de archivos. El nombre del directorio es el nombre de la canalización, que es `my_pipeline` si no lo cambió.\n",
        "\n",
        "> **Haga doble clic para abrir `kubeflow_runner.py`**. Descomente `beam_pipeline_args`. (También asegúrese de comentar `beam_pipeline_args` actuales que agregó en el Paso 7).\n",
        "\n",
        "Ahora la canalización está lista para usar Dataflow. Actualice la canalización y cree una ejecución como lo hicimos en los pasos 5 y 6."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H3HVPcKi0olw"
      },
      "outputs": [],
      "source": [
        "!tfx pipeline update \\\n",
        "--pipeline-path=kubeflow_runner.py \\\n",
        "--endpoint={ENDPOINT}\n",
        "!tfx run create --pipeline-name {PIPELINE_NAME} --endpoint={ENDPOINT}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uxDY13N0oly"
      },
      "source": [
        "Puede encontrar sus trabajos de Dataflow en [Dataflow en la consola de Cloud](http://console.cloud.google.com/dataflow).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJOmh1RY0olz"
      },
      "source": [
        "## Paso 9. (*Opcional*) Pruebe entrenamiento y predicción de Cloud AI Platform con KFP\n",
        "\n",
        "TFX interopera con varios servicios administrados de GCP, como [Cloud AI Platform Training y Prediction](https://cloud.google.com/ai-platform/). Puede configurar su componente `Trainer` para que use Cloud AI Platform Training, un servicio administrado para entrenar modelos de ML. Además, cuando su modelo esté compilado y listo para ser servido, puede *insertarlo* en Cloud AI Platform Prediction para su servicio. En este paso, configuraremos nuestro componente `Trainer` y `Pusher` para utilizar los servicios de Cloud AI Platform.\n",
        "\n",
        "> Antes de editar archivos, es posible que primero tenga que habilitar la *API de Training y Prediction de AI Platform*.\n",
        "\n",
        "> **Haga doble clic en `pipeline` para cambiar de directorio y haga doble clic para abrir `configs.py`**. Descomente la definición de `GOOGLE_CLOUD_REGION`, `GCP_AI_PLATFORM_TRAINING_ARGS` y `GCP_AI_PLATFORM_SERVING_ARGS`. Usaremos nuestra imagen de contenedor personalizada para entrenar un modelo en Cloud AI Platform Training, por lo que debemos configurar `masterConfig.imageUri` en `GCP_AI_PLATFORM_TRAINING_ARGS` con el mismo valor que `CUSTOM_TFX_IMAGE` arriba.\n",
        "\n",
        "> **Cambie el directorio un nivel hacia arriba y haga doble clic para abrir `kubeflow_runner.py`**. Descomente `ai_platform_training_args` y `ai_platform_serving_args`.\n",
        "\n",
        "Actualice la canalización y cree una ejecución como lo hicimos en los pasos 5 y 6."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yxOjhBmG0ol0"
      },
      "outputs": [],
      "source": [
        "!tfx pipeline update \\\n",
        "--pipeline-path=kubeflow_runner.py \\\n",
        "--endpoint={ENDPOINT}\n",
        "!tfx run create --pipeline-name {PIPELINE_NAME} --endpoint={ENDPOINT}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkoIMUfj0ol2"
      },
      "source": [
        "Puede encontrar sus trabajos de entrenamiento en [Cloud AI Platform Jobs](https://console.cloud.google.com/ai-platform/jobs). Si su canalización se completó correctamente, puede encontrar su modelo en [Cloud AI Platform Models](https://console.cloud.google.com/ai-platform/models)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DRTFdTy0ol3"
      },
      "source": [
        "## Paso 10. Ingiera SUS datos en la canalización\n",
        "\n",
        "Creamos una canalización para un modelo utilizando el conjunto de datos Chicago Taxi. Ahora es el momento de poner sus datos en proceso.\n",
        "\n",
        "Sus datos se pueden almacenar en cualquier lugar al que pueda acceder su canalización, incluido GCS o BigQuery. Deberá modificar la definición de la canalización para acceder a sus datos.\n",
        "\n",
        "1. Si sus datos están almacenados en archivos, modifique `DATA_PATH` en `kubeflow_runner.py` o `local_runner.py` y configúrelo en la ubicación de sus archivos. Si sus datos están almacenados en BigQuery, modifique `BIG_QUERY_QUERY` en `pipeline/configs.py` para consultar correctamente sus datos.\n",
        "2. Agregue características en `models` / <code>features.py</code>.\n",
        "3. Modifique `models` / <code>preprocessing.py</code> para <a>transformar los datos de entrada para el entrenamiento</a>.\n",
        "4. Modifique `models` / `keras` / <code>model.py</code> y <code>models</code> / <code>keras</code> / <code>constants.py</code> para <a>describir su modelo de ML</a>.\n",
        "    - También puede utilizar un modelo basado en un estimador. Cambie la constante `RUN_FN` a `models.estimator.model.run_fn` en `pipeline/configs.py`.\n",
        "\n",
        "Consulte la [guía del componente Trainer](https://www.tensorflow.org/tfx/guide/trainer) para obtener más información."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20KRGsPX0ol3"
      },
      "source": [
        "## Limpieza\n",
        "\n",
        "Para limpiar todos los recursos de Google Cloud utilizados en este proyecto, puede [eliminar el proyecto de Google Cloud](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects) que se usó para el tutorial.\n",
        "\n",
        "Alternativamente, puede limpiar recursos individuales si visita cada consola:\n",
        "\n",
        "- [Google Cloud Storage](https://console.cloud.google.com/storage)\n",
        "- [Google Container Registry](https://console.cloud.google.com/gcr)\n",
        "- [Google Kubernetes Engine](https://console.cloud.google.com/kubernetes)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "template.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
