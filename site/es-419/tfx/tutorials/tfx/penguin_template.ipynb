{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjUA6S30k52h"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "SpNWyqewk8fE"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TyrY7lV0oke"
      },
      "source": [
        "# Cómo crear una canalización de TFX para sus datos con la plantilla Penguin\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQmvgl9nsqPW"
      },
      "source": [
        "Nota: Recomendamos ejecutar este tutorial en [Vertex AI Workbench](https://cloud.google.com/vertex-ai-workbench) de Google Cloud. [Vaya a Vertex AI Workbench](https://console.cloud.google.com/vertex-ai/workbench).\n",
        "\n",
        "<div class=\"devsite-table-wrapper\"><table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "<td><a target=\"_blank\" href=\"https://www.tensorflow.org/tfx/tutorials/tfx/penguin_template\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver en TensorFlow.org</a></td>\n",
        "<td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/es-419/tfx/tutorials/tfx/penguin_template.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Ejecutar en Google Colab</a></td>\n",
        "<td><a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/es-419/tfx/tutorials/tfx/penguin_template.ipynb\"><img width=\"32px\" src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver código fuente en GitHub</a></td>\n",
        "<td><a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/es-419/tfx/tutorials/tfx/penguin_template.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Descargar el bloc de notas</a></td>\n",
        "</table></div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLYriYe10okf"
      },
      "source": [
        "## Introducción\n",
        "\n",
        "Este documento nos ofrece instrucciones para crear una canalización de TensorFlow Extended (TFX) para su propio conjunto de datos con ayuda de la *plantilla Penguin* que se proporciona con el paquete de Python para TFX. La canalización creada usará inicialmente el conjunto de datos de [Palmer Penguins](https://allisonhorst.github.io/palmerpenguins/articles/intro.html), pero transformaremos la canalización para su conjunto de datos.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0HDv9FAbUy9"
      },
      "source": [
        "### Requisitos previos\n",
        "\n",
        "- Linux / MacOS\n",
        "- Python 3.6-3.8\n",
        "- Bloc de notas Jupyter\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaXSIXh9czAX"
      },
      "source": [
        "## Paso 1. Copie la plantilla predefinida en el directorio de su proyecto\n",
        "\n",
        "En este paso, crearemos un directorio y archivos de proyecto de canalización de trabajo copiando archivos de la *plantilla Penguin* en TFX. Puede considerar esto como un andamio para su proyecto de canalización de TFX."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WoUaCyNF_YlF"
      },
      "source": [
        "### Actualización de pip\n",
        "\n",
        "Si estamos ejecutando Colab, debemos asegurarnos de tener la última versión de Pip. Por supuesto, los sistemas locales se pueden actualizar por separado.\n",
        "\n",
        "Nota: La actualización probablemente también sea una buena idea si está ejecutando Vertex AI Workbench."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iQIUEpFp_ZA2"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "if 'google.colab' in sys.modules:\n",
        "  !pip install --upgrade pip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmVR97AgacoP"
      },
      "source": [
        "### Instalación del paquete requerido\n",
        "\n",
        "Primero, instale TFX y TensorFlow Model Analysis (TFMA).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XNiqq_kN0okj"
      },
      "outputs": [],
      "source": [
        "!pip install -U tfx tensorflow-model-analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hX1rqpbQ0okp"
      },
      "source": [
        "Revisemos las versiones de TFX."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XAIoKMNG0okq"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_model_analysis as tfma\n",
        "import tfx\n",
        "\n",
        "print('TF version: {}'.format(tf.__version__))\n",
        "print('TFMA version: {}'.format(tfma.__version__))\n",
        "print('TFX version: {}'.format(tfx.__version__))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOsQbkky0ok7"
      },
      "source": [
        "Estamos listos para crear una canalización.\n",
        "\n",
        "Establezca `PROJECT_DIR` en el destino apropiado para su entorno. El valor predeterminado es `~/imported/${PIPELINE_NAME}`, que es apropiado para el entorno de [bloc de notas de Google Cloud AI Platform](https://console.cloud.google.com/ai-platform/notebooks/).\n",
        "\n",
        "Puede cambiar el nombre de su canalización si cambia el valor de `PIPELINE_NAME` a continuación. Este también se convertirá en el nombre del directorio del proyecto donde se colocarán sus archivos.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cIPlt-700ok-"
      },
      "outputs": [],
      "source": [
        "PIPELINE_NAME=\"my_pipeline\"\n",
        "import os\n",
        "# Set this project directory to your new tfx pipeline project.\n",
        "PROJECT_DIR=os.path.join(os.path.expanduser(\"~\"), \"imported\", PIPELINE_NAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozHIomcd0olB"
      },
      "source": [
        "### Copia de archivos de plantilla\n",
        "\n",
        "TFX incluye la plantilla `penguin` con el paquete de Python para TFX. La plantilla `penguin` contiene muchas instrucciones para incorporar su conjunto de datos al proceso, que es el propósito de este tutorial.\n",
        "\n",
        "El comando de CLI `tfx template copy` copia archivos de plantilla predefinidos al directorio de su proyecto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VLXpTTjU0olD"
      },
      "outputs": [],
      "source": [
        "# Set `PATH` to include user python binary directory and a directory containing `skaffold`.\n",
        "PATH=%env PATH\n",
        "%env PATH={PATH}:/home/jupyter/.local/bin\n",
        "\n",
        "!tfx template copy \\\n",
        "  --pipeline-name={PIPELINE_NAME} \\\n",
        "  --destination-path={PROJECT_DIR} \\\n",
        "  --model=penguin"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxOT19QS0olH"
      },
      "source": [
        "Cambie el contexto del directorio de trabajo en este bloc de notas al directorio del proyecto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6P-HljcU0olI"
      },
      "outputs": [],
      "source": [
        "%cd {PROJECT_DIR}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1tEYUQxH0olO"
      },
      "source": [
        "> NOTA: Si está utilizando un bloc de notas de JupyterLab o Google Cloud AI Platform, no olvide cambiar el directorio en `File Browser` a la izquierda haciendo clic en el directorio del proyecto una vez que lo haya creado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzT2PFrN0olQ"
      },
      "source": [
        "### Exploración de archivos fuente copiados\n",
        "\n",
        "La plantilla TFX proporciona archivos de estructura básicos para compilar una canalización, incluido el código fuente de Python y datos de muestra. La plantilla `penguin` usa el mismo conjunto de datos *Palmer Penguins* y modelo de ML que el [ejemplo de Penguin](https://github.com/tensorflow/tfx/tree/master/tfx/examples/penguin).\n",
        "\n",
        "Esta es una breve introducción a cada uno de los archivos de Python.\n",
        "\n",
        "- `pipeline`: este directorio contiene la definición de la canalización.\n",
        "    - `configs.py`: define constantes comunes para los ejecutores de la canalización\n",
        "    - `pipeline.py`: define los componentes de TFX y una canalización\n",
        "- `models`: este directorio contiene definiciones de modelos de ML\n",
        "    - `features.py`, `features_test.py`: define características para el modelo\n",
        "    - `preprocessing.py`, `preprocessing_test.py`: define rutinas de preprocesamiento de datos\n",
        "    - `constants.py`: define las constantes del modelo\n",
        "    - `model.py`, `model_test.py`: define el modelo de ML a partir de marcos de ML como TensorFlow\n",
        "- `local_runner.py`: define un ejecutor para el entorno local que emplea el motor de orquestación local\n",
        "- `kubeflow_runner.py`: define un ejecutor para el motor de orquestación de Kubeflow Pipelines\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "saF1CpVefaf1"
      },
      "source": [
        "De forma predeterminada, la plantilla solo incluye componentes de TFX estándar. Si necesita algunas acciones personalizadas, puede crear componentes personalizados para su canalización. Consulte la [guía de componentes personalizados de TFX](https://www.tensorflow.org/tfx/guide/understanding_custom_components) para obtener más detalles."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROwHAsDK0olT"
      },
      "source": [
        "#### Archivos de prueba unitaria\n",
        "\n",
        "Quizás note que hay algunos archivos con `_test.py` en su nombre. Estas son pruebas unitarias de la canalización y se recomienda agregar más pruebas unitarias a medida que implemente sus propias canalizaciones. Puede ejecutar pruebas unitarias si proporciona el nombre del módulo de los archivos de prueba con la marca `-m`. Generalmente puede obtener el nombre de un módulo al eliminar la extensión `.py` y reemplazarla por `/` con `.`. Por ejemplo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M0cMdE2Z0olU"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "!{sys.executable} -m models.features_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tO9Jhplo0olX"
      },
      "source": [
        "### Creación de una canalización de TFX en el entorno local\n",
        "\n",
        "TFX admite varios motores de orquestación para ejecutar canalizaciones. Usaremos un motor de orquestación local. El motor de orquestación local se ejecuta sin más dependencias y es adecuado para el desarrollo y la depuración porque se ejecuta en un entorno local en lugar de depender de clústeres informáticos remotos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZO6yR8lOo5GZ"
      },
      "source": [
        "Usaremos `local_runner.py` para ejecutar su canalización usando el orquestador local. Tiene que crear una canalización antes de ejecutarla. Puede crear una canalización con el comando `pipeline create`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_9unbcHlo7Yi"
      },
      "outputs": [],
      "source": [
        "!tfx pipeline create --engine=local --pipeline_path=local_runner.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrRL6R06o99S"
      },
      "source": [
        "El comando `pipeline create` registra la canalización definida en `local_runner.py` sin ejecutarla realmente.\n",
        "\n",
        "Ejecutará la canalización creada con el comando `run create` en los siguientes pasos.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7p73589GbTFi"
      },
      "source": [
        "## Paso 2. Ingiera SUS datos a la canalización\n",
        "\n",
        "La canalización inicial ingiere el conjunto de datos Penguin que se incluye en la plantilla. Debe colocar sus datos en la canalización, y la mayoría de las canalizaciones de TFX comienzan con el componente ExampleGen."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEVwa28qtjwi"
      },
      "source": [
        "### Elección de un tipo de ExampleGen\n",
        "\n",
        "Sus datos se pueden almacenar en cualquier lugar al que pueda acceder su canalización, ya sea en un sistema de archivos local o distribuido, o en un sistema con capacidad de consulta. TFX ofrece varios [componentes `ExampleGen`](https://www.tensorflow.org/tfx/guide/examplegen) para llevar sus datos a una canalización de TFX. Puede elegir uno de los siguientes componentes de generación de ejemplo.\n",
        "\n",
        "- CsvExampleGen: lee archivos en formato CSV en un directorio. Se usa en el [ejemplo de pingüinos](https://github.com/tensorflow/tfx/tree/master/tfx/examples/penguin) y en el [ejemplo de taxis de Chicago](https://github.com/tensorflow/tfx/tree/master/tfx/examples/chicago_taxi_pipeline).\n",
        "- ImportExampleGen: toma archivos TFRecord con formato de datos TF Example. Se usa en [ejemplos MNIST](https://github.com/tensorflow/tfx/tree/master/tfx/examples/mnist).\n",
        "- FileBasedExampleGen para formato [Avro](https://github.com/tensorflow/tfx/blob/master/tfx/components/example_gen/custom_executors/avro_executor.py) o [Parquet](https://github.com/tensorflow/tfx/blob/master/tfx/components/example_gen/custom_executors/parquet_executor.py).\n",
        "- [BigQueryExampleGen](https://www.tensorflow.org/tfx/api_docs/python/tfx/extensions/google_cloud_big_query/example_gen/component/BigQueryExampleGen): lee datos directamente en Google Cloud BigQuery. Se usa en [ejemplos de taxis de Chicago](https://github.com/tensorflow/tfx/tree/master/tfx/examples/chicago_taxi_pipeline).\n",
        "\n",
        "También puede crear su propio ExampleGen, por ejemplo, tfx incluye [un ExecampleGen personalizado que utiliza Presto](https://github.com/tensorflow/tfx/tree/master/tfx/examples/custom_components/presto_example_gen) como fuente de datos. Consulte la [guía](https://www.tensorflow.org/tfx/guide/examplegen#custom_examplegen) para obtener más información sobre cómo usar y desarrollar ejecutores personalizados.\n",
        "\n",
        "Una vez que decida qué tipo de ExampleGen usar, deberá modificar la definición de canalización para usar sus datos.\n",
        "\n",
        "1. Modifique `DATA_PATH` en `local_runner.py` y configúrelo en la ubicación de sus archivos.\n",
        "\n",
        "- Si tiene archivos en el entorno local, especifique la ruta. Esta es la mejor opción para desarrollar o depurar una canalización.\n",
        "- Si los archivos están almacenados en GCS, puede usar una ruta que comience con `gs://{bucket_name}/...` Asegúrese de poder acceder a GCS desde su terminal, por ejemplo, usando [`gsutil`](https://cloud.google.com/storage/docs/gsutil). Siga la [guía de autorización en Google Cloud](https://cloud.google.com/sdk/docs/authorizing) si es necesario.\n",
        "- Si quiere usar un ExampleGen basado en consultas como BigQueryExampleGen, necesita una instrucción de consulta para seleccionar datos de la fuente de datos. Hay algunas cosas más que se deben configurar para usar Google Cloud BigQuery como fuente de datos.\n",
        "    - En `pipeline/configs.py`:\n",
        "        - Cambie `GOOGLE_CLOUD_PROJECT` y `GCS_BUCKET_NAME` por su proyecto de GCP y el nombre del depósito. El depósito debería existir antes de ejecutar la canalización.\n",
        "        - Descomente la variable `BIG_QUERY_WITH_DIRECT_RUNNER_BEAM_PIPELINE_ARGS`.\n",
        "        - Descomente y configure la variable `BIG_QUERY_QUERY` en **su declaración de consulta**.\n",
        "    - En `local_runner.py`:\n",
        "        - Comente el argumento `data_path` y descomente el argumento `query` en `pipeline.create_pipeline()`.\n",
        "    - En `pipeline/pipeline.py`:\n",
        "        - Comente el argumento `data_path` y descomente el argumento `query` en `create_pipeline()`.\n",
        "        - Use [BigQueryExampleGen](https://www.tensorflow.org/tfx/api_docs/python/tfx/extensions/google_cloud_big_query/example_gen/component/BigQueryExampleGen) en lugar de CsvExampleGen.\n",
        "\n",
        "1. Reemplace el CsvExampleGen existente por su clase ExampleGen en `pipeline/pipeline.py`. Cada clase de ExampleGen tiene una firma diferente. Consulte la [guía de componentes de ExampleGen](https://www.tensorflow.org/tfx/guide/examplegen) para obtener más detalles. No olvide importar los módulos necesarios con declaraciones `import` en `pipeline/pipeline.py`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xiAG6acjbl5U"
      },
      "source": [
        "La canalización inicial consta de cuatro componentes: `ExampleGen`, `StatisticsGen`, `SchemaGen` y `ExampleValidator`. No necesitamos cambiar nada para `StatisticsGen`, `SchemaGen` y `ExampleValidator`. Ejecutemos la canalización por primera vez."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tKOI48WumF7h"
      },
      "outputs": [],
      "source": [
        "# Update and run the pipeline.\n",
        "!tfx pipeline update --engine=local --pipeline_path=local_runner.py \\\n",
        " && tfx run create --engine=local --pipeline_name={PIPELINE_NAME}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFbYFNVbbzna"
      },
      "source": [
        "Debería ver el mensaje \"Component ExampleValidator is finished.\" si la canalización se ejecutó correctamente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uuD5FRPAcOn8"
      },
      "source": [
        "### Análisis de la salida de la canalización"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tL1wWoDh5wkj"
      },
      "source": [
        "La canalización de TFX produce dos tipos de resultados, artefactos y una [base de datos de metadatos (MLMD)](https://www.tensorflow.org/tfx/guide/mlmd) que contiene metadatos de artefactos y ejecuciones de canalizaciones. La ubicación de la salida se define en `local_runner.py`. De forma predeterminada, los artefactos se almacenan en el directorio `tfx_pipeline_output` y los metadatos se almacenan como una base de datos sqlite en el directorio `tfx_metadata`.\n",
        "\n",
        "Puede utilizar las API de MLMD para examinar estos resultados. Primero, definiremos algunas funciones de utilidad para buscar artefactos de salida que se acaban de producir."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K0i_jTvOI8mv"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tfx\n",
        "from ml_metadata import errors\n",
        "from ml_metadata.proto import metadata_store_pb2\n",
        "from tfx.types import artifact_utils\n",
        "\n",
        "# TODO(b/171447278): Move these functions into TFX library.\n",
        "\n",
        "def get_latest_executions(store, pipeline_name, component_id = None):\n",
        "  \"\"\"Fetch all pipeline runs.\"\"\"\n",
        "  if component_id is None:  # Find entire pipeline runs.\n",
        "    run_contexts = [\n",
        "        c for c in store.get_contexts_by_type('run')\n",
        "        if c.properties['pipeline_name'].string_value == pipeline_name\n",
        "    ]\n",
        "  else:  # Find specific component runs.\n",
        "    run_contexts = [\n",
        "        c for c in store.get_contexts_by_type('component_run')\n",
        "        if c.properties['pipeline_name'].string_value == pipeline_name and\n",
        "           c.properties['component_id'].string_value == component_id\n",
        "    ]\n",
        "  if not run_contexts:\n",
        "    return []\n",
        "  # Pick the latest run context.\n",
        "  latest_context = max(run_contexts,\n",
        "                       key=lambda c: c.last_update_time_since_epoch)\n",
        "  return store.get_executions_by_context(latest_context.id)\n",
        "\n",
        "def get_latest_artifacts(store, pipeline_name, component_id = None):\n",
        "  \"\"\"Fetch all artifacts from latest pipeline execution.\"\"\"\n",
        "  executions = get_latest_executions(store, pipeline_name, component_id)\n",
        "\n",
        "  # Fetch all artifacts produced from the given executions.\n",
        "  execution_ids = [e.id for e in executions]\n",
        "  events = store.get_events_by_execution_ids(execution_ids)\n",
        "  artifact_ids = [\n",
        "      event.artifact_id for event in events\n",
        "      if event.type == metadata_store_pb2.Event.OUTPUT\n",
        "  ]\n",
        "  return store.get_artifacts_by_id(artifact_ids)\n",
        "\n",
        "def find_latest_artifacts_by_type(store, artifacts, artifact_type):\n",
        "  \"\"\"Get the latest artifacts of a specified type.\"\"\"\n",
        "  # Get type information from MLMD\n",
        "  try:\n",
        "    artifact_type = store.get_artifact_type(artifact_type)\n",
        "  except errors.NotFoundError:\n",
        "    return []\n",
        "  # Filter artifacts with type.\n",
        "  filtered_artifacts = [aritfact for aritfact in artifacts\n",
        "                        if aritfact.type_id == artifact_type.id]\n",
        "  # Convert MLMD artifact data into TFX Artifact instances.\n",
        "  return [artifact_utils.deserialize_artifact(artifact_type, artifact)\n",
        "      for artifact in filtered_artifacts]\n",
        "\n",
        "\n",
        "from tfx.orchestration.experimental.interactive import visualizations\n",
        "\n",
        "def visualize_artifacts(artifacts):\n",
        "  \"\"\"Visualizes artifacts using standard visualization modules.\"\"\"\n",
        "  for artifact in artifacts:\n",
        "    visualization = visualizations.get_registry().get_visualization(\n",
        "        artifact.type_name)\n",
        "    if visualization:\n",
        "      visualization.display(artifact)\n",
        "\n",
        "from tfx.orchestration.experimental.interactive import standard_visualizations\n",
        "standard_visualizations.register_standard_visualizations()\n",
        "\n",
        "import pprint\n",
        "\n",
        "from tfx.orchestration import metadata\n",
        "from tfx.types import artifact_utils\n",
        "from tfx.types import standard_artifacts\n",
        "\n",
        "def preview_examples(artifacts):\n",
        "  \"\"\"Preview a few records from Examples artifacts.\"\"\"\n",
        "  pp = pprint.PrettyPrinter()\n",
        "  for artifact in artifacts:\n",
        "    print(\"==== Examples artifact:{}({})\".format(artifact.name, artifact.uri))\n",
        "    for split in artifact_utils.decode_split_names(artifact.split_names):\n",
        "      print(\"==== Reading from split:{}\".format(split))\n",
        "      split_uri = artifact_utils.get_split_uri([artifact], split)\n",
        "\n",
        "      # Get the list of files in this directory (all compressed TFRecord files)\n",
        "      tfrecord_filenames = [os.path.join(split_uri, name)\n",
        "                            for name in os.listdir(split_uri)]\n",
        "      # Create a `TFRecordDataset` to read these files\n",
        "      dataset = tf.data.TFRecordDataset(tfrecord_filenames,\n",
        "                                        compression_type=\"GZIP\")\n",
        "      # Iterate over the first 2 records and decode them.\n",
        "      for tfrecord in dataset.take(2):\n",
        "        serialized_example = tfrecord.numpy()\n",
        "        example = tf.train.Example()\n",
        "        example.ParseFromString(serialized_example)\n",
        "        pp.pprint(example)\n",
        "\n",
        "import local_runner\n",
        "\n",
        "metadata_connection_config = metadata.sqlite_metadata_connection_config(\n",
        "              local_runner.METADATA_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmwor9nVcmxy"
      },
      "source": [
        "Ahora podemos leer metadatos de artefactos de salida de MLMD."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TtsrZEUB1-J4"
      },
      "outputs": [],
      "source": [
        "with metadata.Metadata(metadata_connection_config) as metadata_handler:\n",
        "    # Search all aritfacts from the previous pipeline run.\n",
        "    artifacts = get_latest_artifacts(metadata_handler.store, PIPELINE_NAME)\n",
        "    # Find artifacts of Examples type.\n",
        "    examples_artifacts = find_latest_artifacts_by_type(\n",
        "        metadata_handler.store, artifacts,\n",
        "        standard_artifacts.Examples.TYPE_NAME)\n",
        "    # Find artifacts generated from StatisticsGen.\n",
        "    stats_artifacts = find_latest_artifacts_by_type(\n",
        "        metadata_handler.store, artifacts,\n",
        "        standard_artifacts.ExampleStatistics.TYPE_NAME)\n",
        "    # Find artifacts generated from SchemaGen.\n",
        "    schema_artifacts = find_latest_artifacts_by_type(\n",
        "        metadata_handler.store, artifacts,\n",
        "        standard_artifacts.Schema.TYPE_NAME)\n",
        "    # Find artifacts generated from ExampleValidator.\n",
        "    anomalies_artifacts = find_latest_artifacts_by_type(\n",
        "        metadata_handler.store, artifacts,\n",
        "        standard_artifacts.ExampleAnomalies.TYPE_NAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3U5MNAUIdBtN"
      },
      "source": [
        "Ahora podemos examinar los resultados de cada componente. [La validación de datos de Tensorflow (TFDV)](https://www.tensorflow.org/tfx/data_validation/get_started) se usa en `StatisticsGen`, `SchemaGen` y `ExampleValidator`, y TFDV se puede usar para visualizar los resultados de estos componentes.\n",
        "\n",
        "En este tutorial, usaremos métodos auxiliares de visualización en TFX que usan TFDV internamente para mostrar la visualización. Consulte el [tutorial de componentes de TFX](https://www.tensorflow.org/tfx/tutorials/tfx/components_keras) para obtener más información sobre cada componente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxS6FsgU2IoZ"
      },
      "source": [
        "#### Análisis del formulario de salida ExampleGen\n",
        "\n",
        "Examinemos el resultado de ExampleGen. Echemos un vistazo a los dos primeros ejemplos de cada división:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3NWzXEcE13tW"
      },
      "outputs": [],
      "source": [
        "preview_examples(examples_artifacts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0uiuPhkGEBz"
      },
      "source": [
        "De forma predeterminada, TFX ExampleGen divide los ejemplos en dos divisiones, *train* y *eval*, pero puede [ajustar la configuración de su división](https://www.tensorflow.org/tfx/guide/examplegen#span_version_and_split)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVh13wJu-IRv"
      },
      "source": [
        "#### Análisis del formulario de salida de StatisticsGen\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9LipxUp7-IRw"
      },
      "outputs": [],
      "source": [
        "visualize_artifacts(stats_artifacts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8aebEY4c0Ju7"
      },
      "source": [
        "Estas estadísticas se proporcionan a SchemaGen para construir un esquema de datos automáticamente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExEKbdw8-IRx"
      },
      "source": [
        "#### Análisis del formulario de salida de SchemaGen\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M2IURBSp-IRy"
      },
      "outputs": [],
      "source": [
        "visualize_artifacts(schema_artifacts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTvj8yeBHDdU"
      },
      "source": [
        "Este esquema se infiere automáticamente a partir del resultado de StatisticsGen. Usaremos este esquema generado en este tutorial, pero también puede [modificar y personalizar el esquema](https://www.tensorflow.org/tfx/guide/statsgen#creating_a_curated_schema)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rl1PEUgo-IRz"
      },
      "source": [
        "#### Análisis del formulario de salida de ExampleValidator\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F-4oAjGR-IR0"
      },
      "outputs": [],
      "source": [
        "visualize_artifacts(anomalies_artifacts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t026ZzbU0961"
      },
      "source": [
        "Si se encuentra alguna anomalía, puede revisar los datos para comprobar que todos los ejemplos siguen sus suposiciones. Los resultados de otros componentes como StatisticsGen pueden ser útiles. Las anomalías encontradas no bloquean la ejecución de la canalización."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFMmqy1W-IR1"
      },
      "source": [
        "Puede ver las funciones disponibles en los resultados de `SchemaGen`. Si sus funciones se pueden usar para construir el modelo de ML directamente en `Trainer`, puede omitir el siguiente paso e ir al Paso 4. De lo contrario, puede realizar algún trabajo de ingeniería de funciones en el siguiente paso. El componente `Transform` es necesario cuando se requieren operaciones de paso completo, como calcular promedios, especialmente cuando es necesario escalar."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYH8Y2KB0olm"
      },
      "source": [
        "## Paso 3. (Opcional) Ingeniería de características con el componente Transform\n",
        "\n",
        "En este paso, definirá varios trabajos de ingeniería de funciones que utilizará el componente `Transform` en la canalización. Consulte la [guía de componentes Transform](https://www.tensorflow.org/tfx/guide/transform) para obtener más información.\n",
        "\n",
        "Esto solo es necesario si su código de entrenamiento requiere funciones adicionales que no estén disponibles en la salida de ExampleGen. De lo contrario, siéntase libre de avanzar rápidamente al siguiente paso del uso de Trainer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qm_JjQUydbbb"
      },
      "source": [
        "### Definición de las características del modelo\n",
        "\n",
        "`models/features.py` contiene constantes para definir características para el modelo, incluidos los nombres de las características, el tamaño del vocabulario, etc. De forma predeterminada, la plantilla `penguin` tiene dos costantes, `FEATURE_KEYS` y `LABEL_KEY`, porque nuestro modelo `penguin` resuelve un problema de clasificación mediante aprendizaje supervisado y todas las características son características numéricas continuas. Consulte las [definiciones de funciones del ejemplo de taxis de Chicago](https://github.com/tensorflow/tfx/blob/master/tfx/experimental/templates/taxi/models/features.py) para ver otro ejemplo.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATUeHXvJdcBn"
      },
      "source": [
        "### Implementación del preprocesamiento para entrenamiento/servicio en preprocessing_fn().\n",
        "\n",
        "La ingeniería de características real ocurre en la función `preprocessing_fn()` en `models/preprocessing.py`.\n",
        "\n",
        "En `preprocessing_fn` puede definir una serie de funciones que manipulan el dictado de entrada de los tensores para producir el dictado de salida de los tensores. Hay funciones ayudantes como `scale_to_0_1` y `compute_and_apply_vocabulary` en la API de TensorFlow Transform o simplemente puede usar funciones normales de TensorFlow. De forma predeterminada, la plantilla `penguin` incluye usos de ejemplo de la función [tft.scale_to_z_score](https://www.tensorflow.org/tfx/transform/api_docs/python/tft/scale_to_z_score) para normalizar los valores de las características.\n",
        "\n",
        "Consulte la [guía de Tensorflow Transform](https://www.tensorflow.org/tfx/transform/get_started) para obtener más información sobre la creación de `preprocessing_fn`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUg_Lc43dbTp"
      },
      "source": [
        "### Incorporación del componente Transform a la canalización\n",
        "\n",
        "Si su preprocessing_fn está lista, agregue el componente `Transform` a la canalización.\n",
        "\n",
        "1. En el archivo `pipeline/pipeline.py`, descomente `# components.append(transform)` para agregar el componente a la canalización.\n",
        "\n",
        "Puede actualizar la canalización y ejecutarla nuevamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VE-Pqvto0olm"
      },
      "outputs": [],
      "source": [
        "!tfx pipeline update --engine=local --pipeline_path=local_runner.py \\\n",
        " && tfx run create --engine=local --pipeline_name={PIPELINE_NAME}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8q1ZYEHX0olo"
      },
      "source": [
        "Si la canalización se ejecutó correctamente, debería ver el mensaje \"Component Transform is finished\". en *algún lugar* del registro. Como el componente `Transform` y el componente `ExampleValidator` no dependen entre sí, el orden de ejecución no es fijo. Dicho esto, `Transform` y `ExampleValidator` pueden ser el último componente en la ejecución del proceso."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrPEnZt0E_0m"
      },
      "source": [
        "### Análisis del formulario de salida de Transform\n",
        "\n",
        "El componente Transform crea dos tipos de resultados, un grafo de Tensorflow y ejemplos transformados. Los ejemplos transformados son del tipo de artefacto Ejemplos que también produce ExampleGen, pero este contiene valores de características transformados.\n",
        "\n",
        "Puede examinarlos como lo hicimos en el paso anterior."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FvC5S66ZU5g6"
      },
      "outputs": [],
      "source": [
        "with metadata.Metadata(metadata_connection_config) as metadata_handler:\n",
        "    # Search all aritfacts from the previous run of Transform component.\n",
        "    artifacts = get_latest_artifacts(metadata_handler.store,\n",
        "                                     PIPELINE_NAME, \"Transform\")\n",
        "    # Find artifacts of Examples type.\n",
        "    transformed_examples_artifacts = find_latest_artifacts_by_type(\n",
        "        metadata_handler.store, artifacts,\n",
        "        standard_artifacts.Examples.TYPE_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CAFiEPKuC6Ib"
      },
      "outputs": [],
      "source": [
        "preview_examples(transformed_examples_artifacts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWMBXU510olp"
      },
      "source": [
        "## Paso 4. Entrene su modelo con el componente Trainer\n",
        "\n",
        "Compilaremos un modelo de ML a partir del componente `Trainer`. Consulte la [guía del componente Trainer](https://www.tensorflow.org/tfx/guide/trainer) para obtener más información. Debe proporcionar el código de su modelo al componente Trainer.\n",
        "\n",
        "### Definición del modelo\n",
        "\n",
        "En la plantilla Penguin, `models.model.run_fn` sirve de argumento `run_fn` para el componente `Trainer`. Esto significa que la función `run_fn()` en `models/model.py` se llamará cuando se ejecute el componente `Trainer`. Puede ver el código para construir un modelo DNN simple con la API `keras` en el código proporcionado. Consulte la guía de [TensorFlow 2.x en TFX](https://www.tensorflow.org/tfx/guide/keras) para obtener más información sobre el uso de la API de keras en TFX.\n",
        "\n",
        "En esta `run_fn`, debe compilar un modelo y guardarlo en un directorio señalado por `fn_args.serving_model_dir` que está especificado por el componente. Puede usar otros argumentos en `fn_args` que se pasa a `run_fn`. Consulte los [códigos relacionados](https://github.com/tensorflow/tfx/blob/b01482442891a49a1487c67047e85ab971717b75/tfx/components/trainer/executor.py#L141) para obtener la lista completa de argumentos en `fn_args`.\n",
        "\n",
        "Defina sus funciones en `models/features.py` y utilícelas según sea necesario. Si transformó sus funciones en el Paso 3, debe usar características transformadas como entradas para su modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFiLIaCm-IR4"
      },
      "source": [
        "### Incorporación del componente Trainer a la canalización\n",
        "\n",
        "Si su run_fn está lista, agregue el componente `Trainer` a la canalización.\n",
        "\n",
        "1. En el archivo `pipeline/pipeline.py`, descomente `# components.append(trainer)` para agregar el componente a la canalización.\n",
        "\n",
        "Los argumentos para el componente Trainer pueden depender de si usa o no el componente Transform.\n",
        "\n",
        "- Si **NO** usa el componente `Transform`, no es necesario que cambie los argumentos.\n",
        "\n",
        "- Si usa el componente `Transform`, tendrá que cambiar los argumentos al crear una instancia del componente `Trainer`.\n",
        "\n",
        "    - Cambie el argumento `examples` a `examples=transform.outputs['transformed_examples'],`. Debemos usar ejemplos transformados para el entrenamiento.\n",
        "    - Agregue el argumento `transform_graph` como `transform_graph=transform.outputs['transform_graph'],` Este grafo contiene un grafo de TensorFlow para las operaciones de transformación.\n",
        "    - Después de aplicar los cambios anteriores, el código para la creación del componente Trainer tendrá el siguiente aspecto.\n",
        "\n",
        "    ```python\n",
        "    # If you use a Transform component.\n",
        "    trainer = Trainer(\n",
        "        run_fn=run_fn,\n",
        "        examples=transform.outputs['transformed_examples'],\n",
        "        transform_graph=transform.outputs['transform_graph'],\n",
        "        schema=schema_gen.outputs['schema'],\n",
        "        ...\n",
        "    ```\n",
        "\n",
        "Puede actualizar la canalización y ejecutarla nuevamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VQDNitkH0olq"
      },
      "outputs": [],
      "source": [
        "!tfx pipeline update --engine=local --pipeline_path=local_runner.py \\\n",
        " && tfx run create --engine=local --pipeline_name={PIPELINE_NAME}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksWfVQUnMYCX"
      },
      "source": [
        "Cuando esta ejecución se ejecute correctamente, habrá creado y ejecutado su primera canalización de TFX para su modelo. ¡Felicidades!\n",
        "\n",
        "Su nuevo modelo se ubicará en algún lugar debajo del directorio de salida, pero sería mejor tener un modelo en una ubicación fija o en servicio fuera de la canalización de TFX que contenga muchos resultados provisionales. Aún mejor con la evaluación continua del modelo construido, que es fundamental en los sistemas de producción de ML. Veremos cómo funcionan la evaluación continua y las implementaciones en TFX en el siguiente paso."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DRTFdTy0ol3"
      },
      "source": [
        "## Paso 5. (Opcional) Evalúe el modelo con Evaluator y publíquelo con Pusher\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DID2nzH-IR7"
      },
      "source": [
        "El componente [`Evaluator`](https://www.tensorflow.org/tfx/guide/evaluator) evalúa continuamente cada modelo creado desde `Trainer` y [`Pusher`](https://www.tensorflow.org/tfx/guide/pusher) copia el modelo en una ubicación predefinida en el sistema de archivos o incluso en [modelos de Google Cloud AI Platform](https://console.cloud.google.com/ai-platform/models).\n",
        "\n",
        "### Incorporación del componente Evaluator a la canalización\n",
        "\n",
        "En el archivo `pipeline/pipeline.py`:\n",
        "\n",
        "1. Descomente `# components.append(model_resolver)` para agregar el solucionador de modelos más reciente a la canalización. Evaluator sirve para comparar un modelo con el modelo de referencia anterior que pasó Evaluator en la última ejecución del proceso. `LatestBlessedModelResolver` encuentra el último modelo que pasó Evaluator.\n",
        "2. Configure `tfma.MetricsSpec` adecuadas para su modelo. La evaluación puede ser diferente para cada modelo de ML. En la plantilla Penguin, se usó `SparseCategoricalAccuracy` porque estamos resolviendo un problema de clasificación de múltiples categorías. También debe especificar `tfma.SliceSpec` para analizar su modelo en busca de segmentos específicos. Para obtener más detalles, consulte la [guía del componente Evaluator](https://www.tensorflow.org/tfx/guide/evaluator).\n",
        "3. Descomente `# components.append(evaluator)` para agregar el componente a la canalización.\n",
        "\n",
        "Puede actualizar la canalización y ejecutarla nuevamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i5_ojoZZmaDQ"
      },
      "outputs": [],
      "source": [
        "# Update and run the pipeline.\n",
        "!tfx pipeline update --engine=local --pipeline_path=local_runner.py \\\n",
        " && tfx run create --engine=local --pipeline_name={PIPELINE_NAME}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apZX74qJ-IR7"
      },
      "source": [
        "### Análisis de la salida de Evaluator\n",
        "\n",
        "Este paso requiere la extensión del bloc de notas Jupyter de TensorFlow Model Analysis (TFMA). Tenga en cuenta que la versión de la extensión del bloc de notas de TFMA debe ser idéntica a la versión del paquete de Python para TFMA.\n",
        "\n",
        "El siguiente comando instalará la extensión del bloc de notas de TFMA desde el registro NPM. Es posible que tarde varios minutos en completarse."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VoL46D5Pw5FX"
      },
      "outputs": [],
      "source": [
        "# Install TFMA notebook extension.\n",
        "!jupyter labextension install tensorflow_model_analysis@{tfma.__version__}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKMo4j8ww5PB"
      },
      "source": [
        "Si se completa la instalación, **vuelva a cargar su navegador** para que se aplique la extensión."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ztotdqS-IR8"
      },
      "outputs": [],
      "source": [
        "with metadata.Metadata(metadata_connection_config) as metadata_handler:\n",
        "  # Search all aritfacts from the previous pipeline run.\n",
        "  artifacts = get_latest_artifacts(metadata_handler.store, PIPELINE_NAME)\n",
        "  model_evaluation_artifacts = find_latest_artifacts_by_type(\n",
        "      metadata_handler.store, artifacts,\n",
        "      standard_artifacts.ModelEvaluation.TYPE_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tVojwMCuDJuk"
      },
      "outputs": [],
      "source": [
        "if model_evaluation_artifacts:\n",
        "  tfma_result = tfma.load_eval_result(model_evaluation_artifacts[0].uri)\n",
        "  tfma.view.render_slicing_metrics(tfma_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18tqjyHN-IR9"
      },
      "source": [
        "### Incorporación del componente Pusher a la canalización\n",
        "\n",
        "Si el modelo se ve prometedor, debemos publicarlo. El [componente Pusher](https://www.tensorflow.org/tfx/guide/pusher) puede publicar el modelo en una ubicación del sistema de archivos o en modelos GCP AI Platform mediante [un ejecutor personalizado](https://github.com/tensorflow/tfx/blob/master/tfx/extensions/google_cloud_ai_platform/pusher/executor.py).\n",
        "\n",
        "El componente <a><code data-md-type=\"codespan\">Evaluator</code></a> evalúa continuamente cada modelo creado desde <code>Trainer</code> y <a><code>Pusher</code></a> copia el modelo en una ubicación predefinida en el sistema de archivos o incluso en <a>modelos de Google Cloud AI Platform</a>.\n",
        "\n",
        "1. En `local_runner.py`, configure `SERVING_MODEL_DIR` en un directorio para publicar.\n",
        "2. En el archivo `pipeline/pipeline.py`, descomente `# components.append(pusher)` para agregar Pusher a la canalización.\n",
        "\n",
        "Puede actualizar la canalización y ejecutarla nuevamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QH81d9FsrSXS"
      },
      "outputs": [],
      "source": [
        "# Update and run the pipeline.\n",
        "!tfx pipeline update --engine=local --pipeline_path=local_runner.py \\\n",
        " && tfx run create --engine=local --pipeline_name={PIPELINE_NAME}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_K6Z18tC-IR-"
      },
      "source": [
        "Debería poder encontrar su nuevo modelo en `SERVING_MODEL_DIR`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20KRGsPX0ol3"
      },
      "source": [
        "## Paso 6. (Opcional) Implemente su canalización en Kubeflow Pipelines en GCP\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0X6vfy7s-IR-"
      },
      "source": [
        "Como se mencionó anteriormente, `local_runner.py` es bueno para fines de depuración o desarrollo, pero no es la mejor solución para cargas de trabajo de producción. En este paso, implementaremos la canalización en Kubeflow Pipelines en Google Cloud.\n",
        "\n",
        "### Preparación\n",
        "\n",
        "Necesitamos el paquete de Python para `kfp` y el programa `skaffold` para implementar una canalización en un clúster de Kubeflow Pipelines."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ge1bMUtU-IR_"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade -q kfp\n",
        "\n",
        "# Download skaffold and set it executable.\n",
        "!curl -Lo skaffold https://storage.googleapis.com/skaffold/releases/latest/skaffold-linux-amd64 && chmod +x skaffold"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZsbnGq52-ISB"
      },
      "source": [
        "Debe mover el binario `skaffold` al lugar donde su shell pueda encontrarlo. O puede especificar la ruta a skaffold cuando ejecute el binario `tfx` con la marca `--skaffold-cmd`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4amQ0Elz-ISC"
      },
      "outputs": [],
      "source": [
        "# Move skaffold binary into your path\n",
        "!mv skaffold /home/jupyter/.local/bin/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rmyns-o-ISD"
      },
      "source": [
        "También necesita un clúster de Kubeflow Pipelines para ejecutar la canalización. Siga los pasos 1 y 2 del [tutorial de TFX en Cloud AI Platform Pipelines](https://www.tensorflow.org/tfx/tutorials/tfx/cloud-ai-platform-pipelines).\n",
        "\n",
        "Cuando su clúster esté listo, abra el panel de canalizaciones al hacer clic en *Abrir panel de canalizaciones* en la [página `Pipelines` de la consola en la nube de Google](http://console.cloud.google.com/ai-platform/pipelines). La URL de esta página es `ENDPOINT` para solicitar una ejecución de canalización. El valor del punto de conexión es todo lo que está en la URL después de https://, hasta googleusercontent.com inclusive. Coloque su punto de conexión en el siguiente bloque de código.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hGyj-Qa3-ISD"
      },
      "outputs": [],
      "source": [
        "ENDPOINT='' # Enter your ENDPOINT here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igTo05YI-ISF"
      },
      "source": [
        "Para ejecutar nuestro código en un clúster de Kubeflow Pipelines, necesitamos empaquetar nuestro código en una imagen de contenedor. La imagen se creará automáticamente durante la implementación de nuestra canalización y solo necesitará establecer un nombre y un registro de contenedor para su imagen. En nuestro ejemplo, usaremos el [registro de Google Container](https://cloud.google.com/container-registry) y lo llamaremos `tfx-pipeline`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5J3LrI0K-ISF"
      },
      "outputs": [],
      "source": [
        "# Read GCP project id from env.\n",
        "shell_output=!gcloud config list --format 'value(core.project)' 2>/dev/null\n",
        "GOOGLE_CLOUD_PROJECT=shell_output[0]\n",
        "\n",
        "# Docker image name for the pipeline image.\n",
        "CUSTOM_TFX_IMAGE='gcr.io/' + GOOGLE_CLOUD_PROJECT + '/tfx-pipeline'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gg11pLmU-ISH"
      },
      "source": [
        "### Configuración de la ubicación de los datos\n",
        "\n",
        "Se debe poder acceder a sus datos desde el clúster de Kubeflow Pipelines. Si ha usado datos en su entorno local, es posible que deba cargarlos en un almacenamiento remoto como Google Cloud Storage. Por ejemplo, podemos cargar datos de Penguin en un depósito predeterminado que se crea automáticamente cuando se implementa un clúster de Kubeflow Pipelines como se muestra a continuación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y8MmRIHi-ISH"
      },
      "outputs": [],
      "source": [
        "!gsutil cp data/data.csv gs://{GOOGLE_CLOUD_PROJECT}-kubeflowpipelines-default/tfx-template/data/penguin/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASc1tDMm-ISJ"
      },
      "source": [
        "Actualice la ubicación de los datos almacenados en `DATA_PATH` en `kubeflow_runner.py`.\n",
        "\n",
        "Si usa BigQueryExampleGen, no es necesario cargar el archivo de datos, pero asegúrese de que `kubeflow_runner.py` use la misma `query` y el mismo argumento `beam_pipeline_args` para la función `pipeline.create_pipeline()`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q42gn3XS-ISK"
      },
      "source": [
        "### Implementación de la canalización\n",
        "\n",
        "Si todo está listo, puede crear una canalización a partir del comando `tfx pipeline create`.\n",
        "\n",
        "> Nota: Al crear una canalización para Kubeflow Pipelines, necesitamos una imagen de contenedor que se utilizará para ejecutar nuestra canalización. Y `skaffold` compilará la imagen para nosotros. Debido a que `skaffold` extrae imágenes base del Docker Hub, demorará entre 5 y 10 minutos cuando compilemos la imagen por primera vez, pero tomará mucho menos tiempo desde la segunda compilación.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ytZ0liBn-ISK"
      },
      "outputs": [],
      "source": [
        "!tfx pipeline create  \\\n",
        "--engine=kubeflow \\\n",
        "--pipeline-path=kubeflow_runner.py \\\n",
        "--endpoint={ENDPOINT} \\\n",
        "--build-target-image={CUSTOM_TFX_IMAGE}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFqUQxQG-ISM"
      },
      "source": [
        "Ahora inicie una ejecución con la canalización recién creada con ayuda del comando `tfx run create`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ps-4RHz-ISM"
      },
      "outputs": [],
      "source": [
        "!tfx run create --engine=kubeflow --pipeline-name={PIPELINE_NAME} --endpoint={ENDPOINT}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fx3LtAL0-ISN"
      },
      "source": [
        "O también puede ejecutar la canalización en el panel de Kubeflow Pipelines. La nueva ejecución aparecerá en `Experiments` en el panel de Kubeflow Pipelines. Al hacer clic en el experimento, podrá monitorear el progreso y visualizar los artefactos creados durante la ejecución."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mP8W6zjD-ISO"
      },
      "source": [
        "Si le interesa ejecutar su canalización en Kubeflow Pipelines, consulte instrucciones adicionales en el [tutorial de TFX en Cloud AI Platform Pipelines](https://www.tensorflow.org/tfx/tutorials/tfx/cloud-ai-platform-pipelines)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTsgD_Kz-ISO"
      },
      "source": [
        "### Limpieza\n",
        "\n",
        "Para limpiar todos los recursos de Google Cloud utilizados en este paso, puede [eliminar el proyecto de Google Cloud](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects) que utilizó para el tutorial.\n",
        "\n",
        "Alternativamente, puedes limpiar recursos individuales si visita cada consola:\n",
        "\n",
        "- [Google Cloud Storage](https://console.cloud.google.com/storage)\n",
        "- [Google Container Registry](https://console.cloud.google.com/gcr)\n",
        "- [Google Kubernetes Engine](https://console.cloud.google.com/kubernetes)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "DjUA6S30k52h"
      ],
      "name": "penguin_template.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
