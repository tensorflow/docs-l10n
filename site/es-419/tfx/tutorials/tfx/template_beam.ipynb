{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjUA6S30k52h"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "SpNWyqewk8fE"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqZC7Cv942w0"
      },
      "source": [
        "# Cómo crear una canalización de TFX usando plantillas con el orquestador local"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdSXv1DrxdLL"
      },
      "source": [
        "<div class=\"devsite-table-wrapper\"><table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "<td><a target=\"_blank\" href=\"https://www.tensorflow.org/tfx/tutorials/tfx/template_local\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver en TensorFlow.org</a></td>\n",
        "<td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/tfx/blob/master/docs/tutorials/tfx/template_local.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Ejecutar en Google Colab</a></td>\n",
        "<td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/tfx/tree/master/docs/tutorials/tfx/template_local.ipynb\"><img width=\"32px\" src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver fuente en GitHub</a>\n",
        "</td>\n",
        "<td><a href=\"https://storage.googleapis.com/tensorflow_docs/tfx/docs/tutorials/tfx/template_local.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Descargar el bloc de notas</a></td>\n",
        "</table></div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRBoc5la42w0"
      },
      "source": [
        "## Introducción\n",
        "\n",
        "Este documento proporcionará instrucciones para crear una canalización de TensorFlow Extended (TFX) utilizando las *plantillas* que se proporcionan con el paquete de Python para TFX. La mayoría de las instrucciones son comandos de shell de Linux y se proporcionan las correspondientes celdas de código de Jupyter Notebook que invocan esos comandos usando `!`.\n",
        "\n",
        "Compilará una canalización mediante el uso del [conjunto de datos Taxi Trips](https://data.cityofchicago.org/Transportation/Taxi-Trips/wrvz-psew) publicado por la ciudad de Chicago. Le recomendamos que use esta canalización como punto de referencia para intentar compilar su propia canalización con su conjunto de datos.\n",
        "\n",
        "Compilaremos una canalización que funcione en el entorno local. Si le interesa usar el orquestador de Kubeflow en Google Cloud, consulte el [tutorial de TFX en Cloud AI Platform Pipelines](https://www.tensorflow.org/tfx/tutorials/tfx/cloud-ai-platform-pipelines).\n",
        "\n",
        "## Requisitos previos\n",
        "\n",
        "- Linux / MacOS\n",
        "- Python &gt;= 3.5.3\n",
        "\n",
        "Puede obtener todos los requisitos previos fácilmente [mediante la ejecución de este bloc de notas en Google Colab](https://colab.sandbox.google.com/github/tensorflow/tfx/blob/master/docs/tutorials/tfx/template_local.ipynb).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRW5apUw42w1"
      },
      "source": [
        "## Paso 1. Configure su entorno\n",
        "\n",
        "**A lo largo de este documento, presentaremos comandos dos veces. Una vez como comando de shell listo para copiar y pegar, otra vez como celda de bloc de notas Jupyter. Si está usando Colab, simplemente omita el bloque del script de shell y ejecute las celdas del bloc de notas.**\n",
        "\n",
        "Debe preparar un entorno de desarrollo para compilar una canalización.\n",
        "\n",
        "Instale el paquete de python par a`tfx`. Recomendamos el uso de `virtualenv` en el entorno local. Puede utilizar el siguiente fragmento de script de Shell para configurar su entorno.\n",
        "\n",
        "```sh\n",
        "# Create a virtualenv for tfx.\n",
        "virtualenv -p python3 venv\n",
        "source venv/bin/activate\n",
        "# Install python packages.\n",
        "python -m pip install --upgrade \"tfx<2\"\n",
        "```\n",
        "\n",
        "Si está usando Colab:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "llKzIjr442w1"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "!{sys.executable} -m pip install --upgrade \"tfx<2\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NA86S2v42w1"
      },
      "source": [
        "NOTA: Es posible que se produzcan algunos errores durante la instalación del paquete. Por ejemplo,\n",
        "\n",
        "> ERROR: algún-paquete 0.alguna_versión.1 tiene como requisito ¡otro-paquete!=2.0.,&lt;3,&gt;=1.15, pero tendrá otro-paquete 2.0.0 que es incompatible.\n",
        "\n",
        "Ignore estos errores en este momento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m6-DrWm042w4"
      },
      "outputs": [],
      "source": [
        "# Set `PATH` to include user python binary directory.\n",
        "HOME=%env HOME\n",
        "PATH=%env PATH\n",
        "%env PATH={PATH}:{HOME}/.local/bin"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YszwBVuS42w6"
      },
      "source": [
        "Comprobemos la versión de TFX.\n",
        "\n",
        "```bash\n",
        "python -c \"from tfx import version ; print('TFX version: {}'.format(version.__version__))\"\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sBLyQWYF42w6"
      },
      "outputs": [],
      "source": [
        "!python3 -c \"from tfx import version ; print('TFX version: {}'.format(version.__version__))\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycspntQk42xF"
      },
      "source": [
        "Y ya está. Estamos listos para crear una canalización."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BoSOcmEB42xF"
      },
      "source": [
        "## Paso 2. Copie la plantilla predefinida al directorio de su proyecto\n",
        "\n",
        "En este paso, crearemos un directorio y archivos de proyecto de canalización de trabajo copiando archivos adicionales de una plantilla predefinida.\n",
        "\n",
        "Puede cambiar el nombre de su canalización si cambia el valor de `PIPELINE_NAME` a continuación. Este también se convertirá en el nombre del directorio del proyecto donde se colocarán sus archivos.\n",
        "\n",
        "```bash\n",
        "export PIPELINE_NAME=\"my_pipeline\"\n",
        "export PROJECT_DIR=~/tfx/${PIPELINE_NAME}\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IYGyT4ib42xG"
      },
      "outputs": [],
      "source": [
        "PIPELINE_NAME=\"my_pipeline\"\n",
        "import os\n",
        "# Create a project directory under Colab content directory.\n",
        "PROJECT_DIR=os.path.join(os.sep,\"content\",PIPELINE_NAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GjXe_3oY42xI"
      },
      "source": [
        "TFX incluye la plantilla `taxi` con el paquete de Python para TFX. Si planea resolver un problema de predicción puntual, que incluye clasificación y regresión, esta plantilla podría usarse como punto de partida.\n",
        "\n",
        "El comando de CLI `tfx template copy` copia archivos de plantilla predefinidos al directorio de su proyecto.\n",
        "\n",
        "```sh\n",
        "tfx template copy \\\n",
        "   --pipeline_name=\"${PIPELINE_NAME}\" \\\n",
        "   --destination_path=\"${PROJECT_DIR}\" \\\n",
        "   --model=taxi\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3PmXatBD42xI"
      },
      "outputs": [],
      "source": [
        "!tfx template copy \\\n",
        "  --pipeline_name={PIPELINE_NAME} \\\n",
        "  --destination_path={PROJECT_DIR} \\\n",
        "  --model=taxi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fyhkhhxY42xK"
      },
      "source": [
        "Cambie el contexto del directorio de trabajo en este bloc de notas al directorio del proyecto.\n",
        "\n",
        "```bash\n",
        "cd ${PROJECT_DIR}\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y9e_g5rc42xL"
      },
      "outputs": [],
      "source": [
        "%cd {PROJECT_DIR}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rKBRbE342xN"
      },
      "source": [
        "## Paso 3. Exploración de archivos fuente copiados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdiHik_w42xN"
      },
      "source": [
        "La plantilla de TFX proporciona archivos de estructura básicos para compilar una canalización, incluido el código fuente de Python, datos de muestra y bloc de notas Jupyter para analizar el resultado de la canalización. La plantilla `taxi` utiliza el mismo conjunto de datos *Chicago Taxi* y el mismo modelo de ML que el [Tutorial de Airflow](https://www.tensorflow.org/tfx/tutorials/tfx/airflow_workshop).\n",
        "\n",
        "En Google Colab, puede buscar archivos al hacer clic en el icono de una carpeta a la izquierda. Los archivos deben copiarse en el directorio del proyecto, cuyo nombre es `my_pipeline` en este caso. Puede hacer clic en los nombres de los directorios para ver el contenido del directorio y hacer doble clic en los nombres de los archivos para abrirlos.\n",
        "\n",
        "Esta es una breve introducción a cada uno de los archivos de Python.\n",
        "\n",
        "- `pipeline`: este directorio contiene la definición de la canalización.\n",
        "    - `configs.py`: define constantes comunes para los ejecutores de la canalización\n",
        "    - `pipeline.py`: define los componentes de TFX y una canalización\n",
        "- `models`: este directorio contiene definiciones de modelos de ML.\n",
        "    - `features.py`, `features_test.py`: define características para el modelo\n",
        "    - `preprocessing.py`, `preprocessing_test.py`: define trabajos de preprocesamiento con ayuda de `tf::Transform`\n",
        "    - `estimator`: este directorio contiene un modelo basado en Estimator.\n",
        "        - `constants.py`: define las constantes del modelo\n",
        "        - `model.py`, `model_test.py`: define el modelo DNN utilizando el estimador TF\n",
        "    - `keras`: este directorio contiene un modelo basado en Keras.\n",
        "        - `constants.py`: define las constantes del modelo\n",
        "        - `model.py`, `model_test.py`: define el modelo DNN usando Keras\n",
        "- `local_runner.py`, `kubeflow_runner.py`: define ejecutores para cada motor de orquestación\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmWtR_Eq42xQ"
      },
      "source": [
        "Quizás note que hay algunos archivos con `_test.py` en su nombre. Estas son pruebas unitarias de la canalización y se recomienda agregar más pruebas unitarias a medida que implemente sus propias canalizaciones. Puede ejecutar pruebas unitarias si proporciona el nombre del módulo de los archivos de prueba con la marca `-m`. Generalmente puede obtener el nombre de un módulo al eliminar la extensión `.py` y reemplazarla por `/` con `.`. Por ejemplo:\n",
        "\n",
        "```bash\n",
        "python -m models.features_test\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H0DzGg-642xQ"
      },
      "outputs": [],
      "source": [
        "!{sys.executable} -m models.features_test\n",
        "!{sys.executable} -m models.keras.model_test\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fK_C6C6g42xS"
      },
      "source": [
        "## Paso 4. Ejecute su primera canalización de TFX\n",
        "\n",
        "Puede crear una canalización a partir del comando `pipeline create`.\n",
        "\n",
        "```bash\n",
        "tfx pipeline create --engine=local --pipeline_path=local_runner.py\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D5YikNik42xX"
      },
      "outputs": [],
      "source": [
        "!tfx pipeline create --engine=local --pipeline_path=local_runner.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kvZIn8142xZ"
      },
      "source": [
        "Luego, puede ejecutar la canalización creada a partir del comando `run create`.\n",
        "\n",
        "```sh\n",
        "tfx run create --engine=local --pipeline_name=\"${PIPELINE_NAME}\"\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SnTC_Rql42xZ"
      },
      "outputs": [],
      "source": [
        "!tfx run create --engine=local --pipeline_name={PIPELINE_NAME}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GM1G1Efw42xb"
      },
      "source": [
        "Si tiene éxito, verá que `Component CsvExampleGen is finished.` Cuando copia la plantilla, solo se incluye un componente, CsvExampleGen, en la canalización."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pfQcePs42xc"
      },
      "source": [
        "## Paso 5. Agregue componentes para la validación de datos\n",
        "\n",
        "En este paso, agregará componentes para la validación de datos, incluidos `StatisticsGen`, `SchemaGen` y `ExampleValidator`. Si está interesado en la validación de datos, consulte [Introducción a Tensorflow Data Validation](https://www.tensorflow.org/tfx/data_validation/get_started).\n",
        "\n",
        "Modificaremos la definición de canalización copiada en `pipeline/pipeline.py`. Si está trabajando en su entorno local, utilice su editor favorito para editar el archivo. Si está trabajando en Google Colab,\n",
        "\n",
        "> **Haga clic en el icono de carpeta a la izquierda para abrir la vista `Files`**.\n",
        "\n",
        "> **Haga clic en `my_pipeline` para abrir el directorio y haga clic en el directorio `pipeline` para abrir y haga doble clic en `pipeline.py` para abrir el archivo**.\n",
        "\n",
        "> Busque y descomente las 3 líneas que agregan `StatisticsGen`, `SchemaGen` y `ExampleValidator` a la canalización. (Consejo: busque comentarios que contengan `TODO(step 5):` :).\n",
        "\n",
        "> Su cambio se guardará automáticamente en unos segundos. Asegúrese de que la marca `*` delante de `pipeline.py` desaparezca en el título de la pestaña. **No hay ningún botón para guardar ni acceso directo para el editor de archivos en Colab. Los archivos Python en el editor de archivos se pueden guardar en el entorno de ejecución incluso en el modo `playground`.**\n",
        "\n",
        "Ahora debe actualizar la canalización existente con la definición de canalización modificada. Utilice el comando `tfx pipeline update` para actualizar su canalización, seguido del comando `tfx run create` para crear una nueva ejecución de su canalización actualizada.\n",
        "\n",
        "```sh\n",
        "# Update the pipeline\n",
        "tfx pipeline update --engine=local --pipeline_path=local_runner.py\n",
        "# You can run the pipeline the same way.\n",
        "tfx run create --engine local --pipeline_name \"${PIPELINE_NAME}\"\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wMsT-5EX42xc"
      },
      "outputs": [],
      "source": [
        "# Update the pipeline\n",
        "!tfx pipeline update --engine=local --pipeline_path=local_runner.py\n",
        "# You can run the pipeline the same way.\n",
        "!tfx run create --engine local --pipeline_name {PIPELINE_NAME}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUU5_3yR42xe"
      },
      "source": [
        "Debería poder ver el registro de salida de los componentes agregados. Nuestra canalización crea artefactos de salida en el directorio `tfx_pipeline_output/my_pipeline`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7p7CLDvD42xe"
      },
      "source": [
        "## Paso 6. Agregue componentes para el entrenamiento\n",
        "\n",
        "En este paso, agregará componentes para el entrenamiento y la validación del modelo, incluidos `Transform`, `Trainer`, `Resolver`, `Evaluator` y `Pusher`.\n",
        "\n",
        "> **Abra `pipeline/pipeline.py`**. Busque y descomente 5 líneas que agregan `Transform`, `Trainer`, `Resolver`, `Evaluator` y `Pusher` a la canalización. (Consejo: busque `TODO(step 6):`\n",
        "\n",
        "Como hizo antes, ahora necesita actualizar la canalización existente con la definición de canalización modificada. Las instrucciones son las mismas que las del Paso 5. Actualice la canalización con ayuda de `tfx pipeline update` y use `tfx run create` para crear una ejecución.\n",
        "\n",
        "```sh\n",
        "tfx pipeline update --engine=local --pipeline_path=local_runner.py\n",
        "tfx run create --engine local --pipeline_name \"${PIPELINE_NAME}\"\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ik8JbnRq42xf"
      },
      "outputs": [],
      "source": [
        "!tfx pipeline update --engine=local --pipeline_path=local_runner.py\n",
        "!tfx run create --engine local --pipeline_name {PIPELINE_NAME}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3L3NEPanUGY"
      },
      "source": [
        "Cuando esta ejecución finalice correctamente, habrá creado y ejecutado su primera canalización de TFX con el orquestador local.\n",
        "\n",
        "**NOTA:** Es posible que haya notado que cada vez que creamos una ejecución de canalización, cada componente se ejecuta una y otra vez aunque la entrada y los parámetros no hayan cambiado. Esto implica una pérdida de tiempo y recursos, y puede omitir esas ejecuciones con el almacenamiento en caché de la canalización. Puede habilitar el almacenamiento en caché si especifica `enable_cache=True` para el objeto `Pipeline` en `pipeline.py`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjcMwjov42xh"
      },
      "source": [
        "## Paso 7. (*Opcional*) Pruebe BigQueryExampleGen\n",
        "\n",
        "<a>BigQuery</a> es un almacén de datos en la nube sin servidor, altamente escalable y rentable. BigQuery sirve como fuente de ejemplos de entrenamiento en TFX. En este paso, agregaremos <code>BigQueryExampleGen</code> a la canalización.\n",
        "\n",
        "Necesita una cuenta [de Google Cloud Platform](https://cloud.google.com/gcp/getting-started) para usar BigQuery. Prepare un proyecto de GCP.\n",
        "\n",
        "Use la biblioteca de autenticación de colab o la utilidad `gcloud` para iniciar sesión en su proyecto.\n",
        "\n",
        "```sh\n",
        "# You need `gcloud` tool to login in local shell environment.\n",
        "gcloud auth login\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2K7nuHZ4uNXc"
      },
      "outputs": [],
      "source": [
        "if 'google.colab' in sys.modules:\n",
        "  from google.colab import auth\n",
        "  auth.authenticate_user()\n",
        "  print('Authenticated')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Win212lr03zP"
      },
      "source": [
        "Debe especificar el nombre de su proyecto de GCP para acceder a los recursos de BigQuery mediante TFX. Establezca la variable de entorno `GOOGLE_CLOUD_PROJECT` en el nombre de su proyecto.\n",
        "\n",
        "```sh\n",
        "export GOOGLE_CLOUD_PROJECT=YOUR_PROJECT_NAME_HERE\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vvpw_lGByxSx"
      },
      "outputs": [],
      "source": [
        "# Set your project name below.\n",
        "# WARNING! ENTER your project name before running this cell.\n",
        "%env GOOGLE_CLOUD_PROJECT=YOUR_PROJECT_NAME_HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhClPWEuuOaP"
      },
      "source": [
        "> **Abra `pipeline/pipeline.py`**. Comente `CsvExampleGen` y descomente la línea que crea una instancia de `BigQueryExampleGen`. También debe descomentar el argumento `query` de la función `create_pipeline`.\n",
        "\n",
        "Tenemos que especificar nuevamente qué proyecto de GCP se usará para BigQuery, y para hacer esto hay que configurar `--project` en `beam_pipeline_args` cuando se crea una canalización.\n",
        "\n",
        "> **Abra `pipeline/configs.py`**. Descomente la definición de `BIG_QUERY__WITH_DIRECT_RUNNER_BEAM_PIPELINE_ARGS` y `BIG_QUERY_QUERY`. Debe reemplazar la identificación del proyecto y el valor de la región en este archivo con los valores correctos para su proyecto de GCP.\n",
        "\n",
        "> **Abra `local_runner.py`**. Descomente dos argumentos, `query` y `beam_pipeline_args`, para el método create_pipeline().\n",
        "\n",
        "Ahora la canalización está lista para usar BigQuery como fuente de ejemplo. Actualice la canalización y cree una ejecución como lo hicimos en los pasos 5 y 6."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w8rOdC3r42xi"
      },
      "outputs": [],
      "source": [
        "!tfx pipeline update --engine=local --pipeline_path=local_runner.py\n",
        "!tfx run create --engine local --pipeline_name {PIPELINE_NAME}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxYxNHLN42xo"
      },
      "source": [
        "## Siguientes pasos: ingiera SUS datos en la canalización\n",
        "\n",
        "Creamos una canalización para un modelo utilizando el conjunto de datos Chicago Taxi. Ahora es el momento de poner sus datos en proceso.\n",
        "\n",
        "Sus datos se pueden almacenar en cualquier lugar al que pueda acceder su canalización, incluido GCS o BigQuery. Deberá modificar la definición de la canalización para acceder a sus datos.\n",
        "\n",
        "1. Si sus datos están almacenados en archivos, modifique `DATA_PATH` en `kubeflow_runner.py` o `local_runner.py` y configúrelo en la ubicación de sus archivos. Si sus datos están almacenados en BigQuery, modifique `BIG_QUERY_QUERY` en `pipeline/configs.py` para consultar correctamente sus datos.\n",
        "2. Agregue características en `models` / <code>features.py</code>.\n",
        "3. Modifique `models` / <code>preprocessing.py</code> para <a>transformar los datos de entrada para el entrenamiento</a>.\n",
        "4. Modifique `models` / `keras` / <code>model.py</code> y <code>models</code> / <code>keras</code> / <code>constants.py</code> para <a>describir su modelo de ML</a>.\n",
        "    - También puede utilizar un modelo basado en un estimador. Cambie la constante `RUN_FN` a `models.estimator.model.run_fn` en `pipeline/configs.py`.\n",
        "\n",
        "Consulte la [guía del componente Trainer](https://www.tensorflow.org/tfx/guide/trainer) para obtener más información."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "template_beam.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
