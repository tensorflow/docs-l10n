{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tce3stUlHN0L"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tuOe1ymfHZPu"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFdPvlXBOdUN"
      },
      "source": [
        "# Optimización de la ingeniería de aprendizaje automático con ML Metadata\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfBg1C5NB3X0"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td><a target=\"_blank\" href=\"https://www.tensorflow.org/tfx/tutorials/mlmd/mlmd_tutorial\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver en TensorFlow.org</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/es-419/tfx/tutorials/mlmd/mlmd_tutorial.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Ejecutar en Google Colab</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/es-419/tfx/tutorials/mlmd/mlmd_tutorial.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver fuente en GitHub</a></td>\n",
        "<td><a target=\"_blank\" href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/es-419/tfx/tutorials/mlmd/mlmd_tutorial.ipynb\"><img width=\"32px\" src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Descargar el bloc de notas</a></td>\n",
        "  \n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHxb-dlhMIzW"
      },
      "source": [
        "Pensemos en un escenario en el que se configura una canalización de aprendizaje automático (ML) de producción para clasificar pingüinos. La canalización ingiere los datos de entrenamiento, entrena y evalúa un modelo y lo inserta en producción.\n",
        "\n",
        "Sin embargo, luego, cuando intenta usar este modelo con un conjunto de datos más grande que contiene diferentes tipos de pingüinos, observa que su modelo no se comporta como se esperaba y comienza a clasificar las especies incorrectamente.\n",
        "\n",
        "En este punto, tendrá las siguientes interrogantes:\n",
        "\n",
        "- ¿Cuál es la forma más eficaz de depurar el modelo cuando el único artefacto disponible es el modelo en producción?\n",
        "- ¿Qué conjunto de datos de entrenamiento se usó para entrenar el modelo?\n",
        "- ¿Qué ejecución del entrenamiento condujo a este modelo erróneo?\n",
        "- ¿Dónde están los resultados de la evaluación del modelo?\n",
        "- ¿Por dónde empezar a depurar?\n",
        "\n",
        "[ML Metadata (MLMD)](https://github.com/google/ml-metadata) es una biblioteca que aprovecha los metadatos asociados con los modelos de ML para ayudarlo a responder estas y otras preguntas. Una analogía útil es pensar en estos metadatos como el equivalente al inicio de sesión en el desarrollo de software. MLMD le permite hacer un seguimiento confiable de los artefactos y el linaje asociados con los diversos componentes de su canalización de ML.\n",
        "\n",
        "En este tutorial, configurará una canalización de TFX para crear un modelo que clasifique a los pingüinos en tres especies según la masa corporal, la longitud y profundidad de sus cúlmenes, y la longitud de sus aletas. Luego, puede usar MLMD para hacer un seguimiento del linaje de los componentes de la canalización."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rGF8hLibz6p"
      },
      "source": [
        "## Canalizaciones de TFX en Colab\n",
        "\n",
        "Colab es un entorno de desarrollo sencillo que difiere significativamente de un entorno de producción. En producción, es posible que tenga varios componentes de canalización, como ingesta de datos, transformación, entrenamiento de modelos, historiales de ejecución, etc., en múltiples sistemas distribuidos. Para este tutorial, debe tener en cuenta que existen diferencias significativas en la orquestación y el almacenamiento de metadatos: todo se maneja localmente dentro de Colab. Si desea obtener más información sobre TFX en Colab, consulte [aquí](https://www.tensorflow.org/tfx/tutorials/tfx/components_keras#background) .\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUXex9ctTuDB"
      },
      "source": [
        "## Preparación\n",
        "\n",
        "En primer lugar, tenemos que instalar e importar los paquetes necesarios, configurar rutas y descargar datos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lko0xn8JxI6F"
      },
      "source": [
        "### Actualización de pip\n",
        "\n",
        "Para evitar actualizar Pip en un sistema cuando se ejecuta localmente, verifique que se esté ejecutando en Colab. Por supuesto, los sistemas locales se pueden actualizar por separado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7pXW--mlxQhY"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  import colab\n",
        "  !pip install --upgrade pip\n",
        "except:\n",
        "  pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQV-Cget1S8t"
      },
      "source": [
        "### Instalación e importación de TFX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "82jOhrcA36YA"
      },
      "outputs": [],
      "source": [
        " !pip install -q tfx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5p3LRwkZRbj"
      },
      "source": [
        "### Importación de paquetes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1oayJjlQZxS"
      },
      "source": [
        "#### ¿Reinició el tiempo de ejecución?\n",
        "\n",
        "Si está usando Google Colab, la primera vez que ejecute la celda anterior, debe hacer clic en el botón \"REINICIAR TIEMPO DE EJECUCIÓN\" o usar el menú \"Tiempo de ejecución &gt; Reiniciar tiempo de ejecución ...\" para reiniciar el tiempo de ejecución. Esto se debe a la forma en que Colab carga los paquetes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zknUh9LrZZf2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tempfile\n",
        "import urllib\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow_model_analysis as tfma\n",
        "from tfx.orchestration.experimental.interactive.interactive_context import InteractiveContext"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OD2cRhwM3ez2"
      },
      "source": [
        "Verifique las versiones TFX y MLMD."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z1ut9Wy_Qf1Q"
      },
      "outputs": [],
      "source": [
        "from tfx import v1 as tfx\n",
        "print('TFX version: {}'.format(tfx.__version__))\n",
        "import ml_metadata as mlmd\n",
        "print('MLMD version: {}'.format(mlmd.__version__))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhNtHfuxCGVy"
      },
      "source": [
        "## Cómo descargar el conjunto de datos\n",
        "\n",
        "En esta instancia de Colab, usamos el [conjunto de datos Palmer Penguins](https://allisonhorst.github.io/palmerpenguins/articles/intro.html) que está disponible en [Github](https://github.com/allisonhorst/palmerpenguins). Procesamos el conjunto de datos omitiendo los registros incompletos, eliminamos las columnas `island` y `sex`, y convertimos las etiquetas a `int32`. El conjunto de datos contiene 334 registros de la masa corporal, la longitud y profundidad de los cúlmenes de los pingüinos, y la longitud de sus aletas. Use estos datos para clasificar a los pingüinos en una de tres especies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B_NibNnjzGHu"
      },
      "outputs": [],
      "source": [
        "DATA_PATH = 'https://raw.githubusercontent.com/tensorflow/tfx/master/tfx/examples/penguin/data/labelled/penguins_processed.csv'\n",
        "_data_root = tempfile.mkdtemp(prefix='tfx-data')\n",
        "_data_filepath = os.path.join(_data_root, \"penguins_processed.csv\")\n",
        "urllib.request.urlretrieve(DATA_PATH, _data_filepath)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NXg2bGA19HJ"
      },
      "source": [
        "## Cómo crear un InteractiveContext\n",
        "\n",
        "Para ejecutar componentes de TFX de forma interactiva en este bloc de notas, cree un `InteractiveContext`. `InteractiveContext` usa un directorio temporal con una instancia de base de datos de MLMD efímera. Tenga en cuenta que las llamadas a `InteractiveContext` no son operativas fuera del entorno de Colab.\n",
        "\n",
        "En general, es una buena práctica agrupar ejecuciones de canalizaciones similares dentro de un `Context`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bytrDFKh40mi"
      },
      "outputs": [],
      "source": [
        "interactive_context = InteractiveContext()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-58fa9S6Nao"
      },
      "source": [
        "## Cómo construir una canalización de TFX\n",
        "\n",
        "Una canalización de TFX consta de varios componentes que procesan diferentes aspectos del flujo de trabajo de ML. En este bloc de notas, creará y ejecutará los componentes `ExampleGen`, `StatisticsGen`, `SchemaGen` y `Trainer` y usará los componentes `Evaluator` y `Pusher` para evaluar e insertar el modelo entrenado.\n",
        "\n",
        "Consulte el [tutorial de componentes](https://www.tensorflow.org/tfx/tutorials/tfx/components_keras) para obtener más información sobre los componentes de la canalización de TFX."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urh3FTb81yyM"
      },
      "source": [
        "Nota: La construcción de una canalización de TFX mediante la configuración de los componentes individuales implica una gran cantidad de código repetitivo. A los efectos de este tutorial, está bien si no comprende completamente cada línea de código en la configuración de la canalización. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnnq7Gf8CHZJ"
      },
      "source": [
        "### Creación de una instancia y ejecución del componente ExampleGen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H9zaBZh3C_9x"
      },
      "outputs": [],
      "source": [
        "example_gen = tfx.components.CsvExampleGen(input_base=_data_root)\n",
        "interactive_context.run(example_gen)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqxye_p1DLmf"
      },
      "source": [
        "### Creación de una instancia y ejecución del componente StatisticsGen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s67sHU_vDRds"
      },
      "outputs": [],
      "source": [
        "statistics_gen = tfx.components.StatisticsGen(\n",
        "    examples=example_gen.outputs['examples'])\n",
        "interactive_context.run(statistics_gen)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xib9oRb_ExjJ"
      },
      "source": [
        "### Creación de una instancia y ejecución del componente SchemaGen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "csmD4CSUE3JT"
      },
      "outputs": [],
      "source": [
        "infer_schema = tfx.components.SchemaGen(\n",
        "    statistics=statistics_gen.outputs['statistics'], infer_feature_shape=True)\n",
        "interactive_context.run(infer_schema)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pYNlw7BHUjP"
      },
      "source": [
        "### Creación de una instancia y ejecución del componente Trainer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MTxf8xs_kKfG"
      },
      "outputs": [],
      "source": [
        "# Define the module file for the Trainer component\n",
        "trainer_module_file = 'penguin_trainer.py'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f3nLHEmUkRUw"
      },
      "outputs": [],
      "source": [
        "%%writefile {trainer_module_file}\n",
        "\n",
        "# Define the training algorithm for the Trainer module file\n",
        "import os\n",
        "from typing import List, Text\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from tfx import v1 as tfx\n",
        "from tfx_bsl.public import tfxio\n",
        "\n",
        "from tensorflow_metadata.proto.v0 import schema_pb2\n",
        "\n",
        "# Features used for classification - culmen length and depth, flipper length,\n",
        "# body mass, and species.\n",
        "\n",
        "_LABEL_KEY = 'species'\n",
        "\n",
        "_FEATURE_KEYS = [\n",
        "    'culmen_length_mm', 'culmen_depth_mm', 'flipper_length_mm', 'body_mass_g'\n",
        "]\n",
        "\n",
        "\n",
        "def _input_fn(file_pattern: List[Text],\n",
        "              data_accessor: tfx.components.DataAccessor,\n",
        "              schema: schema_pb2.Schema, batch_size: int) -> tf.data.Dataset:\n",
        "  return data_accessor.tf_dataset_factory(\n",
        "      file_pattern,\n",
        "      tfxio.TensorFlowDatasetOptions(\n",
        "          batch_size=batch_size, label_key=_LABEL_KEY), schema).repeat()\n",
        "\n",
        "\n",
        "def _build_keras_model():\n",
        "  inputs = [keras.layers.Input(shape=(1,), name=f) for f in _FEATURE_KEYS]\n",
        "  d = keras.layers.concatenate(inputs)\n",
        "  d = keras.layers.Dense(8, activation='relu')(d)\n",
        "  d = keras.layers.Dense(8, activation='relu')(d)\n",
        "  outputs = keras.layers.Dense(3)(d)\n",
        "  model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "  model.compile(\n",
        "      optimizer=keras.optimizers.Adam(1e-2),\n",
        "      loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "      metrics=[keras.metrics.SparseCategoricalAccuracy()])\n",
        "  return model\n",
        "\n",
        "\n",
        "def run_fn(fn_args: tfx.components.FnArgs):\n",
        "  schema = schema_pb2.Schema()\n",
        "  tfx.utils.parse_pbtxt_file(fn_args.schema_path, schema)\n",
        "  train_dataset = _input_fn(\n",
        "      fn_args.train_files, fn_args.data_accessor, schema, batch_size=10)\n",
        "  eval_dataset = _input_fn(\n",
        "      fn_args.eval_files, fn_args.data_accessor, schema, batch_size=10)\n",
        "  model = _build_keras_model()\n",
        "  model.fit(\n",
        "      train_dataset,\n",
        "      epochs=int(fn_args.train_steps / 20),\n",
        "      steps_per_epoch=20,\n",
        "      validation_data=eval_dataset,\n",
        "      validation_steps=fn_args.eval_steps)\n",
        "  model.save(fn_args.serving_model_dir, save_format='tf')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qcmSNiqq5QaV"
      },
      "source": [
        "Ejecute el componente `Trainer`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4AzsMk7oflMg"
      },
      "outputs": [],
      "source": [
        "trainer = tfx.components.Trainer(\n",
        "    module_file=os.path.abspath(trainer_module_file),\n",
        "    examples=example_gen.outputs['examples'],\n",
        "    schema=infer_schema.outputs['schema'],\n",
        "    train_args=tfx.proto.TrainArgs(num_steps=100),\n",
        "    eval_args=tfx.proto.EvalArgs(num_steps=50))\n",
        "interactive_context.run(trainer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdCq5c0f5MyA"
      },
      "source": [
        "### Evaluación e inserción del modelo\n",
        "\n",
        "Use el componente `Evaluator` para evaluar y \"apruebe\" el modelo antes de usar el componente `Pusher` para insertar el modelo en un directorio de servicio."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NDx-fTUb6RUU"
      },
      "outputs": [],
      "source": [
        "_serving_model_dir = os.path.join(tempfile.mkdtemp(),\n",
        "                                  'serving_model/penguins_classification')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PpS4-wCf6eLR"
      },
      "outputs": [],
      "source": [
        "eval_config = tfma.EvalConfig(\n",
        "    model_specs=[\n",
        "        tfma.ModelSpec(label_key='species', signature_name='serving_default')\n",
        "    ],\n",
        "    metrics_specs=[\n",
        "        tfma.MetricsSpec(metrics=[\n",
        "            tfma.MetricConfig(\n",
        "                class_name='SparseCategoricalAccuracy',\n",
        "                threshold=tfma.MetricThreshold(\n",
        "                    value_threshold=tfma.GenericValueThreshold(\n",
        "                        lower_bound={'value': 0.6})))\n",
        "        ])\n",
        "    ],\n",
        "    slicing_specs=[tfma.SlicingSpec()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kFuH1YTh8vSf"
      },
      "outputs": [],
      "source": [
        "evaluator = tfx.components.Evaluator(\n",
        "    examples=example_gen.outputs['examples'],\n",
        "    model=trainer.outputs['model'],\n",
        "    schema=infer_schema.outputs['schema'],\n",
        "    eval_config=eval_config)\n",
        "interactive_context.run(evaluator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NCV9gcCQ966W"
      },
      "outputs": [],
      "source": [
        "pusher = tfx.components.Pusher(\n",
        "    model=trainer.outputs['model'],\n",
        "    model_blessing=evaluator.outputs['blessing'],\n",
        "    push_destination=tfx.proto.PushDestination(\n",
        "        filesystem=tfx.proto.PushDestination.Filesystem(\n",
        "            base_directory=_serving_model_dir)))\n",
        "interactive_context.run(pusher)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9K7RzdBzkru7"
      },
      "source": [
        "La ejecución de la canalización de TFX completa la base de datos MLMD. En la siguiente sección, se usará la API MLMD para consultar esta base de datos en busca de información de metadatos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GRCGQu7RguC"
      },
      "source": [
        "## Cómo consultar la base de datos MLMD\n",
        "\n",
        "La base de datos MLMD almacena tres tipos de metadatos:\n",
        "\n",
        "- Metadatos sobre la canalización e información de linaje asociada con los componentes de la canalización\n",
        "- Metadatos sobre artefactos que se generaron durante la ejecución de la canalización\n",
        "- Metadatos sobre las ejecuciones de la canalización\n",
        "\n",
        "Una canalización típica de un entorno de producción sirve a múltiples modelos a medida que llegan nuevos datos. Cuando encuentre resultados erróneos en los modelos servidos, puede consultar la base de datos MLMD para aislar los modelos erróneos. Luego puede hacer un seguimiento del linaje de los componentes de la canalización que corresponden a estos modelos para depurar sus modelos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0xVYqAkJybK"
      },
      "source": [
        "Configure el almacén de metadatos (MD) con el `InteractiveContext` que se definió previamente para consultar la base de datos MLMD."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P1p38etAv0kC"
      },
      "outputs": [],
      "source": [
        "connection_config = interactive_context.metadata_connection_config\n",
        "store = mlmd.MetadataStore(connection_config)\n",
        "\n",
        "# All TFX artifacts are stored in the base directory\n",
        "base_dir = connection_config.sqlite.filename_uri.split('metadata.sqlite')[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uq-1ep4suvuZ"
      },
      "source": [
        "Cree algunas funciones ayudantes para ver los datos del almacén MD."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q1ib8yStu6CW"
      },
      "outputs": [],
      "source": [
        "def display_types(types):\n",
        "  # Helper function to render dataframes for the artifact and execution types\n",
        "  table = {'id': [], 'name': []}\n",
        "  for a_type in types:\n",
        "    table['id'].append(a_type.id)\n",
        "    table['name'].append(a_type.name)\n",
        "  return pd.DataFrame(data=table)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HmqzYZcV3UG5"
      },
      "outputs": [],
      "source": [
        "def display_artifacts(store, artifacts):\n",
        "  # Helper function to render dataframes for the input artifacts\n",
        "  table = {'artifact id': [], 'type': [], 'uri': []}\n",
        "  for a in artifacts:\n",
        "    table['artifact id'].append(a.id)\n",
        "    artifact_type = store.get_artifact_types_by_id([a.type_id])[0]\n",
        "    table['type'].append(artifact_type.name)\n",
        "    table['uri'].append(a.uri.replace(base_dir, './'))\n",
        "  return pd.DataFrame(data=table)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iBdGCZ0CMJDO"
      },
      "outputs": [],
      "source": [
        "def display_properties(store, node):\n",
        "  # Helper function to render dataframes for artifact and execution properties\n",
        "  table = {'property': [], 'value': []}\n",
        "  for k, v in node.properties.items():\n",
        "    table['property'].append(k)\n",
        "    table['value'].append(\n",
        "        v.string_value if v.HasField('string_value') else v.int_value)\n",
        "  for k, v in node.custom_properties.items():\n",
        "    table['property'].append(k)\n",
        "    table['value'].append(\n",
        "        v.string_value if v.HasField('string_value') else v.int_value)\n",
        "  return pd.DataFrame(data=table)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1B-jRNH0M0k4"
      },
      "source": [
        "Primero, consulte el almacén de MD para obtener una lista de todos sus `ArtifactTypes` almacenados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6zXSQL8s5dyL"
      },
      "outputs": [],
      "source": [
        "display_types(store.get_artifact_types())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "quOsBgtM3r7S"
      },
      "source": [
        "A continuación, consulte todos los artefactos `PushedModel`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bUv_EI-bEMMu"
      },
      "outputs": [],
      "source": [
        "pushed_models = store.get_artifacts_by_type(\"PushedModel\")\n",
        "display_artifacts(store, pushed_models)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UecjkVOqJCBE"
      },
      "source": [
        "Consulte el último modelo insertado en el almacén de MD. Este tutorial tiene un solo modelo insertado. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N8tPvRtcPTrU"
      },
      "outputs": [],
      "source": [
        "pushed_model = pushed_models[-1]\n",
        "display_properties(store, pushed_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5Mz4vfP6wHO"
      },
      "source": [
        "Uno de los primeros pasos para depurar un modelo insertado es observar qué modelo entrenado se inserta y qué datos de entrenamiento se usan para entrenar ese modelo.\n",
        "\n",
        "MLMD ofrece API transversales para explorar el grafo de procedencia, que se puede usar para analizar la procedencia del modelo. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BLfydQVxOwf3"
      },
      "outputs": [],
      "source": [
        "def get_one_hop_parent_artifacts(store, artifacts):\n",
        "  # Get a list of artifacts within a 1-hop of the artifacts of interest\n",
        "  artifact_ids = [artifact.id for artifact in artifacts]\n",
        "  executions_ids = set(\n",
        "      event.execution_id\n",
        "      for event in store.get_events_by_artifact_ids(artifact_ids)\n",
        "      if event.type == mlmd.proto.Event.OUTPUT)\n",
        "  artifacts_ids = set(\n",
        "      event.artifact_id\n",
        "      for event in store.get_events_by_execution_ids(executions_ids)\n",
        "      if event.type == mlmd.proto.Event.INPUT)\n",
        "  return [artifact for artifact in store.get_artifacts_by_id(artifacts_ids)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3G0e0WIE9e9w"
      },
      "source": [
        "Consulte los artefactos principales para el modelo insertado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pOEFxucJQ1i6"
      },
      "outputs": [],
      "source": [
        "parent_artifacts = get_one_hop_parent_artifacts(store, [pushed_model])\n",
        "display_artifacts(store, parent_artifacts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJror5mf-W0M"
      },
      "source": [
        "Consulte las propiedades del modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OSCb0bg6Qmj4"
      },
      "outputs": [],
      "source": [
        "exported_model = parent_artifacts[0]\n",
        "display_properties(store, exported_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phz1hfzc_UcK"
      },
      "source": [
        "Consulte los artefactos ascendentes del modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nx_-IVhjRGA4"
      },
      "outputs": [],
      "source": [
        "model_parents = get_one_hop_parent_artifacts(store, [exported_model])\n",
        "display_artifacts(store, model_parents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00jqfk6o_niu"
      },
      "source": [
        "Obtenga los datos de entrenamiento con los que entrenó el modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2nMECsKvROEX"
      },
      "outputs": [],
      "source": [
        "used_data = model_parents[0]\n",
        "display_properties(store, used_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgTMTaew_3Fe"
      },
      "source": [
        "Ahora que tiene los datos de entrenamiento con los que se entrenó el modelo, consulte la base de datos nuevamente para encontrar el paso de entrenamiento (ejecución). Consulte el almacén de MD para obtener una lista de los tipos de ejecución registrados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8cBKQsScaD9a"
      },
      "outputs": [],
      "source": [
        "display_types(store.get_execution_types())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxcue6SggQ_b"
      },
      "source": [
        "El paso de entrenamiento es el `ExecutionType` denominado `tfx.components.trainer.component.Trainer`. Explore el almacén de MD para ejecutar el entrenador que corresponde al modelo insertado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ned8BxHzaunk"
      },
      "outputs": [],
      "source": [
        "def find_producer_execution(store, artifact):\n",
        "  executions_ids = set(\n",
        "      event.execution_id\n",
        "      for event in store.get_events_by_artifact_ids([artifact.id])\n",
        "      if event.type == mlmd.proto.Event.OUTPUT)\n",
        "  return store.get_executions_by_id(executions_ids)[0]\n",
        "\n",
        "trainer = find_producer_execution(store, exported_model)\n",
        "display_properties(store, trainer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYzlTckHClxC"
      },
      "source": [
        "## Resumen\n",
        "\n",
        "En este tutorial, aprendimos cómo sacar provecho de MLMD para hacer un seguimiento del linaje de los componentes de su canalización de TFX y resolver problemas.\n",
        "\n",
        "Para obtener más información sobre cómo usar MLMD, consulte estos recursos adicionales:\n",
        "\n",
        "- [Documentación de la API de MLMD](https://www.tensorflow.org/tfx/ml_metadata/api_docs/python/mlmd)\n",
        "- [Guía de MLMD](https://www.tensorflow.org/tfx/guide/mlmd)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Tce3stUlHN0L"
      ],
      "name": "mlmd_tutorial.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
