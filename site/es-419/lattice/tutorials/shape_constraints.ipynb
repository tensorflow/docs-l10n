{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7765UFHoyGx6"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "KsOkK8O69PyT"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKQpW0JqQQmY"
      },
      "source": [
        "# Restricciones de forma con Tensorflow Lattice\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r61fkA2i9Y3_"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>     <a target=\"_blank\" href=\"https://www.tensorflow.org/lattice/tutorials/shape_constraints\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver en TensorFlow.org</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/lattice/blob/master/docs/tutorials/shape_constraints.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Ejecutar en Google Colab</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/lattice/blob/master/docs/tutorials/shape_constraints.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver código fuente en GitHub</a>\n",
        "</td>\n",
        "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/lattice/docs/tutorials/shape_constraints.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Descargar el bloc de notas</a>\n",
        "</td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2plcL3iTVjsp"
      },
      "source": [
        "## Descripción general\n",
        "\n",
        "Este tutorial es una descripción general de las restricciones y regularizadores proporcionados por la biblioteca TensorFlow Lattice (TFL). Aquí usamos estimadores prediseñados de TFL en conjuntos de datos sintéticos, pero tenga en cuenta que todo en este tutorial también se puede hacer con modelos construidos a partir de capas TFL Keras.\n",
        "\n",
        "Antes de continuar, asegúrese de que su tiempo de ejecución tenga instalados todos los paquetes necesarios (tal como se importan en las celdas de código a continuación)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x769lI12IZXB"
      },
      "source": [
        "## Preparación"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbBVAR6UeRN5"
      },
      "source": [
        "Instalar el paquete TF Lattice:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bpXjJKpSd3j4"
      },
      "outputs": [],
      "source": [
        "#@test {\"skip\": true}\n",
        "!pip install tensorflow-lattice tensorflow_decision_forests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSVl9SHTeSGX"
      },
      "source": [
        "Importar los paquetes requeridos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "both",
        "id": "iY6awAl058TV"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_lattice as tfl\n",
        "import tensorflow_decision_forests as tfdf\n",
        "\n",
        "from IPython.core.pylabtools import figsize\n",
        "import itertools\n",
        "import logging\n",
        "import matplotlib\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sys\n",
        "import tempfile\n",
        "logging.disable(sys.maxsize)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TmBk_IGgJF0"
      },
      "source": [
        "Valores predeterminados que se usan en esta guía:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kQHPyPsPUF92"
      },
      "outputs": [],
      "source": [
        "NUM_EPOCHS = 1000\n",
        "BATCH_SIZE = 64\n",
        "LEARNING_RATE=0.01"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FjR7D8Ag3z0d"
      },
      "source": [
        "## Conjunto de datos de entrenamiento para clasificar restaurantes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1YetzbdFOij"
      },
      "source": [
        "Imagine un escenario simplificado en el que queremos determinar si los usuarios harán clic o no en el resultado de búsqueda de un restaurante. La tarea es predecir la tasa de clics (CTR) según las características de entrada:\n",
        "\n",
        "- Calificación promedio (`avg_rating`): una característica numérica con valores dentro del rango [1,5].\n",
        "- Cantidad de reseñas (`num_reviews`): una característica numérica con valores no mayores que 200, que usamos como medida de tendencia.\n",
        "- Calificación en dólares (`dollar_rating`): una característica categórica con valores de cadena en el conjunto {\"D\", \"DD\", \"DDD\", \"DDDD\"}.\n",
        "\n",
        "Aquí creamos un conjunto de datos sintéticos donde el CTR verdadero proviene de la fórmula: $$ CTR = 1 / (1 + exp{\\mbox{b(dollar_rating)}-\\mbox{avg_rating}\\times log(\\mbox{num_reviews} ) /4 }) $$ donde $b(\\cdot)$ traduce cada dollar_rating a un valor de referencia: $$ \\mbox{D}\\to 3,\\ \\mbox{DD}\\to 2,\\ \\mbox{DDD} \\a 4,\\ \\mbox{DDDD}\\a 4.5. $$\n",
        "\n",
        "Esta fórmula refleja patrones típicos del usuario, por ejemplo, dado que todo lo demás es fijo, los usuarios prefieren restaurantes con calificaciones de estrellas más altas y los restaurantes \"\\$\\$\" recibirán más clics que \"\\$\", seguidos de \"\\$\\$\\$\" y \"\\$\\$\\$\". "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mKovnyv1jATw"
      },
      "outputs": [],
      "source": [
        "def click_through_rate(avg_ratings, num_reviews, dollar_ratings):\n",
        "  dollar_rating_baseline = {\"D\": 3, \"DD\": 2, \"DDD\": 4, \"DDDD\": 4.5}\n",
        "  return 1 / (1 + np.exp(\n",
        "      np.array([dollar_rating_baseline[d] for d in dollar_ratings]) -\n",
        "      avg_ratings * np.log1p(num_reviews) / 4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPlgRdt6jAbP"
      },
      "source": [
        "Echemos un vistazo a los gráficos de contorno de esta función CTR."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KC5qX_XKmc7g"
      },
      "outputs": [],
      "source": [
        "def color_bar():\n",
        "  bar = matplotlib.cm.ScalarMappable(\n",
        "      norm=matplotlib.colors.Normalize(0, 1, True),\n",
        "      cmap=\"viridis\",\n",
        "  )\n",
        "  bar.set_array([0, 1])\n",
        "  return bar\n",
        "\n",
        "\n",
        "def plot_fns(fns, split_by_dollar=False, res=25):\n",
        "  \"\"\"Generates contour plots for a list of (name, fn) functions.\"\"\"\n",
        "  num_reviews, avg_ratings = np.meshgrid(\n",
        "      np.linspace(0, 200, num=res),\n",
        "      np.linspace(1, 5, num=res),\n",
        "  )\n",
        "  if split_by_dollar:\n",
        "    dollar_rating_splits = [\"D\", \"DD\", \"DDD\", \"DDDD\"]\n",
        "  else:\n",
        "    dollar_rating_splits = [None]\n",
        "  if len(fns) == 1:\n",
        "    fig, axes = plt.subplots(2, 2, sharey=True, tight_layout=False)\n",
        "  else:\n",
        "    fig, axes = plt.subplots(\n",
        "        len(dollar_rating_splits), len(fns), sharey=True, tight_layout=False)\n",
        "  axes = axes.flatten()\n",
        "  axes_index = 0\n",
        "  for dollar_rating_split in dollar_rating_splits:\n",
        "    for title, fn in fns:\n",
        "      if dollar_rating_split is not None:\n",
        "        dollar_ratings = np.repeat(dollar_rating_split, res**2)\n",
        "        values = fn(avg_ratings.flatten(), num_reviews.flatten(),\n",
        "                    dollar_ratings)\n",
        "        title = \"{}: dollar_rating={}\".format(title, dollar_rating_split)\n",
        "      else:\n",
        "        values = fn(avg_ratings.flatten(), num_reviews.flatten())\n",
        "      subplot = axes[axes_index]\n",
        "      axes_index += 1\n",
        "      subplot.contourf(\n",
        "          avg_ratings,\n",
        "          num_reviews,\n",
        "          np.reshape(values, (res, res)),\n",
        "          vmin=0,\n",
        "          vmax=1)\n",
        "      subplot.title.set_text(title)\n",
        "      subplot.set(xlabel=\"Average Rating\")\n",
        "      subplot.set(ylabel=\"Number of Reviews\")\n",
        "      subplot.set(xlim=(1, 5))\n",
        "\n",
        "  _ = fig.colorbar(color_bar(), cax=fig.add_axes([0.95, 0.2, 0.01, 0.6]))\n",
        "\n",
        "\n",
        "figsize(11, 11)\n",
        "plot_fns([(\"CTR\", click_through_rate)], split_by_dollar=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ol91olp3muNN"
      },
      "source": [
        "### Preparar datos\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8BOshZS9xwn"
      },
      "source": [
        "Ahora necesitamos crear nuestros conjuntos de datos sintéticos. Comenzamos generando un conjunto de datos simulado de restaurantes y sus características."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MhqcOPdTT_wj"
      },
      "outputs": [],
      "source": [
        "def sample_restaurants(n):\n",
        "  avg_ratings = np.random.uniform(1.0, 5.0, n)\n",
        "  num_reviews = np.round(np.exp(np.random.uniform(0.0, np.log(200), n)))\n",
        "  dollar_ratings = np.random.choice([\"D\", \"DD\", \"DDD\", \"DDDD\"], n)\n",
        "  ctr_labels = click_through_rate(avg_ratings, num_reviews, dollar_ratings)\n",
        "  return avg_ratings, num_reviews, dollar_ratings, ctr_labels\n",
        "\n",
        "\n",
        "np.random.seed(42)\n",
        "avg_ratings, num_reviews, dollar_ratings, ctr_labels = sample_restaurants(2000)\n",
        "\n",
        "figsize(5, 5)\n",
        "fig, axs = plt.subplots(1, 1, sharey=False, tight_layout=False)\n",
        "for rating, marker in [(\"D\", \"o\"), (\"DD\", \"^\"), (\"DDD\", \"+\"), (\"DDDD\", \"x\")]:\n",
        "  plt.scatter(\n",
        "      x=avg_ratings[np.where(dollar_ratings == rating)],\n",
        "      y=num_reviews[np.where(dollar_ratings == rating)],\n",
        "      c=ctr_labels[np.where(dollar_ratings == rating)],\n",
        "      vmin=0,\n",
        "      vmax=1,\n",
        "      marker=marker,\n",
        "      label=rating)\n",
        "plt.xlabel(\"Average Rating\")\n",
        "plt.ylabel(\"Number of Reviews\")\n",
        "plt.legend()\n",
        "plt.xlim((1, 5))\n",
        "plt.title(\"Distribution of restaurants\")\n",
        "_ = fig.colorbar(color_bar(), cax=fig.add_axes([0.95, 0.2, 0.01, 0.6]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRetsfLv_JSR"
      },
      "source": [
        "Vamos a producir los conjuntos de datos de entrenamiento, validación y prueba. Cuando se ve un restaurante en los resultados de búsqueda, podemos registrar la participación del usuario (hace clic o no) como punto de muestra.\n",
        "\n",
        "En la práctica, los usuarios no suelen revisar todos los resultados de búsqueda. Esto significa que los usuarios probablemente solo verán restaurantes que ya se consideran \"buenos\" según el modelo de clasificación actual en uso. Como resultado, los restaurantes \"buenos\" se imprimen con mayor frecuencia y están sobrerrepresentados en los conjuntos de datos de entrenamiento. Cuando se usan más funciones, el conjunto de datos de entrenamiento puede tener grandes pausas en las partes \"malas\" del espacio de funciones.\n",
        "\n",
        "Cuando el modelo se usa para clasificar, suele evaluarse en función de todos los resultados relevantes con una distribución más uniforme que no está bien representada por el conjunto de datos de entrenamiento. Un modelo flexible y complicado podría fallar en este caso debido al sobreajuste de los puntos de datos sobrerrepresentados y, por lo tanto, carecería de generalización. Para controlar este problema aplicamos conocimiento del dominio para agregar *restricciones de forma* que guían al modelo para hacer predicciones razonables que no se pueden obtener del conjunto de datos de entrenamiento.\n",
        "\n",
        "En este ejemplo, el conjunto de datos de entrenamiento consiste principalmente en interacciones de usuarios con restaurantes buenos y populares. El conjunto de datos de prueba tiene una distribución uniforme para simular la configuración de evaluación que se menciona anteriormente. Tenga en cuenta que dicho conjunto de datos de prueba no estará disponible en un entorno de problema real."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jS6WOtXQ8jwX"
      },
      "outputs": [],
      "source": [
        "def sample_dataset(n, testing_set):\n",
        "  (avg_ratings, num_reviews, dollar_ratings, ctr_labels) = sample_restaurants(n)\n",
        "  if testing_set:\n",
        "    # Testing has a more uniform distribution over all restaurants.\n",
        "    num_views = np.random.poisson(lam=3, size=n)\n",
        "  else:\n",
        "    # Training/validation datasets have more views on popular restaurants.\n",
        "    num_views = np.random.poisson(lam=ctr_labels * num_reviews / 50.0, size=n)\n",
        "\n",
        "  return pd.DataFrame({\n",
        "      \"avg_rating\": np.repeat(avg_ratings, num_views),\n",
        "      \"num_reviews\": np.repeat(num_reviews, num_views),\n",
        "      \"dollar_rating\": np.repeat(dollar_ratings, num_views),\n",
        "      \"clicked\": np.random.binomial(n=1, p=np.repeat(ctr_labels, num_views))\n",
        "  })\n",
        "\n",
        "\n",
        "# Generate datasets.\n",
        "np.random.seed(42)\n",
        "data_train = sample_dataset(500, testing_set=False)\n",
        "data_val = sample_dataset(500, testing_set=False)\n",
        "data_test = sample_dataset(500, testing_set=True)\n",
        "\n",
        "# Plotting dataset densities.\n",
        "figsize(12, 5)\n",
        "fig, axs = plt.subplots(1, 2, sharey=False, tight_layout=False)\n",
        "for ax, data, title in [(axs[0], data_train, \"training\"),\n",
        "                        (axs[1], data_test, \"testing\")]:\n",
        "  _, _, _, density = ax.hist2d(\n",
        "      x=data[\"avg_rating\"],\n",
        "      y=data[\"num_reviews\"],\n",
        "      bins=(np.linspace(1, 5, num=21), np.linspace(0, 200, num=21)),\n",
        "      cmap=\"Blues\",\n",
        "  )\n",
        "  ax.set(xlim=(1, 5))\n",
        "  ax.set(ylim=(0, 200))\n",
        "  ax.set(xlabel=\"Average Rating\")\n",
        "  ax.set(ylabel=\"Number of Reviews\")\n",
        "  ax.title.set_text(\"Density of {} examples\".format(title))\n",
        "  _ = fig.colorbar(density, ax=ax)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fVyLgpCT1nW"
      },
      "source": [
        "Definir el input_fns que se usa para el entrenamiento y la evaluación:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DYzRTRR2GKoS"
      },
      "outputs": [],
      "source": [
        "train_input_fn = tf.compat.v1.estimator.inputs.pandas_input_fn(\n",
        "    x=data_train,\n",
        "    y=data_train[\"clicked\"],\n",
        "    batch_size=BATCH_SIZE,\n",
        "    num_epochs=NUM_EPOCHS,\n",
        "    shuffle=False,\n",
        ")\n",
        "\n",
        "# feature_analysis_input_fn is used for TF Lattice estimators.\n",
        "feature_analysis_input_fn = tf.compat.v1.estimator.inputs.pandas_input_fn(\n",
        "    x=data_train,\n",
        "    y=data_train[\"clicked\"],\n",
        "    batch_size=BATCH_SIZE,\n",
        "    num_epochs=1,\n",
        "    shuffle=False,\n",
        ")\n",
        "\n",
        "val_input_fn = tf.compat.v1.estimator.inputs.pandas_input_fn(\n",
        "    x=data_val,\n",
        "    y=data_val[\"clicked\"],\n",
        "    batch_size=BATCH_SIZE,\n",
        "    num_epochs=1,\n",
        "    shuffle=False,\n",
        ")\n",
        "\n",
        "test_input_fn = tf.compat.v1.estimator.inputs.pandas_input_fn(\n",
        "    x=data_test,\n",
        "    y=data_test[\"clicked\"],\n",
        "    batch_size=BATCH_SIZE,\n",
        "    num_epochs=1,\n",
        "    shuffle=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qoTrw3FZqvPK"
      },
      "source": [
        "## Ajuste de árboles potenciados por gradiente"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZklNowexE3wB"
      },
      "source": [
        "Comencemos con solo dos características: `avg_rating` y `num_reviews`.\n",
        "\n",
        "Creamos algunas funciones ayudantes para trazar y calcular métricas de validación y prueba."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SX6rARJWURWl"
      },
      "outputs": [],
      "source": [
        "def analyze_two_d_estimator(estimator, name):\n",
        "  # Extract validation metrics.\n",
        "  if isinstance(estimator, tf.estimator.Estimator):\n",
        "    metric = estimator.evaluate(input_fn=val_input_fn)\n",
        "  else:\n",
        "    metric = estimator.evaluate(\n",
        "        tfdf.keras.pd_dataframe_to_tf_dataset(data_val, label=\"clicked\"),\n",
        "        return_dict=True,\n",
        "        verbose=0)\n",
        "  print(\"Validation AUC: {}\".format(metric[\"auc\"]))\n",
        "\n",
        "  if isinstance(estimator, tf.estimator.Estimator):\n",
        "    metric = estimator.evaluate(input_fn=test_input_fn)\n",
        "  else:\n",
        "    metric = estimator.evaluate(\n",
        "        tfdf.keras.pd_dataframe_to_tf_dataset(data_test, label=\"clicked\"),\n",
        "        return_dict=True,\n",
        "        verbose=0)\n",
        "  print(\"Testing AUC: {}\".format(metric[\"auc\"]))\n",
        "\n",
        "  def two_d_pred(avg_ratings, num_reviews):\n",
        "    if isinstance(estimator, tf.estimator.Estimator):\n",
        "      results = estimator.predict(\n",
        "          tf.compat.v1.estimator.inputs.pandas_input_fn(\n",
        "              x=pd.DataFrame({\n",
        "                  \"avg_rating\": avg_ratings,\n",
        "                  \"num_reviews\": num_reviews,\n",
        "              }),\n",
        "              shuffle=False,\n",
        "          ))\n",
        "      return [x[\"logistic\"][0] for x in results]\n",
        "    else:\n",
        "      return estimator.predict(\n",
        "          tfdf.keras.pd_dataframe_to_tf_dataset(\n",
        "              pd.DataFrame({\n",
        "                  \"avg_rating\": avg_ratings,\n",
        "                  \"num_reviews\": num_reviews,\n",
        "              })),\n",
        "          verbose=0)\n",
        "\n",
        "  def two_d_click_through_rate(avg_ratings, num_reviews):\n",
        "    return np.mean([\n",
        "        click_through_rate(avg_ratings, num_reviews,\n",
        "                           np.repeat(d, len(avg_ratings)))\n",
        "        for d in [\"D\", \"DD\", \"DDD\", \"DDDD\"]\n",
        "    ],\n",
        "                   axis=0)\n",
        "\n",
        "  figsize(11, 5)\n",
        "  plot_fns([(\"{} Estimated CTR\".format(name), two_d_pred),\n",
        "            (\"CTR\", two_d_click_through_rate)],\n",
        "           split_by_dollar=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVef4f8yUUbs"
      },
      "source": [
        "Podemos ajustar árboles de decisión potenciados ​​por gradientes de TensorFlow en el conjunto de datos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DnPYlRAo2mnQ"
      },
      "outputs": [],
      "source": [
        "gbt_model = tfdf.keras.GradientBoostedTreesModel(\n",
        "    features=[\n",
        "        tfdf.keras.FeatureUsage(name=\"num_reviews\"),\n",
        "        tfdf.keras.FeatureUsage(name=\"avg_rating\")\n",
        "    ],\n",
        "    exclude_non_specified_features=True,\n",
        "    num_threads=1,\n",
        "    num_trees=32,\n",
        "    max_depth=6,\n",
        "    min_examples=10,\n",
        "    growing_strategy=\"BEST_FIRST_GLOBAL\",\n",
        "    random_seed=42,\n",
        "    temp_directory=tempfile.mkdtemp(),\n",
        ")\n",
        "gbt_model.compile(metrics=[tf.keras.metrics.AUC(name=\"auc\")])\n",
        "gbt_model.fit(\n",
        "    tfdf.keras.pd_dataframe_to_tf_dataset(data_train, label=\"clicked\"),\n",
        "    validation_data=tfdf.keras.pd_dataframe_to_tf_dataset(\n",
        "        data_val, label=\"clicked\"),\n",
        "    verbose=0)\n",
        "analyze_two_d_estimator(gbt_model, \"GBT\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYZtd6YvsNdn"
      },
      "source": [
        "Aunque el modelo ha capturado la forma general del CTR real y tiene métricas de validación decentes, tiene un comportamiento contrario a la intuición en varias partes del espacio de entrada: el CTR estimado disminuye a medida que aumenta la calificación promedio o el número de reseñas. Esto se debe a la falta de puntos de muestra en áreas que el conjunto de datos de entrenamiento no cubre. El modelo simplemente no tiene forma de deducir el comportamiento correcto únicamente a partir de los datos.\n",
        "\n",
        "Para resolver este problema, aplicamos la restricción de forma que establece que el modelo debe generar valores que aumenten monotonicinicamente con respecto tanto a la calificación promedio como al número de reseñas. Más adelante veremos cómo implementar esto en TFL.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uf7WqGooFiEp"
      },
      "source": [
        "## Ajuste de DNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_s2aT3x0E_tF"
      },
      "source": [
        "Podemos repetir los mismos pasos con un clasificador DNN. Podemos observar un patrón similar: no tener suficientes puntos de muestra con un número pequeño de reseñas da como resultado una extrapolación sin sentido. Tenga en cuenta que aunque la métrica de validación es mejor que la solución de árbol, la métrica de prueba es mucho peor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gFUeG6kLDNhO"
      },
      "outputs": [],
      "source": [
        "feature_columns = [\n",
        "    tf.feature_column.numeric_column(\"num_reviews\"),\n",
        "    tf.feature_column.numeric_column(\"avg_rating\"),\n",
        "]\n",
        "dnn_estimator = tf.estimator.DNNClassifier(\n",
        "    feature_columns=feature_columns,\n",
        "    # Hyper-params optimized on validation set.\n",
        "    hidden_units=[16, 8, 8],\n",
        "    optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=LEARNING_RATE),\n",
        "    config=tf.estimator.RunConfig(tf_random_seed=42),\n",
        ")\n",
        "dnn_estimator.train(input_fn=train_input_fn)\n",
        "analyze_two_d_estimator(dnn_estimator, \"DNN\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Avkw-okw7JL"
      },
      "source": [
        "## Restricciones de forma"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ExyethCFBrP"
      },
      "source": [
        "TensorFlow Lattice (TFL) se centra en hacer cumplir restricciones de forma para salvaguardar el comportamiento del modelo más allá de los datos de entrenamiento. Estas restricciones de forma se aplican a las capas TFL Keras. Se pueden encontrar los detalles en [nuestro artículo de JMLR](http://jmlr.org/papers/volume17/15-243/15-243.pdf).\n",
        "\n",
        "En este tutorial usamos estimadores prediseñados de TF para cubrir varias restricciones de forma, pero tenga en cuenta que todos estos pasos se pueden realizar con modelos creados a partir de capas TFL Keras.\n",
        "\n",
        "Al igual que con cualquier otro estimador de TensorFlow, los estimadores prediseñados de TFL usan [columnas de funciones](https://www.tensorflow.org/api_docs/python/tf/feature_column) para definir el formato de entrada y usan un input_fn de entrenamiento para pasar los datos. El uso de estimadores prediseñados de TFL también requiere:\n",
        "\n",
        "- una *configuración de modelo*: que define la arquitectura del modelo y las restricciones y regularizadores de forma por función.\n",
        "- un *análisis de características input_fn*: un input_fn deTF que pasa datos para la inicialización de TFL.\n",
        "\n",
        "Para obtener una descripción más completa, consulte el tutorial de estimadores prediseñados o los documentos de la API."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anyCM4sCpOSo"
      },
      "source": [
        "### Monotonicidad\n",
        "\n",
        "Primero abordamos las preocupaciones de monotonicidad y agregamos restricciones de forma de monotonicidad a ambas características.\n",
        "\n",
        "Para indicarle a TFL que aplique restricciones de forma, especificamos las restricciones en las *configuraciones de funciones*. El siguiente código muestra cómo podemos exigir que la salida aumente monotonicinicamente con respecto a `num_reviews` y `avg_rating` y configuramos `monotonicity=\"increasing\"`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FCm1lOjmwur_"
      },
      "outputs": [],
      "source": [
        "feature_columns = [\n",
        "    tf.feature_column.numeric_column(\"num_reviews\"),\n",
        "    tf.feature_column.numeric_column(\"avg_rating\"),\n",
        "]\n",
        "model_config = tfl.configs.CalibratedLatticeConfig(\n",
        "    feature_configs=[\n",
        "        tfl.configs.FeatureConfig(\n",
        "            name=\"num_reviews\",\n",
        "            lattice_size=2,\n",
        "            monotonicity=\"increasing\",\n",
        "            pwl_calibration_num_keypoints=20,\n",
        "        ),\n",
        "        tfl.configs.FeatureConfig(\n",
        "            name=\"avg_rating\",\n",
        "            lattice_size=2,\n",
        "            monotonicity=\"increasing\",\n",
        "            pwl_calibration_num_keypoints=20,\n",
        "        )\n",
        "    ])\n",
        "tfl_estimator = tfl.estimators.CannedClassifier(\n",
        "    feature_columns=feature_columns,\n",
        "    model_config=model_config,\n",
        "    feature_analysis_input_fn=feature_analysis_input_fn,\n",
        "    optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=LEARNING_RATE),\n",
        "    config=tf.estimator.RunConfig(tf_random_seed=42),\n",
        ")\n",
        "tfl_estimator.train(input_fn=train_input_fn)\n",
        "analyze_two_d_estimator(tfl_estimator, \"TF Lattice\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubNRBCWW5wQ9"
      },
      "source": [
        "El uso de `CalibratedLatticeConfig` crea un clasificador prediseñado que primero aplica un *calibrador* a cada entrada (una función lineal por partes para funciones numéricas) seguido de una capa *de cuadrícula* para fusionar de forma no lineal las funciones calibradas. Podemos usar `tfl.visualization` para visualizar el modelo. En particular, el siguiente gráfico muestra los dos calibradores entrenados incluidos en el clasificador prediseñado.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "both",
        "id": "C0py9Q6OBRBE"
      },
      "outputs": [],
      "source": [
        "def save_and_visualize_lattice(tfl_estimator):\n",
        "  saved_model_path = tfl_estimator.export_saved_model(\n",
        "      \"/tmp/TensorFlow_Lattice_101/\",\n",
        "      tf.estimator.export.build_parsing_serving_input_receiver_fn(\n",
        "          feature_spec=tf.feature_column.make_parse_example_spec(\n",
        "              feature_columns)))\n",
        "  model_graph = tfl.estimators.get_model_graph(saved_model_path)\n",
        "  figsize(8, 8)\n",
        "  tfl.visualization.draw_model_graph(model_graph)\n",
        "  return model_graph\n",
        "\n",
        "_ = save_and_visualize_lattice(tfl_estimator)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vZ5fShXs504"
      },
      "source": [
        "Con las restricciones agregadas, el CTR estimado siempre aumentará a medida que aumente la calificación promedio o aumente el número de reseñas. Esto se hace asegurándose de que los calibradores y la cuadrícula tengan monoticinidad."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfniRZCHIvfK"
      },
      "source": [
        "### Retornos decrecientes\n",
        "\n",
        "[Los retornos decrecientes](https://en.wikipedia.org/wiki/Diminishing_returns) significan que la ganancia marginal de aumentar el valor de una determinada característica disminuirá a medida que aumentamos el valor. En nuestro caso esperamos que la función `num_reviews` siga este patrón, por lo que podemos configurar su calibrador en consecuencia. Observe que podemos descomponer los retornos decrecientes en dos condiciones suficientes:\n",
        "\n",
        "- el calibrador aumenta de forma monotonicinica y\n",
        "- el calibrador es cóncavo.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XQrM9BskY-wx"
      },
      "outputs": [],
      "source": [
        "feature_columns = [\n",
        "    tf.feature_column.numeric_column(\"num_reviews\"),\n",
        "    tf.feature_column.numeric_column(\"avg_rating\"),\n",
        "]\n",
        "model_config = tfl.configs.CalibratedLatticeConfig(\n",
        "    feature_configs=[\n",
        "        tfl.configs.FeatureConfig(\n",
        "            name=\"num_reviews\",\n",
        "            lattice_size=2,\n",
        "            monotonicity=\"increasing\",\n",
        "            pwl_calibration_convexity=\"concave\",\n",
        "            pwl_calibration_num_keypoints=20,\n",
        "        ),\n",
        "        tfl.configs.FeatureConfig(\n",
        "            name=\"avg_rating\",\n",
        "            lattice_size=2,\n",
        "            monotonicity=\"increasing\",\n",
        "            pwl_calibration_num_keypoints=20,\n",
        "        )\n",
        "    ])\n",
        "tfl_estimator = tfl.estimators.CannedClassifier(\n",
        "    feature_columns=feature_columns,\n",
        "    model_config=model_config,\n",
        "    feature_analysis_input_fn=feature_analysis_input_fn,\n",
        "    optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=LEARNING_RATE),\n",
        "    config=tf.estimator.RunConfig(tf_random_seed=42),\n",
        ")\n",
        "tfl_estimator.train(input_fn=train_input_fn)\n",
        "analyze_two_d_estimator(tfl_estimator, \"TF Lattice\")\n",
        "_ = save_and_visualize_lattice(tfl_estimator)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSmzHkPUo9u5"
      },
      "source": [
        "Observe cómo mejora la métrica de prueba al agregar la restricción de concavidad. El gráfico de predicción también se parece más a la línea base."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6CP2Ovapiu3"
      },
      "source": [
        "### Restricción de forma bidimensional: confianza\n",
        "\n",
        "Una calificación de 5 estrellas para un restaurante con solo una o dos reseñas probablemente no sea una calificación confiable (es posible que restaurante no sea realmente bueno), mientras que una calificación de 4 estrellas para un restaurante con cientos de reseñas es mucho más confiable (es posible que el restaurante sea bueno en este caso). Podemos ver que la cantidad de reseñas de un restaurante afecta la confianza que depositamos en su calificación promedio.\n",
        "\n",
        "Podemos usar restricciones de confianza de TFL para informar al modelo que el valor mayor (o menor) de una característica indica una mayor dependencia o confianza en otra característica. Esto se hace al establecer `reflects_trust_in` en la configuración de funciones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OA14j0erm6TJ"
      },
      "outputs": [],
      "source": [
        "feature_columns = [\n",
        "    tf.feature_column.numeric_column(\"num_reviews\"),\n",
        "    tf.feature_column.numeric_column(\"avg_rating\"),\n",
        "]\n",
        "model_config = tfl.configs.CalibratedLatticeConfig(\n",
        "    feature_configs=[\n",
        "        tfl.configs.FeatureConfig(\n",
        "            name=\"num_reviews\",\n",
        "            lattice_size=2,\n",
        "            monotonicity=\"increasing\",\n",
        "            pwl_calibration_convexity=\"concave\",\n",
        "            pwl_calibration_num_keypoints=20,\n",
        "            # Larger num_reviews indicating more trust in avg_rating.\n",
        "            reflects_trust_in=[\n",
        "                tfl.configs.TrustConfig(\n",
        "                    feature_name=\"avg_rating\", trust_type=\"edgeworth\"),\n",
        "            ],\n",
        "        ),\n",
        "        tfl.configs.FeatureConfig(\n",
        "            name=\"avg_rating\",\n",
        "            lattice_size=2,\n",
        "            monotonicity=\"increasing\",\n",
        "            pwl_calibration_num_keypoints=20,\n",
        "        )\n",
        "    ])\n",
        "tfl_estimator = tfl.estimators.CannedClassifier(\n",
        "    feature_columns=feature_columns,\n",
        "    model_config=model_config,\n",
        "    feature_analysis_input_fn=feature_analysis_input_fn,\n",
        "    optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=LEARNING_RATE),\n",
        "    config=tf.estimator.RunConfig(tf_random_seed=42),\n",
        ")\n",
        "tfl_estimator.train(input_fn=train_input_fn)\n",
        "analyze_two_d_estimator(tfl_estimator, \"TF Lattice\")\n",
        "model_graph = save_and_visualize_lattice(tfl_estimator)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "puvP9X8XxyRV"
      },
      "source": [
        "El siguiente gráfico presenta la función de cuadrícula entrenada. Debido a la restricción de confianza, se espera que los valores más grandes de `num_reviews` calibrados fuercen una pendiente más alta con respecto a `avg_rating` calibrado, lo que resultaría en un movimiento más significativo en la salida de la cuadrícula."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "both",
        "id": "RounEQebxxnA"
      },
      "outputs": [],
      "source": [
        "lat_mesh_n = 12\n",
        "lat_mesh_x, lat_mesh_y = tfl.test_utils.two_dim_mesh_grid(\n",
        "    lat_mesh_n**2, 0, 0, 1, 1)\n",
        "lat_mesh_fn = tfl.test_utils.get_hypercube_interpolation_fn(\n",
        "    model_graph.output_node.weights.flatten())\n",
        "lat_mesh_z = [\n",
        "    lat_mesh_fn([lat_mesh_x.flatten()[i],\n",
        "                 lat_mesh_y.flatten()[i]]) for i in range(lat_mesh_n**2)\n",
        "]\n",
        "trust_plt = tfl.visualization.plot_outputs(\n",
        "    (lat_mesh_x, lat_mesh_y),\n",
        "    {\"Lattice Lookup\": lat_mesh_z},\n",
        "    figsize=(6, 6),\n",
        ")\n",
        "trust_plt.title(\"Trust\")\n",
        "trust_plt.xlabel(\"Calibrated avg_rating\")\n",
        "trust_plt.ylabel(\"Calibrated num_reviews\")\n",
        "trust_plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKe3UHX6pUjw"
      },
      "source": [
        "### Calibradores de suavizado\n",
        "\n",
        "Ahora echemos un vistazo al calibrador de `avg_rating`. Aunque aumenta de forma monotonicica, los cambios en sus pendientes son abruptos y difíciles de interpretar. Eso sugiere que podríamos considerar suavizar este calibrador con una configuración de regularizador en `regularizer_configs`.\n",
        "\n",
        "Aquí aplicamos un regularizador `wrinkle` para reducir los cambios en la curvatura. También puedes usar el regularizador `laplacian` para aplanar el calibrador y el regularizador `hessian` para hacerlo más lineal.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qxFHH3hSpWfq"
      },
      "outputs": [],
      "source": [
        "feature_columns = [\n",
        "    tf.feature_column.numeric_column(\"num_reviews\"),\n",
        "    tf.feature_column.numeric_column(\"avg_rating\"),\n",
        "]\n",
        "model_config = tfl.configs.CalibratedLatticeConfig(\n",
        "    feature_configs=[\n",
        "        tfl.configs.FeatureConfig(\n",
        "            name=\"num_reviews\",\n",
        "            lattice_size=2,\n",
        "            monotonicity=\"increasing\",\n",
        "            pwl_calibration_convexity=\"concave\",\n",
        "            pwl_calibration_num_keypoints=20,\n",
        "            regularizer_configs=[\n",
        "                tfl.configs.RegularizerConfig(name=\"calib_wrinkle\", l2=1.0),\n",
        "            ],\n",
        "            reflects_trust_in=[\n",
        "                tfl.configs.TrustConfig(\n",
        "                    feature_name=\"avg_rating\", trust_type=\"edgeworth\"),\n",
        "            ],\n",
        "        ),\n",
        "        tfl.configs.FeatureConfig(\n",
        "            name=\"avg_rating\",\n",
        "            lattice_size=2,\n",
        "            monotonicity=\"increasing\",\n",
        "            pwl_calibration_num_keypoints=20,\n",
        "            regularizer_configs=[\n",
        "                tfl.configs.RegularizerConfig(name=\"calib_wrinkle\", l2=1.0),\n",
        "            ],\n",
        "        )\n",
        "    ])\n",
        "tfl_estimator = tfl.estimators.CannedClassifier(\n",
        "    feature_columns=feature_columns,\n",
        "    model_config=model_config,\n",
        "    feature_analysis_input_fn=feature_analysis_input_fn,\n",
        "    optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=LEARNING_RATE),\n",
        "    config=tf.estimator.RunConfig(tf_random_seed=42),\n",
        ")\n",
        "tfl_estimator.train(input_fn=train_input_fn)\n",
        "analyze_two_d_estimator(tfl_estimator, \"TF Lattice\")\n",
        "_ = save_and_visualize_lattice(tfl_estimator)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHpp4goLvuPi"
      },
      "source": [
        "Los calibradores ahora funcionan sin problemas y el CTR estimado general coincide mejor con la línea base. Esto se refleja tanto en la métrica de prueba como en los gráficos de contorno."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSUd6aFlpYz4"
      },
      "source": [
        "### Monotonicidad parcial para calibración categórica\n",
        "\n",
        "Hasta ahora hemos usado solo dos de las funciones numéricas del modelo. Aquí agregaremos una tercera función con una capa de calibración categórica. Nuevamente comenzamos configurando funciones ayudante para el trazado y el cálculo métrico."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5tLDKwTmjrLw"
      },
      "outputs": [],
      "source": [
        "def analyze_three_d_estimator(estimator, name):\n",
        "  # Extract validation metrics.\n",
        "  metric = estimator.evaluate(input_fn=val_input_fn)\n",
        "  print(\"Validation AUC: {}\".format(metric[\"auc\"]))\n",
        "  metric = estimator.evaluate(input_fn=test_input_fn)\n",
        "  print(\"Testing AUC: {}\".format(metric[\"auc\"]))\n",
        "\n",
        "  def three_d_pred(avg_ratings, num_reviews, dollar_rating):\n",
        "    results = estimator.predict(\n",
        "        tf.compat.v1.estimator.inputs.pandas_input_fn(\n",
        "            x=pd.DataFrame({\n",
        "                \"avg_rating\": avg_ratings,\n",
        "                \"num_reviews\": num_reviews,\n",
        "                \"dollar_rating\": dollar_rating,\n",
        "            }),\n",
        "            shuffle=False,\n",
        "        ))\n",
        "    return [x[\"logistic\"][0] for x in results]\n",
        "\n",
        "  figsize(11, 22)\n",
        "  plot_fns([(\"{} Estimated CTR\".format(name), three_d_pred),\n",
        "            (\"CTR\", click_through_rate)],\n",
        "           split_by_dollar=True)\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnPiqf4rq6kJ"
      },
      "source": [
        "Para involucrar la tercera función, `dollar_rating`, debemos recordar que las funciones categóricas requieren un tratamiento ligeramente diferente en TFL, tanto como columna de funciones como como configuración de funciones. Aquí aplicamos la restricción de monotonicidad parcial que establece que las salidas de los restaurantes \"DD\" deben ser mayores que las de los restaurantes \"D\" cuando todas las demás entradas son fijas. Esto se hace con la configuración `monotonicity` en la configuración de funciones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m-w7iGEEpgGt"
      },
      "outputs": [],
      "source": [
        "feature_columns = [\n",
        "    tf.feature_column.numeric_column(\"num_reviews\"),\n",
        "    tf.feature_column.numeric_column(\"avg_rating\"),\n",
        "    tf.feature_column.categorical_column_with_vocabulary_list(\n",
        "        \"dollar_rating\",\n",
        "        vocabulary_list=[\"D\", \"DD\", \"DDD\", \"DDDD\"],\n",
        "        dtype=tf.string,\n",
        "        default_value=0),\n",
        "]\n",
        "model_config = tfl.configs.CalibratedLatticeConfig(\n",
        "    feature_configs=[\n",
        "        tfl.configs.FeatureConfig(\n",
        "            name=\"num_reviews\",\n",
        "            lattice_size=2,\n",
        "            monotonicity=\"increasing\",\n",
        "            pwl_calibration_convexity=\"concave\",\n",
        "            pwl_calibration_num_keypoints=20,\n",
        "            regularizer_configs=[\n",
        "                tfl.configs.RegularizerConfig(name=\"calib_wrinkle\", l2=1.0),\n",
        "            ],\n",
        "            reflects_trust_in=[\n",
        "                tfl.configs.TrustConfig(\n",
        "                    feature_name=\"avg_rating\", trust_type=\"edgeworth\"),\n",
        "            ],\n",
        "        ),\n",
        "        tfl.configs.FeatureConfig(\n",
        "            name=\"avg_rating\",\n",
        "            lattice_size=2,\n",
        "            monotonicity=\"increasing\",\n",
        "            pwl_calibration_num_keypoints=20,\n",
        "            regularizer_configs=[\n",
        "                tfl.configs.RegularizerConfig(name=\"calib_wrinkle\", l2=1.0),\n",
        "            ],\n",
        "        ),\n",
        "        tfl.configs.FeatureConfig(\n",
        "            name=\"dollar_rating\",\n",
        "            lattice_size=2,\n",
        "            pwl_calibration_num_keypoints=4,\n",
        "            # Here we only specify one monotonicity:\n",
        "            # `D` resturants has smaller value than `DD` restaurants\n",
        "            monotonicity=[(\"D\", \"DD\")],\n",
        "        ),\n",
        "    ])\n",
        "tfl_estimator = tfl.estimators.CannedClassifier(\n",
        "    feature_columns=feature_columns,\n",
        "    model_config=model_config,\n",
        "    feature_analysis_input_fn=feature_analysis_input_fn,\n",
        "    optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=LEARNING_RATE),\n",
        "    config=tf.estimator.RunConfig(tf_random_seed=42),\n",
        ")\n",
        "tfl_estimator.train(input_fn=train_input_fn)\n",
        "analyze_three_d_estimator(tfl_estimator, \"TF Lattice\")\n",
        "_ = save_and_visualize_lattice(tfl_estimator)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdIzhYL79_Pp"
      },
      "source": [
        "Este calibrador categórico muestra la preferencia de la salida del modelo: DD &gt; D &gt; DDD &gt; DDDD, que es consistente con nuestra configuración. Observe que también hay una columna para los valores faltantes. Aunque no falta ninguna característica en nuestros datos de entrenamiento y prueba, el modelo nos proporciona una imputación del valor faltante en caso de que ocurra durante la entrega del modelo posterior.\n",
        "\n",
        "Aquí también trazamos el CTR previsto de este modelo que se condiciona con `dollar_rating`. Observe que todas las restricciones que requerimos se cumplen en cada uno de los sectores."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rh0H2b6l_rwZ"
      },
      "source": [
        "### Calibración de salida"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPb2ri4e7HXF"
      },
      "source": [
        "Para todos los modelos de TFL que entrenamos hasta ahora, la capa de cuadrícula (\"Lattice\" en el gráfico del modelo) genera directamente la predicción del modelo. A veces no estamos seguros de si la salida de la cuadrícula debe reescalarse para emitir salidas del modelo:\n",
        "\n",
        "- las funciones son recuentos $log$ mientras que las etiquetas son recuentos.\n",
        "- la cuadrícula está configurada para tener muy pocos vértices pero la distribución de etiquetas es relativamente complicada.\n",
        "\n",
        "En esos casos, podemos agregar otro calibrador entre la salida de la cuadrícula y la salida del modelo para aumentar la flexibilidad del modelo. Aquí agreguemos una capa de calibrador con 5 puntos clave al modelo que acabamos de construir. También agregamos un regularizador para el calibrador de salida para mantener la suavidad de la función.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k5Sg_gUj_0i4"
      },
      "outputs": [],
      "source": [
        "feature_columns = [\n",
        "    tf.feature_column.numeric_column(\"num_reviews\"),\n",
        "    tf.feature_column.numeric_column(\"avg_rating\"),\n",
        "    tf.feature_column.categorical_column_with_vocabulary_list(\n",
        "        \"dollar_rating\",\n",
        "        vocabulary_list=[\"D\", \"DD\", \"DDD\", \"DDDD\"],\n",
        "        dtype=tf.string,\n",
        "        default_value=0),\n",
        "]\n",
        "model_config = tfl.configs.CalibratedLatticeConfig(\n",
        "    output_calibration=True,\n",
        "    output_calibration_num_keypoints=5,\n",
        "    regularizer_configs=[\n",
        "        tfl.configs.RegularizerConfig(name=\"output_calib_wrinkle\", l2=0.1),\n",
        "    ],\n",
        "    feature_configs=[\n",
        "    tfl.configs.FeatureConfig(\n",
        "        name=\"num_reviews\",\n",
        "        lattice_size=2,\n",
        "        monotonicity=\"increasing\",\n",
        "        pwl_calibration_convexity=\"concave\",\n",
        "        pwl_calibration_num_keypoints=20,\n",
        "        regularizer_configs=[\n",
        "            tfl.configs.RegularizerConfig(name=\"calib_wrinkle\", l2=1.0),\n",
        "        ],\n",
        "        reflects_trust_in=[\n",
        "            tfl.configs.TrustConfig(\n",
        "                feature_name=\"avg_rating\", trust_type=\"edgeworth\"),\n",
        "        ],\n",
        "    ),\n",
        "    tfl.configs.FeatureConfig(\n",
        "        name=\"avg_rating\",\n",
        "        lattice_size=2,\n",
        "        monotonicity=\"increasing\",\n",
        "        pwl_calibration_num_keypoints=20,\n",
        "        regularizer_configs=[\n",
        "            tfl.configs.RegularizerConfig(name=\"calib_wrinkle\", l2=1.0),\n",
        "        ],\n",
        "    ),\n",
        "    tfl.configs.FeatureConfig(\n",
        "        name=\"dollar_rating\",\n",
        "        lattice_size=2,\n",
        "        pwl_calibration_num_keypoints=4,\n",
        "        # Here we only specify one monotonicity:\n",
        "        # `D` resturants has smaller value than `DD` restaurants\n",
        "        monotonicity=[(\"D\", \"DD\")],\n",
        "    ),\n",
        "])\n",
        "tfl_estimator = tfl.estimators.CannedClassifier(\n",
        "    feature_columns=feature_columns,\n",
        "    model_config=model_config,\n",
        "    feature_analysis_input_fn=feature_analysis_input_fn,\n",
        "    optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=LEARNING_RATE),\n",
        "    config=tf.estimator.RunConfig(tf_random_seed=42),\n",
        ")\n",
        "tfl_estimator.train(input_fn=train_input_fn)\n",
        "analyze_three_d_estimator(tfl_estimator, \"TF Lattice\")\n",
        "_ = save_and_visualize_lattice(tfl_estimator)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLOGDrYY0hH7"
      },
      "source": [
        "La métrica de prueba final y los gráficos muestran cómo el uso de restricciones de sentido común puede ayudar al modelo a evitar comportamientos inesperados y extrapolar mejor a todo el espacio de entrada."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "shape_constraints.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
