{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qN8P0AnTnAhh"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnUwFbCAKB2r"
      },
      "source": [
        "## Antes de empezar\n",
        "\n",
        "Para editar el bloc de notas de colaboración, vaya a \"File\" -&gt; \"Save a copy in Drive\" (\"Archivo\" -&gt; \"Guardar una copia en Drive\") y edite su copia.\n",
        "\n",
        "Antes de empezar, ejecute lo que se encuentra a continuación, para asegurarse de que el entorno esté preparado correctamente. Si no ve un mensaje de inicio, para más instrucciones, consulte la guía de [instalación](../install.md). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "both",
        "id": "ZrGitA_KnRO0"
      },
      "outputs": [],
      "source": [
        "#@title Upgrade tensorflow_federated and load TensorBoard\n",
        "#@test {\"skip\": true}\n",
        "!pip install --quiet --upgrade tensorflow-federated\n",
        "!pip install --quiet --upgrade nest-asyncio\n",
        "\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "%load_ext tensorboard\n",
        "\n",
        "import sys\n",
        "\n",
        "if not sys.warnoptions:\n",
        "    import warnings\n",
        "    warnings.simplefilter(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "both",
        "id": "8BKyHkMxKHfV"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "import collections\n",
        "from matplotlib import pyplot as plt\n",
        "from IPython.display import display, HTML, IFrame\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_federated as tff\n",
        "\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "def greetings():\n",
        "  display(HTML('<b><font size=\"6\" color=\"#ff00f4\">Greetings, virtual tutorial participants!</font></b>'))\n",
        "  return True\n",
        "l = tff.federated_computation(greetings)()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AftvNA5VMemJ"
      },
      "source": [
        "# TensorFlow federado para clasificación de imágenes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coAumH42q9nz"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td><a target=\"_blank\" href=\"https://www.tensorflow.org/federated/tutorials/federated_learning_for_image_classification\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver en TensorFlow.org</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/es-419/federated/openmined2020/openmined_conference_2020.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Ejecutar en Google Colab</a></td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/es-419/federated/openmined2020/openmined_conference_2020.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver fuente en GitHub</a>\n",
        "</td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zs2LgZBOMt4M"
      },
      "source": [
        "Experimentemos con el aprendizaje federado en una simulación. En este tutorial usamos el ejemplo de entrenamiento clásico MNIST para presentar la capa de API de aprendizaje federado (FL, por sus siglas en inglés) de TFF, `tff.learning`; un conjunto de interfaces que se puede utilizar para realizar distintos tipos de tareas de aprendizaje federado, como un entrenamiento federado, con respecto a los modelos implementados por TensorFlow provistos por usuarios.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dN7n8RS7-rLR"
      },
      "source": [
        "# Estructura del tutorial\n",
        "\n",
        "Entrenaremos un modelo para clasificar imágenes con el conjunto de datos clásico MNIST y aplicaremos el aprendizaje de red neuronal para clasificar dígitos de imágenes. En este caso, simularemos aprendizaje federado con los datos de entrenamiento distribuidos en diferentes dispositivos.\n",
        "\n",
        "<p><b>Secciones</b></p>\n",
        "\n",
        "1. Carga de las bibliotecas de TFF.\n",
        "2. Exploración y preprocesamiento del conjunto de datos EMNIST federado.\n",
        "3. Creación de un modelo.\n",
        "4. Configuración del proceso del cálculo de promedio federado para entrenamiento.\n",
        "5. Análisis de las métricas de entrenamiento.\n",
        "6. Configuración del cálculo de evaluación federada.\n",
        "7. Análisis de las métricas de evaluación.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Cyy2AWbLMKj"
      },
      "source": [
        "## Preparación de los datos de entrada\n",
        "\n",
        "Empecemos con los datos. Para poner en práctica el aprendizaje federado es necesario contar con un conjunto de datos federados; es decir, una colección de datos de múltiples usuarios. Los datos federados normalmente son no [i.i.d.](https://en.wikipedia.org/wiki/Independent_and_identically_distributed_random_variables), lo que presenta un  grupo de problemas particulares. Normalmente, los usuarios tienen diferentes distribuciones de datos que dependen de los patrones de uso.\n",
        "\n",
        "A fin de facilitar la experimentación, sembramos el repositorio de TFF con algunos conjuntos de datos.\n",
        "\n",
        "A continuación, compartimos cómo podemos cargar nuestro conjunto de datos de muestra."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bP6WDENHSSZ9"
      },
      "outputs": [],
      "source": [
        "# Code for loading federated data from TFF repository\n",
        "emnist_train, emnist_test = tff.simulation.datasets.emnist.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yeX8BKgPfeFw"
      },
      "source": [
        "Los conjuntos de datos devueltos por `load_data()` son instancias de `tff.simulation.datasets.ClientData`, una interfaz que permite enumerar los conjuntos de usuarios para construir un `tf.data.Dataset` que representa los datos de un usuario en particular y para consultar la estructura de elementos individuales.\n",
        "\n",
        "Exploremos el conjunto de datos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kN4-U5nJgKig"
      },
      "outputs": [],
      "source": [
        "len(emnist_train.client_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZyCzIrSegT62"
      },
      "outputs": [],
      "source": [
        "# Let's look at the shape of our data\n",
        "example_dataset = emnist_train.create_tf_dataset_for_client(\n",
        "    emnist_train.client_ids[0])\n",
        "\n",
        "example_dataset.element_spec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EsvSXGEMgd9G"
      },
      "outputs": [],
      "source": [
        "# Let's select an example dataset from one of our simulated clients\n",
        "example_dataset = emnist_train.create_tf_dataset_for_client(\n",
        "    emnist_train.client_ids[0])\n",
        "\n",
        "# Your code to get an example element from one client:\n",
        "example_element = next(iter(example_dataset))\n",
        "\n",
        "example_element['label'].numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OmLV0nfMg98V"
      },
      "outputs": [],
      "source": [
        "plt.imshow(example_element['pixels'].numpy(), cmap='gray', aspect='equal')\n",
        "plt.grid(False)\n",
        "_ = plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-3KUf0kC8TN"
      },
      "source": [
        "**Exploración de los datos que no tienen una distribución <em>iid</em>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "veWNAxdQfrgZ"
      },
      "outputs": [],
      "source": [
        "## Example MNIST digits for one client\n",
        "f = plt.figure(figsize=(20,4))\n",
        "j = 0\n",
        "\n",
        "for e in example_dataset.take(40):\n",
        "  plt.subplot(4, 10, j+1)\n",
        "  plt.imshow(e['pixels'].numpy(), cmap='gray', aspect='equal')\n",
        "  plt.axis('off')\n",
        "  j += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_XJRWDFWniik"
      },
      "outputs": [],
      "source": [
        "# Number of examples per layer for a sample of clients\n",
        "f = plt.figure(figsize=(12,7))\n",
        "f.suptitle(\"Label Counts for a Sample of Clients\")\n",
        "for i in range(6):\n",
        "  ds = emnist_train.create_tf_dataset_for_client(emnist_train.client_ids[i])\n",
        "  k = collections.defaultdict(list)\n",
        "  for e in ds:\n",
        "    k[e['label'].numpy()].append(e['label'].numpy())\n",
        "  plt.subplot(2, 3, i+1)\n",
        "  plt.title(\"Client {}\".format(i))\n",
        "  for j in range(10):\n",
        "    plt.hist(k[j], density=False, bins=[0,1,2,3,4,5,6,7,8,9,10])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JOUI4zW9LQNH"
      },
      "outputs": [],
      "source": [
        "# Let's play around with the emnist_train dataset.\n",
        "# Let's explore the non-iid charateristic of the example data.\n",
        "\n",
        "for i in range(5):\n",
        "  ds = emnist_train.create_tf_dataset_for_client(emnist_train.client_ids[i])\n",
        "  k = collections.defaultdict(list)\n",
        "  for e in ds:\n",
        "    k[e['label'].numpy()].append(e['pixels'].numpy())\n",
        "  f = plt.figure(i, figsize=(12,5))\n",
        "  f.suptitle(\"Client #{}'s Mean Image Per Label\".format(i))\n",
        "  for j in range(10):\n",
        "    mn_img = np.mean(k[j],0)\n",
        "    plt.subplot(2, 5, j+1)\n",
        "    plt.imshow(mn_img.reshape((28,28)))#,cmap='gray') \n",
        "    plt.axis('off')\n",
        "\n",
        "# Each client has different mean images -- each client will be nudging the model\n",
        "# in their own directions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMd01egqy9we"
      },
      "source": [
        "### Preprocesamiento de los datos\n",
        "\n",
        "Como los datos ya son un `tf.data.Dataset`, el preprocesamiento se puede cumplir con transformaciones de conjuntos de datos. [Consulte aquí](https://www.tensorflow.org/guide/data) por más detalle sobre estas transformaciones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cyG_BMraSuu_"
      },
      "outputs": [],
      "source": [
        "NUM_CLIENTS = 10\n",
        "NUM_EPOCHS = 5\n",
        "BATCH_SIZE = 20\n",
        "SHUFFLE_BUFFER = 100\n",
        "PREFETCH_BUFFER=10\n",
        "\n",
        "def preprocess(dataset):\n",
        "\n",
        "  def batch_format_fn(element):\n",
        "    \"\"\"Flatten a batch `pixels` and return the features as an `OrderedDict`.\"\"\"\n",
        "    return collections.OrderedDict(\n",
        "        x=tf.reshape(element['pixels'], [-1, 784]),\n",
        "        y=tf.reshape(element['label'], [-1, 1]))\n",
        "\n",
        "  return dataset.repeat(NUM_EPOCHS).shuffle(SHUFFLE_BUFFER).batch(\n",
        "      BATCH_SIZE).map(batch_format_fn).prefetch(PREFETCH_BUFFER)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9LXykN_jlJw"
      },
      "source": [
        "Verifiquemos si funcionó."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VChB7LMQjkYz"
      },
      "outputs": [],
      "source": [
        "preprocessed_example_dataset = preprocess(example_dataset)\n",
        "\n",
        "sample_batch = tf.nest.map_structure(lambda x: x.numpy(),\n",
        "                                     next(iter(preprocessed_example_dataset)))\n",
        "\n",
        "sample_batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGsMvRQt9Agl"
      },
      "source": [
        "Aquí, presentamos una función ayudante simple que construirá una lista de conjuntos de datos (a partir de un conjunto dado de usuarios) como entrada a una ronda de entrenamiento o evaluación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_PHMvHAI9xVc"
      },
      "outputs": [],
      "source": [
        "def make_federated_data(client_data, client_ids):\n",
        "  return [\n",
        "      preprocess(client_data.create_tf_dataset_for_client(x))\n",
        "      for x in client_ids\n",
        "  ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0M9PfjOtAVqw"
      },
      "source": [
        "Ahora, ¿cómo elegimos a los clientes?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GZ6NYHxB8xer"
      },
      "outputs": [],
      "source": [
        "sample_clients = emnist_train.client_ids[0:NUM_CLIENTS]\n",
        "\n",
        "# Your code to get the federated dataset here for the sampled clients:\n",
        "federated_train_data = make_federated_data(emnist_train, sample_clients)\n",
        "\n",
        "print('Number of client datasets: {l}'.format(l=len(federated_train_data)))\n",
        "print('First dataset: {d}'.format(d=federated_train_data[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOxq4tbi9m8-"
      },
      "source": [
        "## Creación de un modelo con Keras\n",
        "\n",
        "Si usa Keras, probablemente ya tenga el código que construye un modelo Keras. A continuación, mostramos un ejemplo de un modelo simple que bastará para nuestro propósito."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LYCsJGJFWbqt"
      },
      "outputs": [],
      "source": [
        "def create_keras_model():\n",
        "  return tf.keras.models.Sequential([\n",
        "      tf.keras.layers.InputLayer(input_shape=(784,)),\n",
        "      tf.keras.layers.Dense(10, kernel_initializer='zeros'),\n",
        "      tf.keras.layers.Softmax(),\n",
        "  ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0214iKjCTyX"
      },
      "source": [
        "**Entrenamiento centralizado con Keras**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g5XW_p4iLlJ2"
      },
      "outputs": [],
      "source": [
        "## Centralized training with keras ---------------------------------------------\n",
        "\n",
        "# This is separate from the TFF tutorial, and demonstrates how to train a\n",
        "# Keras model in a centralized fashion (contrasting training in a federated env)\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# Preprocess the data (these are NumPy arrays)\n",
        "x_train = x_train.reshape(60000, 784).astype(\"float32\") / 255\n",
        "\n",
        "y_train = y_train.astype(\"float32\")\n",
        "\n",
        "mod = create_keras_model()\n",
        "mod.compile(\n",
        "    optimizer=tf.keras.optimizers.RMSprop(),\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]\n",
        ")\n",
        "h = mod.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    batch_size=64,\n",
        "    epochs=2\n",
        ")\n",
        "\n",
        "# ------------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6pzsjoJQ2_D"
      },
      "source": [
        "**Entrenamiento federado con un modelo Keras**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHdraKFH4OU2"
      },
      "source": [
        "A fin de usar cualquier modelo con TFF, hay que encapsularlo (<em>wrap</em>) en una instancia de la interfaz del `tff.learning.Model`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mA8cJoGE3Rh_"
      },
      "source": [
        "[Aquí](https://www.tensorflow.org/api_docs/python/tf/keras/metrics) hallará más métricas Keras para agregar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q3ynrxd53HzY"
      },
      "outputs": [],
      "source": [
        "def model_fn():\n",
        "  # We _must_ create a new model here, and _not_ capture it from an external\n",
        "  # scope. TFF will call this within different graph contexts.\n",
        "  keras_model = create_keras_model()\n",
        "  return tff.learning.from_keras_model(\n",
        "      keras_model,\n",
        "      input_spec=preprocessed_example_dataset.element_spec,\n",
        "      loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJ5E3O18_JZ6"
      },
      "source": [
        "## Entrenamiento del modelo sobre datos federados\n",
        "\n",
        "Ahora que tenemos un modelo encapsulado como `tff.learning.Model` para usarlo con TFF, podemos dejar que TFF construya un algoritmo de promedio federado \"Federated Averaging\" si invocamos la función ayudante `tff.learning.build_federated_averaging_process`, como se muestra a continuación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sk6mjOfycX5N"
      },
      "outputs": [],
      "source": [
        "iterative_process = tff.learning.build_federated_averaging_process(\n",
        "    model_fn,\n",
        "    client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.02),\n",
        "    # Add server optimizer here!\n",
        "    server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1.0))\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8FpvN2n67sm"
      },
      "source": [
        "¿Qué acaba de suceder? TFF ha construido un par de *cálculos federados* y los empaquetó en un `tff.templates.IterativeProcess` en los cuales estos cálculos se encuentran en forma de un par de propiedades `initialize` y `next`.\n",
        "\n",
        "Por lo general, un proceso iterativo será provocado por un bucle de control como el siguiente:\n",
        "\n",
        "```\n",
        "def initialize():\n",
        "  ...\n",
        "\n",
        "def next(state):\n",
        "  ...\n",
        "\n",
        "iterative_process = IterativeProcess(initialize, next)\n",
        "state = iterative_process.initialize()\n",
        "for round in range(num_rounds):\n",
        "  state = iterative_process.next(state)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1gbHQ_7BiyT"
      },
      "source": [
        "Invoquemos el cálculo `initialize` para construir el estado del servidor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6cagCWlZmcch"
      },
      "outputs": [],
      "source": [
        "state = iterative_process.initialize()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjjxTx9e_rMd"
      },
      "source": [
        "El segundo par de cálculos federados, `next`, representa a una ronda simple de cálculo de promedio federado de un modelo nuevo actualizado en el servidor, que está compuesta por el envío del estado del servidor (incluidos los parámetros del modelo) a los clientes, el entrenamiento en el dispositivo sobre sus datos locales, las actualizaciones del modelo de recolección y el cálculo del promedio y la producción.\n",
        "\n",
        "Ejecutemos una ronda simple de entrenamiento y observemos los resultados. Podemos usar los datos federados que ya hemos generado (arriba) para una muestra de usuarios."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F3M_W9dDE6Tm"
      },
      "outputs": [],
      "source": [
        "# Run one single round of training.\n",
        "state, metrics = iterative_process.next(state, federated_train_data)\n",
        "print('round  1, metrics={}'.format(metrics['train']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmhReXt9G4A5"
      },
      "source": [
        "Ejecutemos algunas rondas más. Tal como lo señalamos antes, normalmente en esta instancia, elegiríamos un subconjunto de los datos de simulación a partir de una muestra de usuarios seleccionada de forma aleatoria para cada ronda, a fin de simular una implementación realista en la cual los usuarios vienen y van continuamente. Pero en estas notas interactivas, con propósito demostrativo, simplemente reutilizaremos los mismos usuarios, para que el sistema converja rápidamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qrJkQuCRJP9C"
      },
      "outputs": [],
      "source": [
        "NUM_ROUNDS = 11\n",
        "for round_num in range(2, NUM_ROUNDS):\n",
        "  state, metrics = iterative_process.next(state, federated_train_data)\n",
        "  print('round {:2d}, metrics={}'.format(round_num, metrics['train']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "joHYzn9jcs0Y"
      },
      "source": [
        "La pérdida de entrenamiento disminuye después de cada ronda de entrenamiento federado. Es señal de que el modelo está convergiendo. Hay algunas salvedades importantes relacionadas con estas métricas de entrenamiento, pero para conocerlas, consulte más adelante la sección *Evaluación* en este tutorial."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruSHJl1IjhNf"
      },
      "source": [
        "##Se muestran las métricas del modelo en TensorBoard. Luego, observemos las métricas de estos cálculos federados en TensorBoard.\n",
        "\n",
        "Comencemos por crear un directorio y el escritor de resúmenes correspondiente en el que se redactarán las métricas.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E3QUBK41lWDW"
      },
      "outputs": [],
      "source": [
        "#@test {\"skip\": true}\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "logdir = \"/tmp/logs/scalars/training/\"\n",
        "if os.path.exists(logdir):\n",
        "  shutil.rmtree(logdir)\n",
        "\n",
        "# Your code to create a summary writer:\n",
        "summary_writer = tf.summary.create_file_writer(logdir)\n",
        "\n",
        "state = iterative_process.initialize()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-2aGxUlzS_J"
      },
      "source": [
        "Grafiquemos las métricas escalares relevantes con el mismo escritor de resúmenes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JZtr4_8lzN-V"
      },
      "outputs": [],
      "source": [
        "#@test {\"skip\": true}\n",
        "with summary_writer.as_default():\n",
        "  for round_num in range(1, NUM_ROUNDS):\n",
        "    state, metrics = iterative_process.next(state, federated_train_data)\n",
        "    for name, value in metrics['train'].items():\n",
        "      tf.summary.scalar(name, value, step=round_num)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUouyAHG0Mk8"
      },
      "source": [
        "Comencemos por TensorBoard, con el directorio de registros raíz especificado arriba. La carga de los datos puede demorar algunos segundos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "urYYcmA9089p"
      },
      "outputs": [],
      "source": [
        "#@test {\"skip\": true}\n",
        "%tensorboard --logdir /tmp/logs/scalars/ --port=0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jejrFEVP1EDs"
      },
      "source": [
        "A fin de ver las métricas de evaluación del mismo modo, se puede crear una carpeta de evaluación por separado, como \"logs/scalars/eval\", para escribir en TensorBoard."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7lz59lMJ0kj"
      },
      "source": [
        "## Evaluación\n",
        "\n",
        "Para llevar a cabo la evaluación sobre los datos federados, se puede construir otro *cálculo federado* diseñado para este propósito, con la función `tff.learning.build_federated_evaluation` y pasar el constructor del modelo como un argumento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nRiXyqnXM2VO"
      },
      "outputs": [],
      "source": [
        "# Construct federated evaluation computation here:\n",
        "evaluation = tff.learning.build_federated_evaluation(model_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SpfgdNDoRjPy"
      },
      "source": [
        "Ahora compilemos una muestra de prueba de datos federados y volvamos a ejecutar la evaluación de los datos de prueba. Los datos provendrán de una muestra diferente de usuarios y de un conjunto de datos retenidos (<em>held-out</em>) distintivos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "in8vProVNc04"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "shuffled_ids = emnist_test.client_ids.copy()\n",
        "random.shuffle(shuffled_ids)\n",
        "sample_clients = shuffled_ids[0:NUM_CLIENTS]\n",
        "\n",
        "federated_test_data = make_federated_data(emnist_test, sample_clients)\n",
        "\n",
        "len(federated_test_data), federated_test_data[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ty-ZwfE0NJfV"
      },
      "outputs": [],
      "source": [
        "# Run evaluation on the test data here, using the federated model produced from \n",
        "# training:\n",
        "test_metrics = evaluation(state.model, federated_test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e5fGtIJYNqYH"
      },
      "outputs": [],
      "source": [
        "str(test_metrics)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67vYxrDWzRcj"
      },
      "source": [
        "De este modo, se concluye con el tutorial. Le aconsejamos jugar con distintos parámetros (p. ej., los tamaños de los lotes, la cantidad de usuarios, las épocas, las tasas de aprendizaje, etc.), para modificar el código que figura arriba a fin de simular el entrenamiento con muestras aleatorias de usuarios en cada ronda. También le recomendamos explorar los otros tutoriales que hemos desarrollado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Zv28F7QLo8O"
      },
      "source": [
        "# Creación de los propios algoritmos de aprendizaje federado\n",
        "\n",
        "En los tutoriales anteriores aprendimos a configurar las canalizaciones de los datos y del modelo. Además las usamos para realizar entrenamientos federados con la API `tff.learning` API.\n",
        "\n",
        "Por supuesto, esto es solamente la punta del iceberg en la investigación sobre el aprendizaje federado. En este tutorial analizaremos cómo implementar los algoritmos de aprendizaje federado *sin* delegar a la API `tff.learning`. Con este tutorial, pretendemos lograr lo siguiente:\n",
        "\n",
        "**Objetivos:**\n",
        "\n",
        "- Entender la estructura general de los algoritmos de aprendizaje federado.\n",
        "- Explorar el *núcleo federado* de TFF.\n",
        "- Usar el núcleo federado para implementar directamente el cálculo del promedio federado.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQ_N9XbULo8P"
      },
      "source": [
        "## Preparación de los datos de entrada\n",
        "\n",
        "Primero, cargamos y preprocesamos el conjunto de datos EMNIST incluido en TFF. Básicamente usamos el mismo código que se utilizó en el primer tutorial."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-WdnFluLLo8P"
      },
      "outputs": [],
      "source": [
        "emnist_train, emnist_test = tff.simulation.datasets.emnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Blrh8zJgLo8R"
      },
      "outputs": [],
      "source": [
        "NUM_CLIENTS = 10\n",
        "BATCH_SIZE = 20\n",
        "\n",
        "def preprocess(dataset):\n",
        "\n",
        "  def batch_format_fn(element):\n",
        "    \"\"\"Flatten a batch of EMNIST data and return a (features, label) tuple.\"\"\"\n",
        "    return (tf.reshape(element['pixels'], [-1, 784]), \n",
        "            tf.reshape(element['label'], [-1, 1]))\n",
        "\n",
        "  return dataset.batch(BATCH_SIZE).map(batch_format_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-vYM_IT7Lo8W"
      },
      "outputs": [],
      "source": [
        "client_ids = np.random.choice(emnist_train.client_ids, size=NUM_CLIENTS, replace=False)\n",
        "\n",
        "federated_train_data = [preprocess(emnist_train.create_tf_dataset_for_client(x))\n",
        "  for x in client_ids\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNO_Y9j_Lo8X"
      },
      "source": [
        "## Preparación del modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJ0I89ixz8yV"
      },
      "source": [
        "Usamos el mismo modelo del primer tutorial, que tiene una sola capa oculta, seguida por una capa <em>softmax</em>."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yfld4oFNLo8Y"
      },
      "outputs": [],
      "source": [
        "def create_keras_model():\n",
        "  return tf.keras.models.Sequential([\n",
        "      tf.keras.layers.InputLayer(input_shape=(784,)),\n",
        "      tf.keras.layers.Dense(10, kernel_initializer='zeros'),\n",
        "      tf.keras.layers.Softmax(),\n",
        "  ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLln0Q8G0Bky"
      },
      "source": [
        "Encapsulamos (wrap) este modelo Keras como un `tff.learning.Model`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SPwbipTNLo8a"
      },
      "outputs": [],
      "source": [
        "def model_fn():\n",
        "  keras_model = create_keras_model()\n",
        "  return tff.learning.from_keras_model(\n",
        "      keras_model,\n",
        "      input_spec=federated_train_data[0].element_spec,\n",
        "      loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPOWP2JjsfTk"
      },
      "source": [
        "# Personalización del algoritmo de aprendizaje federado\n",
        "\n",
        "Si bien la API `tff.learning` permite que uno cree muchas variantes del cálculo del promedio federado, hay otros algoritmos federados que no se adaptan perfectamente a este marco de trabajo. Por ejemplo, tal vez le convenga agregar algoritmos de regularización, recorte (<em>clipping</em>) u otros más complicados como el [entrenamiento GAN federado](https://github.com/google-research/federated/blob/master/gans). Probablemente, por otra parte, lo que le resulte interesante sea el [análisis federado](https://ai.googleblog.com/2020/05/federated-analytics-collaborative-data.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50N36Zz8qyY-"
      },
      "source": [
        "Para estos algoritmos más avanzados, deberemos escribir nuestro propio algoritmo personalizado de aprendizaje federado.\n",
        "\n",
        "En general, los algoritmos de aprendizaje federado están compuestos por cuatro partes principales:\n",
        "\n",
        "1. Un paso para la emisión (<em>broadcast</em>) del servidor al cliente.\n",
        "2. Un paso para la actualización del cliente local.\n",
        "3. Un paso para la carga del cliente al servidor.\n",
        "4. Un paso para la actualización del servidor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jH8s0GRdQt3b"
      },
      "source": [
        "En TFF, un algoritmo federado, normalmente, está representado por un `IterativeProcess`. Simplemente, es una clase que contiene las funciones `initialize_fn` y `next_fn`. <code>initialize_fn</code> se usará para inicializar el servidor y <code>next_fn</code> realizará una ronda de comunicación del cálculo de promedio federado. Escribamos un esquema sobre cómo debería lucir de nuestro proceso iterativo para FedAvg.\n",
        "\n",
        "Primero, hay una función para inicializar que simplemente crea `tff.learning.Model` y devuelve sus pesos entrenables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ylLpRa7T5DDh"
      },
      "outputs": [],
      "source": [
        "def initialize_fn():\n",
        "  model = model_fn()\n",
        "  return model.weights.trainable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nb1-XAK8fB2A"
      },
      "source": [
        "Esta función tiene buen aspecto, pero como verá más adelante, deberemos hacerle una pequeña modificación para convertirla en un cálculo de TFF.\n",
        "\n",
        "También nos convendrá realizar el esquema de `next_fn`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IeHN-XLZfMso"
      },
      "outputs": [],
      "source": [
        "def next_fn(server_weights, federated_dataset):\n",
        "  # Broadcast the server weights to the clients.\n",
        "  server_weights_at_client = broadcast(server_weights)\n",
        "\n",
        "  # Each client computes their updated weights.\n",
        "  client_weights = client_update(federated_dataset, server_weights_at_client)\n",
        "\n",
        "  # The server averages these updates.\n",
        "  mean_client_weights = mean(client_weights)\n",
        "\n",
        "  # The server updates its model.\n",
        "  server_weights = server_update(mean_client_weights)\n",
        "\n",
        "  return server_weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWXvjXPWeujU"
      },
      "source": [
        "Centrémonos en implementar estos cuatro componentes por separado. Primero, enfoquémonos en las partes que se pueden implementar en TensorFlow puro, a saber, los pasos relacionados con el cliente y el servidor.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yKS4VkALo8g"
      },
      "source": [
        "## Bloques de TensorFlow "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxpNYucgLo8g"
      },
      "source": [
        "### Actualización del cliente\n",
        "\n",
        "Usaremos nuestro `tff.learning.Model` para hacer el entrenamiento del cliente, esencialmente, del mismo modo en que se entrenaría un modelo de TF. En particular, usaremos `tf.GradientTape` para calcular el gradiente en lotes de datos y luego aplicarlo con un `client_optimizer`.\n",
        "\n",
        "Tenga en cuenta que cada instancia de `tff.learning.Model` tiene un atributo de `weights` con dos subatributos:\n",
        "\n",
        "- `trainable`: una lista de tensores correspondientes a las capas entrenables.\n",
        "- `non_trainable`: una lista de tensores correspondientes a las capas no entrenables.\n",
        "\n",
        "Para cumplir con nuestro objetivo, solamente usaremos pesos entrenables (ya que nuestro modelo únicamente tiene los de este tipo).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c5rHPKreLo8g"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def client_update(model, dataset, server_weights, client_optimizer):\n",
        "  \"\"\"Performs training (using the server model weights) on the client's dataset.\"\"\"\n",
        "  # Initialize the client model with the current server weights.\n",
        "  client_weights = model.weights.trainable\n",
        "  # Assign the server weights to the client model.\n",
        "  tf.nest.map_structure(lambda x, y: x.assign(y),\n",
        "                        client_weights, server_weights)\n",
        "\n",
        "  # Use the client_optimizer to update the local model.\n",
        "  for batch in dataset:\n",
        "    with tf.GradientTape() as tape:\n",
        "      # Compute a forward pass on the batch of data\n",
        "      outputs = model.forward_pass(batch)\n",
        "\n",
        "    # Compute the corresponding gradient\n",
        "    grads = tape.gradient(outputs.loss, client_weights)\n",
        "    grads_and_vars = zip(grads, client_weights)\n",
        "\n",
        "    # Apply the gradient using a client optimizer.\n",
        "    client_optimizer.apply_gradients(grads_and_vars)\n",
        "\n",
        "  return client_weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pP0D9XtoLo8i"
      },
      "source": [
        "### Actualización del servidor\n",
        "\n",
        "Para la actualización del servidor se necesitará incluso menos esfuerzo. Implementaremos el cálculo de promedios federados \"vainilla\", en el que los pesos del modelo del servidor se reemplazan por el promedio de los pesos del modelo del cliente. Una vez más, solamente nos centraremos en los pesos entrenables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rYxErLvHLo8i"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def server_update(model, mean_client_weights):\n",
        "  \"\"\"Updates the server model weights as the average of the client model weights.\"\"\"\n",
        "  model_weights = model.weights.trainable\n",
        "  # Assign the mean client weights to the server model.\n",
        "  tf.nest.map_structure(lambda x, y: x.assign(y),\n",
        "                        model_weights, mean_client_weights)\n",
        "  return model_weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddCklfWlVr1U"
      },
      "source": [
        "Tenga en cuenta que para el fragmento anterior es claramente un exceso; ya que, sencillamente, se podría simplificar con la devolución de `mean_client_weights`. Sin embargo, en las implementaciones más avanzadas del cálculo de promedio federado se usa `mean_client_weights` con técnicas más sofisticadas, como <em>momentum</em> o adaptabilidad."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KuP9g6RFLo8k"
      },
      "source": [
        "Hasta el momento, solamente hemos escrito código puro de TensorFlow. El motivo es el diseño, ya que TFF permite usar gran parte del código de TensorFlow con el que ya estamos familiarizados. Sin embargo, deberá especificar la *lógica de orquestación*; es decir, la que dicta lo que el servidor emite (<em>broadcast</em>) al cliente y que el cliente carga en el servidor.\n",
        "\n",
        "El <em>núcleo federado</em> de TFF será indispensable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CgFLVPgLo8l"
      },
      "source": [
        "# Introducción al núcleo federado\n",
        "\n",
        "El núcleo federado (FC, por sus siglas en inglés) es un conjunto de interfaces de bajo nivel que sirve como base para la API `tff.learning`. Sin embargo, estas interfaces no se limitan al aprendizaje. De hecho, se pueden usar para análisis y muchos otros cálculos de datos distribuidos.\n",
        "\n",
        "A un alto nivel, el núcleo federado es un entorno de desarrollo que permite expresar de manera compacta la lógica de programación para combinar código de TensorFlow con los operadores de comunicación distribuidos (como las sumas y las emisiones distribuidas). El objetivo es brindarles a los investigadores y especialistas el control explícito de la comunicación distribuida en sus sistemas, sin requerir de otros detalles para la implementación (tales como la especificación de los intercambios de mensajes de red punto a punto).\n",
        "\n",
        "Un punto clave es que TFF está diseñado para la preservación de la privacidad. Por lo tanto, permite el control explícito del sitio donde residen los datos, para prevenir la acumulación indeseada de datos en el lugar del servidor centralizado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYinjNqZLo8l"
      },
      "source": [
        "## Datos federados\n",
        "\n",
        "Del mismo modo que el concepto de \"tensor\" en TensorFlow es fundamental, el concepto de los \"datos federados\" es clave en TFF. Se refiere a una colección de elementos de datos alojados en un grupo de dispositivos en un sistema distribuido (p. ej., las bases de datos de clientes o los pesos del modelo del servidor). La colección entera de valores de todos los dispositivos se representa con un solo *valor federado*.\n",
        "\n",
        "Por ejemplo, supongamos que hay dispositivos clientes y que cada uno tiene un flotante que representa la temperatura de un sensor. Esos flotantes se pueden representar como *flotante federado* de la siguiente manera:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7EJY0MHpLo8l"
      },
      "outputs": [],
      "source": [
        "federated_float_on_clients = tff.type_at_clients(tf.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSQAXD0FLo8n"
      },
      "source": [
        "Los tipos federados son especificados por un tipo de `T` de los miembros que lo componen (p. ej., `tf.float32`) y un grupo de dispositivos `G`. Nos centraremos en aquellos casos en que `G` es `tff.CLIENTS` o `tff.SERVER`. Un tipo federado como tal se representa con `{T}@G`, como se muestra a continuación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6mlPgubJLo8n"
      },
      "outputs": [],
      "source": [
        "str(federated_float_on_clients)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjAQytkeLo8o"
      },
      "source": [
        "¿Por qué nos interesan tanto las ubicaciones? El objetivo clave de TFF es el de facilitar la escritura de código que se podría implementar en un sistema distribuido real. Significa que es vital razonar con respecto a qué subconjuntos de dispositivos ejecutan qué códigos y dónde residen las diferentes porciones de datos.\n",
        "\n",
        "TFF se centra en tres cosas: en los *datos*, en dónde se *ubican* los datos y en cómo se *transforman* esos datos. Las primeras dos se encuentran encapsuladas dentro de los tipos federados, mientras que la última, en *cálculos federados*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLT2FmVMLo8p"
      },
      "source": [
        "## Cálculos federados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XwDC1vTLo8p"
      },
      "source": [
        "TFF es un entorno de programación funcional fuertemente tipado cuyas unidades básicas son *cálculos federados*. Son porciones de lógica que aceptan valores federados como entrada y devuelven valores federados como salida.\n",
        "\n",
        "Por ejemplo, supongamos que quisiéramos calcular el promedio de temperaturas en los sensores de nuestro cliente. Podríamos definir lo siguiente (con nuestro flotante federado):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IfwXDNR1Lo8p"
      },
      "outputs": [],
      "source": [
        "@tff.federated_computation(tff.type_at_clients(tf.float32))\n",
        "def get_average_temperature(client_temperatures):\n",
        "  return tff.federated_mean(client_temperatures)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSgs6Te5Lo8r"
      },
      "source": [
        "Uno podría preguntarse, en qué difiere esto del decorador `tf.function` de TensorFlow. La respuesta determinante es que el código generado por `tff.federated_computation` no es un código de TensorFlow ni de Python. Es una especificación de un sistema distribuido en un *lenguaje pegamento* interno independiente de plataformas.\n",
        "\n",
        "Si bien es cierto que puede sonar complicado, se puede pensar en los cálculos TFF como funciones con firmas de tipo bien definidas. Estas firmas de tipo se pueden consultar directamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wAG1eDlULo8r"
      },
      "outputs": [],
      "source": [
        "str(get_average_temperature.type_signature)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TveOYFfuLo8s"
      },
      "source": [
        "Este `tff.federated_computation` acepta argumentos del tipo federado `<float32>@CLIENTS` y devuelve valores del mismo tipo `<float32>@SERVER`. Los cálculos federados también pueden ir de servidor a cliente, de cliente a cliente o de servidor a servidor. Los cálculos federados además se pueden componer como las funciones normales, siempre y cuando haya coincidencia entre las firmas de tipo.\n",
        "\n",
        "Para facilitar el desarrollo, TFF permite invocar un `tff.federated_computation` como una función Python. Por ejemplo, podemos llamar lo siguiente:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eFoqtuOTLo8t"
      },
      "outputs": [],
      "source": [
        "get_average_temperature([68.5, 70.3, 69.8])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXn-yje9RJ6H"
      },
      "source": [
        "## Los cálculos sin ejecución <em>eager</em> y con TensorFlow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwyj8f3HLo8w"
      },
      "source": [
        "Hay dos restricciones fundamentales para tener en cuenta. La primera, es que cuando un intérprete Python encuentra un decorador `tff.federated_computation`, la función se rastrea una vez y se serializa para futuros usos. Por lo tanto, los cálculos TFF son fundamentalmente *non-eager* (no utilizan ejecución <em>eager</em>). Este comportamiento es, en cierto modo, análogo al del decorador <a><code>tf.function</code></a> en TensorFlow.\n",
        "\n",
        "La segunda, es que un cálculo federado solamente puede estar compuesto por operadores federados ( como `tff.federated_mean`), no puede contener operaciones de TensorFlow. Hay que confinar el código de TensorFlow a bloques decorados con `tff.tf_computation`. El código TensorFlow más común, directamente, se puede decorar, como la siguiente función que toma un número y le agrega `0.5`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "huz3mNmMLo8w"
      },
      "outputs": [],
      "source": [
        "@tff.tf_computation(tf.float32)\n",
        "def add_half(x):\n",
        "  return tf.add(x, 0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ptjWALDLo8y"
      },
      "source": [
        "Estas también son firmas de tipo, pero *sin ubicaciones*. Por ejemplo, se puede llamar lo siguiente:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xfAb0vG2Lo8y"
      },
      "outputs": [],
      "source": [
        "str(add_half.type_signature)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNjwrNMjLo8z"
      },
      "source": [
        "Observamos entonces, la gran diferencia que hay entre `tff.federated_computation` y `tff.tf_computation`. El primero tiene ubicaciones explícitas, mientras que el segundo no.\n",
        "\n",
        "Podemos usar bloques `tff.tf_computation` en cálculos federados para ubicaciones específicas. Creemos una función que agregue un medio (<em>add half</em>), pero solamente a flotantes federados de clientes. Podemos hacerlo con `tff.federated_map`, que aplica un `tff.tf_computation` dado y, a la vez, preserva la ubicación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pG6nw3wiLo80"
      },
      "outputs": [],
      "source": [
        "@tff.federated_computation(tff.type_at_clients(tf.float32))\n",
        "def add_half_on_clients(x):\n",
        "  return tff.federated_map(add_half, x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4msKRKJLo81"
      },
      "source": [
        "Esta función es casi idéntica a `add_half`, excepto porque solamente acepta valores con ubicación en `tff.CLIENTS` y devuelve valores con la misma ubicación. Podemos observarlo en su firma de tipo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_C2hDiz0Lo82"
      },
      "outputs": [],
      "source": [
        "str(add_half_on_clients.type_signature)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JxQ0DeiLo83"
      },
      "source": [
        "En resumen:\n",
        "\n",
        "- TFF opera sobre valores federados.\n",
        "- Cada valor federado tiene un *tipo federado*, con un *tipo* (p. ej., `tf.float32`) y una *ubicación* (p. ej., `tff.CLIENTS`).\n",
        "- Los valores federados se pueden transformar con *cálculos federados*, que se deben decorar con `tff.federated_computation` y una firma de tipo federado.\n",
        "- El código TensorFlow debe estar contenido en bloques con decoradores `tff.tf_computation`.\n",
        "- Estos bloques, después se pueden incorporar en cálculos federados.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvyFWox3Lo83"
      },
      "source": [
        "# Creación de los propios algoritmos de aprendizaje federado (parte 2)\n",
        "\n",
        "Ahora que ya tenemos una idea de lo que es el núcleo federado, podemos crear un algoritmo propio de aprendizaje federado. Recordemos que antes (arriba) ya definimos un `initialize_fn` y `next_fn` para nuestro algoritmo. El `next_fn` usará `client_update` y `server_update` que ya definimos con código de TensorFlow puro.\n",
        "\n",
        "Sin embargo, para hacer nuestro algoritmo con un cálculo federado, necesitaremos que tanto `next_fn` como `initialize_fn` sean `tff.federated_computation`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvY8fh1cLo84"
      },
      "source": [
        "## Bloques de TensorFlow federado "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0zNTO7LLo84"
      },
      "source": [
        "### Creación del cálculo de inicialización\n",
        "\n",
        "La función de inicializar será bastante simple: deberemos crear un modelo con `model_fn`. Sin embargo, recuerde que debemos separar nuestro código de TensorFlow con `tff.tf_computation`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jJY9xUBZLo84"
      },
      "outputs": [],
      "source": [
        "@tff.tf_computation\n",
        "def server_init():\n",
        "  model = model_fn()\n",
        "  return model.weights.trainable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGlv8LLgLo85"
      },
      "source": [
        "Entonces, ahora, podemos pasarlo directamente a cálculo federado con `tff.federated_value`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m2hinzuRLo86"
      },
      "outputs": [],
      "source": [
        "@tff.federated_computation\n",
        "def initialize_fn():\n",
        "  return tff.federated_value(server_init(), tff.SERVER)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFBghOgxLo88"
      },
      "source": [
        "### Creación de `next_fn`\n",
        "\n",
        "El código de actualización de cliente y servidor ahora se puede usar para escribir el algoritmo real. Primero, se transformará el `client_update` en un `tff.tf_computation` que acepta un conjunto de datos del cliente y los pesos del servidor, y sale un tensor de pesos del cliente actualizado.\n",
        "\n",
        "Necesitaremos los tipos correspondientes que decoren adecuadamente nuestra función. Afortunadamente, el tipo de pesos del servidor se puede extraer directamente desde nuestro modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ph_noHN2Lo88"
      },
      "outputs": [],
      "source": [
        "whimsy_model = model_fn()\n",
        "tf_dataset_type = tff.SequenceType(whimsy_model.input_spec)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMPgpTaW66qx"
      },
      "source": [
        "Observemos la firma de tipo del conjunto de datos. Recordemos que tomamos imágenes de 28 por 28 (con etiquetas de enteros) y las aplanamos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ju91izuz64wD"
      },
      "outputs": [],
      "source": [
        "str(tf_dataset_type)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuS8d0BHLo8-"
      },
      "source": [
        "También podemos extraer el tipo de pesos del modelo con nuestra función `server_init`, que figura más arriba."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4yx6CExMLo8-"
      },
      "outputs": [],
      "source": [
        "model_weights_type = server_init.type_signature.result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mS-Eh6Xj7J15"
      },
      "source": [
        "Al examinar la firma de tipo, podrá ver la arquitectura del modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nPdhhM1O7IIL"
      },
      "outputs": [],
      "source": [
        "str(model_weights_type)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1U1wTGRLo8_"
      },
      "source": [
        "Ahora podemos crear nuestro propio `tff.tf_computation` para la actualización del cliente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q0W05pMWLo9A"
      },
      "outputs": [],
      "source": [
        "@tff.tf_computation(tf_dataset_type, model_weights_type)\n",
        "def client_update_fn(tf_dataset, server_weights):\n",
        "  model = model_fn()\n",
        "  client_optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
        "  return client_update(model, tf_dataset, server_weights, client_optimizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uP5quaAuLo9B"
      },
      "source": [
        "La versión `tff.tf_computation` de la actualización del servidor se puede definir de un modo similar, con los tipos que ya hemos extraído."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F4WvQtVzLo9B"
      },
      "outputs": [],
      "source": [
        "@tff.tf_computation(model_weights_type)\n",
        "def server_update_fn(mean_client_weights):\n",
        "  model = model_fn()\n",
        "  return server_update(model, mean_client_weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SImhLbu4Lo9D"
      },
      "source": [
        "Por último, pero no menos importante, deberemos crear el `tff.federated_computation` que une todo. Esta función aceptará dos *valores federados*, uno correspondiente a los pesos del servidor (con la ubicación `tff.SERVER`) y otro correspondiente a los conjuntos de datos del cliente (con la ubicación `tff.CLIENTS`).\n",
        "\n",
        "Tenga en cuenta que ambos tipos ya han sido definidos más arriba. Simplemente debemos darles la ubicación adecuada con <code>tff.FederatedType</code>."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ekPsA8AsLo9D"
      },
      "outputs": [],
      "source": [
        "federated_server_type = tff.type_at_server(model_weights_type)\n",
        "federated_dataset_type = tff.type_at_clients(tf_dataset_type)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FXAX7vGLo9G"
      },
      "source": [
        "¿Recuerda los 4 elementos de un algoritmo de aprendizaje federado?\n",
        "\n",
        "1. Un paso para la emisión (<em>broadcast</em>) del servidor al cliente.\n",
        "2. Un paso para la actualización del cliente local.\n",
        "3. Un paso para la carga del cliente al servidor.\n",
        "4. Un paso para la actualización del servidor.\n",
        "\n",
        "Ahora que hemos creado lo anterior, cada parte se puede representar de forma compacta como una sola línea de código TFF. Esta simplicidad es el motivo por el cual hemos debido prestar suma atención a la especificación de cosas como los tipos federados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Epc7MwfELo9G"
      },
      "outputs": [],
      "source": [
        "@tff.federated_computation(federated_server_type, federated_dataset_type)\n",
        "def next_fn(server_weights, federated_dataset):\n",
        "  # Broadcast the server weights to the clients.\n",
        "  server_weights_at_client = tff.federated_broadcast(server_weights)\n",
        "\n",
        "  # Each client computes their updated weights.\n",
        "  client_weights = tff.federated_map(\n",
        "      client_update_fn, (federated_dataset, server_weights_at_client))\n",
        "  \n",
        "  # The server averages these updates.\n",
        "  mean_client_weights = tff.federated_mean(client_weights)\n",
        "\n",
        "  # The server updates its model.\n",
        "  server_weights = tff.federated_map(server_update_fn, mean_client_weights)\n",
        "\n",
        "  return server_weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWomG3TtLo9I"
      },
      "source": [
        "Ahora tenemos un `tff.federated_computation` tanto para la inicialización del algoritmo como para la ejecución de un paso del algoritmo. Para terminarlo, pasaremos estos elementos a `tff.templates.IterativeProcess`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GxdWgEddLo9I"
      },
      "outputs": [],
      "source": [
        "federated_algorithm = tff.templates.IterativeProcess(\n",
        "    initialize_fn=initialize_fn,\n",
        "    next_fn=next_fn\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Z__9k-Dc1I3"
      },
      "source": [
        "Observemos la *firma de tipo * de las funciones `initialize` y `next` de nuestro proceso iterativo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kyRLXDj-Lo9J"
      },
      "outputs": [],
      "source": [
        "str(federated_algorithm.initialize.type_signature)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UyyEi5Kec90_"
      },
      "source": [
        "Refleja el hecho de que `federated_algorithm.initialize` es una función no argumentativa que devuelve un modelo de una sola capa (con una matriz de peso de 784 por 10, y 10 unidades de sesgo)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mx6yuIKtLo9M"
      },
      "outputs": [],
      "source": [
        "str(federated_algorithm.next.type_signature)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efpdHodmdU_6"
      },
      "source": [
        "Aquí, podemos ver que `federated_algorithm.next` acepta un modelo de servidor y datos del cliente, y devuelve un modelo de servidor actualizado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4UYZ3qeMLo9N"
      },
      "source": [
        "## Evaluación del algoritmo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwd9Gs0ULo9O"
      },
      "source": [
        "Ejecutemos algunas rondas y veamos cómo cambia la pérdida. Primero, definiremos una función de evaluación con el modo *centralizado* referido en el segundo tutorial.\n",
        "\n",
        "En primer lugar, creamos un conjunto de datos de evaluación centralizado y luego aplicamos el mismo preprocesamiento que usamos para los datos de entrenamiento.\n",
        "\n",
        "Tenga en cuenta que solamente `take` (tomamos) los primeros 1000 elementos, para eficiencia en los cálculos. Pero que normalmente usaríamos el conjunto completo de los datos de prueba."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EdNgYoIwLo9P"
      },
      "outputs": [],
      "source": [
        "central_emnist_test = emnist_test.create_tf_dataset_from_all_clients().take(1000)\n",
        "central_emnist_test = preprocess(central_emnist_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7R50NZ35dphE"
      },
      "source": [
        "A continuación, escribiremos una función que acepte un estado del servidor y usaremos Keras para evaluar el conjunto de datos de prueba. Si está familiarizado con `tf.Keras`, todo esto le resultará conocido; de todos modos, preste particular atención al uso de `set_weights`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I5UEX4EWLo9Q"
      },
      "outputs": [],
      "source": [
        "def evaluate(server_state):\n",
        "  keras_model = create_keras_model()\n",
        "  keras_model.compile(\n",
        "      loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]  \n",
        "  )\n",
        "  keras_model.set_weights(server_state)\n",
        "  keras_model.evaluate(central_emnist_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hygoBACkLo9S"
      },
      "source": [
        "Ahora, inicialicemos nuestro algoritmo y evaluemos el conjunto de prueba."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JC6zMDTTLo9S"
      },
      "outputs": [],
      "source": [
        "server_state = federated_algorithm.initialize()\n",
        "evaluate(server_state)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2knqix2cLo9U"
      },
      "source": [
        "Entrenemos durante algunas rondas y veamos si cambia algo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v1zBlzFILo9U"
      },
      "outputs": [],
      "source": [
        "for round in range(15):\n",
        "  server_state = federated_algorithm.next(server_state, federated_train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q91Vjyc_jumU"
      },
      "outputs": [],
      "source": [
        "evaluate(server_state)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XM34ammUW-T3"
      },
      "source": [
        "Observamos una disminución leve en la función de pérdida. Si bien el salto es pequeño, solamente hemos realizado 15 rondas de entrenamiento y sobre un subconjunto reducido de clientes. Para ver mejores resultados, probablemente debamos hacer cientos o miles de rondas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o13H5dDFXRFn"
      },
      "source": [
        "## Modificación del algoritmo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qt4jVD21XTL-"
      },
      "source": [
        "En este punto, detengámonos a pensar sobre lo que hemos logrado. Hemos implementado el cálculo promedio federado directamente mediante la combinación de código de TensorFlow puro (para las actualizaciones del cliente y del servidor) con cálculos federados del núcleo federado de TFF.\n",
        "\n",
        "Para realizar un aprendizaje más sofisticado, simplemente podemos alterar lo que hicimos arriba. En particular, editando el código de TF puro mencionado podemos cambiar la manera en que el cliente realiza el entrenamiento o cómo el servidor actualiza su modelo.\n",
        "\n",
        "**Desafío:** agregar [recorte (<em>clipping</em>) de gradiente](https://towardsdatascience.com/what-is-gradient-clipping-b8e815cdfb48) a la función <code>client_update</code>.\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "openmined_conference_2020.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
