{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lf7huAiYp-An"
      },
      "source": [
        "##### Copyright 2019 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "YHz2D-oIqBWa"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x44FFES-r6y0"
      },
      "source": [
        "# Aprendizaje federado para generación de textos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPFgLeZIsZ3Q"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td><a target=\"_blank\" href=\"https://www.tensorflow.org/federated/tutorials/federated_learning_for_text_generation\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver en TensorFlow.org</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/es-419/federated/tutorials/federated_learning_for_text_generation.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Ejecutar en Google Colab</a></td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/es-419/federated/tutorials/federated_learning_for_text_generation.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver fuente en GitHub</a>\n",
        "</td>\n",
        "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/es-419/federated/tutorials/federated_learning_for_text_generation.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Descargar bloc de notas</a>\n",
        "</td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbNz2tuvsAFB"
      },
      "source": [
        "**NOTA**: Esta colaboración ha sido verificada para trabajar con la [versión de lanzamiento más reciente](https://github.com/tensorflow/federated#compatibility) del paquete pip `tensorflow_federated`, pero el proyecto federado de TensorFlow aún se encuentra en una etapa de desarrollo previa al lanzamiento. Por lo tanto, es probable que no funcione en `main`.\n",
        "\n",
        "Este tutorial se desarrolla en base a los conceptos del tutorial sobre [aprendizaje federado para clasificación de imágenes](federated_learning_for_image_classification.ipynb), y aquí se demuestran muchos otros métodos útiles  de aplicación del aprendizaje federado.\n",
        "\n",
        "En particular, cargamos un modelo keras previamente entrenado y lo refinamos con el aprendizaje federado de un conjunto de datos (simulado) descentralizado. En la práctica resulta importante por varios motivos. La posibilidad de usar modelos serializados facilita la posibilidad de mezclar aprendizaje federado con otros métodos de aprendizaje automático. Además, permite usar un rango más amplio de modelos previamente entrenados. Por ejemplo, los modelos de lenguaje de entrenamiento desde cero rara vez son necesarios, ya que hoy en día hay muchos modelos previamente entrenados disponibles para usar (consulte, p. ej., [TF Hub](https://www.tensorflow.org/hub)).<br>Tiene más sentido empezar a partir de un modelo previamente entrenado y refinarlo con aprendizaje federado, para adaptarlo a las características particulares de los datos descentralizados para una aplicación particular.\n",
        "\n",
        "Para este tutorial, empezamos con una RNN que genera caracteres ASCII y lo refinamos mediante aprendizaje federado. También mostramos de qué manera los pesos finales se pueden volver a incorporar al modelo Keras original, facilitando la evaluación y la generación de textos con herramientas estándares."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9LcC1AwjoqfR"
      },
      "outputs": [],
      "source": [
        "#@test {\"skip\": true}\n",
        "!pip install --quiet --upgrade tensorflow-federated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZjDQysatrc2S"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "b'Hello, World!'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import collections\n",
        "import functools\n",
        "import os\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_federated as tff\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "# Test that TFF is working:\n",
        "tff.federated_computation(lambda: 'Hello, World!')()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lyICXwVAxvW9"
      },
      "source": [
        "## Carga de un modelo previamente entrenado\n",
        "\n",
        "Cargamos un modelo que fue previamente entrenado siguiendo el tutorial sobre [Generación de textos con una RNN mediante ejecución <em>eager</em>](https://www.tensorflow.org/tutorials/sequences/text_generation) de TensorFlow. Sin embargo, más que entrenar [La obra completa de Shakespeare](http://www.gutenberg.org/files/100/100-0.txt), preentrenamos el modelo con los textos de [Historia de dos ciudades](http://www.ibiblio.org/pub/docs/books/gutenberg/9/98/98.txt) y [Canción de Navidad](http://www.ibiblio.org/pub/docs/books/gutenberg/4/46/46.txt) de Charles Dickens.\n",
        "\n",
        "Si bien expandimos el vocabulario, no modificamos el tutorial original; por lo tanto, este modelo inicial no es de lo más avanzado, pero produce predicciones razonables y es adecuado para cumplir con el objetivo del tutorial. El modelo final fue guardado en `tf.keras.models.save_model(include_optimizer=False)`.\n",
        "\n",
        "Utilizaremos aprendizaje federado para refinar el modelo para trabajar con Shakespeare en este tutorial. Usaremos una versión federada de los datos provistos por TFF.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgF8e2Ksyq1F"
      },
      "source": [
        "### Generación de las tablas para búsqueda de vocabulario"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IlCgQBRVymwR"
      },
      "outputs": [],
      "source": [
        "# A fixed vocabularly of ASCII chars that occur in the works of Shakespeare and Dickens:\n",
        "vocab = list('dhlptx@DHLPTX $(,048cgkoswCGKOSW[_#\\'/37;?bfjnrvzBFJNRVZ\"&*.26:\\naeimquyAEIMQUY]!%)-159\\r')\n",
        "\n",
        "# Creating a mapping from unique characters to indices\n",
        "char2idx = {u:i for i, u in enumerate(vocab)}\n",
        "idx2char = np.array(vocab)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2EH6MFRdzAwd"
      },
      "source": [
        "### Carga del modelo previamente entrenado y generación de algo de texto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iIK674SrtCTm"
      },
      "outputs": [],
      "source": [
        "def load_model(batch_size):\n",
        "  urls = {\n",
        "      1: 'https://storage.googleapis.com/tff-models-public/dickens_rnn.batch1.kerasmodel',\n",
        "      8: 'https://storage.googleapis.com/tff-models-public/dickens_rnn.batch8.kerasmodel'}\n",
        "  assert batch_size in urls, 'batch_size must be in ' + str(urls.keys())\n",
        "  url = urls[batch_size]\n",
        "  local_file = tf.keras.utils.get_file(os.path.basename(url), origin=url)  \n",
        "  return tf.keras.models.load_model(local_file, compile=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WvuwZBX5Ogfd"
      },
      "outputs": [],
      "source": [
        "def generate_text(model, start_string):\n",
        "  # From https://www.tensorflow.org/tutorials/sequences/text_generation\n",
        "  num_generate = 200\n",
        "  input_eval = [char2idx[s] for s in start_string]\n",
        "  input_eval = tf.expand_dims(input_eval, 0)\n",
        "  text_generated = []\n",
        "  temperature = 1.0\n",
        "\n",
        "  model.reset_states()\n",
        "  for i in range(num_generate):\n",
        "    predictions = model(input_eval)\n",
        "    predictions = tf.squeeze(predictions, 0)\n",
        "    predictions = predictions / temperature\n",
        "    predicted_id = tf.random.categorical(\n",
        "        predictions, num_samples=1)[-1, 0].numpy()\n",
        "    input_eval = tf.expand_dims([predicted_id], 0)\n",
        "    text_generated.append(idx2char[predicted_id])\n",
        "\n",
        "  return (start_string + ''.join(text_generated))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MGAdStJ5wDPV"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tff-models-public/dickens_rnn.batch1.kerasmodel\n",
            "16193984/16193984 [==============================] - 0s 0us/step\n",
            "What of TensorFlow Federated, you ask? Same yee you? Have I so,\n",
            "often games in a man who rode one knee over his friend, with the\n",
            "stone faces of the dread prisoners, dud a tender mastery. They\n",
            "are not alive is infirmed us--to ever resume\n"
          ]
        }
      ],
      "source": [
        "# Text generation requires a batch_size=1 model.\n",
        "keras_model_batch1 = load_model(batch_size=1)\n",
        "print(generate_text(keras_model_batch1, 'What of TensorFlow Federated, you ask? '))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKMUn-TlgxuP"
      },
      "source": [
        "## Carga y procesamiento previo de los datos federados de Shakespeare\n",
        "\n",
        "El paquete `tff.simulation.datasets` ofrece una variedad de conjuntos de datos separados en los \"clientes\", donde a cada cliente le corresponde un conjunto de datos en un dispositivo en particular que podría participar en el aprendizaje federado.\n",
        "\n",
        "Estos conjuntos de datos muestran distribuciones realistas de datos no independientes (<em>non-IID</em>), que replican en simulación las dificultades del entrenamiento en datos reales descentralizados. Parte de este procesamiento previo de los datos se realizó con herramientas del [proyecto Leaf](https://arxiv.org/abs/1812.01097) ([github](https://github.com/TalwalkarLab/leaf))."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "di3nStTDg0qc"
      },
      "outputs": [],
      "source": [
        "train_data, test_data = tff.simulation.datasets.shakespeare.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_iiY65Vv4QNK"
      },
      "source": [
        "Los conjuntos de datos provistos por `shakespeare.load_data()` están compuestos por una secuencia de cadena de `Tensors`, una para cada línea hablada por uno de los personajes de una obra de Shakespeare. Las claves de cliente están formadas por el nombre de la obra y el nombre del personaje; por ejemplo `MUCH_ADO_ABOUT_NOTHING_OTHELLO` corresponde a las líneas del personaje Otelo en la obra *Mucho ruido y pocas nueces*. Tenga en cuenta que en un escenario de aprendizaje federado a los clientes nunca se los identifica ni se los rastrea por ID, pero para la simulación resulta útil trabajar con conjuntos de datos codificados (con clave).\n",
        "\n",
        "Aquí, por ejemplo, podemos observar algunos datos de El rey Lear:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FEKiy1ntmmnk"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(b'', shape=(), dtype=string)\n",
            "tf.Tensor(b'What?', shape=(), dtype=string)\n"
          ]
        }
      ],
      "source": [
        "# Here the play is \"The Tragedy of King Lear\" and the character is \"King\".\n",
        "raw_example_dataset = train_data.create_tf_dataset_for_client(\n",
        "    'THE_TRAGEDY_OF_KING_LEAR_KING')\n",
        "# To allow for future extensions, each entry x\n",
        "# is an OrderedDict with a single key 'snippets' which contains the text.\n",
        "for x in raw_example_dataset.take(2):\n",
        "  print(x['snippets'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUnbI5Hp4sXg"
      },
      "source": [
        "Ahora usamos transformaciones `tf.data.Dataset` para preparar estos datos para el entrenamiento en la RNN cargada anteriormente.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9kDkmGe-7No7"
      },
      "outputs": [],
      "source": [
        "# Input pre-processing parameters\n",
        "SEQ_LENGTH = 100\n",
        "BATCH_SIZE = 8\n",
        "BUFFER_SIZE = 100  # For dataset shuffling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W95Of6Bwsrfc"
      },
      "outputs": [],
      "source": [
        "# Construct a lookup table to map string chars to indexes,\n",
        "# using the vocab loaded above:\n",
        "table = tf.lookup.StaticHashTable(\n",
        "    tf.lookup.KeyValueTensorInitializer(\n",
        "        keys=vocab, values=tf.constant(list(range(len(vocab))),\n",
        "                                       dtype=tf.int64)),\n",
        "    default_value=0)\n",
        "\n",
        "\n",
        "def to_ids(x):\n",
        "  s = tf.reshape(x['snippets'], shape=[1])\n",
        "  chars = tf.strings.bytes_split(s).values\n",
        "  ids = table.lookup(chars)\n",
        "  return ids\n",
        "\n",
        "\n",
        "def split_input_target(chunk):\n",
        "  input_text = tf.map_fn(lambda x: x[:-1], chunk)\n",
        "  target_text = tf.map_fn(lambda x: x[1:], chunk)\n",
        "  return (input_text, target_text)\n",
        "\n",
        "\n",
        "def preprocess(dataset):\n",
        "  return (\n",
        "      # Map ASCII chars to int64 indexes using the vocab\n",
        "      dataset.map(to_ids)\n",
        "      # Split into individual chars\n",
        "      .unbatch()\n",
        "      # Form example sequences of SEQ_LENGTH +1\n",
        "      .batch(SEQ_LENGTH + 1, drop_remainder=True)\n",
        "      # Shuffle and form minibatches\n",
        "      .shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
        "      # And finally split into (input, target) tuples,\n",
        "      # each of length SEQ_LENGTH.\n",
        "      .map(split_input_target))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jw98HnKmEhuh"
      },
      "source": [
        "Considere que para facilitar la formación de las secuencias originales y la de los lotes que figuran aquí arriba usamos `drop_remainder=True`. Significa que cualquiera de los personajes (clientes) que no tienen al menos `(SEQ_LENGTH + 1) * BATCH_SIZE` caracteres de texto tendrán bases de datos vacías. Una forma muy común de abordarlo sería agrupando los lotes con un token especial y enmascarando después la pérdida para que no se tengan en cuenta los tokens de agrupamiento (<em>padding</em>).\n",
        "\n",
        "En cierto modo, esto haría que el ejemplo fuera más complicado. Entonces, para este tutorial solamente usamos lotes completos, como en el [tutorial estándar](https://www.tensorflow.org/tutorials/sequences/text_generation). Sin embargo, en el ambiente federado este problema se torna más significativo, porque puede haber muchos usuarios con pequeños conjuntos de datos.\n",
        "\n",
        "Ahora podemos procesar nuestro `raw_example_dataset` y verificar los tipos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7rTal7bksWwc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(TensorSpec(shape=(8, 100), dtype=tf.int64, name=None), TensorSpec(shape=(8, 100), dtype=tf.int64, name=None))\n"
          ]
        }
      ],
      "source": [
        "example_dataset = preprocess(raw_example_dataset)\n",
        "print(example_dataset.element_spec)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePT8Oawm8SRP"
      },
      "source": [
        "## Compilación del modelo y comprobación de los datos preprocesados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEgDsz-48cAq"
      },
      "source": [
        "Cargamos un modelo keras sin compilar, pero para ejecutar `keras_model.evaluate` necesitamos compilarlo con una pérdida y métricas. También compilamos un optimizador, que se usará como optimizador en dispositivos, como parte del aprendizaje federado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsuVZ5KMWnn8"
      },
      "source": [
        "El tutorial original no tiene una precisión a nivel de caracteres (la fracción de predicciones en que la probabilidad más alta se asignó al siguiente carácter correcto). Es una métrica útil, así que la agregamos. Sin embargo, debemos definir una clase de métrica nueva porque nuestras predicciones tienen un nivel 3 (un vector de funciones <em>logit</em> para cada predicción `BATCH_SIZE * SEQ_LENGTH`) y `SparseCategoricalAccuracy` espera solamente predicciones de nivel 2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gOUiDBvmWlM9"
      },
      "outputs": [],
      "source": [
        "class FlattenedCategoricalAccuracy(tf.keras.metrics.SparseCategoricalAccuracy):\n",
        "\n",
        "  def __init__(self, name='accuracy', dtype=tf.float32):\n",
        "    super().__init__(name, dtype=dtype)\n",
        "\n",
        "  def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "    y_true = tf.reshape(y_true, [-1, 1])\n",
        "    y_pred = tf.reshape(y_pred, [-1, len(vocab), 1])\n",
        "    return super().update_state(y_true, y_pred, sample_weight)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2X9eFgt94PM"
      },
      "source": [
        "Ahora podemos compilar un modelo y evaluarlo en nuestro `example_dataset`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3Xd-52-9zGa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tff-models-public/dickens_rnn.batch8.kerasmodel\n",
            "16193984/16193984 [==============================] - 0s 0us/step\n",
            "Evaluating on an example Shakespeare character: 0.45.000\n",
            "Expected accuracy for random guessing: 0.012\n",
            "Evaluating on completely random data: 0.011\n"
          ]
        }
      ],
      "source": [
        "BATCH_SIZE = 8  # The training and eval batch size for the rest of this tutorial.\n",
        "keras_model = load_model(batch_size=BATCH_SIZE)\n",
        "keras_model.compile(\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[FlattenedCategoricalAccuracy()])\n",
        "\n",
        "# Confirm that loss is much lower on Shakespeare than on random data\n",
        "loss, accuracy = keras_model.evaluate(example_dataset.take(5), verbose=0)\n",
        "print(\n",
        "    'Evaluating on an example Shakespeare character: {a:3f}'.format(a=accuracy))\n",
        "\n",
        "# As a sanity check, we can construct some completely random data, where we expect\n",
        "# the accuracy to be essentially random:\n",
        "random_guessed_accuracy = 1.0 / len(vocab)\n",
        "print('Expected accuracy for random guessing: {a:.3f}'.format(\n",
        "    a=random_guessed_accuracy))\n",
        "random_indexes = np.random.randint(\n",
        "    low=0, high=len(vocab), size=1 * BATCH_SIZE * (SEQ_LENGTH + 1))\n",
        "data = collections.OrderedDict(\n",
        "    snippets=tf.constant(\n",
        "        ''.join(np.array(vocab)[random_indexes]), shape=[1, 1]))\n",
        "random_dataset = preprocess(tf.data.Dataset.from_tensor_slices(data))\n",
        "loss, accuracy = keras_model.evaluate(random_dataset, steps=10, verbose=0)\n",
        "print('Evaluating on completely random data: {a:.3f}'.format(a=accuracy))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lH0WzL5L8Lm4"
      },
      "source": [
        "## Ajuste fino del modelo con aprendizaje federado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCao4M3L_tsA"
      },
      "source": [
        "TFF serializa todos los cálculos de TensorFlow para que se puedan ejecutar potencialmente en un entorno que no sea de Python (a pesar de que en este momento, solamente hay un tiempo de ejecución de simulación implementado en Python). Si bien la ejecución se hace en modo <em>eager</em>, (TF 2.0), actualmente TFF serializa los cálculos de TensorFlow construyendo las operaciones necesarias dentro del contexto de una afirmación \"`with tf.Graph.as_default()`\". Por lo tanto, debemos aportar una función que TFF pueda usar para introducir nuestro modelo en un grafo que controle. Lo hacemos de la siguiente manera:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5KadIvFp7m6y"
      },
      "outputs": [],
      "source": [
        "# Clone the keras_model inside `create_tff_model()`, which TFF will\n",
        "# call to produce a new copy of the model inside the graph that it will \n",
        "# serialize. Note: we want to construct all the necessary objects we'll need \n",
        "# _inside_ this method.\n",
        "def create_tff_model():\n",
        "  # TFF uses an `input_spec` so it knows the types and shapes\n",
        "  # that your model expects.\n",
        "  input_spec = example_dataset.element_spec\n",
        "  keras_model_clone = tf.keras.models.clone_model(keras_model)\n",
        "  return tff.learning.models.from_keras_model(\n",
        "      keras_model_clone,\n",
        "      input_spec=input_spec,\n",
        "      loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "      metrics=[FlattenedCategoricalAccuracy()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJF_yhJxAi2l"
      },
      "source": [
        "Ahora estamos listos para construir un proceso iterativo de cálculo de promedios federados que luego usaremos para mejorar el modelo (para más detalles sobre el algoritmo de cálculo de promedio federado, consulte la publicación [Communication-Efficient Learning of Deep Networks from Decentralized Data](https://arxiv.org/abs/1602.05629) (Aprendizaje con comunicaciones eficientes de redes profundas a partir de datos descentralizados).\n",
        "\n",
        "Usamos un modelo Keras para realizar una evaluación estándar (no federada) después de cada ronda de entrenamiento federado. A los fines investigativos, resulta útil cuando hacemos aprendizaje federado simulado con un conjunto de datos de prueba estándar.\n",
        "\n",
        "En un entorno de producción realista esta misma técnica se podría utilizar para tomar modelos entrenados con aprendizaje federado y evaluarlos en un conjunto de datos centralizado de referencia para realizar las pruebas o para aseguramiento de la calidad."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "my3PW3qhAMDA"
      },
      "outputs": [],
      "source": [
        "# This command builds all the TensorFlow graphs and serializes them: \n",
        "fed_avg = tff.learning.algorithms.build_weighted_fed_avg(\n",
        "    model_fn=create_tff_model,\n",
        "    client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVOkzs9C9kmv"
      },
      "source": [
        "El siguiente es el ciclo más simple posible, en él ejecutamos el cálculo de promedio federado para una ronda en un solo cliente de un solo lote:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lrjUrkjq9jYk"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss=4.399, accuracy=0.139\n"
          ]
        }
      ],
      "source": [
        "state = fed_avg.initialize()\n",
        "result = fed_avg.next(state, [example_dataset.take(5)])\n",
        "state = result.state\n",
        "train_metrics = result.metrics['client_work']['train']\n",
        "print('loss={l:.3f}, accuracy={a:.3f}'.format(\n",
        "    l=train_metrics['loss'], a=train_metrics['accuracy']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2CjvVg0FZpS"
      },
      "source": [
        "Ahora escribamos un ciclo de entrenamiento y evaluación un poco más interesante.\n",
        "\n",
        "Para que esta simulación todavía se ejecute con rapidez, llevaremos a cabo el entrenamiento en los mismos tres clientes cada vez, considerando solamente dos minilotes para cada una.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wE386-rbMCve"
      },
      "outputs": [],
      "source": [
        "def data(client, source=train_data):\n",
        "  return preprocess(source.create_tf_dataset_for_client(client)).take(5)\n",
        "\n",
        "\n",
        "clients = [\n",
        "    'ALL_S_WELL_THAT_ENDS_WELL_CELIA', 'MUCH_ADO_ABOUT_NOTHING_OTHELLO',\n",
        "]\n",
        "\n",
        "train_datasets = [data(client) for client in clients]\n",
        "\n",
        "# We concatenate the test datasets for evaluation with Keras by creating a \n",
        "# Dataset of Datasets, and then identity flat mapping across all the examples.\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices(\n",
        "    [data(client, test_data) for client in clients]).flat_map(lambda x: x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cU3FuY00MOoX"
      },
      "source": [
        "El estado inicial del modelo producido por `fed_avg.initialize()` se basa en los inicializadores aleatorios para el modelo Keras, no en los pesos que se cargaron, ya que `clone_model()` no clona los pesos. Para empezar el entrenamiento a partir de un modelo previamente entrenado, configuramos los pesos del modelo en el estado del servidor directamente a partir del modelo cargado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vm_-PU8OFXpY"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Round 0\n",
            "\tEval: loss=3.171, accuracy=0.428\n",
            "\tTrain: loss=4.309, accuracy=0.098\n",
            "Round 1\n",
            "\tEval: loss=4.188, accuracy=0.185\n",
            "\tTrain: loss=4.037, accuracy=0.223\n",
            "Round 2\n",
            "\tEval: loss=3.948, accuracy=0.200\n",
            "\tTrain: loss=3.797, accuracy=0.228\n",
            "Round 3\n",
            "\tEval: loss=3.826, accuracy=0.179\n",
            "\tTrain: loss=3.662, accuracy=0.219\n",
            "Round 4\n",
            "\tEval: loss=3.723, accuracy=0.171\n",
            "\tTrain: loss=3.440, accuracy=0.245\n",
            "Final evaluation\n",
            "\tEval: loss=3.599, accuracy=0.181\n"
          ]
        }
      ],
      "source": [
        "NUM_ROUNDS = 5\n",
        "\n",
        "# The state of the FL server, containing the model and optimization state.\n",
        "state = fed_avg.initialize()\n",
        "\n",
        "# Load our pre-trained Keras model weights into the global model state.\n",
        "pre_trained_weights = tff.learning.models.ModelWeights(\n",
        "    trainable=[v.numpy() for v in keras_model.trainable_weights],\n",
        "    non_trainable=[v.numpy() for v in keras_model.non_trainable_weights]\n",
        ")\n",
        "state = fed_avg.set_model_weights(state, pre_trained_weights)\n",
        "\n",
        "\n",
        "def keras_evaluate(state, round_num):\n",
        "  # Take our global model weights and push them back into a Keras model to\n",
        "  # use its standard `.evaluate()` method.\n",
        "  keras_model = load_model(batch_size=BATCH_SIZE)\n",
        "  keras_model.compile(\n",
        "      loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "      metrics=[FlattenedCategoricalAccuracy()])\n",
        "  model_weights = fed_avg.get_model_weights(state)\n",
        "  model_weights.assign_weights_to(keras_model)\n",
        "  loss, accuracy = keras_model.evaluate(example_dataset, steps=2, verbose=0)\n",
        "  print('\\tEval: loss={l:.3f}, accuracy={a:.3f}'.format(l=loss, a=accuracy))\n",
        "\n",
        "\n",
        "for round_num in range(NUM_ROUNDS):\n",
        "  print('Round {r}'.format(r=round_num))\n",
        "  keras_evaluate(state, round_num)\n",
        "  result = fed_avg.next(state, train_datasets)\n",
        "  state = result.state\n",
        "  train_metrics = result.metrics['client_work']['train']\n",
        "  print('\\tTrain: loss={l:.3f}, accuracy={a:.3f}'.format(\n",
        "      l=train_metrics['loss'], a=train_metrics['accuracy']))\n",
        "\n",
        "print('Final evaluation')\n",
        "keras_evaluate(state, NUM_ROUNDS + 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SoshvcHhXVa6"
      },
      "source": [
        "Con los cambios predeterminados, el entrenamiento no ha sido suficiente como para lograr una gran diferencia. Pero si lo entrenamos por más tiempo y con más datos de Shakespeare deberíamos notar una diferencia en el estilo del texto generado con el modelo actualizado:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NTUig7QmXavy"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "What of TensorFlow Federated, you ask? She will be\n",
            "heard of; or whether they recovered her faltering place, that a great mark of\n",
            "being so final dark and distrustner the dearer to the chin, all\n",
            "staftly towards him, or trot's in foot thro\n"
          ]
        }
      ],
      "source": [
        "# Set our newly trained weights back in the originally created model.\n",
        "keras_model_batch1.set_weights([v.numpy() for v in keras_model.weights])\n",
        "# Text generation requires batch_size=1\n",
        "print(generate_text(keras_model_batch1, 'What of TensorFlow Federated, you ask? '))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DA1Fkf5mN0s"
      },
      "source": [
        "## Extensiones sugeridas\n",
        "\n",
        "En este tutorial se muestra solamente el primer paso. A continuación, compartimos algunas ideas sobre cómo ampliar lo compartido en estas notas:\n",
        "\n",
        "- Escriba un circuito de entrenamiento más realista en el que se haga entrenamiento aleatorio con clientes de muestra.\n",
        "- Use \"`.repeat(NUM_EPOCHS)`\" de los conjuntos de datos del cliente para intentar multiplicar las épocas de entrenamiento focal (p. ej., como en [McMahan et. al.](https://arxiv.org/abs/1602.05629)). Consulte también [Aprendizaje federado para clasificación de imágenes](federated_learning_for_image_classification.ipynb), que lo hace.\n",
        "- Cambie el comando `compile()` para experimentar con diferentes algoritmos de optimización en el cliente.\n",
        "- Pruebe el argumento `server_optimizer` para `build_weighted_fed_avg` con el objetivo de probar algoritmos diferentes para aplicar las actualizaciones del modelo en el servidor."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "federated_learning_for_text_generation.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
