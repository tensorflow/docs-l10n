{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkdnLiKk71g-"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "0asMuNro71hA"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPFgLeZIsZ3Q"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td><a target=\"_blank\" href=\"https://www.tensorflow.org/federated/tutorials/building_your_own_federated_learning_algorithm\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver en TensorFlow.org</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/es-419/federated/tutorials/building_your_own_federated_learning_algorithm.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Ejecutar en Google Colab</a></td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/es-419/federated/tutorials/building_your_own_federated_learning_algorithm.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver fuente en GitHub</a>\n",
        "</td>\n",
        "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/es-419/federated/tutorials/building_your_own_federated_learning_algorithm.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Descargar  bloc de notas</a>\n",
        "</td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnUwFbCAKB2r"
      },
      "source": [
        "## Antes de empezar\n",
        "\n",
        "Antes de empezar, ejecute lo que se encuentra a continuación, para asegurarse de que el entorno esté preparado correctamente. Si no ve un mensaje de inicio, para más instrucciones, consulte la guía de [instalación](../install.md). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZrGitA_KnRO0"
      },
      "outputs": [],
      "source": [
        "#@test {\"skip\": true}\n",
        "!pip install --quiet --upgrade tensorflow-federated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HGTM6tWOLo8M"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_federated as tff"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yr3ztf28fa1F"
      },
      "source": [
        "**NOTA**: Esta colaboración ha sido verificada para trabajar con la [versión de lanzamiento más reciente](https://github.com/tensorflow/federated#compatibility) del paquete pip `tensorflow_federated`, pero el proyecto federado de TensorFlow aún se encuentra en una etapa de desarrollo previa al lanzamiento. Por lo tanto, es probable que no funcione en `main`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Zv28F7QLo8O"
      },
      "source": [
        "# Creación de un algoritmo propio de aprendizaje federado\n",
        "\n",
        "Con los tutoriales de [clasificación de imágenes](federated_learning_for_image_classification.ipynb) y de [generación de textos](federated_learning_for_text_generation.ipynb), se aprende a preparar el modelo y las canalizaciones de los datos para el aprendizaje federado (FL, por sus siglas en inglés) y se realizan entrenamientos federados mediante la capa de la API `tff.learning` de TFF.\n",
        "\n",
        "Es la punta del iceberg en la investigación sobre el aprendizaje federado. En este tutorial se analiza cómo implementar los algoritmos de aprendizaje federado *sin* delegar a la API `tff.learning`. Con este tutorial, logrará lo siguiente:\n",
        "\n",
        "**Objetivos:**\n",
        "\n",
        "- Entender la estructura general de los algoritmos de aprendizaje federado.\n",
        "- Explorar el *núcleo federado* de TFF.\n",
        "- Usar el núcleo federado para implementar directamente el cálculo del promedio federado.\n",
        "\n",
        "Si bien este tutorial contiene todo lo necesario para entenderlo sin lecturas extra, puede ser de utilidad consultar primero los tutoriales de [clasificación de imágenes](federated_learning_for_image_classification.ipynb) y de [generación de textos](federated_learning_for_text_generation.ipynb).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQ_N9XbULo8P"
      },
      "source": [
        "## Preparación de los datos de entrada\n",
        "\n",
        "Primero, hay que cargar y procesar el conjunto de datos EMNIST incluido en TFF. Para más detalles, consulte el tutorial sobre [clasificación de imágenes](federated_learning_for_image_classification.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-WdnFluLLo8P"
      },
      "outputs": [],
      "source": [
        "emnist_train, emnist_test = tff.simulation.datasets.emnist.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kq8893GogB8E"
      },
      "source": [
        "A fin de alimentar nuestro modelo con el conjunto de datos, estos datos se aplanan. Cada ejemplo se transforma en una tupla con la forma `(flattened_image_vector, label)`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Blrh8zJgLo8R"
      },
      "outputs": [],
      "source": [
        "NUM_CLIENTS = 10\n",
        "BATCH_SIZE = 20\n",
        "\n",
        "def preprocess(dataset):\n",
        "\n",
        "  def batch_format_fn(element):\n",
        "    \"\"\"Flatten a batch of EMNIST data and return a (features, label) tuple.\"\"\"\n",
        "    return (tf.reshape(element['pixels'], [-1, 784]), \n",
        "            tf.reshape(element['label'], [-1, 1]))\n",
        "\n",
        "  return dataset.batch(BATCH_SIZE).map(batch_format_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Piy8EzqmgNqV"
      },
      "source": [
        "Ahora, seleccione una pequeña cantidad de clientes y aplique el preprocesamiento anterior a los conjuntos de datos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-vYM_IT7Lo8W"
      },
      "outputs": [],
      "source": [
        "client_ids = sorted(emnist_train.client_ids)[:NUM_CLIENTS]\n",
        "federated_train_data = [preprocess(emnist_train.create_tf_dataset_for_client(x))\n",
        "  for x in client_ids\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNO_Y9j_Lo8X"
      },
      "source": [
        "## Preparación del modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJ0I89ixz8yV"
      },
      "source": [
        "Se usa el mismo modelo que en el tutorial de [clasificación de imágenes](federated_learning_for_image_classification.ipynb). En este modelo (implementado mediante `tf.keras`) hay una sola capa oculta, seguida por una capa <em>softmax</em>."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yfld4oFNLo8Y"
      },
      "outputs": [],
      "source": [
        "def create_keras_model():\n",
        "  initializer = tf.keras.initializers.GlorotNormal(seed=0)\n",
        "  return tf.keras.models.Sequential([\n",
        "      tf.keras.layers.Input(shape=(784,)),\n",
        "      tf.keras.layers.Dense(10, kernel_initializer=initializer),\n",
        "      tf.keras.layers.Softmax(),\n",
        "  ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLln0Q8G0Bky"
      },
      "source": [
        "A fin de usar este modelo en TFF, encapsule el modelo Keras como un [`tff.learning.models.VariableModel`](https://www.tensorflow.org/federated/api_docs/python/tff/learning/Model). Esto permite hacer el [pase hacia adelante](https://www.tensorflow.org/federated/api_docs/python/tff/learning/Model#forward_pass) del modelo dentro de TFF y [extraer las salidas](https://www.tensorflow.org/federated/api_docs/python/tff/learning/Model#report_local_unfinalized_metrics) (del modelo). Para más información, también consulte el tutorial sobre [clasificación de imágenes](federated_learning_for_image_classification.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SPwbipTNLo8a"
      },
      "outputs": [],
      "source": [
        "def model_fn():\n",
        "  keras_model = create_keras_model()\n",
        "  return tff.learning.models.from_keras_model(\n",
        "      keras_model,\n",
        "      input_spec=federated_train_data[0].element_spec,\n",
        "      loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCxa44rFiere"
      },
      "source": [
        "Mientras que en el caso de arriba se usó `tf.keras` para crear un `tff.learning.models.VariableModel`, TFF admite modelos mucho más generales. Estos modelos tienen los siguientes atributos relevantes que capturan los pesos:\n",
        "\n",
        "- `trainable_variables`: un iterable de tensores correspondiente a las capas entrenables.\n",
        "- `non_trainable_variables`: un iterable de tensores correspondiente a capas no entrenables.\n",
        "\n",
        "Para este tutorial, solamente se usarán las `trainable_variables`. (ya que son las únicas que tiene el modelo)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPOWP2JjsfTk"
      },
      "source": [
        "# Creación de un algoritmo propio de aprendizaje federado\n",
        "\n",
        "Si bien la API `tff.learning` permite que uno cree muchas variantes del cálculo del promedio federado, hay otros algoritmos federados que no se adaptan perfectamente a este marco de trabajo. Por ejemplo, tal vez le convenga agregar algoritmos de regularización, recorte (<em>clipping</em>) u otros más complicados como el [entrenamiento GAN federado](https://github.com/tensorflow/federated/tree/main/tensorflow_federated/python/research/gans). Probablemente, por otra parte, lo que le resulte interesante sea el [análisis federado](https://ai.googleblog.com/2020/05/federated-analytics-collaborative-data.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50N36Zz8qyY-"
      },
      "source": [
        "Si pretende trabajar con algoritmos más avanzados, deberá escribir su propio algoritmo con TFF. En muchos casos, los algoritmos federados tienen los siguientes 4 componentes:\n",
        "\n",
        "1. Un paso para la emisión (<em>broadcast</em>) del servidor al cliente.\n",
        "2. Un paso para la actualización del cliente local.\n",
        "3. Un paso para la carga del cliente al servidor.\n",
        "4. Un paso para la actualización del servidor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jH8s0GRdQt3b"
      },
      "source": [
        "En TFF, un algoritmo federado, normalmente, está representado por un [`tff.templates.IterativeProcess`](https://www.tensorflow.org/federated/api_docs/python/tff/templates/IterativeProcess) (que será referido simplemente como un `IterativeProcess`). Es una clase que contiene las funciones `initialize` y `next`. Aquí, `initialize` se usa para inicializar el servidor y `next` realizará una ronda de comunicación del algoritmo federado. Escribamos un esquema sobre cómo debería lucir de nuestro proceso iterativo para FedAvg.\n",
        "\n",
        "Primero, hay una función para inicializar que simplemente crea `tff.learning.models.VariableModel` y devuelve sus pesos entrenables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ylLpRa7T5DDh"
      },
      "outputs": [],
      "source": [
        "def initialize_fn():\n",
        "  model = model_fn()\n",
        "  return model.trainable_variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nb1-XAK8fB2A"
      },
      "source": [
        "Esta función tiene buen aspecto, pero como verá más adelante, deberá hacerle una pequeña modificación para convertirla en un \"cálculo TFF\".\n",
        "\n",
        "Luego, esbocemos un `next_fn`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IeHN-XLZfMso"
      },
      "outputs": [],
      "source": [
        "def next_fn(server_weights, federated_dataset):\n",
        "  # Broadcast the server weights to the clients.\n",
        "  server_weights_at_client = broadcast(server_weights)\n",
        "\n",
        "  # Each client computes their updated weights.\n",
        "  client_weights = client_update(federated_dataset, server_weights_at_client)\n",
        "\n",
        "  # The server averages these updates.\n",
        "  mean_client_weights = mean(client_weights)\n",
        "\n",
        "  # The server updates its model.\n",
        "  server_weights = server_update(mean_client_weights)\n",
        "\n",
        "  return server_weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWXvjXPWeujU"
      },
      "source": [
        "Centrémonos en implementar estos cuatro componentes por separado. Primero, enfoquémonos en las partes que se pueden implementar en TensorFlow puro, a saber, los pasos relacionados con el cliente y el servidor.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yKS4VkALo8g"
      },
      "source": [
        "## Bloques de TensorFlow "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxpNYucgLo8g"
      },
      "source": [
        "### Actualización del cliente\n",
        "\n",
        "El `tff.learning.models.VariableModel` se puede usar para hacer el entrenamiento del cliente, esencialmente, del mismo modo en que se entrenaría un modelo de TensorFlow. En particular, uno puede usar `tf.GradientTape` para calcular el gradiente en lotes de datos y luego aplicarlo con un `client_optimizer`. Este procedimiento solamente incluirá los pesos entrenables.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c5rHPKreLo8g"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def client_update(model, dataset, server_weights, client_optimizer):\n",
        "  \"\"\"Performs training (using the server model weights) on the client's dataset.\"\"\"\n",
        "  # Initialize the client model with the current server weights.\n",
        "  client_weights = model.trainable_variables\n",
        "  # Assign the server weights to the client model.\n",
        "  tf.nest.map_structure(lambda x, y: x.assign(y),\n",
        "                        client_weights, server_weights)\n",
        "\n",
        "  # Use the client_optimizer to update the local model.\n",
        "  for batch in dataset:\n",
        "    with tf.GradientTape() as tape:\n",
        "      # Compute a forward pass on the batch of data\n",
        "      outputs = model.forward_pass(batch)\n",
        "\n",
        "    # Compute the corresponding gradient\n",
        "    grads = tape.gradient(outputs.loss, client_weights)\n",
        "    grads_and_vars = zip(grads, client_weights)\n",
        "\n",
        "    # Apply the gradient using a client optimizer.\n",
        "    client_optimizer.apply_gradients(grads_and_vars)\n",
        "\n",
        "  return client_weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pP0D9XtoLo8i"
      },
      "source": [
        "### Actualización del servidor\n",
        "\n",
        "La actualización del servidor FedAvg es más simple que la del cliente. En este tutorial implementaremos el cálculo de promedios federados \"vainilla\", en el que los pesos del modelo del servidor se reemplazan con el promedio de los pesos del modelo del cliente. Una vez más, solamente se usan los pesos entrenables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rYxErLvHLo8i"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def server_update(model, mean_client_weights):\n",
        "  \"\"\"Updates the server model weights as the average of the client model weights.\"\"\"\n",
        "  model_weights = model.trainable_variables\n",
        "  # Assign the mean client weights to the server model.\n",
        "  tf.nest.map_structure(lambda x, y: x.assign(y),\n",
        "                        model_weights, mean_client_weights)\n",
        "  return model_weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddCklfWlVr1U"
      },
      "source": [
        "El fragmento se podría simplificar sencillamente con la devolución de `mean_client_weights`. Sin embargo, en las implementaciones más avanzadas del cálculo de promedio federado se usa `mean_client_weights` con técnicas más sofisticadas como <em>momentum</em> o adaptabilidad.\n",
        "\n",
        "**Desafío**: implementar una versión `server_update` que actualice los pesos del servidor para ser el punto medio entre model_weights y mean_client_weights. (Nota: este tipo de método de \"punto medio\" es análogo a trabajos recientes sobre el [<em>optimizador Lookahead</em>](https://arxiv.org/abs/1907.08610))."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KuP9g6RFLo8k"
      },
      "source": [
        "Hasta el momento, solamente se ha incluido código de TensorFlow. El motivo es el diseño, ya que el TFF permite usar gran parte del código de TensorFlow con el que ya está familiarizado. A continuación, deberá especificar la **lógica de orquestación**; es decir, la que dicta que el servidor emite (<em>broadcast</em>) al cliente y que el cliente carga en el servidor.\n",
        "\n",
        "El *núcleo federado* de TFF será indispensable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CgFLVPgLo8l"
      },
      "source": [
        "# Introducción al núcleo federado\n",
        "\n",
        "El núcleo federado (FC, por sus siglas en inglés) es un conjunto de interfaces de bajo nivel que sirve como base para la API `tff.learning`. Sin embargo, estas interfaces no se limitan al aprendizaje. De hecho, se pueden usar para análisis y muchos otros cálculos de datos distribuidos.\n",
        "\n",
        "A un alto nivel, el núcleo federado es un entorno de desarrollo que permite expresar de manera compacta la lógica de programación para combinar código de TensorFlow con los operadores de comunicación distribuidos (como las sumas y las emisiones distribuidas). El objetivo es brindarles a los investigadores y especialistas el control explícito de la comunicación distribuida en sus sistemas, sin requerir de otros detalles para la implementación (tales como la especificación de los intercambios de mensajes de red punto a punto).\n",
        "\n",
        "Un punto clave es que TFF está diseñado para la preservación de la privacidad. Por lo tanto, permite el control explícito del sitio donde residen los datos, para prevenir la acumulación indeseada de datos en el lugar del servidor centralizado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYinjNqZLo8l"
      },
      "source": [
        "## Datos federados\n",
        "\n",
        "El concepto de los \"datos federados\" es clave en TFF. Se refiere a una colección de elementos de datos alojados en un grupo de dispositivos en un sistema distribuido (p. ej., las bases de datos de clientes o los pesos del modelo del servidor). La colección entera de valores de todos los dispositivos se representa con un solo *valor federado*.\n",
        "\n",
        "Por ejemplo, supongamos que hay dispositivos clientes y que cada uno tiene un flotante que representa la temperatura de un tensor. Esos flotantes se pueden representar como *flotante federado* de la siguiente manera:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7EJY0MHpLo8l"
      },
      "outputs": [],
      "source": [
        "federated_float_on_clients = tff.FederatedType(tf.float32, tff.CLIENTS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSQAXD0FLo8n"
      },
      "source": [
        "Los tipos federados son especificados por un tipo de `T` de los miembros que lo componen (p. ej., `tf.float32`) y un grupo de dispositivos `G`. Normalmente, `G` es `tff.CLIENTS` o `tff.SERVER`. Un tipo federado como tal se representa con `{T}@G`, tal como se muestra a continuación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6mlPgubJLo8n"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'{float32}@CLIENTS'"
            ]
          },
          "execution_count": 12,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "str(federated_float_on_clients)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjAQytkeLo8o"
      },
      "source": [
        "¿Por qué a TFF le interesan tanto las ubicaciones? El objetivo clave de TFF es el de facilitar la escritura de código que se podría implementar en un sistema distribuido real. Significa que es vital razonar con respecto a qué subconjuntos de dispositivos ejecutan qué códigos y dónde residen las diferentes porciones de datos.\n",
        "\n",
        "TFF se centra en tres cosas: en los *datos*, en dónde se *ubican* los datos y en cómo se *transforman* esos datos. Las primeras dos se encuentran encapsuladas dentro de los tipos federados, mientras que la última, en *cálculos federados*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLT2FmVMLo8p"
      },
      "source": [
        "## Cálculos federados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XwDC1vTLo8p"
      },
      "source": [
        "TFF es un entorno de programación funcional fuertemente tipado cuyas unidades básicas son *cálculos federados*. Son porciones de lógica que aceptan valores federados como entrada y devuelven valores federados como salida.\n",
        "\n",
        "Por ejemplo, supongamos que quisiera calcular el promedio de temperaturas en los sensores de nuestro cliente. Podría definir lo siguiente (con nuestro flotante federado):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IfwXDNR1Lo8p"
      },
      "outputs": [],
      "source": [
        "@tff.federated_computation(tff.FederatedType(tf.float32, tff.CLIENTS))\n",
        "def get_average_temperature(client_temperatures):\n",
        "  return tff.federated_mean(client_temperatures)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSgs6Te5Lo8r"
      },
      "source": [
        "Podría preguntarse, en qué difiere esto del decorador `tf.function` de TensorFlow. La respuesta determinante es que el código generado por `tff.federated_computation` no es un código de TensorFlow ni de Python. Es una especificación de un sistema distribuido en un *lenguaje pegamento* interno independiente de plataformas.\n",
        "\n",
        "Si bien es cierto que puede sonar complicado, puede pensar en los cálculos TFF como funciones con firmas bien definidas. Este tipo de firmas se puede consultar directamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mVq500KzG2mB"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'({float32}@CLIENTS -> float32@SERVER)'"
            ]
          },
          "execution_count": 14,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "str(get_average_temperature.type_signature)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TveOYFfuLo8s"
      },
      "source": [
        "Este `tff.federated_computation` acepta argumentos del tipo federado `<float>@CLIENTS` y devuelve valores del mismo tipo `<float>@SERVER`. Los cálculos federados también van de servidor a cliente, de cliente a cliente o de servidor a servidor. Los cálculos federados además se pueden componer como las funciones normales, siempre y cuando haya coincidencia entre las firmas de tipo.\n",
        "\n",
        "Para facilitar el desarrollo, TFF permite invocar un `tff.federated_computation` como una función Python. Por ejemplo, se puede llamar lo siguiente:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PTowUHohG2mB"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "69.53334"
            ]
          },
          "execution_count": 15,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_average_temperature([68.5, 70.3, 69.8])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXn-yje9RJ6H"
      },
      "source": [
        "## Los cálculos sin ejecución <em>eager</em> y TensorFlow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwyj8f3HLo8w"
      },
      "source": [
        "Hay dos restricciones fundamentales para tener en cuenta. La primera, es que cuando un interpretador Python encuentra un decorador `tff.federated_computation`, la función se rastrea una vez y se serializa para futuros usos. Debido a la naturaleza descentralizada del aprendizaje federado, este uso futuro puede producirse en cualquier otro lugar, como en un entorno de ejecución remota. Por lo tanto, los cálculos TFF son fundamentalmente *non-eager* (no utilizan ejecución *eager*. Este comportamiento es, en cierto modo, análogo al del decorador [`tf.function`](https://www.tensorflow.org/api_docs/python/tf/function) en TensorFlow.\n",
        "\n",
        "La segunda, es que un cálculo federado solamente puede estar compuesto por operadores federados ( como `tff.federated_mean`), no pueden contener operaciones de TensorFlow. Hay que confinar el código de TensorFlow a bloques decorados con `tff.tf_computation`. El código TensorFlow más común, directamente, se puede decorar, como la siguiente función que toma un número y le agrega `0.5`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "huz3mNmMLo8w"
      },
      "outputs": [],
      "source": [
        "@tff.tf_computation(tf.float32)\n",
        "def add_half(x):\n",
        "  return tf.add(x, 0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ptjWALDLo8y"
      },
      "source": [
        "Estas también son firmas de tipo, pero *sin ubicaciones*. Por ejemplo, se puede llamar lo siguiente:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "34x5H2hzG2mC"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'(float32 -> float32)'"
            ]
          },
          "execution_count": 17,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "str(add_half.type_signature)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNjwrNMjLo8z"
      },
      "source": [
        "De este modo se pone de manifiesto la gran diferencia que hay entre `tff.federated_computation` y `tff.tf_computation`. El primero tiene ubicaciones explícitas, mientras que el segundo no.\n",
        "\n",
        "Se pueden usar bloques `tff.tf_computation` en cálculos federados para ubicaciones específicas. Cree una función que agregue un medio (<em>add half</em>), pero solamente a flotantes federados de clientes. Se puede hacer con `tff.federated_map`, que aplica un `tff.tf_computation` dado y, a la vez, preserva la ubicación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pG6nw3wiLo80"
      },
      "outputs": [],
      "source": [
        "@tff.federated_computation(tff.FederatedType(tf.float32, tff.CLIENTS))\n",
        "def add_half_on_clients(x):\n",
        "  return tff.federated_map(add_half, x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4msKRKJLo81"
      },
      "source": [
        "Esta función es casi idéntica a `add_half`, excepto porque solamente acepta valores con ubicación en `tff.CLIENTS` y devuelve valores con la misma ubicación. Esto se puede observar en su firma de tipo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x3H-oeWIG2mC"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'({float32}@CLIENTS -> {float32}@CLIENTS)'"
            ]
          },
          "execution_count": 19,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "str(add_half_on_clients.type_signature)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JxQ0DeiLo83"
      },
      "source": [
        "En resumen:\n",
        "\n",
        "- TFF opera sobre valores federados.\n",
        "- Cada valor federado tiene un *tipo federado*, con un *tipo* (p. ej., `tf.float32`) y una *ubicación* (p. ej., `tff.CLIENTS`).\n",
        "- Los valores federados se pueden transformar con *cálculos federados*, que se deben decorar con `tff.federated_computation` y una firma de tipo federado.\n",
        "- El código TensorFlow debe estar contenido en bloques con decoradores `tff.tf_computation`.\n",
        "- Estos bloques, después se pueden incorporar en cálculos federados.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvyFWox3Lo83"
      },
      "source": [
        "# Creación de un algoritmo propio de aprendizaje federado (repaso)\n",
        "\n",
        "Ahora que ya tiene una idea de lo que es el núcleo federado, puede crear su propio algoritmo de aprendizaje federado. Recuerde que antes (arriba) ya definió un `initialize_fn` y `next_fn` para su algoritmo. El `next_fn` usará `client_update` y `server_update` que ya ha definido<br>con código de TensorFlow puro.\n",
        "\n",
        "Sin embargo, para hacer nuestro algoritmo con un cálculo federado, necesitará que tanto `next_fn` como `initialize_fn` sean cada uno un `tff.federated_computation`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvY8fh1cLo84"
      },
      "source": [
        "## Bloques federados de TensorFlow "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0zNTO7LLo84"
      },
      "source": [
        "### Creación del cálculo de inicialización\n",
        "\n",
        "La función de inicializar será bastante simple: deberá crear un modelo con `model_fn`. Sin embargo, recuerde que debe separar nuestro código de TensorFlow con `tff.tf_computation`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jJY9xUBZLo84"
      },
      "outputs": [],
      "source": [
        "@tff.tf_computation\n",
        "def server_init():\n",
        "  model = model_fn()\n",
        "  return model.trainable_variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGlv8LLgLo85"
      },
      "source": [
        "Entonces, ahora, puede pasarlo directamente a cálculo federado con `tff.federated_value`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m2hinzuRLo86"
      },
      "outputs": [],
      "source": [
        "@tff.federated_computation\n",
        "def initialize_fn():\n",
        "  return tff.federated_value(server_init(), tff.SERVER)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFBghOgxLo88"
      },
      "source": [
        "### Creación de `next_fn`\n",
        "\n",
        "El código de actualización de cliente y servidor ahora se puede usar para escribir el algoritmo real. Primero, se transformará el `client_update` en un `tff.tf_computation` que acepta un conjunto de datos del cliente y los pesos del servidor, y sale un tensor de pesos del cliente actualizado.\n",
        "\n",
        "Necesitará los tipos correspondientes que decoren adecuadamente nuestra función. Afortunadamente, el tipo de pesos del servidor se puede extraer directamente desde nuestro modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ph_noHN2Lo88"
      },
      "outputs": [],
      "source": [
        "whimsy_model = model_fn()\n",
        "tf_dataset_type = tff.SequenceType(whimsy_model.input_spec)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMPgpTaW66qx"
      },
      "source": [
        "Observemos la firma de tipo del conjunto de datos. Recordemos que tomamos imágenes de 28 por 28 (con etiquetas de enteros) y las aplanamos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GE2sYVA9G2mE"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<float32[?,784],int32[?,1]>*'"
            ]
          },
          "execution_count": 23,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "str(tf_dataset_type)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuS8d0BHLo8-"
      },
      "source": [
        "También se puede extraer el tipo de pesos del modelo con nuestra función `server_init`, que figura más arriba."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4yx6CExMLo8-"
      },
      "outputs": [],
      "source": [
        "model_weights_type = server_init.type_signature.result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mS-Eh6Xj7J15"
      },
      "source": [
        "Al examinar la firma de tipo, podrá ver la arquitectura del modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_s8eFsyvG2mE"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<float32[784,10],float32[10]>'"
            ]
          },
          "execution_count": 25,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "str(model_weights_type)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1U1wTGRLo8_"
      },
      "source": [
        "Ahora podemos crear nuestro propio `tff.tf_computation` para la actualización del cliente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q0W05pMWLo9A"
      },
      "outputs": [],
      "source": [
        "@tff.tf_computation(tf_dataset_type, model_weights_type)\n",
        "def client_update_fn(tf_dataset, server_weights):\n",
        "  model = model_fn()\n",
        "  client_optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
        "  return client_update(model, tf_dataset, server_weights, client_optimizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uP5quaAuLo9B"
      },
      "source": [
        "La versión `tff.tf_computation` de la actualización del servidor se puede definir de un modo similar, con los tipos que ya ha extraído."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F4WvQtVzLo9B"
      },
      "outputs": [],
      "source": [
        "@tff.tf_computation(model_weights_type)\n",
        "def server_update_fn(mean_client_weights):\n",
        "  model = model_fn()\n",
        "  return server_update(model, mean_client_weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SImhLbu4Lo9D"
      },
      "source": [
        "Por último, pero no menos importante, deberá crear el `tff.federated_computation` que une todo. Esta función aceptará dos *valores federados*, uno correspondiente a los pesos del servidor (con la ubicación `tff.SERVER`) y otro correspondiente a los conjuntos de datos del cliente (con la ubicación `tff.CLIENTS`).\n",
        "\n",
        "Tenga en cuenta que ambos tipos ya han sido definidos más arriba. Simplemente debe darles la ubicación adecuada con `tff.FederatedType`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ekPsA8AsLo9D"
      },
      "outputs": [],
      "source": [
        "federated_server_type = tff.FederatedType(model_weights_type, tff.SERVER)\n",
        "federated_dataset_type = tff.FederatedType(tf_dataset_type, tff.CLIENTS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FXAX7vGLo9G"
      },
      "source": [
        "¿Recuerda los 4 elementos de un algoritmo FL (de aprendizaje federado)?\n",
        "\n",
        "1. Un paso para la emisión (<em>broadcast</em>) del servidor al cliente.\n",
        "2. Un paso para la actualización del cliente local.\n",
        "3. Un paso para la carga del cliente al servidor.\n",
        "4. Un paso para la actualización del servidor.\n",
        "\n",
        "Ahora que ha creado lo anterior, cada parte se puede representar de forma compacta como una sola línea de código TFF. Esta simplicidad es el motivo por el cual ha debido prestar suma atención a la especificación de cosas como los tipos federados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Epc7MwfELo9G"
      },
      "outputs": [],
      "source": [
        "@tff.federated_computation(federated_server_type, federated_dataset_type)\n",
        "def next_fn(server_weights, federated_dataset):\n",
        "  # Broadcast the server weights to the clients.\n",
        "  server_weights_at_client = tff.federated_broadcast(server_weights)\n",
        "\n",
        "  # Each client computes their updated weights.\n",
        "  client_weights = tff.federated_map(\n",
        "      client_update_fn, (federated_dataset, server_weights_at_client))\n",
        "  \n",
        "  # The server averages these updates.\n",
        "  mean_client_weights = tff.federated_mean(client_weights)\n",
        "\n",
        "  # The server updates its model.\n",
        "  server_weights = tff.federated_map(server_update_fn, mean_client_weights)\n",
        "\n",
        "  return server_weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWomG3TtLo9I"
      },
      "source": [
        "Ahora tiene un `tff.federated_computation` tanto para la inicialización del algoritmo como para la ejecución de un paso del algoritmo. Para terminarlo, debe pasar estos elementos a `tff.templates.IterativeProcess`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GxdWgEddLo9I"
      },
      "outputs": [],
      "source": [
        "federated_algorithm = tff.templates.IterativeProcess(\n",
        "    initialize_fn=initialize_fn,\n",
        "    next_fn=next_fn\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Z__9k-Dc1I3"
      },
      "source": [
        "Observemos la *firma de tipo * de las funciones `initialize` y `next` de nuestro proceso iterativo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EmyYgDNdG2mF"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'( -> <float32[784,10],float32[10]>@SERVER)'"
            ]
          },
          "execution_count": 31,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "str(federated_algorithm.initialize.type_signature)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UyyEi5Kec90_"
      },
      "source": [
        "Refleja el hecho de que `federated_algorithm.initialize` es una función no argumentativa que devuelve un modelo de una sola capa (con una matriz de peso de 784 por 10, y 10 unidades de sesgo)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZRwHwQsCG2mG"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'(<server_weights=<float32[784,10],float32[10]>@SERVER,federated_dataset={<float32[?,784],int32[?,1]>*}@CLIENTS> -> <float32[784,10],float32[10]>@SERVER)'"
            ]
          },
          "execution_count": 32,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "str(federated_algorithm.next.type_signature)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efpdHodmdU_6"
      },
      "source": [
        "Aquí, uno puede ver que `federated_algorithm.next` acepta un modelo de servidor y datos del cliente, y devuelve un modelo de servidor actualizado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4UYZ3qeMLo9N"
      },
      "source": [
        "## Evaluación del algoritmo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwd9Gs0ULo9O"
      },
      "source": [
        "Ejecutemos algunas rondas y veamos cómo cambia la pérdida. Primero, definirá una función de evaluación con el modo *centralizado* referido en el segundo tutorial.\n",
        "\n",
        "En primer lugar, creará un conjunto de datos de evaluación centralizado y luego aplicará el mismo preprocesamiento que se usó para los datos entrenados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EdNgYoIwLo9P"
      },
      "outputs": [],
      "source": [
        "central_emnist_test = emnist_test.create_tf_dataset_from_all_clients()\n",
        "central_emnist_test = preprocess(central_emnist_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7R50NZ35dphE"
      },
      "source": [
        "A continuación, deberá escribir una función que acepte un estado del servidor y use Keras para evaluar en el conjunto de datos de prueba. Si está familiarizado con `tf.Keras`, todo esto también le resultará familiar; de todos modos, preste particular atención al uso de `set_weights`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I5UEX4EWLo9Q"
      },
      "outputs": [],
      "source": [
        "def evaluate(server_state):\n",
        "  keras_model = create_keras_model()\n",
        "  keras_model.compile(\n",
        "      loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]  \n",
        "  )\n",
        "  keras_model.set_weights(server_state)\n",
        "  keras_model.evaluate(central_emnist_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hygoBACkLo9S"
      },
      "source": [
        "Ahora, inicialicemos nuestro algoritmo y evaluemos el conjunto de prueba."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CDarZn71G2mH"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2042/2042 [==============================] - 2s 767us/step - loss: 2.8479 - sparse_categorical_accuracy: 0.1027\n"
          ]
        }
      ],
      "source": [
        "server_state = federated_algorithm.initialize()\n",
        "evaluate(server_state)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2knqix2cLo9U"
      },
      "source": [
        "Entrenemos durante algunas rondas y veamos si cambia algo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v1zBlzFILo9U"
      },
      "outputs": [],
      "source": [
        "for round in range(15):\n",
        "  server_state = federated_algorithm.next(server_state, federated_train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2QDhaI_DG2mH"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2042/2042 [==============================] - 2s 738us/step - loss: 2.5867 - sparse_categorical_accuracy: 0.0980\n"
          ]
        }
      ],
      "source": [
        "evaluate(server_state)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XM34ammUW-T3"
      },
      "source": [
        "Hay una disminución leve en la función de pérdida. Si bien el salto es pequeño, solamente ha realizado 15 rondas de entrenamiento y sobre un subconjunto reducido de clientes. Para ver mejores resultados, probablemente deba hacer cientos o miles de rondas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o13H5dDFXRFn"
      },
      "source": [
        "## Modificación del algoritmo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qt4jVD21XTL-"
      },
      "source": [
        "En este punto, detengámonos a pensar sobre lo que hemos logrado. Ha implementado el cálculo promedio federado directamente mediante la combinación de código de TensorFlow puro (para las actualizaciones del cliente y del servidor) con cálculos federados del núcleo federado de TFF.\n",
        "\n",
        "Para realizar un aprendizaje más sofisticado, simplemente puede alterar lo que hizo arriba. En particular, editando el código de TF puro mencionado puede cambiar la manera en que el cliente realiza el entrenamiento o cómo el servidor actualiza su modelo.\n",
        "\n",
        "**Desafío:** agregar [recorte (<em>clipping</em>) de gradiente](https://towardsdatascience.com/what-is-gradient-clipping-b8e815cdfb48) a la función `client_update`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7wvwgS7bCTy"
      },
      "source": [
        "Si lo que busca es hacer cambios más grandes, también podría hacer que el servidor almacene y emita más datos. Por ejemplo, el servidor también podría almacenar la velocidad de aprendizaje del cliente y hacerla decaer a lo largo del tiempo. Tenga en cuenta que, para que esto suceda, podría haber que hacer cambios en las firmas de tipo usadas arriba en las llamadas de `tff.tf_computation`.\n",
        "\n",
        "**Desafío mayor:** implementar el cálculo de promedio federado con el decaimiento de la velocidad en los clientes.\n",
        "\n",
        "A esta altura, podría empezar a darse cuenta de cuánta flexibilidad hay en lo que puede implementar en este marco de trabajo. Para más ideas (incluida la respuesta al desafío mayor anterior) puede ver el código fuente para [`tff.learning.algorithms.build_weighted_fed_avg`](https://www.tensorflow.org/federated/api_docs/python/tff/learning/algorithms/build_weighted_fed_avg) o consultar varios [proyectos de investigación](https://github.com/google-research/federated) en los que se usa TFF."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "building_your_own_federated_learning_algorithm.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
