{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qN8P0AnTnAhh"
      },
      "source": [
        "##### Copyright 2019 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "p8SrVqkmnDQv"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AftvNA5VMemJ"
      },
      "source": [
        "# Aprendizaje federado para clasificación de imágenes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coAumH42q9nz"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td><a target=\"_blank\" href=\"https://www.tensorflow.org/federated/tutorials/federated_learning_for_image_classification\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver en TensorFlow.org</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/es-419/federated/tutorials/federated_learning_for_image_classification.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Ver en TensorFlow.org</a></td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/es-419/federated/tutorials/federated_learning_for_image_classification.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver fuente en GitHub</a>\n",
        "</td>\n",
        "  <td><a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/es-419/federated/tutorials/federated_learning_for_image_classification.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Descargar el bloc de notas</a></td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zs2LgZBOMt4M"
      },
      "source": [
        "**NOTA**: Esta colaboración ha sido verificada para trabajar con la [versión de lanzamiento más reciente](https://github.com/tensorflow/federated#compatibility) del paquete pip `tensorflow_federated`, pero el proyecto federado de TensorFlow aún se encuentra en una etapa de desarrollo previa al lanzamiento. Por lo tanto, es probable que no funcione en `main`.\n",
        "\n",
        "En este tutorial usamos el ejemplo de entrenamiento clásico MNIST para presentar la capa de API de aprendizaje federado (FL, por sus siglas en inglés) de TFF, `tff.learning`; un conjunto de interfaces que se puede utilizar para realizar distintos tipos de tareas de aprendizaje federado, como un entrenamiento federado, con respecto a los modelos implementados por TensorFlow provistos por usuarios.\n",
        "\n",
        "Este tutorial y la API de aprendizaje federado se diseñaron principalmente para usuarios que deseen conectar sus propios modelos de TensorFlow a TFF, tratando a este último principalmente como una caja negra. Para comprender mejor TFF y cómo implementar sus propios algoritmos de aprendizaje federado, consulte los tutoriales sobre la API FC Core: [algoritmos federados personalizados, parte 1](custom_federated_algorithms_1.ipynb) y [parte 2](custom_federated_algorithms_2.ipynb).\n",
        "\n",
        "Para obtener más información sobre `tff.learning`, continúe con el tutorial [Aprendizaje federado para generación de textos](federated_learning_for_text_generation.ipynb), que además de cubrir modelos recurrentes, también demuestra cómo cargar un modelo Keras serializado previamente entrenado para refinarlo con aprendizaje federado combinado con evaluación usando Keras."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnUwFbCAKB2r"
      },
      "source": [
        "## Antes de empezar\n",
        "\n",
        "Antes de empezar, ejecute lo que se encuentra a continuación, para asegurarse de que el entorno esté preparado correctamente. Si no ve un mensaje de inicio, consulte la guía de [instalación](../install.md) para obtener más instrucciones. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZrGitA_KnRO0"
      },
      "outputs": [],
      "source": [
        "#@test {\"skip\": true}\n",
        "\n",
        "!pip install --quiet --upgrade tensorflow-federated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QLyJIaLlERJ8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Fetching TensorBoard MPM version 'live'... done.\n"
          ]
        }
      ],
      "source": [
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8BKyHkMxKHfV"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "b'Hello, World!'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import collections\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_federated as tff\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "tff.federated_computation(lambda: 'Hello, World!')()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Cyy2AWbLMKj"
      },
      "source": [
        "## Preparación de los datos de entrada\n",
        "\n",
        "Empecemos con los datos. Para poner en práctica el aprendizaje federado es necesario contar con un conjunto de datos federados; es decir, una colección de datos de múltiples usuarios. Los datos federados normalmente son no [i.i.d.](https://en.wikipedia.org/wiki/Independent_and_identically_distributed_random_variables), lo que presenta un grupo de problemas particulares.\n",
        "\n",
        "Para facilitar la experimentación, sembramos el repositorio de TFF con algunos conjuntos de datos, incluida una versión federada de MNIST que contiene una versión [conjunto de datos original de NIST](https://www.nist.gov/srd/nist-special-database-19) que ha sido reprocesado usando [Leaf](https://github.com/TalwalkarLab/leaf) para que los datos sean codificados por el escritor original de los dígitos. Dado que cada escritor tiene un estilo único, este conjunto de datos muestra el tipo de comportamiento no i.i.d. que se espera de los conjuntos de datos federados.\n",
        "\n",
        "Podemos cargarlo de la siguiente manera."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NayDhCX6SjwE"
      },
      "outputs": [],
      "source": [
        "emnist_train, emnist_test = tff.simulation.datasets.emnist.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yeX8BKgPfeFw"
      },
      "source": [
        "Los conjuntos de datos que devuelve `load_data()` son instancias de `tff.simulation.ClientData`, una interfaz que le permite enumerar el conjunto de usuarios, construir un `tf.data.Dataset` que representa los datos de un usuario en particular y consultar la estructura de elementos individuales. A continuación, se explica cómo puede utilizar esta interfaz para explorar el contenido del conjunto de datos. Tenga en cuenta que, si bien esta interfaz le permite iterar sobre los identificadores de los clientes, esto es solo una característica de los datos de simulación. Como verá en breve, el marco de aprendizaje federado no utiliza identidades de clientes; su único propósito es permitirle seleccionar subconjuntos de datos para simulaciones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kN4-U5nJgKig"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3383"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(emnist_train.client_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZyCzIrSegT62"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "OrderedDict([('label', TensorSpec(shape=(), dtype=tf.int32, name=None)), ('pixels', TensorSpec(shape=(28, 28), dtype=tf.float32, name=None))])"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "emnist_train.element_type_structure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EsvSXGEMgd9G"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "example_dataset = emnist_train.create_tf_dataset_for_client(\n",
        "    emnist_train.client_ids[0])\n",
        "\n",
        "example_element = next(iter(example_dataset))\n",
        "\n",
        "example_element['label'].numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OmLV0nfMg98V"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.imshow(example_element['pixels'].numpy(), cmap='gray', aspect='equal')\n",
        "plt.grid(False)\n",
        "_ = plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGnxdUp8Cj5h"
      },
      "source": [
        "### Exploración de la heterogeneidad en datos federados\n",
        "\n",
        "Los datos federados normalmente no son [i.i.d.](https://en.wikipedia.org/wiki/Independent_and_identically_distributed_random_variables) y los usuarios suelen tener diferentes distribuciones de datos según los patrones de uso. Algunos clientes pueden tener menos ejemplos de entrenamiento en el dispositivo, ya que sufren escasez de datos a nivel local, mientras que otros clientes tendrán ejemplos de entrenamiento más que suficientes. Exploremos este concepto de heterogeneidad de datos típico de un sistema federado con los datos de EMNIST que tenemos disponibles. Es importante tener en cuenta que este análisis profundo de los datos de un cliente solo está disponible para nosotros porque se trata de un entorno de simulación donde todos los datos están disponibles para nosotros localmente. En un entorno federado de producción real, no sería posible inspeccionar los datos de un solo cliente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77mx33vXFrqd"
      },
      "source": [
        "Primero, tomemos una muestra de los datos de un cliente para tener una idea de los ejemplos en un dispositivo simulado. Debido a que el conjunto de datos que estamos usando fue codificado por un escritor único, los datos de un cliente representan la escritura a mano de una persona para una muestra de los dígitos del 0 al 9, simulando el \"patrón de uso\" único de un usuario."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PfRva0fsFfSX"
      },
      "outputs": [],
      "source": [
        "## Example MNIST digits for one client\n",
        "figure = plt.figure(figsize=(20, 4))\n",
        "j = 0\n",
        "\n",
        "for example in example_dataset.take(40):\n",
        "  plt.subplot(4, 10, j+1)\n",
        "  plt.imshow(example['pixels'].numpy(), cmap='gray', aspect='equal')\n",
        "  plt.axis('off')\n",
        "  j += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6wB6PggHO3g"
      },
      "source": [
        "Ahora visualicemos la cantidad de ejemplos en cada cliente para cada etiqueta de dígito MNIST. En el entorno federado, la cantidad de ejemplos en cada cliente puede variar bastante, según el comportamiento del usuario."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vrjtRk5kICeN"
      },
      "outputs": [],
      "source": [
        "# Number of examples per layer for a sample of clients\n",
        "f = plt.figure(figsize=(12, 7))\n",
        "f.suptitle('Label Counts for a Sample of Clients')\n",
        "for i in range(6):\n",
        "  client_dataset = emnist_train.create_tf_dataset_for_client(\n",
        "      emnist_train.client_ids[i])\n",
        "  plot_data = collections.defaultdict(list)\n",
        "  for example in client_dataset:\n",
        "    # Append counts individually per label to make plots\n",
        "    # more colorful instead of one color per plot.\n",
        "    label = example['label'].numpy()\n",
        "    plot_data[label].append(label)\n",
        "  plt.subplot(2, 3, i+1)\n",
        "  plt.title('Client {}'.format(i))\n",
        "  for j in range(10):\n",
        "    plt.hist(\n",
        "        plot_data[j],\n",
        "        density=False,\n",
        "        bins=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9vBNGd2I4Kn"
      },
      "source": [
        "Ahora visualicemos la imagen media por cliente para cada etiqueta MNIST. Este código producirá la media de cada valor de píxel para todos los ejemplos del usuario para una etiqueta. Veremos que la imagen media de un cliente para un dígito se verá diferente a la imagen media de otro cliente para el mismo dígito, debido al estilo de escritura único de cada persona. Podemos reflexionar sobre cómo cada ronda de entrenamiento local empujará el modelo en una dirección diferente en cada cliente, a medida que aprendemos de los datos únicos de ese usuario en esa ronda local. Más adelante en el tutorial veremos cómo podemos tomar cada actualización del modelo de todos los clientes y agregarlas en nuestro nuevo modelo global, que ha aprendido de los datos únicos de cada uno de nuestros clientes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qfkNoBCTJ5Pl"
      },
      "outputs": [],
      "source": [
        "# Each client has different mean images, meaning each client will be nudging\n",
        "# the model in their own directions locally.\n",
        "\n",
        "for i in range(5):\n",
        "  client_dataset = emnist_train.create_tf_dataset_for_client(\n",
        "      emnist_train.client_ids[i])\n",
        "  plot_data = collections.defaultdict(list)\n",
        "  for example in client_dataset:\n",
        "    plot_data[example['label'].numpy()].append(example['pixels'].numpy())\n",
        "  f = plt.figure(i, figsize=(12, 5))\n",
        "  f.suptitle(\"Client #{}'s Mean Image Per Label\".format(i))\n",
        "  for j in range(10):\n",
        "    mean_img = np.mean(plot_data[j], 0)\n",
        "    plt.subplot(2, 5, j+1)\n",
        "    plt.imshow(mean_img.reshape((28, 28)))\n",
        "    plt.axis('off')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpBrx5Jn7X5E"
      },
      "source": [
        "Los datos del usuario pueden ser ruidosos y estar etiquetados de manera poco confiable. Por ejemplo, al observar los datos del Cliente n.º 2 anteriores, podemos ver que para la etiqueta 2, es posible que haya habido algunos ejemplos mal etiquetados que crearon una imagen media más ruidosa."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0pwnQZUKea2"
      },
      "source": [
        "### Preprocesamiento de los datos de entrada"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMd01egqy9we"
      },
      "source": [
        "Dado que los datos ya son `tf.data.Dataset`, el preprocesamiento se puede lograr mediante transformaciones de conjuntos de datos. Aquí, aplanamos las imágenes de `28x28` en arreglos de `784` elementos, mezclamos los ejemplos individuales, los organizamos en lotes y cambiamos el nombre de las características de `pixels` y `label` a `x` para usarlas con Keras. También incluimos una `repeat` del conjunto de datos para ejecutar varias épocas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cyG_BMraSuu_"
      },
      "outputs": [],
      "source": [
        "NUM_CLIENTS = 10\n",
        "NUM_EPOCHS = 5\n",
        "BATCH_SIZE = 20\n",
        "SHUFFLE_BUFFER = 100\n",
        "PREFETCH_BUFFER = 10\n",
        "\n",
        "def preprocess(dataset):\n",
        "\n",
        "  def batch_format_fn(element):\n",
        "    \"\"\"Flatten a batch `pixels` and return the features as an `OrderedDict`.\"\"\"\n",
        "    return collections.OrderedDict(\n",
        "        x=tf.reshape(element['pixels'], [-1, 784]),\n",
        "        y=tf.reshape(element['label'], [-1, 1]))\n",
        "\n",
        "  return dataset.repeat(NUM_EPOCHS).shuffle(SHUFFLE_BUFFER, seed=1).batch(\n",
        "      BATCH_SIZE).map(batch_format_fn).prefetch(PREFETCH_BUFFER)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9LXykN_jlJw"
      },
      "source": [
        "Verifiquemos si funcionó."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VChB7LMQjkYz"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "OrderedDict([('x', array([[1., 1., 1., ..., 1., 1., 1.],\n",
              "       [1., 1., 1., ..., 1., 1., 1.],\n",
              "       [1., 1., 1., ..., 1., 1., 1.],\n",
              "       ...,\n",
              "       [1., 1., 1., ..., 1., 1., 1.],\n",
              "       [1., 1., 1., ..., 1., 1., 1.],\n",
              "       [1., 1., 1., ..., 1., 1., 1.]], dtype=float32)), ('y', array([[2],\n",
              "       [1],\n",
              "       [5],\n",
              "       [7],\n",
              "       [1],\n",
              "       [7],\n",
              "       [7],\n",
              "       [1],\n",
              "       [4],\n",
              "       [7],\n",
              "       [4],\n",
              "       [2],\n",
              "       [2],\n",
              "       [5],\n",
              "       [4],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [9]], dtype=int32))])"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "preprocessed_example_dataset = preprocess(example_dataset)\n",
        "\n",
        "sample_batch = tf.nest.map_structure(lambda x: x.numpy(),\n",
        "                                     next(iter(preprocessed_example_dataset)))\n",
        "\n",
        "sample_batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGsMvRQt9Agl"
      },
      "source": [
        "Ya tenemos casi todos los bloques de creación necesarios para construir conjuntos de datos federados.\n",
        "\n",
        "Una de las formas de cargar datos federados a TFF en una simulación es simplemente como una lista de Python, en la que cada elemento de la lista contiene los datos de un usuario individual, ya sea como una lista o como un `tf.data.Dataset`. Como ya tenemos una interfaz que ofrece esto último, usémosla.\n",
        "\n",
        "Aquí, presentamos una función ayudante simple que construirá una lista de conjuntos de datos (a partir de un conjunto dado de usuarios) como entrada a una ronda de entrenamiento o evaluación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_PHMvHAI9xVc"
      },
      "outputs": [],
      "source": [
        "def make_federated_data(client_data, client_ids):\n",
        "  return [\n",
        "      preprocess(client_data.create_tf_dataset_for_client(x))\n",
        "      for x in client_ids\n",
        "  ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0M9PfjOtAVqw"
      },
      "source": [
        "Ahora, ¿cómo elegimos a los clientes?\n",
        "\n",
        "En un escenario de entrenamiento federado típico, nos encontramos con una población potencialmente muy grande de dispositivos de usuario, de los cuales solo una fracción puede estar disponible para el entrenamiento en un momento determinado. Este es el caso, por ejemplo, cuando los dispositivos cliente son teléfonos móviles que participan en el entrenamiento solo cuando están conectados a una fuente de energía, fuera de una red medida y, en general, inactivos.\n",
        "\n",
        "Por supuesto, estamos en un entorno de simulación y todos los datos están disponibles a nivel local. Por lo general, cuando ejecutamos simulaciones, simplemente tomamos muestras de un subconjunto aleatorio de los clientes que participarán en cada ronda de entrenamiento, que generalmente son diferentes en cada ronda.\n",
        "\n",
        "Dicho esto, como podrá comprobar si estudia el documento sobre el algoritmo de [promediado federado](https://arxiv.org/abs/1602.05629), lograr la convergencia en un sistema con subconjuntos de clientes seleccionados aleatoriamente en cada ronda puede llevar un tiempo, y no sería práctico tener que ejecutar cientos de rondas en este tutorial interactivo.\n",
        "\n",
        "Lo que haremos en su lugar es tomar muestras del conjunto de clientes una vez y reutilizar el mismo conjunto en rondas para acelerar la convergencia (sobreajustando intencionalmente los datos de estos pocos usuarios). Como ejercicio, el lector puede modificar este tutorial para simular la toma de muestras aleatorias; es una tarea bastante fácil (una vez que lo haga, tenga en cuenta que lograr que el modelo converja podría llevar un tiempo)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GZ6NYHxB8xer"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of client datasets: 10\n",
            "First dataset: <_PrefetchDataset element_spec=OrderedDict([('x', TensorSpec(shape=(None, 784), dtype=tf.float32, name=None)), ('y', TensorSpec(shape=(None, 1), dtype=tf.int32, name=None))])>\n"
          ]
        }
      ],
      "source": [
        "sample_clients = emnist_train.client_ids[0:NUM_CLIENTS]\n",
        "\n",
        "federated_train_data = make_federated_data(emnist_train, sample_clients)\n",
        "\n",
        "print(f'Number of client datasets: {len(federated_train_data)}')\n",
        "print(f'First dataset: {federated_train_data[0]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOxq4tbi9m8-"
      },
      "source": [
        "## Creación de un modelo con Keras\n",
        "\n",
        "Si usa Keras, probablemente ya tenga el código que construye un modelo Keras. A continuación, mostramos un ejemplo de un modelo simple que bastará para nuestro propósito."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LYCsJGJFWbqt"
      },
      "outputs": [],
      "source": [
        "def create_keras_model():\n",
        "  return tf.keras.models.Sequential([\n",
        "      tf.keras.layers.InputLayer(input_shape=(784,)),\n",
        "      tf.keras.layers.Dense(10, kernel_initializer='zeros'),\n",
        "      tf.keras.layers.Softmax(),\n",
        "  ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHdraKFH4OU2"
      },
      "source": [
        "**Nota:** Aún no compilamos el modelo. La pérdida, las métricas y los optimizadores se presentan más adelante.\n",
        "\n",
        "Para utilizar cualquier modelo con TFF, es necesario incluirlo en una instancia de la interfaz `tff.learning.models.VariableModel`, que expone métodos para marcar el paso directo del modelo, las propiedades de los metadatos, etc., de manera similar a Keras, pero también introduce elementos adicionales, como formas de controlar el proceso de cálculo de métricas federadas. No nos preocupemos por esto por ahora; Si tiene un modelo de Keras como el que acabamos de definir anteriormente, puede hacer que TFF lo envuelva por usted al invocar `tff.learning.models.from_keras_model`, pasando el modelo y un lote de datos de muestra como argumentos, como se muestra a continuación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q3ynrxd53HzY"
      },
      "outputs": [],
      "source": [
        "def model_fn():\n",
        "  # We _must_ create a new model here, and _not_ capture it from an external\n",
        "  # scope. TFF will call this within different graph contexts.\n",
        "  keras_model = create_keras_model()\n",
        "  return tff.learning.models.from_keras_model(\n",
        "      keras_model,\n",
        "      input_spec=preprocessed_example_dataset.element_spec,\n",
        "      loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJ5E3O18_JZ6"
      },
      "source": [
        "## Entrenamiento del modelo con datos federados\n",
        "\n",
        "Ahora que tenemos un modelo envuelto como `tff.learning.models.VariableModel` para usar con TFF, podemos dejar que TFF construya un algoritmo de promediado federado invocando la función ayudante `tff.learning.algorithms.build_weighted_fed_avg`, como se muestra a continuación.\n",
        "\n",
        "Tenga en cuenta que el argumento debe ser un constructor (como `model_fn` arriba), no una instancia ya construida, para que la construcción de su modelo pueda ocurrir en un contexto controlado por TFF (si le interesa conocer las razones de esto, le recomendamos que lea el tutorial de seguimiento sobre [algoritmos personalizados](custom_federated_algorithms_1.ipynb)).\n",
        "\n",
        "Una observación importante sobre el algoritmo de promediado federado que se muestra a continuación es que hay **2** optimizadores: *client_optimizer* y *server_optimizer*. El optimizador *client_optimizer* solo se usa para calcular actualizaciones del modelo local en cada cliente. El optimizador *server_optimizer* aplica la actualización promediada al modelo global en el servidor. En concreto, esto significa que quizá deba elegir un optimizador y una tasa de aprendizaje distintos de los que usó para entrenar el modelo en un conjunto de datos i.i.d. estándar. Recomendamos comenzar con un SGD normal, posiblemente con una tasa de aprendizaje menor de la habitual. La tasa de aprendizaje que usamos no se ajustó cuidadosamente, siéntase libre de experimentar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sk6mjOfycX5N"
      },
      "outputs": [],
      "source": [
        "training_process = tff.learning.algorithms.build_weighted_fed_avg(\n",
        "    model_fn,\n",
        "    client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.02),\n",
        "    server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1.0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8FpvN2n67sm"
      },
      "source": [
        "¿Qué acaba de suceder? TFF ha construido un par de *cálculos federados* y los empaquetó en un `tff.templates.IterativeProcess` en el que estos cálculos están disponibles como un par de propiedades `initialize` y `next`.\n",
        "\n",
        "En pocas palabras, *los cálculos federados* son programas en el lenguaje interno de TFF que pueden expresar varios algoritmos federados (consulte más información al respecto en el tutorial de [algoritmos personalizados](custom_federated_algorithms_1.ipynb)). En este caso, los dos cálculos generados y empaquetados en `iterative_process` implementan el [promedio federado](https://arxiv.org/abs/1602.05629).\n",
        "\n",
        "Uno de los objetivos de TFF es definir los cálculos de tal forma que puedan ejecutarse en entornos reales de aprendizaje federado, pero actualmente solo se implementa el tiempo de ejecución de simulación de ejecución local. Para ejecutar un cálculo en un simulador, simplemente invóquelo como una función de Python. Este entorno interpretado de forma predeterminada no está diseñado para ofrecer un gran rendimiento, pero será suficiente para este tutorial; esperamos proporcionar tiempos de ejecución de simulación de mayor rendimiento para facilitar la investigación a mayor escala en versiones futuras.\n",
        "\n",
        "Comencemos con el cálculo `initialize`. Como pasa con todos los cálculos federados, se puede considerar como una función. El cálculo no toma argumentos y devuelve un resultado: la representación del estado del proceso de promediado federado en el servidor. Aunque no queremos entrar en los detalles de TFF, quizá resulte útil ver cómo es este estado. Puede verlo de la siguiente manera."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z4pcfWsUBp_5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "( -> <\n",
            "  global_model_weights=<\n",
            "    trainable=<\n",
            "      float32[784,10],\n",
            "      float32[10]\n",
            "    >,\n",
            "    non_trainable=<>\n",
            "  >,\n",
            "  distributor=<>,\n",
            "  client_work=<>,\n",
            "  aggregator=<\n",
            "    value_sum_process=<>,\n",
            "    weight_sum_process=<>\n",
            "  >,\n",
            "  finalizer=<\n",
            "    int64,\n",
            "    float32[784,10],\n",
            "    float32[10]\n",
            "  >\n",
            ">@SERVER)\n"
          ]
        }
      ],
      "source": [
        "print(training_process.initialize.type_signature.formatted_representation())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1gbHQ_7BiyT"
      },
      "source": [
        "Si bien la firma de tipo anterior puede parecer un poco críptica al principio, puede reconocer que el estado del servidor consta de `global_model_weights` (los parámetros del modelo inicial para MNIST que se distribuirán a todos los dispositivos), algunos parámetros vacíos (como `distributor`, que controla la comunicación de servidor a cliente) y un componente `finalizer`. Este último controla la lógica que utiliza el servidor para actualizar su modelo al final de una ronda y contiene un número entero que representa cuántas rondas de FedAvg se ejecutaron.\n",
        "\n",
        "Invoquemos el cálculo `initialize` para construir el estado del servidor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6cagCWlZmcch"
      },
      "outputs": [],
      "source": [
        "train_state = training_process.initialize()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjjxTx9e_rMd"
      },
      "source": [
        "El segundo par de cálculos federados, `next`, representa a una única ronda de promediado federado, que consiste en enviar el estado del servidor (incluidos los parámetros del modelo) a los clientes, el entrenamiento en el dispositivo sobre sus datos locales, la recopilación y promediado de las actualizaciones del modelo, y la producción de un nuevo modelo que se actualiza en el servidor.\n",
        "\n",
        "A nivel conceptual, se puede pensar que `next` tiene una firma de tipo funcional con el siguiente aspecto.\n",
        "\n",
        "```\n",
        "SERVER_STATE, FEDERATED_DATA -&gt; SERVER_STATE, TRAINING_METRICS\n",
        "```\n",
        "\n",
        "En particular, uno no debería pensar en `next()` como una función que se ejecuta en un servidor, sino más bien como una representación funcional declarativa de todo el cálculo descentralizado: el servidor proporciona algunas de las entradas (`SERVER_STATE`), pero cada dispositivo participante aporta su propio conjunto de datos local.\n",
        "\n",
        "Ejecutemos una única ronda de entrenamiento y observemos los resultados. Podemos usar los datos federados que ya generamos anteriormente como muestra de usuarios."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F3M_W9dDE6Tm"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "round  1, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.12345679), ('loss', 3.1193733), ('num_examples', 4860), ('num_batches', 248)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n"
          ]
        }
      ],
      "source": [
        "result = training_process.next(train_state, federated_train_data)\n",
        "train_state = result.state\n",
        "train_metrics = result.metrics\n",
        "print('round  1, metrics={}'.format(train_metrics))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmhReXt9G4A5"
      },
      "source": [
        "Ejecutemos algunas rondas más. Tal como lo señalamos antes, normalmente en esta instancia, elegiríamos un subconjunto de los datos de simulación a partir de una muestra de usuarios seleccionada de forma aleatoria para cada ronda, a fin de simular una implementación realista en la cual los usuarios entran y salen continuamente. Pero en estas notas interactivas, con propósito demostrativo, nos limitaremos a reutilizar los mismos usuarios, para que el sistema converja rápidamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qrJkQuCRJP9C"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "round  2, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.14012346), ('loss', 2.9851403), ('num_examples', 4860), ('num_batches', 248)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "round  3, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.1590535), ('loss', 2.8617127), ('num_examples', 4860), ('num_batches', 248)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "round  4, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.17860082), ('loss', 2.7401376), ('num_examples', 4860), ('num_batches', 248)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "round  5, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.20102881), ('loss', 2.6186547), ('num_examples', 4860), ('num_batches', 248)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "round  6, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.22345679), ('loss', 2.5006158), ('num_examples', 4860), ('num_batches', 248)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "round  7, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.24794239), ('loss', 2.3858356), ('num_examples', 4860), ('num_batches', 248)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "round  8, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.27160493), ('loss', 2.2757034), ('num_examples', 4860), ('num_batches', 248)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "round  9, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.2958848), ('loss', 2.17098), ('num_examples', 4860), ('num_batches', 248)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "round 10, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.3251029), ('loss', 2.072707), ('num_examples', 4860), ('num_batches', 248)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n"
          ]
        }
      ],
      "source": [
        "NUM_ROUNDS = 11\n",
        "for round_num in range(2, NUM_ROUNDS):\n",
        "  result = training_process.next(train_state, federated_train_data)\n",
        "  train_state = result.state\n",
        "  train_metrics = result.metrics\n",
        "  print('round {:2d}, metrics={}'.format(round_num, train_metrics))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "joHYzn9jcs0Y"
      },
      "source": [
        "La pérdida de entrenamiento disminuye después de cada ronda de entrenamiento federado. Es señal de que el modelo está convergiendo. No obstante, hay algunas salvedades importantes relacionadas con estas métricas de entrenamiento. Si desea conocerlas, consulte la sección *Evaluación* que se trata más adelante en este tutorial."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruSHJl1IjhNf"
      },
      "source": [
        "## Visualización de las métricas del modelo en TensorBoard\n",
        "\n",
        "A continuación, observemos las métricas de estos cálculos federados en TensorBoard.\n",
        "\n",
        "Comencemos por crear un directorio y el escritor de resúmenes correspondiente en el que se redactarán las métricas.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E3QUBK41lWDW"
      },
      "outputs": [],
      "source": [
        "#@test {\"skip\": true}\n",
        "logdir = \"/tmp/logs/scalars/training/\"\n",
        "try:\n",
        "  tf.io.gfile.rmtree(logdir)  # delete any previous results\n",
        "except tf.errors.NotFoundError as e:\n",
        "  pass # Ignore if the directory didn't previously exist.\n",
        "summary_writer = tf.summary.create_file_writer(logdir)\n",
        "train_state = training_process.initialize()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-2aGxUlzS_J"
      },
      "source": [
        "Tracemos las métricas escalares relevantes con el mismo escritor de resúmenes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JZtr4_8lzN-V"
      },
      "outputs": [],
      "source": [
        "#@test {\"skip\": true}\n",
        "with summary_writer.as_default():\n",
        "  for round_num in range(1, NUM_ROUNDS):\n",
        "    result = training_process.next(train_state, federated_train_data)\n",
        "    train_state = result.state\n",
        "    train_metrics = result.metrics\n",
        "    for name, value in train_metrics['client_work']['train'].items():\n",
        "      tf.summary.scalar(name, value, step=round_num)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUouyAHG0Mk8"
      },
      "source": [
        "Iniciemos TensorBoard con el directorio de registros raíz que se especifica arriba. La carga de los datos puede demorar algunos segundos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "urYYcmA9089p"
      },
      "outputs": [],
      "source": [
        "#@test {\"skip\": true}\n",
        "!ls {logdir}\n",
        "%tensorboard --logdir {logdir} --port=0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZMcV15W7b1wG"
      },
      "outputs": [],
      "source": [
        "#@test {\"skip\": true}\n",
        "# Uncomment and run this cell to clean your directory of old output for\n",
        "# future graphs from this directory. We don't run it by default so that if \n",
        "# you do a \"Runtime > Run all\" you don't lose your results.\n",
        "\n",
        "# !rm -R /tmp/logs/scalars/*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jejrFEVP1EDs"
      },
      "source": [
        "A fin de ver las métricas de evaluación del mismo modo, se puede crear una carpeta de evaluación por separado, como \"logs/scalars/eval\", para escribir en TensorBoard."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4hneAcb-F2l"
      },
      "source": [
        "## Personalización de la implementación del modelo\n",
        "\n",
        "Keras es la [API de modelo de alto nivel recomendada para TensorFlow](https://medium.com/tensorflow/standardizing-on-keras-guidance-on-high-level-apis-in-tensorflow-2-0-bad2b04c819a) y promovemos el uso de modelos Keras (a través de `tff.learning.models.from_keras_model`) en TFF siempre que sea posible.\n",
        "\n",
        "No obstante, `tff.learning` ofrece una interfaz de modelo de nivel inferior, `tff.learning.models.VariableModel`, que expone la funcionalidad mínima necesaria para usar un modelo para el aprendizaje federado. La implementación directa de esta interfaz (que probablemente todavía use bloques de construcción como `tf.keras.layers`) permite alcanzar la máxima personalización sin modificar los aspectos internos de los algoritmos de aprendizaje federados.\n",
        "\n",
        "Así que, empecemos todo de nuevo desde cero.\n",
        "\n",
        "### Definición de variables del modelo, paso hacia adelante y métricas\n",
        "\n",
        "El primer paso consiste en identificar las variables de TensorFlow con las que vamos a trabajar. Para que el siguiente código sea más legible, definamos una estructura de datos para representar el conjunto completo. Esto incluirá variables como `weights` y `bias` que entrenaremos, así como variables que contendrán varias estadísticas acumulativas y contadores que actualizaremos durante el entrenamiento, como `loss_sum`, `accuracy_sum` y `num_examples`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uqRD72WQC4u1"
      },
      "outputs": [],
      "source": [
        "MnistVariables = collections.namedtuple(\n",
        "    'MnistVariables', 'weights bias num_examples loss_sum accuracy_sum')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkJfDcY5oXii"
      },
      "source": [
        "Este es un método que crea las variables. Para que resulte más sencillo, representamos todas las estadísticas como `tf.float32`, ya que eso eliminará la necesidad de realizar conversiones de tipos en una etapa posterior. Envolver inicializadores de variables como lambdas es un requisito impuesto por [las variables de recursos](https://www.tensorflow.org/api_docs/python/tf/enable_resource_variables)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H3GQHLNqCfMU"
      },
      "outputs": [],
      "source": [
        "def create_mnist_variables():\n",
        "  return MnistVariables(\n",
        "      weights=tf.Variable(\n",
        "          lambda: tf.zeros(dtype=tf.float32, shape=(784, 10)),\n",
        "          name='weights',\n",
        "          trainable=True),\n",
        "      bias=tf.Variable(\n",
        "          lambda: tf.zeros(dtype=tf.float32, shape=(10)),\n",
        "          name='bias',\n",
        "          trainable=True),\n",
        "      num_examples=tf.Variable(0.0, name='num_examples', trainable=False),\n",
        "      loss_sum=tf.Variable(0.0, name='loss_sum', trainable=False),\n",
        "      accuracy_sum=tf.Variable(0.0, name='accuracy_sum', trainable=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SrdnR0fAre-Q"
      },
      "source": [
        "Con las variables para los parámetros del modelo y las estadísticas acumuladas ya establecidas, ahora podemos definir el método de paso hacia adelante que calcula la pérdida, emite predicciones y actualiza las estadísticas acumuladas para un único lote de datos de entrada, de la siguiente manera."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZYSRAl-KCvC7"
      },
      "outputs": [],
      "source": [
        "def predict_on_batch(variables, x):\n",
        "  return tf.nn.softmax(tf.matmul(x, variables.weights) + variables.bias)\n",
        "\n",
        "def mnist_forward_pass(variables, batch):\n",
        "  y = predict_on_batch(variables, batch['x'])\n",
        "  predictions = tf.cast(tf.argmax(y, 1), tf.int32)\n",
        "\n",
        "  flat_labels = tf.reshape(batch['y'], [-1])\n",
        "  loss = -tf.reduce_mean(\n",
        "      tf.reduce_sum(tf.one_hot(flat_labels, 10) * tf.math.log(y), axis=[1]))\n",
        "  accuracy = tf.reduce_mean(\n",
        "      tf.cast(tf.equal(predictions, flat_labels), tf.float32))\n",
        "\n",
        "  num_examples = tf.cast(tf.size(batch['y']), tf.float32)\n",
        "\n",
        "  variables.num_examples.assign_add(num_examples)\n",
        "  variables.loss_sum.assign_add(loss * num_examples)\n",
        "  variables.accuracy_sum.assign_add(accuracy * num_examples)\n",
        "\n",
        "  return loss, predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gm-yx2Mr_bl"
      },
      "source": [
        "A continuación, volvemos a usar TensorFlow, esta vez para definir dos funciones que están relacionadas con métricas locales.\n",
        "\n",
        "La primera función `get_local_unfinalized_metrics` devuelve los valores de métricas sin finalizar (además de las actualizaciones del modelo, que se gestionan automáticamente) que son elegibles para agregarse al servidor en un proceso de evaluación o aprendizaje federado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RkAZXhjGEekp"
      },
      "outputs": [],
      "source": [
        "def get_local_unfinalized_metrics(variables):\n",
        "  return collections.OrderedDict(\n",
        "      num_examples=[variables.num_examples],\n",
        "      loss=[variables.loss_sum, variables.num_examples],\n",
        "      accuracy=[variables.accuracy_sum, variables.num_examples])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-yS2g9nJQwe"
      },
      "source": [
        "La segunda función `get_metric_finalizers` devuelve un `OrderedDict` de `tf.function`s con las mismas claves (es decir, nombres de métricas) que `get_local_unfinalized_metrics`. Cada `tf.function` toma los valores sin finalizar de la métrica y calcula la métrica finalizada."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y0f_Hc4sJTo6"
      },
      "outputs": [],
      "source": [
        "def get_metric_finalizers():\n",
        "  return collections.OrderedDict(\n",
        "      num_examples=tf.function(func=lambda x: x[0]),\n",
        "      loss=tf.function(func=lambda x: x[0] / x[1]),\n",
        "      accuracy=tf.function(func=lambda x: x[0] / x[1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqnmjV3zJaeC"
      },
      "source": [
        "La forma en que se agregan las métricas locales sin finalizar que devuelve `get_local_unfinalized_metrics` entre los clientes se especifica mediante el parámetro `metrics_aggregator` al definir los procesos de evaluación o aprendizaje federados. Por ejemplo, en la API [`tff.learning.algorithms.build_weighted_fed_avg`](https://www.tensorflow.org/federated/api_docs/python/tff/learning/algorithms/build_weighted_fed_avg) (que se muestra en la siguiente sección), el valor predeterminado para `metrics_aggregator` es [`tff.learning.metrics.sum_then_finalize`](https://www.tensorflow.org/federated/api_docs/python/tff/learning/metrics/sum_then_finalize), que primero suma las métricas sin finalizar de `CLIENTS` y ​​luego aplica los finalizadores de métricas en `SERVER`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7MXGAuQRvmcp"
      },
      "source": [
        "### Construcción de una instancia de `tff.learning.models.VariableModel`\n",
        "\n",
        "Una vez que hayamos implementado todo lo anterior, podremos construir una representación del modelo para usar con TFF que sea similar a la que se genera cuando permitimos que TFF incorpore un modelo de Keras."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "blQGiTQFS9_r"
      },
      "outputs": [],
      "source": [
        "import collections\n",
        "from collections.abc import Callable\n",
        "\n",
        "class MnistModel(tff.learning.models.VariableModel):\n",
        "\n",
        "  def __init__(self):\n",
        "    self._variables = create_mnist_variables()\n",
        "\n",
        "  @property\n",
        "  def trainable_variables(self):\n",
        "    return [self._variables.weights, self._variables.bias]\n",
        "\n",
        "  @property\n",
        "  def non_trainable_variables(self):\n",
        "    return []\n",
        "\n",
        "  @property\n",
        "  def local_variables(self):\n",
        "    return [\n",
        "        self._variables.num_examples, self._variables.loss_sum,\n",
        "        self._variables.accuracy_sum\n",
        "    ]\n",
        "\n",
        "  @property\n",
        "  def input_spec(self):\n",
        "    return collections.OrderedDict(\n",
        "        x=tf.TensorSpec([None, 784], tf.float32),\n",
        "        y=tf.TensorSpec([None, 1], tf.int32))\n",
        "\n",
        "  @tf.function\n",
        "  def predict_on_batch(self, x, training=True):\n",
        "    del training\n",
        "    return predict_on_batch(self._variables, x)\n",
        "    \n",
        "  @tf.function\n",
        "  def forward_pass(self, batch, training=True):\n",
        "    del training\n",
        "    loss, predictions = mnist_forward_pass(self._variables, batch)\n",
        "    num_exmaples = tf.shape(batch['x'])[0]\n",
        "    return tff.learning.models.BatchOutput(\n",
        "        loss=loss, predictions=predictions, num_examples=num_exmaples)\n",
        "\n",
        "  @tf.function\n",
        "  def report_local_unfinalized_metrics(\n",
        "      self) -> collections.OrderedDict[str, list[tf.Tensor]]:\n",
        "    \"\"\"Creates an `OrderedDict` of metric names to unfinalized values.\"\"\"\n",
        "    return get_local_unfinalized_metrics(self._variables)\n",
        "\n",
        "  def metric_finalizers(\n",
        "      self) -> collections.OrderedDict[str, Callable[[list[tf.Tensor]], tf.Tensor]]:\n",
        "    \"\"\"Creates an `OrderedDict` of metric names to finalizers.\"\"\"\n",
        "    return get_metric_finalizers()\n",
        "\n",
        "  @tf.function\n",
        "  def reset_metrics(self):\n",
        "    \"\"\"Resets metrics variables to initial value.\"\"\"\n",
        "    for var in self.local_variables:\n",
        "      var.assign(tf.zeros_like(var))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMN1AszMwLHL"
      },
      "source": [
        "Como puede ver, los métodos abstractos y las propiedades definidas por `tff.learning.models.VariableModel` corresponden a los fragmentos de código de la sección anterior que introdujeron las variables y definieron la pérdida y las estadísticas.\n",
        "\n",
        "Vale la pena resaltar algunos puntos:\n",
        "\n",
        "- Todos los estados que usará su modelo se deben capturar como variables de TensorFlow, ya que TFF no usa Python en tiempo de ejecución (recuerde que su código debe escribirse de manera que pueda implementarse en dispositivos móviles; consulte el tutorial de [algoritmos personalizados](custom_federated_algorithms_1.ipynb) para acceder a información más detallada sobre las razones).\n",
        "- Su modelo debe describir qué forma de datos acepta (`input_spec`), ya que, en general, TFF es un entorno fuertemente tipado y tiende a determinar firmas de tipo para todos los componentes. Declarar el formato de la entrada de su modelo es fundamental.\n",
        "- Si bien técnicamente no es necesario, recomendamos envolver toda la lógica de TensorFlow (paso hacia adelante, cálculos métricos, etc.) como `tf.function`s, ya que esto ayuda a garantizar que TensorFlow se pueda serializar y elimina la necesidad de contar con dependencias de control explícitas.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DVhXk2Bu-GU"
      },
      "source": [
        "Con lo expuesto anteriormente es suficiente para la evaluación y los algoritmos como Federated SGD. Sin embargo, para el promediado federado, debemos especificar el método de entrenamiento local del modelo en cada lote. Al crear el algoritmo de promediado federado, especificaremos un optimizador local."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVBugKP3yw03"
      },
      "source": [
        "### Simulación del entrenamiento federado con el nuevo modelo\n",
        "\n",
        "Una vez que haya hecho todo lo anterior, el resto del proceso se parece a lo que ya hemos visto: simplemente reemplace el constructor del modelo con el constructor de nuestra nueva clase de modelo y use los dos cálculos federados en el proceso iterativo que creó para recorrer rondas de entrenamiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FK3c8_leS9_t"
      },
      "outputs": [],
      "source": [
        "training_process = tff.learning.algorithms.build_weighted_fed_avg(\n",
        "    MnistModel,\n",
        "    client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.02))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jv_LiggwS9_u"
      },
      "outputs": [],
      "source": [
        "train_state = training_process.initialize()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PtOLElmzDPxs"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "round  1, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('num_examples', 4860.0), ('loss', 3.119374), ('accuracy', 0.12345679)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n"
          ]
        }
      ],
      "source": [
        "result = training_process.next(train_state, federated_train_data)\n",
        "train_state = result.state\n",
        "metrics = result.metrics\n",
        "print('round  1, metrics={}'.format(metrics))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gFkv0yJEGhue"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "round  2, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('num_examples', 4860.0), ('loss', 2.98514), ('accuracy', 0.14012346)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "round  3, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('num_examples', 4860.0), ('loss', 2.8617127), ('accuracy', 0.1590535)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "round  4, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('num_examples', 4860.0), ('loss', 2.740137), ('accuracy', 0.17860082)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "round  5, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('num_examples', 4860.0), ('loss', 2.6186547), ('accuracy', 0.20102881)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "round  6, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('num_examples', 4860.0), ('loss', 2.5006158), ('accuracy', 0.22345679)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "round  7, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('num_examples', 4860.0), ('loss', 2.3858361), ('accuracy', 0.24794239)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "round  8, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('num_examples', 4860.0), ('loss', 2.275704), ('accuracy', 0.27160493)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "round  9, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('num_examples', 4860.0), ('loss', 2.1709805), ('accuracy', 0.2958848)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "round 10, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('num_examples', 4860.0), ('loss', 2.0727067), ('accuracy', 0.3251029)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n"
          ]
        }
      ],
      "source": [
        "for round_num in range(2, 11):\n",
        "  result = training_process.next(train_state, federated_train_data)\n",
        "  train_state = result.state\n",
        "  metrics = result.metrics\n",
        "  print('round {:2d}, metrics={}'.format(round_num, metrics))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iswqa2Uj7phq"
      },
      "source": [
        "Para ver estas métricas dentro de TensorBoard, consulte los pasos mencionados anteriormente en \"Visualización de las métricas del modelo en TensorBoard\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7lz59lMJ0kj"
      },
      "source": [
        "## Evaluación\n",
        "\n",
        "Hasta el momento, todos nuestros experimentos presentaron solo métricas de entrenamiento federadas: las métricas promedio de todos los lotes de datos entrenados en todos los clientes de la ronda. Esto plantea el clásico problema del sobreajuste, sobre todo porque, para simplificar, usamos el mismo conjunto de clientes en cada ronda, pero existe una noción adicional de sobreajuste en las métricas de entrenamiento específicas del algoritmo de promediado federado. Esto es más fácil de ver si imaginamos que cada cliente tiene un solo lote de datos y entrenamos en ese lote durante muchas iteraciones (épocas). En este caso, el modelo local rápidamente se ajustará exactamente a ese lote, por lo que la métrica de precisión local que promediamos se aproximará a 1,0. Así, estas métricas de entrenamiento pueden tomarse como una señal de que el entrenamiento está progresando, pero no mucho más.\n",
        "\n",
        "Para evaluar los datos federados, puede construir otro *cálculo federado* diseñado precisamente para este propósito, que utilice la función `tff.learning.build_federated_evaluation` y pase el constructor de su modelo como argumento. Tenga en cuenta que, a diferencia del promediado federado, donde usamos `MnistTrainableModel`, basta con pasar `MnistModel`. La evaluación no realiza un descenso del gradiente y no es necesario construir optimizadores.\n",
        "\n",
        "Para experimentación e investigación, cuando hay un conjunto de datos de prueba centralizado disponible, [Aprendizaje federado para clasificación de imágenes](federated_learning_for_text_generation.ipynb) demuestra otra opción de evaluación: tomar las ponderaciones entrenadas del aprendizaje federado, aplicarlas a un modelo Keras estándar y luego simplemente llamar `tf.keras.models.Model.evaluate()` en un conjunto de datos centralizado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nRiXyqnXM2VO"
      },
      "outputs": [],
      "source": [
        "evaluation_process = tff.learning.algorithms.build_fed_eval(MnistModel)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwfINGoNQEuV"
      },
      "source": [
        "Puede inspeccionar la firma de tipo abstracto de la función de evaluación de la siguiente manera."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3q5ueoO0NDNb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(<\n",
            "  state=<\n",
            "    global_model_weights=<\n",
            "      trainable=<\n",
            "        float32[784,10],\n",
            "        float32[10]\n",
            "      >,\n",
            "      non_trainable=<>\n",
            "    >,\n",
            "    distributor=<>,\n",
            "    client_work=<\n",
            "      <>,\n",
            "      <\n",
            "        num_examples=<\n",
            "          float32\n",
            "        >,\n",
            "        loss=<\n",
            "          float32,\n",
            "          float32\n",
            "        >,\n",
            "        accuracy=<\n",
            "          float32,\n",
            "          float32\n",
            "        >\n",
            "      >\n",
            "    >,\n",
            "    aggregator=<\n",
            "      value_sum_process=<>,\n",
            "      weight_sum_process=<>\n",
            "    >,\n",
            "    finalizer=<>\n",
            "  >@SERVER,\n",
            "  client_data={<\n",
            "    x=float32[?,784],\n",
            "    y=int32[?,1]\n",
            "  >*}@CLIENTS\n",
            "> -> <\n",
            "  state=<\n",
            "    global_model_weights=<\n",
            "      trainable=<\n",
            "        float32[784,10],\n",
            "        float32[10]\n",
            "      >,\n",
            "      non_trainable=<>\n",
            "    >,\n",
            "    distributor=<>,\n",
            "    client_work=<\n",
            "      <>,\n",
            "      <\n",
            "        num_examples=<\n",
            "          float32\n",
            "        >,\n",
            "        loss=<\n",
            "          float32,\n",
            "          float32\n",
            "        >,\n",
            "        accuracy=<\n",
            "          float32,\n",
            "          float32\n",
            "        >\n",
            "      >\n",
            "    >,\n",
            "    aggregator=<\n",
            "      value_sum_process=<>,\n",
            "      weight_sum_process=<>\n",
            "    >,\n",
            "    finalizer=<>\n",
            "  >@SERVER,\n",
            "  metrics=<\n",
            "    distributor=<>,\n",
            "    client_work=<\n",
            "      eval=<\n",
            "        current_round_metrics=<\n",
            "          num_examples=float32,\n",
            "          loss=float32,\n",
            "          accuracy=float32\n",
            "        >,\n",
            "        total_rounds_metrics=<\n",
            "          num_examples=float32,\n",
            "          loss=float32,\n",
            "          accuracy=float32\n",
            "        >\n",
            "      >\n",
            "    >,\n",
            "    aggregator=<\n",
            "      mean_value=<>,\n",
            "      mean_weight=<>\n",
            "    >,\n",
            "    finalizer=<>\n",
            "  >@SERVER\n",
            ">)\n"
          ]
        }
      ],
      "source": [
        "print(evaluation_process.next.type_signature.formatted_representation())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XA3v7f2SQs6q"
      },
      "source": [
        "Tenga en cuenta que el proceso de evaluación es un objeto `tff.lenaring.templates.LearningProcess`. El objeto tiene un método `initialize` que creará el estado, pero al principio contendrá un modelo sin entrenar. Inserte las ponderaciones del estado de entrenamiento a evaluar con ayuda del método `set_model_weights`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OX4Sk_uyOaYa"
      },
      "outputs": [],
      "source": [
        "evaluation_state = evaluation_process.initialize()\n",
        "model_weights = training_process.get_model_weights(train_state)\n",
        "evaluation_state = evaluation_process.set_model_weights(evaluation_state, model_weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5H66kcZRMBB"
      },
      "source": [
        "Ahora que el estado de evaluación contiene las ponderaciones del modelo que se van a evaluar, podemos usar los conjuntos de datos de evaluación para calcular las métricas de evaluación si llamamos al método `next` en el proceso, como se hizo en el entrenamiento.\n",
        "\n",
        "Esto volverá a devolver una instancia `tff.learning.templates.LearingProcessOutput`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kT53YGdkRccR"
      },
      "outputs": [],
      "source": [
        "evaluation_output = evaluation_process.next(evaluation_state, federated_train_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UeEsdwJgRGMW"
      },
      "source": [
        "Esto es lo que obtenemos. Como podemos observar, al parecer las cifras son ligeramente mejores que las que se informaron en la última ronda de entrenamiento anterior. Por convención, las métricas de entrenamiento reportadas por el proceso de entrenamiento iterativo generalmente reflejan el desempeño del modelo al inicio de la ronda de entrenamiento, por lo que las métricas de evaluación siempre estarán un paso adelante."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zwCy1IPxOfiT"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"OrderedDict([('distributor', ()), ('client_work', OrderedDict([('eval', OrderedDict([('current_round_metrics', OrderedDict([('num_examples', 4860.0), ('loss', 1.6654209), ('accuracy', 0.3621399)])), ('total_rounds_metrics', OrderedDict([('num_examples', 4860.0), ('loss', 1.6654209), ('accuracy', 0.3621399)]))]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', ())])\""
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "str(evaluation_output.metrics)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SpfgdNDoRjPy"
      },
      "source": [
        "Ahora compilemos una muestra de prueba de datos federados y volvamos a ejecutar la evaluación de los datos de prueba. Los datos provendrán de la misma muestra de usuarios, pero de un conjunto de datos retenidos distinto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "in8vProVNc04"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10,\n",
              " <_PrefetchDataset element_spec=OrderedDict([('x', TensorSpec(shape=(None, 784), dtype=tf.float32, name=None)), ('y', TensorSpec(shape=(None, 1), dtype=tf.int32, name=None))])>)"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "federated_test_data = make_federated_data(emnist_test, sample_clients)\n",
        "\n",
        "len(federated_test_data), federated_test_data[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ty-ZwfE0NJfV"
      },
      "outputs": [],
      "source": [
        "evaluation_output = evaluation_process.next(evaluation_state, federated_test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e5fGtIJYNqYH"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"OrderedDict([('distributor', ()), ('client_work', OrderedDict([('eval', OrderedDict([('current_round_metrics', OrderedDict([('num_examples', 580.0), ('loss', 1.7750846), ('accuracy', 0.33620688)])), ('total_rounds_metrics', OrderedDict([('num_examples', 580.0), ('loss', 1.7750846), ('accuracy', 0.33620688)]))]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', ())])\""
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "str(evaluation_output.metrics)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67vYxrDWzRcj"
      },
      "source": [
        "De este modo, se concluye con el tutorial. Le aconsejamos que pruebe con distintos parámetros (p. ej., los tamaños de los lotes, la cantidad de usuarios, las épocas, las tasas de aprendizaje, etc.), para modificar el código que figura arriba a fin de simular el entrenamiento con muestras aleatorias de usuarios en cada ronda. También le recomendamos explorar los otros tutoriales que hemos desarrollado."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "federated_learning_for_image_classification.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
