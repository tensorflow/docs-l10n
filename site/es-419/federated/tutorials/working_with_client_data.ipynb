{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lf7huAiYp-An"
      },
      "source": [
        "##### Copyright 2021 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "YHz2D-oIqBWa"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x44FFES-r6y0"
      },
      "source": [
        "# Trabajar con ClientData de TFF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPFgLeZIsZ3Q"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td><a target=\"_blank\" href=\"https://www.tensorflow.org/federated/tutorials/working_with_client_data\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver en TensorFlow.org</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/es-419/federated/tutorials/working_with_client_data.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Ejecutar en Google Colab</a></td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/es-419/federated/tutorials/working_with_client_data.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver código fuente en GitHub</a>\n",
        "</td>\n",
        "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/es-419/federated/tutorials/working_with_client_data.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Descargar el bloc de notas</a>\n",
        "</td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8RVecD0EfXdb"
      },
      "source": [
        "La idea de un conjunto de datos que los clientes codifican (por ejemplo, usuarios) es esencial para el cálculo federado tal como se modela en TFF. TFF proporciona la interfaz [`tff.simulation.datasets.ClientData`](https://www.tensorflow.org/federated/api_docs/python/tff/simulation/datasets/ClientData) para abstraer este concepto y los conjuntos de datos que aloja TFF ([stackoverflow](https://www.tensorflow.org/federated/api_docs/python/tff/simulation/datasets/stackoverflow), [shakespeare](https://www.tensorflow.org/federated/api_docs/python/tff/simulation/datasets/shakespeare), [emnist](https://www.tensorflow.org/federated/api_docs/python/tff/simulation/datasets/emnist), [cifar100](https://www.tensorflow.org/federated/api_docs/python/tff/simulation/datasets/cifar100) y [gldv2](https://www.tensorflow.org/federated/api_docs/python/tff/simulation/datasets/gldv2)) implementan esta interfaz.\n",
        "\n",
        "Si está trabajando en aprendizaje federado con su propio conjunto de datos, TFF le recomienda encarecidamente que implemente la interfaz `ClientData` o que use una de las funciones ayudantes de TFF para generar un `ClientData` que represente sus datos en el disco, por ejemplo, [`tff.simulation.datasets.ClientData.from_clients_and_fn`](https://www.tensorflow.org/federated/api_docs/python/tff/simulation/datasets/ClientData#from_clients_and_fn).\n",
        "\n",
        "Como la mayoría de los ejemplos integrales de TFF comienzan con objetos `ClientData`, implementar la interfaz `ClientData` con su conjunto de datos personalizado hará que sea más fácil explorar el código existente escrito con TFF. Además, los `tf.data.Datasets` que construye `ClientData` se pueden iterar directamente para generar estructuras de arreglos `numpy`, por eso los objetos `ClientData` pueden usarse con cualquier marco de aprendizaje automático basado en Python antes de pasar a TFF.\n",
        "\n",
        "Hay varios patrones que pueden facilitarle la vida si piensa aumentar sus simulaciones a muchas máquinas o si piensa implementarlas. A continuación, analizaremos algunas de las formas en que se puede usar `ClientData` y TFF para que nuestra experiencia de iteración a pequeña escala a experimentación a gran escala a implementación de producción sea lo más fluida posible."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snsz06ESrGvL"
      },
      "source": [
        "## ¿Qué patrón debo usar para pasar ClientData a TFF?\n",
        "\n",
        "Analizaremos dos usos de `ClientData` de TFF en profundidad; si usted entra en alguna de las dos categorías siguientes, claramente preferirá una sobre la otra. De lo contrario, es posible que necesite entender en más detalle las ventajas y las desventajas de cada uno para tomar una decisión más elaborada.\n",
        "\n",
        "- Quiero iterar lo más rápido posible en una máquina local; no necesito poder aprovechar el tiempo de ejecución distribuido de TFF de forma fácil.\n",
        "\n",
        "    - Quiere pasar `tf.data.Datasets` a TFF directamente.\n",
        "    - Esto le permite programar de forma imperativa con objetos `tf.data.Dataset` y procesarlos arbitrariamente.\n",
        "    - Proporciona más flexibilidad que la próxima opción; el enviar lógica a los clientes requiere que la lógica sea serializable.\n",
        "\n",
        "- Quiero ejecutar mi cálculo federado en el tiempo de ejecución remoto de TFF o planeo hacerlo pronto.\n",
        "\n",
        "    - En este caso, desea asignar la construcción y el preprocesamiento del conjunto de datos a los clientes.\n",
        "    - Esto da como resultado que usted pase simplemente una lista de `client_ids` directamente a su cálculo federado.\n",
        "\n",
        "- Enviar la construcción y el preprocesamiento de conjuntos de datos a los clientes evita cuellos de botella en la serialización y aumenta significativamente el rendimiento con cientos a miles de clientes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KoCHeay4Rozd"
      },
      "outputs": [],
      "source": [
        "#@title Set up open-source environment\n",
        "#@test {\"skip\": true}\n",
        "\n",
        "# tensorflow_federated_nightly also bring in tf_nightly, which\n",
        "# can causes a duplicate tensorboard install, leading to errors.\n",
        "!pip uninstall --yes tensorboard tb-nightly\n",
        "\n",
        "!pip install --quiet --upgrade tensorflow_federated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LNduVQsPNoH7"
      },
      "outputs": [],
      "source": [
        "#@title Import packages\n",
        "import collections\n",
        "import time\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_federated as tff"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dNOfCerkfZh_"
      },
      "source": [
        "## Manipular un objeto ClientData\n",
        "\n",
        "Comencemos por cargar y explorar `ClientData` de EMNIST de TFF:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Rd8vaOOfbe5X"
      },
      "outputs": [],
      "source": [
        "client_data, _ = tff.simulation.datasets.emnist.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-46eXnKbmYP"
      },
      "source": [
        "Al inspeccionar el primer conjunto de datos podemos ver qué tipo de ejemplos hay en `ClientData`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "N1JvJvDkbxDo"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OrderedDict([('label', TensorSpec(shape=(), dtype=tf.int32, name=None)), ('pixels', TensorSpec(shape=(28, 28), dtype=tf.float32, name=None))])\n"
          ]
        }
      ],
      "source": [
        "first_client_id = client_data.client_ids[0]\n",
        "first_client_dataset = client_data.create_tf_dataset_for_client(\n",
        "    first_client_id)\n",
        "print(first_client_dataset.element_spec)\n",
        "# This information is also available as a `ClientData` property:\n",
        "assert client_data.element_type_structure == first_client_dataset.element_spec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Z8l3uuYv8cD"
      },
      "source": [
        "Tenga en cuenta que el conjunto de datos produce objetos `collections.OrderedDict` que tienen `pixels` y claves `label`, donde píxeles es un tensor con forma `[28, 28]`. Supongamos que queremos aplanar las entradas en la forma `[784]`. Una posible forma de hacer esto sería aplicar una función de preprocesamiento a nuestro objeto `ClientData`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "VyPqaw6Uv7Fu"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OrderedDict([('x', TensorSpec(shape=(None, 784), dtype=tf.float32, name=None)), ('y', TensorSpec(shape=(None, 1), dtype=tf.int64, name=None))])\n"
          ]
        }
      ],
      "source": [
        "def preprocess_dataset(dataset):\n",
        "  \"\"\"Create batches of 5 examples, and limit to 3 batches.\"\"\"\n",
        "\n",
        "  def map_fn(input):\n",
        "    return collections.OrderedDict(\n",
        "        x=tf.reshape(input['pixels'], shape=(-1, 784)),\n",
        "        y=tf.cast(tf.reshape(input['label'], shape=(-1, 1)), tf.int64),\n",
        "    )\n",
        "\n",
        "  return dataset.batch(5).map(\n",
        "      map_fn, num_parallel_calls=tf.data.experimental.AUTOTUNE).take(5)\n",
        "\n",
        "\n",
        "preprocessed_client_data = client_data.preprocess(preprocess_dataset)\n",
        "\n",
        "# Notice that we have both reshaped and renamed the elements of the ordered dict.\n",
        "first_client_dataset = preprocessed_client_data.create_tf_dataset_for_client(\n",
        "    first_client_id)\n",
        "print(first_client_dataset.element_spec)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NtpLRgdpl9Js"
      },
      "source": [
        "Quizas también queremos realizar un preprocesamiento más complejo (y posiblemente con estado), como por ejemplo aleatorizar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "CtBVHcAmmKiu"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OrderedDict([('x', TensorSpec(shape=(None, 784), dtype=tf.float32, name=None)), ('y', TensorSpec(shape=(None, 1), dtype=tf.int64, name=None))])\n"
          ]
        }
      ],
      "source": [
        "def preprocess_and_shuffle(dataset):\n",
        "  \"\"\"Applies `preprocess_dataset` above and shuffles the result.\"\"\"\n",
        "  preprocessed = preprocess_dataset(dataset)\n",
        "  return preprocessed.shuffle(buffer_size=5)\n",
        "\n",
        "preprocessed_and_shuffled = client_data.preprocess(preprocess_and_shuffle)\n",
        "\n",
        "# The type signature will remain the same, but the batches will be shuffled.\n",
        "first_client_dataset = preprocessed_and_shuffled.create_tf_dataset_for_client(\n",
        "    first_client_id)\n",
        "print(first_client_dataset.element_spec)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ek7W3ZZHMr1k"
      },
      "source": [
        "## Interconectar con un `tff.Computation`\n",
        "\n",
        "Ahora que podemos realizar algunas manipulaciones básicas con objetos `ClientData`, ya podemos ingresar datos en `tff.Computation`. Definamos un [`tff.templates.IterativeProcess`](https://www.tensorflow.org/federated/api_docs/python/tff/templates/IterativeProcess) que implementa el [promedio federado](https://arxiv.org/abs/1602.05629) y exploremos los diferentes métodos para pasarle datos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "j41nKFYse8GC"
      },
      "outputs": [],
      "source": [
        "def model_fn():\n",
        "  model = tf.keras.models.Sequential([\n",
        "      tf.keras.layers.InputLayer(input_shape=(784,)),\n",
        "      tf.keras.layers.Dense(10, kernel_initializer='zeros'),\n",
        "  ])\n",
        "  return tff.learning.models.from_keras_model(\n",
        "      model,\n",
        "      # Note: input spec is the _batched_ shape, and includes the \n",
        "      # label tensor which will be passed to the loss function. This model is\n",
        "      # therefore configured to accept data _after_ it has been preprocessed.\n",
        "      input_spec=collections.OrderedDict(\n",
        "          x=tf.TensorSpec(shape=[None, 784], dtype=tf.float32),\n",
        "          y=tf.TensorSpec(shape=[None, 1], dtype=tf.int64)),\n",
        "      loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
        "  \n",
        "trainer = tff.learning.algorithms.build_weighted_fed_avg(\n",
        "    model_fn,\n",
        "    client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.01))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICJdME7-5lMx"
      },
      "source": [
        "Antes de empezar a trabajar con `IterativeProcess`, tenemos que hacer un comentario sobre la semántica de `ClientData`. Un objeto `ClientData` representa la *totalidad* de la población disponible para el entrenamiento federado, que en general [no está disponible para el entorno de ejecución de un sistema FL de producción](https://arxiv.org/abs/1902.01046) y es específico de la simulación. De hecho, `ClientData` brinda al usuario la capacidad de evitar por completo el cálculo federado y simplemente entrenar un modelo del lado del servidor como de costumbre a través de [`ClientData.create_tf_dataset_from_all_clients`](https://www.tensorflow.org/federated/api_docs/python/tff/simulation/datasets/ClientData?hl=en#create_tf_dataset_from_all_clients).\n",
        "\n",
        "El entorno de simulación de TFF otorga al investigador el control total del bucle exterior. En particular, esto implica que el usuario o la secuencia de comandos del controlador de Python deben abordar las consideraciones de disponibilidad del cliente, abandono del cliente, etc. Por ejemplo, se podría modelar el abandono del cliente ajustando la distribución de muestreo en los `client_ids` de `ClientData's` de manera que la probabilidad de que se seleccionen los usuarios con más datos (y, en consecuencia, cálculos locales de mayor duración) sea menor.\n",
        "\n",
        "Sin embargo, en un sistema federado real, quien entrena el modelo no puede seleccionar explícitamente a los clientes; la selección de clientes se delega al sistema que ejecuta el cálculo federado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zaoo661LOaCK"
      },
      "source": [
        "### Pasar `tf.data.Datasets` directamente a TFF\n",
        "\n",
        "Una opción para interconectar entre `ClientData` y `IterativeProcess` es construir `tf.data.Datasets` en Python y pasar estos conjuntos de datos a TFF.\n",
        "\n",
        "Tenga en cuenta que si usamos nuestros `ClientData` preprocesados, los conjuntos de datos que obtenemos son del tipo adecuado que necesita nuestro modelo definido anteriormente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "U3R4cvZvPmxt"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss 2.934802532196045, round time 2.5420753955841064\n",
            "loss 3.350963830947876, round time 0.45527172088623047\n",
            "loss 3.1382687091827393, round time 0.47087883949279785\n",
            "loss 3.0774152278900146, round time 0.4089682102203369\n",
            "loss 2.9193594455718994, round time 0.3964221477508545\n"
          ]
        }
      ],
      "source": [
        "selected_client_ids = preprocessed_and_shuffled.client_ids[:10]\n",
        "\n",
        "preprocessed_data_for_clients = [\n",
        "    preprocessed_and_shuffled.create_tf_dataset_for_client(\n",
        "        selected_client_ids[i]) for i in range(10)\n",
        "]\n",
        "\n",
        "state = trainer.initialize()\n",
        "for _ in range(5):\n",
        "  t1 = time.time()\n",
        "  result = trainer.next(state, preprocessed_data_for_clients)\n",
        "  state = result.state\n",
        "  train_metrics = result.metrics['client_work']['train']\n",
        "  t2 = time.time()\n",
        "  print('loss {}, round time {}'.format(train_metrics['loss'], t2 - t1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFaFlB59nAVi"
      },
      "source": [
        "Sin embargo, si seguimos este camino, ***no podremos pasar trivialmente a la simulación multimáquina***. Los conjuntos de datos que construimos en el tiempo de ejecución local de TensorFlow pueden *capturar el estado del entorno Python que los envuelve* y no pueden con la serialización o deserialización cuando intentan hacer referencia a un estado que ya no está disponible para ellos. Esto puede manifestarse, por ejemplo, en el error inescrutable de `tensor_util.cc` de TensorFlow:\n",
        "\n",
        "```\n",
        "Check failed: DT_VARIANT == input.dtype() (21 vs. 20)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5VKu7OLny5X"
      },
      "source": [
        "### Asignar la construcción y el preprocesamiento en los clientes\n",
        "\n",
        "Para evitar este problema, TFF recomienda que sus usuarios consideren la creación de instancias y el preprocesamiento del conjunto de datos como *algo que sucede localmente en cada cliente* y que usen los ayudantes de TFF o `federated_map` para ejecutar explícitamente este código de preprocesamiento en cada cliente.\n",
        "\n",
        "Conceptualmente, el motivo para preferir esto es claro: en el tiempo de ejecución local de TFF, los clientes solo tienen acceso \"accidentalmente\" al entorno global de Python debido al hecho de que toda la orquestación federada ocurre en una sola máquina. Vale la pena señalar en este punto que un pensamiento similar da lugar a la filosofía funcional, multiplataforma y siempre serializable de TFF.\n",
        "\n",
        "TFF simplifica este cambio a través del atributo `dataset_computation` de `ClientData's`, un `tff.Computation` que toma un `client_id` y devuelve el `tf.data.Dataset` asociado.\n",
        "\n",
        "Tenga en cuenta que `preprocess` simplemente funciona con `dataset_computation`; el atributo `dataset_computation` de `ClientData` preprocesado incorpora todo el proceso de preprocesamiento que acabamos de definir:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "yKiTjDj3pw4R"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dataset computation without preprocessing:\n",
            "(string -> <label=int32,pixels=float32[28,28]>*)\n",
            "\n",
            "\n",
            "dataset computation with preprocessing:\n",
            "(string -> <x=float32[?,784],y=int64[?,1]>*)\n"
          ]
        }
      ],
      "source": [
        "print('dataset computation without preprocessing:')\n",
        "print(client_data.dataset_computation.type_signature)\n",
        "print('\\n')\n",
        "print('dataset computation with preprocessing:')\n",
        "print(preprocessed_and_shuffled.dataset_computation.type_signature)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGcSqAjuqJau"
      },
      "source": [
        "Podríamos invocar `dataset_computation` y recibir un conjunto de datos eager en el tiempo de ejecución de Python, pero el verdadero poder de este enfoque se ejerce cuando componemos con un proceso iterativo u otro cálculo para evitar materializar estos conjuntos de datos en el tiempo de ejecución eager global. TFF proporciona una función ayudante [`tff.simulation.compose_dataset_computation_with_iterative_process`](https://www.tensorflow.org/federated/api_docs/python/tff/simulation/compose_dataset_computation_with_iterative_process) que se puede usa para hacer exactamente esto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "69vY85cmPsel"
      },
      "outputs": [],
      "source": [
        "trainer_accepting_ids = tff.simulation.compose_dataset_computation_with_iterative_process(\n",
        "    preprocessed_and_shuffled.dataset_computation, trainer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ixrmztq6SbRE"
      },
      "source": [
        "Tanto este `tff.templates.IterativeProcesses` como el anterior se ejecutan de la misma manera; pero el primero acepta conjuntos de datos preprocesados de clientes ​​y el segundo acepta cadenas de texto que representan identificadores de clientes, controlando tanto la construcción del conjunto de datos como el preprocesamiento en su cuerpo. De hecho, el `state` se puede pasar entre los dos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ZcYPQxqlSapn"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss 2.6114611625671387, round time 1.4935951232910156\n",
            "loss 2.612247943878174, round time 0.30751872062683105\n",
            "loss 2.8368589878082275, round time 0.3043978214263916\n",
            "loss 2.6863903999328613, round time 0.3107311725616455\n",
            "loss 2.6816341876983643, round time 0.4325370788574219\n"
          ]
        }
      ],
      "source": [
        "for _ in range(5):\n",
        "  t1 = time.time()\n",
        "  result = trainer_accepting_ids.next(state, selected_client_ids)\n",
        "  state = result.state\n",
        "  train_metrics = result.metrics['client_work']['train']\n",
        "  t2 = time.time()\n",
        "  print('loss {}, round time {}'.format(train_metrics['loss'], t2 - t1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SeoQzU-5XeGz"
      },
      "source": [
        "### Escalar a un gran número de clientes\n",
        "\n",
        "`trainer_accepting_ids` se puede usar inmediatamente en el tiempo de ejecución de múltiples máquinas de TFF y evita la materialización de `tf.data.Datasets` y del controlador (y, por lo tanto, serializarlos y enviarlos a los trabajadores).\n",
        "\n",
        "Esto acelera significativamente las simulaciones distribuidas, especialmente con una gran cantidad de clientes, y permite la agregación intermedia para evitar una sobrecarga similar de serialización/deserialización.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSy1t2UZQWCy"
      },
      "source": [
        "### Análisis profundo opcional: componer de forma manual la lógica de preprocesamiento en TFF\n",
        "\n",
        "TFF está diseñado para la composicionalidad desde cero; el tipo de composición que acaba de realizar el ayudante de TFF está totalmente bajo nuestro control como usuarios. Podríamos haber compuesto manualmente el cálculo de preprocesamiento que acabamos de definir con el `next` del entrenador de manera bastante simple:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "yasFmYyIwTKY"
      },
      "outputs": [],
      "source": [
        "selected_clients_type = tff.FederatedType(preprocessed_and_shuffled.dataset_computation.type_signature.parameter, tff.CLIENTS)\n",
        "\n",
        "@tff.federated_computation(trainer.next.type_signature.parameter[0], selected_clients_type)\n",
        "def new_next(server_state, selected_clients):\n",
        "  preprocessed_data = tff.federated_map(preprocessed_and_shuffled.dataset_computation, selected_clients)\n",
        "  return trainer.next(server_state, preprocessed_data)\n",
        "\n",
        "manual_trainer_with_preprocessing = tff.templates.IterativeProcess(initialize_fn=trainer.initialize, next_fn=new_next)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHG0NXbWQuk7"
      },
      "source": [
        "De hecho, esto es efectivamente lo que el ayudante que usamos hace detrás de escena (además de realizar la verificación y manipulación de los tipos adecuados). Incluso podríamos haber expresado la misma lógica de manera un poco diferente, si serializamos `preprocess_and_shuffle` en `tff.Computation` y descomponemos `federated_map` en un paso que construye conjuntos de datos no preprocesados ​​y otro que ejecuta `preprocess_and_shuffle` en cada cliente.\n",
        "\n",
        "Podemos verificar que esta forma más manual da como resultado cálculos con la misma signatura de tipo que el ayudante de TFF (nombres de parámetros de módulo):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "C2sc5HkLPwkp"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(<state=<global_model_weights=<trainable=<float32[784,10],float32[10]>,non_trainable=<>>,distributor=<>,client_work=<>,aggregator=<value_sum_process=<>,weight_sum_process=<>>,finalizer=<int64>>@SERVER,client_data={string}@CLIENTS> -> <state=<global_model_weights=<trainable=<float32[784,10],float32[10]>,non_trainable=<>>,distributor=<>,client_work=<>,aggregator=<value_sum_process=<>,weight_sum_process=<>>,finalizer=<int64>>@SERVER,metrics=<distributor=<>,client_work=<train=<sparse_categorical_accuracy=float32,loss=float32,num_examples=int64,num_batches=int64>>,aggregator=<mean_value=<>,mean_weight=<>>,finalizer=<>>@SERVER>)\n",
            "(<server_state=<global_model_weights=<trainable=<float32[784,10],float32[10]>,non_trainable=<>>,distributor=<>,client_work=<>,aggregator=<value_sum_process=<>,weight_sum_process=<>>,finalizer=<int64>>@SERVER,selected_clients={string}@CLIENTS> -> <state=<global_model_weights=<trainable=<float32[784,10],float32[10]>,non_trainable=<>>,distributor=<>,client_work=<>,aggregator=<value_sum_process=<>,weight_sum_process=<>>,finalizer=<int64>>@SERVER,metrics=<distributor=<>,client_work=<train=<sparse_categorical_accuracy=float32,loss=float32,num_examples=int64,num_batches=int64>>,aggregator=<mean_value=<>,mean_weight=<>>,finalizer=<>>@SERVER>)\n"
          ]
        }
      ],
      "source": [
        "print(trainer_accepting_ids.next.type_signature)\n",
        "print(manual_trainer_with_preprocessing.next.type_signature)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "working_with_client_data.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
