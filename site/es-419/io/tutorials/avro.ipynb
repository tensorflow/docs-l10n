{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tce3stUlHN0L"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow IO Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tuOe1ymfHZPu"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFdPvlXBOdUN"
      },
      "source": [
        "# API de conjunto de datos de Avro"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfBg1C5NB3X0"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>     <a target=\"_blank\" href=\"https://www.tensorflow.org/io/tutorials/avro\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver en TensorFlow.org</a> </td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/es-419/io/tutorials/avro.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Ejecutar en Google Colab</a> </td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/es-419/io/tutorials/avro.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver código fuente en GitHub</a> </td>\n",
        "      <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/es-419/io/tutorials/avro.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Descargar el bloc de notas</a> </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHxb-dlhMIzW"
      },
      "source": [
        "## Descripción general\n",
        "\n",
        "El objetivo de la API del conjunto de datos de Avro es cargar datos formateados en Avro de forma nativa en TensorFlow como <a target=\"_blank\" href=\"https://www.tensorflow.org/api_docs/python/tf/data/Dataset\">un conjunto de datos de TensorFlow</a>. Avro es un sistema de serialización de datos similar a Protocol Buffers. Se usa mucho en Apache Hadoop, donde puede proporcionar un formato de serialización para datos persistentes y un formato de conexión para la comunicación entre nodos de Hadoop. Los datos de Avro son un formato de datos binarios compactados y orientados a filas. Se basa en un esquema que se almacena como un archivo JSON independiente. Para conocer las especificaciones del formato Avro y la declaración del esquema, consulte <a target=\"_blank\" href=\"https://avro.apache.org/docs/current/spec.html\">el manual oficial</a>.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUXex9ctTuDB"
      },
      "source": [
        "## Paquete de preparación\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upgCc3gXybsA"
      },
      "source": [
        "### Instalar el paquete tensorflow-io necesario"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uUDYyMZRfkX4"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow-io"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjrZNJQRJP-U"
      },
      "source": [
        "### Importe paquetes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m6KXZuTBWgRm"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_io as tfio\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCgO11GTJaTj"
      },
      "source": [
        "### Validar las importaciones de tf y de tfio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dX74RKfZ_TdF"
      },
      "outputs": [],
      "source": [
        "print(\"tensorflow-io version: {}\".format(tfio.__version__))\n",
        "print(\"tensorflow version: {}\".format(tf.__version__))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0ZKhA6s0Pjp"
      },
      "source": [
        "## Uso"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CfKVmCvwcL7"
      },
      "source": [
        "### Explorar el conjunto de datos\n",
        "\n",
        "Para los fines de este tutorial, descarguemos el conjunto de datos de muestra de Avro.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGnbXuVnSo8T"
      },
      "source": [
        "Descargue un archivo Avro de muestra:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tu01THzWcE-J"
      },
      "outputs": [],
      "source": [
        "!curl -OL https://github.com/tensorflow/io/raw/master/docs/tutorials/avro/train.avro\n",
        "!ls -l train.avro"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJzE6lMwhY7l"
      },
      "source": [
        "Descargue el archivo de esquema correspondiente del archivo Avro de muestra:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cpxa6yhLhY7l"
      },
      "outputs": [],
      "source": [
        "!curl -OL https://github.com/tensorflow/io/raw/master/docs/tutorials/avro/train.avsc\n",
        "!ls -l train.avsc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9GCyPWNuOm7"
      },
      "source": [
        "En el ejemplo anterior, se creó un conjunto de datos de Avro de prueba basado en el conjunto de datos mnist. El conjunto de datos mnist original en formato TFRecord se genera a partir del <a target=\"_blank\" href=\"https://www.tensorflow.org/datasets/api_docs/python/tfds/load\">conjunto de datos con nombre TF</a>. Sin embargo, el conjunto de datos mnist es demasiado grande como conjunto de datos de demostración. Para simplificar, se recortó bastante y solo se conservaron los primeros registros. Además, se realizó un recorte adicional para el campo `image` en el conjunto de datos original de mnist y se asignó al campo `features` en Avro. Entonces, el archivo avro `train.avro` tiene 4 registros, cada uno de los cuales tiene 3 campos: `features`, que es un arreglo de int, `label`, un int o nulo y `dataType`, una enum. Para ver el `train.avro` decodificado (tenga en cuenta que <a target=\"_blank\" href=\"https://github.com/tensorflow/io/raw/master/docs/tutorials/avro/train.avro\">el archivo de datos de Avro original</a> no es legible por humanos ya que avro es un formato compactado):\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upgCc3gXybsB"
      },
      "source": [
        "Instale el paquete requerido para leer el archivo Avro:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nS3eTBvjt-O4"
      },
      "outputs": [],
      "source": [
        "!pip install avro\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7XR0agdhY7n"
      },
      "source": [
        "Para leer e imprimir un archivo Avro en un formato legible por humanos:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nS3eTBvjt-O5"
      },
      "outputs": [],
      "source": [
        "from avro.io import DatumReader\n",
        "from avro.datafile import DataFileReader\n",
        "\n",
        "import json\n",
        "\n",
        "def print_avro(avro_file, max_record_num=None):\n",
        "    if max_record_num is not None and max_record_num <= 0:\n",
        "        return\n",
        "\n",
        "    with open(avro_file, 'rb') as avro_handler:\n",
        "        reader = DataFileReader(avro_handler, DatumReader())\n",
        "        record_count = 0\n",
        "        for record in reader:\n",
        "            record_count = record_count+1\n",
        "            print(record)\n",
        "            if max_record_num is not None and record_count == max_record_num:\n",
        "               break\n",
        "\n",
        "print_avro(avro_file='train.avro')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKgUPm6JhY7n"
      },
      "source": [
        "Y el esquema de `train.avro` representado por `train.avsc` es un archivo con formato JSON. Para ver el `train.avsc`:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D-95aom1hY7o"
      },
      "outputs": [],
      "source": [
        "def print_schema(avro_schema_file):\n",
        "    with open(avro_schema_file, 'r') as handle:\n",
        "        parsed = json.load(handle)\n",
        "    print(json.dumps(parsed, indent=4, sort_keys=True))\n",
        "\n",
        "print_schema('train.avsc')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21szKFY1hY7o"
      },
      "source": [
        "### Preparar el conjunto de datos\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNeBO9m-hY7o"
      },
      "source": [
        "Cargue `train.avro` como conjunto de datos de TensorFlow con la API del conjunto de datos de Avro:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v-nbLZHKhY7o"
      },
      "outputs": [],
      "source": [
        "features = {\n",
        "    'features[*]': tfio.experimental.columnar.VarLenFeatureWithRank(dtype=tf.int32),\n",
        "    'label': tf.io.FixedLenFeature(shape=[], dtype=tf.int32, default_value=-100),\n",
        "    'dataType': tf.io.FixedLenFeature(shape=[], dtype=tf.string)\n",
        "}\n",
        "\n",
        "schema = tf.io.gfile.GFile('train.avsc').read()\n",
        "\n",
        "dataset = tfio.experimental.columnar.make_avro_record_dataset(file_pattern=['train.avro'],\n",
        "                                                              reader_schema=schema,\n",
        "                                                              features=features,\n",
        "                                                              shuffle=False,\n",
        "                                                              batch_size=3,\n",
        "                                                              num_epochs=1)\n",
        "\n",
        "for record in dataset:\n",
        "    print(record['features[*]'])\n",
        "    print(record['label'])\n",
        "    print(record['dataType'])\n",
        "    print(\"--------------------\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IF_kYz_o2DH4"
      },
      "source": [
        "En el ejemplo anterior se convierte `train.avro` en un conjunto de datos de TensorFlow. Cada elemento del conjunto de datos es un diccionario cuya clave es el nombre de la función, el valor es el tensor denso o disperso convertido. Por ejemplo, convierte el campo `features`, `label` y `dataType` en VarLenFeature(SparseTensor), FixedLenFeature(DenseTensor) y FixedLenFeature(DenseTensor) respectivamente. Dado que batch_size es 3, coacciona 3 registros de `train.avro` en un elemento en el conjunto de datos resultante. Para el primer registro en `train.avro` cuya etiqueta es nula, el lector de Avro lo reemplaza con el valor predeterminado especificado (-100). En este ejemplo, hay 4 registros en total en `train.avro`. Dado que el tamaño del lote es 3, el conjunto de datos resultante contiene 3 elementos, el último de los cuales tiene un tamaño de lote de 1. Sin embargo, el usuario también puede descartar el último lote si el tamaño es menor que el tamaño del lote habilitando `drop_final_batch`. Por ejemplo:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bc9vDHyghY7p"
      },
      "outputs": [],
      "source": [
        "dataset = tfio.experimental.columnar.make_avro_record_dataset(file_pattern=['train.avro'],\n",
        "                                                              reader_schema=schema,\n",
        "                                                              features=features,\n",
        "                                                              shuffle=False,\n",
        "                                                              batch_size=3,\n",
        "                                                              drop_final_batch=True,\n",
        "                                                              num_epochs=1)\n",
        "\n",
        "for record in dataset:\n",
        "    print(record)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x45KolnDhY7p"
      },
      "source": [
        "También se puede aumentar num_parallel_reads para acelerar el procesamiento de datos de Avro aumentando el paralelismo de parseo/lectura de Avro.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z2x-gPj_hY7p"
      },
      "outputs": [],
      "source": [
        "dataset = tfio.experimental.columnar.make_avro_record_dataset(file_pattern=['train.avro'],\n",
        "                                                              reader_schema=schema,\n",
        "                                                              features=features,\n",
        "                                                              shuffle=False,\n",
        "                                                              num_parallel_reads=16,\n",
        "                                                              batch_size=3,\n",
        "                                                              drop_final_batch=True,\n",
        "                                                              num_epochs=1)\n",
        "\n",
        "for record in dataset:\n",
        "    print(record)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6V-nwDJGhY7p"
      },
      "source": [
        "Para conocer el uso detallado de `make_avro_record_dataset`, consulte el <a target=\"_blank\" href=\"https://www.tensorflow.org/io/api_docs/python/tfio/experimental/columnar/make_avro_record_dataset\">documento de API</a>.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIOijGlAhY7p"
      },
      "source": [
        "### Entrenar modelos tf.keras con el conjunto de datos de Avro\n",
        "\n",
        "Ahora veamos un ejemplo de principio a fin de entrenamiento del modelo tf.keras con un conjunto de datos de Avro basado en un conjunto de datos mnist.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7K85D53hY7q"
      },
      "source": [
        "Cargue `train.avro` como conjunto de datos de TensorFlow con la API del conjunto de datos de Avro:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VFoeLwIOhY7q"
      },
      "outputs": [],
      "source": [
        "features = {\n",
        "    'features[*]': tfio.experimental.columnar.VarLenFeatureWithRank(dtype=tf.int32),\n",
        "    'label': tf.io.FixedLenFeature(shape=[], dtype=tf.int32, default_value=-100),\n",
        "}\n",
        "\n",
        "\n",
        "schema = tf.io.gfile.GFile('train.avsc').read()\n",
        "\n",
        "dataset = tfio.experimental.columnar.make_avro_record_dataset(file_pattern=['train.avro'],\n",
        "                                                              reader_schema=schema,\n",
        "                                                              features=features,\n",
        "                                                              shuffle=False,\n",
        "                                                              batch_size=1,\n",
        "                                                              num_epochs=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hR2FnIIMhY7q"
      },
      "source": [
        "Defina un modelo keras simple:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hGV5rHfJhY7q"
      },
      "outputs": [],
      "source": [
        "def build_and_compile_cnn_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.compile(optimizer='sgd', loss='mse')\n",
        "    return model\n",
        "\n",
        "model = build_and_compile_cnn_model()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tuv9n6HshY7q"
      },
      "source": [
        "### Entrene el modelo keras con el conjunto de datos de Avro:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lb44cUuWhY7r"
      },
      "outputs": [],
      "source": [
        "def extract_label(feature):\n",
        "  label = feature.pop('label')\n",
        "  return tf.sparse.to_dense(feature['features[*]']), label\n",
        "\n",
        "model.fit(x=dataset.map(extract_label), epochs=1, steps_per_epoch=1, verbose=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7K6qAv5rhY7r"
      },
      "source": [
        "El conjunto de datos de Avro puede parsear y convertir cualquier dato de Avro en tensores de TensorFlow, incluidos registros en registros, mapas, arreglos, ramas y enumeraciones. La información de parseo se pasa a la implementación del conjunto de datos de Avro como un mapa donde las claves codifican cómo parsear los valores de datos y codifican cómo convertir los datos en tensores de TensorFlow. Así se decide el tipo primitivo (por ejemplo, bool, int, long, float, double, string) así como también el tipo de tensor (por ejemplo, disperso o denso). A continuación, se proporciona una lista de los tipos de parseadores de TensorFlow (consulte la Tabla 1) y la coerción de los tipos primitivos (Tabla 2).\n",
        "\n",
        "Tabla 1: tipos de parseadores de TensorFlow admitidos:\n",
        "\n",
        "Tipos de parseadores de TensorFlow | Tensores de TensorFlow | Explicación\n",
        "--- | --- | ---\n",
        "tf.FixedLenFeature([], tf.int32) | tensor denso | Parsee una característica de longitud fija; es decir, todas las filas tienen una misma cantidad constante de elementos, por ejemplo, solo un elemento o un arreglo que siempre tiene la misma cantidad de elementos para cada fila.\n",
        "tf.SparseFeature(index_key=['key_1st_index', 'key_2nd_index'], value_key='key_value', dtype=tf.int64, size=[20, 50]) | tensor disperso | Parsee una característica dispersa donde cada fila tiene una lista de índices y valores de longitud variable. La 'index_key' identifica los índices. La 'value_key' identifica el valor. El 'dtype' es el tipo de datos. El 'size' es el valor de índice máximo esperado para cada entrada de índice.\n",
        "tfio.experimental.columnar.VarLenFeatureWithRank([],tf.int64) | tensor disperso | Parsee una característica de longitud variable; eso significa que cada fila de datos puede tener una cantidad variable de elementos, por ejemplo, la primera fila tiene 5 elementos, la segunda fila tiene 7 elementos\n",
        "\n",
        "Tabla 2, conversión admitida de tipos Avro a tipos de TensorFlow:\n",
        "\n",
        "Tipo primitivo de Avro | Tipo primitivo de TensorFlow\n",
        "--- | ---\n",
        "booleano: un valor binario | tf.bool\n",
        "bytes: una secuencia de bytes de 8 bits sin signo | tf.string\n",
        "double: número de punto flotante IEEE de 64 bits de doble precisión | tf.float64\n",
        "enum: tipo de enumeración | tf.string con el nombre del símbolo\n",
        "float: número de punto flotante IEEE de 32 bits de precisión simple | tf.float32\n",
        "int: entero de 32 bits con signo | tf.int32\n",
        "int: entero de 64 bits con signo | tf.int64\n",
        "null: sin valor | usa el valor predeterminado\n",
        "string: secuencia de caracteres de Unicode | tf.string\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PFQPuy5hY7r"
      },
      "source": [
        "En <a target=\"_blank\" href=\"https://github.com/tensorflow/io/blob/master/tests/test_parse_avro.py#L437\">las pruebas</a> puede encontrar un conjunto completo de ejemplos de la API del conjunto de datos de Avro.\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "Tce3stUlHN0L"
      ],
      "name": "avro.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
