{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mt9dL5dIir8X"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ufPx7EiCiqgR"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucMoYase6URl"
      },
      "source": [
        "# Carga y procesamiento de imágenes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Wwu5SXZmEkB"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>     <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/load_data/images\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver en TensorFlow.org</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/es-419/tutorials/load_data/images.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Ejecutar en Google Colab</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/es-419/tutorials/load_data/images.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver código fuente en GitHub</a>\n",
        "</td>\n",
        "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/es-419/tutorials/load_data/images.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Descargar el bloc de notas</a>\n",
        "</td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oxw4WahM7DU9"
      },
      "source": [
        "En este tutorial se muestra cómo cargar y preprocesar un conjunto de datos de imágenes de tres formas:\n",
        "\n",
        "- Primero, usarás las utilidades de preprocesamiento de alto nivel de Keras (como `tf.keras.utils.image_dataset_from_directory`) y capas (como `tf.keras.layers.Rescaling`) para leer un directorio de imágenes en un disco.\n",
        "- Luego, escribirá su propia canalización de entrada desde cero [con tf.data](../../guide/data.ipynb).\n",
        "- Por último, descargará un conjunto de datos de un [catálogo](https://www.tensorflow.org/datasets/catalog/overview) más grande que está disponible en [TensorFlow Datasets](https://www.tensorflow.org/datasets)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hoQQiZDB6URn"
      },
      "source": [
        "## Preparación"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3vhAMaIOBIee"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import PIL.Image\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qnp9Z2sT5dWj"
      },
      "outputs": [],
      "source": [
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wO0InzL66URu"
      },
      "source": [
        "### Descargar el conjunto de datos de flores\n",
        "\n",
        "Este tutorial usa un conjunto de datos de miles de fotos de flores. El conjunto de datos de flores contiene cinco subdirectorios, uno por clase.\n",
        "\n",
        "```\n",
        "flowers_photos/\n",
        "  daisy/\n",
        "  dandelion/\n",
        "  roses/\n",
        "  sunflowers/\n",
        "  tulips/\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ju2yXtdV5YaT"
      },
      "source": [
        "Nota: todas las imágenes son licencia de CC-BY, los creadores están en el archivo LICENSE.txt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rN-Pc6Zd6awg"
      },
      "outputs": [],
      "source": [
        "import pathlib\n",
        "dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n",
        "archive = tf.keras.utils.get_file(origin=dataset_url, extract=True)\n",
        "data_dir = pathlib.Path(archive).with_suffix('')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFkFK74oO--g"
      },
      "source": [
        "Después de la descarga (218MB), debería tener una copia disponible de las fotos de flores. Son 3670 imágenes en total."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QhewYCxhXQBX"
      },
      "outputs": [],
      "source": [
        "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
        "print(image_count)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZUFusk44d9GW"
      },
      "source": [
        "Cada directorio contiene imágenes de ese tipo de flor. Estas son algunas rosas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "crs7ZjEp60Ot"
      },
      "outputs": [],
      "source": [
        "roses = list(data_dir.glob('roses/*'))\n",
        "PIL.Image.open(str(roses[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oV9PtjdKKWyI"
      },
      "outputs": [],
      "source": [
        "roses = list(data_dir.glob('roses/*'))\n",
        "PIL.Image.open(str(roses[1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_kge08gSCan"
      },
      "source": [
        "## Cargar datos con una utilidad de Keras\n",
        "\n",
        "Carguemos estas imágenes fuera del disco con la utilidad `tf.keras.utils.image_dataset_from_directory` que es muy útil."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jobDTUs8Wxu"
      },
      "source": [
        "### Crear un conjunto de datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAmtzsnjDNhB"
      },
      "source": [
        "Defina algunos parámetros para el cargador:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qJdpyqK541ty"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "img_height = 180\n",
        "img_width = 180"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehhW308g8soJ"
      },
      "source": [
        "Se considera buena práctica usar un separador de validación al desarrollar el modelo. El 80 % de las imágenes las usará para entrenamiento y el 20 % para validación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "chqakIP14PDm"
      },
      "outputs": [],
      "source": [
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"training\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pb2Af2lsUShk"
      },
      "outputs": [],
      "source": [
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"validation\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ug3ITsz0b_cF"
      },
      "source": [
        "En estos conjuntos de datos, puede encontrar los nombres de clase en el atributo `class_names`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R7z2yKt7VDPJ"
      },
      "outputs": [],
      "source": [
        "class_names = train_ds.class_names\n",
        "print(class_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bK6CQCqIctCd"
      },
      "source": [
        "### Visualizar los datos\n",
        "\n",
        "Aquí están las primeras nueve imágenes del conjunto de datos para entrenamiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AAY3LJN28Kuy"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in train_ds.take(1):\n",
        "  for i in range(9):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "    plt.title(class_names[labels[i]])\n",
        "    plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUI0fr7igPtA"
      },
      "source": [
        "Puede entrenar un modelo con estos conjuntos de datos al pasarlos a `model.fit` (lo veremos más adelante). Si quiere, también puede iterar manualmente por los conjuntos de datos y recuperar lotes de imágenes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BdPHeHXt9sjA"
      },
      "outputs": [],
      "source": [
        "for image_batch, labels_batch in train_ds:\n",
        "  print(image_batch.shape)\n",
        "  print(labels_batch.shape)\n",
        "  break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZgIZeXaDUsF"
      },
      "source": [
        "El lote de imagen `image_batch` es un tensor de la forma `(32, 180, 180, 3)`. Esto es un lote de 32 imágenes de forma `180x180x3` (la última dimensión hace referencia a los canales de color RGB). El lote `label_batch` es un tensor de la forma `(32,)`, estas son etiquetas que concuerdan con las 32 imágenes.\n",
        "\n",
        "Se puede llamar a `.numpy()` en cualquiera de estos tensores para convertirlos en `numpy.ndarray`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ybl6a2YCg1rV"
      },
      "source": [
        "### Estandarizar los datos\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdogGjM2K6OU"
      },
      "source": [
        "Los valores del canal RGB están dentro del rango `[0, 255]`, lo cual no es ideal para una red neuronal. En general, debería buscar que los valores de su entrada sean bajos.\n",
        "\n",
        "Aquí, estandarizará los valores para que estén dentro del rango `[0, 1]` mediante el uso de `tf.keras.layers.Rescaling`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "16yNdZXdExyM"
      },
      "outputs": [],
      "source": [
        "normalization_layer = tf.keras.layers.Rescaling(1./255)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nd0_enkb8uxZ"
      },
      "source": [
        "Esta capa se puede usar de dos formas. Se puede aplicar en el conjunto de datos llamando `Dataset.map`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QgOnza-U_z5Y"
      },
      "outputs": [],
      "source": [
        "normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "image_batch, labels_batch = next(iter(normalized_ds))\n",
        "first_image = image_batch[0]\n",
        "# Notice the pixel values are now in `[0,1]`.\n",
        "print(np.min(first_image), np.max(first_image))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z39nXayj9ioS"
      },
      "source": [
        "O, se puede incluir la capa en la definición de su modelo para simplificar la implementación. Aquí se usará el segundo enfoque."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXLd3wMpDIkp"
      },
      "source": [
        "Nota: Si lo que quiere es escalar valores de píxeles a `[-1,1]` escriba `tf.keras.layers.Rescaling(1./127.5, offset=-1)` en su lugar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LeNWVa8qRBGm"
      },
      "source": [
        "Nota: Previamente, usaste el argumento `image_size` de `tf.keras.utils.image_dataset_from_directory` para ajustar el tamaño de las imágenes. Si también quiere incluir la lógica del ajuste en su modelo, puede usar la capa `tf.keras.layers.Resizing`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ti8avTlLofoJ"
      },
      "source": [
        "### Configurar el conjunto de datos para rendimiento\n",
        "\n",
        "Vamos a asegurarnos de usar una preextracción almacenada en el búfer para que pueda producir datos desde el disco sin provocar un bloqueo en la E/S. Hay dos métodos importantes que deberías usar al cargar datos:\n",
        "\n",
        "- `Dataset.cache` conserva los datos en la memoria después de que se carga desde el disco durante la primera época. Así se garantiza que el conjunto de datos no se transforme en un cuello de botella mientras entrena su modelo. Si su conjunto de datos es muy grande para guardar en la memoria, también puede usar este método para crear un caché en disco de alto rendimiento.\n",
        "- `Dataset.prefetch` superpone el preprocesamiento de los datos y la ejecución del modelo durante el entrenamiento.\n",
        "\n",
        "Quienes quieran aprender más sobre ambos modelos y también sobre cómo copiar datos en caché en disco, pueden leer la sección *Preextracción* de la guía [Mejor rendimiento con la API tf.data](../../guide/data_performance.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ea3kbMe-pGDw"
      },
      "outputs": [],
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqHjIr6cplwY"
      },
      "source": [
        "### Entrenar un modelo\n",
        "\n",
        "Para completar el tutorial, deberá mostrar cómo entrenar un modelo simple con los conjuntos de datos que acaba de preparar.\n",
        "\n",
        "El modelo [Sequential](https://www.tensorflow.org/guide/keras/sequential_model) consiste en tres bloques de convolución (`tf.keras.layers.Conv2D`) con una capa de agrupación máxima (`tf.keras.layers.MaxPooling2D`) en cada uno de ellos. Hay una capa totalmente conectada (`tf.keras.layers.Dense`) con 128 unidades más que se activa con una función de activación de ReLU (`'relu'`). El modelo no tiene ningún ajuste, el objetivo es mostrarle los mecanismos con los conjuntos de datos que usted acaba de crear. Para aprender más sobre la clasificación de imágenes, vea el tutorial de [Clasificación de imágenes](../images/classification.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LdR0BzCcqxw0"
      },
      "outputs": [],
      "source": [
        "num_classes = 5\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Rescaling(1./255),\n",
        "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(),\n",
        "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(),\n",
        "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dense(num_classes)\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d83f5aa7f3fb"
      },
      "source": [
        "Escoja el optimizador `tf.keras.optimizers.Adam` y la función de pérdida `tf.keras.losses.SparseCategoricalCrossentropy`. Para ver la precisión de entrenamiento y validación de cada época de entrenamiento, realice una pasada del argumento de `métricas` en `Model.compile`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t_BlmsnmsEr4"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "  optimizer='adam',\n",
        "  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "  metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffwd44ldNMOE"
      },
      "source": [
        "Nota: Solo lo entrenará para algunas épocas para que el tutorial se ejecute rápido. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S08ZKKODsnGW"
      },
      "outputs": [],
      "source": [
        "model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=3\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEtT9YGjSAOK"
      },
      "source": [
        "Nota: También puede escribir un bucle de entrenamiento personalizado en vez de usar `Model.fit`. Para más información, visite el tutorial de [Escribir un bucle desde cero](https://www.tensorflow.org/guide/keras/writing_a_training_loop_from_scratch)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BaW4wx5L7hrZ"
      },
      "source": [
        "Quizás notará que la precisión de la validación es baja en comparación con la precisión del entrenamiento, esto quiere decir que su modelo está sobreajustado. Puede obtener más información sobre sobrejuste y sobre cómo reducirlo en este [tutorial](https://www.tensorflow.org/tutorials/keras/overfit_and_underfit)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxS1cLzM8mEp"
      },
      "source": [
        "## El uso de tf.data para control más preciso"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ylj9fgkamgWZ"
      },
      "source": [
        "La utilidad de preprocesamiento de Keras mencionada anteriormente, `tf.keras.utils.image_dataset_from_directory`, es una forma conveniente de crear un `tf.data.Dataset` desde una directorio de imágenes.\n",
        "\n",
        "Para control más preciso y específico, puede escribir su propia canalización de entrada con `tf.data`. En esta sección se muestra cómo hacerlo, empezando con las rutas de archivo del archivo TGZ que descargó antes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lAkQp5uxoINu"
      },
      "outputs": [],
      "source": [
        "list_ds = tf.data.Dataset.list_files(str(data_dir/'*/*'), shuffle=False)\n",
        "list_ds = list_ds.shuffle(image_count, reshuffle_each_iteration=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "coORvEH-NGwc"
      },
      "outputs": [],
      "source": [
        "for f in list_ds.take(5):\n",
        "  print(f.numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NLQ_VJhWO4z"
      },
      "source": [
        "La estructura de árbol de estos archivos puede usarse para compilar una lista `class_names`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uRPHzDGhKACK"
      },
      "outputs": [],
      "source": [
        "class_names = np.array(sorted([item.name for item in data_dir.glob('*') if item.name != \"LICENSE.txt\"]))\n",
        "print(class_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CiptrWmAlmAa"
      },
      "source": [
        "Divida los conjuntos de datos en conjuntos de entrenamiento y validación:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GWHNPzXclpVr"
      },
      "outputs": [],
      "source": [
        "val_size = int(image_count * 0.2)\n",
        "train_ds = list_ds.skip(val_size)\n",
        "val_ds = list_ds.take(val_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkB-IR4-pS3U"
      },
      "source": [
        "Puede imprimir la longitud de cada conjunto de datos como se muestra a continuación:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SiKQrb9ppS-7"
      },
      "outputs": [],
      "source": [
        "print(tf.data.experimental.cardinality(train_ds).numpy())\n",
        "print(tf.data.experimental.cardinality(val_ds).numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91CPfUUJ_8SZ"
      },
      "source": [
        "Escriba una función breve que convierta una ruta de archivo en una pareja `(img, label)`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "arSQzIey-4D4"
      },
      "outputs": [],
      "source": [
        "def get_label(file_path):\n",
        "  # Convert the path to a list of path components\n",
        "  parts = tf.strings.split(file_path, os.path.sep)\n",
        "  # The second to last is the class-directory\n",
        "  one_hot = parts[-2] == class_names\n",
        "  # Integer encode the label\n",
        "  return tf.argmax(one_hot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MGlq4IP4Aktb"
      },
      "outputs": [],
      "source": [
        "def decode_img(img):\n",
        "  # Convert the compressed string to a 3D uint8 tensor\n",
        "  img = tf.io.decode_jpeg(img, channels=3)\n",
        "  # Resize the image to the desired size\n",
        "  return tf.image.resize(img, [img_height, img_width])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-xhBRgvNqRRe"
      },
      "outputs": [],
      "source": [
        "def process_path(file_path):\n",
        "  label = get_label(file_path)\n",
        "  # Load the raw data from the file as a string\n",
        "  img = tf.io.read_file(file_path)\n",
        "  img = decode_img(img)\n",
        "  return img, label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9a5GpsUOBx8"
      },
      "source": [
        "Use `Dataset.map` para crear un conjunto de datos de parejas de `image, label`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3SDhbo8lOBQv"
      },
      "outputs": [],
      "source": [
        "# Set `num_parallel_calls` so multiple images are loaded/processed in parallel.\n",
        "train_ds = train_ds.map(process_path, num_parallel_calls=AUTOTUNE)\n",
        "val_ds = val_ds.map(process_path, num_parallel_calls=AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kxrl0lGdnpRz"
      },
      "outputs": [],
      "source": [
        "for image, label in train_ds.take(1):\n",
        "  print(\"Image shape: \", image.numpy().shape)\n",
        "  print(\"Label: \", label.numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYGCgJuR_9Qp"
      },
      "source": [
        "### Configurar conjuntos de datos para rendimiento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwZavzgsIytz"
      },
      "source": [
        "Para entrenar un modelo con este conjunto de datos, necesita que los datos:\n",
        "\n",
        "- Estén en orden aleatorio.\n",
        "- Estén en lotes.\n",
        "- Que los lotes estén disponibles lo antes posible.\n",
        "\n",
        "Se pueden agregar estas características con la API `tf.data`. Para más información, lea la guía [Input Pipeline Performance](../../guide/performance/datasets.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uZmZJx8ePw_5"
      },
      "outputs": [],
      "source": [
        "def configure_for_performance(ds):\n",
        "  ds = ds.cache()\n",
        "  ds = ds.shuffle(buffer_size=1000)\n",
        "  ds = ds.batch(batch_size)\n",
        "  ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
        "  return ds\n",
        "\n",
        "train_ds = configure_for_performance(train_ds)\n",
        "val_ds = configure_for_performance(val_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45P7OvzRWzOB"
      },
      "source": [
        "### Visualizar los datos\n",
        "\n",
        "Puede visualizar estos conjuntos de datos de forma similar a como lo hizo previamente:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UN_Dnl72YNIj"
      },
      "outputs": [],
      "source": [
        "image_batch, label_batch = next(iter(train_ds))\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(9):\n",
        "  ax = plt.subplot(3, 3, i + 1)\n",
        "  plt.imshow(image_batch[i].numpy().astype(\"uint8\"))\n",
        "  label = label_batch[i]\n",
        "  plt.title(class_names[label])\n",
        "  plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMT8kh_uXPRU"
      },
      "source": [
        "### Continuar entrenando el modelo\n",
        "\n",
        "Ahora ha construido un `tf.data.Dataset` parecido al de `tf.keras.utils.image_dataset_from_directory` anteriormente. Puede continuar entrenándolo con ese modelo. Igual que antes, solo lo entrenará para algunas épocas para que el tiempo de ejecución sea corto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vm_bi7NKXOzW"
      },
      "outputs": [],
      "source": [
        "model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=3\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDJXAexrwsx8"
      },
      "source": [
        "## El uso de TensorFlow Datasets\n",
        "\n",
        "Por ahora, este tutorial solo se ha enfocado en cargar datos fuera del disco. También puede encontrar conjuntos de datos para usar si explora el gran [catálogo](https://www.tensorflow.org/datasets/catalog/overview) de conjuntos de datos de fácil descarga en  [TensorFlow Datasets](https://www.tensorflow.org/datasets).\n",
        "\n",
        "Previamente, ya cargó el conjunto de datos de flores fuera del disco, ahora lo vamos a importar con TensorFlow Datasets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qyu9wWDf1gfH"
      },
      "source": [
        "Descargue el [conjunto de datos](https://www.tensorflow.org/datasets/catalog/tf_flowers) de flores con TensorFlow Datasets:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NTQ-53DNwv8o"
      },
      "outputs": [],
      "source": [
        "(train_ds, val_ds, test_ds), metadata = tfds.load(\n",
        "    'tf_flowers',\n",
        "    split=['train[:80%]', 'train[80%:90%]', 'train[90%:]'],\n",
        "    with_info=True,\n",
        "    as_supervised=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hxXSgtj1iLV"
      },
      "source": [
        "El conjunto de datos de flores tiene cinco clases:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kJvt6qzF1i4L"
      },
      "outputs": [],
      "source": [
        "num_classes = metadata.features['label'].num_classes\n",
        "print(num_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dbvEz_F1lgE"
      },
      "source": [
        "Recupere una imagen del conjunto de datos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1lF3IUAO1ogi"
      },
      "outputs": [],
      "source": [
        "get_label_name = metadata.features['label'].int2str\n",
        "\n",
        "image, label = next(iter(train_ds))\n",
        "_ = plt.imshow(image)\n",
        "_ = plt.title(get_label_name(label))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHOOH_4TwaUb"
      },
      "source": [
        "Igual que antes, recuerde que los conjuntos de entrenamiento, validación y prueba deben estar en lotes, en orden aleatorio y configurados para buen rendimiento:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AMV6GtZiwfGP"
      },
      "outputs": [],
      "source": [
        "train_ds = configure_for_performance(train_ds)\n",
        "val_ds = configure_for_performance(val_ds)\n",
        "test_ds = configure_for_performance(test_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmR7kT8l1w20"
      },
      "source": [
        "Puede encontrar un ejemplo completo que usa el conjunto de datos de flores y TensorFlow Datasets en el tutorial de [Aumento de datos](../images/data_augmentation.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cqkPenZIaHl"
      },
      "source": [
        "## Próximos pasos\n",
        "\n",
        "En este tutorial se mostraron dos formas de cargar imágenes fuera del disco. Primero, aprendió a cargar y preprocesar un conjunto de imágenes con las capas y utilidades de preprocesamiento de Keras. Luego, aprendió cómo escribir una canalización de entrada desde cero con `tf.data{/code}. Por último, aprendió cómo descargar un conjunto de datos desde TensorFlow Datasets.`\n",
        "\n",
        "Para sus próximos pasos:\n",
        "\n",
        "- Puede aprender [cómo agregar aumento de datos](https://www.tensorflow.org/tutorials/images/data_augmentation).\n",
        "- Aprender más sobre `tf.data`, puede leer la guía [tf.data: Construir canalizaciones de entrada de TensorFlow](https://www.tensorflow.org/guide/data)."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "images.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
