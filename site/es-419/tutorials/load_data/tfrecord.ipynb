{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pL--_KGdYoBz"
      },
      "source": [
        "##### Copyright 2019 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "uBDvXpYzYnGj"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQzaEQuJiW_d"
      },
      "source": [
        "# TFRecord y tf.train.Example\n",
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td><a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/load_data/tfrecord\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver en TensorFlow.org</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/es-419/tutorials/load_data/tfrecord.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Ejecutar en Google Colab</a></td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/es-419/tutorials/load_data/tfrecord.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver fuente en GitHub</a>\n",
        "</td>\n",
        "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/es-419/tutorials/load_data/tfrecord.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Descargar bloc de notas</a>\n",
        "</td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3pkUd_9IZCFO"
      },
      "source": [
        "El formato TFRecord es un formato simple para almacenar una secuencia de registros binarios.\n",
        "\n",
        "Los [búferes de protocolo](https://developers.google.com/protocol-buffers/) son bibliotecas interlenguaje, interplataforma que se usan para la serialización eficiente de los datos estructurados.\n",
        "\n",
        "Los archivos `.proto` definen los mensajes de protocolo. Por lo general, son la forma más fácil de entender un tipo de mensaje.\n",
        "\n",
        "El mensaje `tf.train.Example` (o protobúfer) es un tipo de mensaje flexible que representa el mapeo de un `{\"string\": value}`. Está diseñado para ser usado con TensorFlow y se usa en las API de alto nivel como [TFX](https://www.tensorflow.org/tfx/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ac83J0QxjhFt"
      },
      "source": [
        "En estas notas se demuestra cómo crear, analizar y usar el mensaje `tf.train.Example`. Después, se serializan, escriben y leen mensajes `tf.train.Example` hacia archivos `.tfrecord` y desde ellos.\n",
        "\n",
        "Nota: Si bien son útiles, estas estructuras son opcionales. No hay necesidad de convertir códigos existentes para usar TFRecords, a menos que use [tf.data](https://www.tensorflow.org/guide/data) y lea datos, y todavía se genere un cuello de botella para el entrenamiento. Para más consejos sobre el rendimiento de los conjuntos de datos, consulte [Mejor rendimiento con la API tf.data](https://www.tensorflow.org/guide/data_performance).\n",
        "\n",
        "Nota: En general, debería particionar horizontalmente los datos en múltiples archivos para poder paralelizar las entradas y salidas (dentro de un único <em>host</em> o en varios de ellos). Por regla general, habría que tener al menos 10 veces más archivos de los que los <em>hosts</em> leerán los datos. A la vez, cada archivo debería ser lo suficientemente grande (al menos más de 10 MB e idealmente más de 100 MB+) como para que la preextracción de entradas o salidas sea beneficiosa. Por ejemplo, digamos que tiene `X` GB de datos y que planea entrenar hasta `N` <em>hosts</em>. Lo ideal sería particionar horizontalmente los datos a archivos ~`10*N`, siempre y cuando ~`X/(10*N)` tenga más de 10 MB (y preferentemente más de 100 MB). Si el tamaño es menor, probablemente sea necesario generar menos particionamientos horizontales para compensar los beneficios del paralelismo y de la preextracción de entradas o salidas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WkRreBf1eDVc"
      },
      "source": [
        "## Preparación"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ja7sezsmnXph"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "import IPython.display as display"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5Kq88ccUWQV"
      },
      "source": [
        "## `tf.train.Example`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VrdQHgvNijTi"
      },
      "source": [
        "### Tipos de datos para `tf.train.Example`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZw57Qrn4CTE"
      },
      "source": [
        "Fundamentalmente, un `tf.train.Example` es un mapeo `{\"string\": tf.train.Feature}`.\n",
        "\n",
        "Para el tipo de mensaje `tf.train.Feature` se puede aceptar uno de los siguientes tipos (consulte el [archivo `.proto`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/example/feature.proto) para referencia). La mayoría de los demás tipos genéricos se pueden coercionar en uno de los siguientes:\n",
        "\n",
        "1. `tf.train.BytesList` (los siguientes tipos se pueden coercionar)\n",
        "\n",
        "- `string`\n",
        "- `byte`\n",
        "\n",
        "1. `tf.train.FloatList` (los siguientes tipos se pueden coercionar)\n",
        "\n",
        "- `float` (`float32`)\n",
        "- `double` (`float64`)\n",
        "\n",
        "1. `tf.train.Int64List` (los siguientes tipos se pueden coercionar)\n",
        "\n",
        "- `bool`\n",
        "- `enum`\n",
        "- `int32`\n",
        "- `uint32`\n",
        "- `int64`\n",
        "- `uint64`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_e3g9ExathXP"
      },
      "source": [
        "Para convertir a un tipo estándar de TensorFlow en un `tf.train.Example`, compatible con `tf.train.Feature`, puede usar las funciones de atajo que se encuentran debajo. Tenga en cuenta que cada función debe contar con un valor de entrada escalar y devuelve una `tf.train.Feature` que contiene uno de los tres tipos de `list` que se mostraron arriba:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mbsPOUpVtYxA"
      },
      "outputs": [],
      "source": [
        "# The following functions can be used to convert a value to a type compatible\n",
        "# with tf.train.Example.\n",
        "\n",
        "def _bytes_feature(value):\n",
        "  \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
        "  if isinstance(value, type(tf.constant(0))):\n",
        "    value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
        "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
        "\n",
        "def _float_feature(value):\n",
        "  \"\"\"Returns a float_list from a float / double.\"\"\"\n",
        "  return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
        "\n",
        "def _int64_feature(value):\n",
        "  \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
        "  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wst0v9O8hgzy"
      },
      "source": [
        "Nota: Para no complejizar el tema, digamos que en este ejemplo solamente se usan entradas escalares. La manera más sencilla de manejar funciones no escalares es con `tf.io.serialize_tensor` para convertir tensores en cadenas binarias. Las cadenas son escalares en TensorFlow. Para volver a convertir la cadena binaria en un tensor, use `tf.io.parse_tensor`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsMbkkC8xxtB"
      },
      "source": [
        "Más adelante hay algunos ejemplos sobre cómo trabajan estas funciones. Observe los diferentes tipos de entradas y los tipos estandarizados de salidas. Si el tipo de entrada de una función no coincide con uno de los tipos coercibles mencionados arriba, la función creará una excepción (p. ej., `_int64_feature(1.0)` mostrará un error porque `1.0` es flotante; por lo tanto, debería usarse con la función `_float_feature`):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hZzyLGr0u73y"
      },
      "outputs": [],
      "source": [
        "print(_bytes_feature(b'test_string'))\n",
        "print(_bytes_feature(u'test_bytes'.encode('utf-8')))\n",
        "\n",
        "print(_float_feature(np.exp(1)))\n",
        "\n",
        "print(_int64_feature(True))\n",
        "print(_int64_feature(1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nj1qpfQU5qmi"
      },
      "source": [
        "Todos los protomensajes se pueden serializar en una cadena binaria aplicando el método `.SerializeToString`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5afZkORT5pjm"
      },
      "outputs": [],
      "source": [
        "feature = _float_feature(np.exp(1))\n",
        "\n",
        "feature.SerializeToString()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "laKnw9F3hL-W"
      },
      "source": [
        "### Creación de un mensaje `tf.train.Example`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_MEnhxchQPC"
      },
      "source": [
        "Supongamos que desea crear un mensaje `tf.train.Example` a partir de datos existentes. En la práctica, el conjunto de datos puede provenir de cualquier parte, pero el procedimiento de crear el mensaje `tf.train.Example` a partir de una observación simple será siempre el mismo:\n",
        "\n",
        "1. Dentro de cada observación, cada uno de los valores debe convertirse a `tf.train.Feature` y debe contener uno de los 3 tipos compatibles. Debe usar una de las funciones mencionadas arriba.\n",
        "\n",
        "2. Cree un mapa (diccionario) que parta de la cadena del nombre de la función y llegue al valor de la función codificada producido en el número 1.\n",
        "\n",
        "3. El mapa producido en el paso 2 se convierte en un [mensaje `Features`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/example/feature.proto#L85)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4EgFQ2uHtchc"
      },
      "source": [
        "En este bloc de notas, creara un conjunto de datos con NumPy.\n",
        "\n",
        "Este conjunto de datos tendrá 4 funciones:\n",
        "\n",
        "- una función booleana, `False` o `True` con iguales probabilidades\n",
        "- una función de enteros elegidos de manera aleatoria y uniforme a partir de `[0, 5]`\n",
        "- una función de cadena generada a partir de una tabla de cadenas usando la función de enteros como índice.\n",
        "- una función flotante de una distribución normal estándar\n",
        "\n",
        "Piense en una muestra compuesta de 10 000 observaciones distribuidas de idéntico modo, para cada una de las distribuciones mencionadas arriba:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CnrguFAy3YQv"
      },
      "outputs": [],
      "source": [
        "# The number of observations in the dataset.\n",
        "n_observations = int(1e4)\n",
        "\n",
        "# Boolean feature, encoded as False or True.\n",
        "feature0 = np.random.choice([False, True], n_observations)\n",
        "\n",
        "# Integer feature, random from 0 to 4.\n",
        "feature1 = np.random.randint(0, 5, n_observations)\n",
        "\n",
        "# String feature.\n",
        "strings = np.array([b'cat', b'dog', b'chicken', b'horse', b'goat'])\n",
        "feature2 = strings[feature1]\n",
        "\n",
        "# Float feature, from a standard normal distribution.\n",
        "feature3 = np.random.randn(n_observations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGrscehJr7Jd"
      },
      "source": [
        "Cada una de estas funciones se puede coercionar para generar un tipo `tf.train.Example` compatible usando una de las siguientes opciones: `_bytes_feature`, `_float_feature` o `_int64_feature`. Después, se puede crear un mensaje `tf.train.Example` a partir de estas funciones codificadas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RTCS49Ij_kUw"
      },
      "outputs": [],
      "source": [
        "def serialize_example(feature0, feature1, feature2, feature3):\n",
        "  \"\"\"\n",
        "  Creates a tf.train.Example message ready to be written to a file.\n",
        "  \"\"\"\n",
        "  # Create a dictionary mapping the feature name to the tf.train.Example-compatible\n",
        "  # data type.\n",
        "  feature = {\n",
        "      'feature0': _int64_feature(feature0),\n",
        "      'feature1': _int64_feature(feature1),\n",
        "      'feature2': _bytes_feature(feature2),\n",
        "      'feature3': _float_feature(feature3),\n",
        "  }\n",
        "\n",
        "  # Create a Features message using tf.train.Example.\n",
        "\n",
        "  example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
        "  return example_proto.SerializeToString()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XftzX9CN_uGT"
      },
      "source": [
        "Por ejemplo, supongamos que tiene una observación simple de un conjunto de datos, `[False, 4, bytes('goat'), 0.9876]`. Con ello puede crear e imprimir el mensaje `tf.train.Example` para la observación con `create_message()`. Cada observación simple se escribirá como un mensaje `Features` según lo que se encuentra arriba. Tenga en cuenta que el [mensaje](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/example/example.proto#L88) `tf.train.Example` solamente es un envoltorio (<em>wrapper</em>) en torno al mensaje `Features`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N8BtSx2RjYcb"
      },
      "outputs": [],
      "source": [
        "# This is an example observation from the dataset.\n",
        "\n",
        "example_observation = []\n",
        "\n",
        "serialized_example = serialize_example(False, 4, b'goat', 0.9876)\n",
        "serialized_example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pbGATlG6u-4"
      },
      "source": [
        "Para decodificar el mensaje, use el método `tf.train.Example.FromString`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dGim-mEm6vit"
      },
      "outputs": [],
      "source": [
        "example_proto = tf.train.Example.FromString(serialized_example)\n",
        "example_proto"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6qxofy89obI"
      },
      "source": [
        "## Detalles del formato TFRecords\n",
        "\n",
        "Un archivo TFRecord contiene una secuencia de registros. El archivo solamente se puede leer de forma secuencial.\n",
        "\n",
        "Cada registro contiene una cadena de bytes, para una carga útil de datos, además de la longitud de los datos y CRC-32C ([CRC (verificación de redundancia cíclica) de 32-bit](https://en.wikipedia.org/wiki/Cyclic_redundancy_check#CRC-32_algorithm) con los <em>hashes</em> del [polinomio de Castagnoli](https://en.wikipedia.org/wiki/Cyclic_redundancy_check#Standards_and_common_use)) para control de integridad.\n",
        "\n",
        "Los registros se almacenan en los siguientes formatos:\n",
        "\n",
        "```\n",
        "uint64 length\n",
        "uint32 masked_crc32_of_length\n",
        "byte   data[length]\n",
        "uint32 masked_crc32_of_data\n",
        "```\n",
        "\n",
        "Los registros se concatenan juntos para producir el archivo. Las CRC [se describen aquí](https://en.wikipedia.org/wiki/Cyclic_redundancy_check) y la máscara de una CRC es la siguiente:\n",
        "\n",
        "```\n",
        "masked_crc = ((crc >> 15) | (crc << 17)) + 0xa282ead8ul\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0iHagLQCJv6"
      },
      "source": [
        "Nota: No es obligatorio usar `tf.train.Example` en archivos TFRecord. `tf.train.Example` solamente es un método que sirve para la serialización de diccionarios en cadenas de bytes. Cualquier cadena de bytes que se puede decodificar en TensorFlow se podría almacenar en un archivo TFRecord. Entre los ejemplos se encuentra lo siguiente: líneas de texto, JSON (con `tf.io.decode_json_example`), datos de imágenes codificados o `tf.Tensors` serializados (con `tf.io.serialize_tensor`/`tf.io.parse_tensor`). Para más opciones, consulte el módulo `tf.io`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-Hjmee-fbLH"
      },
      "source": [
        "## Archivos TFRecord con `tf.data`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmehkCCT81Ez"
      },
      "source": [
        "El módulo `tf.data` también brinda herramientas para leer y escribir datos en TensorFlow."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FISEuz8ubu3"
      },
      "source": [
        "### Escritura de un archivo TFRecord\n",
        "\n",
        "La forma más fácil de incluir los datos en un conjunto de datos es mediante la aplicación del método `from_tensor_slices`.\n",
        "\n",
        "Aplicado a un arreglo, devuelve un conjunto de datos de escalares:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mXeaukvwu5_-"
      },
      "outputs": [],
      "source": [
        "tf.data.Dataset.from_tensor_slices(feature1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-q0VKyZvcad"
      },
      "source": [
        "Aplicado a un arreglo, devuelve un conjunto de datos de tuplas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H5sWyu1kxnvg"
      },
      "outputs": [],
      "source": [
        "features_dataset = tf.data.Dataset.from_tensor_slices((feature0, feature1, feature2, feature3))\n",
        "features_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m1C-t71Nywze"
      },
      "outputs": [],
      "source": [
        "# Use `take(1)` to only pull one example from the dataset.\n",
        "for f0,f1,f2,f3 in features_dataset.take(1):\n",
        "  print(f0)\n",
        "  print(f1)\n",
        "  print(f2)\n",
        "  print(f3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhIe63awyZYd"
      },
      "source": [
        "Use el método `tf.data.Dataset.map` para aplicar la función en cada elemento de un `Dataset`.\n",
        "\n",
        "La función mapeada debe trabajar en el modo de grafo de TensorFlow. Debe operar y devolver `tf.Tensors`. Una función sin tensores, como `serialize_example`, se puede encapsular en `tf.py_function` para hacerla compatible.\n",
        "\n",
        "Para usar `tf.py_function` es necesario especificar el tamaño y el tipo de información que, de otro modo, no estaría disponible:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "apB5KYrJzjPI"
      },
      "outputs": [],
      "source": [
        "def tf_serialize_example(f0,f1,f2,f3):\n",
        "  tf_string = tf.py_function(\n",
        "    serialize_example,\n",
        "    (f0, f1, f2, f3),  # Pass these args to the above function.\n",
        "    tf.string)      # The return type is `tf.string`.\n",
        "  return tf.reshape(tf_string, ()) # The result is a scalar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lHFjW4u4Npz9"
      },
      "outputs": [],
      "source": [
        "tf_serialize_example(f0, f1, f2, f3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrFZ9avE3HUF"
      },
      "source": [
        "Aplique esta función a cada elemento del conjunto de datos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VDeqYVbW3ww9"
      },
      "outputs": [],
      "source": [
        "serialized_features_dataset = features_dataset.map(tf_serialize_example)\n",
        "serialized_features_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DlDfuh46bRf6"
      },
      "outputs": [],
      "source": [
        "def generator():\n",
        "  for features in features_dataset:\n",
        "    yield serialize_example(*features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iv9oXKrcbhvX"
      },
      "outputs": [],
      "source": [
        "serialized_features_dataset = tf.data.Dataset.from_generator(\n",
        "    generator, output_types=tf.string, output_shapes=())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dqz8C4D5cIj9"
      },
      "outputs": [],
      "source": [
        "serialized_features_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6lw5VYpjZZC"
      },
      "source": [
        "Y escríbalos en un archivo TFRecord:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vP1VgTO44UIE"
      },
      "outputs": [],
      "source": [
        "filename = 'test.tfrecord'\n",
        "writer = tf.data.experimental.TFRecordWriter(filename)\n",
        "writer.write(serialized_features_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aV0GQhV8tmp"
      },
      "source": [
        "### Lectura de un archivo TFRecord"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3J5D4gcSy8N"
      },
      "source": [
        "También puede leer el archivo TFRecord con la clase `tf.data.TFRecordDataset`.\n",
        "\n",
        "Para más información sobre archivos TFRecord de consumo que usan `tf.data`, consulte la guía [tf.data: compilar canalizaciones de entrada de TensorFlow](https://www.tensorflow.org/guide/data#consuming_tfrecord_data).\n",
        "\n",
        "Los `TFRecordDataset` pueden ser útiles para estandarizar los datos de entrada y optimizar el rendimiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6OjX6UZl-bHC"
      },
      "outputs": [],
      "source": [
        "filenames = [filename]\n",
        "raw_dataset = tf.data.TFRecordDataset(filenames)\n",
        "raw_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_EQ9i2E_-Fz"
      },
      "source": [
        "En este punto, el conjunto de datos contiene mensajes serializados `tf.train.Example`. Al iterar, los devuelve como tensores de cadenas escalares.\n",
        "\n",
        "Use el método `.take` para mostrar solamente los primeros 10 registros.\n",
        "\n",
        "Nota: Al iterar sobre un `tf.data.Dataset` solamente funciona la ejecución de tipo <em>eager</em> activa."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hxVXpLz_AJlm"
      },
      "outputs": [],
      "source": [
        "for raw_record in raw_dataset.take(10):\n",
        "  print(repr(raw_record))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-6oNzM4luFQ"
      },
      "source": [
        "Estos tensores se pueden analizar (<em>parse</em>) con la función que se encuentra debajo. Tenga en cuenta que aquí es necesario usar `feature_description` porque los `tf.data.Dataset` usan la ejecución basada en grafos y necesitan esta descripción para generar su propio tamaño y tipo de firma:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zQjbIR1nleiy"
      },
      "outputs": [],
      "source": [
        "# Create a description of the features.\n",
        "feature_description = {\n",
        "    'feature0': tf.io.FixedLenFeature([], tf.int64, default_value=0),\n",
        "    'feature1': tf.io.FixedLenFeature([], tf.int64, default_value=0),\n",
        "    'feature2': tf.io.FixedLenFeature([], tf.string, default_value=''),\n",
        "    'feature3': tf.io.FixedLenFeature([], tf.float32, default_value=0.0),\n",
        "}\n",
        "\n",
        "def _parse_function(example_proto):\n",
        "  # Parse the input `tf.train.Example` proto using the dictionary above.\n",
        "  return tf.io.parse_single_example(example_proto, feature_description)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWETjUqhEQZf"
      },
      "source": [
        "Como alternativa, use `tf.parse_example` para analizar el lote completo a la vez. Aplique esta función a cada elemento del conjunto de datos con el método `tf.data.Dataset.map`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Ob7D-zmBm1w"
      },
      "outputs": [],
      "source": [
        "parsed_dataset = raw_dataset.map(_parse_function)\n",
        "parsed_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNV-XclGnOvn"
      },
      "source": [
        "Use la ejecución <em>eager</em> para mostrar las observaciones en el conjunto de datos. En este conjunto de datos hay 10 000 observaciones, pero solamente se mostrarán las primeras 10. Los datos se muestran como un diccionario de características. Cada elemento es un `tf.Tensor` y el elemento `numpy` de ese tensor muestra el valor de la característica:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x2LT2JCqhoD_"
      },
      "outputs": [],
      "source": [
        "for parsed_record in parsed_dataset.take(10):\n",
        "  print(repr(parsed_record))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cig9EodTlDmg"
      },
      "source": [
        "Aquí, la función `tf.parse_example` desempaqueta los campos `tf.train.Example` en tensores estándar."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyg1g3gU7DNn"
      },
      "source": [
        "## Archivos TFRecord en Python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FXG3miA7Kf1"
      },
      "source": [
        "El módulo `tf.io` también contiene funciones puras de Python para leer y escribir archivos de TFRecord."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKn5uql2lAaN"
      },
      "source": [
        "### Escritura de un archivo TFRecord"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNW_FA-GQWXs"
      },
      "source": [
        "A continuación, escriba las 10 000 observaciones en el archivo `test.tfrecord`. Cada observación se convierte en un mensaje `tf.train.Example`, que después se escribe en el archivo. Después, se puede verificar si el archivo `test.tfrecord` se ha creado:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MKPHzoGv7q44"
      },
      "outputs": [],
      "source": [
        "# Write the `tf.train.Example` observations to the file.\n",
        "with tf.io.TFRecordWriter(filename) as writer:\n",
        "  for i in range(n_observations):\n",
        "    example = serialize_example(feature0[i], feature1[i], feature2[i], feature3[i])\n",
        "    writer.write(example)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EjdFHHJMpUUo"
      },
      "outputs": [],
      "source": [
        "!du -sh {filename}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2osVRnYNni-E"
      },
      "source": [
        "### Lectura de un archivo TFRecord\n",
        "\n",
        "Estos tensores serializados se pueden analizar fácilmente con `tf.train.Example.ParseFromString`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U3tnd3LerOtV"
      },
      "outputs": [],
      "source": [
        "filenames = [filename]\n",
        "raw_dataset = tf.data.TFRecordDataset(filenames)\n",
        "raw_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nsEAACHcnm3f"
      },
      "outputs": [],
      "source": [
        "for raw_record in raw_dataset.take(1):\n",
        "  example = tf.train.Example()\n",
        "  example.ParseFromString(raw_record.numpy())\n",
        "  print(example)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhnZZmhm1miG"
      },
      "source": [
        "Eso devuelve un prototipo `tf.train.Example` que resulta difícil de usar en el estado en que se encuentra, pero que, en esencia, es una representación de lo siguiente:\n",
        "\n",
        "```\n",
        "Dict[str,\n",
        "     Union[List[float],\n",
        "           List[int],\n",
        "           List[str]]]\n",
        "```\n",
        "\n",
        "El siguiente código convierte manualmente el `Example` en un diccionario de arreglos NumPy, sin usar operaciones de TensorFlow Ops. Para más detalles, consulte el [archivo PROTO](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/example/feature.proto)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ziv9tiNE1l6J"
      },
      "outputs": [],
      "source": [
        "result = {}\n",
        "# example.features.feature is the dictionary\n",
        "for key, feature in example.features.feature.items():\n",
        "  # The values are the Feature objects which contain a `kind` which contains:\n",
        "  # one of three fields: bytes_list, float_list, int64_list\n",
        "\n",
        "  kind = feature.WhichOneof('kind')\n",
        "  result[key] = np.array(getattr(feature, kind).value)\n",
        "\n",
        "result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0tFDrwdoj3q"
      },
      "source": [
        "## Paso a paso: lectura y escritura de datos de imágenes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjN2LFxFpcR9"
      },
      "source": [
        "Este es un ejemplo completo de cómo leer y escribir datos de imágenes con TFRecords. Con una imagen como dato de entrada, escribirá los datos como archivo TFRecord, después, vuelve a leer el archivo y muestra la imagen.\n",
        "\n",
        "Puede resultar útil si, por ejemplo, se desea usar varios modelos en el mismo conjunto de datos de entrada. En vez de almacenar los datos sin procesar de la imagen, lo que puede hacer es procesarlos en formato TFRecords, y eso se puede usar en todos los siguientes procesamientos o modelados.\n",
        "\n",
        "Primero, descargue [esta imagen](https://commons.wikimedia.org/wiki/File:Felis_catus-cat_on_snow.jpg) de un gato en la nieve y [esta foto](https://upload.wikimedia.org/wikipedia/commons/f/fe/New_East_River_Bridge_from_Brooklyn_det.4a09796u.jpg) del puente de Williamsburg (Nueva York) en construcción."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Lk2qrKvN0yu"
      },
      "source": [
        "### Extracción de las imágenes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3a0fmwg8lHdF"
      },
      "outputs": [],
      "source": [
        "cat_in_snow  = tf.keras.utils.get_file(\n",
        "    '320px-Felis_catus-cat_on_snow.jpg',\n",
        "    'https://storage.googleapis.com/download.tensorflow.org/example_images/320px-Felis_catus-cat_on_snow.jpg')\n",
        "\n",
        "williamsburg_bridge = tf.keras.utils.get_file(\n",
        "    '194px-New_East_River_Bridge_from_Brooklyn_det.4a09796u.jpg',\n",
        "    'https://storage.googleapis.com/download.tensorflow.org/example_images/194px-New_East_River_Bridge_from_Brooklyn_det.4a09796u.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7aJJh7vENeE4"
      },
      "outputs": [],
      "source": [
        "display.display(display.Image(filename=cat_in_snow))\n",
        "display.display(display.HTML('Image cc-by: <a \"href=https://commons.wikimedia.org/wiki/File:Felis_catus-cat_on_snow.jpg\">Von.grzanka</a>'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KkW0uuhcXZqA"
      },
      "outputs": [],
      "source": [
        "display.display(display.Image(filename=williamsburg_bridge))\n",
        "display.display(display.HTML('<a \"href=https://commons.wikimedia.org/wiki/File:New_East_River_Bridge_from_Brooklyn_det.4a09796u.jpg\">From Wikimedia</a>'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VSOgJSwoN5TQ"
      },
      "source": [
        "### Escritura del archivo TFRecord"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Azx83ryQEU6T"
      },
      "source": [
        "Al igual que antes, codifique las características como tipos compatibles con `tf.train.Example`. De este modo, se almacena la característica de la cadena de la imagen sin procesar y también, la altura, el ancho, la profundidad y las características de la `label` arbitraria. Lo último se usa para escribir el archivo, para distinguir entre la imagen del gato y la del puente. Use `0` para la del gato y `1` para la del puente:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kC4TS1ZEONHr"
      },
      "outputs": [],
      "source": [
        "image_labels = {\n",
        "    cat_in_snow : 0,\n",
        "    williamsburg_bridge : 1,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c5njMSYNEhNZ"
      },
      "outputs": [],
      "source": [
        "# This is an example, just using the cat image.\n",
        "image_string = open(cat_in_snow, 'rb').read()\n",
        "\n",
        "label = image_labels[cat_in_snow]\n",
        "\n",
        "# Create a dictionary with features that may be relevant.\n",
        "def image_example(image_string, label):\n",
        "  image_shape = tf.io.decode_jpeg(image_string).shape\n",
        "\n",
        "  feature = {\n",
        "      'height': _int64_feature(image_shape[0]),\n",
        "      'width': _int64_feature(image_shape[1]),\n",
        "      'depth': _int64_feature(image_shape[2]),\n",
        "      'label': _int64_feature(label),\n",
        "      'image_raw': _bytes_feature(image_string),\n",
        "  }\n",
        "\n",
        "  return tf.train.Example(features=tf.train.Features(feature=feature))\n",
        "\n",
        "for line in str(image_example(image_string, label)).split('\\n')[:15]:\n",
        "  print(line)\n",
        "print('...')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2G_o3O9MN0Qx"
      },
      "source": [
        "Note que todas las características ahora están almacenadas en el mensaje `tf.train.Example`. A continuación, funcionalice el código que figura arriba y escriba los mensajes del ejemplo en un archivo con el nombre `images.tfrecords`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qcw06lQCOCZU"
      },
      "outputs": [],
      "source": [
        "# Write the raw image files to `images.tfrecords`.\n",
        "# First, process the two images into `tf.train.Example` messages.\n",
        "# Then, write to a `.tfrecords` file.\n",
        "record_file = 'images.tfrecords'\n",
        "with tf.io.TFRecordWriter(record_file) as writer:\n",
        "  for filename, label in image_labels.items():\n",
        "    image_string = open(filename, 'rb').read()\n",
        "    tf_example = image_example(image_string, label)\n",
        "    writer.write(tf_example.SerializeToString())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yJrTe6tHPCfs"
      },
      "outputs": [],
      "source": [
        "!du -sh {record_file}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJSsCkZLPH6K"
      },
      "source": [
        "### Lectura del archivo TFRecord\n",
        "\n",
        "Ahora, tiene el archivo `images.tfrecords` y puede iterar sobre los registros que se encuentran en él para volver a leer lo que escribió inicialmente. Dado que en este ejemplo solamente se reproducirá la imagen, la única característica que necesitará será la cadena de la imagen sin procesar. Extráigala con los <em>getters</em> descriptos anteriormente, concretamente con `example.features.feature['image_raw'].bytes_list.value[0]`. También se pueden usar etiquetas para determinar qué registro es el del gato y cuál el del puente:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M6Cnfd3cTKHN"
      },
      "outputs": [],
      "source": [
        "raw_image_dataset = tf.data.TFRecordDataset('images.tfrecords')\n",
        "\n",
        "# Create a dictionary describing the features.\n",
        "image_feature_description = {\n",
        "    'height': tf.io.FixedLenFeature([], tf.int64),\n",
        "    'width': tf.io.FixedLenFeature([], tf.int64),\n",
        "    'depth': tf.io.FixedLenFeature([], tf.int64),\n",
        "    'label': tf.io.FixedLenFeature([], tf.int64),\n",
        "    'image_raw': tf.io.FixedLenFeature([], tf.string),\n",
        "}\n",
        "\n",
        "def _parse_image_function(example_proto):\n",
        "  # Parse the input tf.train.Example proto using the dictionary above.\n",
        "  return tf.io.parse_single_example(example_proto, image_feature_description)\n",
        "\n",
        "parsed_image_dataset = raw_image_dataset.map(_parse_image_function)\n",
        "parsed_image_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0PEEFPk4NEg1"
      },
      "source": [
        "Recupere las imágenes del archivo TFRecord:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yZf8jOyEIjSF"
      },
      "outputs": [],
      "source": [
        "for image_features in parsed_image_dataset:\n",
        "  image_raw = image_features['image_raw'].numpy()\n",
        "  display.display(display.Image(data=image_raw))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "pL--_KGdYoBz"
      ],
      "name": "tfrecord.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
