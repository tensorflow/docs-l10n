{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4HI2mpwlrcn"
      },
      "source": [
        "##### Copyright 2019 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "679Lmwt3l1Bk"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSPCom-KmApV"
      },
      "source": [
        "# Red neuronal convolucional (CNN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "klAltGp8ycek"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td><a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/images/cnn\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver en TensorFlow.org</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/es-419/tutorials/images/cnn.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Ejecutar en Google Colab</a></td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/es-419/tutorials/images/cnn.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver fuente en GitHub</a>\n",
        "</td>\n",
        "  <td><a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/es-419/tutorials/images/cnn.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Descargar el bloc de notas</a></td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLGkt5qiyz4E"
      },
      "source": [
        "En este tutorial se muestra el entrenamiento de una sencilla [Red neuronal convolucional](https://developers.google.com/machine-learning/glossary/#convolutional_neural_network) (CNN) para clasificar [imágenes CIFAR](https://www.cs.toronto.edu/~kriz/cifar.html). Dado que este tutorial utiliza la [API secuencial de Keras](https://www.tensorflow.org/guide/keras/overview), crear y entrenar su modelo le llevará tan solo unas pocas líneas de código.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7KBpffWzlxH"
      },
      "source": [
        "### Importar TensorFlow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iAve6DCL4JH4"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRFxccghyMVo"
      },
      "source": [
        "### Descargue y prepare el conjunto de datos CIFAR10\n",
        "\n",
        "El conjunto de datos CIFAR10 contiene 60,000 imágenes en color en 10 clases, con 6,000 imágenes en cada clase. El conjunto de datos se divide en 50,000 imágenes de entrenamiento y 10,000 imágenes de prueba. Las clases son mutuamente excluyentes y no hay superposición entre ellas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JWoEqyMuXFF4"
      },
      "outputs": [],
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
        "\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wArwCTJJlUa"
      },
      "source": [
        "### Verifique los datos\n",
        "\n",
        "Para verificar que el conjunto de datos parece correcto, vamos a representar las 25 primeras imágenes del conjunto de entrenamiento y a mostrar el nombre de la clase debajo de cada imagen:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K3PAELE2eSU9"
      },
      "outputs": [],
      "source": [
        "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(train_images[i])\n",
        "    # The CIFAR labels happen to be arrays, \n",
        "    # which is why you need the extra index\n",
        "    plt.xlabel(class_names[train_labels[i][0]])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oewp-wYg31t9"
      },
      "source": [
        "### Cree la base convolucional"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hQvqXpNyN3x"
      },
      "source": [
        "Las 6 líneas de código siguientes definen la base convolucional utilizando un patrón común: una pila de capas [Conv2D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D) y [MaxPooling2D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/MaxPool2D).\n",
        "\n",
        "Como entrada, una CNN toma tensores de forma (image_height, image_width, color_channels), ignorando el tamaño del lote. Si no conoce estas dimensiones, color_channels se refiere a (R,G,B). En este ejemplo, configurará su CNN para procesar entradas de forma (32, 32, 3), que es el formato de las imágenes CIFAR. Puede hacerlo pasando el argumento `input_shape` a su primera capa.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L9YmGQBQPrdn"
      },
      "outputs": [],
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvDVFkg-2DPm"
      },
      "source": [
        "Visualicemos la arquitectura de su modelo hasta ahora:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8-C4XBg4UTJy"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_j-AXYeZ2GO5"
      },
      "source": [
        "Arriba, puede ver que la salida de cada capa Conv2D y MaxPooling2D es un tensor 3D de forma (altura, ancho, canales). Las dimensiones de ancho y altura tienden a reducirse conforme se profundiza en la red. El número de canales de salida de cada capa Conv2D se controla mediante el primer argumento (por ejemplo, 32 o 64). Normalmente, cuando el ancho y la altura se encogen, puede permitirse (computacionalmente) agregar más canales de salida en cada capa Conv2D."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_v8sVOtG37bT"
      },
      "source": [
        "### Agregue capas densas en la parte superior\n",
        "\n",
        "Para completar el modelo, introducirá el último tensor de salida de la base convolucional (de forma (4, 4, 64)) en una o varias capas densas para realizar la clasificación. Las capas densas toman vectores como entrada (que son 1D), mientras que la salida actual es un tensor 3D. Primero, aplanará (o desenrollará) la salida 3D a 1D, y después agregará una o más capas Densas en la parte superior. CIFAR tiene 10 clases de salida, por lo que utilizará una capa Densa final con 10 salidas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mRs95d6LUVEi"
      },
      "outputs": [],
      "source": [
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipGiQMcR4Gtq"
      },
      "source": [
        "Esta es la arquitectura completa de su modelo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Yu_m-TZUWGX"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNKXi-Gy3RO-"
      },
      "source": [
        "El resumen de la red muestra que las salidas (4, 4, 64) se aplanaron en vectores de forma (1024) antes de pasar por dos capas densas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3odqfHP4M67"
      },
      "source": [
        "### Compile y entrene el modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MdDzI75PUXrG"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_images, train_labels, epochs=10, \n",
        "                    validation_data=(test_images, test_labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKgyC5K_4O0d"
      },
      "source": [
        "### Evaluación del modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gtyDF0MKUcM7"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0.5, 1])\n",
        "plt.legend(loc='lower right')\n",
        "\n",
        "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0LvwaKhtUdOo"
      },
      "outputs": [],
      "source": [
        "print(test_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cfJ8AR03gT5"
      },
      "source": [
        "Su CNN simple ha logrado una precisión en las pruebas de más del 70%. ¡No está mal para unas pocas líneas de código! Para otro estilo de CNN, eche un vistazo al ejemplo [TensorFlow 2 quickstart para expertos](https://www.tensorflow.org/tutorials/quickstart/advanced) que utiliza la API de subclases de Keras y `tf.GradientTape`."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "cnn.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
