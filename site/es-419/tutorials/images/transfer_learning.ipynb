{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77gENRVX40S7"
      },
      "source": [
        "##### Copyright 2019 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "d8jyt37T42Vf"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "aPxHdjwW5P2j"
      },
      "outputs": [],
      "source": [
        "#@title MIT License\n",
        "#\n",
        "# Copyright (c) 2017 François Chollet                                                                                                                    # IGNORE_COPYRIGHT: cleared by OSS licensing\n",
        "#\n",
        "# Permission is hereby granted, free of charge, to any person obtaining a\n",
        "# copy of this software and associated documentation files (the \"Software\"),\n",
        "# to deal in the Software without restriction, including without limitation\n",
        "# the rights to use, copy, modify, merge, publish, distribute, sublicense,\n",
        "# and/or sell copies of the Software, and to permit persons to whom the\n",
        "# Software is furnished to do so, subject to the following conditions:\n",
        "#\n",
        "# The above copyright notice and this permission notice shall be included in\n",
        "# all copies or substantial portions of the Software.\n",
        "#\n",
        "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n",
        "# THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n",
        "# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n",
        "# DEALINGS IN THE SOFTWARE."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRTa3Ee15WsJ"
      },
      "source": [
        "# Aprendizaje por transferencia y la puesta a punto"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQHMcypT3vDT"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td><a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/images/transfer_learning\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver en TensorFlow.org</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/es-419/tutorials/images/transfer_learning.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Ejecutar en Google Colab</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/es-419/tutorials/images/transfer_learning.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver fuente en GitHub</a></td>\n",
        "  <td><a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/es-419/tutorials/images/transfer_learning.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Descargar el bloc de notas</a></td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2X4KyhORdSeO"
      },
      "source": [
        "En este tutorial aprenderá a clasificar imágenes de perros y gatos usando el aprendizaje por transferencia a partir de una red preentrenada.\n",
        "\n",
        "Un modelo preentrenado es una red guardada que se ha entrenado previamente en un gran conjunto de datos, normalmente en una tarea de clasificación de imágenes a gran escala. Puede usar el modelo preentrenado tal cual o utilizar el aprendizaje por transferencia para adaptar este modelo a una tarea determinada.\n",
        "\n",
        "La intuición que hay detrás del aprendizaje por transferencia para la clasificación de imágenes es que si se entrena un modelo en un conjunto de datos lo suficientemente grande y general, este modelo servirá efectivamente como modelo genérico del mundo visual. Entonces, se pueden aprovechar estos mapas de características aprendidas sin tener que empezar de cero a entrenar un modelo amplio en un gran conjunto de datos.\n",
        "\n",
        "En este bloc de notas, probará dos formas de personalizar un modelo preentrenado:\n",
        "\n",
        "1. Extracción de características: Use las representaciones aprendidas por una red anterior para extraer características significativas de las nuevas muestras. Basta con añadir un nuevo clasificador, que se entrenará desde cero, sobre el modelo preentrenado para poder reutilizar los mapas de características aprendidas previamente para el conjunto de datos.\n",
        "\n",
        "No es necesario (re)entrenar todo el modelo. La red convolucional base ya contiene características que son genéricamente útiles para clasificar imágenes. Sin embargo, la parte final de clasificación del modelo preentrenado es específica de la tarea de clasificación original y, posteriormente, específica del conjunto de clases sobre las que se estableció el modelo.\n",
        "\n",
        "1. Ajuste fino: Desbloquee algunas de las capas superiores de un modelo base inmovilizado y entrene conjuntamente tanto las capas clasificadoras recién añadidas como las últimas capas del modelo base. Esto nos permite \"afinar\" las representaciones de características de más alto orden en el modelo base para hacerlas más relevantes en la tarea específica.\n",
        "\n",
        "Seguirá el flujo de trabajo general del aprendizaje automático.\n",
        "\n",
        "1. Examinar y comprender los datos\n",
        "2. Construir una canalización de entrada, en este caso usando el ImageDataGenerator de Keras.\n",
        "3. Armar el modelo\n",
        "    - Cargar el modelo base preentrenado (y las ponderaciones preentrenadas)\n",
        "    - Acumular las capas de clasificación en la parte superior\n",
        "4. Entrenar el modelo\n",
        "5. Evaluar el modelo\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TqOt6Sv7AsMi"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v77rlkCKW0IJ"
      },
      "source": [
        "## Preprocesamiento de los datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GoKGm1duzgk"
      },
      "source": [
        "### Descarga de datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHP9qMJxt2oz"
      },
      "source": [
        "En este tutorial, usará un conjunto de datos compuesto por varios miles de imágenes de gatos y perros. Descargue y extraiga un archivo zip que contiene las imágenes y, a continuación, cree un `tf.data.Dataset` para el entrenamiento y la validación mediante la utilidad `tf.keras.utils.image_dataset_from_directory`. Si desea obtener más información sobre la carga de imágenes, consulte este [tutorial](https://www.tensorflow.org/tutorials/load_data/images)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ro4oYaEmxe4r"
      },
      "outputs": [],
      "source": [
        "_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
        "path_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)\n",
        "PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')\n",
        "\n",
        "train_dir = os.path.join(PATH, 'train')\n",
        "validation_dir = os.path.join(PATH, 'validation')\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "IMG_SIZE = (160, 160)\n",
        "\n",
        "train_dataset = tf.keras.utils.image_dataset_from_directory(train_dir,\n",
        "                                                            shuffle=True,\n",
        "                                                            batch_size=BATCH_SIZE,\n",
        "                                                            image_size=IMG_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cAvtLwi7_J__"
      },
      "outputs": [],
      "source": [
        "validation_dataset = tf.keras.utils.image_dataset_from_directory(validation_dir,\n",
        "                                                                 shuffle=True,\n",
        "                                                                 batch_size=BATCH_SIZE,\n",
        "                                                                 image_size=IMG_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yO1Q2JaW5sIy"
      },
      "source": [
        "Muestre las nueve primeras imágenes y etiquetas del conjunto de entrenamiento:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K5BeQyKThC_Y"
      },
      "outputs": [],
      "source": [
        "class_names = train_dataset.class_names\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in train_dataset.take(1):\n",
        "  for i in range(9):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "    plt.title(class_names[labels[i]])\n",
        "    plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZqCX_mpV3Mx"
      },
      "source": [
        "Como el conjunto de datos original no incluye un conjunto de prueba, deberá crear uno. Para ello, determine cuántos lotes de datos están disponibles en el conjunto de validación utilizando `tf.data.experimental.cardinality` y, a continuación, traslade el 20 % de ellos a un conjunto de prueba."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uFFIYrTFV9RO"
      },
      "outputs": [],
      "source": [
        "val_batches = tf.data.experimental.cardinality(validation_dataset)\n",
        "test_dataset = validation_dataset.take(val_batches // 5)\n",
        "validation_dataset = validation_dataset.skip(val_batches // 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q9pFlFWgBKgH"
      },
      "outputs": [],
      "source": [
        "print('Number of validation batches: %d' % tf.data.experimental.cardinality(validation_dataset))\n",
        "print('Number of test batches: %d' % tf.data.experimental.cardinality(test_dataset))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MakSrdd--RKg"
      },
      "source": [
        "### Configurar el conjunto de datos para rendimiento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22XWC7yjkZu4"
      },
      "source": [
        "Use la preextracción en búfer para cargar imágenes desde el disco sin que la E/S se bloquee. Si desea más información sobre este método, consulte la guía [rendimiento de datos](https://www.tensorflow.org/guide/data_performance)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p3UUPdm86LNC"
      },
      "outputs": [],
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
        "validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)\n",
        "test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYfcVwYLiR98"
      },
      "source": [
        "### Usar aumentación de datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDWc5Oad1daX"
      },
      "source": [
        "Cuando no se dispone de un gran conjunto de datos de imágenes, es una buena práctica introducir artificialmente la diversidad del muestreo aplicando transformaciones aleatorias, aunque realistas, a las imágenes de entrenamiento, como la rotación y el volteado horizontal. Esto ayuda a exponer el modelo a diferentes aspectos de los datos de entrenamiento y a reducir el [sobreajuste](https://www.tensorflow.org/tutorials/keras/overfit_and_underfit). Si desea obtener más información sobre la aumentación de datos, consulte este [tutorial](https://www.tensorflow.org/tutorials/images/data_augmentation)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3P99QiMGit1A"
      },
      "outputs": [],
      "source": [
        "data_augmentation = tf.keras.Sequential([\n",
        "  tf.keras.layers.RandomFlip('horizontal'),\n",
        "  tf.keras.layers.RandomRotation(0.2),\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9SlcbhrarOO"
      },
      "source": [
        "Nota: Estas capas sólo están activas durante el entrenamiento, cuando se llama a `Model.fit`. Están inactivas cuando se usa el modelo en modo de inferencia en `Model.evaluate`, `Model.predict`, o `Model.call`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mD3rE2Lm7-d"
      },
      "source": [
        "Apliquemos repetidamente estas capas a la misma imagen y veamos el resultado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aQullOUHkm67"
      },
      "outputs": [],
      "source": [
        "for image, _ in train_dataset.take(1):\n",
        "  plt.figure(figsize=(10, 10))\n",
        "  first_image = image[0]\n",
        "  for i in range(9):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    augmented_image = data_augmentation(tf.expand_dims(first_image, 0))\n",
        "    plt.imshow(augmented_image[0] / 255)\n",
        "    plt.axis('off')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAywKtuVn8uK"
      },
      "source": [
        "### Reescalar valores de pixel\n",
        "\n",
        "En un momento, descargará `tf.keras.applications.MobileNetV2` para usarlo como modelo base. Este modelo espera valores de píxel en `[-1, 1]`, pero en este momento, los valores de píxel de sus imágenes están en `[0, 255]`. Para reescalarlos, use el método de preprocesamiento incluido con el modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cO0HM9JAQUFq"
      },
      "outputs": [],
      "source": [
        "preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnr81qRMzcs5"
      },
      "source": [
        "Nota: Como alternativa, podría reescalar los valores de los píxeles de `[0, 255]` a `[-1, 1]` usando `tf.keras.layers.Rescaling`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R2NyJn4KQMux"
      },
      "outputs": [],
      "source": [
        "rescale = tf.keras.layers.Rescaling(1./127.5, offset=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wz7qgImhTxw4"
      },
      "source": [
        "Nota: Si utiliza otras `tf.keras.applications`, asegúrese de consultar la documentación de la API para determinar si esperan pixeles en `[-1, 1]` o `[0, 1]`, o use la función incluida `preprocess_input`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkH-kazQecHB"
      },
      "source": [
        "## Crear el modelo base a partir de las redes convolucionales preentrenadas\n",
        "\n",
        "Creará el modelo base a partir del modelo **MobileNet V2** desarrollado en Google. Éste está preentrenado en el conjunto de datos ImageNet, un gran conjunto de datos compuesto por 1.4M de imágenes y 1000 clases. ImageNet es un conjunto de datos de entrenamiento para la investigación con una gran variedad de categorías como `jackfruit` y `syringe`. Esta base de conocimientos nos ayudará a clasificar perros y gatos a partir de nuestro conjunto de datos específico.\n",
        "\n",
        "En primer lugar, tiene que elegir qué capa de MobileNet V2 va a usar para la extracción de características. La última capa de clasificación (en la \"parte superior\", ya que la mayoría de los diagramas de modelos de aprendizaje automático van de abajo a arriba) no es muy útil. En su lugar, seguirá la práctica común de depender de la última capa antes de la operación de aplanamiento. Esta capa se denomina \"capa cuello de botella\". Las características de la capa cuello de botella conservan más generalidad comparadas con las de la capa final/superior.\n",
        "\n",
        "En primer lugar, instancie un modelo MobileNet V2 precargado con ponderaciones entrenadas en ImageNet. Al especificar el argumento **include_top=False**, se carga una red que no incluye las capas de clasificación en la parte superior, lo que resulta ideal para la extracción de características."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "19IQ2gqneqmS"
      },
      "outputs": [],
      "source": [
        "# Create the base model from the pre-trained model MobileNet V2\n",
        "IMG_SHAPE = IMG_SIZE + (3,)\n",
        "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
        "                                               include_top=False,\n",
        "                                               weights='imagenet')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AqcsxoJIEVXZ"
      },
      "source": [
        "Este extractor de características convierte cada imagen `160x160x3` en un bloque `5x5x1280` de características. Veamos lo que hace con un lote de imágenes de ejemplo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y-2LJL0EEUcx"
      },
      "outputs": [],
      "source": [
        "image_batch, label_batch = next(iter(train_dataset))\n",
        "feature_batch = base_model(image_batch)\n",
        "print(feature_batch.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlx56nQtfe8Y"
      },
      "source": [
        "## Extracción de características\n",
        "\n",
        "En este paso, congelará la base convolucional creada en el paso anterior y la usará como extractor de características. Además, añadirá un clasificador sobre ella y entrenará al clasificador de nivel superior."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnMLieHBCwil"
      },
      "source": [
        "### Congelar la base convolucional"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fL6upiN3ekS"
      },
      "source": [
        "Es importante congelar la base convolucional antes de compilar y entrenar el modelo. La congelación (al configurar layer.trainable = False) impide que las ponderaciones de una capa determinada se actualicen durante el entrenamiento. MobileNet V2 tiene muchas capas, por lo que si configura el indicador `trainable` de todo el modelo en False, se congelarán todas ellas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OTCJH4bphOeo"
      },
      "outputs": [],
      "source": [
        "base_model.trainable = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsNHwpm7BeVM"
      },
      "source": [
        "### Nota importante sobre las capas BatchNormalization\n",
        "\n",
        "Muchos modelos contienen capas `tf.keras.layers.BatchNormalization`. Esta capa es un caso especial y deben tomarse precauciones en el contexto del ajuste fino, como se muestra más adelante en este tutorial.\n",
        "\n",
        "Si configura `layer.trainable = False`, la capa `BatchNormalization` se ejecutará en modo de inferencia y no actualizará sus estadísticas de media y varianza.\n",
        "\n",
        "Cuando descongele un modelo que contenga capas BatchNormalization para realizar un ajuste fino, deberá mantener las capas BatchNormalization en modo de inferencia pasando `training = False` al llamar al modelo base. De lo contrario, las actualizaciones aplicadas a las ponderaciones no entrenables destruirán lo que el modelo ha aprendido.\n",
        "\n",
        "Para más detalles, consulte la [Guía de aprendizaje por transferencia](https://www.tensorflow.org/guide/keras/transfer_learning)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KpbzSmPkDa-N"
      },
      "outputs": [],
      "source": [
        "# Let's take a look at the base model architecture\n",
        "base_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdMRM8YModbk"
      },
      "source": [
        "### Añadir una cabecera de clasificación"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBc31c4tMOdH"
      },
      "source": [
        "Para generar predicciones a partir del bloque de características, realice un promedio sobre las ubicaciones espaciales `5x5`, usando una capa `tf.keras.layers.GlobalAveragePooling2D` para convertir las características en un único vector de 1280 elementos por imagen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dLnpMF5KOALm"
      },
      "outputs": [],
      "source": [
        "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
        "feature_batch_average = global_average_layer(feature_batch)\n",
        "print(feature_batch_average.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1p0OJBR6dOT"
      },
      "source": [
        "Aplique una capa `tf.keras.layers.Dense` para convertir estas características en una única predicción por imagen. No necesita una función de activación aquí porque esta predicción se tratará como un `logit`, o un valor de predicción en bruto. Los números positivos predicen la clase 1, los números negativos predicen la clase 0."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wv4afXKj6cVa"
      },
      "outputs": [],
      "source": [
        "prediction_layer = tf.keras.layers.Dense(1)\n",
        "prediction_batch = prediction_layer(feature_batch_average)\n",
        "print(prediction_batch.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXvz-ZkTa9b3"
      },
      "source": [
        "Construya un modelo encadenando las capas de aumento de datos, reescalado, `base_model` y extractor de características usando la [API Functional de Keras](https://www.tensorflow.org/guide/keras/functional). Como se mencionó anteriormente, use `training=False` ya que nuestro modelo contiene una capa `BatchNormalization`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DgzQX6Veb2WT"
      },
      "outputs": [],
      "source": [
        "inputs = tf.keras.Input(shape=(160, 160, 3))\n",
        "x = data_augmentation(inputs)\n",
        "x = preprocess_input(x)\n",
        "x = base_model(x, training=False)\n",
        "x = global_average_layer(x)\n",
        "x = tf.keras.layers.Dropout(0.2)(x)\n",
        "outputs = prediction_layer(x)\n",
        "model = tf.keras.Model(inputs, outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I8ARiyMFsgbH"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxOcmVr0ydFZ"
      },
      "source": [
        "Los más de 8 millones de parámetros de MobileNet están congelados, pero hay 1.2 mil parámetros *entrenables* en la capa Dense. Éstos se dividen entre dos objetos `tf.Variable`, las ponderaciones y los sesgos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "krvBumovycVA"
      },
      "outputs": [],
      "source": [
        "len(model.trainable_variables)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jeGk93R2ahav"
      },
      "outputs": [],
      "source": [
        "tf.keras.utils.plot_model(model, show_shapes=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0ylJXE_kRLi"
      },
      "source": [
        "### Compilar el modelo\n",
        "\n",
        "Compile el modelo antes de entrenarlo. Como hay dos clases, use la pérdida `tf.keras.losses.BinaryCrossentropy` con `from_logits=True` ya que el modelo proporciona una salida lineal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RpR8HdyMhukJ"
      },
      "outputs": [],
      "source": [
        "base_learning_rate = 0.0001\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate),\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              metrics=[tf.keras.metrics.BinaryAccuracy(threshold=0, name='accuracy')])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RxvgOYTDSWTx"
      },
      "source": [
        "### Entrenar el modelo\n",
        "\n",
        "Tras un entrenamiento de 10 épocas, debería obtener una precisión del 96 % en el conjunto de validación.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Om4O3EESkab1"
      },
      "outputs": [],
      "source": [
        "initial_epochs = 10\n",
        "\n",
        "loss0, accuracy0 = model.evaluate(validation_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8cYT1c48CuSd"
      },
      "outputs": [],
      "source": [
        "print(\"initial loss: {:.2f}\".format(loss0))\n",
        "print(\"initial accuracy: {:.2f}\".format(accuracy0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JsaRFlZ9B6WK"
      },
      "outputs": [],
      "source": [
        "history = model.fit(train_dataset,\n",
        "                    epochs=initial_epochs,\n",
        "                    validation_data=validation_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hd94CKImf8vi"
      },
      "source": [
        "### Curvas de aprendizaje\n",
        "\n",
        "Analicemos las curvas de aprendizaje de la precisión/pérdida en el entrenamiento y la validación al usar el modelo base MobileNetV2 como extractor de características fijas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "53OTCh3jnbwV"
      },
      "outputs": [],
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([min(plt.ylim()),1])\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('Cross Entropy')\n",
        "plt.ylim([0,1.0])\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "foWMyyUHbc1j"
      },
      "source": [
        "Nota: Si se pregunta por qué las métricas de validación son claramente mejores que las de entrenamiento, el factor principal se debe a que capas como `tf.keras.layers.BatchNormalization` y `tf.keras.layers.Dropout` afectan a la precisión durante el entrenamiento. Se desactivan cuando se calcula la pérdida de validación.\n",
        "\n",
        "En menor medida, también se debe a que las métricas de entrenamiento informan de la media de una época, mientras que las métricas de validación se evalúan después de la época, por lo que las métricas de validación ven un modelo que ha entrenado ligeramente más tiempo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CqwV-CRdS6Nv"
      },
      "source": [
        "## Afinado\n",
        "\n",
        "En el experimento de extracción de características, sólo se entrenaron unas pocas capas sobre un modelo base MobileNetV2. Las ponderaciones de la red preentrenada no se **actualizaron** durante el entrenamiento.\n",
        "\n",
        "Una forma de aumentar aún más el rendimiento es entrenar (o \"afinar\") las ponderaciones de las capas superiores del modelo preentrenado junto con el entrenamiento del clasificador que ha añadido. El proceso de entrenamiento forzará el afinado de las ponderaciones a partir de mapas de características genéricas a características asociadas específicamente con el conjunto de datos.\n",
        "\n",
        "Nota: Esto sólo debe intentarse después de haber entrenado el clasificador de nivel superior con el modelo preentrenado configurado como no entrenable. Si añade un clasificador inicializado aleatoriamente sobre un modelo preentrenado e intenta entrenar todas las capas conjuntamente, la magnitud de las actualizaciones del gradiente será demasiado grande (debido a las ponderaciones aleatorias del clasificador) y su modelo preentrenado olvidará lo que ha aprendido.\n",
        "\n",
        "Además, debería intentar afinar un pequeño número de capas superiores en lugar de todo el modelo MobileNet. En la mayoría de las redes convolucionales, cuanto más alta es una capa, más especializada está. Las primeras capas aprenden características muy simples y genéricas que se generalizan a casi todos los tipos de imágenes. A medida que se asciende, las características son cada vez más específicas del conjunto de datos sobre el que se ha entrenado el modelo. La meta de la afinación es adaptar estas características especializadas para que funcionen con el nuevo conjunto de datos, en lugar de sobrescribir el aprendizaje genérico."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPXnzUK0QonF"
      },
      "source": [
        "### Descongelar las capas superiores del modelo\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfxv_ifotQak"
      },
      "source": [
        "Todo lo que tiene que hacer es descongelar el `base_model` y configurar que las capas inferiores no se puedan entrenar. Luego, deberá recompilar el modelo (necesario para que estos cambios surtan efecto), y reanudar el entrenamiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4nzcagVitLQm"
      },
      "outputs": [],
      "source": [
        "base_model.trainable = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-4HgVAacRs5v"
      },
      "outputs": [],
      "source": [
        "# Let's take a look to see how many layers are in the base model\n",
        "print(\"Number of layers in the base model: \", len(base_model.layers))\n",
        "\n",
        "# Fine-tune from this layer onwards\n",
        "fine_tune_at = 100\n",
        "\n",
        "# Freeze all the layers before the `fine_tune_at` layer\n",
        "for layer in base_model.layers[:fine_tune_at]:\n",
        "  layer.trainable = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Uk1dgsxT0IS"
      },
      "source": [
        "### Compilar el modelo\n",
        "\n",
        "Como está entrenando un modelo mucho más grande y quiere readaptar las ponderaciones preentrenadas, es importante usar una tasa de aprendizaje más baja en esta fase. De lo contrario, su modelo podría sobreajustarse muy rápidamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NtUnaz0WUDva"
      },
      "outputs": [],
      "source": [
        "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer = tf.keras.optimizers.RMSprop(learning_rate=base_learning_rate/10),\n",
        "              metrics=[tf.keras.metrics.BinaryAccuracy(threshold=0, name='accuracy')])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WwBWy7J2kZvA"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bNXelbMQtonr"
      },
      "outputs": [],
      "source": [
        "len(model.trainable_variables)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4G5O4jd6TuAG"
      },
      "source": [
        "### Continuar entrenando el modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0foWUN-yDLo_"
      },
      "source": [
        "Si se ha entrenado antes hasta la convergencia, este paso mejorará su precisión en algunos puntos porcentuales."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ECQLkAsFTlun"
      },
      "outputs": [],
      "source": [
        "fine_tune_epochs = 10\n",
        "total_epochs =  initial_epochs + fine_tune_epochs\n",
        "\n",
        "history_fine = model.fit(train_dataset,\n",
        "                         epochs=total_epochs,\n",
        "                         initial_epoch=history.epoch[-1],\n",
        "                         validation_data=validation_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfXEmsxQf6eP"
      },
      "source": [
        "Echemos un vistazo a las curvas de aprendizaje de la precisión/pérdida de entrenamiento y validación al ajustar las últimas capas del modelo base MobileNetV2 y entrenar el clasificador sobre él. La pérdida de validación es mucho mayor que la pérdida de entrenamiento, por lo que es posible que se produzca un sobreajuste.\n",
        "\n",
        "También es posible que se produzca cierto sobreajuste, ya que el nuevo conjunto de entrenamiento es relativamente pequeño y similar a los conjuntos de datos originales de MobileNetV2.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNtfNZKlInGT"
      },
      "source": [
        "Tras el afinamiento, el modelo alcanza casi un 98 % de precisión en el conjunto de validación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PpA8PlpQKygw"
      },
      "outputs": [],
      "source": [
        "acc += history_fine.history['accuracy']\n",
        "val_acc += history_fine.history['val_accuracy']\n",
        "\n",
        "loss += history_fine.history['loss']\n",
        "val_loss += history_fine.history['val_loss']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "chW103JUItdk"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.ylim([0.8, 1])\n",
        "plt.plot([initial_epochs-1,initial_epochs-1],\n",
        "          plt.ylim(), label='Start Fine Tuning')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.ylim([0, 1.0])\n",
        "plt.plot([initial_epochs-1,initial_epochs-1],\n",
        "         plt.ylim(), label='Start Fine Tuning')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6cWgjgfrsn5"
      },
      "source": [
        "### Evaluación y predicción"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSXH7PRMxOi5"
      },
      "source": [
        "Por último, puede verificar el rendimiento del modelo en los nuevos datos usando el conjunto de pruebas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2KyNhagHwfar"
      },
      "outputs": [],
      "source": [
        "loss, accuracy = model.evaluate(test_dataset)\n",
        "print('Test accuracy :', accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UjS5ukZfOcR"
      },
      "source": [
        "Y ahora ya está todo configurado para usar este modelo para predecir si su mascota es un gato o un perro."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RUNoQNgtfNgt"
      },
      "outputs": [],
      "source": [
        "# Retrieve a batch of images from the test set\n",
        "image_batch, label_batch = test_dataset.as_numpy_iterator().next()\n",
        "predictions = model.predict_on_batch(image_batch).flatten()\n",
        "\n",
        "# Apply a sigmoid since our model returns logits\n",
        "predictions = tf.nn.sigmoid(predictions)\n",
        "predictions = tf.where(predictions < 0.5, 0, 1)\n",
        "\n",
        "print('Predictions:\\n', predictions.numpy())\n",
        "print('Labels:\\n', label_batch)\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(9):\n",
        "  ax = plt.subplot(3, 3, i + 1)\n",
        "  plt.imshow(image_batch[i].astype(\"uint8\"))\n",
        "  plt.title(class_names[predictions[i]])\n",
        "  plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TZTwG7nhm0C"
      },
      "source": [
        "## Resumen\n",
        "\n",
        "- **Usar un modelo preentrenado para la extracción de características**: Cuando se trabaja con un conjunto de datos pequeño, es una práctica común aprovechar las características aprendidas por un modelo entrenado en un conjunto de datos más grande en el mismo dominio. Esto se hace instanciando el modelo preentrenado y añadiendo encima un clasificador totalmente conectado. El modelo preentrenado se \"congela\" y sólo se actualizan las ponderaciones del clasificador durante el entrenamiento. En este caso, la base convolucional extrajo todas las características asociadas a cada imagen y usted acaba de entrenar un clasificador que determina la clase de imagen dado ese conjunto de características extraídas.\n",
        "\n",
        "- **{nbsp}Afinando un modelo preentrenado**: Para mejorar aún más el rendimiento, quizá quiera adaptar las capas superiores de los modelos preentrenados al nuevo conjunto de datos afinando el ajuste. En este caso, ajustó las ponderaciones de forma que su modelo aprendiera características de alto nivel específicas del conjunto de datos. Esta técnica suele recomendarse cuando el conjunto de datos de entrenamiento es grande y muy similar al conjunto de datos original en el que se entrenó el modelo preentrenado.\n",
        "\n",
        "Para saber más, visite la [Guía de aprendizaje por transferencia](https://www.tensorflow.org/guide/keras/transfer_learning).\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "transfer_learning.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
