{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tce3stUlHN0L"
      },
      "source": [
        "##### Copyright 2019 The TensorFlow Authors.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tuOe1ymfHZPu"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfBg1C5NB3X0"
      },
      "source": [
        "# Entrenamiento distribuido con DTensors\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6P32iYYV27b"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td><a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/distribute/dtensor_ml_tutorial\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver en TensorFlow.org</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/es-419/tutorials/distribute/dtensor_ml_tutorial.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Ejecutar en Google Colab</a></td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/es-419/tutorials/distribute/dtensor_ml_tutorial.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver fuente en GitHub</a> </td>\n",
        "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/es-419/tutorials/distribute/dtensor_ml_tutorial.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Descargar cuaderno</a> </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kiF4jjX4O1mF"
      },
      "source": [
        "## Visión general\n",
        "\n",
        "DTensor ofrece una forma de distribuir el entrenamiento de su modelo entre dispositivos para mejorar la eficacia, la fiabilidad y la escalabilidad. Si desea más detalles sobre los conceptos de DTensor, consulte [La Guía de Programación de DTensor](https://www.tensorflow.org/guide/dtensor_overview).\n",
        "\n",
        "En este tutorial, entrenará un modelo de Análisis de Opinión con DTensor. Con este ejemplo se demuestran tres esquemas de entrenamiento distribuido:\n",
        "\n",
        "- Entrenamiento paralelo de datos, en el que las muestras de entrenamiento se fragmentan (particionan) en dispositivos.\n",
        "- Entrenamiento paralelo del modelo, en el que las variables del modelo se fragmentan entre los dispositivos.\n",
        "- Entrenamiento paralelo espacial, en el que las características de los datos de entrada se fragmentan en dispositivos (también conocido como [Particionamiento espacial](https://cloud.google.com/blog/products/ai-machine-learning/train-ml-models-on-large-images-and-3d-volumes-with-spatial-partitioning-on-cloud-tpus)).\n",
        "\n",
        "La parte de entrenamiento de este tutorial está inspirada en el bloc de notas [Una guía Kaggle sobre Análisis de Opinión](https://www.kaggle.com/code/anasofiauzsoy/yelp-review-sentiment-analysis-tensorflow-tfds/notebook). Para conocer el flujo de trabajo completo de entrenamiento y evaluación (sin DTensor), consulte dicho bloc.\n",
        "\n",
        "Este tutorial seguirá los siguientes pasos:\n",
        "\n",
        "- Primero empiece con una limpieza de datos para obtener un `tf.data.Dataset` de frases tokenizadas y su polaridad.\n",
        "\n",
        "- Luego construya un modelo MLP con capas personalizadas Dense y BatchNorm. Use un `tf.Module` para hacer un seguimiento de las variables de inferencia. El constructor del modelo toma argumentos adicionales `Layout` para controlar la fragmentación de las variables.\n",
        "\n",
        "- Para el entrenamiento, primero usará el entrenamiento paralelo de datos junto con la función de punto de verificación de `tf.experimental.dtensor`. Después continúe con el Entrenamiento Paralelo del Modelo y el Entrenamiento Paralelo Espacial.\n",
        "\n",
        "- La sección final describe brevemente la interacción entre `tf.saved_model` y `tf.experimental.dtensor` a partir de TensorFlow 2.9.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YD80veeg7QtW"
      },
      "source": [
        "## Preparación\n",
        "\n",
        "DTensor forma parte de la versión 2.9.0 de TensorFlow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-RKXLJN-7Yyb"
      },
      "outputs": [],
      "source": [
        "!pip install --quiet --upgrade --pre tensorflow tensorflow-datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcxP4_Zu7ciQ"
      },
      "source": [
        "A continuación, importe `tensorflow` y `tensorflow.experimental.dtensor`. Luego, configure TensorFlow para que use 8 CPU virtuales.\n",
        "\n",
        "Aunque este ejemplo usa CPUs, DTensor funciona igual en dispositivos con CPU, GPU o TPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dXcB26oP7dUd"
      },
      "outputs": [],
      "source": [
        "import tempfile\n",
        "import numpy as np\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.experimental import dtensor\n",
        "print('TensorFlow version:', tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oHtO6MJLUXlz"
      },
      "outputs": [],
      "source": [
        "def configure_virtual_cpus(ncpu):\n",
        "  phy_devices = tf.config.list_physical_devices('CPU')\n",
        "  tf.config.set_logical_device_configuration(phy_devices[0], [\n",
        "        tf.config.LogicalDeviceConfiguration(),\n",
        "    ] * ncpu)\n",
        "\n",
        "configure_virtual_cpus(8)\n",
        "DEVICES = [f'CPU:{i}' for i in range(8)]\n",
        "\n",
        "tf.config.list_logical_devices('CPU')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omYd4jbF7j_I"
      },
      "source": [
        "## Descargar el conjunto de datos\n",
        "\n",
        "Descargue el conjunto de datos de críticas de IMDB para entrenar el modelo de análisis de sentimientos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fW4w4QlFVHhx"
      },
      "outputs": [],
      "source": [
        "train_data = tfds.load('imdb_reviews', split='train', shuffle_files=True, batch_size=64)\n",
        "train_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ki3mpfi4aZH8"
      },
      "source": [
        "## Preparar los datos\n",
        "\n",
        "Primero tokenize el texto. Aquí se usa una extensión de la codificación en un solo paso, el modo `'tf_idf'` de `tf.keras.layers.TextVectorization`.\n",
        "\n",
        "- Para mayor rapidez, limite el número de tokens a 1200.\n",
        "- Para conservar la sencillez de `tf.Module`, ejecute `TextVectorization` como paso de preprocesamiento antes del entrenamiento.\n",
        "\n",
        "El resultado final de la sección de limpieza de datos es un `Dataset` con el texto tokenizado como `x` y la etiqueta como `y`.\n",
        "\n",
        "**Nota**: Ejecutar `TextVectorization` como paso de preprocesamiento **no es una práctica habitual ni recomendable**, ya que hacerlo supone que los datos de entrenamiento caben en la memoria del cliente, lo que no siempre es así.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zNpxjku_57Lg"
      },
      "outputs": [],
      "source": [
        "text_vectorization = tf.keras.layers.TextVectorization(output_mode='tf_idf', max_tokens=1200, output_sequence_length=None)\n",
        "text_vectorization.adapt(data=train_data.map(lambda x: x['text']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q16bjngoVwQp"
      },
      "outputs": [],
      "source": [
        "def vectorize(features):\n",
        "  return text_vectorization(features['text']), features['label']\n",
        "\n",
        "train_data_vec = train_data.map(vectorize)\n",
        "train_data_vec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atTqL9kE5wz4"
      },
      "source": [
        "## Cree una red neuronal con DTensor\n",
        "\n",
        "A continuación, construya una red Perceptrón Multicapa (MLP) con `DTensor`. La red usará capas Dense y BatchNorm totalmente conectadas.\n",
        "\n",
        "`DTensor` expande TensorFlow utilizando la expansión multidatos de un solo programa (SPMD) de las operaciones regulares de TensorFlow según los atributos `dtensor.Layout` de sus `Tensor` y variables de entrada.\n",
        "\n",
        "Las variables de las capas sensibles al `DTensor` son `dtensor.DVariable`, y los constructores de los objetos de capa sensibles al `DTensor` toman entradas adicionales `Layout` además de los parámetros habituales de las capas.\n",
        "\n",
        "Nota: A partir de TensorFlow 2.9, las capas Keras como `tf.keras.layer.Dense`, y `tf.keras.layer.BatchNormalization` aceptan argumentos `dtensor.Layout`. Consulte el [Tutorial de Integración de DTensor en Keras](/tutorials/distribute/dtensor_keras_tutorial) para saber más sobre cómo usar Keras con DTensor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMCt-Gj3b3Jy"
      },
      "source": [
        "### Capa Dense\n",
        "\n",
        "La siguiente capa Dense personalizada define 2 variables de capa: $W_{ij}$ es la variable de las ponderaciones, y $b_i$ es la variable de los sesgos.\n",
        "\n",
        "$$ y_j = \\sigma(\\sum_i x_i W_{ij} + b_j) $$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYlFUJWNjl4N"
      },
      "source": [
        "### Deducción de Layout\n",
        "\n",
        "Este resultado surge de las siguientes observaciones:\n",
        "\n",
        "- La fragmentación DTensor preferida para los operandos de una matriz producto punto $t_j = \\sum_i x_i W_{ij}$ es fragmentar $\\mathbf{W}$ y $\\mathbf{x}$ de la misma forma a lo largo del eje $i$.\n",
        "\n",
        "- La fragmentación DTensor preferida para los operandos de una suma de matrices $t_j + b_j$, es fragmentar $\\mathbf{t}$ y $\\mathbf{b}$ de la misma manera a lo largo del eje $j$.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VpKblz7Yb16G"
      },
      "outputs": [],
      "source": [
        "class Dense(tf.Module):\n",
        "\n",
        "  def __init__(self, input_size, output_size,\n",
        "               init_seed, weight_layout, activation=None):\n",
        "    super().__init__()\n",
        "\n",
        "    random_normal_initializer = tf.function(tf.random.stateless_normal)\n",
        "\n",
        "    self.weight = dtensor.DVariable(\n",
        "        dtensor.call_with_layout(\n",
        "            random_normal_initializer, weight_layout,\n",
        "            shape=[input_size, output_size],\n",
        "            seed=init_seed\n",
        "            ))\n",
        "    if activation is None:\n",
        "      activation = lambda x:x\n",
        "    self.activation = activation\n",
        "    \n",
        "    # bias is sharded the same way as the last axis of weight.\n",
        "    bias_layout = weight_layout.delete([0])\n",
        "\n",
        "    self.bias = dtensor.DVariable(\n",
        "        dtensor.call_with_layout(tf.zeros, bias_layout, [output_size]))\n",
        "\n",
        "  def __call__(self, x):\n",
        "    y = tf.matmul(x, self.weight) + self.bias\n",
        "    y = self.activation(y)\n",
        "\n",
        "    return y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfVY_vAKbxM0"
      },
      "source": [
        "### BatchNorm\n",
        "\n",
        "Una capa de normalización por lotes ayuda a evitar el colapso de los modos mientas se entrena. En este caso, añadir capas de normalización por lotes ayuda a que el entrenamiento del modelo evite producir un modelo que sólo produzca ceros.\n",
        "\n",
        "El constructor de la capa personalizada `BatchNorm` de abajo no toma un argumento `Layout`. Esto se debe a que `BatchNorm` no tiene variables de capa. Esto sigue funcionando con DTensor porque \"x\", la única entrada de la capa, ya es un DTensor que representa el lote global.\n",
        "\n",
        "Nota: Con DTensor, el Tensor de entrada \"x\" siempre representa el lote global. Por lo tanto, `tf.nn.batch_normalization` se aplica al lote global. Esto es distinto del entrenamiento con `tf.distribute.MirroredStrategy`, en el que el Tensor 'x' sólo representa el fragmento por réplica del lote (el lote local)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "riBA9pfhlPFq"
      },
      "outputs": [],
      "source": [
        "class BatchNorm(tf.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "  def __call__(self, x, training=True):\n",
        "    if not training:\n",
        "      # This branch is not used in the Tutorial.\n",
        "      pass\n",
        "    mean, variance = tf.nn.moments(x, axes=[0])\n",
        "    return tf.nn.batch_normalization(x, mean, variance, 0.0, 1.0, 1e-5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4R4MPz5prh4"
      },
      "source": [
        "Una capa de normalización por lotes completa (como `tf.keras.layers.BatchNormalization`) necesitará argumentos Layout para sus variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "unFcP99zprJj"
      },
      "outputs": [],
      "source": [
        "def make_keras_bn(bn_layout):\n",
        "  return tf.keras.layers.BatchNormalization(gamma_layout=bn_layout,\n",
        "                                            beta_layout=bn_layout,\n",
        "                                            moving_mean_layout=bn_layout,\n",
        "                                            moving_variance_layout=bn_layout,\n",
        "                                            fused=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8Dj7AJ_lPs0"
      },
      "source": [
        "### Juntando las capas\n",
        "\n",
        "A continuación, construya una red perceptrón multicapa (MLP) con los bloques de construcción anteriores.  El diagrama siguiente muestra las relaciones de ejes entre la entrada `x` y las matrices de ponderación de las dos capas `Dense` sin aplicar ninguna fragmentación ni replicación de DTensores."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udFGAO-NrZw6"
      },
      "source": [
        "<img src=\"https://www.tensorflow.org/images/dtensor/no_dtensor.png\" class=\"no-filter\" alt=\"Las matrices de entrada y ponderación de un modelo no distribuido.\"> \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DCQ0aQ5rQtB"
      },
      "source": [
        "La salida de la primera capa `Dense` se pasa a la entrada de la segunda capa `Dense` (después de la `BatchNorm`). Por lo tanto, la fragmentación DTensor preferida para la salida de la primera capa `Dense` ($\\mathbf{W_1}$) y la entrada de la segunda capa `Dense` ($\\mathbf{W_2}$) es fragmentar $\\mathbf{W_1}$ y $\\mathbf{W_2}$$ del mismo modo a lo largo del eje común $\\hat{j}$,\n",
        "\n",
        "$$ \\mathsf{Layout}[{W_{1,ij}}; i, j] = \\left[\\hat{i}, \\hat{j}\\right] \\ \\mathsf{Layout}[{W_{2,jk}}; j, k] = \\left[\\hat{j}, \\hat{k} \\right] $$\n",
        "\n",
        "Aunque la deducción de disposición muestra que las 2 disposiciones no son independientes, en aras de la simplicidad de la interfaz del modelo, `MLP` tomará 2 argumentos `Layout`, uno por cada capa Dense."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "junyS-965opl"
      },
      "outputs": [],
      "source": [
        "from typing import Tuple\n",
        "\n",
        "class MLP(tf.Module):\n",
        "\n",
        "  def __init__(self, dense_layouts: Tuple[dtensor.Layout, dtensor.Layout]):\n",
        "    super().__init__()\n",
        "\n",
        "    self.dense1 = Dense(\n",
        "        1200, 48, (1, 2), dense_layouts[0], activation=tf.nn.relu)\n",
        "    self.bn = BatchNorm()\n",
        "    self.dense2 = Dense(48, 2, (3, 4), dense_layouts[1])\n",
        "\n",
        "  def __call__(self, x):\n",
        "    y = x\n",
        "    y = self.dense1(y)\n",
        "    y = self.bn(y)\n",
        "    y = self.dense2(y)\n",
        "    return y\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dgLmebHhr7h"
      },
      "source": [
        "Las APIs que usan DTensor suelen tener como punto de diseño el equilibrio entre la corrección de las restricciones de deducción del diseño y la sencillez de la API. También es posible capturar la dependencia entre las `Layout` con una API diferente. Por ejemplo, la clase `MLPStricter` crea los objetos `Layout` en el constructor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wEZR7UlihsYX"
      },
      "outputs": [],
      "source": [
        "class MLPStricter(tf.Module):\n",
        "\n",
        "  def __init__(self, mesh, input_mesh_dim, inner_mesh_dim1, output_mesh_dim):\n",
        "    super().__init__()\n",
        "\n",
        "    self.dense1 = Dense(\n",
        "        1200, 48, (1, 2), dtensor.Layout([input_mesh_dim, inner_mesh_dim1], mesh),\n",
        "        activation=tf.nn.relu)\n",
        "    self.bn = BatchNorm()\n",
        "    self.dense2 = Dense(48, 2, (3, 4), dtensor.Layout([inner_mesh_dim1, output_mesh_dim], mesh))\n",
        "\n",
        "\n",
        "  def __call__(self, x):\n",
        "    y = x\n",
        "    y = self.dense1(y)\n",
        "    y = self.bn(y)\n",
        "    y = self.dense2(y)\n",
        "    return y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GcQi7D5mal2L"
      },
      "source": [
        "Para asegurarse de que el modelo funciona, pruebe su modelo con diseños totalmente replicados y un lote totalmente replicado de entrada `'x'`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zOPuYeQwallh"
      },
      "outputs": [],
      "source": [
        "WORLD = dtensor.create_mesh([(\"world\", 8)], devices=DEVICES)\n",
        "\n",
        "model = MLP([dtensor.Layout.replicated(WORLD, rank=2),\n",
        "             dtensor.Layout.replicated(WORLD, rank=2)])\n",
        "\n",
        "sample_x, sample_y = train_data_vec.take(1).get_single_element()\n",
        "sample_x = dtensor.copy_to_mesh(sample_x, dtensor.Layout.replicated(WORLD, rank=2))\n",
        "print(model(sample_x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akrjDstEpDv9"
      },
      "source": [
        "## Mover datos al dispositivo\n",
        "\n",
        "Normalmente, los iteradores `tf.data` (y otros métodos de extracción de datos) producen objetos tensor respaldados por la memoria del dispositivo anfitrión local. Estos datos deben transferirse a la memoria del dispositivo acelerador que respalda los tensores componentes del DTensor.\n",
        "\n",
        "`dtensor.copy_to_mesh` no es adecuada para esta situación porque replica los tensores de entrada a todos los dispositivos por la perspectiva global de DTensor. Así que en este tutorial usará una función ayudante `repack_local_tensor`, para facilitar la transferencia de datos. Esta función ayudante usa `dtensor.pack` para enviar (y sólo enviar) el fragmento del lote global destinado a una réplica al dispositivo que respalda la réplica.\n",
        "\n",
        "Esta función simplificada presupone un único cliente. En una aplicación multicliente, puede ser muy laborioso determinar la forma correcta de dividir el tensor local y el mapeado entre las piezas de la división y los dispositivos locales.\n",
        "\n",
        "Está prevista una API DTensor adicional para simplificar la integración de `tf.data`, compatible con aplicaciones de cliente único y multicliente. Se lo haremos saber."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3t5WvQR4Hvo4"
      },
      "outputs": [],
      "source": [
        "def repack_local_tensor(x, layout):\n",
        "  \"\"\"Repacks a local Tensor-like to a DTensor with layout.\n",
        "\n",
        "  This function assumes a single-client application.\n",
        "  \"\"\"\n",
        "  x = tf.convert_to_tensor(x)\n",
        "  sharded_dims = []\n",
        "\n",
        "  # For every sharded dimension, use tf.split to split the along the dimension.\n",
        "  # The result is a nested list of split-tensors in queue[0].\n",
        "  queue = [x]\n",
        "  for axis, dim in enumerate(layout.sharding_specs):\n",
        "    if dim == dtensor.UNSHARDED:\n",
        "      continue\n",
        "    num_splits = layout.shape[axis]\n",
        "    queue = tf.nest.map_structure(lambda x: tf.split(x, num_splits, axis=axis), queue)\n",
        "    sharded_dims.append(dim)\n",
        "\n",
        "  # Now we can build the list of component tensors by looking up the location in\n",
        "  # the nested list of split-tensors created in queue[0].\n",
        "  components = []\n",
        "  for locations in layout.mesh.local_device_locations():\n",
        "    t = queue[0]\n",
        "    for dim in sharded_dims:\n",
        "      split_index = locations[dim]  # Only valid on single-client mesh.\n",
        "      t = t[split_index]\n",
        "    components.append(t)\n",
        "\n",
        "  return dtensor.pack(components, layout)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KKCDcjG7zj2"
      },
      "source": [
        "## Entrenamiento paralelo de datos\n",
        "\n",
        "En esta sección, entrenará su modelo MLP haciendo un entrenamiento paralelo de datos. Las secciones siguientes mostrarán el entrenamiento paralelo del modelo y el entrenamiento paralelo espacial.\n",
        "\n",
        "El entrenamiento en paralelo de datos es un esquema comúnmente usado para el aprendizaje automático distribuido:\n",
        "\n",
        "- Las variables del modelo se reproducen en N dispositivos cada una.\n",
        "- Un lote global se divide en N lotes por réplica.\n",
        "- Cada lote por réplica se entrena en el dispositivo de réplica.\n",
        "- El gradiente se reduce antes de que la ponderación de los datos se realice colectivamente en todas las réplicas.\n",
        "\n",
        "El entrenamiento paralelo de datos ofrece una aceleración casi lineal con respecto al número de dispositivos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMsLUyTGq3oL"
      },
      "source": [
        "### Crear una malla paralela de datos\n",
        "\n",
        "Un típico bucle de entrenamiento en paralelismo de datos usa un DTensor `Mesh` que consta de una única dimensión `batch`, donde cada dispositivo se convierte en una réplica que recibe un fragmento del lote global.\n",
        "\n",
        "\n",
        "<img src=\"https://www.tensorflow.org/images/dtensor/dtensor_data_para.png\" class=\"no-filter\" alt=\"Malla paralela de datos\">\n",
        "\n",
        "El modelo replicado se ejecuta en la réplica, por lo que las variables del modelo están totalmente replicadas (sin fragmentar)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C0IyOlxmeu4I"
      },
      "outputs": [],
      "source": [
        "mesh = dtensor.create_mesh([(\"batch\", 8)], devices=DEVICES)\n",
        "\n",
        "model = MLP([dtensor.Layout([dtensor.UNSHARDED, dtensor.UNSHARDED], mesh),\n",
        "             dtensor.Layout([dtensor.UNSHARDED, dtensor.UNSHARDED], mesh),])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OREKwBybo1gZ"
      },
      "source": [
        "### Empaquetar datos de entrenamiento en DTensores\n",
        "\n",
        "El lote de datos de entrenamiento debe empaquetarse en DTensores fragmentados a lo largo del eje `'batch'`(primero), de modo que el DTensor distribuya uniformemente los datos de entrenamiento en la dimensión de malla `'batch'`.\n",
        "\n",
        "**Nota**: En DTensor, el `batch size` siempre se refiere al tamaño de lote global. El tamaño del lote debe seleccionarse de modo que pueda dividirse uniformemente por el tamaño de la dimensión de malla `batch`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8xMYkTpGocY8"
      },
      "outputs": [],
      "source": [
        "def repack_batch(x, y, mesh):\n",
        "  x = repack_local_tensor(x, layout=dtensor.Layout(['batch', dtensor.UNSHARDED], mesh))\n",
        "  y = repack_local_tensor(y, layout=dtensor.Layout(['batch'], mesh))\n",
        "  return x, y\n",
        "\n",
        "sample_x, sample_y = train_data_vec.take(1).get_single_element()\n",
        "sample_x, sample_y = repack_batch(sample_x, sample_y, mesh)\n",
        "\n",
        "print('x', sample_x[:, 0])\n",
        "print('y', sample_y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uONSiqOIkFL1"
      },
      "source": [
        "### Paso de entrenamiento\n",
        "\n",
        "Este ejemplo usa un optimizador de Descenso Gradiente Estocástico con el Bucle de Entrenamiento Personalizado (CTL). Consulte la [Guía del Bucle de Entrenamiento Personalizado](https://www.tensorflow.org/guide/keras/writing_a_training_loop_from_scratch) y el [Tutorial](https://www.tensorflow.org/tutorials/customization/custom_training_walkthrough) para obtener más información sobre estos temas.\n",
        "\n",
        "El `train_step` se encapsula como `tf.function` para indicar que este cuerpo se va a trazar como un grafo TensorFlow. El cuerpo de `train_step` consta de una pasada de inferencia hacia delante, una pasada de gradiente hacia atrás y la actualización de variables.\n",
        "\n",
        "Observe que el cuerpo de `train_step` no contiene ninguna anotación DTensor especial. En su lugar, `train_step` sólo contiene operaciones TensorFlow de alto nivel que procesan la entrada `x` y `y` desde la vista global del lote de entrada y el modelo. Todas las anotaciones del DTensor (`Mesh`, `Layout`) se eliminan del paso de entrenamiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BwUFzLGDtQT6"
      },
      "outputs": [],
      "source": [
        "# Refer to the CTL (custom training loop guide)\n",
        "@tf.function\n",
        "def train_step(model, x, y, learning_rate=tf.constant(1e-4)):\n",
        "  with tf.GradientTape() as tape:\n",
        "    logits = model(x)\n",
        "    # tf.reduce_sum sums the batch sharded per-example loss to a replicated\n",
        "    # global loss (scalar).\n",
        "    loss = tf.reduce_sum(\n",
        "        tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
        "            logits=logits, labels=y))\n",
        "  parameters = model.trainable_variables\n",
        "  gradients = tape.gradient(loss, parameters)\n",
        "  for parameter, parameter_gradient in zip(parameters, gradients):\n",
        "    parameter.assign_sub(learning_rate * parameter_gradient)\n",
        "\n",
        "  # Define some metrics\n",
        "  accuracy = 1.0 - tf.reduce_sum(tf.cast(tf.argmax(logits, axis=-1, output_type=tf.int64) != y, tf.float32)) / x.shape[0]\n",
        "  loss_per_sample = loss / len(x)\n",
        "  return {'loss': loss_per_sample, 'accuracy': accuracy}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OYTu4j0evWT"
      },
      "source": [
        "### Punto de verificación\n",
        "\n",
        "Puede crear un punto de verificación de un modelo DTensor usando `tf.train.Checkpoint` que ya viene integrado. Guardar y restaurar DVariables fragmentadas realizará un guardado y restauración fragmentados eficientes. Actualmente, al usar `tf.train.Checkpoint.save` y `tf.train.Checkpoint.restore`, todas las DVariables deben estar en la misma malla de host, y las DVariables y las variables normales no pueden guardarse juntas. Puede obtener más información sobre los puntos de verificación en [esta guía](../../guide/checkpoint.ipynb).\n",
        "\n",
        "Cuando se restaura un punto de verificación DTensor, las `Layout` de las variables pueden ser diferentes de cuando se guarda el punto de verificación. Es decir, el guardado de modelos DTensor es independiente del layout y de la malla, y sólo afecta a la eficacia del guardado fragmentado. Puede guardar un modelo DTensor con una malla y un diseño y restaurarlo con una malla y un diseño diferentes. Este tutorial usa esta función para continuar el entrenamiento en las secciones Entrenamiento en modelos paralelos y Entrenamiento en modelos espaciales paralelos.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rsInFFJg7x9t"
      },
      "outputs": [],
      "source": [
        "CHECKPOINT_DIR = tempfile.mkdtemp()\n",
        "\n",
        "def start_checkpoint_manager(model):\n",
        "  ckpt = tf.train.Checkpoint(root=model)\n",
        "  manager = tf.train.CheckpointManager(ckpt, CHECKPOINT_DIR, max_to_keep=3)\n",
        "\n",
        "  if manager.latest_checkpoint:\n",
        "    print(\"Restoring a checkpoint\")\n",
        "    ckpt.restore(manager.latest_checkpoint).assert_consumed()\n",
        "  else:\n",
        "    print(\"New training\")\n",
        "  return manager\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9r77ky5Jgp1j"
      },
      "source": [
        "### Bucle de entrenamiento\n",
        "\n",
        "Para el esquema de entrenamiento paralelo de datos, entrena por épocas e informa del progreso. 3 épocas son insuficientes para entrenar el modelo: una precisión del 50% es lo mismo que adivinar al azar.\n",
        "\n",
        "Active la función de punto de verificación para que pueda retomar el entrenamiento más tarde. En la siguiente sección, cargará el punto de verificación y hará el entrenamiento con un esquema paralelo diferente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UaLn-vGZgqbS"
      },
      "outputs": [],
      "source": [
        "num_epochs = 2\n",
        "manager = start_checkpoint_manager(model)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  step = 0\n",
        "  pbar = tf.keras.utils.Progbar(target=int(train_data_vec.cardinality()), stateful_metrics=[])\n",
        "  metrics = {'epoch': epoch}\n",
        "  for x,y in train_data_vec:\n",
        "\n",
        "    x, y = repack_batch(x, y, mesh)\n",
        "\n",
        "    metrics.update(train_step(model, x, y, 1e-2))\n",
        "\n",
        "    pbar.update(step, values=metrics.items(), finalize=False)\n",
        "    step += 1\n",
        "  manager.save()\n",
        "  pbar.update(step, values=metrics.items(), finalize=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRFJEhum7EGD"
      },
      "source": [
        "## Entrenamiento paralelo de modelo\n",
        "\n",
        "Si cambia a una `Mesh` de 2 dimensiones, y fragmenta las variables del modelo a lo largo de la segunda dimensión de la malla, entonces el entrenamiento se convierte en Paralelo de modelo.\n",
        "\n",
        "En el entrenamiento Paralelo de Modelo, cada réplica del modelo abarca varios dispositivos (2 en este caso):\n",
        "\n",
        "- Hay 4 réplicas del modelo, y el lote de datos de entrenamiento se distribuye entre las 4 réplicas.\n",
        "- Los 2 dispositivos de una misma réplica del modelo reciben datos de entrenamiento replicados.\n",
        "\n",
        "\n",
        "<img src=\"https://www.tensorflow.org/images/dtensor/dtensor_model_para.png\" class=\"no-filter\" alt=\"Malla paralela de modelos\"> \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5gZE9IT5Dzwl"
      },
      "outputs": [],
      "source": [
        "mesh = dtensor.create_mesh([(\"batch\", 4), (\"model\", 2)], devices=DEVICES)\n",
        "model = MLP([dtensor.Layout([dtensor.UNSHARDED, \"model\"], mesh), \n",
        "             dtensor.Layout([\"model\", dtensor.UNSHARDED], mesh)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ihof3DkMFKnf"
      },
      "source": [
        "Como los datos de entrenamiento siguen fragmentados a lo largo de la dimensión del lote, puede reutilizar la misma función `repack_batch` que en el caso del entrenamiento Paralelo de Datos. DTensor replicará automáticamente el lote por réplica a todos los dispositivos dentro de la réplica a lo largo de la dimensión de malla `\"model\"`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dZf56ynbE_p1"
      },
      "outputs": [],
      "source": [
        "def repack_batch(x, y, mesh):\n",
        "  x = repack_local_tensor(x, layout=dtensor.Layout(['batch', dtensor.UNSHARDED], mesh))\n",
        "  y = repack_local_tensor(y, layout=dtensor.Layout(['batch'], mesh))\n",
        "  return x, y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UW3OXdhNFfpv"
      },
      "source": [
        "A continuación, ejecute el bucle de entrenamiento. El bucle de entrenamiento reutiliza el mismo Gestor de puntos de verificación que el ejemplo de entrenamiento Paralelo de datos, y el código parece idéntico.\n",
        "\n",
        "Puede seguir entrenando el modelo entrenado paralelo de datos en entrenamiento paralelo de modelos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LLC0wgii7EgA"
      },
      "outputs": [],
      "source": [
        "num_epochs = 2\n",
        "manager = start_checkpoint_manager(model)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  step = 0\n",
        "  pbar = tf.keras.utils.Progbar(target=int(train_data_vec.cardinality()))\n",
        "  metrics = {'epoch': epoch}\n",
        "  for x,y in train_data_vec:\n",
        "    x, y = repack_batch(x, y, mesh)\n",
        "    metrics.update(train_step(model, x, y, 1e-2))\n",
        "    pbar.update(step, values=metrics.items(), finalize=False)\n",
        "    step += 1\n",
        "  manager.save()\n",
        "  pbar.update(step, values=metrics.items(), finalize=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZH-aMrVzi2L"
      },
      "source": [
        "## Entrenamiento paralelo espacial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-bK6IZ9GCS9"
      },
      "source": [
        "Cuando se entrenan datos de muy alta dimensionalidad (por ejemplo, una imagen muy grande o un vídeo), puede ser conveniente fragmentarlos a lo largo de la dimensión de la característica. Esto se denomina [Partición espacial](https://cloud.google.com/blog/products/ai-machine-learning/train-ml-models-on-large-images-and-3d-volumes-with-spatial-partitioning-on-cloud-tpus), que se introdujo por primera vez en TensorFlow para el entrenamiento de modelos con grandes muestras de entrada en 3D.\n",
        "\n",
        "\n",
        "<img src=\"https://www.tensorflow.org/images/dtensor/dtensor_spatial_para.png\" class=\"no-filter\" alt=\"Malla paralela espacial\">\n",
        "\n",
        "DTensor también es compatible con este caso. El único cambio necesario es crear una Malla que incluya una dimensión `feature`, y aplicar el correspondiente `Layout`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jpc9mqURGpmK"
      },
      "outputs": [],
      "source": [
        "mesh = dtensor.create_mesh([(\"batch\", 2), (\"feature\", 2), (\"model\", 2)], devices=DEVICES)\n",
        "model = MLP([dtensor.Layout([\"feature\", \"model\"], mesh), \n",
        "             dtensor.Layout([\"model\", dtensor.UNSHARDED], mesh)])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i07Wrv-jHBc1"
      },
      "source": [
        "Fragmente los datos de entrada a lo largo de la dimensión `feature` al empaquetar los tensores de entrada en DTensores. Puede hacerlo con una función de reempaquetado ligeramente distinta, `repack_batch_for_spt`, donde `spt` significa Entrenamiento Paralelo Espacial."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DWR8qF6BGtFL"
      },
      "outputs": [],
      "source": [
        "def repack_batch_for_spt(x, y, mesh):\n",
        "    # Shard data on feature dimension, too\n",
        "    x = repack_local_tensor(x, layout=dtensor.Layout([\"batch\", 'feature'], mesh))\n",
        "    y = repack_local_tensor(y, layout=dtensor.Layout([\"batch\"], mesh))\n",
        "    return x, y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ygl9dqMUHTVN"
      },
      "source": [
        "El entrenamiento paralelo espacial también puede continuar desde un punto de verificación creado con otros esquemas de entrenamiento paralelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p3NnpHSKo-hx"
      },
      "outputs": [],
      "source": [
        "num_epochs = 2\n",
        "\n",
        "manager = start_checkpoint_manager(model)\n",
        "for epoch in range(num_epochs):\n",
        "  step = 0\n",
        "  metrics = {'epoch': epoch}\n",
        "  pbar = tf.keras.utils.Progbar(target=int(train_data_vec.cardinality()))\n",
        "\n",
        "  for x, y in train_data_vec:\n",
        "    x, y = repack_batch_for_spt(x, y, mesh)\n",
        "    metrics.update(train_step(model, x, y, 1e-2))\n",
        "\n",
        "    pbar.update(step, values=metrics.items(), finalize=False)\n",
        "    step += 1\n",
        "  manager.save()\n",
        "  pbar.update(step, values=metrics.items(), finalize=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vp4L59CpJjYr"
      },
      "source": [
        "## SavedModel y DTensor\n",
        "\n",
        "La integración de DTensor y SavedModel aún está en desarrollo.\n",
        "\n",
        "A partir de TensorFlow `2.11`, `tf.saved_model` puede guardar modelos DTensor fragmentados y replicados, y permite realizar un guardado fragmentado eficiente en distintos dispositivos de la malla. Sin embargo, después de guardar un modelo, se pierden todas las anotaciones del DTensor y las firmas guardadas sólo se pueden usar con Tensores normales, no con DTensores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "49HfIq_SJZoj"
      },
      "outputs": [],
      "source": [
        "mesh = dtensor.create_mesh([(\"world\", 1)], devices=DEVICES[:1])\n",
        "mlp = MLP([dtensor.Layout([dtensor.UNSHARDED, dtensor.UNSHARDED], mesh), \n",
        "           dtensor.Layout([dtensor.UNSHARDED, dtensor.UNSHARDED], mesh)])\n",
        "\n",
        "manager = start_checkpoint_manager(mlp)\n",
        "\n",
        "model_for_saving = tf.keras.Sequential([\n",
        "  text_vectorization,\n",
        "  mlp\n",
        "])\n",
        "\n",
        "@tf.function(input_signature=[tf.TensorSpec([None], tf.string)])\n",
        "def run(inputs):\n",
        "  return {'result': model_for_saving(inputs)}\n",
        "\n",
        "tf.saved_model.save(\n",
        "    model_for_saving, \"/tmp/saved_model\",\n",
        "    signatures=run)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6Csim_VMGxQ"
      },
      "source": [
        "A partir de TensorFlow 2.9.0, sólo se puede llamar a una firma cargada con un Tensor normal, o con un DTensor totalmente replicado (que se convertirá en un Tensor normal)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HG_ASSzR4IWW"
      },
      "outputs": [],
      "source": [
        "sample_batch = train_data.take(1).get_single_element()\n",
        "sample_batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qW8yKPrhKQ5b"
      },
      "outputs": [],
      "source": [
        "loaded = tf.saved_model.load(\"/tmp/saved_model\")\n",
        "\n",
        "run_sig = loaded.signatures[\"serving_default\"]\n",
        "result = run_sig(sample_batch['text'])['result']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GahGbv0ZmkJb"
      },
      "outputs": [],
      "source": [
        "np.mean(tf.argmax(result, axis=-1) == sample_batch['label'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ks-Vs9qsH6jO"
      },
      "source": [
        "## ¿Qué sigue?\n",
        "\n",
        "Este tutorial muestra cómo construir y entrenar un modelo MLP de análisis de opiniones con DTensor.\n",
        "\n",
        "Mediante las primitivas `Mesh` y `Layout`, DTensor puede transformar un `tf.function` de TensorFlow en un programa distribuido adecuado para diversos esquemas de entrenamiento.\n",
        "\n",
        "Para no producir un modelo sobreajustado en el mundo real, en una aplicación de aprendizaje automático deben aplicarse la evaluación y la validación cruzada. Las técnicas presentadas en este tutorial también pueden aplicarse para introducir paralelismo a la evaluación.\n",
        "\n",
        "Elaborar un modelo con `tf.Module` desde cero es mucho trabajo, y si se reutilizan los bloques de construcción existentes, como las capas y las funciones ayudantes, se puede acelerar drásticamente el desarrollo del modelo. A partir de TensorFlow 2.9, todas las Capas Keras incluidas en `tf.keras.layers` aceptan diseños DTensor como argumentos, y pueden usarse para construir modelos DTensor. Incluso puede reutilizar directamente un modelo Keras con DTensor sin modificar la implementación del modelo. Consulte el [Tutorial de integración de DTensor Keras](https://www.tensorflow.org/tutorials/distribute/dtensor_keras_tutorial) para saber cómo usar DTensor Keras. "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "dtensor_ml_tutorial.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
