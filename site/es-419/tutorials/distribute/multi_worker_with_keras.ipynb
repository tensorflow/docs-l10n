{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tce3stUlHN0L"
      },
      "source": [
        "##### Copyright 2019 The TensorFlow Authors.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tuOe1ymfHZPu"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfBg1C5NB3X0"
      },
      "source": [
        "# Entrenamiento multitrabajador con Keras\n",
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td><a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/distribute/multi_worker_with_keras\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver en TensorFlow.org</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/es-419/tutorials/distribute/multi_worker_with_keras.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Ejecutar en Google Colab</a></td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/es-419/tutorials/distribute/multi_worker_with_keras.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver código fuente en GitHub</a>\n",
        "</td>\n",
        "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/es-419/tutorials/distribute/multi_worker_with_keras.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Descargar bloc de notas</a>\n",
        "</td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHxb-dlhMIzW"
      },
      "source": [
        "## Visión general\n",
        "\n",
        "Este tutorial demuestra cómo realizar un entrenamiento distribuido multitrabajador con un modelo Keras y la API `Model.fit` usando la API `tf.distribute.MultiWorkerMirroredStrategy`. Con la ayuda de esta estrategia, un modelo Keras que ha sido diseñado para ejecutarse en un único trabajador puede funcionar sin problemas en multitrabajador con cambios mínimos en el código.\n",
        "\n",
        "Para aprender a usar la `MultiWorkerMirroredStrategy` con Keras y un bucle de entrenamiento personalizado, consulte [Bucle de entrenamiento personalizado con Keras y MultiWorkerMirroredStrategy](multi_worker_with_ctl.ipynb).\n",
        "\n",
        "Este tutorial incluye un ejemplo mínimo de multitrabajador con dos trabajadores a modo de demostración."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUdRerXg6yz3"
      },
      "source": [
        "### Elegir la estrategia adecuada"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAiCV_oL63GM"
      },
      "source": [
        "Antes de empezar, cerciórese de que `tf.distribute.MultiWorkerMirroredStrategy` es la opción adecuada para su(s) acelerador(es) y entrenamiento. Se trata de dos formas habituales de distribuir el entrenamiento con paralelismo de datos:\n",
        "\n",
        "- *Entrenamiento síncrono*, en el que los pasos del entrenamiento se sincronizan entre los trabajadores y las réplicas, como `tf.distribute.MirroredStrategy`, `tf.distribute.TPUStrategy`, y `tf.distribute.MultiWorkerMirroredStrategy`. Todos los trabajadores se entrenan sobre diferentes porciones de datos de entrada de forma sincronizada, y agregando gradientes en cada paso.\n",
        "- *Entrenamiento asíncrono*, en el que los pasos del entrenamiento no están estrictamente sincronizados, como `tf.distribute.experimental.ParameterServerStrategy`. Todos los trabajadores están entrenando de forma independiente sobre los datos de entrada y actualizando las variables de forma asíncrona.\n",
        "\n",
        "Si lo que busca es un entrenamiento síncrono multitrabajador sin TPU, entonces necesita `tf.distribute.MultiWorkerMirroredStrategy`. Crea copias de todas las variables de las capas del modelo en cada dispositivo a través de todos los trabajadores. Usa `CollectiveOps`, una op de TensorFlow para la comunicación colectiva, para agregar gradientes y conserva las variables sincronizadas. Si está interesado, consulte la información sobre el parámetro `tf.distribute.experimental.CommunicationOptions` para ver las opciones de implementación de colectivos.\n",
        "\n",
        "Consulte [Entrenamiento distribuido en TensorFlow](../../guide/distributed_training.ipynb) para ver un resumen de las API `tf.distribute.Strategy`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUXex9ctTuDB"
      },
      "source": [
        "## Preparación\n",
        "\n",
        "Comience con algunas importaciones necesarias:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bnYxvfLD-LW-"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "import sys"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zz0EY91y3mxy"
      },
      "source": [
        "Antes de importar TensorFlow, realice algunos cambios en el entorno:\n",
        "\n",
        "- En una aplicación del mundo real, cada trabajador estaría en una máquina diferente. Para efectos de este tutorial, todos los trabajadores se ejecutarán en la máquina **this**. Así pues, desactive todas las GPU para evitar errores causados por todos los trabajadores que intentan usar la misma GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rpEIVI5upIzM"
      },
      "outputs": [],
      "source": [
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7X1MS6385BWi"
      },
      "source": [
        "- Restablezca la variable de entorno `TF_CONFIG` (aprenderá más sobre esto más adelante):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WEJLYa2_7OZF"
      },
      "outputs": [],
      "source": [
        "os.environ.pop('TF_CONFIG', None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rd4L9Ii77SS8"
      },
      "source": [
        "- Asegúrese de que el directorio actual está en la ruta de Python; esto permite al bloc de notas importar posteriormente los archivos escritos por `%%writefile`:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hPBuZUNSZmrQ"
      },
      "outputs": [],
      "source": [
        "if '.' not in sys.path:\n",
        "  sys.path.insert(0, '.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hLpDZhAz2q-"
      },
      "source": [
        "Instale `tf-nightly`, ya que la frecuencia de guardado de puntos de verificación en un paso concreto con el argumento `save_freq` en `tf.keras.callbacks.BackupAndRestore` se introduce a partir de TensorFlow 2.10:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-XqozLfzz30N"
      },
      "outputs": [],
      "source": [
        "!pip install tf-nightly"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "524e38dab658"
      },
      "source": [
        "Finalmente, importe TensorFlow:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vHNvttzV43sA"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0S2jpf6Sx50i"
      },
      "source": [
        "### Definición del conjunto de datos y del modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLW6D2TzvC-4"
      },
      "source": [
        "A continuación, cree un archivo `mnist_setup.py` con una configuración sencilla del modelo y el conjunto de datos. Este archivo Python será usado por los procesos de los trabajadores en este tutorial:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dma_wUAxZqo2"
      },
      "outputs": [],
      "source": [
        "%%writefile mnist_setup.py\n",
        "\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "def mnist_dataset(batch_size):\n",
        "  (x_train, y_train), _ = tf.keras.datasets.mnist.load_data()\n",
        "  # The `x` arrays are in uint8 and have values in the [0, 255] range.\n",
        "  # You need to convert them to float32 with values in the [0, 1] range.\n",
        "  x_train = x_train / np.float32(255)\n",
        "  y_train = y_train.astype(np.int64)\n",
        "  train_dataset = tf.data.Dataset.from_tensor_slices(\n",
        "      (x_train, y_train)).shuffle(60000).repeat().batch(batch_size)\n",
        "  return train_dataset\n",
        "\n",
        "def build_and_compile_cnn_model():\n",
        "  model = tf.keras.Sequential([\n",
        "      tf.keras.layers.InputLayer(input_shape=(28, 28)),\n",
        "      tf.keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
        "      tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
        "      tf.keras.layers.Flatten(),\n",
        "      tf.keras.layers.Dense(128, activation='relu'),\n",
        "      tf.keras.layers.Dense(10)\n",
        "  ])\n",
        "  model.compile(\n",
        "      loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "      optimizer=tf.keras.optimizers.SGD(learning_rate=0.001),\n",
        "      metrics=['accuracy'])\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UL3kisMO90X"
      },
      "source": [
        "### Entrenamiento de modelo en un solo trabajador\n",
        "\n",
        "Pruebe a entrenar el modelo durante un pequeño número de épocas y observe los resultados de *un solo trabajador* para asegurarse de que todo funciona correctamente. Conforme avance el entrenamiento, la pérdida debería disminuir y la precisión debería aumentar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Qe6iAf5O8iJ"
      },
      "outputs": [],
      "source": [
        "import mnist_setup\n",
        "\n",
        "batch_size = 64\n",
        "single_worker_dataset = mnist_setup.mnist_dataset(batch_size)\n",
        "single_worker_model = mnist_setup.build_and_compile_cnn_model()\n",
        "single_worker_model.fit(single_worker_dataset, epochs=3, steps_per_epoch=70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmgZwwymxqt5"
      },
      "source": [
        "## Configuración multitrabajador\n",
        "\n",
        "Entremos ahora en el mundo del entrenamiento multitrabajador.\n",
        "\n",
        "### Un cluster con trabajos y tareas\n",
        "\n",
        "En TensorFlow, el entrenamiento distribuido implica un `'cluster'` con varios trabajos, y cada uno de los trabajos puede tener una o más `'task'`.\n",
        "\n",
        "Necesitará la variable de entorno de configuración `TF_CONFIG` para el entrenamiento en múltiples máquinas, cada una de las cuales posiblemente tenga un rol diferente. `TF_CONFIG` es una cadena JSON empleada para especificar la configuración del clúster para cada trabajador que forme parte del clúster.\n",
        "\n",
        "Hay dos componentes de una variable `TF_CONFIG`: `'cluster'` y `'task'`.\n",
        "\n",
        "- Un `'cluster'` es el mismo para todos los trabajadores y da información sobre el cluster de entrenamiento, que es un diccionario formado por diferentes tipos de trabajos, como `'worker'` o `'chief'`.\n",
        "\n",
        "    - En el entrenamiento multitrabajador con `tf.distribute.MultiWorkerMirroredStrategy`, suele haber un `'worker'` que asume más responsabilidades, como guardar un punto de verificación y escribir un archivo sumario para TensorBoard, además de lo que hace un `'worker'` normal. A este `'worker'` se le identifica como el \"worker\" jefe (con un nombre de trabajo `'chief'`).\n",
        "    - Es habitual que el trabajador con `'index'` `0` sea el `'chief'`.\n",
        "\n",
        "- Una `'task'` da información sobre la tarea actual y es diferente para cada trabajador. Especifica el `'type'` y el `'index'` de ese trabajador.\n",
        "\n",
        "Below is an example configuration:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XK1eTYvSZiX7"
      },
      "outputs": [],
      "source": [
        "tf_config = {\n",
        "    'cluster': {\n",
        "        'worker': ['localhost:12345', 'localhost:23456']\n",
        "    },\n",
        "    'task': {'type': 'worker', 'index': 0}\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjgwJbPKZkJL"
      },
      "source": [
        "Tenga en cuenta que `tf_config` es sólo una variable local en Python. Para usarla para la configuración del entrenamiento, serialícela como JSON y colóquela en una variable de entorno `TF_CONFIG`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yY-T0YDQZjbu"
      },
      "outputs": [],
      "source": [
        "json.dumps(tf_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YFpxrcsZ2xG"
      },
      "source": [
        "En el ejemplo de configuración anterior, se establece el `'type'` de tarea a `'worker'` y el `'index'` de la tarea en `0`. Por lo tanto, esta máquina es la *primera* trabajadora. Será designada como el trabajador `'chief'`.\n",
        "\n",
        "Nota: Otras máquinas necesitarán tener la variable de entorno `TF_CONFIG` establecida también, y deberá tener el mismo diccionario `'cluster'`, pero diferentes `'type'` de tareas o `'index'` de tareas, dependiendo de los roles de esas máquinas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aogb74kHxynz"
      },
      "source": [
        "En la práctica, usted crearía varios trabajadores en direcciones IP/puertos externos y configuraría una variable `TF_CONFIG` en cada trabajador según corresponda. Como ejemplo, este tutorial muestra cómo puede configurar una variable `TF_CONFIG` con dos trabajadores en un `localhost`:\n",
        "\n",
        "- El `TF_CONFIG` del primer trabajador (`'chief'`) como se muestra arriba.\n",
        "- Para el segundo trabajador, fijará `tf_config['task']['index']=1`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cIlkfWmjz1PG"
      },
      "source": [
        "### Variables de entorno y subprocesos en blocs de notas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcjAbuGY1ACJ"
      },
      "source": [
        "Los subprocesos heredan las variables de entorno de su padre. Así que si configura una variable de entorno en este proceso de bloc de notas Jupyter:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PH2gHn2_0_U8"
      },
      "outputs": [],
      "source": [
        "os.environ['GREETINGS'] = 'Hello TensorFlow!'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQkIX-cg18md"
      },
      "source": [
        "... entonces puede acceder a la variable de entorno desde los subprocesos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pquKO6IA18G5"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "echo ${GREETINGS}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "af6BCA-Y2fpz"
      },
      "source": [
        "En la siguiente sección, usará este método para pasar el `TF_CONFIG` a los subprocesos de los trabajadores. En un escenario real nunca ejecutaría sus trabajos de esta forma; este tutorial sólo muestra cómo hacerlo con un ejemplo multitrabajador mínimo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnDJmaRA9qnf"
      },
      "source": [
        "## Entrenar el modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhNtHfuxCGVy"
      },
      "source": [
        "Para entrenar el modelo, cree en primer lugar una instancia del modelo `tf.distribute.MultiWorkerMirroredStrategy`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1uFSHCJXMrQ-"
      },
      "outputs": [],
      "source": [
        "strategy = tf.distribute.MultiWorkerMirroredStrategy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0iv7SyyAohc"
      },
      "source": [
        "Nota: `TF_CONFIG` se parsea y los servidores GRPC de TensorFlow se inician en el momento en que se llama a `MultiWorkerMirroredStrategy`, por lo que la variable de entorno `TF_CONFIG` debe configurarse antes de crear una instancia `tf.distribute.Strategy`. Dado que `TF_CONFIG` aún no está establecida, la estrategia anterior es efectivamente un entrenamiento para un solo trabajador."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H47DDcOgfzm7"
      },
      "source": [
        "Con la integración de la API `tf.distribute.Strategy` en `tf.keras`, el único cambio que hará para distribuir el entrenamiento a múltiples trabajadores es acotar la construcción del modelo y la llamada `model.compile` dentro de `strategy.scope()`. El ámbito de la estrategia de distribución dicta cómo y dónde se crean las variables, y en el caso de `MultiWorkerMirroredStrategy`, las variables creadas son `MirroredVariable`, y se replican en cada uno de los trabajadores.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wo6b9wX65glL"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "  # Model building/compiling need to be within `strategy.scope()`.\n",
        "  multi_worker_model = mnist_setup.build_and_compile_cnn_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mhq3fzyR5hTw"
      },
      "source": [
        "Nota: Actualmente existe una limitación en `MultiWorkerMirroredStrategy` en la que las operaciones TensorFlow deben crearse después de crear la instancia de la estrategia. Si se encuentra con el error `RuntimeError: Collective ops must be configured at program startup`, pruebe a crear la instancia de `MultiWorkerMirroredStrategy` al principio del programa y ponga el código que pueda crear ops después de instanciar la estrategia."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfYpmIxO6Jck"
      },
      "source": [
        "Para ejecutar realmente con `MultiWorkerMirroredStrategy` necesitará ejecutar procesos worker y pasarles un `TF_CONFIG`.\n",
        "\n",
        "Al igual que el archivo `mnist_setup.py` escrito anteriormente, aquí está el `main.py` que cada trabajador ejecutará:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BcsuBYrpgnlS"
      },
      "outputs": [],
      "source": [
        "%%writefile main.py\n",
        "\n",
        "import os\n",
        "import json\n",
        "\n",
        "import tensorflow as tf\n",
        "import mnist_setup\n",
        "\n",
        "per_worker_batch_size = 64\n",
        "tf_config = json.loads(os.environ['TF_CONFIG'])\n",
        "num_workers = len(tf_config['cluster']['worker'])\n",
        "\n",
        "strategy = tf.distribute.MultiWorkerMirroredStrategy()\n",
        "\n",
        "global_batch_size = per_worker_batch_size * num_workers\n",
        "multi_worker_dataset = mnist_setup.mnist_dataset(global_batch_size)\n",
        "\n",
        "with strategy.scope():\n",
        "  # Model building/compiling need to be within `strategy.scope()`.\n",
        "  multi_worker_model = mnist_setup.build_and_compile_cnn_model()\n",
        "\n",
        "\n",
        "multi_worker_model.fit(multi_worker_dataset, epochs=3, steps_per_epoch=70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aom9xelvJQ_6"
      },
      "source": [
        "En el fragmento de código anterior, observe que `global_batch_size`, que se pasa a `Dataset.batch`, se configura en `per_worker_batch_size * num_workers`. Esto garantiza que cada trabajador procese lotes de `per_worker_batch_size` ejemplos independientemente del número de trabajadores."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHLhOii67Saa"
      },
      "source": [
        "El directorio actual contiene ahora ambos archivos Python:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bi6x05Sr60O9"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "ls *.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmEEStPS6vR_"
      },
      "source": [
        "Serialice el `TF_CONFIG` a JSON y añádalo a las variables de entorno:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9uu3g7vV7Bbt"
      },
      "outputs": [],
      "source": [
        "os.environ['TF_CONFIG'] = json.dumps(tf_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MsY3dQLK7jdf"
      },
      "source": [
        "Ahora, puede iniciar un proceso trabajador que ejecutará el `main.py` y usará el `TF_CONFIG`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "txMXaq8d8N_S"
      },
      "outputs": [],
      "source": [
        "# first kill any previous runs\n",
        "%killbgscripts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qnSma_Ck7r-r"
      },
      "outputs": [],
      "source": [
        "%%bash --bg\n",
        "python main.py &> job_0.log"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZChyazqS7v0P"
      },
      "source": [
        "Hay que tener en cuenta algunas cosas sobre el comando anterior:\n",
        "\n",
        "1. Éste usa el `%%bash` que es una [\"magia\" de bloc de notas](https://ipython.readthedocs.io/en/stable/interactive/magics.html) para ejecutar algunos comandos bash.\n",
        "2. Usa la bandera `--bg` para ejecutar el proceso `bash` en segundo plano, porque este trabajador no terminará. Espera a todos los trabajadores antes de iniciarse.\n",
        "\n",
        "El proceso trabajador en segundo plano no imprimirá la salida en este bloc de notas, por lo que el `&>` redirige su salida a un archivo para que pueda inspeccionar lo sucedido en un archivo de registro más adelante.\n",
        "\n",
        "Por lo tanto, espere unos segundos a que se inicie el proceso:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hm2yrULE9281"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "time.sleep(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFPoNxg_9_Mx"
      },
      "source": [
        "Ahora, inspeccione lo que se ha volcado en el archivo de registro del trabajador hasta el momento:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vZEOuVgQ9-hn"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "cat job_0.log"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqZhVF7L_KOy"
      },
      "source": [
        "La última línea del archivo de registro debería decir: `Started server with target: grpc://localhost:12345`. El primer trabajador ya está listo y está esperando a que todos los demás trabajadores estén listos para continuar."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pi8vPNNA_l4a"
      },
      "source": [
        "Así que actualice el `tf_config` para que el proceso del segundo trabajador retome el trabajo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lAiYkkPu_Jqd"
      },
      "outputs": [],
      "source": [
        "tf_config['task']['index'] = 1\n",
        "os.environ['TF_CONFIG'] = json.dumps(tf_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0AshGVO0_x0w"
      },
      "source": [
        "Inicie el segundo trabajador. Esto iniciará el entrenamiento, ya que todos los trabajadores están activos (por lo que no es necesario poner este proceso en segundo plano):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ESVtyQ9_xjx"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "python main.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hX4FA2O2AuAn"
      },
      "source": [
        "Si se vuelven a revisar los registros escritos por el primer trabajador, se sabrá que participó en el entrenamiento de ese modelo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rc6hw3yTBKXX"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "cat job_0.log"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zL79ak5PMzEg"
      },
      "source": [
        "Nota: Esto puede correr más lento que la ejecución de prueba al principio de este tutorial porque ejecutar múltiples trabajadores en una sola máquina sólo añade sobrecarga. La meta aquí no es mejorar el tiempo de entrenamiento sino dar un ejemplo de entrenamiento multitrabajador.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sG5_1UgrgniF"
      },
      "outputs": [],
      "source": [
        "# Delete the `TF_CONFIG`, and kill any background tasks so they don't affect the next section.\n",
        "os.environ.pop('TF_CONFIG', None)\n",
        "%killbgscripts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9j2FJVHoUIrE"
      },
      "source": [
        "## Entrenamiento multitrabajador a fondo\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1hBks_dAZmT"
      },
      "source": [
        "Por el momento, ha aprendido a realizar una configuración multitrabajador básica. El resto del tutorial repasa en detalle otros factores que pueden ser útiles o importantes para casos de uso reales."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rr14Vl9GR4zq"
      },
      "source": [
        "### Fragmentación de conjuntos de datos\n",
        "\n",
        "En el entrenamiento multitrabajador, *es necesario fragmentar el conjunto de datos* para garantizar la convergencia y el rendimiento.\n",
        "\n",
        "El ejemplo de la sección anterior se basa en el autosharding predeterminado proporcionado por la API `tf.distribute.Strategy`. Puede controlar el fragmentado estableciendo la `tf.data.experimental.AutoShardPolicy` del `tf.data.experimental.DistributeOptions`.\n",
        "\n",
        "Para saber más sobre *auto fragmentación*, consulte la [Guía de entrada distribuida](https://www.tensorflow.org/tutorials/distribute/input#sharding).\n",
        "\n",
        "Aquí tiene un ejemplo rápido de cómo desactivar la auto fragmentación, para que cada réplica procese cada ejemplo (*no recomendado*):\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JxEtdh1vH-TF"
      },
      "outputs": [],
      "source": [
        "options = tf.data.Options()\n",
        "options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.OFF\n",
        "\n",
        "global_batch_size = 64\n",
        "multi_worker_dataset = mnist_setup.mnist_dataset(batch_size=64)\n",
        "dataset_no_auto_shard = multi_worker_dataset.with_options(options)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z85hElxsBQsT"
      },
      "source": [
        "### Evaluación"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmqvlh5LhAoU"
      },
      "source": [
        "Si pasa también el `validation_data` a `Model.fit`, alternará entre entrenamiento y evaluación para cada época. El trabajo de evaluación se distribuye entre el mismo grupo de trabajadores, y sus resultados se agregan y están disponibles para todos los trabajadores.\n",
        "\n",
        "Parecido al entrenamiento, el conjunto de datos de validación se auto fragmenta a nivel de archivo. Debe configurar un tamaño de lote global en el conjunto de datos de validación y configurar los `validation_steps`.\n",
        "\n",
        "Se recomienda utilizar un conjunto de datos repetido (llamando a `tf.data.Dataset.repeat`) para la evaluación.\n",
        "\n",
        "Otra posibilidad es crear otra tarea que lea periódicamente los puntos de verificación y ejecute la evaluación. Esto es lo que hace un Estimator. Pero no se recomienda esta forma de realizar la evaluación, por lo que se omiten sus detalles."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNkoxUPJBNTb"
      },
      "source": [
        "### Rendimiento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVk4ftYx6JAO"
      },
      "source": [
        "Para mejorar el rendimiento del entrenamiento multitrabajador, puede probar lo siguiente:\n",
        "\n",
        "- `tf.distribute.MultiWorkerMirroredStrategy` provee múltiples [implementaciones de comunicación de colectivos](https://www.tensorflow.org/api_docs/python/tf/distribute/experimental/CommunicationImplementation):\n",
        "\n",
        "    - `RING` implementa colectivos en anillos usando gRPC como capa de comunicación entre hosts.\n",
        "    - `NCCL` usa la [Librería de Comunicación Colectiva de NVIDIA](https://developer.nvidia.com/nccl) para implementar los colectivos.\n",
        "    - `AUTO` deja la elección al runtime.\n",
        "\n",
        "    La mejor elección para implementar colectivos depende del número y el tipo de GPU y de las interconexiones de red del cluster. Para anular la elección automática, especifique el parámetro `communication_options` del constructor de `MultiWorkerMirroredStrategy`. Por ejemplo:\n",
        "\n",
        "    ```python\n",
        "    communication_options=tf.distribute.experimental.CommunicationOptions(implementation=tf.distribute.experimental.CommunicationImplementation.NCCL)\n",
        "    ```\n",
        "\n",
        "- Haga cast de las variables a `tf.float` si es posible:\n",
        "\n",
        "    - El modelo oficial de ResNet incluye [un ejemplo](https://github.com/tensorflow/models/blob/8367cf6dabe11adf7628541706b660821f397dce/official/resnet/resnet_model.py#L466) de cómo hacerlo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97WhAu8uKw3j"
      },
      "source": [
        "### Tolerancia a fallos\n",
        "\n",
        "En el entrenamiento síncrono, el cluster fallaría si uno de los trabajadores falla y no existe ningún mecanismo de recuperación de fallos.\n",
        "\n",
        "Usar Keras con `tf.distribute.Strategy` ofrece la ventaja de la tolerancia a fallos cuando los trabajadores mueren o son inestables por algún otro motivo. Puede hacerlo conservando el estado de entrenamiento en el sistema de archivos distribuido de su elección, de forma que al reiniciar la instancia que falló o se adelantó previamente, se recupere el estado de entrenamiento.\n",
        "\n",
        "Cuando un trabajador deja de estar disponible, otros trabajadores fallarán (posiblemente tras un tiempo de espera). En tales casos, es necesario reiniciar el trabajador no disponible, así como otros trabajadores que hayan fallado.\n",
        "\n",
        "Nota: Anteriormente, la retrollamada `ModelCheckpoint` servía de mecanismo para restaurar el estado de entrenamiento tras un reinicio por fallo de un trabajo para el entrenamiento multitrabajador. El equipo de TensorFlow está añadiendo una nueva retrollamada [`BackupAndRestore`](#scrollTo=kmH8uCUhfn4w), que añade también el soporte al entrenamiento de un solo trabajador para una experiencia consistente, y ha eliminado la funcionalidad de tolerancia a fallos de la retrollamada `ModelCheckpoint` existente. A partir de ahora, las aplicaciones que dependan de este comportamiento deberán migrar a la nueva retrollamada `BackupAndRestore`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvHPjGlyyFt6"
      },
      "source": [
        "#### La retrollamada `ModelCheckpoint`\n",
        "\n",
        "La retrollamada `ModelCheckpoint` ya no ofrece la funcionalidad de tolerancia a fallos, así que use en su lugar la retrollamada [`BackupAndRestore`](#scrollTo=kmH8uCUhfn4w).\n",
        "\n",
        "La retrollamada `ModelCheckpoint` aún puede usarse para guardar puntos de verificación. Sin embargo, si el entrenamiento se interrumpió o finalizó con éxito, para continuar el entrenamiento a partir del punto de verificación, el usuario es responsable de cargar el modelo manualmente.\n",
        "\n",
        "De forma opcional, los usuarios pueden elegir guardar y restaurar el modelo/las ponderaciones fuera de la retrollamada `ModelCheckpoint`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUNV5Utc1d0s"
      },
      "source": [
        "### Guardar y cargar modelos\n",
        "\n",
        "Para guardar su modelo usando `model.save` o `tf.saved_model.save`, es necesario que la dirección de guardado sea diferente para cada trabajador.\n",
        "\n",
        "- Para los trabajadores que no sean jefes, tendrá que guardar el modelo en un directorio temporal.\n",
        "- Para el jefe, tendrá que guardar en el directorio de modelos proporcionado.\n",
        "\n",
        "Los directorios temporales del trabajador deben ser únicos para evitar errores resultantes de que varios trabajadores intenten escribir en la misma ubicación.\n",
        "\n",
        "El modelo guardado en todos los directorios es idéntico, y por lo general sólo hay que consultar el modelo guardado por el jefe para restaurarlo o usarlo.\n",
        "\n",
        "Debe tener alguna lógica de limpieza que borre los directorios temporales creados por los trabajadores una vez que su entrenamiento se haya llenado.\n",
        "\n",
        "La razón para guardar en el jefe y en los trabajadores al mismo tiempo es que podría estar agregando variables durante el punto de verificación, lo que requiere que tanto el jefe como los trabajadores participen en el protocolo de comunicación allreduce. Por otro lado, dejar que el jefe y los trabajadores guarden en el mismo directorio del modelo resultará en errores debido a la contención.\n",
        "\n",
        "Usando la `MultiWorkerMirroredStrategy`, el programa se ejecuta en cada trabajador, y para saber si el trabajador actual es el jefe, aprovecha el objeto resolutor del cluster que tiene atributos `task_type` y `task_id`:\n",
        "\n",
        "- `task_type` le indica cuál es el trabajo actual (por ejemplo, `'worker'`).\n",
        "- `task_id` le indica el identificador del trabajador.\n",
        "- El trabajador con `task_id == 0` es designado como trabajador jefe.\n",
        "\n",
        "En el fragmento de código siguiente, la función `write_filepath` indica la ruta del archivo a escribir, que depende del `task_id` del trabajador:\n",
        "\n",
        "- Para el trabajador jefe (con `task_id == 0`), escribe en la ruta del archivo original.\n",
        "- Para otros trabajadores, crea un directorio temporal (`temp_dir`) con el `task_id` en la ruta del directorio para escribir en él:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XQfGkmg-pfCY"
      },
      "outputs": [],
      "source": [
        "model_path = '/tmp/keras-model'\n",
        "\n",
        "def _is_chief(task_type, task_id):\n",
        "  # Note: there are two possible `TF_CONFIG` configurations.\n",
        "  #   1) In addition to `worker` tasks, a `chief` task type is use;\n",
        "  #      in this case, this function should be modified to\n",
        "  #      `return task_type == 'chief'`.\n",
        "  #   2) Only `worker` task type is used; in this case, worker 0 is\n",
        "  #      regarded as the chief. The implementation demonstrated here\n",
        "  #      is for this case.\n",
        "  # For the purpose of this Colab section, the `task_type` is `None` case\n",
        "  # is added because it is effectively run with only a single worker.\n",
        "  return (task_type == 'worker' and task_id == 0) or task_type is None\n",
        "\n",
        "def _get_temp_dir(dirpath, task_id):\n",
        "  base_dirpath = 'workertemp_' + str(task_id)\n",
        "  temp_dir = os.path.join(dirpath, base_dirpath)\n",
        "  tf.io.gfile.makedirs(temp_dir)\n",
        "  return temp_dir\n",
        "\n",
        "def write_filepath(filepath, task_type, task_id):\n",
        "  dirpath = os.path.dirname(filepath)\n",
        "  base = os.path.basename(filepath)\n",
        "  if not _is_chief(task_type, task_id):\n",
        "    dirpath = _get_temp_dir(dirpath, task_id)\n",
        "  return os.path.join(dirpath, base)\n",
        "\n",
        "task_type, task_id = (strategy.cluster_resolver.task_type,\n",
        "                      strategy.cluster_resolver.task_id)\n",
        "write_model_path = write_filepath(model_path, task_type, task_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hs0_agYR_qKm"
      },
      "source": [
        "Con eso, ya está listo para guardar:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnToxeIcg_6O"
      },
      "source": [
        "Obsoleto: Para los objetos Keras, se recomienda usar el nuevo formato de alto nivel `.keras` y `tf.keras.Model.export`, como se demuestra en la guía [aquí](https://www.tensorflow.org/guide/keras/save_and_serialize). El formato SavedModel de bajo nivel sigue siendo compatible con el código existente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J-yA3BYG_vTs"
      },
      "outputs": [],
      "source": [
        "multi_worker_model.save(write_model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LXUVVl9_v5x"
      },
      "source": [
        "Como ya se ha descrito, más adelante el modelo sólo debe cargarse desde la ruta del archivo en el que guardó el trabajador jefe. Por lo tanto, elimine los temporales que hayan guardado los trabajadores no jefes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aJTyu-97ABpY"
      },
      "outputs": [],
      "source": [
        "if not _is_chief(task_type, task_id):\n",
        "  tf.io.gfile.rmtree(os.path.dirname(write_model_path))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nr-2PKlHAPBT"
      },
      "source": [
        "Ahora, cuando sea el momento de cargar, use la práctica API `tf.keras.models.load_model`, y continúe con el trabajo posterior.\n",
        "\n",
        "Aquí, supongamos que sólo se usa un único trabajador para cargar y continuar el entrenamiento, en cuyo caso no se llama a `tf.keras.models.load_model` dentro de otro `strategy.scope()` (tenga en cuenta que `strategy = tf.distribute.MultiWorkerMirroredStrategy()`, como se definió anteriormente):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iUZna-JKAOrX"
      },
      "outputs": [],
      "source": [
        "loaded_model = tf.keras.models.load_model(model_path)\n",
        "\n",
        "# Now that the model is restored, and can continue with the training.\n",
        "loaded_model.fit(single_worker_dataset, epochs=2, steps_per_epoch=20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJ1fmxmTpocS"
      },
      "source": [
        "### Guardado y restauración del punto de verificación\n",
        "\n",
        "Por otro lado, el punto de verificación le permite guardar las ponderaciones de su modelo y restaurarlas sin tener que guardar todo el modelo.\n",
        "\n",
        "Aquí, creará un `tf.train.Checkpoint` que realice el seguimiento del modelo, que será administrado por el `tf.train.CheckpointManager`, de forma que sólo se conserve el último punto de verificación:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_1-RYaB5xnNH"
      },
      "outputs": [],
      "source": [
        "checkpoint_dir = '/tmp/ckpt'\n",
        "\n",
        "checkpoint = tf.train.Checkpoint(model=multi_worker_model)\n",
        "write_checkpoint_dir = write_filepath(checkpoint_dir, task_type, task_id)\n",
        "checkpoint_manager = tf.train.CheckpointManager(\n",
        "    checkpoint, directory=write_checkpoint_dir, max_to_keep=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oBpPCRsW1MF"
      },
      "source": [
        "Una vez configurado el `CheckpointManager`, ya está listo para guardar y eliminar los puntos de verificación que hayan guardado los trabajadores no jefes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l1ZXG_GbWzLp"
      },
      "outputs": [],
      "source": [
        "checkpoint_manager.save()\n",
        "if not _is_chief(task_type, task_id):\n",
        "  tf.io.gfile.rmtree(write_checkpoint_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RO7cbN40XD5v"
      },
      "source": [
        "Ahora, cuando necesite restaurar el modelo, puede encontrar el último punto de verificación guardado usando la práctica función `tf.train.latest_checkpoint`. Tras restaurar el punto de verificación, puede continuar con el entrenamiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NJW7vtknXFEH"
      },
      "outputs": [],
      "source": [
        "latest_checkpoint = tf.train.latest_checkpoint(checkpoint_dir)\n",
        "checkpoint.restore(latest_checkpoint)\n",
        "multi_worker_model.fit(multi_worker_dataset, epochs=2, steps_per_epoch=20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmH8uCUhfn4w"
      },
      "source": [
        "#### La retrollamada `BackupAndRestore`\n",
        "\n",
        "La retrollamada `tf.keras.callbacks.BackupAndRestore` ofrece la funcionalidad de tolerancia a fallos haciendo una copia de seguridad del modelo y del estado actual del entrenamiento en un archivo temporal de puntos de verificación bajo el argumento `backup_dir` a `BackupAndRestore`.\n",
        "\n",
        "Nota: En Tensorflow 2.9, se realiza una copia de seguridad del modelo actual y del estado de entrenamiento en los límites de las épocas. En la versión `tf-nightly` y a partir de TensorFlow 2.10, la retrollamada `BackupAndRestore` puede realizar una copia de seguridad del modelo y del estado de entrenamiento en los límites de época o de paso. `BackupAndRestore` acepta un argumento opcional `save_freq`. `save_freq` acepta ya sea `'epoch'` o un valor `int`. Si `save_freq` se configura como `'epoch'` se realiza una copia de seguridad del modelo después de cada época. Si `save_freq` se configura como valor entero superior a `0`, se realiza una copia de seguridad del modelo después de cada `save_freq` número de lotes.\n",
        "\n",
        "Una vez que los trabajos se interrumpen y se reinician, la retrollamada `BackupAndRestore` restaura el último punto de verificación, y puede continuar el entrenamiento desde el principio de la época y el paso en los que se guardó por última vez el estado de entrenamiento.\n",
        "\n",
        "Para usarlo, facilite una instancia de `tf.keras.callbacks.BackupAndRestore` en la llamada `Model.fit`.\n",
        "\n",
        "Con `MultiWorkerMirroredStrategy`, si un trabajador es interrumpido, todo el cluster hará una pausa hasta que el trabajador interrumpido vuelva a arrancar. Los demás trabajadores también se reiniciarán y el trabajador interrumpido volverá a unirse al clúster. Entonces, cada trabajador leerá el archivo de punto de verificación que se guardó previamente y retomará su estado anterior, permitiendo así que el clúster vuelva a entrar en sincronía. A continuación, continuará el entrenamiento. El estado del iterador del conjunto de datos distribuido se reiniciará y no se restaurará.\n",
        "\n",
        "La retrollamada `BackupAndRestore` usa el `CheckpointManager` para guardar y restaurar el estado de entrenamiento, lo que genera un archivo llamado checkpoint que hace un seguimiento de los puntos de verificación existentes junto con el más reciente. Por este motivo, `backup_dir` no debe usarse para almacenar otros puntos de verificación a fin de evitar la colisión de nombres.\n",
        "\n",
        "Actualmente, la retrollamada `BackupAndRestore` admite el entrenamiento de un solo trabajador sin estrategia (`MirroredStrategy`) y el entrenamiento multitrabajador con `MultiWorkerMirroredStrategy`.\n",
        "\n",
        "He aquí dos ejemplos tanto para el entrenamiento de multitrabajadores como para el de un solo trabajador:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CYdzZi4Qs1jz"
      },
      "outputs": [],
      "source": [
        "# Multi-worker training with `MultiWorkerMirroredStrategy`\n",
        "# and the `BackupAndRestore` callback. The training state \n",
        "# is backed up at epoch boundaries by default.\n",
        "\n",
        "callbacks = [tf.keras.callbacks.BackupAndRestore(backup_dir='/tmp/backup')]\n",
        "with strategy.scope():\n",
        "  multi_worker_model = mnist_setup.build_and_compile_cnn_model()\n",
        "multi_worker_model.fit(multi_worker_dataset,\n",
        "                       epochs=3,\n",
        "                       steps_per_epoch=70,\n",
        "                       callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8e86TAp0Rsl"
      },
      "source": [
        "Si el argumento `save_freq` de la retrollamada `BackupAndRestore` se configura como `'epoch'`, se realiza una copia de seguridad del modelo después de cada época."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rZjQGPsF0aEI"
      },
      "outputs": [],
      "source": [
        "# The training state is backed up at epoch boundaries because `save_freq` is\n",
        "# set to `epoch`.\n",
        "\n",
        "callbacks = [tf.keras.callbacks.BackupAndRestore(backup_dir='/tmp/backup')]\n",
        "with strategy.scope():\n",
        "  multi_worker_model = mnist_setup.build_and_compile_cnn_model()\n",
        "multi_worker_model.fit(multi_worker_dataset,\n",
        "                       epochs=3,\n",
        "                       steps_per_epoch=70,\n",
        "                       callbacks=callbacks)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-r44kCM0jc6"
      },
      "source": [
        "Nota: El siguiente bloque de código usa funciones que sólo disponibles en `tf-nightly` hasta que se publique Tensorflow 2.10.\n",
        "\n",
        "Si el argumento `save_freq` de la retrollamada `BackupAndRestore` se configura en un valor entero superior a `0`, se hace una copia de seguridad del modelo después de cada `save_freq` número de lotes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bSJUyLSF0moC"
      },
      "outputs": [],
      "source": [
        "# The training state is backed up at every 30 steps because `save_freq` is set\n",
        "# to an integer value of `30`.\n",
        "\n",
        "callbacks = [tf.keras.callbacks.BackupAndRestore(backup_dir='/tmp/backup', save_freq=30)]\n",
        "with strategy.scope():\n",
        "  multi_worker_model = mnist_setup.build_and_compile_cnn_model()\n",
        "multi_worker_model.fit(multi_worker_dataset,\n",
        "                       epochs=3,\n",
        "                       steps_per_epoch=70,\n",
        "                       callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIV5_3ebzXmB"
      },
      "source": [
        "Si examina el directorio de `backup_dir` que especificó en `BackupAndRestore`, puede que note algunos archivos de puntos de verificación generados temporalmente. Esos archivos son necesarios para recuperar las instancias perdidas anteriormente, y serán eliminados por la librería al final de `Model.fit` al salir con éxito de su entrenamiento.\n",
        "\n",
        "Nota: Actualmente la retrollamada `BackupAndRestore` sólo soporta eager mode. En modo grafo, considere usar `Model.save`/`tf.saved_model.save` y `tf.keras.models.load_model` para guardar y recuperar modelos, respectivamente, como se describe en la sección *Guardar y cargar modelos* anterior, y proporcionando `initial_epoch` en `Model.fit` durante el entrenamiento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ega2hdOQEmy_"
      },
      "source": [
        "## Recursos adicionales\n",
        "\n",
        "1. La guía [Entrenamiento distribuido en TensorFlow](../../guide/distributed_training.ipynb) proporciona una visión general de las estrategias de distribución disponibles.\n",
        "2. El tutorial [Bucle de entrenamiento personalizado con Keras y MultiWorkerMirroredStrategy](multi_worker_with_ctl.ipynb) muestra cómo usar la `MultiWorkerMirroredStrategy` con Keras y un bucle de entrenamiento personalizado.\n",
        "3. Consulte los [modelos oficiales](https://github.com/tensorflow/models/tree/master/official), muchos de los cuales pueden configurarse para ejecutar múltiples estrategias de distribución.\n",
        "4. La guía [Un mejor rendimiento con tf.function](../../guide/function.ipynb) ofrece información sobre otras estrategias y herramientas, como el [Perfilador TensorFlow](../../guide/profiler.md) que puede usar para optimizar el rendimiento de sus modelos TensorFlow."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "multi_worker_with_keras.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
