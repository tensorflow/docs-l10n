{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tce3stUlHN0L"
      },
      "source": [
        "##### Copyright 2019 The TensorFlow Authors.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tuOe1ymfHZPu"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfBg1C5NB3X0"
      },
      "source": [
        "# Entrenamiento multitrabajador con Estimator\n",
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td><a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/distribute/multi_worker_with_estimator\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver en TensorFlow.org</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/es-419/tutorials/distribute/multi_worker_with_estimator.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Ejecutar en Google Colab</a></td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/es-419/tutorials/distribute/multi_worker_with_estimator.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver código fuente en GitHub</a>\n",
        "</td>\n",
        "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/es-419/tutorials/distribute/multi_worker_with_estimator.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Descargar bloc de notas</a>\n",
        "</td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_ZO8y69hs-N"
      },
      "source": [
        "> Advertencia: Los estimadores no se recomiendan para código nuevo. Los estimadores ejecutan el código de estilo `v1.Session` que es más difícil de escribir correctamente y puede tener un comportamiento inesperado; particularmente, cuando se combina con código TF 2. Los estimadores están incluidos dentro de nuestras [garantías de compatibilidad](https://tensorflow.org/guide/versions), pero no se les harán correcciones a menos que se trate de vulnerabilidades de seguridad. Para más detalles, consulte la [Guía de migración](https://tensorflow.org/guide/migrate)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHxb-dlhMIzW"
      },
      "source": [
        "## Visión general\n",
        "\n",
        "Nota: Aunque puede usar Estimators con la API `tf.distribute`, se recomienda usar Keras con `tf.distribute`, consulte [entrenamiento multitrabajador con Keras](multi_worker_with_keras.ipynb). El entrenamiento de estimadores con `tf.distribute.Strategy` tiene un soporte limitado.\n",
        "\n",
        "Este tutorial demuestra cómo se puede usar `tf.distribute.Strategy` para el entrenamiento distribuido multitrabajador con `tf.estimator`. Si escribe su código usando `tf.estimator`, y está interesado en escalar más allá de una sola máquina con alto rendimiento, este tutorial es para usted.\n",
        "\n",
        "Antes de empezar, lea la guía [estrategia de distribución](../../guide/distributed_training.ipynb). El [tutorial de entrenamiento multi-GPU](./keras.ipynb) también es relevante, porque este tutorial usa el mismo modelo.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUXex9ctTuDB"
      },
      "source": [
        "## Preparación\n",
        "\n",
        "Primero, configure TensorFlow y las importaciones necesarias."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bnYxvfLD-LW-"
      },
      "outputs": [],
      "source": [
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "\n",
        "import os, json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xicK9byC7hi"
      },
      "source": [
        "Nota: A partir de TF2.4 la estrategia multitrabajador en espejo falla con los estimadores si se ejecuta con eager habilitado (la opción predeterminada). El error en TF2.4 es `TypeError: cannot pickle '_thread.lock' object`, Véase [problema #46556](https://github.com/tensorflow/tensorflow/issues/46556) para más detalles. La solución consiste en desactivar eager execution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5dJ6UYrGDsVs"
      },
      "outputs": [],
      "source": [
        "tf.compat.v1.disable_eager_execution()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPBuZUNSZmrQ"
      },
      "source": [
        "## Función de entrada\n",
        "\n",
        "Este tutorial usa el conjunto de datos MNIST de [Conjuntos de datos de TensorFlow](https://www.tensorflow.org/datasets).  El código aquí es similar al del [tutorial de entrenamiento multi-GPU](./keras.ipynb) con una diferencia clave: cuando se usa Estimator para el entrenamiento multitrabajador, es necesario fragmentar el conjunto de datos según el número de trabajadores para asegurar la convergencia del modelo.  Los datos de entrada se fragmentan según el índice de trabajadores, de modo que cada trabajador procesa `1/num_workers` porciones distintas del conjunto de datos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dma_wUAxZqo2"
      },
      "outputs": [],
      "source": [
        "BUFFER_SIZE = 10000\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "def input_fn(mode, input_context=None):\n",
        "  datasets, info = tfds.load(name='mnist',\n",
        "                                with_info=True,\n",
        "                                as_supervised=True)\n",
        "  mnist_dataset = (datasets['train'] if mode == tf.estimator.ModeKeys.TRAIN else\n",
        "                   datasets['test'])\n",
        "\n",
        "  def scale(image, label):\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    image /= 255\n",
        "    return image, label\n",
        "\n",
        "  if input_context:\n",
        "    mnist_dataset = mnist_dataset.shard(input_context.num_input_pipelines,\n",
        "                                        input_context.input_pipeline_id)\n",
        "  return mnist_dataset.map(scale).cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BlcVXMhB59T"
      },
      "source": [
        "Otro enfoque razonable para lograr la convergencia sería barajar el conjunto de datos con semillas distintas en cada trabajador."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YFpxrcsZ2xG"
      },
      "source": [
        "## Configuración multitrabajador\n",
        "\n",
        "Una de las diferencias clave en este tutorial (en comparación con el tutorial de entrenamiento [multi-GPU](./keras.ipynb)) es la configuración multitrabajador.  La variable de entorno `TF_CONFIG` es la forma estándar de especificar la configuración del cluster a cada trabajador que forma parte del cluster.\n",
        "\n",
        "Hay dos componentes de `TF_CONFIG`: `cluster` y `task`. `cluster` ofrece información sobre todo el clúster, es decir, los trabajadores y los servidores de parámetros del clúster. `task` ofrece información sobre la tarea actual. El primer componente `cluster` es el mismo para todos los trabajadores y servidores de parámetros del cluster, y el segundo componente `task` es diferente en cada trabajador y servidor de parámetros y especifica su propio `type` y `index`. En este ejemplo, la tarea `type` es `worker` y la tarea `index` es `0`.\n",
        "\n",
        "A modo de ilustración, este tutorial muestra cómo configurar un `TF_CONFIG` con 2 trabajadores en `localhost`. En la práctica, usted crearía varios trabajadores en una dirección IP y un puerto externos, y configuraría `TF_CONFIG` en cada trabajador adecuadamente, es decir, modificaría la tarea `index`.\n",
        "\n",
        "Advertencia: *No ejecute el siguiente código en Colab.* El runtime de TensorFlow intentará crear un servidor gRPC en la dirección IP y puerto especificados, lo que probablemente fracasará. Consulte la [versión con keras](multi_worker_with_keras.ipynb) de este tutorial para un ejemplo de cómo puede probar la ejecución de múltiples trabajadores en una sola máquina.\n",
        "\n",
        "```\n",
        "os.environ['TF_CONFIG'] = json.dumps({\n",
        "    'cluster': {\n",
        "        'worker': [\"localhost:12345\", \"localhost:23456\"]\n",
        "    },\n",
        "    'task': {'type': 'worker', 'index': 0}\n",
        "})\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDreJzTffAP5"
      },
      "source": [
        "## Definir el modelo\n",
        "\n",
        "Escriba las capas, el optimizador y la función de pérdida para el entrenamiento. Este tutorial define el modelo con capas Keras, similar al [tutorial de entrenamiento multi-GPU](./keras.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WNvOn_OeiUYC"
      },
      "outputs": [],
      "source": [
        "LEARNING_RATE = 1e-4\n",
        "def model_fn(features, labels, mode):\n",
        "  model = tf.keras.Sequential([\n",
        "      tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(28, 28, 1)),\n",
        "      tf.keras.layers.MaxPooling2D(),\n",
        "      tf.keras.layers.Flatten(),\n",
        "      tf.keras.layers.Dense(64, activation='relu'),\n",
        "      tf.keras.layers.Dense(10)\n",
        "  ])\n",
        "  logits = model(features, training=False)\n",
        "\n",
        "  if mode == tf.estimator.ModeKeys.PREDICT:\n",
        "    predictions = {'logits': logits}\n",
        "    return tf.estimator.EstimatorSpec(labels=labels, predictions=predictions)\n",
        "\n",
        "  optimizer = tf.compat.v1.train.GradientDescentOptimizer(\n",
        "      learning_rate=LEARNING_RATE)\n",
        "  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "      from_logits=True, reduction=tf.keras.losses.Reduction.NONE)(labels, logits)\n",
        "  loss = tf.reduce_sum(loss) * (1. / BATCH_SIZE)\n",
        "  if mode == tf.estimator.ModeKeys.EVAL:\n",
        "    return tf.estimator.EstimatorSpec(mode, loss=loss)\n",
        "\n",
        "  return tf.estimator.EstimatorSpec(\n",
        "      mode=mode,\n",
        "      loss=loss,\n",
        "      train_op=optimizer.minimize(\n",
        "          loss, tf.compat.v1.train.get_or_create_global_step()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P94PrIW_kSCE"
      },
      "source": [
        "Nota: Aunque la tasa de aprendizaje es fija en este ejemplo, en general puede ser necesario ajustarla en función del tamaño global del lote."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhNtHfuxCGVy"
      },
      "source": [
        "## MultiWorkerMirroredStrategy\n",
        "\n",
        "Para entrenar el modelo, use una instancia de `tf.distribute.experimental.MultiWorkerMirroredStrategy`.  `MultiWorkerMirroredStrategy` crea copias de todas las variables de las capas del modelo en cada dispositivo y en todos los trabajadores. Usa `CollectiveOps`, un op de TensorFlow para la comunicación colectiva, para agregar gradientes y conservar las variables sincronizadas. La guía [`tf.distribute.Strategy`](../../guide/distributed_training.ipynb) tiene más detalles sobre esta estrategia."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1uFSHCJXMrQ-"
      },
      "outputs": [],
      "source": [
        "strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H47DDcOgfzm7"
      },
      "source": [
        "## Entrenamiento y evaluación del modelo\n",
        "\n",
        "Posteriormente, especifique la estrategia de distribución en `RunConfig` para el estimador, y entrene y evalúe invocando `tf.estimator.train_and_evaluate`. Este tutorial distribuye sólo el entrenamiento especificando la estrategia mediante `train_distribute`. También es posible distribuir la evaluación mediante `eval_distribute`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BcsuBYrpgnlS"
      },
      "outputs": [],
      "source": [
        "config = tf.estimator.RunConfig(train_distribute=strategy)\n",
        "\n",
        "classifier = tf.estimator.Estimator(\n",
        "    model_fn=model_fn, model_dir='/tmp/multiworker', config=config)\n",
        "tf.estimator.train_and_evaluate(\n",
        "    classifier,\n",
        "    train_spec=tf.estimator.TrainSpec(input_fn=input_fn),\n",
        "    eval_spec=tf.estimator.EvalSpec(input_fn=input_fn)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVk4ftYx6JAO"
      },
      "source": [
        "## Optimizar el rendimiento del entrenamiento\n",
        "\n",
        "Ahora dispone de un modelo y de un estimador con capacidad multitrabajador impulsado por `tf.distribute.Strategy`.  Puede probar las siguientes técnicas para optimizar el rendimiento del entrenamiento multitrabajador:\n",
        "\n",
        "- *Aumentar el tamaño del lote:* El tamaño de lote especificado aquí es por GPU. En general, se aconseja el mayor tamaño de lote que quepa en la memoria de la GPU.\n",
        "\n",
        "- *Casting de variables:* Hacer casting a las variables a `tf.float` si es posible. El modelo oficial de ResNet incluye [un ejemplo](https://github.com/tensorflow/models/blob/8367cf6dabe11adf7628541706b660821f397dce/official/resnet/resnet_model.py#L466) de cómo puede hacerse.\n",
        "\n",
        "- *Utilice la comunicación colectiva:* `MultiWorkerMirroredStrategy` brinda múltiples [implementaciones de comunicación colectiva](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/distribute/cross_device_ops.py).\n",
        "\n",
        "    - `RING`implementa colectivos en anillo usando gRPC como capa de comunicación entre hosts.\n",
        "    - `NCCL` usa [NCCL de Nvidia](https://developer.nvidia.com/nccl) para implementar los colectivos.\n",
        "    - `AUTO` deja la elección al runtime.\n",
        "\n",
        "    La mejor elección de la implementación de colectivos depende del número y el tipo de GPU y de la interconexión de red del cluster. Para obviar la elección automática, especifique un valor válido para el parámetro `communication` del constructor de `MultiWorkerMirroredStrategy`, por ejemplo `communication=tf.distribute.experimental.CollectiveCommunication.NCCL`.\n",
        "\n",
        "Visite la [sección de Rendimiento](../../guide/function.ipynb) de la guía para saber más sobre otras estrategias y [herramientas](../../guide/profiler.md) al alcance de su mano para optimizar el rendimiento de sus modelos TensorFlow.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AW0Hb2xM6EGX"
      },
      "source": [
        "## Otros ejemplos de código\n",
        "\n",
        "1. [Ejemplo de principio a fin](https://github.com/tensorflow/ecosystem/tree/master/distribution_strategy) para entrenamiento multitrabajador en tensorflow/ecosystem usando plantillas Kubernetes. Este ejemplo comienza con un modelo Keras y lo convierte en un Estimator usando la API `tf.keras.estimator.model_to_estimator`.\n",
        "2. [Modelos oficiales](https://github.com/tensorflow/models/tree/master/official), muchos de los cuales pueden configurarse para ejecutar múltiples estrategias de distribución.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Tce3stUlHN0L"
      ],
      "name": "multi_worker_with_estimator.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
