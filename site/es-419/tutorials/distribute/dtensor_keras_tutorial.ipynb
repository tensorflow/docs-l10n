{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tce3stUlHN0L"
      },
      "source": [
        "##### Copyright 2019 The TensorFlow Authors.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tuOe1ymfHZPu"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MT-LkFOl2axM"
      },
      "source": [
        "# Usar DTensors con Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6P32iYYV27b"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>     <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/distribute/dtensor_keras_tutorial\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver en TensorFlow.org</a> </td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/es-419/tutorials/distribute/dtensor_keras_tutorial.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Ejecutar en Google Colab</a> </td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/es-419/tutorials/distribute/dtensor_keras_tutorial.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver fuente en GitHub</a> </td>\n",
        "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/es-419/tutorials/distribute/dtensor_keras_tutorial.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Descargar cuaderno</a> </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTe9dcbUAwqx"
      },
      "source": [
        "## Visión general\n",
        "\n",
        "En este tutorial aprenderá a usar DTensor con Keras.\n",
        "\n",
        "Gracias a la integración de DTensor con Keras, puede reutilizar sus capas y modelos existentes de Keras para construir y entrenar modelos distribuidos de aprendizaje automático.\n",
        "\n",
        "Entrenará un modelo de clasificación multicapa con los datos MNIST. Se demostrará cómo configurar el modelo de subclasificación, el modelo secuencial y el modelo funcional.\n",
        "\n",
        "Este tutorial asume que ya ha leído la [Guía de programación del DTensor](/guide/dtensor_overview), y que está familiarizado con conceptos básicos del DTensor como `Mesh` y `Layout`.\n",
        "\n",
        "Este tutorial se basa en https://www.tensorflow.org/datasets/keras_example."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "keIyP3IoA1o4"
      },
      "source": [
        "## Preparar\n",
        "\n",
        "DTensor forma parte de la versión 2.9.0 de TensorFlow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4dHik7NYA5vm"
      },
      "outputs": [],
      "source": [
        "!pip install --quiet --upgrade --pre tensorflow tensorflow-datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VttBMZngDx8x"
      },
      "source": [
        "A continuación, importe `tensorflow` y `tensorflow.experimental.dtensor`, y configure TensorFlow para que use 8 CPU virtuales.\n",
        "\n",
        "Aunque este ejemplo usa CPUs, DTensor funciona igual en dispositivos con CPU, GPU o TPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CodX6idGBGSm"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.experimental import dtensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aAtvrpasDpDD"
      },
      "outputs": [],
      "source": [
        "def configure_virtual_cpus(ncpu):\n",
        "  phy_devices = tf.config.list_physical_devices('CPU')\n",
        "  tf.config.set_logical_device_configuration(\n",
        "        phy_devices[0], \n",
        "        [tf.config.LogicalDeviceConfiguration()] * ncpu)\n",
        "  \n",
        "configure_virtual_cpus(8)\n",
        "tf.config.list_logical_devices('CPU')\n",
        "\n",
        "devices = [f'CPU:{i}' for i in range(8)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogULE1OHtyd9"
      },
      "source": [
        "## Generadores de números pseudoaleatorios deterministas\n",
        "\n",
        "Algo que debe tener en cuenta es que la API DTensor requiere que cada uno de los clientes en ejecución tenga las mismas semillas aleatorias, para así poder tener un comportamiento determinista a la hora de inicializar las ponderaciones. Puede conseguirlo si establece las semillas globales en keras mediante `tf.keras.utils.set_random_seed()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9u85YypguL8N"
      },
      "outputs": [],
      "source": [
        "tf.keras.backend.experimental.enable_tf_random_generator()\n",
        "tf.keras.utils.set_random_seed(1337)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tO11XvPDAu3_"
      },
      "source": [
        "## Crear una malla Paralela de Datos\n",
        "\n",
        "Este tutorial demuestra el entrenamiento Paralelo de Datos. Adaptarse al entrenamiento Paralelo de Modelos y Paralelo Espacial puede ser tan sencillo como cambiar a un conjunto diferente de objetos `Layout`. Consulte el [Tutorial detallado de ML con DTensor](https://www.tensorflow.org/tutorials/distribute/dtensor_ml_tutorial) para saber más sobre el entrenamiento distribuido más allá de Paralelo de Datos.\n",
        "\n",
        "El entrenamiento Paralelo de Datos es un esquema de entrenamiento paralelo muy usado, que también usa, por ejemplo, `tf.distribute.MirroredStrategy`.\n",
        "\n",
        "Con DTensor, un bucle de entrenamiento Paralelo de Datos usa un `Mesh` que consiste en una única dimensión \"lote\", donde cada dispositivo ejecuta una réplica del modelo que recibe un fragmento del lote global.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6sT6s6z4j9H-"
      },
      "outputs": [],
      "source": [
        "mesh = dtensor.create_mesh([(\"batch\", 8)], devices=devices)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rouFcF6FE0aF"
      },
      "source": [
        "Como cada dispositivo ejecuta una réplica completa del modelo, las variables del modelo estarán totalmente replicadas en toda la malla (sin fragmentar). Por ejemplo, un Layout totalmente replicada para una ponderación de rango 2 en esta `Mesh` sería la siguiente:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U8OxvkDKE1Nu"
      },
      "outputs": [],
      "source": [
        "example_weight_layout = dtensor.Layout([dtensor.UNSHARDED, dtensor.UNSHARDED], mesh)  # or\n",
        "example_weight_layout = dtensor.Layout.replicated(mesh, rank=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Bnic98RE0xi"
      },
      "source": [
        "Una disposición para un tensor de datos de rango 2 en esta `Mesh` sería fragmentada a lo largo de la primera dimensión (a veces conocida como `batch_sharded`),"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PhYp0EKBFfxt"
      },
      "outputs": [],
      "source": [
        "example_data_layout = dtensor.Layout(['batch', dtensor.UNSHARDED], mesh)  # or\n",
        "example_data_layout = dtensor.Layout.batch_sharded(mesh, 'batch', rank=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4U-6n0DericV"
      },
      "source": [
        "## Crear capas Keras con disposición\n",
        "\n",
        "En el esquema paralelo de datos, normalmente usted crea las ponderaciones de su modelo con una disposición totalmente replicada, de modo que cada réplica del modelo pueda hacer cálculos con los datos de entrada fragmentados.\n",
        "\n",
        "Para configurar la información de disposición de las ponderaciones de sus capas, Keras ha expuesto un parámetro extra en el constructor de capa para la mayoría de las capas incorporadas.\n",
        "\n",
        "El siguiente ejemplo construye un pequeño modelo de clasificación de imágenes con una distribución de ponderaciones totalmente replicada. Puede especificar la información de layout `kernel` y `bias` en `tf.keras.layers.Dense` mediante los argumentos `kernel_layout` y `bias_layout`. La mayoría de las capas incorporadas de keras están preparadas para especificar explícitamente la `Layout` para las ponderaciones de la capa."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Koc5GlA1tFXY"
      },
      "outputs": [],
      "source": [
        "unsharded_layout_2d = dtensor.Layout.replicated(mesh, 2)\n",
        "unsharded_layout_1d = dtensor.Layout.replicated(mesh, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GfOGTIxGs5Ql"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "  tf.keras.layers.Dense(128, \n",
        "                        activation='relu',\n",
        "                        name='d1',\n",
        "                        kernel_layout=unsharded_layout_2d, \n",
        "                        bias_layout=unsharded_layout_1d),\n",
        "  tf.keras.layers.Dense(10,\n",
        "                        name='d2',\n",
        "                        kernel_layout=unsharded_layout_2d, \n",
        "                        bias_layout=unsharded_layout_1d)\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0frf3jsVtx_n"
      },
      "source": [
        "Puede comprobar la información sobre layout examinando la propiedad `layout` de las ponderaciones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z_nqv_VdwcXo"
      },
      "outputs": [],
      "source": [
        "for weight in model.weights:\n",
        "  print(f'Weight name: {weight.name} with layout: {weight.layout}')\n",
        "  break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FMGB-QsxPtU"
      },
      "source": [
        "## Cargar un conjunto de datos y crear una canalización de entrada\n",
        "\n",
        "Cargue un conjunto de datos MNIST y configure algunas canalizaciones de entrada de preprocesamiento para él. El conjunto de datos en sí no está asociado a ninguna información de disposición DTensor. Hay planes para mejorar la integración del DTensor Keras con `tf.data` en futuras versiones de TensorFlow.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zGt4kwltxOt4"
      },
      "outputs": [],
      "source": [
        "(ds_train, ds_test), ds_info = tfds.load(\n",
        "    'mnist',\n",
        "    split=['train', 'test'],\n",
        "    shuffle_files=True,\n",
        "    as_supervised=True,\n",
        "    with_info=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HkUaOB_ryaLH"
      },
      "outputs": [],
      "source": [
        "def normalize_img(image, label):\n",
        "  \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
        "  return tf.cast(image, tf.float32) / 255., label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Efm2H1iqydan"
      },
      "outputs": [],
      "source": [
        "batch_size = 128\n",
        "\n",
        "ds_train = ds_train.map(\n",
        "    normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "ds_train = ds_train.cache()\n",
        "ds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\n",
        "ds_train = ds_train.batch(batch_size)\n",
        "ds_train = ds_train.prefetch(tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lcrg6QAtyis4"
      },
      "outputs": [],
      "source": [
        "ds_test = ds_test.map(\n",
        "    normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "ds_test = ds_test.batch(batch_size)\n",
        "ds_test = ds_test.cache()\n",
        "ds_test = ds_test.prefetch(tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHEZwib7lhqn"
      },
      "source": [
        "## Definir la lógica de entrenamiento del modelo\n",
        "\n",
        "A continuación, defina la lógica de entrenamiento y evaluación del modelo.\n",
        "\n",
        "A partir de TensorFlow 2.9, debe escribir un bucle de entrenamiento personalizado para un modelo Keras habilitado para DTensor. Esto sirve para empaquetar los datos de entrada con la información de disposición adecuada, la cual no está integrada con las funciones estándar `tf.keras.Model.fit()` o `tf.keras.Model.eval()` de Keras. En las próximas versiones habrá más compatibilidad con `tf.data`. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CAx11gMjzzjs"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def train_step(model, x, y, optimizer, metrics):\n",
        "  with tf.GradientTape() as tape:\n",
        "    logits = model(x, training=True)\n",
        "    # tf.reduce_sum sums the batch sharded per-example loss to a replicated\n",
        "    # global loss (scalar).\n",
        "    loss = tf.reduce_sum(tf.keras.losses.sparse_categorical_crossentropy(\n",
        "        y, logits, from_logits=True))\n",
        "    \n",
        "  gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "  for metric in metrics.values():\n",
        "    metric.update_state(y_true=y, y_pred=logits)\n",
        "\n",
        "  loss_per_sample = loss / len(x)\n",
        "  results = {'loss': loss_per_sample}\n",
        "  return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "maSTWeRemO0P"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def eval_step(model, x, y, metrics):\n",
        "  logits = model(x, training=False)\n",
        "  loss = tf.reduce_sum(tf.keras.losses.sparse_categorical_crossentropy(\n",
        "        y, logits, from_logits=True))\n",
        "\n",
        "  for metric in metrics.values():\n",
        "    metric.update_state(y_true=y, y_pred=logits)\n",
        "\n",
        "  loss_per_sample = loss / len(x)\n",
        "  results = {'eval_loss': loss_per_sample}\n",
        "  return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dt00axcLmvLr"
      },
      "outputs": [],
      "source": [
        "def pack_dtensor_inputs(images, labels, image_layout, label_layout):\n",
        "  num_local_devices = image_layout.mesh.num_local_devices()\n",
        "  images = tf.split(images, num_local_devices)\n",
        "  labels = tf.split(labels, num_local_devices)\n",
        "  images = dtensor.pack(images, image_layout)\n",
        "  labels = dtensor.pack(labels, label_layout)\n",
        "  return  images, labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Eb-qIJGrxB9"
      },
      "source": [
        "## Métricas y optimizadores\n",
        "\n",
        "Cuando use la API DTensor con `Metric` y `Optimizer` de Keras, tendrá que dar la información adicional de Mesh, para que las variables de estado internas y los tensores puedan funcionar con las variables del modelo.\n",
        "\n",
        "- Para un optimizador, DTensor introduce un nuevo namespace experimental `keras.dtensor.experimental.optimizers`, donde muchos optimizadores Keras existentes se amplían para recibir un argumento adicional `mesh`. En futuras versiones, es posible que se fusione con los optimizadores centrales de Keras.\n",
        "\n",
        "- En cuanto a las métricas, puede especificar directamente la `mesh` al constructor como argumento para convertirlo en una `Metric` compatible con DTensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1lu_0mz1sxrl"
      },
      "outputs": [],
      "source": [
        "optimizer = tf.keras.dtensor.experimental.optimizers.Adam(0.01, mesh=mesh)\n",
        "metrics = {'accuracy': tf.keras.metrics.SparseCategoricalAccuracy(mesh=mesh)}\n",
        "eval_metrics = {'eval_accuracy': tf.keras.metrics.SparseCategoricalAccuracy(mesh=mesh)}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzufrkistELx"
      },
      "source": [
        "## Entrenar el modelo\n",
        "\n",
        "El siguiente ejemplo fragmenta los datos de la canalización de entrada en la dimensión de lote, y entrena con el modelo, que tiene ponderaciones totalmente replicadas.\n",
        "\n",
        "Con 3 épocas, el modelo debería alcanzar aproximadamente un 97 % de precisión."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kZW568Dk0vvL"
      },
      "outputs": [],
      "source": [
        "num_epochs = 3\n",
        "\n",
        "image_layout = dtensor.Layout.batch_sharded(mesh, 'batch', rank=4)\n",
        "label_layout = dtensor.Layout.batch_sharded(mesh, 'batch', rank=1)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  print(\"============================\") \n",
        "  print(\"Epoch: \", epoch)\n",
        "  for metric in metrics.values():\n",
        "    metric.reset_state()\n",
        "  step = 0\n",
        "  results = {}\n",
        "  pbar = tf.keras.utils.Progbar(target=None, stateful_metrics=[])\n",
        "  for input in ds_train:\n",
        "    images, labels = input[0], input[1]\n",
        "    images, labels = pack_dtensor_inputs(\n",
        "        images, labels, image_layout, label_layout)\n",
        "\n",
        "    results.update(train_step(model, images, labels, optimizer, metrics))\n",
        "    for metric_name, metric in metrics.items():\n",
        "      results[metric_name] = metric.result()\n",
        "\n",
        "    pbar.update(step, values=results.items(), finalize=False)\n",
        "    step += 1\n",
        "  pbar.update(step, values=results.items(), finalize=True)\n",
        "\n",
        "  for metric in eval_metrics.values():\n",
        "    metric.reset_state()\n",
        "  for input in ds_test:\n",
        "    images, labels = input[0], input[1]\n",
        "    images, labels = pack_dtensor_inputs(\n",
        "        images, labels, image_layout, label_layout)\n",
        "    results.update(eval_step(model, images, labels, eval_metrics))\n",
        "\n",
        "  for metric_name, metric in eval_metrics.items():\n",
        "    results[metric_name] = metric.result()\n",
        "  \n",
        "  for metric_name, metric in results.items():\n",
        "    print(f\"{metric_name}: {metric.numpy()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYEXF6qCuoSr"
      },
      "source": [
        "## Especificar Layout para código de modelo existente\n",
        "\n",
        "Muchas veces usted tiene modelos que funcionan bien para su caso de uso. Especificar la información `Layout` a cada capa individual dentro del modelo supondrá una gran cantidad de trabajo que requerirá muchas ediciones.\n",
        "\n",
        "Si quiere convertir fácilmente su modelo Keras existente para que funcione con la API DTensor, puede usar la nueva API `dtensor.LayoutMap` que le permite especificar la `Layout` desde un punto de vista global.\n",
        "\n",
        "Lo primero será crear una instancia `LayoutMap`, que es un objeto similar a un diccionario que contiene todos los `Layout` que quiera especificar para las ponderaciones de tu modelo.\n",
        "\n",
        "`LayoutMap` necesita una instancia `Mesh` en el init, que puede usarse para crear `Layout` replicados por defecto para cualquier ponderación que no tenga Layout configurado. Si quiere que todas las ponderaciones de su modelo estén totalmente replicadas, puede indicar un `LayoutMap` vacío, y la malla predeterminada se usará para crear un `Layout` replicado.\n",
        "\n",
        "`LayoutMap` usa una cadena como clave y un `Layout` como valor. Hay una diferencia de comportamiento entre un diccionario Python normal y esta clase. La cadena clave se tratará como una expresión regular al recuperar el valor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCq5Nl-UP_dS"
      },
      "source": [
        "### Modelo subclaseados\n",
        "\n",
        "Considere el siguiente modelo definido usando la sintaxis Model de subclase de Keras."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LZ0hRFs8unu0"
      },
      "outputs": [],
      "source": [
        "class SubclassedModel(tf.keras.Model):\n",
        "\n",
        "  def __init__(self, name=None):\n",
        "    super().__init__(name=name)\n",
        "    self.feature = tf.keras.layers.Dense(16)\n",
        "    self.feature_2 = tf.keras.layers.Dense(24)\n",
        "    self.dropout = tf.keras.layers.Dropout(0.1)\n",
        "\n",
        "  def call(self, inputs, training=None):\n",
        "    x = self.feature(inputs)\n",
        "    x = self.dropout(x, training=training)\n",
        "    return self.feature_2(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1njxqPB-yS97"
      },
      "source": [
        "Hay 4 ponderaciones en este modelo, que son `kernel` y `bias` para dos capas `Dense`. Cada una de ellas se mapea en función de la ruta del objeto:\n",
        "\n",
        "- `model.feature.kernel`\n",
        "- `model.feature.bias`\n",
        "- `model.feature_2.kernel`\n",
        "- `model.feature_2.bias`\n",
        "\n",
        "Nota: Para los Modelos subclaseados, se usa el nombre del atributo, en lugar del atributo `.name` de la capa, como clave para recuperar el Esquema del mapeado. Esto es consistente con la convención seguida por la aplicación de puntos de verificación de `tf.Module`. Para modelos complejos con más de unas pocas capas, puede [inspeccionar manualmente los puntos de verificación](https://www.tensorflow.org/guide/checkpoint#manually_inspecting_checkpoints) para ver los mapeos de atributos.\n",
        "\n",
        "Ahora defina el siguiente `LayoutMap` y aplíquelo al modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "goVX6iIZw468"
      },
      "outputs": [],
      "source": [
        "layout_map = tf.keras.dtensor.experimental.LayoutMap(mesh=mesh)\n",
        "\n",
        "layout_map['feature.*kernel'] = dtensor.Layout.batch_sharded(mesh, 'batch', rank=2)\n",
        "layout_map['feature.*bias'] = dtensor.Layout.batch_sharded(mesh, 'batch', rank=1)\n",
        "\n",
        "with layout_map.scope():\n",
        "  subclassed_model = SubclassedModel()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M32HcSp_PyWs"
      },
      "source": [
        "Las ponderaciones del modelo se crean en la primera llamada, así que llame al modelo con una entrada DTensor y confirme que las ponderaciones tienen las distribuciones esperadas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3CbD9l7qUNq"
      },
      "outputs": [],
      "source": [
        "dtensor_input = dtensor.copy_to_mesh(tf.zeros((16, 16)), layout=unsharded_layout_2d)\n",
        "# Trigger the weights creation for subclass model\n",
        "subclassed_model(dtensor_input)\n",
        "\n",
        "print(subclassed_model.feature.kernel.layout)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZyCnfd-4Q2jk"
      },
      "source": [
        "Así, puede mapear rápidamente el `Layout` a sus modelos sin actualizar el código existente. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GliUdWTQnKC"
      },
      "source": [
        "### Modelos Secuencial y Funcional"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zzvTqAR2Teu"
      },
      "source": [
        "Para los modelos funcional y secuencial de keras, también puede usar `LayoutMap`.\n",
        "\n",
        "Nota: Para los modelos funcional y secuencial, los mapeos son ligeramente distintos. Las capas del modelo no tienen un atributo público asociado al modelo (aunque puede acceder a ellas a través de `model.layers` como una lista). Use el nombre de la cadena como clave en este caso. Se garantiza que el nombre de la cadena es único dentro de un modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gXK2EquIRJCC"
      },
      "outputs": [],
      "source": [
        "layout_map = tf.keras.dtensor.experimental.LayoutMap(mesh=mesh)\n",
        "\n",
        "layout_map['feature.*kernel'] = dtensor.Layout.batch_sharded(mesh, 'batch', rank=2)\n",
        "layout_map['feature.*bias'] = dtensor.Layout.batch_sharded(mesh, 'batch', rank=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cBzwJqrg2TH3"
      },
      "outputs": [],
      "source": [
        "with layout_map.scope():\n",
        "  inputs = tf.keras.Input((16,), batch_size=16)\n",
        "  x = tf.keras.layers.Dense(16, name='feature')(inputs)\n",
        "  x = tf.keras.layers.Dropout(0.1)(x)\n",
        "  output = tf.keras.layers.Dense(32, name='feature_2')(x)\n",
        "  model = tf.keras.Model(inputs, output)\n",
        "\n",
        "print(model.layers[1].kernel.layout)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pPuh1NlE3-wO"
      },
      "outputs": [],
      "source": [
        "with layout_map.scope():\n",
        "  model = tf.keras.Sequential([\n",
        "      tf.keras.layers.Dense(16, name='feature', input_shape=(16,)),\n",
        "      tf.keras.layers.Dropout(0.1),\n",
        "      tf.keras.layers.Dense(32, name='feature_2')\n",
        "  ])\n",
        "\n",
        "print(model.layers[2].kernel.layout)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "dtensor_keras_tutorial.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
