{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tce3stUlHN0L"
      },
      "source": [
        "##### Copyright 2019 The TensorFlow Authors.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tuOe1ymfHZPu"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfBg1C5NB3X0"
      },
      "source": [
        "# Bucle de entrenamiento personalizado con Keras y MultiWorkerMirroredStrategy\n",
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td><a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/distribute/multi_worker_with_ctl\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver en TensorFlow.org</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/es-419/tutorials/distribute/multi_worker_with_ctl.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Ejecutar en Google Colab</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/es-419/tutorials/distribute/multi_worker_with_ctl.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver fuente en GitHub</a></td>\n",
        "  <td><a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/es-419/tutorials/distribute/multi_worker_with_ctl.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Descargar bloc de notas</a></td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHxb-dlhMIzW"
      },
      "source": [
        "## Descripción general\n",
        "\n",
        "Este tutorial muestra cómo realizar un entrenamiento distribuido multitrabajador con un modelo Keras y con [bucles de entrenamiento personalizados](https://www.tensorflow.org/guide/keras/writing_a_training_loop_from_scratch) utilizando la API `tf.distribute.Strategy`. El bucle de entrenamiento se distribuye a través de `tf.distribute.MultiWorkerMirroredStrategy`, por lo que un modelo `tf.keras` (diseñado para ejecutarse en [un solo trabajador](custom_training.ipynb)) puede funcionar sin problemas en múltiples trabajadores con cambios mínimos en el código. Los bucles de entrenamiento personalizados aportan flexibilidad y un mayor control sobre el entrenamiento, a la vez que facilitan la depuración del modelo. Aprenda más sobre [cómo escribir un bucle de entrenamiento básico](../../guide/basic_training_loops.ipynb), [cómo escribir un bucle de entrenamiento desde cero](https://www.tensorflow.org/guide/keras/writing_a_training_loop_from_scratch) y [entrenamiento personalizado](../customization/custom_training_walkthrough.ipynb).\n",
        "\n",
        "Si está buscando cómo usar `MultiWorkerMirroredStrategy` con `tf.keras.Model.fit`, consulte en su lugar este [tutorial](multi_worker_with_keras.ipynb).\n",
        "\n",
        "Para aquellos interesados en una comprensión más profunda de las APIs `tf.distribute.Strategy` está disponible la [Guía de entrenamiento distribuido en TensorFlow](../../guide/distributed_training.ipynb) para una visión general de las estrategias de distribución que TensorFlow soporta."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUXex9ctTuDB"
      },
      "source": [
        "## Preparación\n",
        "\n",
        "En primer lugar, algunas importaciones necesarias."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bnYxvfLD-LW-"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "import sys"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zz0EY91y3mxy"
      },
      "source": [
        "Antes de importar TensorFlow, realice algunos cambios en el entorno:\n",
        "\n",
        "- Desactive todas las GPU. Esto evita errores causados por todos los trabajadores tratando de usar la misma GPU. En una aplicación del mundo real, cada trabajador estaría en una máquina diferente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "685pbYEY3jGC"
      },
      "outputs": [],
      "source": [
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7X1MS6385BWi"
      },
      "source": [
        "- Restablezca la variable de entorno `'TF_CONFIG'` (verá más sobre esto más adelante)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WEJLYa2_7OZF"
      },
      "outputs": [],
      "source": [
        "os.environ.pop('TF_CONFIG', None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rd4L9Ii77SS8"
      },
      "source": [
        "- Asegúrese de que el directorio actual está en la ruta de Python. Esto permitirá al bloc de notas importar posteriormente los archivos escritos por `%%writefile`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hPBuZUNSZmrQ"
      },
      "outputs": [],
      "source": [
        "if '.' not in sys.path:\n",
        "  sys.path.insert(0, '.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDhHuMjb7bfU"
      },
      "source": [
        "Ahora importe TensorFlow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vHNvttzV43sA"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0S2jpf6Sx50i"
      },
      "source": [
        "### Definición del conjunto de datos y del modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLW6D2TzvC-4"
      },
      "source": [
        "A continuación, cree un archivo `mnist.py` con un modelo simple y la configuración del conjunto de datos. Este archivo Python será usado por los procesos-trabajadores de este tutorial:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dma_wUAxZqo2"
      },
      "outputs": [],
      "source": [
        "%%writefile mnist.py\n",
        "\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "def mnist_dataset(batch_size):\n",
        "  (x_train, y_train), _ = tf.keras.datasets.mnist.load_data()\n",
        "  # The `x` arrays are in uint8 and have values in the range [0, 255].\n",
        "  # You need to convert them to float32 with values in the range [0, 1]\n",
        "  x_train = x_train / np.float32(255)\n",
        "  y_train = y_train.astype(np.int64)\n",
        "  train_dataset = tf.data.Dataset.from_tensor_slices(\n",
        "      (x_train, y_train)).shuffle(60000)\n",
        "  return train_dataset\n",
        "\n",
        "def dataset_fn(global_batch_size, input_context):\n",
        "  batch_size = input_context.get_per_replica_batch_size(global_batch_size)\n",
        "  dataset = mnist_dataset(batch_size)\n",
        "  dataset = dataset.shard(input_context.num_input_pipelines,\n",
        "                          input_context.input_pipeline_id)\n",
        "  dataset = dataset.batch(batch_size)\n",
        "  return dataset\n",
        "\n",
        "def build_cnn_model():\n",
        "  regularizer = tf.keras.regularizers.L2(1e-5)\n",
        "  return tf.keras.Sequential([\n",
        "      tf.keras.Input(shape=(28, 28)),\n",
        "      tf.keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
        "      tf.keras.layers.Conv2D(32, 3,\n",
        "                             activation='relu',\n",
        "                             kernel_regularizer=regularizer),\n",
        "      tf.keras.layers.Flatten(),\n",
        "      tf.keras.layers.Dense(128,\n",
        "                            activation='relu',\n",
        "                            kernel_regularizer=regularizer),\n",
        "      tf.keras.layers.Dense(10, kernel_regularizer=regularizer)\n",
        "  ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmgZwwymxqt5"
      },
      "source": [
        "## Configuración multitrabajador\n",
        "\n",
        "Entremos ahora en el mundo del entrenamiento multitrabajador. En TensorFlow, la variable de entorno `'TF_CONFIG'` es necesaria para el entrenamiento en múltiples máquinas. Cada máquina puede tener un rol diferente. La variable `'TF_CONFIG'` que se usa a continuación es una cadena JSON que especifica la configuración del cluster en cada trabajador que forma parte del cluster. Este es el método predeterminado para especificar un clúster, usando `cluster_resolver.TFConfigClusterResolver`, pero hay otras opciones disponibles en el módulo `distribute.cluster_resolver`. Obtenga más información sobre el ajuste de la variable `'TF_CONFIG'` en la [Guía de entrenamiento de distribución](../../guide/distributed_training.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SS8WhvRhe_Ya"
      },
      "source": [
        "### Describa su clúster\n",
        "\n",
        "Esta es una configuración de ejemplo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XK1eTYvSZiX7"
      },
      "outputs": [],
      "source": [
        "tf_config = {\n",
        "    'cluster': {\n",
        "        'worker': ['localhost:12345', 'localhost:23456']\n",
        "    },\n",
        "    'task': {'type': 'worker', 'index': 0}\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjgwJbPKZkJL"
      },
      "source": [
        "Tenga en cuenta que `tf_config` es sólo una variable local en Python. Para usarla para la configuración del entrenamiento, serialícela como JSON y colóquela en una variable de entorno `'TF_CONFIG'`. Aquí está el mismo `'TF_CONFIG'` serializado como una cadena JSON:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yY-T0YDQZjbu"
      },
      "outputs": [],
      "source": [
        "json.dumps(tf_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUBmYRZqxthH"
      },
      "source": [
        "Hay dos componentes de la `'TF_CONFIG'`: `'cluster'` y `'task'`.\n",
        "\n",
        "- `'cluster'` es el mismo para todos los trabajadores y da información sobre el cluster de entrenamiento, que es un dict formado por diferentes tipos de trabajos como `'worker'`. En el entrenamiento multitrabajador con `MultiWorkerMirroredStrategy`, suele haber un `'worker'` que asume un poco más de responsabilidad, como guardar puntos de verificación y escribir archivos de resumen para TensorBoard, además de lo que hace un `'worker'` normal. A dicho trabajador se le llama `'chief'`, y es habitual que el `'worker'` con `'index'` 0 sea el designado como `worker` chief o \"jefe\".\n",
        "\n",
        "- `'task'` da información de la tarea actual y es diferente en cada trabajador. Especifica el `'type'` y el `'index'` de ese trabajador."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YFpxrcsZ2xG"
      },
      "source": [
        "En este ejemplo, se pone el `'type'` de la tarea como `'worker'` y el `'index'` de la tarea como `0`. Esta máquina es el primer trabajador y será designada como trabajador chief y realizará más trabajo que las demás. Tenga en cuenta que las demás máquinas también deberán tener configurada la variable de entorno `'TF_CONFIG'` y deberá tener el mismo dict `'cluster'`, pero diferente `'type'` de tarea o `'index'` de tarea dependiendo de cuáles sean los roles de esas máquinas.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aogb74kHxynz"
      },
      "source": [
        "Para fines ilustrativos, este tutorial muestra cómo se puede establecer un `'TF_CONFIG'` con dos trabajadores en `'localhost'`.  En la práctica, los usuarios crearían múltiples trabajadores en direcciones IP/puertos externos, y configurarían `'TF_CONFIG'` en cada trabajador apropiadamente.\n",
        "\n",
        "Este ejemplo usa dos trabajadores. El `'TF_CONFIG'` del primer trabajador se muestra arriba. Para el segundo trabajador, configure `tf_config['task']['index']=1`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cIlkfWmjz1PG"
      },
      "source": [
        "### Variables de entorno y subprocesos en blocs de notas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcjAbuGY1ACJ"
      },
      "source": [
        "Los subprocesos heredan las variables de entorno de su padre. Así que si configura una variable de entorno en este proceso de bloc de notas Jupyter:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PH2gHn2_0_U8"
      },
      "outputs": [],
      "source": [
        "os.environ['GREETINGS'] = 'Hello TensorFlow!'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQkIX-cg18md"
      },
      "source": [
        "podrá acceder a la variable de entorno desde un subproceso:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pquKO6IA18G5"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "echo ${GREETINGS}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "af6BCA-Y2fpz"
      },
      "source": [
        "En la siguiente sección, usará esto para pasar el `'TF_CONFIG'` a los subprocesos de los trabajadores. Realmente usted nunca iniciaría sus trabajos de esta manera, pero es suficiente para los propósitos de este tutorial: demostrar un ejemplo mínimo de multitrabajador."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhNtHfuxCGVy"
      },
      "source": [
        "## MultiWorkerMirroredStrategy\n",
        "\n",
        "Antes de entrenar el modelo, cree primero una instancia de `tf.distribute.MultiWorkerMirroredStrategy`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1uFSHCJXMrQ-"
      },
      "outputs": [],
      "source": [
        "strategy = tf.distribute.MultiWorkerMirroredStrategy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0iv7SyyAohc"
      },
      "source": [
        "Nota: `'TF_CONFIG'` se parsea y los servidores GRPC de TensorFlow se inician en el momento en que usted llama a `tf.distribute.MultiWorkerMirroredStrategy.` Por lo tanto, debe establecer la variable de entorno `'TF_CONFIG'` antes de instanciar una `tf.distribute.Strategy`. Para ganar tiempo en este ejemplo ilustrativo, esto no se demuestra en este tutorial, para que no tenga que iniciar los servidores. Puede encontrar un ejemplo completo en la última sección de este tutorial."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TS4S-faBHHam"
      },
      "source": [
        "Utilice `tf.distribute.Strategy.scope` para especificar que se debe usar una estrategia al construir su modelo. Esto permitirá que la estrategia regule aspectos como la ubicación de las variables: creará copias de todas las variables de las capas del modelo en cada dispositivo de todos los trabajadores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nXV49tG1_opc"
      },
      "outputs": [],
      "source": [
        "import mnist\n",
        "with strategy.scope():\n",
        "  # Model building needs to be within `strategy.scope()`.\n",
        "  multi_worker_model = mnist.build_cnn_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSYkM-on6r3Y"
      },
      "source": [
        "## Fragmentar datos automáticamente entre los trabajadores\n",
        "\n",
        "En el entrenamiento multitrabajador, *se necesita fragmentar el conjunto de datos* para garantizar la convergencia y la reproducibilidad. Fragmentar significa entregar a cada trabajador un subconjunto de todo el conjunto de datos -ayuda a crear una experiencia similar al entrenamiento en un solo trabajador. En el ejemplo siguiente, se utiliza la política predeterminada de autofragmentación de `tf.distribute`. También puede personalizarla configurando la `tf.data.experimental.AutoShardPolicy` de las `tf.data.experimental.DistributeOptions`. Para obtener más información, consulte la sección *Fragmentación* del [Tutorial de entrada distribuida](input.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "65-p36pt6rUF"
      },
      "outputs": [],
      "source": [
        "per_worker_batch_size = 64\n",
        "num_workers = len(tf_config['cluster']['worker'])\n",
        "global_batch_size = per_worker_batch_size * num_workers\n",
        "\n",
        "with strategy.scope():\n",
        "  multi_worker_dataset = strategy.distribute_datasets_from_function(\n",
        "      lambda input_context: mnist.dataset_fn(global_batch_size, input_context))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkNzSR3g60iP"
      },
      "source": [
        "## Definir un bucle de entrenamiento personalizado y entrenar el modelo\n",
        "\n",
        "Especifique un optimizador:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NoMr4_zTeKSn"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "  # The creation of optimizer and train_accuracy needs to be in\n",
        "  # `strategy.scope()` as well, since they create variables.\n",
        "  optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.001)\n",
        "  train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
        "      name='train_accuracy')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmrDcAii4B5O"
      },
      "source": [
        "Defina un paso de entrenamiento con `tf.function`:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "znXWN5S3eUDB"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def train_step(iterator):\n",
        "  \"\"\"Training step function.\"\"\"\n",
        "\n",
        "  def step_fn(inputs):\n",
        "    \"\"\"Per-Replica step function.\"\"\"\n",
        "    x, y = inputs\n",
        "    with tf.GradientTape() as tape:\n",
        "      predictions = multi_worker_model(x, training=True)\n",
        "      per_example_loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "          from_logits=True,\n",
        "          reduction=tf.keras.losses.Reduction.NONE)(y, predictions)\n",
        "      loss = tf.nn.compute_average_loss(per_example_loss)\n",
        "      model_losses = multi_worker_model.losses\n",
        "      if model_losses:\n",
        "        loss += tf.nn.scale_regularization_loss(tf.add_n(model_losses))\n",
        "\n",
        "    grads = tape.gradient(loss, multi_worker_model.trainable_variables)\n",
        "    optimizer.apply_gradients(\n",
        "        zip(grads, multi_worker_model.trainable_variables))\n",
        "    train_accuracy.update_state(y, predictions)\n",
        "    return loss\n",
        "\n",
        "  per_replica_losses = strategy.run(step_fn, args=(next(iterator),))\n",
        "  return strategy.reduce(\n",
        "      tf.distribute.ReduceOp.SUM, per_replica_losses, axis=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFXHsUVBy0Rx"
      },
      "source": [
        "### Guardado y restauración del punto de verificación\n",
        "\n",
        "Al escribir un bucle de entrenamiento personalizado, deberá gestionar [el guardado de puntos de verificación](../../guide/checkpoint.ipynb) manualmente en lugar de confiar en una retrollamada de Keras. Tenga en cuenta que para `MultiWorkerMirroredStrategy`, guardar un punto de verificación o un modelo completo requiere la participación de todos los trabajadores, porque intentar guardar sólo en el trabajador jefe podría llevar a un punto muerto. Los trabajadores también necesitan escribir en rutas diferentes para evitar sobrescribirse unos a otros. Aquí tiene un ejemplo de cómo configurar los directorios:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LcFO6x1KyjhI"
      },
      "outputs": [],
      "source": [
        "from multiprocessing import util\n",
        "checkpoint_dir = os.path.join(util.get_temp_dir(), 'ckpt')\n",
        "\n",
        "def _is_chief(task_type, task_id, cluster_spec):\n",
        "  return (task_type is None\n",
        "          or task_type == 'chief'\n",
        "          or (task_type == 'worker'\n",
        "              and task_id == 0\n",
        "              and \"chief\" not in cluster_spec.as_dict()))\n",
        "\n",
        "def _get_temp_dir(dirpath, task_id):\n",
        "  base_dirpath = 'workertemp_' + str(task_id)\n",
        "  temp_dir = os.path.join(dirpath, base_dirpath)\n",
        "  tf.io.gfile.makedirs(temp_dir)\n",
        "  return temp_dir\n",
        "\n",
        "def write_filepath(filepath, task_type, task_id, cluster_spec):\n",
        "  dirpath = os.path.dirname(filepath)\n",
        "  base = os.path.basename(filepath)\n",
        "  if not _is_chief(task_type, task_id, cluster_spec):\n",
        "    dirpath = _get_temp_dir(dirpath, task_id)\n",
        "  return os.path.join(dirpath, base)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nrcdPHtG4ObO"
      },
      "source": [
        "Cree un `tf.train.Checkpoint` que realice el seguimiento del modelo, administrado por un `tf.train.CheckpointManager`, de forma que sólo se conserven los últimos puntos de verificación:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4rURT2pI4aqV"
      },
      "outputs": [],
      "source": [
        "epoch = tf.Variable(\n",
        "    initial_value=tf.constant(0, dtype=tf.dtypes.int64), name='epoch')\n",
        "step_in_epoch = tf.Variable(\n",
        "    initial_value=tf.constant(0, dtype=tf.dtypes.int64),\n",
        "    name='step_in_epoch')\n",
        "task_type, task_id = (strategy.cluster_resolver.task_type,\n",
        "                      strategy.cluster_resolver.task_id)\n",
        "# Normally, you don't need to manually instantiate a `ClusterSpec`, but in this\n",
        "# illustrative example you did not set `'TF_CONFIG'` before initializing the\n",
        "# strategy. Check out the next section for \"real-world\" usage.\n",
        "cluster_spec = tf.train.ClusterSpec(tf_config['cluster'])\n",
        "\n",
        "checkpoint = tf.train.Checkpoint(\n",
        "    model=multi_worker_model, epoch=epoch, step_in_epoch=step_in_epoch)\n",
        "\n",
        "write_checkpoint_dir = write_filepath(checkpoint_dir, task_type, task_id,\n",
        "                                      cluster_spec)\n",
        "checkpoint_manager = tf.train.CheckpointManager(\n",
        "    checkpoint, directory=write_checkpoint_dir, max_to_keep=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RO7cbN40XD5v"
      },
      "source": [
        "Ahora, cuando necesite restaurar un punto de verificación, podrá encontrar el último punto de verificación guardado usando la práctica función `tf.train.latest_checkpoint` (o llamando a `tf.train.CheckpointManager.restore_or_initialize`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gniynaQj6HMV"
      },
      "outputs": [],
      "source": [
        "latest_checkpoint = tf.train.latest_checkpoint(checkpoint_dir)\n",
        "if latest_checkpoint:\n",
        "  checkpoint.restore(latest_checkpoint)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1j9JuI-h6ObW"
      },
      "source": [
        "Tras restablecer el punto de verificación, podrá continuar con el entrenamiento de su bucle de entrenamiento personalizado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kZzXZCh45FY6"
      },
      "outputs": [],
      "source": [
        "num_epochs = 3\n",
        "num_steps_per_epoch = 70\n",
        "\n",
        "while epoch.numpy() < num_epochs:\n",
        "  iterator = iter(multi_worker_dataset)\n",
        "  total_loss = 0.0\n",
        "  num_batches = 0\n",
        "\n",
        "  while step_in_epoch.numpy() < num_steps_per_epoch:\n",
        "    total_loss += train_step(iterator)\n",
        "    num_batches += 1\n",
        "    step_in_epoch.assign_add(1)\n",
        "\n",
        "  train_loss = total_loss / num_batches\n",
        "  print('Epoch: %d, accuracy: %f, train_loss: %f.'\n",
        "                %(epoch.numpy(), train_accuracy.result(), train_loss))\n",
        "\n",
        "  train_accuracy.reset_states()\n",
        "\n",
        "  # Once the `CheckpointManager` is set up, you're now ready to save, and remove\n",
        "  # the checkpoints non-chief workers saved.\n",
        "  checkpoint_manager.save()\n",
        "  if not _is_chief(task_type, task_id, cluster_spec):\n",
        "    tf.io.gfile.rmtree(write_checkpoint_dir)\n",
        "\n",
        "  epoch.assign_add(1)\n",
        "  step_in_epoch.assign(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0W1Osks466DE"
      },
      "source": [
        "## Código completo de un vistazo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfYpmIxO6Jck"
      },
      "source": [
        "Para resumir todos los procedimientos analizados hasta ahora:\n",
        "\n",
        "1. Cree procesos de trabajo.\n",
        "2. Pase `'TF_CONFIG'`s a los procesos trabajadores.\n",
        "3. Deje que cada proceso trabajador ejecute el script de abajo que contiene el código de entrenamiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MIDCESkVzN6M"
      },
      "outputs": [],
      "source": [
        "%%writefile main.py\n",
        "#@title File: `main.py`\n",
        "import os\n",
        "import json\n",
        "import tensorflow as tf\n",
        "import mnist\n",
        "from multiprocessing import util\n",
        "\n",
        "per_worker_batch_size = 64\n",
        "tf_config = json.loads(os.environ['TF_CONFIG'])\n",
        "num_workers = len(tf_config['cluster']['worker'])\n",
        "global_batch_size = per_worker_batch_size * num_workers\n",
        "\n",
        "num_epochs = 3\n",
        "num_steps_per_epoch=70\n",
        "\n",
        "# Checkpoint saving and restoring\n",
        "def _is_chief(task_type, task_id, cluster_spec):\n",
        "  return (task_type is None\n",
        "          or task_type == 'chief'\n",
        "          or (task_type == 'worker'\n",
        "              and task_id == 0\n",
        "              and 'chief' not in cluster_spec.as_dict()))\n",
        "\n",
        "def _get_temp_dir(dirpath, task_id):\n",
        "  base_dirpath = 'workertemp_' + str(task_id)\n",
        "  temp_dir = os.path.join(dirpath, base_dirpath)\n",
        "  tf.io.gfile.makedirs(temp_dir)\n",
        "  return temp_dir\n",
        "\n",
        "def write_filepath(filepath, task_type, task_id, cluster_spec):\n",
        "  dirpath = os.path.dirname(filepath)\n",
        "  base = os.path.basename(filepath)\n",
        "  if not _is_chief(task_type, task_id, cluster_spec):\n",
        "    dirpath = _get_temp_dir(dirpath, task_id)\n",
        "  return os.path.join(dirpath, base)\n",
        "\n",
        "checkpoint_dir = os.path.join(util.get_temp_dir(), 'ckpt')\n",
        "\n",
        "# Define Strategy\n",
        "strategy = tf.distribute.MultiWorkerMirroredStrategy()\n",
        "\n",
        "with strategy.scope():\n",
        "  # Model building/compiling need to be within `tf.distribute.Strategy.scope`.\n",
        "  multi_worker_model = mnist.build_cnn_model()\n",
        "\n",
        "  multi_worker_dataset = strategy.distribute_datasets_from_function(\n",
        "      lambda input_context: mnist.dataset_fn(global_batch_size, input_context))\n",
        "  optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.001)\n",
        "  train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
        "      name='train_accuracy')\n",
        "\n",
        "@tf.function\n",
        "def train_step(iterator):\n",
        "  \"\"\"Training step function.\"\"\"\n",
        "\n",
        "  def step_fn(inputs):\n",
        "    \"\"\"Per-Replica step function.\"\"\"\n",
        "    x, y = inputs\n",
        "    with tf.GradientTape() as tape:\n",
        "      predictions = multi_worker_model(x, training=True)\n",
        "      per_example_loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "          from_logits=True,\n",
        "          reduction=tf.keras.losses.Reduction.NONE)(y, predictions)\n",
        "      loss = tf.nn.compute_average_loss(per_example_loss)\n",
        "      model_losses = multi_worker_model.losses\n",
        "      if model_losses:\n",
        "        loss += tf.nn.scale_regularization_loss(tf.add_n(model_losses))\n",
        "\n",
        "    grads = tape.gradient(loss, multi_worker_model.trainable_variables)\n",
        "    optimizer.apply_gradients(\n",
        "        zip(grads, multi_worker_model.trainable_variables))\n",
        "    train_accuracy.update_state(y, predictions)\n",
        "\n",
        "    return loss\n",
        "\n",
        "  per_replica_losses = strategy.run(step_fn, args=(next(iterator),))\n",
        "  return strategy.reduce(\n",
        "      tf.distribute.ReduceOp.SUM, per_replica_losses, axis=None)\n",
        "\n",
        "epoch = tf.Variable(\n",
        "    initial_value=tf.constant(0, dtype=tf.dtypes.int64), name='epoch')\n",
        "step_in_epoch = tf.Variable(\n",
        "    initial_value=tf.constant(0, dtype=tf.dtypes.int64),\n",
        "    name='step_in_epoch')\n",
        "\n",
        "task_type, task_id, cluster_spec = (strategy.cluster_resolver.task_type,\n",
        "                                    strategy.cluster_resolver.task_id,\n",
        "                                    strategy.cluster_resolver.cluster_spec())\n",
        "\n",
        "checkpoint = tf.train.Checkpoint(\n",
        "    model=multi_worker_model, epoch=epoch, step_in_epoch=step_in_epoch)\n",
        "\n",
        "write_checkpoint_dir = write_filepath(checkpoint_dir, task_type, task_id,\n",
        "                                      cluster_spec)\n",
        "checkpoint_manager = tf.train.CheckpointManager(\n",
        "    checkpoint, directory=write_checkpoint_dir, max_to_keep=1)\n",
        "\n",
        "# Restoring the checkpoint\n",
        "latest_checkpoint = tf.train.latest_checkpoint(checkpoint_dir)\n",
        "if latest_checkpoint:\n",
        "  checkpoint.restore(latest_checkpoint)\n",
        "\n",
        "# Resume our CTL training\n",
        "while epoch.numpy() < num_epochs:\n",
        "  iterator = iter(multi_worker_dataset)\n",
        "  total_loss = 0.0\n",
        "  num_batches = 0\n",
        "\n",
        "  while step_in_epoch.numpy() < num_steps_per_epoch:\n",
        "    total_loss += train_step(iterator)\n",
        "    num_batches += 1\n",
        "    step_in_epoch.assign_add(1)\n",
        "\n",
        "  train_loss = total_loss / num_batches\n",
        "  print('Epoch: %d, accuracy: %f, train_loss: %f.'\n",
        "                %(epoch.numpy(), train_accuracy.result(), train_loss))\n",
        "\n",
        "  train_accuracy.reset_states()\n",
        "\n",
        "  checkpoint_manager.save()\n",
        "  if not _is_chief(task_type, task_id, cluster_spec):\n",
        "    tf.io.gfile.rmtree(write_checkpoint_dir)\n",
        "\n",
        "  epoch.assign_add(1)\n",
        "  step_in_epoch.assign(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ItVOvPN1qnZ6"
      },
      "source": [
        "El directorio actual contiene ahora ambos archivos Python:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bi6x05Sr60O9"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "ls *.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmEEStPS6vR_"
      },
      "source": [
        "Entonces, serialice el `'TF_CONFIG'` a JSON y añádalo a las variables de entorno:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9uu3g7vV7Bbt"
      },
      "outputs": [],
      "source": [
        "os.environ['TF_CONFIG'] = json.dumps(tf_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MsY3dQLK7jdf"
      },
      "source": [
        "Ahora, puede lanzar un proceso trabajador que ejecutará el `main.py` y usará el `'TF_CONFIG'`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "txMXaq8d8N_S"
      },
      "outputs": [],
      "source": [
        "# first kill any previous runs\n",
        "%killbgscripts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qnSma_Ck7r-r"
      },
      "outputs": [],
      "source": [
        "%%bash --bg\n",
        "python main.py &> job_0.log"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZChyazqS7v0P"
      },
      "source": [
        "Hay que tener en cuenta algunas cosas sobre el comando anterior:\n",
        "\n",
        "1. Usa el `%%bash` que es [\"magia\" de bloc de notas](https://ipython.readthedocs.io/en/stable/interactive/magics.html) para ejecutar algunos comandos bash.\n",
        "2. Usa el indicador `--bg` para ejecutar el proceso `bash` en segundo plano, porque este trabajador no terminará. Espera a todos los trabajadores antes de iniciarse.\n",
        "\n",
        "El proceso trabajador en segundo plano no imprimirá la salida en este bloc de notas. El `&>` redirige su salida a un archivo, para que pueda inspeccionar lo sucedido.\n",
        "\n",
        "Espere unos segundos a que se inicie el proceso:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hm2yrULE9281"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "time.sleep(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFPoNxg_9_Mx"
      },
      "source": [
        "Ahora, revise la salida al archivo de registro del trabajador hasta el momento:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vZEOuVgQ9-hn"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "cat job_0.log"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqZhVF7L_KOy"
      },
      "source": [
        "La última línea del archivo de registro debería decir: `Started server with target: grpc://localhost:12345`. El primer trabajador ya está listo y está esperando a que todos los demás trabajadores estén listos para continuar."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pi8vPNNA_l4a"
      },
      "source": [
        "Actualice el `tf_config` para que el proceso del segundo trabajador prosiga desde ahí:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lAiYkkPu_Jqd"
      },
      "outputs": [],
      "source": [
        "tf_config['task']['index'] = 1\n",
        "os.environ['TF_CONFIG'] = json.dumps(tf_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0AshGVO0_x0w"
      },
      "source": [
        "Ahora lance el segundo trabajador. Esto iniciará el entrenamiento ya que todos los trabajadores están activos (por lo que no es necesario poner este proceso en segundo plano):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ESVtyQ9_xjx"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "python main.py > /dev/null 2>&1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hX4FA2O2AuAn"
      },
      "source": [
        "Si vuelve a revisar los registros escritos por el primer trabajador, observará que participó en el entrenamiento de ese modelo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rc6hw3yTBKXX"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "cat job_0.log"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sG5_1UgrgniF"
      },
      "outputs": [],
      "source": [
        "# Delete the `'TF_CONFIG'`, and kill any background tasks so they don't affect the next section.\n",
        "os.environ.pop('TF_CONFIG', None)\n",
        "%killbgscripts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhxMXa0AaZkK"
      },
      "source": [
        "## Entrenamiento multitrabajador a fondo\n",
        "\n",
        "Este tutorial ha demostrado un flujo de trabajo de bucle de entrenamiento personalizado de la configuración multitrabajador. Encontrará descripciones detalladas de otros temas en el tutorial [Entrenamiento multitrabajador con (`tf.keras.Model.fit`) de Keras](multi_worker_with_keras.ipynb) aplicable a los bucles de entrenamiento personalizados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ega2hdOQEmy_"
      },
      "source": [
        "## Más información\n",
        "\n",
        "1. La guía [Entrenamiento distribuido en TensorFlow](../../guide/distributed_training.ipynb) proporciona una visión general de las estrategias de distribución disponibles.\n",
        "2. [Modelos oficiales](https://github.com/tensorflow/models/tree/master/official), muchos de los cuales pueden configurarse para ejecutar múltiples estrategias de distribución.\n",
        "3. La [sección Rendimiento](../../guide/function.ipynb) de la guía `tf.function` proporciona información sobre otras estrategias y [herramientas](../../guide/profiler.md) que puede usar para optimizar el rendimiento de sus modelos TensorFlow.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "multi_worker_with_ctl.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
