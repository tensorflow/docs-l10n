{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0DH9bjZD_Cfi"
      },
      "source": [
        "##### Copyright 2021 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "JO1GUwC1_T2x"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4xOsFiu-1-c"
      },
      "source": [
        "# Generar música con una RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OyzAxV7Vu_9Y"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>     <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/audio/music_generation\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver en TensorFlow.org</a> </td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/es-419/tutorials/audio/music_generation.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Ejecutar en Google Colab</a> </td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/es-419/tutorials/audio/music_generation.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver fuente en GitHub</a> </td>\n",
        "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/es-419/tutorials/audio/music_generation.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Descargar cuaderno</a> </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hr78EkAY-FFg"
      },
      "source": [
        "Este tutorial usa una sencilla red neuronal recurrente (RNN) para generar notas musicales. Usted entrenará un modelo usando una colección de archivos MIDI de piano del [conjunto de datos MAESTRO](https://magenta.tensorflow.org/datasets/maestro). Su modelo aprenderá a predecir la siguiente nota de la secuencia, dada una secuencia de notas. Llame repetidamente al modelo para generar secuencias de notas más largas.\n",
        "\n",
        "Este tutorial contiene el código completo para parsear y generar archivos MIDI. Consulte el tutorial [Generación de texto con una RNN](https://www.tensorflow.org/text/tutorials/text_generation) para saber más sobre cómo funcionan las RNN."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZniYb7Y_0Ey"
      },
      "source": [
        "## Preparación"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ks8__E_WUGt"
      },
      "source": [
        "Este tutorial usa la librería [`pretty_midi`](https://github.com/craffel/pretty-midi) para crear y parsear archivos MIDI, y [`pyfluidsynth`](https://github.com/nwhitehead/pyfluidsynth) para generar la reproducción de audio en Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kahm6Z8v_TqC"
      },
      "outputs": [],
      "source": [
        "!sudo apt install -y fluidsynth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M0lAReB7_Vqb"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade pyfluidsynth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G46kKoQZmIa8"
      },
      "outputs": [],
      "source": [
        "!pip install pretty_midi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GsLFq7nsiqcq"
      },
      "outputs": [],
      "source": [
        "import collections\n",
        "import datetime\n",
        "import fluidsynth\n",
        "import glob\n",
        "import numpy as np\n",
        "import pathlib\n",
        "import pandas as pd\n",
        "import pretty_midi\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "\n",
        "from IPython import display\n",
        "from matplotlib import pyplot as plt\n",
        "from typing import Optional"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Efja_OtJNzAM"
      },
      "outputs": [],
      "source": [
        "seed = 42\n",
        "tf.random.set_seed(seed)\n",
        "np.random.seed(seed)\n",
        "\n",
        "# Sampling rate for audio playback\n",
        "_SAMPLING_RATE = 16000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FzIbfb-Ikgg7"
      },
      "source": [
        "## Descargar el conjunto de datos Maestro"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mwja4SWmibrL"
      },
      "outputs": [],
      "source": [
        "data_dir = pathlib.Path('data/maestro-v2.0.0')\n",
        "if not data_dir.exists():\n",
        "  tf.keras.utils.get_file(\n",
        "      'maestro-v2.0.0-midi.zip',\n",
        "      origin='https://storage.googleapis.com/magentadata/datasets/maestro/v2.0.0/maestro-v2.0.0-midi.zip',\n",
        "      extract=True,\n",
        "      cache_dir='.', cache_subdir='data',\n",
        "  )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7UYBSxcINqJ"
      },
      "source": [
        "El conjunto de datos contiene unos 1200 archivos MIDI."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "72iFI1bPB9o1"
      },
      "outputs": [],
      "source": [
        "filenames = glob.glob(str(data_dir/'**/*.mid*'))\n",
        "print('Number of files:', len(filenames))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BlRafYDIRgA"
      },
      "source": [
        "## Procesar un archivo MIDI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFsmG87gXSbh"
      },
      "source": [
        "Lo primero que hay que hacer es usar `pretty_midi` para parsear un único archivo MIDI y comprobar el formato de las notas. Si quiere descargar el siguiente archivo MIDI para reproducirlo en su computadora, puede hacerlo con colab escribiendo `files.download(sample_file)`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6oSCbHvJNbci"
      },
      "outputs": [],
      "source": [
        "sample_file = filenames[1]\n",
        "print(sample_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A48VdGEpXnLp"
      },
      "source": [
        "Genere un objeto `PrettyMIDI` para el archivo MIDI de muestra."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1YSQ5DjRI2md"
      },
      "outputs": [],
      "source": [
        "pm = pretty_midi.PrettyMIDI(sample_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZNVsZuA_lef"
      },
      "source": [
        "Reproduzca el archivo de muestra. El widget de reproducción puede tardar varios segundos en cargarse."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vzoHAaVY_kyY"
      },
      "outputs": [],
      "source": [
        "def display_audio(pm: pretty_midi.PrettyMIDI, seconds=30):\n",
        "  waveform = pm.fluidsynth(fs=_SAMPLING_RATE)\n",
        "  # Take a sample of the generated waveform to mitigate kernel resets\n",
        "  waveform_short = waveform[:seconds*_SAMPLING_RATE]\n",
        "  return display.Audio(waveform_short, rate=_SAMPLING_RATE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GOe-3AAi_sRw"
      },
      "outputs": [],
      "source": [
        "display_audio(pm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Lqe7nOsIyh1"
      },
      "source": [
        "Inspeccione el archivo MIDI. ¿Qué instrumentos se usan?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SIGHYQPZQnRo"
      },
      "outputs": [],
      "source": [
        "print('Number of instruments:', len(pm.instruments))\n",
        "instrument = pm.instruments[0]\n",
        "instrument_name = pretty_midi.program_to_instrument_name(instrument.program)\n",
        "print('Instrument name:', instrument_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVQfV2hVKB28"
      },
      "source": [
        "## Extraer notas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nYZm_VehYOTZ"
      },
      "outputs": [],
      "source": [
        "for i, note in enumerate(instrument.notes[:10]):\n",
        "  note_name = pretty_midi.note_number_to_name(note.pitch)\n",
        "  duration = note.end - note.start\n",
        "  print(f'{i}: pitch={note.pitch}, note_name={note_name},'\n",
        "        f' duration={duration:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jutzynyqX_GC"
      },
      "source": [
        "Cuando entrene el modelo, usará tres variables para representar una nota: `pitch`, `step` y `duration`. Pitch (tono) es la calidad percibida del sonido como un número de nota MIDI. `step` es el tiempo transcurrido desde la nota anterior o el inicio de la pista. `duration` es cuánto tiempo se reproducirá la nota en segundos y es la diferencia entre su hora de finalización y la hora de inicio.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGn7Juv_PTi6"
      },
      "source": [
        "Extraiga las notas del archivo MIDI de muestra."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wyp_wdcEPWby"
      },
      "outputs": [],
      "source": [
        "def midi_to_notes(midi_file: str) -> pd.DataFrame:\n",
        "  pm = pretty_midi.PrettyMIDI(midi_file)\n",
        "  instrument = pm.instruments[0]\n",
        "  notes = collections.defaultdict(list)\n",
        "\n",
        "  # Sort the notes by start time\n",
        "  sorted_notes = sorted(instrument.notes, key=lambda note: note.start)\n",
        "  prev_start = sorted_notes[0].start\n",
        "\n",
        "  for note in sorted_notes:\n",
        "    start = note.start\n",
        "    end = note.end\n",
        "    notes['pitch'].append(note.pitch)\n",
        "    notes['start'].append(start)\n",
        "    notes['end'].append(end)\n",
        "    notes['step'].append(start - prev_start)\n",
        "    notes['duration'].append(end - start)\n",
        "    prev_start = start\n",
        "\n",
        "  return pd.DataFrame({name: np.array(value) for name, value in notes.items()})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X0kPjLBlcnY6"
      },
      "outputs": [],
      "source": [
        "raw_notes = midi_to_notes(sample_file)\n",
        "raw_notes.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-71LPvjubOSO"
      },
      "source": [
        "Quizá sea más fácil interpretar los nombres de las notas en lugar de los tonos, así que puede usar la siguiente función para convertir los valores numéricos de tono en nombres de nota. El nombre de la nota muestra el tipo de nota, su alteración y el número de octava (por ejemplo, C#4). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WE9YXrGZbY2X"
      },
      "outputs": [],
      "source": [
        "get_note_names = np.vectorize(pretty_midi.note_number_to_name)\n",
        "sample_note_names = get_note_names(raw_notes['pitch'])\n",
        "sample_note_names[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7sjqbp1e_f-"
      },
      "source": [
        "Para visualizar la pieza musical, dibuje el tono, el inicio y el final de las notas a lo largo de la pista (es decir, el teclado del piano). Empiece con las 100 primeras notas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "liD2N7x_WOTp"
      },
      "outputs": [],
      "source": [
        "def plot_piano_roll(notes: pd.DataFrame, count: Optional[int] = None):\n",
        "  if count:\n",
        "    title = f'First {count} notes'\n",
        "  else:\n",
        "    title = f'Whole track'\n",
        "    count = len(notes['pitch'])\n",
        "  plt.figure(figsize=(20, 4))\n",
        "  plot_pitch = np.stack([notes['pitch'], notes['pitch']], axis=0)\n",
        "  plot_start_stop = np.stack([notes['start'], notes['end']], axis=0)\n",
        "  plt.plot(\n",
        "      plot_start_stop[:, :count], plot_pitch[:, :count], color=\"b\", marker=\".\")\n",
        "  plt.xlabel('Time [s]')\n",
        "  plt.ylabel('Pitch')\n",
        "  _ = plt.title(title)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vWeUbqmAXjOs"
      },
      "outputs": [],
      "source": [
        "plot_piano_roll(raw_notes, count=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcUyCXYhXeVA"
      },
      "source": [
        "Dibuje las notas de toda la pista."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G7l76hEDZX8Z"
      },
      "outputs": [],
      "source": [
        "plot_piano_roll(raw_notes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GM1bi3aX8rd"
      },
      "source": [
        "Verifique la distribución de cada variable de nota."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pq9C9XBBaK7W"
      },
      "outputs": [],
      "source": [
        "def plot_distributions(notes: pd.DataFrame, drop_percentile=2.5):\n",
        "  plt.figure(figsize=[15, 5])\n",
        "  plt.subplot(1, 3, 1)\n",
        "  sns.histplot(notes, x=\"pitch\", bins=20)\n",
        "\n",
        "  plt.subplot(1, 3, 2)\n",
        "  max_step = np.percentile(notes['step'], 100 - drop_percentile)\n",
        "  sns.histplot(notes, x=\"step\", bins=np.linspace(0, max_step, 21))\n",
        "  \n",
        "  plt.subplot(1, 3, 3)\n",
        "  max_duration = np.percentile(notes['duration'], 100 - drop_percentile)\n",
        "  sns.histplot(notes, x=\"duration\", bins=np.linspace(0, max_duration, 21))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Nu2Pw24acFD"
      },
      "outputs": [],
      "source": [
        "plot_distributions(raw_notes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "poIivompcfS4"
      },
      "source": [
        "## Crear un archivo MIDI\n",
        "\n",
        "La siguiente función le permite crear su propio archivo MIDI a partir de una lista de notas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BD5rsMRARYoV"
      },
      "outputs": [],
      "source": [
        "def notes_to_midi(\n",
        "  notes: pd.DataFrame,\n",
        "  out_file: str, \n",
        "  instrument_name: str,\n",
        "  velocity: int = 100,  # note loudness\n",
        ") -> pretty_midi.PrettyMIDI:\n",
        "\n",
        "  pm = pretty_midi.PrettyMIDI()\n",
        "  instrument = pretty_midi.Instrument(\n",
        "      program=pretty_midi.instrument_name_to_program(\n",
        "          instrument_name))\n",
        "\n",
        "  prev_start = 0\n",
        "  for i, note in notes.iterrows():\n",
        "    start = float(prev_start + note['step'])\n",
        "    end = float(start + note['duration'])\n",
        "    note = pretty_midi.Note(\n",
        "        velocity=velocity,\n",
        "        pitch=int(note['pitch']),\n",
        "        start=start,\n",
        "        end=end,\n",
        "    )\n",
        "    instrument.notes.append(note)\n",
        "    prev_start = start\n",
        "\n",
        "  pm.instruments.append(instrument)\n",
        "  pm.write(out_file)\n",
        "  return pm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wTazLbuWPIPF"
      },
      "outputs": [],
      "source": [
        "example_file = 'example.midi'\n",
        "example_pm = notes_to_midi(\n",
        "    raw_notes, out_file=example_file, instrument_name=instrument_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XG0N9zZV_4Gp"
      },
      "source": [
        "Reproduzca el archivo MIDI generado y revise si hay alguna diferencia."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fGRLs-eR_4uK"
      },
      "outputs": [],
      "source": [
        "display_audio(example_pm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLrUscjhBzYc"
      },
      "source": [
        "También aquí puede escribir `files.download(example_file)` para descargar y reproducir este archivo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfRNk9tEScuf"
      },
      "source": [
        "## Crear el conjunto de datos de entrenamiento\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b77zHR1udDrK"
      },
      "source": [
        "Cree el conjunto de datos de entrenamiento extrayendo notas de los archivos MIDI. Empiece con un pequeño número de archivos y luego experimente con más. Esto puede llevarle unos cuantos minutos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GiaQiTnXSW-T"
      },
      "outputs": [],
      "source": [
        "num_files = 5\n",
        "all_notes = []\n",
        "for f in filenames[:num_files]:\n",
        "  notes = midi_to_notes(f)\n",
        "  all_notes.append(notes)\n",
        "\n",
        "all_notes = pd.concat(all_notes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F4bMDeRvgWqx"
      },
      "outputs": [],
      "source": [
        "n_notes = len(all_notes)\n",
        "print('Number of notes parsed:', n_notes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIBLvj-cODWS"
      },
      "source": [
        "Luego, cree un `tf.data.Dataset` a partir de las notas parseadas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mvNHCHZdXG2P"
      },
      "outputs": [],
      "source": [
        "key_order = ['pitch', 'step', 'duration']\n",
        "train_notes = np.stack([all_notes[key] for key in key_order], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PLC_19tshyFk"
      },
      "outputs": [],
      "source": [
        "notes_ds = tf.data.Dataset.from_tensor_slices(train_notes)\n",
        "notes_ds.element_spec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sj9SXRCjt3I7"
      },
      "source": [
        "Va a entrenar este modelo con lotes de secuencias de notas. Cada ejemplo tiene una secuencia de notas como elemento de entrada y la nota siguiente como la etiqueta. De este modo, el modelo se entrena para predecir la siguiente nota de una secuencia. Puede encontrar un diagrama que explica este proceso (y más detalles) en [Clasificación de texto con una RNN](https://www.tensorflow.org/text/tutorials/text_generation).\n",
        "\n",
        "Puede usar la práctica función [window](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#window) con tamaño `seq_length` para crear las características y etiquetas en este formato."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZkEC-5s6wJJV"
      },
      "outputs": [],
      "source": [
        "def create_sequences(\n",
        "    dataset: tf.data.Dataset, \n",
        "    seq_length: int,\n",
        "    vocab_size = 128,\n",
        ") -> tf.data.Dataset:\n",
        "  \"\"\"Returns TF Dataset of sequence and label examples.\"\"\"\n",
        "  seq_length = seq_length+1\n",
        "\n",
        "  # Take 1 extra for the labels\n",
        "  windows = dataset.window(seq_length, shift=1, stride=1,\n",
        "                              drop_remainder=True)\n",
        "\n",
        "  # `flat_map` flattens the\" dataset of datasets\" into a dataset of tensors\n",
        "  flatten = lambda x: x.batch(seq_length, drop_remainder=True)\n",
        "  sequences = windows.flat_map(flatten)\n",
        "  \n",
        "  # Normalize note pitch\n",
        "  def scale_pitch(x):\n",
        "    x = x/[vocab_size,1.0,1.0]\n",
        "    return x\n",
        "\n",
        "  # Split the labels\n",
        "  def split_labels(sequences):\n",
        "    inputs = sequences[:-1]\n",
        "    labels_dense = sequences[-1]\n",
        "    labels = {key:labels_dense[i] for i,key in enumerate(key_order)}\n",
        "\n",
        "    return scale_pitch(inputs), labels\n",
        "\n",
        "  return sequences.map(split_labels, num_parallel_calls=tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xDX5pVkegrv"
      },
      "source": [
        "Especifique la longitud de la secuencia para cada ejemplo. Experimente con distintas longitudes (por ejemplo, 50, 100, 150) para encontrar la que mejor se adapte a los datos, o use [ajuste de hiperparámetros](https://www.tensorflow.org/tutorials/keras/keras_tuner). El tamaño (`vocab_size`) del vocabulario se establece en 128, lo que representa todos los tonos admitidos por `pretty_midi`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fGA3VxcFXZ4T"
      },
      "outputs": [],
      "source": [
        "seq_length = 25\n",
        "vocab_size = 128\n",
        "seq_ds = create_sequences(notes_ds, seq_length, vocab_size)\n",
        "seq_ds.element_spec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AX9nKmSYetGo"
      },
      "source": [
        "La forma del conjunto de datos es `(100,1)`, de modo que el modelo toma 100 notas como entrada y aprende a predecir la siguiente nota como salida."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ESK9cL7__TF3"
      },
      "outputs": [],
      "source": [
        "for seq, target in seq_ds.take(1):\n",
        "  print('sequence shape:', seq.shape)\n",
        "  print('sequence elements (first 10):', seq[0: 10])\n",
        "  print()\n",
        "  print('target:', target)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kR3TVZZGk5Qq"
      },
      "source": [
        "Procese los ejemplos por lotes y configure el conjunto de datos para enfocarse al rendimiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fTpFoiM_AV_Y"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "buffer_size = n_notes - seq_length  # the number of items in the dataset\n",
        "train_ds = (seq_ds\n",
        "            .shuffle(buffer_size)\n",
        "            .batch(batch_size, drop_remainder=True)\n",
        "            .cache()\n",
        "            .prefetch(tf.data.experimental.AUTOTUNE))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LySbjV0GzXQu"
      },
      "outputs": [],
      "source": [
        "train_ds.element_spec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWZmfkshqP8G"
      },
      "source": [
        "## Cómo entrenar y crear su modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGQn32q-hdK2"
      },
      "source": [
        "Hay tres salidas del modelo, una para cada variable de nota. Para `step` y `duration` se usará una función de pérdida personalizada basada en el error cuadrático medio para que el modelo produzca valores no negativos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "erxLOif08e8v"
      },
      "outputs": [],
      "source": [
        "def mse_with_positive_pressure(y_true: tf.Tensor, y_pred: tf.Tensor):\n",
        "  mse = (y_true - y_pred) ** 2\n",
        "  positive_pressure = 10 * tf.maximum(-y_pred, 0.0)\n",
        "  return tf.reduce_mean(mse + positive_pressure)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kNaVWcCzAm5V"
      },
      "outputs": [],
      "source": [
        "input_shape = (seq_length, 3)\n",
        "learning_rate = 0.005\n",
        "\n",
        "inputs = tf.keras.Input(input_shape)\n",
        "x = tf.keras.layers.LSTM(128)(inputs)\n",
        "\n",
        "outputs = {\n",
        "  'pitch': tf.keras.layers.Dense(128, name='pitch')(x),\n",
        "  'step': tf.keras.layers.Dense(1, name='step')(x),\n",
        "  'duration': tf.keras.layers.Dense(1, name='duration')(x),\n",
        "}\n",
        "\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "loss = {\n",
        "      'pitch': tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "          from_logits=True),\n",
        "      'step': mse_with_positive_pressure,\n",
        "      'duration': mse_with_positive_pressure,\n",
        "}\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "model.compile(loss=loss, optimizer=optimizer)\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDL0Jypt3eU5"
      },
      "source": [
        "Si probamos la función `model.evaluate`, veremos que la pérdida de `pitch` es significativamente mayor que las pérdidas de `step` y `duration`. Observe que `loss` es la pérdida total al sumar todas las demás pérdidas, y en este momento está dominada por la pérdida de `pitch`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BlATt7Rl0XJl"
      },
      "outputs": [],
      "source": [
        "losses = model.evaluate(train_ds, return_dict=True)\n",
        "losses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLvNLvtR3W59"
      },
      "source": [
        "Se puede compensar usando el argumento `loss_weights` al compilar:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9fQB5SiN3ufX"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    loss=loss,\n",
        "    loss_weights={\n",
        "        'pitch': 0.05,\n",
        "        'step': 1.0,\n",
        "        'duration':1.0,\n",
        "    },\n",
        "    optimizer=optimizer,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPMUnIMelHgR"
      },
      "source": [
        "El `loss` se convierte entonces en la suma ponderada de las pérdidas individuales."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T7CzWmFR38ut"
      },
      "outputs": [],
      "source": [
        "model.evaluate(train_ds, return_dict=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJbn7HZgfosr"
      },
      "source": [
        "Entrenar el modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uQA_rwKEgPjp"
      },
      "outputs": [],
      "source": [
        "callbacks = [\n",
        "    tf.keras.callbacks.ModelCheckpoint(\n",
        "        filepath='./training_checkpoints/ckpt_{epoch}',\n",
        "        save_weights_only=True),\n",
        "    tf.keras.callbacks.EarlyStopping(\n",
        "        monitor='loss',\n",
        "        patience=5,\n",
        "        verbose=1,\n",
        "        restore_best_weights=True),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aLoYY8-XaPFN"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "epochs = 50\n",
        "\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    epochs=epochs,\n",
        "    callbacks=callbacks,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PYBSjgDWiUfT"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.epoch, history.history['loss'], label='total loss')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPWI94lQ8uQA"
      },
      "source": [
        "## Generar notas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wbaoiy4Hf-n5"
      },
      "source": [
        "Para usar el modelo para generar notas, primero necesitará suministrar una secuencia inicial de notas. La siguiente función genera una nota a partir de una secuencia de notas.\n",
        "\n",
        "Para el tono de la nota, tome una muestra de la distribución softmax de notas producidas por el modelo, en lugar de elegir simplemente la nota con mayor probabilidad. Si siempre se eligiera la nota con mayor probabilidad, se obtendrían secuencias repetitivas de notas.\n",
        "\n",
        "El parámetro `temperature` sirve para controlar qué tan aleatorias son las notas generadas. Puede encontrar más detalles sobre la temperatura en [Generación de texto con una RNN](https://www.tensorflow.org/text/tutorials/text_generation)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1mil8ZyJNe1w"
      },
      "outputs": [],
      "source": [
        "def predict_next_note(\n",
        "    notes: np.ndarray, \n",
        "    keras_model: tf.keras.Model, \n",
        "    temperature: float = 1.0) -> tuple[int, float, float]:\n",
        "  \"\"\"Generates a note as a tuple of (pitch, step, duration), using a trained sequence model.\"\"\"\n",
        "\n",
        "  assert temperature > 0\n",
        "\n",
        "  # Add batch dimension\n",
        "  inputs = tf.expand_dims(notes, 0)\n",
        "\n",
        "  predictions = model.predict(inputs)\n",
        "  pitch_logits = predictions['pitch']\n",
        "  step = predictions['step']\n",
        "  duration = predictions['duration']\n",
        " \n",
        "  pitch_logits /= temperature\n",
        "  pitch = tf.random.categorical(pitch_logits, num_samples=1)\n",
        "  pitch = tf.squeeze(pitch, axis=-1)\n",
        "  duration = tf.squeeze(duration, axis=-1)\n",
        "  step = tf.squeeze(step, axis=-1)\n",
        "\n",
        "  # `step` and `duration` values should be non-negative\n",
        "  step = tf.maximum(0, step)\n",
        "  duration = tf.maximum(0, duration)\n",
        "\n",
        "  return int(pitch), float(step), float(duration)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W64K-EX3hxU_"
      },
      "source": [
        "Ahora genere algunas notas. Pruebe a jugar con la temperatura y la secuencia de inicio en `next_notes`, a ver qué pasa."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "87fPl4auPdR3"
      },
      "outputs": [],
      "source": [
        "temperature = 2.0\n",
        "num_predictions = 120\n",
        "\n",
        "sample_notes = np.stack([raw_notes[key] for key in key_order], axis=1)\n",
        "\n",
        "# The initial sequence of notes; pitch is normalized similar to training\n",
        "# sequences\n",
        "input_notes = (\n",
        "    sample_notes[:seq_length] / np.array([vocab_size, 1, 1]))\n",
        "\n",
        "generated_notes = []\n",
        "prev_start = 0\n",
        "for _ in range(num_predictions):\n",
        "  pitch, step, duration = predict_next_note(input_notes, model, temperature)\n",
        "  start = prev_start + step\n",
        "  end = start + duration\n",
        "  input_note = (pitch, step, duration)\n",
        "  generated_notes.append((*input_note, start, end))\n",
        "  input_notes = np.delete(input_notes, 0, axis=0)\n",
        "  input_notes = np.append(input_notes, np.expand_dims(input_note, 0), axis=0)\n",
        "  prev_start = start\n",
        "\n",
        "generated_notes = pd.DataFrame(\n",
        "    generated_notes, columns=(*key_order, 'start', 'end'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0MK7HmqLuqka"
      },
      "outputs": [],
      "source": [
        "generated_notes.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e9K9KHPaTNnK"
      },
      "outputs": [],
      "source": [
        "out_file = 'output.mid'\n",
        "out_pm = notes_to_midi(\n",
        "    generated_notes, out_file=out_file, instrument_name=instrument_name)\n",
        "display_audio(out_pm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4N9_Y03Kw-3"
      },
      "source": [
        "Si quiere descargar el archivo de audio, añada las dos líneas siguientes:\n",
        "\n",
        "```\n",
        "from google.colab import files\n",
        "files.download(out_file)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trp82gTqskPR"
      },
      "source": [
        "Visualice las notas generadas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NlNsxcnhvbcK"
      },
      "outputs": [],
      "source": [
        "plot_piano_roll(generated_notes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5_yA9lvvitC"
      },
      "source": [
        "Revisa las distribuciones de `pitch{/código0}, `step{/código1} y `duration{/código2}.```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j5bco2WVRkAa"
      },
      "outputs": [],
      "source": [
        "plot_distributions(generated_notes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAyxR7Itw3Wh"
      },
      "source": [
        "Notará el cambio en la distribución de las variables de nota en los gráficos anteriores. Como existe un bucle de retroalimentación entre las salidas y las entradas del modelo, éste tiende a generar secuencias similares de salidas para reducir la pérdida, especialmente para `step` y `duration`, que usan la pérdida MSE. Para `pitch`, puede aumentar la aleatoriedad aumentando la `temperature` en `predict_next_note`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bkfe3GYZEu4l"
      },
      "source": [
        "## Siguientes pasos\n",
        "\n",
        "Este tutorial muestra la mecánica de usar una RNN para generar secuencias de notas a partir de un conjunto de datos de archivos MIDI. Si quiere saber más, puede consultar el tutorial relacionado [Generación de texto con una RNN](https://www.tensorflow.org/text/tutorials/text_generation), que tiene más diagramas y explicaciones.\n",
        "\n",
        "Las GAN son una de las alternativas a las RNN para la generación de música. En lugar de generar audio, un enfoque basado en GAN puede generar una secuencia completa en paralelo. Es impresionante el trabajo realizado por el equipo de Magenta con [GANSynth](https://magenta.tensorflow.org/gansynth). También puede encontrar muchos proyectos musicales y artísticos maravillosos y código fuente abierto en el sitio web del proyecto [Magenta](https://magenta.tensorflow.org/)."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "music_generation.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
