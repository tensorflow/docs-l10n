{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDnwEv8FtJm7"
      },
      "source": [
        "##### Copyright 2018 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "JlknJBWQtKkI"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60RdWsg1tETW"
      },
      "source": [
        "# Capas personalizadas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcJg7Enms86w"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>     <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/customization/custom_layers\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver en TensorFlow.org</a> </td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/es-419/tutorials/customization/custom_layers.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Ejecutar en Google Colab</a> </td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/es-419/tutorials/customization/custom_layers.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver fuente en GitHub</a> </td>\n",
        "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/es-419/tutorials/customization/custom_layers.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Descargar cuaderno</a> </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEu3q4jmpKVT"
      },
      "source": [
        "Como API de alto nivel para construir redes neuronales, recomendamos usar `tf.keras`. Sin embargo, la mayoría de las API de TensorFlow son utilizables con eager execution.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Py0m-N6VgQFJ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TluWFcB_2nP5"
      },
      "outputs": [],
      "source": [
        "print(tf.config.list_physical_devices('GPU'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSFfVVjkrrsI"
      },
      "source": [
        "## Capas: grupos comunes de operaciones útiles\n",
        "\n",
        "Cuando escriba código para modelos de aprendizaje automático, normalmente querrá operar a un nivel de abstracción superior al de las operaciones simples y la manipulación de variables.\n",
        "\n",
        "Muchos modelos de aprendizaje automático pueden expresarse como formada por capas relativamente simples pero arregladas y apiladas. TensorFlow ofrece tanto un grupo de muchas capas comunes como formas sencillas para que usted escriba sus propias capas específicas de la aplicación, ya sea desde cero o como una composición de capas existentes.\n",
        "\n",
        "TensorFlow viene con la API [Keras](https://keras.io) completa en el paquete tf.keras, y las capas Keras son muy útiles si desea construir sus propios modelos.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8PyXlPl-4TzQ"
      },
      "outputs": [],
      "source": [
        "# In the tf.keras.layers package, layers are objects. To construct a layer,\n",
        "# simply construct the object. Most layers take as a first argument the number\n",
        "# of output dimensions / channels.\n",
        "layer = tf.keras.layers.Dense(100)\n",
        "# The number of input dimensions is often unnecessary, as it can be inferred\n",
        "# the first time the layer is used, but it can be provided if you want to\n",
        "# specify it manually, which is useful in some complex models.\n",
        "layer = tf.keras.layers.Dense(10, input_shape=(None, 5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fn69xxPO5Psr"
      },
      "source": [
        "Consulte la [documentación](https://www.tensorflow.org/api_docs/python/tf/keras/layers) para ver la lista completa de capas preexistentes. Entre ellas se encuentran Dense (una capa totalmente conectada), Conv2D, LSTM, BatchNormalization, Dropout y muchas otras."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E3XKNknP5Mhb"
      },
      "outputs": [],
      "source": [
        "# To use a layer, simply call it.\n",
        "layer(tf.zeros([10, 5]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wt_Nsv-L5t2s"
      },
      "outputs": [],
      "source": [
        "# Layers have many useful methods. For example, you can inspect all variables\n",
        "# in a layer using `layer.variables` and trainable variables using\n",
        "# `layer.trainable_variables`. In this case a fully-connected layer\n",
        "# will have variables for weights and biases.\n",
        "layer.variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ilvKjz8_4MQ"
      },
      "outputs": [],
      "source": [
        "# The variables are also accessible through nice accessors\n",
        "layer.kernel, layer.bias"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0kDbE54-5VS"
      },
      "source": [
        "## Implementar capas personalizadas\n",
        "\n",
        "La mejor forma de implementar su propia capa es extender la clase tf.keras.Layer e implementar:\n",
        "\n",
        "1. `__init__`, donde puede hacer toda la inicialización independiente de la entrada\n",
        "2. `build`, donde usted sabe las formas de los tensores de entrada y puede hacer el resto de la inicialización por sí mismo.\n",
        "3. `call`, donde usted realiza computación hacia adelante\n",
        "\n",
        "Tenga en cuenta que no tiene que esperar hasta que se llame a `build`  para crear sus variables. También puede crearlas en `__init__`. Sin embargo, la ventaja de esperar a `build` es que le permite crear variables en una fase posterior según la forma de las entradas sobre las que operará la capa. Y a la inversa, crear variables en `__init__` significa que las formas necesarias para crear las variables tienen que definirse explícitamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Byl3n1k5kIy"
      },
      "outputs": [],
      "source": [
        "class MyDenseLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self, num_outputs):\n",
        "    super(MyDenseLayer, self).__init__()\n",
        "    self.num_outputs = num_outputs\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    self.kernel = self.add_weight(\"kernel\",\n",
        "                                  shape=[int(input_shape[-1]),\n",
        "                                         self.num_outputs])\n",
        "\n",
        "  def call(self, inputs):\n",
        "    return tf.matmul(inputs, self.kernel)\n",
        "\n",
        "layer = MyDenseLayer(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vrmBsYGOnuGO"
      },
      "outputs": [],
      "source": [
        "_ = layer(tf.zeros([10, 5])) # Calling the layer `.builds` it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1bsLjiPfnvat"
      },
      "outputs": [],
      "source": [
        "print([var.name for var in layer.trainable_variables])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tk8E2vY0-z4Z"
      },
      "source": [
        "El código en su conjunto es más fácil de leer y mantener si usa capas estándares siempre que sea posible, ya que los demás usuarios estarán familiarizados con el comportamiento de estas capas. ¡Considere la posibilidad de registrar una <a>incidencia en github</a> o, mejor aún, de enviarnos una solicitud de incorporación si desea usar una capa que no está en <code>tf.keras.layers</code>!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qhg4KlbKrs3G"
      },
      "source": [
        "## Modelos: Composición de capas\n",
        "\n",
        "En los modelos de aprendizaje automático, muchas cosas interesantes parecidas a las capas se implementan al hacer composiciones de capas existentes. Por ejemplo, cada bloque residual en una retícula es una composición de convoluciones, normalizaciones de lotes y un enlace. Puede anidar capas dentro de otras capas.\n",
        "\n",
        "Normalmente se hace herencia de `keras.Model` cuando se necesita los métodos del modelo como `Model.fit`, `Model.evaluate` y `Model.save` (para más detalles, consulte [Capas y modelos personalizados de Keras](https://www.tensorflow.org/guide/keras/custom_layers_and_models)).\n",
        "\n",
        "Otra característica de `keras.Model` (en lugar de `keras.layers.Layer`) es que no sólo realiza un seguimiento de las variables, sino que un `keras.Model` también sigue sus capas internas, lo que simplifica su inspección.\n",
        "\n",
        "Por ejemplo, aquí hay un bloque ResNet:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N30DTXiRASlb"
      },
      "outputs": [],
      "source": [
        "class ResnetIdentityBlock(tf.keras.Model):\n",
        "  def __init__(self, kernel_size, filters):\n",
        "    super(ResnetIdentityBlock, self).__init__(name='')\n",
        "    filters1, filters2, filters3 = filters\n",
        "\n",
        "    self.conv2a = tf.keras.layers.Conv2D(filters1, (1, 1))\n",
        "    self.bn2a = tf.keras.layers.BatchNormalization()\n",
        "\n",
        "    self.conv2b = tf.keras.layers.Conv2D(filters2, kernel_size, padding='same')\n",
        "    self.bn2b = tf.keras.layers.BatchNormalization()\n",
        "\n",
        "    self.conv2c = tf.keras.layers.Conv2D(filters3, (1, 1))\n",
        "    self.bn2c = tf.keras.layers.BatchNormalization()\n",
        "\n",
        "  def call(self, input_tensor, training=False):\n",
        "    x = self.conv2a(input_tensor)\n",
        "    x = self.bn2a(x, training=training)\n",
        "    x = tf.nn.relu(x)\n",
        "\n",
        "    x = self.conv2b(x)\n",
        "    x = self.bn2b(x, training=training)\n",
        "    x = tf.nn.relu(x)\n",
        "\n",
        "    x = self.conv2c(x)\n",
        "    x = self.bn2c(x, training=training)\n",
        "\n",
        "    x += input_tensor\n",
        "    return tf.nn.relu(x)\n",
        "\n",
        "\n",
        "block = ResnetIdentityBlock(1, [1, 2, 3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7D8ZR5mqtokj"
      },
      "outputs": [],
      "source": [
        "_ = block(tf.zeros([1, 2, 3, 3])) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MJ8rzFpdoE_m"
      },
      "outputs": [],
      "source": [
        "block.layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dewldLuDvQRM"
      },
      "outputs": [],
      "source": [
        "len(block.variables)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FrqIXeSetaYi"
      },
      "outputs": [],
      "source": [
        "block.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYfucVw65PMj"
      },
      "source": [
        "La mayoría de las veces, sin embargo, los modelos que constan de muchas capas simplemente llaman a una capa tras otra. Esto puede hacerse con muy poco código usando `tf.keras.Sequential`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L9frk7Ur4uvJ"
      },
      "outputs": [],
      "source": [
        "my_seq = tf.keras.Sequential([tf.keras.layers.Conv2D(1, (1, 1),\n",
        "                                                    input_shape=(\n",
        "                                                        None, None, 3)),\n",
        "                             tf.keras.layers.BatchNormalization(),\n",
        "                             tf.keras.layers.Conv2D(2, 1,\n",
        "                                                    padding='same'),\n",
        "                             tf.keras.layers.BatchNormalization(),\n",
        "                             tf.keras.layers.Conv2D(3, (1, 1)),\n",
        "                             tf.keras.layers.BatchNormalization()])\n",
        "my_seq(tf.zeros([1, 2, 3, 3]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tVAsbFITuScB"
      },
      "outputs": [],
      "source": [
        "my_seq.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5YwYcnuK-wc"
      },
      "source": [
        "# Siguientes pasos\n",
        "\n",
        "Ya puede volver al bloc de notas anterior y adaptar el ejemplo de regresión lineal usando capas y modelos para que esté mejor estructurado."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "custom_layers.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
