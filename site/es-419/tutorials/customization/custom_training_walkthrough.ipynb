{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwxGnsA92emp"
      },
      "source": [
        "##### Copyright 2018 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "CPII1rGR2rF9"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JtEZ1pCPn--z"
      },
      "source": [
        "# Entrenamiento personalizado: tutorial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GV1F7tVTN3Dn"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td><a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/customization/custom_training_walkthrough\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver en TensorFlow.org</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/es-419/tutorials/customization/custom_training_walkthrough.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Ejecutar en Google Colab</a></td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/es-419/tutorials/customization/custom_training_walkthrough.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver fuente en GitHub</a> </td>\n",
        "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/es-419/tutorials/customization/custom_training_walkthrough.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Descargar cuaderno</a> </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDrzLFXE8T1l"
      },
      "source": [
        "Este tutorial le muestra cómo entrenar un modelo de aprendizaje automático con un bucle de entrenamiento personalizado para *categorizar* pingüinos por especies. En este bloc de notas, usará TensorFlow para hacer lo siguiente:\n",
        "\n",
        "1. Importar un conjunto de datos\n",
        "2. Construir un modelo lineal simple\n",
        "3. Entrenar el modelo\n",
        "4. Evaluar la eficacia del modelo\n",
        "5. Usar el modelo entrenado para hacer predicciones\n",
        "\n",
        "## Programar el TensorFlow\n",
        "\n",
        "Este tutorial demuestra las siguientes tareas de programación de TensorFlow:\n",
        "\n",
        "- Importar datos con la [API de conjuntos de datos de TensorFlow](https://www.tensorflow.org/datasets/overview#load_a_dataset)\n",
        "- Construir modelos y capas con la [API Keras](https://www.tensorflow.org/guide/keras/)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zx7wc0LuuxaJ"
      },
      "source": [
        "## Problema de clasificación de pingüinos\n",
        "\n",
        "Imagine que es un ornitólogo en busca de cómo categorizar automáticamente cada pingüino que encuentra. El aprendizaje automático ofrece muchos algoritmos para clasificar pingüinos estadísticamente. Por ejemplo, un sofisticado programa de aprendizaje automático podría clasificar pingüinos basándose en fotografías. El modelo que construye en este tutorial es un poco más sencillo. Clasifica a los pingüinos basándose en su peso corporal, la longitud de sus aletas y sus picos, es decir, la longitud y anchura de su [culmen](https://en.wikipedia.org/wiki/Beak#Culmen).\n",
        "\n",
        "Hay 18 especies de pingüinos, pero en este tutorial sólo intentará clasificar las tres siguientes:\n",
        "\n",
        "- Pingüinos barbijo\n",
        "- Pingüinos gentú\n",
        "- Pingüinos de Adelia\n",
        "\n",
        "<table>\n",
        "  <tr><td>     <img src=\"https://www.tensorflow.org/tutorials/customization/images/penguins_ds_species.png\" class=\"no-filter\" alt=\"Ilustración de los pingüinos barbijo, gentú y de Adelia\"> </td></tr>\n",
        "  <tr><td align=\"center\">     <b>Figura 1.</b> Pingüinos <a href=\"https://en.wikipedia.org/wiki/Chinstrap_penguin\">barbijo</a>, <a href=\"https://en.wikipedia.org/wiki/Gentoo_penguin\">gentú</a>, y <a href=\"https://en.wikipedia.org/wiki/Ad%C3%A9lie_penguin\">de Adelia</a> (Ilustraciones de @allison_horst, CC BY-SA 2.0).<br> </td></tr>\n",
        "</table>\n",
        "\n",
        "Por suerte, un equipo de investigadores ya ha creado y compartido un [conjunto de datos de 334 pingüinos](https://allisonhorst.github.io/palmerpenguins/) con peso corporal, longitud de las aletas, medidas del pico y otros datos. Este conjunto de datos también está convenientemente disponible como el Conjunto de Datos TensorFlow [penguins](https://www.tensorflow.org/datasets/catalog/penguins). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1J3AuPBT9gyR"
      },
      "source": [
        "## Preparación\n",
        "\n",
        "Instale el paquete `tfds-nightly` para el conjunto de datos penguins. El paquete `tfds-nightly` es la versión nightly de los Conjuntos de Datos TensorFlow (TFDS). Para más información sobre TFDS, consulte [Descripción general de los conjuntos de datos TensorFlow](https://www.tensorflow.org/datasets/overview)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4XXWn1eDZmET"
      },
      "outputs": [],
      "source": [
        "!pip install -q tfds-nightly"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DtGeMicKRGzU"
      },
      "source": [
        "A continuación, seleccione **Tiempo de ejecución &gt; Reiniciar tiempo de ejecución** en el menú Colab para reiniciar el tiempo de ejecución de Colab.\n",
        "\n",
        "No siga con el resto de este tutorial sin antes reiniciar el tiempo de ejecución."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9onjGZWZbA-"
      },
      "source": [
        "Importe TensorFlow y los demás módulos de Python necesarios. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jElLULrDhQZR"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"TensorFlow version: {}\".format(tf.__version__))\n",
        "print(\"TensorFlow Datasets version: \",tfds.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Px6KAg0Jowz"
      },
      "source": [
        "## Importar el conjunto de datos\n",
        "\n",
        "El conjunto de datos predeterminado [penguins/processed](https://www.tensorflow.org/datasets/catalog/penguins) ya está limpio, normalizado y listo para construir un modelo. Antes de descargar los datos procesados, previsualice una versión simplificada para familiarizarse con los datos originales del estudio sobre pingüinos.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnX1-aLors4S"
      },
      "source": [
        "### Previsualizar los datos\n",
        "\n",
        "Descargue la versión simplificada del conjunto de datos de pingüinos (`penguins/simple`) usando el método [`tdfs.load`](https://www.tensorflow.org/datasets/api_docs/python/tfds/load) de Conjuntos de Datos TensorFlow. Hay 344 registros de datos en este conjunto de datos. Extraiga los cinco primeros registros en un objeto [`DataFrame`](https://www.tensorflow.org/datasets/api_docs/python/tfds/as_dataframe) para inspeccionar una muestra de los valores de este conjunto de datos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FQvb_JYdrpPm"
      },
      "outputs": [],
      "source": [
        "ds_preview, info = tfds.load('penguins/simple', split='train', with_info=True)\n",
        "df = tfds.as_dataframe(ds_preview.take(5), info)\n",
        "print(df)\n",
        "print(info.features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQhzD6P-uBoq"
      },
      "source": [
        "Las filas numeradas son registros de datos, un *[ejemplo](https://developers.google.com/machine-learning/glossary/#example)* por línea, donde:\n",
        "\n",
        "- Los seis primeros campos son *[características](https://developers.google.com/machine-learning/glossary/#feature)*: son las características de un ejemplo. Aquí, los campos contienen números que representan medidas de pingüinos.\n",
        "- La última columna es la *[etiqueta](https://developers.google.com/machine-learning/glossary/#label)*: es el valor que se quiere predecir. Para este conjunto de datos, es un valor entero de 0, 1 o 2 que corresponde al nombre de una especie de pingüino."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCtwLoJhhDNc"
      },
      "source": [
        "En el conjunto de datos, la etiqueta de la especie de pingüino se representa como un número para que sea más fácil trabajar con ella en el modelo que construye. Estos números corresponden a las siguientes especies de pingüinos:\n",
        "\n",
        "- `0`: pingüino de Adelia\n",
        "- `1`: pingüino barbijo\n",
        "- `2`: pingüino gentú\n",
        "\n",
        "Cree una lista que contenga los nombres de las especies de pingüinos en este orden. Usará esta lista para interpretar los resultados del modelo de clasificación:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sVNlJlUOhkoX"
      },
      "outputs": [],
      "source": [
        "class_names = ['Adélie', 'Chinstrap', 'Gentoo']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iav9kEgxpY0s"
      },
      "source": [
        "Para saber más sobre características y etiquetas, consulte la [sección Terminología ML del Curso acelerado de aprendizaje automático](https://developers.google.com/machine-learning/crash-course/framing/ml-terminology)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PD33PxSmCrtL"
      },
      "source": [
        "### Descargar el conjunto de datos preprocesados\n",
        "\n",
        "Ahora, descargue el conjunto de datos preprocesado de pingüinos (`penguins/processed`) con el método `tfds.load`, que devuelve una lista de objetos `tf.data.Dataset`. Tenga en cuenta que el conjunto de datos `penguins/processed` no viene con su propio conjunto de prueba, así que use una división 80:20 para [dividir el conjunto de datos completo](https://www.tensorflow.org/datasets/splits) en los conjuntos de entrenamiento y prueba. Usará el conjunto de datos de prueba más adelante para verificar su modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EVV96zIYYAi8"
      },
      "outputs": [],
      "source": [
        "ds_split, info = tfds.load(\"penguins/processed\", split=['train[:20%]', 'train[20%:]'], as_supervised=True, with_info=True)\n",
        "\n",
        "ds_test = ds_split[0]\n",
        "ds_train = ds_split[1]\n",
        "assert isinstance(ds_test, tf.data.Dataset)\n",
        "\n",
        "print(info.features)\n",
        "df_test = tfds.as_dataframe(ds_test.take(5), info)\n",
        "print(\"Test dataset sample: \")\n",
        "print(df_test)\n",
        "\n",
        "df_train = tfds.as_dataframe(ds_train.take(5), info)\n",
        "print(\"Train dataset sample: \")\n",
        "print(df_train)\n",
        "\n",
        "ds_train_batch = ds_train.batch(32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xX2NfLyQOK1y"
      },
      "source": [
        "Observe que esta versión del conjunto de datos se procesó reduciendo los datos a cuatro características normalizadas y una etiqueta de especie. En este formato, los datos pueden usarse rápidamente para entrenar un modelo sin más procesamiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iDuG94H-C122"
      },
      "outputs": [],
      "source": [
        "features, labels = next(iter(ds_train_batch))\n",
        "\n",
        "print(features)\n",
        "print(labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E63mArnQaAGz"
      },
      "source": [
        "Puede visualizar algunos clusters trazando algunas características del lote:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "me5Wn-9FcyyO"
      },
      "outputs": [],
      "source": [
        "plt.scatter(features[:,0],\n",
        "            features[:,2],\n",
        "            c=labels,\n",
        "            cmap='viridis')\n",
        "\n",
        "plt.xlabel(\"Body Mass\")\n",
        "plt.ylabel(\"Culmen Length\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LsaVrtNM3Tx5"
      },
      "source": [
        "## Construir un modelo lineal simple\n",
        "\n",
        "### ¿Por qué un modelo?\n",
        "\n",
        "Un *[modelo](https://developers.google.com/machine-learning/crash-course/glossary#model)* es una relación entre las características y la etiqueta. Para resolver el problema de clasificación de pingüinos, el modelo define la relación entre las medidas de masa corporal, aletas y culmen y la especie de pingüino predicha. Algunos modelos sencillos pueden describirse con unas pocas líneas de álgebra, pero los modelos complejos de aprendizaje automático tienen un gran número de parámetros que son difíciles de resumir.\n",
        "\n",
        "¿Podría determinar la relación entre las cuatro características y la especie de pingüino *sin* usar el aprendizaje automático? Es decir, ¿podría usar técnicas de programación tradicionales (por ejemplo, muchas sentencias condicionales) para crear un modelo? Tal vez, si analizara el conjunto de datos el tiempo suficiente para determinar las relaciones entre la masa corporal y las medidas del culmen con una especie concreta. Y esto se hace difícil (quizá imposible) en conjuntos de datos más complicados. Un buen enfoque de aprendizaje automático *determina el modelo por usted*. Si le da suficientes ejemplos representativos al tipo de modelo de aprendizaje automático adecuado, el programa determina las relaciones por usted.\n",
        "\n",
        "### Elegir el modelo\n",
        "\n",
        "Después tiene que elegir el tipo de modelo que va a entrenar. Hay muchos tipos de modelos y elegir uno bueno requiere experiencia. Este tutorial usa una red neuronal para resolver el problema de clasificación de pingüinos. [*Las redes neuronales*](https://developers.google.com/machine-learning/glossary/#neural_network) pueden encontrar relaciones complejas entre las características y la etiqueta. Se trata de un grafo muy estructurado, organizado en una o varias [*capas ocultas*](https://developers.google.com/machine-learning/glossary/#hidden_layer). Cada capa oculta está formada por una o más [*neuronas*](https://developers.google.com/machine-learning/glossary/#neuron). Existen varias categorías de redes neuronales y este programa usa una red neuronal densa, o [*completamente conectada*](https://developers.google.com/machine-learning/glossary/#fully_connected_layer): las neuronas de una capa reciben conexiones de entrada de *cada* neurona de la capa anterior. Por ejemplo, la figura 2 ilustra una red neuronal densa formada por una capa de entrada, dos capas ocultas y una capa de salida:\n",
        "\n",
        "<table>\n",
        "  <tr><td>     <img src=\"https://www.tensorflow.org/tutorials/customization/images/full_network_penguin.png\" class=\"no-filter\" alt=\"Diagrama de la arquitectura de la red: Entradas, 2 capas ocultas y salidas\"> </td></tr>\n",
        "  <tr><td align=\"center\">     <b>Figura 2.</b> Una red neuronal con características, capas ocultas y predicciones.<br> </td></tr>\n",
        "</table>\n",
        "\n",
        "Cuando entrena el modelo de la Figura 2 y lo alimenta con un ejemplo sin etiquetar, produce tres predicciones: la probabilidad de que este pingüino sea de la especie dada. Esta predicción se llama [*inferencia*](https://developers.google.com/machine-learning/crash-course/glossary#inference). En este ejemplo, la suma de las predicciones de salida es 1.0. En la Figura 2, esta predicción se desglosa como `0.02` para la especie *de Adelia*, `0.95` para la especie *barbijo*, y `0.03` para la especie *gentú*. Esto significa que el modelo predice (con un 95 % de probabilidad) que un pingüino de ejemplo no etiquetado es un *pingüino Barbijo*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W23DIMVPQEBt"
      },
      "source": [
        "### Crear un modelo usando Keras\n",
        "\n",
        "La API TensorFlow `tf.keras` es la forma preferida de crear modelos y capas. Esto facilita la creación de modelos y la experimentación, a la vez que Keras se encarga de la complejidad de conectarlo todo.\n",
        "\n",
        "El modelo `tf.keras.Sequential` es una pila lineal de capas. Su constructor toma una lista de instancias de capas, en este caso, dos capas `tf.keras.layers.Dense` con 10 nodos cada una, y una capa de salida con 3 nodos para representar sus predicciones de etiquetas. El parámetro `input_shape` de la primera capa corresponde al número de características del conjunto de datos, y es obligatorio:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2fZ6oL2ig3ZK"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(10, activation=tf.nn.relu, input_shape=(4,)),  # input shape required\n",
        "  tf.keras.layers.Dense(10, activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dense(3)\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHcbEzMpxbHL"
      },
      "source": [
        "La [*función de activación*](https://developers.google.com/machine-learning/crash-course/glossary#activation_function) determina la forma de salida de cada nodo de la capa. Estas no linealidades son importantes: sin ellas, el modelo sería equivalente a una sola capa. Hay muchas `tf.keras.activations`, pero para las capas ocultas es común usar [ReLU](https://developers.google.com/machine-learning/crash-course/glossary#ReLU).\n",
        "\n",
        "La cantidad ideal de capas ocultas y neuronas varía en función del problema y del conjunto de datos. Igual que muchos aspectos del aprendizaje automático, se requiere una mezcla de conocimientos y experimentación para elegir la mejor forma de la red neuronal. Como regla general, aumentar el número de capas ocultas y neuronas suele crear un modelo más potente, que requiere más datos para entrenarse eficazmente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wFKnhWCpDSS"
      },
      "source": [
        "### Usar el modelo\n",
        "\n",
        "Veamos rápidamente lo que hace este modelo con un lote de funciones:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xe6SQ5NrpB-I"
      },
      "outputs": [],
      "source": [
        "predictions = model(features)\n",
        "predictions[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxyXOhwVr5S3"
      },
      "source": [
        "Aquí, cada ejemplo devuelve un [logit](https://developers.google.com/machine-learning/crash-course/glossary#logits) para cada clase.\n",
        "\n",
        "Para convertir estos logits en una probabilidad para cada clase, use la función [softmax](https://developers.google.com/machine-learning/crash-course/glossary#softmax):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_tRwHZmTNTX2"
      },
      "outputs": [],
      "source": [
        "tf.nn.softmax(predictions[:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRZmchElo481"
      },
      "source": [
        "Si se toma el `tf.math.argmax` entre las clases, obtenemos el índice de clase predicho. Pero el modelo aún no se ha entrenado, así que no son buenas predicciones:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Jzm_GoErz8B"
      },
      "outputs": [],
      "source": [
        "print(\"Prediction: {}\".format(tf.math.argmax(predictions, axis=1)))\n",
        "print(\"    Labels: {}\".format(labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vzq2E5J2QMtw"
      },
      "source": [
        "## Entrenar el modelo\n",
        "\n",
        "El [*entrenamiento*](https://developers.google.com/machine-learning/crash-course/glossary#training) es la fase del aprendizaje automático en la que el modelo se optimiza gradualmente, es decir, el modelo *aprende* el conjunto de datos. La meta es que aprenda lo suficiente sobre la estructura del conjunto de datos de entrenamiento para hacer predicciones sobre datos que no haya visto. Si aprende *demasiado* sobre el conjunto de datos de entrenamiento, las predicciones sólo funcionarán para los datos que haya visto y no serán generalizables. Este problema se llama [*sobreajuste*](https://developers.google.com/machine-learning/crash-course/glossary#overfitting): es como memorizar las respuestas en lugar de comprender cómo resolver un problema.\n",
        "\n",
        "El problema de clasificación de pingüinos es un ejemplo de [*aprendizaje automático supervisado*](https://developers.google.com/machine-learning/glossary/#supervised_machine_learning): el modelo se entrena a partir de ejemplos que contienen etiquetas. En el [*aprendizaje automático no supervisado*](https://developers.google.com/machine-learning/glossary/#unsupervised_machine_learning), los ejemplos no contienen etiquetas. En su lugar, el modelo suele encontrar patrones entre las características."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RaKp8aEjKX6B"
      },
      "source": [
        "### Definir la pérdida y la función de gradientes\n",
        "\n",
        "Tanto en la fase de entrenamiento como en la de evaluación hay que calcular la [*pérdida*](https://developers.google.com/machine-learning/crash-course/glossary#loss) del modelo. Esto mide lo alejadas que están las predicciones de un modelo de la etiqueta deseada, en otras palabras, lo mal que funciona el modelo. Se desea minimizar, u optimizar, este valor.\n",
        "\n",
        "Su modelo calculará su pérdida usando la función `tf.keras.losses.SparseCategoricalCrossentropy` que toma las predicciones de probabilidad de clase del modelo y la etiqueta deseada, y devuelve la pérdida media en todos los ejemplos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QOsi6b-1CXIn"
      },
      "outputs": [],
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tMAT4DcMPwI-"
      },
      "outputs": [],
      "source": [
        "def loss(model, x, y, training):\n",
        "  # training=training is needed only if there are layers with different\n",
        "  # behavior during training versus inference (e.g. Dropout).\n",
        "  y_ = model(x, training=training)\n",
        "\n",
        "  return loss_object(y_true=y, y_pred=y_)\n",
        "\n",
        "l = loss(model, features, labels, training=False)\n",
        "print(\"Loss test: {}\".format(l))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IcPqA24QM6B"
      },
      "source": [
        "Use el contexto `tf.GradientTape` para calcular los [*gradientes*](https://developers.google.com/machine-learning/crash-course/glossary#gradient) usados para optimizar su modelo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x57HcKWhKkei"
      },
      "outputs": [],
      "source": [
        "def grad(model, inputs, targets):\n",
        "  with tf.GradientTape() as tape:\n",
        "    loss_value = loss(model, inputs, targets, training=True)\n",
        "  return loss_value, tape.gradient(loss_value, model.trainable_variables)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOxFimtlKruu"
      },
      "source": [
        "### Crear un optimizador\n",
        "\n",
        "Un [*optimizador*](https://developers.google.com/machine-learning/crash-course/glossary#optimizer) aplica los gradientes calculados a los parámetros del modelo para minimizar la función `loss`. Imagine la función loss como una superficie curva (vea la Figura 3) y quiere encontrar su punto más bajo andando a su alrededor. Los gradientes apuntan en la dirección del ascenso más pronunciado, así que se desplazará en sentido contrario y bajará por la colina. Calculando iterativamente la pérdida y el gradiente para cada lote, ajustará el modelo durante el entrenamiento. Gradualmente, el modelo encontrará la mejor combinación de ponderaciones y sesgo para minimizar la pérdida. Y cuanto menor sea la pérdida, mejores serán las predicciones del modelo.\n",
        "\n",
        "<table>\n",
        "  <tr><td>     <img src=\"https://cs231n.github.io/assets/nn3/opt1.gif\" width=\"70%\" alt=\"Algoritmos de optimización visualizados en el tiempo en un espacio 3D.\"> </td></tr>\n",
        "  <tr><td align=\"center\">     <b>Figura 3.</b> Algoritmos de optimización visualizados en el tiempo en un espacio 3D.<br>(Fuente: <a href=\"http://cs231n.github.io/neural-networks-3/\">Stanford class CS231n</a>, licencia del MIT, Créditos de imagen: <a href=\"https://twitter.com/alecrad\">Alec Radford</a>)</td></tr>\n",
        "</table>\n",
        "\n",
        "TensorFlow tiene muchos algoritmos de optimización disponibles para el entrenamiento. En este tutorial, usará `tf.keras.optimizers.SGD` que implementa el algoritmo [*descenso de gradiente estocástico*](https://developers.google.com/machine-learning/crash-course/glossary#gradient_descent) (SGD). El parámetro `learning_rate` fija el tamaño del paso que hay que dar en cada iteración cuesta abajo. Esta tasa es un [*hiperparámetro*](https://developers.google.com/machine-learning/glossary/#hyperparameter) que deberá ajustar habitualmente para obtener mejores resultados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkUd6UiZa_dF"
      },
      "source": [
        "Instancie el optimizador con una [*velocidad de aprendizaje*](https://developers.google.com/machine-learning/glossary#learning-rate) de `0.01`, un valor escalar que se multiplica por el gradiente en cada iteración del entrenamiento:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8xxi2NNGKwG_"
      },
      "outputs": [],
      "source": [
        "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJVRZ0hP52ZB"
      },
      "source": [
        "A continuación, use este objeto para calcular un único paso de optimización:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rxRNTFVe56RG"
      },
      "outputs": [],
      "source": [
        "loss_value, grads = grad(model, features, labels)\n",
        "\n",
        "print(\"Step: {}, Initial Loss: {}\".format(optimizer.iterations.numpy(),\n",
        "                                          loss_value.numpy()))\n",
        "\n",
        "optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "print(\"Step: {},         Loss: {}\".format(optimizer.iterations.numpy(),\n",
        "                                          loss(model, features, labels, training=True).numpy()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Y2VSELvwAvW"
      },
      "source": [
        "### Bucle de entrenamiento\n",
        "\n",
        "Con todas las piezas en su sitio, ¡el modelo está listo para ser entrenado! Un bucle de entrenamiento alimenta el modelo con los ejemplos del conjunto de datos para ayudarle a hacer mejores predicciones. El siguiente bloque de código establece estos pasos de entrenamiento:\n",
        "\n",
        "1. Itere cada *epoca*. Una época es una pasada por el conjunto de datos.\n",
        "2. Dentro de una época, itere sobre cada ejemplo del `Dataset` de entrenamiento tomando sus *características* (`x`) y *etiqueta* (`y`).\n",
        "3. Usando las características del ejemplo, haga una predicción y compárela con la etiqueta. Mida la inexactitud de la predicción y úsela para calcular la pérdida y los gradientes del modelo.\n",
        "4. Use un `optimizer` para actualizar los parámetros del modelo.\n",
        "5. Conserve algunas estadísticas para visualizarlas.\n",
        "6. Repítalo para cada época.\n",
        "\n",
        "La variable `num_epochs` es el número de veces que se repite el bucle sobre la colección de conjuntos de datos. En el siguiente código, `num_epochs` se fija en 201, lo que significa que este bucle de entrenamiento se ejecutará 201 veces. Aunque parezca contradictorio, entrenar un modelo durante más tiempo no garantiza un mejor modelo. `num_epochs` es un [*hiperparámetro*](https://developers.google.com/machine-learning/glossary/#hyperparameter) que puede ajustar. Seleccionar el número adecuado suele requerir experiencia y experimentación:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AIgulGRUhpto"
      },
      "outputs": [],
      "source": [
        "## Note: Rerunning this cell uses the same model parameters\n",
        "\n",
        "# Keep results for plotting\n",
        "train_loss_results = []\n",
        "train_accuracy_results = []\n",
        "\n",
        "num_epochs = 201\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  epoch_loss_avg = tf.keras.metrics.Mean()\n",
        "  epoch_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "\n",
        "  # Training loop - using batches of 32\n",
        "  for x, y in ds_train_batch:\n",
        "    # Optimize the model\n",
        "    loss_value, grads = grad(model, x, y)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "    # Track progress\n",
        "    epoch_loss_avg.update_state(loss_value)  # Add current batch loss\n",
        "    # Compare predicted label to actual label\n",
        "    # training=True is needed only if there are layers with different\n",
        "    # behavior during training versus inference (e.g. Dropout).\n",
        "    epoch_accuracy.update_state(y, model(x, training=True))\n",
        "\n",
        "  # End epoch\n",
        "  train_loss_results.append(epoch_loss_avg.result())\n",
        "  train_accuracy_results.append(epoch_accuracy.result())\n",
        "\n",
        "  if epoch % 50 == 0:\n",
        "    print(\"Epoch {:03d}: Loss: {:.3f}, Accuracy: {:.3%}\".format(epoch,\n",
        "                                                                epoch_loss_avg.result(),\n",
        "                                                                epoch_accuracy.result()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Diep-ROEuKyl"
      },
      "source": [
        "También puede usar el método incorporado [`Model.fit(ds_train_batch)`](https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit) de Keras para entrenar su modelo. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FQHVUnm_rjw"
      },
      "source": [
        "### Ver la función de pérdida en el tiempo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3wdbmtLVTyr"
      },
      "source": [
        "Aunque es útil imprimir el progreso del entrenamiento del modelo, puede visualizarlo con [TensorBoard](https://www.tensorflow.org/tensorboard), una herramienta de visualización y métricas que viene incluida con TensorFlow. Para este sencillo ejemplo, usará el módulo `matplotlib` para crear gráficos básicos.\n",
        "\n",
        "Hay que aprender a interpretar estos gráficos, pero en general lo que se desea es que disminuya la *pérdida* y aumente la *precisión*:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "agjvNd2iUGFn"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(2, sharex=True, figsize=(12, 8))\n",
        "fig.suptitle('Training Metrics')\n",
        "\n",
        "axes[0].set_ylabel(\"Loss\", fontsize=14)\n",
        "axes[0].plot(train_loss_results)\n",
        "\n",
        "axes[1].set_ylabel(\"Accuracy\", fontsize=14)\n",
        "axes[1].set_xlabel(\"Epoch\", fontsize=14)\n",
        "axes[1].plot(train_accuracy_results)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zg8GoMZhLpGH"
      },
      "source": [
        "## Evaluar la eficacia del modelo\n",
        "\n",
        "Ahora que el modelo está entrenado, puede sacar algunas estadísticas sobre su rendimiento.\n",
        "\n",
        "*Evaluar* significa determinar la eficacia del modelo a la hora de hacer predicciones. Para determinar la eficacia del modelo en la clasificación de pingüinos, pásele algunas mediciones y pídale que prediga qué especie de pingüino representan. Luego compare sus predicciones con la etiqueta real. Por ejemplo, un modelo que eligió la especie correcta en la mitad de los ejemplos de entrada tiene una [*precisión*](https://developers.google.com/machine-learning/glossary/#accuracy) de `0.5`. La figura 4 muestra un modelo ligeramente más eficaz, que acierta 4 de cada 5 predicciones con una precisión del 80%:\n",
        "\n",
        "<table cellpadding=\"8\" border=\"0\">\n",
        "  <colgroup>\n",
        "    <col span=\"4\">\n",
        "    <col span=\"1\" bgcolor=\"lightblue\">\n",
        "    <col span=\"1\" bgcolor=\"lightgreen\">\n",
        "  </colgroup>\n",
        "  <tr bgcolor=\"lightgray\">\n",
        "    <th colspan=\"4\">Características de ejemplo</th>\n",
        "    <th colspan=\"1\">Etiqueta</th>\n",
        "    <th colspan=\"1\">Predicción del modelo</th>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>5.9</td>\n",
        "<td>3.0</td>\n",
        "<td>4.3</td>\n",
        "<td>1.5</td>\n",
        "<td align=\"center\">1</td>\n",
        "<td align=\"center\">1</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>6.9</td>\n",
        "<td>3.1</td>\n",
        "<td>5.4</td>\n",
        "<td>2.1</td>\n",
        "<td align=\"center\">2</td>\n",
        "<td align=\"center\">2</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>5.1</td>\n",
        "<td>3.3</td>\n",
        "<td>1.7</td>\n",
        "<td>0.5</td>\n",
        "<td align=\"center\">0</td>\n",
        "<td align=\"center\">0</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>6.0</td> <td>3.4</td> <td>4.5</td> <td>1.6</td> <td align=\"center\">1</td>\n",
        "<td align=\"center\" bgcolor=\"red\">2</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>5.5</td>\n",
        "<td>2.5</td>\n",
        "<td>4.0</td>\n",
        "<td>1.3</td>\n",
        "<td align=\"center\">1</td>\n",
        "<td align=\"center\">1</td>\n",
        "  </tr>\n",
        "  <tr><td align=\"center\" colspan=\"6\">     <b>Figura 4.</b> Un clasificador de pingüinos con un 80% de precisión.<br> </td></tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-EvK7hGL0d8"
      },
      "source": [
        "### Configurar el conjunto de pruebas\n",
        "\n",
        "Evaluar el modelo es similar a entrenarlo. La mayor diferencia es que los ejemplos vienen de un *[conjunto de prueba](https://developers.google.com/machine-learning/crash-course/glossary#test_set)* distinto del conjunto de entrenamiento. Si quiere evaluar correctamente la eficacia de un modelo, los ejemplos usados para evaluarlo deben ser distintos de los usados para entrenarlo.\n",
        "\n",
        "El conjunto de datos de pingüinos no tiene un conjunto de datos de prueba separado, así que, en la sección anterior Descargar el conjunto de datos, divida el conjunto de datos original en conjuntos de datos de prueba y de entrenamiento. Use el conjunto de datos `ds_test_batch` para la evaluación."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFuOKXJdMAdm"
      },
      "source": [
        "### Evaluar el modelo en el conjunto de datos de prueba\n",
        "\n",
        "A diferencia de la etapa de entrenamiento, el modelo sólo evalúa una única [época](https://developers.google.com/machine-learning/glossary/#epoch) de los datos de prueba. El código siguiente itera sobre cada ejemplo del conjunto de prueba y compara la predicción del modelo con la etiqueta real. Esta comparación se usa para medir la precisión del modelo en todo el conjunto de pruebas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tw03-MK1cYId"
      },
      "outputs": [],
      "source": [
        "test_accuracy = tf.keras.metrics.Accuracy()\n",
        "ds_test_batch = ds_test.batch(10)\n",
        "\n",
        "for (x, y) in ds_test_batch:\n",
        "  # training=False is needed only if there are layers with different\n",
        "  # behavior during training versus inference (e.g. Dropout).\n",
        "  logits = model(x, training=False)\n",
        "  prediction = tf.math.argmax(logits, axis=1, output_type=tf.int64)\n",
        "  test_accuracy(prediction, y)\n",
        "\n",
        "print(\"Test set accuracy: {:.3%}\".format(test_accuracy.result()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fel8ql2qzGlK"
      },
      "source": [
        "También puede usar la función `model.evaluate(ds_test, return_dict=True)` de keras para conseguir información de qué tan preciso es su conjunto de datos de prueba. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcKEZMtCOeK-"
      },
      "source": [
        "Al inspeccionar el último lote, por ejemplo, puede ver que las predicciones del modelo suelen ser correctas.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uNwt2eMeOane"
      },
      "outputs": [],
      "source": [
        "tf.stack([y,prediction],axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Li2r1tYvW7S"
      },
      "source": [
        "## Usar el modelo entrenado para hacer predicciones\n",
        "\n",
        "Ha entrenado un modelo y \"demostrado\" que es bueno (pero no perfecto) para clasificar las especies de pingüinos. Ahora vamos a usar el modelo entrenado para hacer algunas predicciones con [*ejemplos sin etiquetar*](https://developers.google.com/machine-learning/glossary/#unlabeled_example); es decir, con ejemplos que tienen características pero no etiquetas.\n",
        "\n",
        "En la vida real, los ejemplos sin etiquetar pueden venir de muchas fuentes distintas, como apps, archivos CSV y fuentes de datos. Para este tutorial, le damos manualmente tres ejemplos sin etiquetar para predecir sus etiquetas. Recuerde que los números de etiqueta se mapean en una representación con nombre como:\n",
        "\n",
        "- `0`: pingüino de Adelia\n",
        "- `1`: pingüino barbijo\n",
        "- `2`: pingüino gentú"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kesTS5Lzv-M2"
      },
      "outputs": [],
      "source": [
        "predict_dataset = tf.convert_to_tensor([\n",
        "    [0.3, 0.8, 0.4, 0.5,],\n",
        "    [0.4, 0.1, 0.8, 0.5,],\n",
        "    [0.7, 0.9, 0.8, 0.4]\n",
        "])\n",
        "\n",
        "# training=False is needed only if there are layers with different\n",
        "# behavior during training versus inference (e.g. Dropout).\n",
        "predictions = model(predict_dataset, training=False)\n",
        "\n",
        "for i, logits in enumerate(predictions):\n",
        "  class_idx = tf.math.argmax(logits).numpy()\n",
        "  p = tf.nn.softmax(logits)[class_idx]\n",
        "  name = class_names[class_idx]\n",
        "  print(\"Example {} prediction: {} ({:4.1f}%)\".format(i, name, 100*p))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "custom_training_walkthrough.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
