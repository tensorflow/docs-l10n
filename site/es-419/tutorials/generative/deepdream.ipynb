{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SgrstLXNbG_"
      },
      "source": [
        "##### Copyright 2019 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "k7gifg92NbG9"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCMqzy7BNbG9"
      },
      "source": [
        "# DeepDream"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yqCPS8SNbG8"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>     <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/generative/deepdream\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver en TensorFlow.org</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/es-419/tutorials/generative/deepdream.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Ejecutar en Google Colab</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/es-419/tutorials/generative/deepdream.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver código fuente en GitHub</a>\n",
        "</td>\n",
        "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/es-419/tutorials/generative/deepdream.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Descargar el bloc de notas</a>\n",
        "</td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPDKhwPcNbG7"
      },
      "source": [
        "En este tutorial encontrará una implementación mínima de DeepDream, como se describe en esta [entrada de blog](https://ai.googleblog.com/2015/06/inceptionism-going-deeper-into-neural.html) de Alexander Mordvintsev.\n",
        "\n",
        "DeepDream es un experimento que visualiza los patrones aprendidos por la red neuronal. De forma similar a la que un niño mira las nubes e intenta interpretar formas aleatorias, DeepDream sobreinterpreta y mejora los patrones en una imagen.\n",
        "\n",
        "Para hacer esto, DeepDream envía una imagen a través de la red, luego calcula el gradiente de la imagen en relación con las activaciones de una capa en particular. Entonces se modifica la imagen para aumentar las activaciones y se mejoran los patrones que ve la red, lo que da como resultado una imagen onírica. Este proceso se denomina \"inceptionism\" (una referencia a [InceptionNet](https://arxiv.org/pdf/1409.4842.pdf) y a la [película](https://en.wikipedia.org/wiki/Inception) El origen).\n",
        "\n",
        "Veamos cómo puede hacer que una red neuronal \"sueñe\" y mejore los patrones surreales que ve en una imagen.\n",
        "\n",
        "![Dogception](https://www.tensorflow.org/tutorials/generative/images/dogception.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sc5Yq_Rgxreb"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g_Qp173_NbG5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "import matplotlib as mpl\n",
        "\n",
        "import IPython.display as display\n",
        "import PIL.Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgeIJg82NbG4"
      },
      "source": [
        "## Elegir una imagen para hacerla onírica"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yt6zam_9NbG4"
      },
      "source": [
        "Para este tutorial, usemos una imagen de un [labrador](https://commons.wikimedia.org/wiki/File:YellowLabradorLooking_new.jpg)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0lclzk9sNbG2"
      },
      "outputs": [],
      "source": [
        "url = 'https://storage.googleapis.com/download.tensorflow.org/example_images/YellowLabradorLooking_new.jpg'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y5BPgc8NNbG0"
      },
      "outputs": [],
      "source": [
        "# Download an image and read it into a NumPy array.\n",
        "def download(url, max_dim=None):\n",
        "  name = url.split('/')[-1]\n",
        "  image_path = tf.keras.utils.get_file(name, origin=url)\n",
        "  img = PIL.Image.open(image_path)\n",
        "  if max_dim:\n",
        "    img.thumbnail((max_dim, max_dim))\n",
        "  return np.array(img)\n",
        "\n",
        "# Normalize an image\n",
        "def deprocess(img):\n",
        "  img = 255*(img + 1.0)/2.0\n",
        "  return tf.cast(img, tf.uint8)\n",
        "\n",
        "# Display an image\n",
        "def show(img):\n",
        "  display.display(PIL.Image.fromarray(np.array(img)))\n",
        "\n",
        "\n",
        "# Downsizing the image makes it easier to work with.\n",
        "original_img = download(url, max_dim=500)\n",
        "show(original_img)\n",
        "display.display(display.HTML('Image cc-by: <a \"href=https://commons.wikimedia.org/wiki/File:Felis_catus-cat_on_snow.jpg\">Von.grzanka</a>'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4RBFfIWNbG0"
      },
      "source": [
        "## Preparar el modelo de extracción de características"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cruNQmMDNbGz"
      },
      "source": [
        "Descargue y prepare un modelo de clasificación de imágenes preentrenado. Usará [InceptionV3](https://keras.io/api/applications/inceptionv3/) que es similar al modelo usado originalmente en DeepDream. Tenga en cuenta que cualquier [modelo preentrenado](https://keras.io/api/applications/#available-models) funcionará, aunque, si lo cambia, deberá ajustar los nombres de la capa a continuación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GlLi48GKNbGy"
      },
      "outputs": [],
      "source": [
        "base_model = tf.keras.applications.InceptionV3(include_top=False, weights='imagenet')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bujb0jPNNbGx"
      },
      "source": [
        "La idea en DeepDream es elegir una capa (o capas) y maximizar la \"pérdida\" de manera que la imagen \"avive\" las capas progresivamente. La complejidad de las características incorporadas depende de las capas que usted elija, por ejemplo, las capas inferiores producen trazos y patrones simples, mientras que las capas más profundas les dan características más sofisticadas a las imágenes o incluso objetos enteros."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOVmDO4LNbGv"
      },
      "source": [
        "La arquitectura de InceptionV3 es bastante grande (para ver un gráfico de la arquitectura del modelo visite el [repositorio de investigación](https://github.com/tensorflow/models/tree/master/research/slim)) de TensorFlow. Para DeepDream, las capas de interés son aquellas donde las convoluciones están concatenadas. En InceptionV3 hay 11 de estas capas, llamadas \"mixed0\" hasta \"mixed10\". El uso de diferentes capas dará resultados de diferentes imágenes oníricas. Las capas más profundas responden a características de nivel más alto (como ojos y caras), mientras que las primeras capas responden a características más simples (como bordes, formas y texturas). Puede experimentar libremente con las capas que seleccione a continuación, pero tenga en cuenta que llevará más tiempo entrenar las capas más profundas (aquellas con un mayor índice) ya que la computación de gradientes es más profunda."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "08KB502ONbGt"
      },
      "outputs": [],
      "source": [
        "# Maximize the activations of these layers\n",
        "names = ['mixed3', 'mixed5']\n",
        "layers = [base_model.get_layer(name).output for name in names]\n",
        "\n",
        "# Create the feature extraction model\n",
        "dream_model = tf.keras.Model(inputs=base_model.input, outputs=layers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sb7u31B4NbGt"
      },
      "source": [
        "## Calcular la pérdida\n",
        "\n",
        "La pérdida es la suma de las activaciones en las capas seleccionadas. La pérdida se normaliza en cada capa para que la contribución de las capas más grandes no supere el peso de las capas más pequeñas. Normalmente, la pérdida es una cantidad que se quiere minimizar con el descenso del gradiente. En DeepDream, maximizará esta pérdida mediante el ascenso del gradiente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8MhfSweXXiuq"
      },
      "outputs": [],
      "source": [
        "def calc_loss(img, model):\n",
        "  # Pass forward the image through the model to retrieve the activations.\n",
        "  # Converts the image into a batch of size 1.\n",
        "  img_batch = tf.expand_dims(img, axis=0)\n",
        "  layer_activations = model(img_batch)\n",
        "  if len(layer_activations) == 1:\n",
        "    layer_activations = [layer_activations]\n",
        "\n",
        "  losses = []\n",
        "  for act in layer_activations:\n",
        "    loss = tf.math.reduce_mean(act)\n",
        "    losses.append(loss)\n",
        "\n",
        "  return  tf.reduce_sum(losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4TCNsAUO9kI"
      },
      "source": [
        "## Ascenso de gradiente\n",
        "\n",
        "Una vez calculada la pérdida para las capas seleccionadas, lo único que queda es calcular los gradientes con respecto a la imagen y agregarlas a la imagen original.\n",
        "\n",
        "Al agregar los gradientes en la imagen, se mejoran los patrones que ve la red. En cada paso, creará una imagen que avive progresivamente las activaciones de ciertas capas en la red.\n",
        "\n",
        "El método que hace esto, a continuación, estará encapsulado en un `tf.function` para mejorar el rendimiento. Use un `input_signature` para que no se vuelva a recorrer la función para distintos tamaños de imágenes o valores de`pasos`/`step_size`. Vea la [Guía de funciones concretas](../../guide/function.ipynb) para obtener más detalles."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qRScWg_VNqvj"
      },
      "outputs": [],
      "source": [
        "class DeepDream(tf.Module):\n",
        "  def __init__(self, model):\n",
        "    self.model = model\n",
        "\n",
        "  @tf.function(\n",
        "      input_signature=(\n",
        "        tf.TensorSpec(shape=[None,None,3], dtype=tf.float32),\n",
        "        tf.TensorSpec(shape=[], dtype=tf.int32),\n",
        "        tf.TensorSpec(shape=[], dtype=tf.float32),)\n",
        "  )\n",
        "  def __call__(self, img, steps, step_size):\n",
        "      print(\"Tracing\")\n",
        "      loss = tf.constant(0.0)\n",
        "      for n in tf.range(steps):\n",
        "        with tf.GradientTape() as tape:\n",
        "          # This needs gradients relative to `img`\n",
        "          # `GradientTape` only watches `tf.Variable`s by default\n",
        "          tape.watch(img)\n",
        "          loss = calc_loss(img, self.model)\n",
        "\n",
        "        # Calculate the gradient of the loss with respect to the pixels of the input image.\n",
        "        gradients = tape.gradient(loss, img)\n",
        "\n",
        "        # Normalize the gradients.\n",
        "        gradients /= tf.math.reduce_std(gradients) + 1e-8 \n",
        "        \n",
        "        # In gradient ascent, the \"loss\" is maximized so that the input image increasingly \"excites\" the layers.\n",
        "        # You can update the image by directly adding the gradients (because they're the same shape!)\n",
        "        img = img + gradients*step_size\n",
        "        img = tf.clip_by_value(img, -1, 1)\n",
        "\n",
        "      return loss, img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yB9pTqn6xfuK"
      },
      "outputs": [],
      "source": [
        "deepdream = DeepDream(dream_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLArRTVHZFAi"
      },
      "source": [
        "## Bucle principal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9vHEcy7dTysi"
      },
      "outputs": [],
      "source": [
        "def run_deep_dream_simple(img, steps=100, step_size=0.01):\n",
        "  # Convert from uint8 to the range expected by the model.\n",
        "  img = tf.keras.applications.inception_v3.preprocess_input(img)\n",
        "  img = tf.convert_to_tensor(img)\n",
        "  step_size = tf.convert_to_tensor(step_size)\n",
        "  steps_remaining = steps\n",
        "  step = 0\n",
        "  while steps_remaining:\n",
        "    if steps_remaining>100:\n",
        "      run_steps = tf.constant(100)\n",
        "    else:\n",
        "      run_steps = tf.constant(steps_remaining)\n",
        "    steps_remaining -= run_steps\n",
        "    step += run_steps\n",
        "\n",
        "    loss, img = deepdream(img, run_steps, tf.constant(step_size))\n",
        "    \n",
        "    display.clear_output(wait=True)\n",
        "    show(deprocess(img))\n",
        "    print (\"Step {}, loss {}\".format(step, loss))\n",
        "\n",
        "\n",
        "  result = deprocess(img)\n",
        "  display.clear_output(wait=True)\n",
        "  show(result)\n",
        "\n",
        "  return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tEfd00rr0j8Z"
      },
      "outputs": [],
      "source": [
        "dream_img = run_deep_dream_simple(img=original_img, \n",
        "                                  steps=100, step_size=0.01)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PbfXEVFNbGp"
      },
      "source": [
        "## Subir una octava\n",
        "\n",
        "Todo muy lindo pero hay algunos problemas con el primer intento:\n",
        "\n",
        "1. La salida tiene ruido (esto puede tratarse con una pérdida `tf.image.total_variation`).\n",
        "2. La imagen es de baja resolución.\n",
        "3. Parece como si los patrones ocurrieran en la misma granularidad.\n",
        "\n",
        "Nuestro enfoque para encargarse de todos estos problemas es aplicar un ascenso de gradiente a diferentes escalas. Esto permitirá que los patrones se generen a escalas más pequeñas para que sean incorporados en patrones de escalas más altas y que se completen con detalles adicionales.\n",
        "\n",
        "Para hacer esto, puede ejecutar el enfoque previo de ascenso de gradiente, luego puede aumentar el tamaño de la imagen (conocido como una octava) y repetir el proceso para múltiples octavas.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0eGDSdatLT-8"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "start = time.time()\n",
        "\n",
        "OCTAVE_SCALE = 1.30\n",
        "\n",
        "img = tf.constant(np.array(original_img))\n",
        "base_shape = tf.shape(img)[:-1]\n",
        "float_base_shape = tf.cast(base_shape, tf.float32)\n",
        "\n",
        "for n in range(-2, 3):\n",
        "  new_shape = tf.cast(float_base_shape*(OCTAVE_SCALE**n), tf.int32)\n",
        "\n",
        "  img = tf.image.resize(img, new_shape).numpy()\n",
        "\n",
        "  img = run_deep_dream_simple(img=img, steps=50, step_size=0.01)\n",
        "\n",
        "display.clear_output(wait=True)\n",
        "img = tf.image.resize(img, base_shape)\n",
        "img = tf.image.convert_image_dtype(img/255.0, dtype=tf.uint8)\n",
        "show(img)\n",
        "\n",
        "end = time.time()\n",
        "end-start"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9xqyeuwLZFy"
      },
      "source": [
        "## Opcional: Aumentar la escala con mosaicos\n",
        "\n",
        "Se debe considerar que a medida que aumenta el tamaño de la imagen, también aumentará el tiempo y la memoria que se necesitan para realizar el cálculo del gradiente. La implementación de la octava anterior no funcionará en imágenes muy grandes o en muchas octavas.\n",
        "\n",
        "Para evitar este problema puede dividir la imagen en mosaicos y calcular el gradiente de cada mosaico.\n",
        "\n",
        "Al aplicar desplazamientos aleatorios en la imagen antes de cada cálculo de mosaico se evita que aparezcan uniones de mosaicos.\n",
        "\n",
        "Para empezar, implemente el desplazamiento aleatorio:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oGgLHk7o80ac"
      },
      "outputs": [],
      "source": [
        "def random_roll(img, maxroll):\n",
        "  # Randomly shift the image to avoid tiled boundaries.\n",
        "  shift = tf.random.uniform(shape=[2], minval=-maxroll, maxval=maxroll, dtype=tf.int32)\n",
        "  img_rolled = tf.roll(img, shift=shift, axis=[0,1])\n",
        "  return shift, img_rolled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sKsiqWfA9H41"
      },
      "outputs": [],
      "source": [
        "shift, img_rolled = random_roll(np.array(original_img), 512)\n",
        "show(img_rolled)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGIjA3UhhAt8"
      },
      "source": [
        "Aquí hay un equivalente en mosaico de la función `deepdream` definida anteriormente:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x__TZ0uqNbGm"
      },
      "outputs": [],
      "source": [
        "class TiledGradients(tf.Module):\n",
        "  def __init__(self, model):\n",
        "    self.model = model\n",
        "\n",
        "  @tf.function(\n",
        "      input_signature=(\n",
        "        tf.TensorSpec(shape=[None,None,3], dtype=tf.float32),\n",
        "        tf.TensorSpec(shape=[2], dtype=tf.int32),\n",
        "        tf.TensorSpec(shape=[], dtype=tf.int32),)\n",
        "  )\n",
        "  def __call__(self, img, img_size, tile_size=512):\n",
        "    shift, img_rolled = random_roll(img, tile_size)\n",
        "\n",
        "    # Initialize the image gradients to zero.\n",
        "    gradients = tf.zeros_like(img_rolled)\n",
        "    \n",
        "    # Skip the last tile, unless there's only one tile.\n",
        "    xs = tf.range(0, img_size[1], tile_size)[:-1]\n",
        "    if not tf.cast(len(xs), bool):\n",
        "      xs = tf.constant([0])\n",
        "    ys = tf.range(0, img_size[0], tile_size)[:-1]\n",
        "    if not tf.cast(len(ys), bool):\n",
        "      ys = tf.constant([0])\n",
        "\n",
        "    for x in xs:\n",
        "      for y in ys:\n",
        "        # Calculate the gradients for this tile.\n",
        "        with tf.GradientTape() as tape:\n",
        "          # This needs gradients relative to `img_rolled`.\n",
        "          # `GradientTape` only watches `tf.Variable`s by default.\n",
        "          tape.watch(img_rolled)\n",
        "\n",
        "          # Extract a tile out of the image.\n",
        "          img_tile = img_rolled[y:y+tile_size, x:x+tile_size]\n",
        "          loss = calc_loss(img_tile, self.model)\n",
        "\n",
        "        # Update the image gradients for this tile.\n",
        "        gradients = gradients + tape.gradient(loss, img_rolled)\n",
        "\n",
        "    # Undo the random shift applied to the image and its gradients.\n",
        "    gradients = tf.roll(gradients, shift=-shift, axis=[0,1])\n",
        "\n",
        "    # Normalize the gradients.\n",
        "    gradients /= tf.math.reduce_std(gradients) + 1e-8 \n",
        "\n",
        "    return gradients "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vcq4GubA2e5J"
      },
      "outputs": [],
      "source": [
        "get_tiled_gradients = TiledGradients(dream_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hYnTTs_qiaND"
      },
      "source": [
        "Al ponerlo todo junto, le da una implementación de DeepDream escalable que tiene en cuenta la octava:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gA-15DM4NbGk"
      },
      "outputs": [],
      "source": [
        "def run_deep_dream_with_octaves(img, steps_per_octave=100, step_size=0.01, \n",
        "                                octaves=range(-2,3), octave_scale=1.3):\n",
        "  base_shape = tf.shape(img)\n",
        "  img = tf.keras.utils.img_to_array(img)\n",
        "  img = tf.keras.applications.inception_v3.preprocess_input(img)\n",
        "\n",
        "  initial_shape = img.shape[:-1]\n",
        "  img = tf.image.resize(img, initial_shape)\n",
        "  for octave in octaves:\n",
        "    # Scale the image based on the octave\n",
        "    new_size = tf.cast(tf.convert_to_tensor(base_shape[:-1]), tf.float32)*(octave_scale**octave)\n",
        "    new_size = tf.cast(new_size, tf.int32)\n",
        "    img = tf.image.resize(img, new_size)\n",
        "\n",
        "    for step in range(steps_per_octave):\n",
        "      gradients = get_tiled_gradients(img, new_size)\n",
        "      img = img + gradients*step_size\n",
        "      img = tf.clip_by_value(img, -1, 1)\n",
        "\n",
        "      if step % 10 == 0:\n",
        "        display.clear_output(wait=True)\n",
        "        show(deprocess(img))\n",
        "        print (\"Octave {}, Step {}\".format(octave, step))\n",
        "    \n",
        "  result = deprocess(img)\n",
        "  return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T7PbRLV74RrU"
      },
      "outputs": [],
      "source": [
        "img = run_deep_dream_with_octaves(img=original_img, step_size=0.01)\n",
        "\n",
        "display.clear_output(wait=True)\n",
        "img = tf.image.resize(img, base_shape)\n",
        "img = tf.image.convert_image_dtype(img/255.0, dtype=tf.uint8)\n",
        "show(img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Og0-qLwNbGg"
      },
      "source": [
        "¡Mucho mejor! Pruebe con distintas cantidades de octavas, escala de octavas y capas activadas para cambiar como luce la imagen creada con DeepDream.\n",
        "\n",
        "Quizás también le interese [TensorFlow Lucid](https://github.com/tensorflow/lucid) que expande las ideas presentadas en este tutorial para visualizar e interpretar redes neuronales."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "deepdream.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
