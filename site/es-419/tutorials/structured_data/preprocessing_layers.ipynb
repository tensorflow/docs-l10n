{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zg02FZzDyEqd"
      },
      "source": [
        "##### Copyright 2019 The TensorFlow Authors.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "2mapZ9afGJ69"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMYQvJuBi7MS"
      },
      "source": [
        "# Clasificar datos estructurados usando capas de preprocesamiento Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FaL4wnr22oy"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td><a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/structured_data/preprocessing_layers\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver en TensorFlow.org</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/es-419/tutorials/structured_data/preprocessing_layers.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Ejecutar en Google Colab</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/es-419/tutorials/structured_data/preprocessing_layers.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver fuente en GitHub</a></td>\n",
        "  <td><a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/es-419/tutorials/structured_data/preprocessing_layers.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Descargar el bloc de notas</a></td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nna1tOKxyEqe"
      },
      "source": [
        "Este tutorial muestra cómo clasificar datos estructurados, como datos tabulares, usando una versión simplificada del conjunto de datos <a href=\"https://www.kaggle.com/c/petfinder-adoption-prediction\" class=\"external\">PetFinder de un concurso de Kaggle</a> almacenado en un archivo CSV.\n",
        "\n",
        "Utilizará [Keras](https://www.tensorflow.org/guide/keras) para definir el modelo, y [capas de preprocesamiento Keras](https://www.tensorflow.org/guide/keras/preprocessing_layers) como puente para mapear desde columnas en un archivo CSV a características utilizadas para entrenar el modelo. La meta es predecir si una mascota será adoptada.\n",
        "\n",
        "Este tutorial contiene el código completo para:\n",
        "\n",
        "- Carga de un archivo CSV en un <a href=\"https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html\" class=\"external\">DataFrame</a> usando <a href=\"https://pandas.pydata.org/\" class=\"external\">pandas</a>.\n",
        "- Construir una canalización de entrada para procesar por lotes y barajar las filas usando `tf.data` (visite [tf.data: Construir canalizaciones de entrada TensorFlow](../../guide/data.ipynb) para más detalles).\n",
        "- Mapeo de las columnas del archivo CSV a las características usadas para entrenar el modelo con las capas de preprocesamiento de Keras.\n",
        "- Construir, entrenar y evaluar un modelo usando los métodos incorporados de Keras."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5xkXCicjFQD"
      },
      "source": [
        "Nota: Este tutorial es similar a [Clasificar datos estructurados con columnas de características](../structured_data/feature_columns.ipynb). Esta versión usa las capas de preprocesamiento [Keras](https://www.tensorflow.org/guide/keras/preprocessing_layers) en lugar de la API `tf.feature_column`, ya que las primeras son más intuitivas y pueden incluirse fácilmente dentro de su modelo para simplificar la implementación."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHxU1FMNpomc"
      },
      "source": [
        "## El mini conjunto de datos PetFinder.my\n",
        "\n",
        "Hay varios miles de filas en el mini archivo de datos CSV de PetFinder.my, donde cada fila describe una mascota (un perro o un gato) y cada columna describe un atributo, como la edad, la raza, el color, etc.\n",
        "\n",
        "En el resumen del conjunto de datos que aparece a continuación, observe que hay principalmente columnas numéricas y categóricas. En este tutorial, sólo se ocupará de esos dos tipos de características, eliminando `Description` (una característica de texto libre) y `AdoptionSpeed` (una característica de clasificación) durante el preprocesamiento de los datos.\n",
        "\n",
        "Columna | Descripción de mascota | Tipo de característica | Tipo de datos\n",
        "--- | --- | --- | ---\n",
        "`Type` | Tipo de animal (`Dog`, `Cat`) | Categórica | cadena\n",
        "`Age` | Edad | Numérica | entero\n",
        "`Breed1` | Raza primaria | Categórica | cadena\n",
        "`Color1` | Color 1 | Categórica | cadena\n",
        "`Color2` | Color 2 | Categórica | cadena\n",
        "`MaturitySize` | Tamaño de adulto | Categórica | cadena\n",
        "`FurLength` | Largo de pelo | Categórica | cadena\n",
        "`Vaccinated` | La mascota ha sido vacunada | Categórica | cadena\n",
        "`Sterilized` | La mascota ha sido esterilizada | Categórica | cadena\n",
        "`Health` | Condición de salud | Categórica | cadena\n",
        "`Fee` | Tarifa de adopción | Numérica | entero\n",
        "`Description` | Redacción del perfil | Texto | cadena\n",
        "`PhotoAmt` | Total de fotos subidas | Numérica | entero\n",
        "`AdoptionSpeed` | Rapidez de adopción categórica | Clasificación | entero"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjFbdBldyEqf"
      },
      "source": [
        "## Importar TensorFlow y otras librerías\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LklnLlt6yEqf"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TKU7RyoQGVKB"
      },
      "outputs": [],
      "source": [
        "tf.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXvBvobayEqi"
      },
      "source": [
        "## Cargar el conjunto de datos y leerlo en un DataFrame pandas\n",
        "\n",
        "<a href=\"https://pandas.pydata.org/\" class=\"external\">pandas</a> es una librería de Python con muchas utilidades útiles para cargar y trabajar con datos estructurados. Use `tf.keras.utils.get_file` para descargar y extraer el archivo CSV con el miniconjunto de datos PetFinder.my, y cárguelo en un <a href=\"https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html\" class=\"external\">DataFrame</a> con <a href=\"https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html\" class=\"external\"><code>pandas.read_csv</code></a>:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qJ4Ajn-YyEqj"
      },
      "outputs": [],
      "source": [
        "dataset_url = 'http://storage.googleapis.com/download.tensorflow.org/data/petfinder-mini.zip'\n",
        "csv_file = 'datasets/petfinder-mini/petfinder-mini.csv'\n",
        "\n",
        "tf.keras.utils.get_file('petfinder_mini.zip', dataset_url,\n",
        "                        extract=True, cache_dir='.')\n",
        "dataframe = pd.read_csv(csv_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efa6910dfa5f"
      },
      "source": [
        "Inspeccione el conjunto de datos comprobando las cinco primeras filas del DataFrame:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3uiq4hoIGyXI"
      },
      "outputs": [],
      "source": [
        "dataframe.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3zDbrozyEqq"
      },
      "source": [
        "## Crear una variable objetivo\n",
        "\n",
        "La tarea original del <a href=\"https://www.kaggle.com/c/petfinder-adoption-prediction\" class=\"external\">concurso de Kaggle sobre predicción de adopciones PetFinder.my</a> consistía en predecir la velocidad a la que se adoptará una mascota (por ejemplo, en la primera semana, el primer mes, los tres primeros meses, etc.).\n",
        "\n",
        "En este tutorial, simplificará la tarea transformándola en un problema de clasificación binaria, en el que simplemente tendrá que predecir si una mascota ha sido adoptada o no.\n",
        "\n",
        "Tras modificar la columna `AdoptionSpeed`, `0` indicará que la mascota no fue adoptada y `1` indicará que sí lo fue."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wmMDc46-yEqq"
      },
      "outputs": [],
      "source": [
        "# In the original dataset, `'AdoptionSpeed'` of `4` indicates\n",
        "# a pet was not adopted.\n",
        "dataframe['target'] = np.where(dataframe['AdoptionSpeed']==4, 0, 1)\n",
        "\n",
        "# Drop unused features.\n",
        "dataframe = dataframe.drop(columns=['AdoptionSpeed', 'Description'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sp0NCbswyEqs"
      },
      "source": [
        "## Dividir el DataFrame en conjuntos de entrenamiento, validación y prueba\n",
        "\n",
        "El conjunto de datos está en un único DataFrame pandas. Divídalo en conjuntos de entrenamiento, validación y prueba usando, por ejemplo, una proporción 80:10:10, respectivamente:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XvSinthO8oMj"
      },
      "outputs": [],
      "source": [
        "train, val, test = np.split(dataframe.sample(frac=1), [int(0.8*len(dataframe)), int(0.9*len(dataframe))])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U02Q1moWoPwQ"
      },
      "outputs": [],
      "source": [
        "print(len(train), 'training examples')\n",
        "print(len(val), 'validation examples')\n",
        "print(len(test), 'test examples')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_7uVu-xyEqv"
      },
      "source": [
        "## Crear una canalización de entrada usando tf.data\n",
        "\n",
        "A continuación, cree una función de utilidad que convierta cada conjunto de datos de entrenamiento, validación y prueba en un `tf.data.Dataset` y, a continuación, mezcle y agrupe los datos.\n",
        "\n",
        "Nota: Si estuviera trabajando con un archivo CSV muy grande (tan grande que no cupiera en memoria), usaría la API `tf.data` para leerlo directamente del disco. Eso no se trata en este tutorial."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7r4j-1lRyEqw"
      },
      "outputs": [],
      "source": [
        "def df_to_dataset(dataframe, shuffle=True, batch_size=32):\n",
        "  df = dataframe.copy()\n",
        "  labels = df.pop('target')\n",
        "  df = {key: value[:,tf.newaxis] for key, value in dataframe.items()}\n",
        "  ds = tf.data.Dataset.from_tensor_slices((dict(df), labels))\n",
        "  if shuffle:\n",
        "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
        "  ds = ds.batch(batch_size)\n",
        "  ds = ds.prefetch(batch_size)\n",
        "  return ds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYxIXH579uS9"
      },
      "source": [
        "Ahora, use la función recién creada (`df_to_dataset`) para comprobar el formato de los datos que devuelve la función ayudante a la canalización de entrada llamándola sobre los datos de entrenamiento, y use un tamaño de lote pequeño para mantener la legibilidad de la salida:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tYiNH-QI96Jo"
      },
      "outputs": [],
      "source": [
        "batch_size = 5\n",
        "train_ds = df_to_dataset(train, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nFYir6S8HgIJ"
      },
      "outputs": [],
      "source": [
        "[(train_features, label_batch)] = train_ds.take(1)\n",
        "print('Every feature:', list(train_features.keys()))\n",
        "print('A batch of ages:', train_features['Age'])\n",
        "print('A batch of targets:', label_batch )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "geqHWW54Hmte"
      },
      "source": [
        "Como demuestra la salida, el conjunto de entrenamiento devuelve un diccionario de nombres de columnas (del DataFrame) que se mapean a valores de columnas de filas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-v50jBIuj4gb"
      },
      "source": [
        "## Aplicar las capas de preprocesamiento Keras\n",
        "\n",
        "Las capas de preprocesamiento de Keras le permiten construir canalizaciones de procesamiento de entrada nativas de Keras, que pueden usarse como código de preprocesamiento independiente en flujos de trabajo no Keras, combinarse directamente con modelos Keras y exportarse como parte de un SavedModel de Keras.\n",
        "\n",
        "En este tutorial, usará las cuatro capas de preprocesamiento siguientes para demostrar cómo realizar el preprocesamiento, la codificación de datos estructurados y la ingeniería de características:\n",
        "\n",
        "- `tf.keras.layers.Normalization`: Realiza la normalización de las características de entrada.\n",
        "- `tf.keras.layers.CategoryEncoding`: Convierte los rasgos categóricos enteros en representaciones densas de uno, varios o <a href=\"https://en.wikipedia.org/wiki/Tf%E2%80%93idf\" class=\"external\">tf-idf</a> pasos.\n",
        "- `tf.keras.layers.StringLookup`: Convierte los valores categóricos de cadena en índices enteros.\n",
        "- `tf.keras.layers.IntegerLookup`: Convierte valores categóricos enteros en índices enteros.\n",
        "\n",
        "Puede obtener más información sobre las capas disponibles en la guía [Trabajar con capas de preprocesamiento](https://www.tensorflow.org/guide/keras/preprocessing_layers).\n",
        "\n",
        "- Para las *características numéricas* del miniconjunto de datos PetFinder.my, usará una capa `tf.keras.layers.Normalization` para normalizar la distribución de los datos.\n",
        "- Para las *características categóricas*, como las `Type` de mascotas (`Dog` y `Cat`), las transformará en tensores codificados con `tf.keras.layers.CategoryEncoding`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twXBSxnT66o8"
      },
      "source": [
        "### Columnas numéricas\n",
        "\n",
        "Para cada característica numérica del miniconjunto de datos PetFinder.my, usará una capa `tf.keras.layers.Normalization` para estandarizar la distribución de los datos.\n",
        "\n",
        "Defina una nueva función de utilidad que devuelva una capa que aplique la normalización por características a las características numéricas usando esa capa Keras de preprocesamiento:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D6OuEKMMyEq1"
      },
      "outputs": [],
      "source": [
        "def get_normalization_layer(name, dataset):\n",
        "  # Create a Normalization layer for the feature.\n",
        "  normalizer = layers.Normalization(axis=None)\n",
        "\n",
        "  # Prepare a Dataset that only yields the feature.\n",
        "  feature_ds = dataset.map(lambda x, y: x[name])\n",
        "\n",
        "  # Learn the statistics of the data.\n",
        "  normalizer.adapt(feature_ds)\n",
        "\n",
        "  return normalizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lL4TRreQCPjV"
      },
      "source": [
        "A continuación, pruebe la nueva función llamándola sobre el total de características de las fotos de mascotas cargadas para normalizar `'PhotoAmt'`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MpKgUDyk69bM"
      },
      "outputs": [],
      "source": [
        "photo_count_col = train_features['PhotoAmt']\n",
        "layer = get_normalization_layer('PhotoAmt', train_ds)\n",
        "layer(photo_count_col)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "foWY00YBUx9N"
      },
      "source": [
        "Nota: Si tiene muchas características numéricas (cientos, o más), es más eficiente concatenarlas primero y usar una única capa `tf.keras.layers.Normalization`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVD--2WZ7vmh"
      },
      "source": [
        "### Columnas categóricas\n",
        "\n",
        "El `Tipo` de mascota en el conjunto de datos se representa como cadenas-`Perro`y `Gato`-que deben codificarse de forma múltiple antes de introducirse en el modelo. La característica `Age`\n",
        "\n",
        "Defina otra nueva función de utilidad que devuelva una capa que mapee valores de un vocabulario a índices enteros y codifique de forma múltiple las características usando las capas de preprocesamiento `tf.keras.layers.StringLookup`, `tf.keras.layers.IntegerLookup`, y `tf.keras.CategoryEncoding`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GmgaeRjlDoUO"
      },
      "outputs": [],
      "source": [
        "def get_category_encoding_layer(name, dataset, dtype, max_tokens=None):\n",
        "  # Create a layer that turns strings into integer indices.\n",
        "  if dtype == 'string':\n",
        "    index = layers.StringLookup(max_tokens=max_tokens)\n",
        "  # Otherwise, create a layer that turns integer values into integer indices.\n",
        "  else:\n",
        "    index = layers.IntegerLookup(max_tokens=max_tokens)\n",
        "\n",
        "  # Prepare a `tf.data.Dataset` that only yields the feature.\n",
        "  feature_ds = dataset.map(lambda x, y: x[name])\n",
        "\n",
        "  # Learn the set of possible values and assign them a fixed integer index.\n",
        "  index.adapt(feature_ds)\n",
        "\n",
        "  # Encode the integer indices.\n",
        "  encoder = layers.CategoryEncoding(num_tokens=index.vocabulary_size())\n",
        "\n",
        "  # Apply multi-hot encoding to the indices. The lambda function captures the\n",
        "  # layer, so you can use them, or include them in the Keras Functional model later.\n",
        "  return lambda feature: encoder(index(feature))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7b3DwtTeCPjX"
      },
      "source": [
        "Pruebe la función `get_category_encoding_layer` llamándola sobre rasgos `'Type'` de mascota para convertirlos en tensores codificados multihilo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X2t2ff9K8PcT"
      },
      "outputs": [],
      "source": [
        "test_type_col = train_features['Type']\n",
        "test_type_layer = get_category_encoding_layer(name='Type',\n",
        "                                              dataset=train_ds,\n",
        "                                              dtype='string')\n",
        "test_type_layer(test_type_col)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6eDongw8knz"
      },
      "source": [
        "Repita el proceso en las características `'Age'` de la mascota:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7FjBioQ38oNE"
      },
      "outputs": [],
      "source": [
        "test_age_col = train_features['Age']\n",
        "test_age_layer = get_category_encoding_layer(name='Age',\n",
        "                                             dataset=train_ds,\n",
        "                                             dtype='int64',\n",
        "                                             max_tokens=5)\n",
        "test_age_layer(test_age_col)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiE0glOPkMyh"
      },
      "source": [
        "## Preprocesar las características seleccionadas para entrenar sobre el modelo\n",
        "\n",
        "Ha aprendido a usar varios tipos de capas de preprocesamiento Keras. A continuación, hará lo siguiente:\n",
        "\n",
        "- Aplicará las funciones de utilidad de preprocesamiento definidas anteriormente a 13 características numéricas y categóricas del miniconjunto de datos PetFinder.my.\n",
        "- Añada todas las entradas de características a una lista.\n",
        "\n",
        "Como se mencionó al principio, para entrenar el modelo, usará las características numéricas (`'PhotoAmt'`, `'Fee'`) y categóricas (`'Age'`, `'Type'`, `'Color1'`, `'Color2'`, `'Sex'`, `'MaturitySize'`, `'FurLength'`, `'Vaccinated'`, `'Sterilized'`, `'Health'`, `'Breed1'`) del miniconjunto de datos PetFinder.my.\n",
        "\n",
        "Nota: Si su objetivo es construir un modelo preciso, pruebe con un conjunto de datos propio más amplio y piense detenidamente qué características son las más significativas que debe incluir y cómo deben representarse."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uj1GoHSZ9R3H"
      },
      "source": [
        "Anteriormente, usó un tamaño de lote pequeño para demostrar la canalización de entrada. Ahora creemos una nueva canalización de entrada con un tamaño de lote mayor, de 256:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rcv2kQTTo23h"
      },
      "outputs": [],
      "source": [
        "batch_size = 256\n",
        "train_ds = df_to_dataset(train, batch_size=batch_size)\n",
        "val_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)\n",
        "test_ds = df_to_dataset(test, shuffle=False, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bIGNYN2V7iR"
      },
      "source": [
        "Normalice las características numéricas (el número de fotos de mascotas y la cuota de adopción) y añádalas a una lista de entradas llamada `encoded_features`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q3RBa51VkaAn"
      },
      "outputs": [],
      "source": [
        "all_inputs = []\n",
        "encoded_features = []\n",
        "\n",
        "# Numerical features.\n",
        "for header in ['PhotoAmt', 'Fee']:\n",
        "  numeric_col = tf.keras.Input(shape=(1,), name=header)\n",
        "  normalization_layer = get_normalization_layer(header, train_ds)\n",
        "  encoded_numeric_col = normalization_layer(numeric_col)\n",
        "  all_inputs.append(numeric_col)\n",
        "  encoded_features.append(encoded_numeric_col)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVcUAFd6bvlT"
      },
      "source": [
        "Convierta los valores categóricos enteros del conjunto de datos (la edad de la mascota) en índices enteros, realice una codificación de múltiples pasos y añada las entradas de características resultantes a `encoded_features`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1FOMGfZflhoA"
      },
      "outputs": [],
      "source": [
        "age_col = tf.keras.Input(shape=(1,), name='Age', dtype='int64')\n",
        "\n",
        "encoding_layer = get_category_encoding_layer(name='Age',\n",
        "                                             dataset=train_ds,\n",
        "                                             dtype='int64',\n",
        "                                             max_tokens=5)\n",
        "encoded_age_col = encoding_layer(age_col)\n",
        "all_inputs.append(age_col)\n",
        "encoded_features.append(encoded_age_col)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYzynk6wdqKe"
      },
      "source": [
        "Repita el mismo paso para los valores categóricos de cadena:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K8C8xyiXm-Ie"
      },
      "outputs": [],
      "source": [
        "categorical_cols = ['Type', 'Color1', 'Color2', 'Gender', 'MaturitySize',\n",
        "                    'FurLength', 'Vaccinated', 'Sterilized', 'Health', 'Breed1']\n",
        "\n",
        "for header in categorical_cols:\n",
        "  categorical_col = tf.keras.Input(shape=(1,), name=header, dtype='string')\n",
        "  encoding_layer = get_category_encoding_layer(name=header,\n",
        "                                               dataset=train_ds,\n",
        "                                               dtype='string',\n",
        "                                               max_tokens=5)\n",
        "  encoded_categorical_col = encoding_layer(categorical_col)\n",
        "  all_inputs.append(categorical_col)\n",
        "  encoded_features.append(encoded_categorical_col)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHSnhz2fyEq3"
      },
      "source": [
        "## Crear, compilar y entrenar el modelo\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDGyN_wpo0XS"
      },
      "source": [
        "El siguiente paso es crear un modelo usando la [API Functional de Keras](https://www.tensorflow.org/guide/keras/functional). Para la primera capa de su modelo, fusione la lista de entradas de características (`encoded_features`) en un vector mediante concatenación con `tf.keras.layers.concatenate`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Yrj-_pr6jyL"
      },
      "outputs": [],
      "source": [
        "all_features = tf.keras.layers.concatenate(encoded_features)\n",
        "x = tf.keras.layers.Dense(32, activation=\"relu\")(all_features)\n",
        "x = tf.keras.layers.Dropout(0.5)(x)\n",
        "output = tf.keras.layers.Dense(1)(x)\n",
        "\n",
        "model = tf.keras.Model(all_inputs, output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRLDRcYAefTA"
      },
      "source": [
        "Configure el modelo con `Model.compile` de Keras:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GZDb_lJdelSg"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6mNMfG6yEq5"
      },
      "source": [
        "Visualicemos el grafo de conectividad:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y7Bkx4c7yEq5"
      },
      "outputs": [],
      "source": [
        "# Use `rankdir='LR'` to make the graph horizontal.\n",
        "tf.keras.utils.plot_model(model, show_shapes=True, rankdir=\"LR\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CED6OStLyEq7"
      },
      "source": [
        "A continuación, entrene el modelo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OQfE3PC6yEq8"
      },
      "outputs": [],
      "source": [
        "model.fit(train_ds, epochs=10, validation_data=val_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T8N2uAdU2Cni"
      },
      "outputs": [],
      "source": [
        "loss, accuracy = model.evaluate(test_ds)\n",
        "print(\"Accuracy\", accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmZMnTKaCZda"
      },
      "source": [
        "## Realizar inferencias\n",
        "\n",
        "El modelo que ha desarrollado ahora puede clasificar una fila a partir de un archivo CSV directamente después de haber incluido las capas de preprocesamiento dentro del propio modelo.\n",
        "\n",
        "Ahora puede [guardar y volver a cargar el modelo Keras](../keras/save_and_load.ipynb) con `Model.save` y `Model.load_model` antes de realizar la inferencia sobre nuevos datos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QH9Zy1sBvwOH"
      },
      "outputs": [],
      "source": [
        "model.save('my_pet_classifier.keras')\n",
        "reloaded_model = tf.keras.models.load_model('my_pet_classifier.keras')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D973plJrdwQ9"
      },
      "source": [
        "Para obtener una predicción para una nueva muestra, basta con llamar al método `Model.predict` de Keras. Sólo tiene que hacer dos cosas:\n",
        "\n",
        "1. Encapsule los escalares en una lista para que tengan una dimensión de lote (`Model`s sólo procesan lotes de datos, no muestras individuales).\n",
        "2. Llame a `tf.convert_to_tensor` sobre cada característica."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rKq4pxtdDa7i"
      },
      "outputs": [],
      "source": [
        "sample = {\n",
        "    'Type': 'Cat',\n",
        "    'Age': 3,\n",
        "    'Breed1': 'Tabby',\n",
        "    'Gender': 'Male',\n",
        "    'Color1': 'Black',\n",
        "    'Color2': 'White',\n",
        "    'MaturitySize': 'Small',\n",
        "    'FurLength': 'Short',\n",
        "    'Vaccinated': 'No',\n",
        "    'Sterilized': 'No',\n",
        "    'Health': 'Healthy',\n",
        "    'Fee': 100,\n",
        "    'PhotoAmt': 2,\n",
        "}\n",
        "\n",
        "input_dict = {name: tf.convert_to_tensor([value]) for name, value in sample.items()}\n",
        "predictions = reloaded_model.predict(input_dict)\n",
        "prob = tf.nn.sigmoid(predictions[0])\n",
        "\n",
        "print(\n",
        "    \"This particular pet had a %.1f percent probability \"\n",
        "    \"of getting adopted.\" % (100 * prob)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJQQZEiH2FaB"
      },
      "source": [
        "Nota: Normalmente obtendrá mejores resultados con el aprendizaje profundo con conjuntos de datos más grandes y complejos. Cuando trabaje con un conjunto de datos pequeño, como el simplificado PetFinder.my, puede usar un <a href=\"https://developers.google.com/machine-learning/glossary#decision-tree\" class=\"external\">árbol de decisión</a> o un <a href=\"https://developers.google.com/machine-learning/glossary#random-forest\" class=\"external\">bosque aleatorio</a> como línea de referencia sólida. La meta de este tutorial es demostrar la mecánica de trabajar con datos estructurados, para que tenga un punto de partida cuando trabaje con sus propios conjuntos de datos en el futuro.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0QAY2Tb2HYG"
      },
      "source": [
        "## Siguientes pasos\n",
        "\n",
        "Para aprender más sobre la clasificación de datos estructurados, pruebe a trabajar con otros conjuntos de datos. Para mejorar la precisión durante el entrenamiento y las pruebas de sus modelos, piense detenidamente qué características incluir en su modelo y cómo deben representarse.\n",
        "\n",
        "Aquí tiene algunas sugerencias de conjuntos de datos:\n",
        "\n",
        "- [Conjuntos de datos TensorFlow: MovieLens](https://www.tensorflow.org/datasets/catalog/movie_lens): Un conjunto de clasificaciones de un servicio de recomendación de películas.\n",
        "- [Conjuntos de datos TensorFlow: Wine Quality](https://www.tensorflow.org/datasets/catalog/wine_quality): Dos conjuntos de datos relacionados con las variantes tintas y blancas del vino portugués \"Vinho Verde\". También puede encontrar el conjunto de datos Red Wine Quality en <a href=\"https://www.kaggle.com/uciml/red-wine-quality-cortez-et-al-2009\" class=\"external\">Kaggle</a>.\n",
        "- <a href=\"https://www.kaggle.com/Cornell-University/arxiv\" class=\"external\">Kaggle: conjunto de datos arXiv</a>: Un corpus de 1.7 millones de artículos académicos de arXiv, que abarca la física, la informática, las matemáticas, la estadística, la ingeniería eléctrica, la biología cuantitativa y la economía.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "preprocessing_layers.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
