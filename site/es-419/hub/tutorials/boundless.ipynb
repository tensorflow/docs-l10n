{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9veUEV0CfmHX"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow Hub Authors.\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "both",
        "id": "BlCInyRifxHS"
      },
      "outputs": [],
      "source": [
        "#@title Copyright 2020 The TensorFlow Hub Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# =============================================================================="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LRMeRxCfzC4"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>     <a target=\"_blank\" href=\"https://www.tensorflow.org/hub/tutorials/boundless\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver en TensorFlow.org</a>\n",
        "</td>\n",
        "  <td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/es-419/hub/tutorials/boundless.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Ejecutar en Google Colab</a></td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/es-419/hub/tutorials/boundless.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver en GitHub</a>\n",
        "</td>\n",
        "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/es-419/hub/tutorials/boundless.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Descargar el bloc de notas</a>\n",
        "</td>\n",
        "  <td>     <a href=\"https://tfhub.dev/s?q=google%2Fboundless\"><img src=\"https://www.tensorflow.org/images/hub_logo_32px.png\">Ver modelos de TF Hub</a>\n",
        "</td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOjczJJ4gWHS"
      },
      "source": [
        "# Colab de Boundless\n",
        "\n",
        "¡Le damos la bienvenida al Colab del modelo Boundless! En estas notas leerá los pasos necesarios para la ejecución del modelo con imágenes y la visualización de los resultados.\n",
        "\n",
        "## Descripción general\n",
        "\n",
        "Boundless es un modelo que sirve para la extrapolación de imágenes. Este modelo toma una imagen, enmascara internamente una porción de dicha imagen ([1/2](https://tfhub.dev/google/boundless/half/1), [1/4](https://tfhub.dev/google/boundless/quarter/1), [3/4](https://tfhub.dev/google/boundless/three_quarter/1)) y completa la parte enmascarada. Para más detalles, consulte [Boundless: Generative Adversarial Networks for Image Extension](https://arxiv.org/pdf/1908.07007.pdf) o la documentación del modelo en TensorFlow Hub."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDKbpAEZf8Lt"
      },
      "source": [
        "## Importaciones y preparación\n",
        "\n",
        "Comencemos con las importaciones de base."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xJMFtTqPr7lf"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from io import BytesIO\n",
        "from PIL import Image as PilImage\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from six.moves.urllib.request import urlopen"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pigUDIXtciQO"
      },
      "source": [
        "## Lectura de imágenes para entrada\n",
        "\n",
        "Creemos un método \"util\" para cargar la imagen y formatearla para el modelo (257 × 257 × 3). Este método también recortará la imagen para que sea un cuadrado a fin de evitar que se distorsione y para poder usarla con imágenes locales o de internet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KTEVPgXH6rtV"
      },
      "outputs": [],
      "source": [
        "  def read_image(filename):\n",
        "    fd = None\n",
        "    if(filename.startswith('http')):\n",
        "      fd = urlopen(filename)\n",
        "    else:\n",
        "      fd = tf.io.gfile.GFile(filename, 'rb')\n",
        "\n",
        "    pil_image = PilImage.open(fd)\n",
        "    width, height = pil_image.size\n",
        "    # crop to make the image square\n",
        "    pil_image = pil_image.crop((0, 0, height, height))\n",
        "    pil_image = pil_image.resize((257,257),PilImage.LANCZOS)\n",
        "    image_unscaled = np.array(pil_image)\n",
        "    image_np = np.expand_dims(\n",
        "        image_unscaled.astype(np.float32) / 255., axis=0)\n",
        "    return image_np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lonrLxuKcsL0"
      },
      "source": [
        "## Método de visualización\n",
        "\n",
        "También crearemos un método de visualización para mostrar la imagen original con la versión enmascarada y la versión \"rellenada\" una al lado de la otra, ambas generadas por el modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j7AkoMFG7r-O"
      },
      "outputs": [],
      "source": [
        "def visualize_output_comparison(img_original, img_masked, img_filled):\n",
        "  plt.figure(figsize=(24,12))\n",
        "  plt.subplot(131)\n",
        "  plt.imshow((np.squeeze(img_original)))\n",
        "  plt.title(\"Original\", fontsize=24)\n",
        "  plt.axis('off')\n",
        "  plt.subplot(132)\n",
        "  plt.imshow((np.squeeze(img_masked)))\n",
        "  plt.title(\"Masked\", fontsize=24)\n",
        "  plt.axis('off')\n",
        "  plt.subplot(133)\n",
        "  plt.imshow((np.squeeze(img_filled)))\n",
        "  plt.title(\"Generated\", fontsize=24)\n",
        "  plt.axis('off')\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rwaCWmxdJGH"
      },
      "source": [
        "## Carga de una imagen\n",
        "\n",
        "Cargaremos una imagen de ejemplo, pero no olvide que puede cargar su propia imagen en el Colab y probar con ella. Recuerde que el modelo tiene algunos límites relacionados con las imágenes humanas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "92w-Jfbm60XA"
      },
      "outputs": [],
      "source": [
        "wikimedia = \"https://upload.wikimedia.org/wikipedia/commons/thumb/3/31/Nusfjord_road%2C_2010_09.jpg/800px-Nusfjord_road%2C_2010_09.jpg\"\n",
        "# wikimedia = \"https://upload.wikimedia.org/wikipedia/commons/thumb/4/47/Beech_forest_M%C3%A1tra_in_winter.jpg/640px-Beech_forest_M%C3%A1tra_in_winter.jpg\"\n",
        "# wikimedia = \"https://upload.wikimedia.org/wikipedia/commons/thumb/b/b2/Marmolada_Sunset.jpg/640px-Marmolada_Sunset.jpg\"\n",
        "# wikimedia = \"https://upload.wikimedia.org/wikipedia/commons/thumb/9/9d/Aegina_sunset.jpg/640px-Aegina_sunset.jpg\"\n",
        "\n",
        "input_img = read_image(wikimedia)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4lIkmZL_dtyX"
      },
      "source": [
        "## Selección de un modelo de TensorFlow Hub\n",
        "\n",
        "En TensorFlow Hub tenemos 3 versiones del modelo Boundless: uno de la mitad, otro de un cuarto y el último de tres cuartos. En la siguiente celda puede elegir cualquiera de ellos y probar con una imagen propia. Si desea intentar con otra, simplemente, elíjala y ejecute las siguientes celdas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B3myNctEQ5GE"
      },
      "outputs": [],
      "source": [
        "#@title Model Selection { display-mode: \"form\" }\n",
        "model_name = 'Boundless Quarter' # @param ['Boundless Half', 'Boundless Quarter', 'Boundless Three Quarters']\n",
        "model_handle_map = {\n",
        "    'Boundless Half' : 'https://tfhub.dev/google/boundless/half/1',\n",
        "    'Boundless Quarter' : 'https://tfhub.dev/google/boundless/quarter/1', \n",
        "    'Boundless Three Quarters' : 'https://tfhub.dev/google/boundless/three_quarter/1'\n",
        "}\n",
        "\n",
        "model_handle = model_handle_map[model_name]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSJFeNNSeOn8"
      },
      "source": [
        "Ahora que hemos elegido el modelo que queremos, carguémoslo desde TensorFlow Hub.\n",
        "\n",
        "**Nota**: El navegador se puede apuntar a un <em>handle</em> para que lea la documentación del modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0IDKMNyYSWsj"
      },
      "outputs": [],
      "source": [
        "print(\"Loading model {} ({})\".format(model_name, model_handle))\n",
        "model = hub.load(model_handle)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4G7CPOaeuQb"
      },
      "source": [
        "## Inferencia\n",
        "\n",
        "El modelo Boundless tiene dos salidas:\n",
        "\n",
        "- La imagen de entrada con una máscara aplicada.\n",
        "- La imagen enmascarada con la extrapolación necesaria para completarla.\n",
        "\n",
        "Podemos usar ambas imágenes para mostrar una vista comparativa."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W7uCAuKxSd-M"
      },
      "outputs": [],
      "source": [
        "result = model.signatures['default'](tf.constant(input_img))\n",
        "generated_image =  result['default']\n",
        "masked_image = result['masked_image']\n",
        "\n",
        "visualize_output_comparison(input_img, masked_image, generated_image)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "boundless.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
