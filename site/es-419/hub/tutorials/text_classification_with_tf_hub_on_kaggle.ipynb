{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6ZDpd9XzFeN"
      },
      "source": [
        "##### Copyright 2018 The TensorFlow Hub Authors.\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "KUu4vOt5zI9d"
      },
      "outputs": [],
      "source": [
        "# Copyright 2018 The TensorFlow Hub Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# =============================================================================="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ok9PfyoQ2rH_"
      },
      "source": [
        "# Cómo resolver un problema en Kaggle con TF-Hub\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfBg1C5NB3X0"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td><a target=\"_blank\" href=\"https://www.tensorflow.org/hub/tutorials/text_classification_with_tf_hub_on_kaggle\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver en TensorFlow.org</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/es-419/hub/tutorials/text_classification_with_tf_hub_on_kaggle.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Ejecutar en Google Colab</a></td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/es-419/hub/tutorials/text_classification_with_tf_hub_on_kaggle.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver en GitHub</a>\n",
        "</td>\n",
        "  <td><a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/es-419/hub/tutorials/text_classification_with_tf_hub_on_kaggle.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Descargar el bloc de notas</a></td>\n",
        "  <td>     <a href=\"https://tfhub.dev/google/nnlm-en-dim128/1\"><img src=\"https://www.tensorflow.org/images/hub_logo_32px.png\">Ver modelos de TF Hub</a>\n",
        "</td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "556YQZLUO4Ih"
      },
      "source": [
        "TF-Hub es una plataforma para compartir conocimientos en aprendizaje automático presentados en forma de recursos reutilizables, en particular **módulos** preentrenados. En este tutorial, usaremos un módulo de incorporación de texto de TF-Hub para entrenar un clasificador de sentimientos simple con una precisión de referencia razonable. Luego enviaremos las predicciones a Kaggle.\n",
        "\n",
        "Para obtener un tutorial más detallado sobre la clasificación de texto con TF-Hub y los  pasos adicionales para mejorar la precisión, consulte [Clasificación de texto con TF-Hub](https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/hub/tutorials/text_classification_with_tf_hub.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4DN769E2O_R"
      },
      "source": [
        "## Preparación"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9KyLct9rq0lo"
      },
      "outputs": [],
      "source": [
        "!pip install -q kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v7hy0bhngTUp"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import zipfile\n",
        "\n",
        "from sklearn import model_selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvgBdeMsuu_3"
      },
      "source": [
        "Dado que este tutorial usará un conjunto de datos de Kaggle, se requiere [crear un token de API](https://github.com/Kaggle/kaggle-api) para su cuenta de Kaggle y cargarlo en el entorno de Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nI7C-Zc4urOH"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pathlib\n",
        "\n",
        "# Upload the API token.\n",
        "def get_kaggle():\n",
        "  try:\n",
        "    import kaggle\n",
        "    return kaggle\n",
        "  except OSError:\n",
        "    pass\n",
        "\n",
        "  token_file = pathlib.Path(\"~/.kaggle/kaggle.json\").expanduser()\n",
        "  token_file.parent.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "  try:\n",
        "    from google.colab import files\n",
        "  except ImportError:\n",
        "    raise ValueError(\"Could not find kaggle token.\")\n",
        "\n",
        "  uploaded = files.upload()\n",
        "  token_content = uploaded.get('kaggle.json', None)\n",
        "  if token_content:\n",
        "    token_file.write_bytes(token_content)\n",
        "    token_file.chmod(0o600)\n",
        "  else:\n",
        "    raise ValueError('Need a file named \"kaggle.json\"')\n",
        "  \n",
        "  import kaggle\n",
        "  return kaggle\n",
        "\n",
        "\n",
        "kaggle = get_kaggle()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OPyVxHuiTEE"
      },
      "source": [
        "# Empecemos\n",
        "\n",
        "## Datos\n",
        "\n",
        "Intentaremos resolver la tarea de [Análisis de sentimiento de reseñas de películas](https://www.kaggle.com/c/sentiment-analysis-on-movie-reviews/data) de Kaggle. El conjunto de datos consta de subfrases sintácticas de las reseñas de películas de Rotten Tomatoes. La tarea consiste en etiquetar las frases como **negativas** o **positivas** en la escala del 1 al 5.\n",
        "\n",
        "Debe [aceptar las reglas de la competencia](https://www.kaggle.com/c/sentiment-analysis-on-movie-reviews/data) antes de poder usar la API para descargar los datos.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "both",
        "id": "rKzc-fOGV72G"
      },
      "outputs": [],
      "source": [
        "SENTIMENT_LABELS = [\n",
        "    \"negative\", \"somewhat negative\", \"neutral\", \"somewhat positive\", \"positive\"\n",
        "]\n",
        "\n",
        "# Add a column with readable values representing the sentiment.\n",
        "def add_readable_labels_column(df, sentiment_value_column):\n",
        "  df[\"SentimentLabel\"] = df[sentiment_value_column].replace(\n",
        "      range(5), SENTIMENT_LABELS)\n",
        "    \n",
        "# Download data from Kaggle and create a DataFrame.\n",
        "def load_data_from_zip(path):\n",
        "  with zipfile.ZipFile(path, \"r\") as zip_ref:\n",
        "    name = zip_ref.namelist()[0]\n",
        "    with zip_ref.open(name) as zf:\n",
        "      return pd.read_csv(zf, sep=\"\\t\", index_col=0)\n",
        "\n",
        "\n",
        "# The data does not come with a validation set so we'll create one from the\n",
        "# training set.\n",
        "def get_data(competition, train_file, test_file, validation_set_ratio=0.1):\n",
        "  data_path = pathlib.Path(\"data\")\n",
        "  kaggle.api.competition_download_files(competition, data_path)\n",
        "  competition_path = (data_path/competition)\n",
        "  competition_path.mkdir(exist_ok=True, parents=True)\n",
        "  competition_zip_path = competition_path.with_suffix(\".zip\")\n",
        "\n",
        "  with zipfile.ZipFile(competition_zip_path, \"r\") as zip_ref:\n",
        "    zip_ref.extractall(competition_path)\n",
        "  \n",
        "  train_df = load_data_from_zip(competition_path/train_file)\n",
        "  test_df = load_data_from_zip(competition_path/test_file)\n",
        "\n",
        "  # Add a human readable label.\n",
        "  add_readable_labels_column(train_df, \"Sentiment\")\n",
        "\n",
        "  # We split by sentence ids, because we don't want to have phrases belonging\n",
        "  # to the same sentence in both training and validation set.\n",
        "  train_indices, validation_indices = model_selection.train_test_split(\n",
        "      np.unique(train_df[\"SentenceId\"]),\n",
        "      test_size=validation_set_ratio,\n",
        "      random_state=0)\n",
        "\n",
        "  validation_df = train_df[train_df[\"SentenceId\"].isin(validation_indices)]\n",
        "  train_df = train_df[train_df[\"SentenceId\"].isin(train_indices)]\n",
        "  print(\"Split the training data into %d training and %d validation examples.\" %\n",
        "        (len(train_df), len(validation_df)))\n",
        "\n",
        "  return train_df, validation_df, test_df\n",
        "\n",
        "\n",
        "train_df, validation_df, test_df = get_data(\n",
        "    \"sentiment-analysis-on-movie-reviews\",\n",
        "    \"train.tsv.zip\", \"test.tsv.zip\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFq_EyS1BEyK"
      },
      "source": [
        "Nota: En esta competencia la tarea no es calificar reseñas completas, sino frases individuales dentro de las reseñas. Esta es una tarea mucho más difícil."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "42hgsiWNq5y9"
      },
      "outputs": [],
      "source": [
        "train_df.head(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPuHgx3BWBOg"
      },
      "source": [
        "## Entrenar un modelo\n",
        "\n",
        "*Nota: Podríamos modelar esta tarea también como una regresión, consulte [Clasificación de texto con TF-Hub](https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/hub/tutorials/text_classification_with_tf_hub.ipynb).*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23U30yEkVq4w"
      },
      "outputs": [],
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self, hub_url):\n",
        "    super().__init__()\n",
        "    self.hub_url = hub_url\n",
        "    self.embed = hub.load(self.hub_url).signatures['default']\n",
        "    self.sequential = tf.keras.Sequential([\n",
        "      tf.keras.layers.Dense(500),\n",
        "      tf.keras.layers.Dense(100),\n",
        "      tf.keras.layers.Dense(5),\n",
        "    ])\n",
        "\n",
        "  def call(self, inputs):\n",
        "    phrases = inputs['Phrase'][:,0]\n",
        "    embedding = 5*self.embed(phrases)['default']\n",
        "    return self.sequential(embedding)\n",
        "\n",
        "  def get_config(self):\n",
        "    return {\"hub_url\":self.hub_url}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JE--GDMM2tSp"
      },
      "outputs": [],
      "source": [
        "model = MyModel(\"https://tfhub.dev/google/nnlm-en-dim128/1\")\n",
        "model.compile(\n",
        "    loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    optimizer=tf.optimizers.Adam(), \n",
        "    metrics = [tf.keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\")])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SRr-lvhstiNw"
      },
      "outputs": [],
      "source": [
        "history = model.fit(x=dict(train_df), y=train_df['Sentiment'],\n",
        "          validation_data=(dict(validation_df), validation_df['Sentiment']),\n",
        "          epochs = 25)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8j7YTRSe7Pj"
      },
      "source": [
        "# Predicción\n",
        "\n",
        "Ejecute predicciones para el conjunto de validación y el conjunto de entrenamiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iGqVNSl87bgN"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zbLg5LzGwAfC"
      },
      "outputs": [],
      "source": [
        "train_eval_result = model.evaluate(dict(train_df), train_df['Sentiment'])\n",
        "validation_eval_result = model.evaluate(dict(validation_df), validation_df['Sentiment'])\n",
        "\n",
        "print(f\"Training set accuracy: {train_eval_result[1]}\")\n",
        "print(f\"Validation set accuracy: {validation_eval_result[1]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DR2IsTF5vuAX"
      },
      "source": [
        "## Matriz de confusión\n",
        "\n",
        "Otra estadística muy interesante, especialmente para problemas multiclase, es la [matriz de confusión](https://en.wikipedia.org/wiki/Confusion_matrix). La matriz de confusión permite visualizar la proporción de ejemplos etiquetados correctamente e incorrectamente. Podemos ver fácilmente hasta qué punto nuestro clasificador está sesgado y si la distribución de etiquetas tiene sentido. Lo ideal sería que la mayor fracción de predicciones se distribuya a lo largo de la diagonal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yKUnJFYY8bO_"
      },
      "outputs": [],
      "source": [
        "predictions = model.predict(dict(validation_df))\n",
        "predictions = tf.argmax(predictions, axis=-1)\n",
        "predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fjAs8W_Z9BvP"
      },
      "outputs": [],
      "source": [
        "cm = tf.math.confusion_matrix(validation_df['Sentiment'], predictions)\n",
        "cm = cm/cm.numpy().sum(axis=1)[:, tf.newaxis]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nT71CtArpsKz"
      },
      "outputs": [],
      "source": [
        "sns.heatmap(\n",
        "    cm, annot=True,\n",
        "    xticklabels=SENTIMENT_LABELS,\n",
        "    yticklabels=SENTIMENT_LABELS)\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pic7o2m04weY"
      },
      "source": [
        "Podemos enviar fácilmente las predicciones a Kaggle si pegamos el siguiente código en una celda de código y lo ejecutamos:\n",
        "\n",
        "```python\n",
        "test_predictions = model.predict(dict(test_df))\n",
        "test_predictions = np.argmax(test_predictions, axis=-1)\n",
        "\n",
        "result_df = test_df.copy()\n",
        "\n",
        "result_df[\"Predictions\"] = test_predictions\n",
        "\n",
        "result_df.to_csv(\n",
        "    \"predictions.csv\",\n",
        "    columns=[\"Predictions\"],\n",
        "    header=[\"Sentiment\"])\n",
        "kaggle.api.competition_submit(\"predictions.csv\", \"Submitted from Colab\",\n",
        "                              \"sentiment-analysis-on-movie-reviews\")\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50BLu-JX_dlm"
      },
      "source": [
        "Después de enviarlo, [consulte la tabla de clasificación](https://www.kaggle.com/c/sentiment-analysis-on-movie-reviews/leaderboard) para ver cómo le fue."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "text_classification_with_tf_hub_on_kaggle.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
