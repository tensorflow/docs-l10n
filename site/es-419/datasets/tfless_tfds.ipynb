{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_nWetWWd_ns"
      },
      "source": [
        "##### Copyright 2023 The TensorFlow Datasets Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "2pHVBk_seED1"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7vSdG6sAIQn"
      },
      "source": [
        "# TFDS para Jax y PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwc5GKHBASdc"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>     <a target=\"_blank\" href=\"https://www.tensorflow.org/datasets/tfless_tfds\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver en TensorFlow.org</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/es-419/datasets/tfless_tfds.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Ejecutar en Google Colab</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/es-419/datasets/tfless_tfds.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver fuente en GitHub</a>\n",
        "</td>\n",
        "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/es-419/datasets/tfless_tfds.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Descargar notebook</a>\n",
        "</td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ee074e4"
      },
      "source": [
        "TFDS siempre ha sido independiente del framework. Por ejemplo, puede cargar fácilmente conjuntos de datos en [formato NumPy](https://www.tensorflow.org/datasets/api_docs/python/tfds/as_numpy) para utilizarlos en Jax y PyTorch.\n",
        "\n",
        "TensorFlow y su solución de carga de datos ( [`tf.data`](https://www.tensorflow.org/guide/data) ) son ciudadanos de primera clase en nuestra API por diseño.\n",
        "\n",
        "Hemos extendido TFDS para soportar la carga de datos sólo NumPy sin TensorFlow. Esto puede ser conveniente para el uso en marcos de ML como Jax y PyTorch. De hecho, para estos últimos usuarios, TensorFlow puede:\n",
        "\n",
        "- Reservar memoria GPU/TPU;\n",
        "- Aumentar el tiempo de compilación en CI/CD;\n",
        "- Tardan en importarse en tiempo de ejecución.\n",
        "\n",
        "TensorFlow ya no es una dependencia para leer conjuntos de datos.\n",
        "\n",
        "Las tuberías de aprendizaje automático necesitan un cargador de datos para cargar ejemplos, descodificarlos y presentarlos al modelo. Los cargadores de datos utilizan el paradigma \"fuente/muestreador/cargador\":\n",
        "\n",
        "```\n",
        " Conjunto de datos TFDS ┌────────────────┐\n",
        "en disco │ │\n",
        "┌──────────►│ Datos │\n",
        "|..|... │ | │ fuente ├─┐\n",
        "├──┼────┴─────┤ │ │ │\n",
        "12│imagen12 ──┐\n",
        "├──┼──────────┤ │ │ │\n",
        "│13│imagen13 │ ├───►│ Datos ├───► Tubería de aprendizaje automático\n",
        "├──┼──────────┤ │ │ cargador │\n",
        "│14│imagen14 │ ┌────────────────┐ │ │ │\n",
        "├──┼──────────┤ │ │ │ └────────────────┘\n",
        "|..|... | │ Índice ├─┘\n",
        "│ muestrario │\n",
        "│ │\n",
        "└────────────────┘\n",
        "```\n",
        "\n",
        "- La fuente de datos es responsable de acceder y decodificar ejemplos de un conjunto de datos TFDS sobre la marcha.\n",
        "- El muestreador de índices es responsable de determinar el orden en que se procesan los registros. Esto es importante para implementar transformaciones globales (por ejemplo, barajado global, fragmentación, repetición para múltiples épocas) antes de leer cualquier registro.\n",
        "- El cargador de datos orquesta la carga aprovechando la fuente de datos y el muestreador de índices. Permite optimizar el rendimiento (por ejemplo, precarga, multiprocesamiento o multihilo).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UaWdLA3fQDK2"
      },
      "source": [
        "## TL;DR\n",
        "\n",
        "`tfds.data_source` es una API para crear fuentes de datos:\n",
        "\n",
        "1. Para la creación rápida de prototipos en tuberías puramente de Python\n",
        "2. Para gestionar procesos de aprendizaje automático con gran cantidad de datos a gran escala."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLho3l_Vd0a5"
      },
      "source": [
        "## Instalación\n",
        "\n",
        "Vamos a instalar e importar las dependencias necesarias:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c4COEsqIdvYH"
      },
      "outputs": [],
      "source": [
        "!pip install array_record\n",
        "!pip install tfds-nightly\n",
        "\n",
        "import os\n",
        "os.environ.pop('TFDS_DATA_DIR', None)\n",
        "\n",
        "import tensorflow_datasets as tfds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjEJeF1Id_JM"
      },
      "source": [
        "## Fuentes de datos\n",
        "\n",
        "Las fuentes de datos son básicamente secuencias de Python. Entonces necesitan implementar el siguiente protocolo:\n",
        "\n",
        "```python\n",
        "class RandomAccessDataSource(Protocol):\n",
        "  \"\"\"Interfaz para fuentes de datos en las que el almacenamiento admite un acceso aleatorio eficiente.\"\"\"\n",
        "\n",
        "  def __len__(self) -> int:\n",
        "    \"\"\"Numero de registros del conjunto de datos.\"\"\"\n",
        "\n",
        "  def __getitem__(self, record_key: int) -> Sequence[Any]:\n",
        "    \"\"\"Recupera los registros para las record_keys dadas.\"\"\"\n",
        "```\n",
        "\n",
        "**Advertencia**: la API todavía está en desarrollo continuo. En particular, en este momento, `__getitem__` debe soportar tanto `int` como `list[int]` en la entrada. En el futuro, probablemente sólo soportará `int` según [el estándar](https://docs.python.org/3/reference/datamodel.html#object.__getitem__).\n",
        "\n",
        "El formato de archivo subyacente debe permitir un acceso aleatorio eficaz. Actualmente, TFDS depende de [`array_record`](https://github.com/google/array_record).\n",
        "\n",
        "[`array_record`](https://github.com/google/array_record) es un nuevo formato de archivo derivado de [Riegeli](https://github.com/google/riegeli), que alcanza una nueva frontera de eficiencia de E/S. En concreto, ArrayRecord admite la lectura, escritura y acceso aleatorio en paralelo por índice de registro. ArrayRecord se basa en Riegeli y admite los mismos algoritmos de compresión.\n",
        "\n",
        "[`fashion_mnist`](https://www.tensorflow.org/datasets/catalog/fashion_mnist) es un conjunto de datos habitual para la visión por ordenador. Para recuperar una fuente de datos basada en ArrayRecord con TFDS, basta con utilizar:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Tslzx0_eEWx"
      },
      "outputs": [],
      "source": [
        "ds = tfds.data_source('fashion_mnist')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlaRrD_SeHLY"
      },
      "source": [
        "`tfds.data_source` es un contenedor conveniente. es equivalente a:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "duHDKzXReIKB"
      },
      "outputs": [],
      "source": [
        "builder = tfds.builder('fashion_mnist', file_format='array_record')\n",
        "builder.download_and_prepare()\n",
        "ds = builder.as_data_source()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlyIsd0ueKjQ"
      },
      "source": [
        "Esto genera un diccionario de fuentes de datos:\n",
        "\n",
        "```\n",
        "{\n",
        "  'train': DataSource(name=fashion_mnist, split='train', decoders=None),\n",
        "  'test': DataSource(name=fashion_mnist, split='test', decoders=None),\n",
        "}\n",
        "```\n",
        "\n",
        "Una vez que `download_and_prepare` se ha ejecutado, y has generado los archivos de registro, ya no necesitamos TensorFlow. ¡Todo se hará en Python/NumPy!\n",
        "\n",
        "Verifiquemos esto desinstalando TensorFlow y volviendo a cargar la fuente de datos en otro subproceso:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mTfSzvaQkSd9"
      },
      "outputs": [],
      "source": [
        "!pip uninstall -y tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3sT5AN7neNT9"
      },
      "outputs": [],
      "source": [
        "%%writefile no_tensorflow.py\n",
        "import os\n",
        "os.environ.pop('TFDS_DATA_DIR', None)\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "try:\n",
        "  import tensorflow as tf\n",
        "except ImportError:\n",
        "  print('No TensorFlow found...')\n",
        "\n",
        "ds = tfds.data_source('fashion_mnist')\n",
        "print('...but the data source could still be loaded...')\n",
        "ds['train'][0]\n",
        "print('...and the records can be decoded.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FxohFdb3kSxh"
      },
      "outputs": [],
      "source": [
        "!python no_tensorflow.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1o8n-BhhePYY"
      },
      "source": [
        "En futuras versiones, también vamos a hacer que la preparación del conjunto de datos sea independiente de TensorFlow.\n",
        "\n",
        "Una fuente de datos tiene una longitud:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qtfl17SQeQ7F"
      },
      "outputs": [],
      "source": [
        "len(ds['train'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-UFBu8leSMp"
      },
      "source": [
        "Accediendo al primer elemento del conjunto de datos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFvT2Sx2eToh"
      },
      "outputs": [],
      "source": [
        "%%timeit\n",
        "ds['train'][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTgZskyZeU_D"
      },
      "source": [
        "...es tan barato como acceder a cualquier otro elemento. Esta es la definición de [acceso aleatorio](https://en.wikipedia.org/wiki/Random_access):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cPJFa6aIeWcY"
      },
      "outputs": [],
      "source": [
        "%%timeit\n",
        "ds['train'][1000]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fs3kafYheX6N"
      },
      "source": [
        "Las funciones ahora utilizan NumPy DTypes (en lugar de TensorFlow DTypes). Puede inspeccionar las características con:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q7x5AEEaeZja"
      },
      "outputs": [],
      "source": [
        "features = tfds.builder('fashion_mnist').info.features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOnLqAZOeiBi"
      },
      "source": [
        "Encontrará más información sobre [las funciones en nuestra documentación](https://www.tensorflow.org/datasets/api_docs/python/tfds/features). Aquí podemos recuperar notablemente la forma de las imágenes, y el número de clases:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xk8Vc-y0edlb"
      },
      "outputs": [],
      "source": [
        "shape = features['image'].shape\n",
        "num_classes = features['label'].num_classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFh8pytVemsu"
      },
      "source": [
        "## Uso en Python puro\n",
        "\n",
        "Puedes utilizar fuentes de datos en Python iterando sobre ellas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ULjO-JDVefNf"
      },
      "outputs": [],
      "source": [
        "for example in ds['train']:\n",
        "  print(example)\n",
        "  break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZRHZNOkenPb"
      },
      "source": [
        "Si inspeccionas los elementos, también notarás que todas las características ya están decodificadas usando NumPy. Entre bastidores, utilizamos [OpenCV](https://opencv.org) por defecto porque es rápido. Si no tienes OpenCV instalado, usamos por defecto [Pillow](python-pillow.org) para proporcionar una decodificación de imágenes ligera y rápida.\n",
        "\n",
        "```\n",
        "{\n",
        "  'image': array([[[0], [0], ..., [0]],\n",
        "                  [[0], [0], ..., [0]]], dtype=uint8),\n",
        "  'label': 2,\n",
        "}\n",
        "```\n",
        "\n",
        "{Nota: Actualmente, la función sólo está disponible para las funciones `Tensor`, `Image` y `Scalar`. Las funciones `Audio` y `Video` estarán disponibles próximamente. Permanece atento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8kLyK5j1enhc"
      },
      "source": [
        "## Uso con PyTorch\n",
        "\n",
        "PyTorch utiliza el paradigma fuente/muestreador/cargador. En Torch, las \"fuentes de datos\" se llaman \" datasets\". [`torch.utils.data`](https://pytorch.org/docs/stable/data.html) contiene todos los detalles que necesita saber para construir tuberías de entrada eficientes en Torch.\n",
        "\n",
        "Las fuentes de datos TFDS pueden utilizarse como [conjuntos de datos  tipo mapa](https://pytorch.org/docs/stable/data.html#map-style-datasets) normales.\n",
        "\n",
        "Primero instalamos e importamos Torch:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3aKol1fDeyoK"
      },
      "outputs": [],
      "source": [
        "!pip install torch\n",
        "\n",
        "from tqdm import tqdm\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKdJvYywe0YC"
      },
      "source": [
        "Ya hemos definido las fuentes de datos para entrenamiento y prueba (respectivamente, `ds['train']` y `ds['test']`). Ahora podemos definir el muestreador y los cargadores:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_4P2JIrie23f"
      },
      "outputs": [],
      "source": [
        "batch_size = 128\n",
        "train_sampler = torch.utils.data.RandomSampler(ds['train'], num_samples=5_000)\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    ds['train'],\n",
        "    sampler=train_sampler,\n",
        "    batch_size=batch_size,\n",
        ")\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    ds['test'],\n",
        "    sampler=None,\n",
        "    batch_size=batch_size,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVhofOm4e53O"
      },
      "source": [
        "Utilizando PyTorch, entrenamos y evaluamos una regresión logística simple en los primeros ejemplos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HcAmvMa-e42p"
      },
      "outputs": [],
      "source": [
        "class LinearClassifier(torch.nn.Module):\n",
        "  def __init__(self, shape, num_classes):\n",
        "    super(LinearClassifier, self).__init__()\n",
        "    height, width, channels = shape\n",
        "    self.classifier = torch.nn.Linear(height * width * channels, num_classes)\n",
        "\n",
        "  def forward(self, image):\n",
        "    image = image.view(image.size()[0], -1).to(torch.float32)\n",
        "    return self.classifier(image)\n",
        "\n",
        "\n",
        "model = LinearClassifier(shape, num_classes)\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "print('Training...')\n",
        "model.train()\n",
        "for example in tqdm(train_loader):\n",
        "  image, label = example['image'], example['label']\n",
        "  prediction = model(image)\n",
        "  loss = loss_function(prediction, label)\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "print('Testing...')\n",
        "model.eval()\n",
        "num_examples = 0\n",
        "true_positives = 0\n",
        "for example in tqdm(test_loader):\n",
        "  image, label = example['image'], example['label']\n",
        "  prediction = model(image)\n",
        "  num_examples += image.shape[0]\n",
        "  predicted_label = prediction.argmax(dim=1)\n",
        "  true_positives += (predicted_label == label).sum().item()\n",
        "print(f'\\nAccuracy: {true_positives/num_examples * 100:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewKJQpwZe6Ik"
      },
      "source": [
        "## Próximamente: uso con JAX\n",
        "\n",
        "Estamos trabajando estrechamente con [Grain](https://github.com/google/grain). Grain es un cargador de datos de código abierto, rápido y determinista para Python. Estén al tanto."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvLEtCWRvvy8"
      },
      "source": [
        "## Más información\n",
        "\n",
        "Para obtener más información, consulte [`tfds.data_source`](https://www.tensorflow.org/datasets/api_docs/python/tfds/data_source) API doc."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "tfless_tfds.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
