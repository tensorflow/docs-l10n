{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FN7k9-TsMICZ"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "FNJDzmhEMJxP"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPVGKX1CDwk6"
      },
      "source": [
        "# TFDS y determinismo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLgkbSCbTHGT"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td><a target=\"_blank\" href=\"https://www.tensorflow.org/datasets/determinism\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver en TensorFlow.org</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/es-419/datasets/determinism.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Ejecutar en Google Colab</a></td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/es-419/datasets/determinism.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver en GitHub</a>\n",
        "</td>\n",
        "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/es-419/datasets/determinism.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Descargar el bloc de notas</a>\n",
        "</td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxyk-aykTMBQ"
      },
      "source": [
        "En este documento se explica:\n",
        "\n",
        "- Las garantías de TFDS en el determinismo\n",
        "- El orden en el que TFDS lee  los ejemplos\n",
        "- Una variedad de precauciones y errores\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RvSNu11KPL1l"
      },
      "source": [
        "## Preparación\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Ho-Btn6CRpM"
      },
      "source": [
        "### Conjuntos de datos\n",
        "\n",
        "Se necesita algo de contexto para entender cómo TFDS lee los datos.\n",
        "\n",
        "Durante la generación, TFDS escribe los datos originales en archivos `.tfrecord` estandarizados. Para los conjuntos de datos grandes, se crean varios archivos `.tfrecord`, cada uno de los cuales contiene varios ejemplos. A cada archivo `.tfrecord` lo llamamos **partición**.\n",
        "\n",
        "Esta guía usa  imagenet que tiene 1024 particiones:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5uWx_PnYB_OO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "imagenet has 1024 shards (1281167 examples)\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "imagenet = tfds.builder('imagenet2012')\n",
        "\n",
        "num_shards = imagenet.info.splits['train'].num_shards\n",
        "num_examples = imagenet.info.splits['train'].num_examples\n",
        "print(f'imagenet has {num_shards} shards ({num_examples} examples)')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXwzaoLkD3vl"
      },
      "source": [
        "### Encontrar los id de los ejemplos del conjunto de datos\n",
        "\n",
        "Vaya a la siguiente sección si solo desea saber sobre el determinismo.\n",
        "\n",
        "Cada ejemplo de los conjuntos de datos se identifica de forma única mediante un `id` (por ejemplo `'imagenet2012-train.tfrecord-01023-of-01024__32'`). Se puede recuperar el `id` al pasar `read_config.add_tfds_id = True`, que agregará una clave `'tfds_id'` en el dict de `tf.data.Dataset`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ud9H2rr4R5g0"
      },
      "source": [
        "En este tutorial, definimos una pequeña util que imprimirá los id de ejemplo del conjunto de datos (convertidos en números enteros para que sean más legibles para los humanos):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "wnybvfFAB2QZ"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "\n",
        "def load_dataset(builder, **as_dataset_kwargs):\n",
        "  \"\"\"Load the dataset with the tfds_id.\"\"\"\n",
        "  read_config = as_dataset_kwargs.pop('read_config', tfds.ReadConfig())\n",
        "  read_config.add_tfds_id = True  # Set `True` to return the 'tfds_id' key\n",
        "  return builder.as_dataset(read_config=read_config, **as_dataset_kwargs)\n",
        "\n",
        "def print_ex_ids(\n",
        "    builder,\n",
        "    *,\n",
        "    take: int,\n",
        "    skip: int = None,\n",
        "    **as_dataset_kwargs,\n",
        ") -> None:\n",
        "  \"\"\"Print the example ids from the given dataset split.\"\"\"\n",
        "  ds = load_dataset(builder, **as_dataset_kwargs)\n",
        "  if skip:\n",
        "    ds = ds.skip(skip)\n",
        "  ds = ds.take(take)\n",
        "  exs = [ex['tfds_id'].numpy().decode('utf-8') for ex in ds]\n",
        "  exs = [id_to_int(tfds_id, builder=builder) for tfds_id in exs]\n",
        "  print(exs)\n",
        "\n",
        "def id_to_int(tfds_id: str, builder) -> str:\n",
        "  \"\"\"Format the tfds_id in a more human-readable.\"\"\"\n",
        "  match = re.match(r'\\w+-(\\w+).\\w+-(\\d+)-of-\\d+__(\\d+)', tfds_id)\n",
        "  split_name, shard_id, ex_id = match.groups()\n",
        "  split_info = builder.info.splits[split_name]\n",
        "  return sum(split_info.shard_lengths[:int(shard_id)]) + int(ex_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OuB1fVkMThfc"
      },
      "source": [
        "## Determinismo cuando se lee\n",
        "\n",
        "En esta sección se explica la garantía determinista de `tfds.load`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUQnKzMfCKhr"
      },
      "source": [
        "### Con `shuffle_files=False` (predeterminado)\n",
        "\n",
        "De forma predeterminada, TFDS produce ejemplos de forma determinista (`shuffle_files=False`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I2DS1cIXCnRv"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 1251, 1252, 1253, 1254]\n",
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 1251, 1252, 1253, 1254]\n"
          ]
        }
      ],
      "source": [
        "# Same as: imagenet.as_dataset(split='train').take(20)\n",
        "print_ex_ids(imagenet, split='train', take=20)\n",
        "print_ex_ids(imagenet, split='train', take=20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOTdwzguYRua"
      },
      "source": [
        "Para mejorar el rendimiento, TFDS lee varias particiones al mismo tiempo con [tf.data.Dataset.interleave](https://www.tensorflow.org/api_docs/python/tf/data/Dataset?version=nightly#interleave). En este ejemplo, vemos que TFDS cambia a la partición 2 después de leer 16 ejemplos (`..., 14, 15, 1251, 1252, ...`). A continuación, tiene más información sobre la intercalación."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mm74ZShHDLaD"
      },
      "source": [
        "De manera similar, la API de subdivisión también es determinista:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sy2ZbVrIDPjL"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[858382, 858383, 858384, 858385, 858386, 858387, 858388, 858389, 858390, 858391, 858392, 858393, 858394, 858395, 858396, 858397, 859533, 859534, 859535, 859536]\n",
            "[858382, 858383, 858384, 858385, 858386, 858387, 858388, 858389, 858390, 858391, 858392, 858393, 858394, 858395, 858396, 858397, 859533, 859534, 859535, 859536]\n"
          ]
        }
      ],
      "source": [
        "print_ex_ids(imagenet, split='train[67%:84%]', take=20)\n",
        "print_ex_ids(imagenet, split='train[67%:84%]', take=20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTz1KewrEFbl"
      },
      "source": [
        "Si está entrenando para más de una época, no se recomienda la configuración anterior ya que todas las épocas leerán las particiones en el mismo orden (por lo que la aleatoriedad se limita al tamaño del búfer `ds = ds.shuffle(buffer)`)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-VHVi3RDdBf"
      },
      "source": [
        "### Con `shuffle_files=True`\n",
        "\n",
        "Con `shuffle_files=True`, las particiones se aleatorizan para cada época, por lo que la lectura ya no es determinista."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NdUzVeYyFUD9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[568017, 329050, 329051, 329052, 329053, 329054, 329056, 329055, 568019, 568020, 568021, 568022, 568023, 568018, 568025, 568024, 568026, 568028, 568030, 568031]\n",
            "[43790, 43791, 43792, 43793, 43796, 43794, 43797, 43798, 43795, 43799, 43800, 43801, 43802, 43803, 43804, 43805, 43806, 43807, 43809, 43810]\n"
          ]
        }
      ],
      "source": [
        "print_ex_ids(imagenet, split='train', shuffle_files=True, take=20)\n",
        "print_ex_ids(imagenet, split='train', shuffle_files=True, take=20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAJTLLsuFeuP"
      },
      "source": [
        "Nota: Al configurar `shuffle_files=True` también [se desactiva](https://github.com/tensorflow/datasets/tree/master/tensorflow_datasets/core/dataset_builder.py?l=676&rcl=354322021) `deterministic` en [`tf.data.Options`](https://www.tensorflow.org/api_docs/python/tf/data/Options) para mejorar el rendimiento. Por lo tanto, incluso los conjuntos de datos pequeños que solo tienen una partición (como mnist) se vuelven no deterministas.\n",
        "\n",
        "Vea la receta a continuación para obtener una aleatorización de archivos determinista."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDg18upoKFX0"
      },
      "source": [
        "### Advertencia de determinismo: intercalar args"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4vjtL11KSIg"
      },
      "source": [
        "Al cambiar `read_config.interleave_cycle_length`, `read_config.interleave_block_length` cambiará el orden de los ejemplos.\n",
        "\n",
        "TFDS depende de [tf.data.Dataset.interleave](https://www.tensorflow.org/api_docs/python/tf/data/Dataset?version=nightly#interleave) para cargar solo unas pocas particiones a la vez, lo que mejora el rendimiento y reduce el uso de memoria.\n",
        "\n",
        "Solo se puede garantizar que el orden del ejemplo sea el mismo para un valor fijo de args intercalados. Consulte [el documento de intercalación](https://www.tensorflow.org/api_docs/python/tf/data/Dataset?version=nightly#interleave) para entender qué `cycle_length` y `block_length` corresponden también.\n",
        "\n",
        "- `cycle_length=16`, `block_length=16` (predeterminado, igual que antes):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vMq50jt6KRY-"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 1251, 1252, 1253, 1254]\n"
          ]
        }
      ],
      "source": [
        "print_ex_ids(imagenet, split='train', take=20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pjdo3ExfT7vw"
      },
      "source": [
        "- `cycle_length=3`, `block_length=2`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mrE-qErdmxAi"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0, 1, 1251, 1252, 2502, 2503, 2, 3, 1253, 1254, 2504, 2505, 4, 5, 1255, 1256, 2506, 2507, 6, 7]\n"
          ]
        }
      ],
      "source": [
        "read_config = tfds.ReadConfig(\n",
        "    interleave_cycle_length=3,\n",
        "    interleave_block_length=2,\n",
        ")\n",
        "print_ex_ids(imagenet, split='train', read_config=read_config, take=20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGsbzwRXS3LR"
      },
      "source": [
        "En el segundo ejemplo, vemos que el conjunto de datos lee 2 ejemplos (`block_length=2`) en una partición y luego cambia la siguiente partición. Cada 2 * 3 ejemplos (`cycle_length=3`), vuelve a la primera partición `shard0-ex0, shard0-ex1, shard1-ex0, shard1-ex1, shard2-ex0, shard2-ex1, shard0-ex2, shard0-ex3, shard1-ex2, shard1-ex3, shard2-ex2,...`).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WHS1DRgJ1W8"
      },
      "source": [
        "### Subdivisión y orden del ejemplo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4O3cTBBCV8q"
      },
      "source": [
        "Cada ejemplo tiene un id `0, 1, ..., num_examples-1`. La [API de subdivisión](https://www.tensorflow.org/datasets/splits) selecciona un segmento de ejemplos (por ejemplo, `train[:x]` selecciona `0, 1, ..., x-1`).\n",
        "\n",
        "Sin embargo, dentro de la subdivisión, los ejemplos no se leen en orden ascendiente del id (debido a las particiones y la intercalación).\n",
        "\n",
        "Más específicamente, `ds.take(x)` y `split='train[:x]'` **no** son equivalentes.\n",
        "\n",
        "Esto se puede ver fácilmente en el ejemplo de intercalación anterior, donde los ejemplos provienen de diferentes particiones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7afoTz2XCEFv"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259]\n",
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]\n"
          ]
        }
      ],
      "source": [
        "print_ex_ids(imagenet, split='train', take=25)  # tfds.load(..., split='train').take(25)\n",
        "print_ex_ids(imagenet, split='train[:25]', take=-1)  # tfds.load(..., split='train[:25]')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_e-lAnkSvSX"
      },
      "source": [
        "Después de los 16 ejemplos (block_length), `.take(25)` cambia a la siguiente partición mientras que `train[:25]` continúa leyendo ejemplos desde la primera partición."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZ4RWjOvbLEc"
      },
      "source": [
        "## Recetas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Vf0Qg2eVjrH"
      },
      "source": [
        "### Obtenga una aleatorización de archivos determinista\n",
        "\n",
        "Hay 2 formas de realizar una aleatorización determinista:\n",
        "\n",
        "1. Configurar `shuffle_seed`. Nota: Se requiere cambiar el valor de iniciación en cada época; de lo contrario, se leerán las particiones en el mismo orden entre épocas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ii0lhSSTYQ9-"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[176411, 176412, 176413, 176414, 176415, 176416, 176417, 176418, 176419, 176420, 176421, 176422, 176423, 176424, 176425, 176426, 710647, 710648, 710649, 710650, 710651, 710652]\n",
            "[176411, 176412, 176413, 176414, 176415, 176416, 176417, 176418, 176419, 176420, 176421, 176422, 176423, 176424, 176425, 176426, 710647, 710648, 710649, 710650, 710651, 710652]\n"
          ]
        }
      ],
      "source": [
        "read_config = tfds.ReadConfig(\n",
        "    shuffle_seed=32,\n",
        ")\n",
        "\n",
        "# Deterministic order, different from the default shuffle_files=False above\n",
        "print_ex_ids(imagenet, split='train', shuffle_files=True, read_config=read_config, take=22)\n",
        "print_ex_ids(imagenet, split='train', shuffle_files=True, read_config=read_config, take=22)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaMHOCAMVw2A"
      },
      "source": [
        "1. Con `experimental_interleave_sort_fn`: brinda control total sobre qué particiones se leen y en qué orden, en lugar de depender del orden `ds.shuffle`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WMylp8UmZSSr"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1279916, 1279917, 1279918, 1279919, 1279920]\n"
          ]
        }
      ],
      "source": [
        "def _reverse_order(file_instructions):\n",
        "  return list(reversed(file_instructions))\n",
        "\n",
        "read_config = tfds.ReadConfig(\n",
        "    experimental_interleave_sort_fn=_reverse_order,\n",
        ")\n",
        "\n",
        "# Last shard (01023-of-01024) is read first\n",
        "print_ex_ids(imagenet, split='train', read_config=read_config, take=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUFRWRa1V28p"
      },
      "source": [
        "### Obtener una canalización determinista que se puede interrumpir\n",
        "\n",
        "Éste es más complicado. No existe una solución fácil y satisfactoria.\n",
        "\n",
        "1. En teoría, sin `ds.shuffle` y con una aleatorización determinista, debería ser posible contar los ejemplos que se han leído y deducir qué ejemplos se han leído en cada partición (como una función de `cycle_length`, `block_length` y el orden de las particiones). Luego, se podría instertar `skip`, `take` para cada partición mediante `experimental_interleave_sort_fn`.\n",
        "\n",
        "2. Es probable que no sea posible con `ds.shuffle` sin volver a reproducir toda la canalización del entrenamiento. Sería necesario guardar el estado del búfer `ds.shuffle` para deducir qué ejemplos se han leído. Los ejemplos podrían ser discontinuos (por ejemplo, que se lea `shard5_ex2`, `shard5_ex4` pero no `shard5_ex3`).\n",
        "\n",
        "3. Con `ds.shuffle`, una forma sería guardar todos los shards_ids/example_ids leídos (que se deducen de `tfds_id`) y luego deducir las instrucciones del archivo a partir de eso.\n",
        "\n",
        "El caso más simple para `1.` es hacer que `.skip(x).take(y)` coincida con `train[x:x+y]`. Se debe hacer lo siguiente:\n",
        "\n",
        "- Establecer `cycle_length=1` (para que se lean las particiones secuencialmente)\n",
        "- Establecer `shuffle_files=False`\n",
        "- No usar `ds.shuffle`\n",
        "\n",
        "Solo debe usarse en conjuntos de datos grandes donde el entrenamiento es de solo 1 época. Los ejemplos se leerán en el orden aleatorio predeterminado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UP3jmvZPfrGf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61]\n",
            "[40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61]\n"
          ]
        }
      ],
      "source": [
        "read_config = tfds.ReadConfig(\n",
        "    interleave_cycle_length=1,  # Read shards sequentially\n",
        ")\n",
        "\n",
        "print_ex_ids(imagenet, split='train', read_config=read_config, skip=40, take=22)\n",
        "# If the job get pre-empted, using the subsplit API will skip at most `len(shard0)`\n",
        "print_ex_ids(imagenet, split='train[40:]', read_config=read_config, take=22)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKw9kG6SaT2E"
      },
      "source": [
        "### Encuentrar qué particiones/ejemplos se leen para una subdivisión determinada\n",
        "\n",
        "Con `tfds.core.DatasetInfo`, se tiene acceso directo a las instrucciones de lectura."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "caqarAYkafEo"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[FileInstruction(filename='imagenet2012-train.tfrecord-00450-of-01024', skip=700, take=-1, num_examples=551),\n",
              " FileInstruction(filename='imagenet2012-train.tfrecord-00451-of-01024', skip=0, take=-1, num_examples=1251),\n",
              " FileInstruction(filename='imagenet2012-train.tfrecord-00452-of-01024', skip=0, take=-1, num_examples=1251),\n",
              " FileInstruction(filename='imagenet2012-train.tfrecord-00453-of-01024', skip=0, take=-1, num_examples=1251),\n",
              " FileInstruction(filename='imagenet2012-train.tfrecord-00454-of-01024', skip=0, take=-1, num_examples=1252),\n",
              " FileInstruction(filename='imagenet2012-train.tfrecord-00455-of-01024', skip=0, take=-1, num_examples=1251),\n",
              " FileInstruction(filename='imagenet2012-train.tfrecord-00456-of-01024', skip=0, take=-1, num_examples=1251),\n",
              " FileInstruction(filename='imagenet2012-train.tfrecord-00457-of-01024', skip=0, take=-1, num_examples=1251),\n",
              " FileInstruction(filename='imagenet2012-train.tfrecord-00458-of-01024', skip=0, take=-1, num_examples=1251),\n",
              " FileInstruction(filename='imagenet2012-train.tfrecord-00459-of-01024', skip=0, take=-1, num_examples=1251),\n",
              " FileInstruction(filename='imagenet2012-train.tfrecord-00460-of-01024', skip=0, take=1001, num_examples=1001)]"
            ]
          },
          "execution_count": 48,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "imagenet.info.splits['train[44%:45%]'].file_instructions"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "FN7k9-TsMICZ"
      ],
      "name": "determinism.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
