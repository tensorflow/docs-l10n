{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIMvgrGMe7ZF"
      },
      "source": [
        "##### Copyright 2022 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "n25wrPRbfCGc"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZyGUj_q7IdfQ"
      },
      "source": [
        "# Colecciones de conjuntos de datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LpO0um1nez_q"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td><a target=\"_blank\" href=\"https://www.tensorflow.org/datasets/dataset_collections\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver en TensorFlow.org</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/es-419/datasets/dataset_collections.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Ejecutar en Google Colab</a></td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/es-419/datasets/dataset_collections.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver en GitHub</a>\n",
        "</td>\n",
        "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/es-419/datasets/dataset_collections.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Descargar el bloc de notas</a>\n",
        "</td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p8AFT7CpSzBG"
      },
      "source": [
        "## Descripción general\n",
        "\n",
        "Las colecciones de conjuntos de datos proporcionan una manera simple de agrupar una cantidad arbitraria de conjuntos de datos TFDS existentes y realizar operaciones simples en ellos.\n",
        "\n",
        "Pueden resultar útiles, por ejemplo, para agrupar diferentes conjuntos de datos que se relacionan con la misma tarea o para [realizar una prueba comparativa](https://ruder.io/nlp-benchmarking/) sencilla de modelos en un número fijo de tareas diferentes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZjxBV9E79Fl"
      },
      "source": [
        "## Preparación\n",
        "\n",
        "Para comenzar, instale algunos paquetes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1AnxnW65I_FC"
      },
      "outputs": [],
      "source": [
        "# Use tfds-nightly to ensure access to the latest features.\n",
        "!pip install -q tfds-nightly tensorflow\n",
        "!pip install -U conllu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81CCGS5R8GeV"
      },
      "source": [
        "Importe TensorFlow y el paquete Tensorflow Datasets a su entorno de desarrollo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-hxMPT0wIu3f"
      },
      "outputs": [],
      "source": [
        "import pprint\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "at0bMS_jIdjt"
      },
      "source": [
        "Las colecciones de conjuntos de datos proporcionan una manera simple de agrupar una cantidad arbitraria de conjuntos de datos existentes desde Tensorflow Datasets (TFDS) y realizar operaciones simples en ellos.\n",
        "\n",
        "Pueden resultar útiles, por ejemplo, para agrupar diferentes conjuntos de datos que se relacionan con la misma tarea o para [realizar una prueba comparativa](https://ruder.io/nlp-benchmarking/) sencilla de modelos en un número fijo de tareas diferentes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLvkZBKwIdmL"
      },
      "source": [
        "## Encuentrar colecciones de conjuntos de datos disponibles\n",
        "\n",
        "Todos los generadores de colecciones de conjuntos de datos son una subclase de `tfds.core.dataset_collection_builder.DatasetCollection`.\n",
        "\n",
        "Para obtener la lista de generadores disponibles, use `tfds.list_dataset_collections()`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R14uGGzKItDz"
      },
      "outputs": [],
      "source": [
        "tfds.list_dataset_collections()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jpcq2AMvI5K1"
      },
      "source": [
        "## Cargar e inspeccionar una colección de conjuntos de datos\n",
        "\n",
        "La forma más fácil de cargar una colección de conjuntos de datos es crear una instancia de un objeto `DatasetCollectionLoader` mediante el uso del comando [`tfds.dataset_collection`](https://www.tensorflow.org/datasets/api_docs/python/tfds/dataset_collection).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "leIwyl9aI3WA"
      },
      "outputs": [],
      "source": [
        "collection_loader = tfds.dataset_collection('xtreme')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgjomybjY7qI"
      },
      "source": [
        "Se pueden cargar versiones específicas de la colección de conjuntos de datos al seguir la misma sintaxis que con los conjuntos de datos TFDS:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pyILkuYJY6ts"
      },
      "outputs": [],
      "source": [
        "collection_loader = tfds.dataset_collection('xtreme:1.0.0')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKOJ6CNQKG9S"
      },
      "source": [
        "Un cargador de colecciones de conjuntos de datos puede mostrar información sobre la colección:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kwk4PVDoKEAC"
      },
      "outputs": [],
      "source": [
        "collection_loader.print_info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FlLLbwuLLTu"
      },
      "source": [
        "El cargador de conjuntos de datos también puede mostrar información sobre los conjuntos de datos que tiene la colección:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IxNJEie6K55T"
      },
      "outputs": [],
      "source": [
        "collection_loader.print_datasets()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGxorc3kLwRj"
      },
      "source": [
        "### Cargar conjuntos de datos desde una colección de conjuntos de datos\n",
        "\n",
        "La forma más fácil de cargar un conjunto de datos de una colección es con el método `load_dataset` de un objeto `DatasetCollectionLoader`, que carga el conjunto de datos requerido llamando al [`tfds.load`](https://www.tensorflow.org/datasets/api_docs/python/tfds/load).\n",
        "\n",
        "Esta llamada devuelve un diccionario de nombres divididos y los `tf.data.Dataset` correspondientes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UP1nRj4ILwb6"
      },
      "outputs": [],
      "source": [
        "splits = collection_loader.load_dataset(\"ner\")\n",
        "\n",
        "pprint.pprint(splits)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2spLEgN1Lwmm"
      },
      "source": [
        "`load_dataset` acepta los siguientes parámetros opcionales:\n",
        "\n",
        "- `split`: qué división o divisiones cargar. Acepta una única división (`split=\"test\"`) o una lista de divisiones: ( `split=[\"train\", \"test\"]`). Si no se especifica, cargará todas las divisiones para el conjunto de datos dado.\n",
        "- `loader_kwargs`: argumentos de palabras clave que se pasarán a la función `tfds.load`. Consulte la documentación [`tfds.load`](https://www.tensorflow.org/datasets/api_docs/python/tfds/load) para obtener una descripción general completa de las diferentes opciones de carga."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aClLU4eAh2oC"
      },
      "source": [
        "### Cargar varios conjuntos de datos desde una colección de conjuntos de datos\n",
        "\n",
        "La forma más fácil de cargar varios conjuntos de datos de una colección es con el método `load_dataset` de un objeto `DatasetCollectionLoader`, que carga el conjunto de datos requerido llamando al [`tfds.load`](https://www.tensorflow.org/datasets/api_docs/python/tfds/load).\n",
        "\n",
        "Devuelve un diccionario de nombres de conjuntos de datos, cada uno de estos está asociado con un diccionario de nombres divididos y los `tf.data.Dataset` correspondientes, como en el siguiente ejemplo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sEG5744Oh2vQ"
      },
      "outputs": [],
      "source": [
        "datasets = collection_loader.load_datasets(['xnli', 'bucc'])\n",
        "\n",
        "pprint.pprint(datasets)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WF0kNqwsiN1Y"
      },
      "source": [
        "El método `load_all_datasets` carga *todos* los conjuntos de datos disponibles para una colección determinada:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QX-M3xcjiM35"
      },
      "outputs": [],
      "source": [
        "all_datasets = collection_loader.load_all_datasets()\n",
        "\n",
        "pprint.pprint(all_datasets)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXxVztK5kAHh"
      },
      "source": [
        "El método `load_datasets` acepta los siguientes parámetros opcionales:\n",
        "\n",
        "- `split`: qué división o divisiones cargar. Acepta una única división (`split=\"test\"`) o una lista de divisiones: ( `split=[\"train\", \"test\"]`). Si no se especifica, cargará todas las divisiones para el conjunto de datos dado.\n",
        "- `loader_kwargs`: argumentos de palabras clave que se pasarán a la función `tfds.load`. Consulte la documentación [`tfds.load`](https://www.tensorflow.org/datasets/api_docs/python/tfds/load) para obtener una descripción general completa de las diferentes opciones de carga."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4JoreSHfcKZ"
      },
      "source": [
        "### Especificar `loader_kwargs`\n",
        "\n",
        "Los `loader_kwargs` son argumentos de palabras clave opcionales que se pasarán a la función [`tfds.load`](https://www.tensorflow.org/datasets/api_docs/python/tfds/load). Se pueden especificar de tres maneras:\n",
        "\n",
        "1. Al inicializar la clase `DatasetCollectionLoader`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TjgZSIlvfcSP"
      },
      "outputs": [],
      "source": [
        "collection_loader = tfds.dataset_collection('xtreme', loader_kwargs=dict(split='train', lote_size=10, try_gcs=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJcEZl97Xj6Y"
      },
      "source": [
        "1. Con el método `set_loader_kwargs` de `DatasetCollectioLoader`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zrysflp-k1d3"
      },
      "outputs": [],
      "source": [
        "collection_loader.set_loader_kwargs(dict(split='train', batch_size=10, try_gcs=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ra-ZonhfXkLD"
      },
      "source": [
        "1. Como parámetros opcionales para los métodos `load_dataset`, `load_datasets` y `load_all_datasets`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rHSu-8GnlGTk"
      },
      "outputs": [],
      "source": [
        "dataset = collection_loader.load_dataset('ner', loader_kwargs=dict(split='train', batch_size=10, try_gcs=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJDGoeAqmJAQ"
      },
      "source": [
        "### Comentarios\n",
        "\n",
        "Siempre buscamos mejorar el flujo de trabajo de la creación de conjuntos de datos, pero solo podemos hacerlo si conocemos los problemas que hay. ¿Qué problemas o errores encontró al crear la colección del conjunto de datos? ¿Hubo alguna parte que le resultó confusa o no funcionó la primera vez? Comparta sus comentarios en [GitHub](https://github.com/tensorflow/datasets/issues)."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "dataset_collections.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
