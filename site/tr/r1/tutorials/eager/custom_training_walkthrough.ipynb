{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rwxGnsA92emp"
      },
      "source": [
        "##### Copyright 2018 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "cellView": "form",
        "colab": {},
        "colab_type": "code",
        "id": "CPII1rGR2rF9"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JtEZ1pCPn--z"
      },
      "source": [
        "# Kisisellestirilmis egitim: adim adim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GV1F7tVTN3Dn"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/tr/r1/tutorials/eager/custom_training_walkthrough.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/tr/r1/tutorials/eager/custom_training_walkthrough.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LDrzLFXE8T1l"
      },
      "source": [
        "Bu egitim kitapciginda makine ogrenmesini kullanarak zambak ciceklerini turlerine gore *siniflandirmayi* ogrenecegiz. Bunun icin TensorFlow'un [eager modunu](https://www.tensorflow.org/r1/guide/eager) kullanacagiz:\n",
        "1. Modeli olustur,\n",
        "2. Ornek veri ustunde modeli egit ve\n",
        "3. Bilinmeyen veri hakkinda tahmin yurutmek icin modeli kullan.\n",
        "\n",
        "## TensorFlow yazilimi\n",
        "\n",
        "Burada yuksek-seviye TensorFlow kapsamlarini kullanacagiz:\n",
        "\n",
        "* [Eager modu](https://www.tensorflow.org/r1/guide/eager) gelistirme ortamini aktive etmek,\n",
        "* [Datasets API](https://www.tensorflow.org/r1/guide/datasets)'si ile verileri iceri almak,\n",
        "* TensorFlow [Keras API](https://keras.io/getting-started/sequential-model-guide/)'si ile modelleri ve katmanlari olusturmak.\n",
        "\n",
        "Bu kitapcigi bircok TensorFlow programi gibi planladik:\n",
        "\n",
        "1. Veri setlerini iceri al ve ayristir.\n",
        "2. Modeli sec.\n",
        "3. Modeli egit.\n",
        "4. Modelin verimliligini degerlendir\n",
        "5. Egitilen modeli tahmin yurutmek icin kullan."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yNr7H-AIoLOR"
      },
      "source": [
        "## Programi kuralim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1J3AuPBT9gyR"
      },
      "source": [
        "### Iceri alimlari ve eager modunu yapilandiralim\n",
        "\n",
        "TensorFlow'da dahil olmak uzere gerekli Python birimlerini iceri alalim ve eager modunu aktiflestirelim. Eager modu sayesinde TensorFlow operasyonlari aninda degerlendirir ve daha sonra yurutulecek bir [computational graph(Hesap grafigi)](https://www.tensorflow.org/r1/guide/graphs) olusturmak yerine somut degerler cikartir. Bu REPL ya da 'python'un etkilesimli konsoluna cok benzer. Eager modu [Tensorlow >=1.8](https://www.tensorflow.org/install/)'da bulunmaktadir.\n",
        "\n",
        "Eager modu bir kere aktive edildiginde ayni program icinde kapatilamaz. Detaylar icin [eager modu rehberine](https://www.tensorflow.org/r1/guide/eager) bakiniz."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "g4Wzg69bnwK2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow.compat.v1 as tf\n",
        "\n",
        "\n",
        "\n",
        "print(\"TensorFlow version: {}\".format(tf.__version__))\n",
        "print(\"Eager execution: {}\".format(tf.executing_eagerly()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Zx7wc0LuuxaJ"
      },
      "source": [
        "## Zambak siniflandirmasi problemi\n",
        "\n",
        "Buldugunuz her zambak cicegini siniflandirmayi amaclayan bir botanikci oldugunuzu hayal edin. Makine ogrenmesi bunu istatistiksel olarak yapmanizi saglayan algoritmalar saglar. Ornegin, iyi bir makine ogrenmesi programi cicekleri resimlerine bakarak siniflandirabilir. Biz burada daha mutevazi bir yol izleyip zambaklari [canak yapraklarinin](https://en.wikipedia.org/wiki/Sepal) ve [tac yapraklarinin](https://en.wikipedia.org/wiki/Petal) uzunluguna ve capina gore siniflandiracagiz.\n",
        "\n",
        "300'den fazla zambak turu bulunmasina ragmen programimiz bunlardan ucunu siniflandiracak:\n",
        "\n",
        "* Iris setosa\n",
        "* Iris virginica\n",
        "* Iris versicolor\n",
        "\n",
        "<table>\n",
        "  <tr><td>\n",
        "    <img src=\"https://www.tensorflow.org/images/iris_three_species.jpg\"\n",
        "         alt=\"Petal geometry compared for three iris species: Iris setosa, Iris virginica, and Iris versicolor\">\n",
        "  </td></tr>\n",
        "  <tr><td align=\"center\">\n",
        "    <b>Figure 1.</b> <a href=\"https://commons.wikimedia.org/w/index.php?curid=170298\">Iris setosa</a> (by <a href=\"https://commons.wikimedia.org/wiki/User:Radomil\">Radomil</a>, CC BY-SA 3.0), <a href=\"https://commons.wikimedia.org/w/index.php?curid=248095\">Iris versicolor</a>, (by <a href=\"https://commons.wikimedia.org/wiki/User:Dlanglois\">Dlanglois</a>, CC BY-SA 3.0), and <a href=\"https://www.flickr.com/photos/33397993@N05/3352169862\">Iris virginica</a> (by <a href=\"https://www.flickr.com/photos/33397993@N05\">Frank Mayfield</a>, CC BY-SA 2.0).<br/>&nbsp;\n",
        "  </td></tr>\n",
        "</table>\n",
        "\n",
        "Sansimiza bir [120 zambak cicegi veri seti](https://en.wikipedia.org/wiki/Iris_flower_data_set) tac ve canak yapragi olculeri ile olusturulmus. Bu makine ogrenmesi siniflandirma problemine acemi olanlar icin populer bir veri setidir."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3Px6KAg0Jowz"
      },
      "source": [
        "## Egitim veri setini iceri al ve ayristir\n",
        "\n",
        "Veri seti dosyasini indirelim ve bu Python programi tarafindan kullanilabilecek yapiya cevirelim.\n",
        "\n",
        "### Veri setini indirelim\n",
        "\n",
        "[tf.keras.utils.get_file](https://www.tensorflow.org/api_docs/python/tf/keras/utils/get_file) fonksiyonunu kullanarak egitim veri setini indirelim. Bu yontem indirilen dosyanin dosya yolunu geri dondurur."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "J6c7uEU9rjRM"
      },
      "outputs": [],
      "source": [
        "train_dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\"\n",
        "\n",
        "train_dataset_fp = tf.keras.utils.get_file(fname=os.path.basename(train_dataset_url),\n",
        "                                           origin=train_dataset_url)\n",
        "\n",
        "print(\"Local copy of the dataset file: {}\".format(train_dataset_fp))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qnX1-aLors4S"
      },
      "source": [
        "### Veriyi inceleyelim\n",
        "\n",
        "Bu veri seti, `iris_training.csv`, virgulle ayrilmis degerlerin (CSV) bulundugu basit bir metin dosyasidir. `head -n5` komutunu kullanarak ilk bes girise goz atabiliriz:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "FQvb_JYdrpPm"
      },
      "outputs": [],
      "source": [
        "!head -n5 {train_dataset_fp}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kQhzD6P-uBoq"
      },
      "source": [
        "Veri setine bu acidan baktigimizda sunlara dikkat edelim:\n",
        "\n",
        "1. Ilk satir veri seti ile ilgili bilgi iceren basliktir:\n",
        "  * Toplamda 120 ornek bulunur. Her ornekte dort ozellik ve olasi uc etiket isminden birisi vardir.\n",
        "2. Sonra gelen satirlar veri kayitlarini gosterir, *[ornegin](https://developers.google.com/machine-learning/glossary/#example)* burada:\n",
        "  * Ilk dort alan *[ozelliklerdir](https://developers.google.com/machine-learning/glossary/#feature)*. Burada, alanlarda bulunan reel sayilar cicegin olculerini temsil eder.\n",
        "  * Son sutun ise *[etiket](https://developers.google.com/machine-learning/glossary/#label)* yani tahmin etmek istedigimiz degerdir. Bu veri setinde 0, 1 ve 2 sayilari bir cicek adina karsilik gelir.\n",
        "\n",
        "Simdi bu kodu yazalim:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "9Edhevw7exl6"
      },
      "outputs": [],
      "source": [
        "# CSV dosyasindaki sutun sirasi\n",
        "column_names = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species']\n",
        "\n",
        "feature_names = column_names[:-1]\n",
        "label_name = column_names[-1]\n",
        "\n",
        "print(\"Features: {}\".format(feature_names))\n",
        "print(\"Label: {}\".format(label_name))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CCtwLoJhhDNc"
      },
      "source": [
        "Her etiket bir dizgi adiyla baglantilidir (ornegin, \"setosa\"), ama makine ogrenmesi genellikler sayilarla calisir. Etiket sayilari su sekilde isimlerle eslestirilebilir:\n",
        "\n",
        "* `0`: Iris setosa\n",
        "* `1`: Iris versicolor\n",
        "* `2`: Iris virginica\n",
        "\n",
        "Ozellikler ve etiketlerle ilgili daha fazla bilgi almak istiyorsaniz [buraya bakiniz](https://developers.google.com/machine-learning/crash-course/framing/ml-terminology)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "sVNlJlUOhkoX"
      },
      "outputs": [],
      "source": [
        "class_names = ['Iris setosa', 'Iris versicolor', 'Iris virginica']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dqPkQExM2Pwt"
      },
      "source": [
        "### `tf.data.Dataset`i olusturalim\n",
        "\n",
        "TensorFlow'un [Dataset API](https://www.tensorflow.org/r1/guide/datasets)'si veriyi modele yuklerken gorulen bircok durumu halledebilir. Veriyi okumak ve egitim icin uygun sekle sokmak icin yuksek-seviye bir API'dir. Detayli bilgi icin [buraya bakiniz](https://www.tensorflow.org/get_started/datasets_quickstart).\n",
        "\n",
        "\n",
        "CSV bicimli metin dosyasi olarak elimizde olan veri setini [make_csv_dataset](https://www.tensorflow.org/api_docs/python/tf/contrib/data/make_csv_dataset) fonksiyonunu kullanarak veriyi uygun sekle sokabiliriz. Bu fonksiyon egitim modelleri icin veri urettigi icin, varsayilan davranis verinin karistirilip (`shuffle=True, shuffle_buffer_size=10000`), veri setinin sonsuza kadar tekrarlanmasidir (`num_epochs=None`). Burada ayrica [batch_size](https://developers.google.com/machine-learning/glossary/#batch_size) degistirgesini de belirtiyoruz."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "WsxHnz1ebJ2S"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "\n",
        "train_dataset = tf.contrib.data.make_csv_dataset(\n",
        "    train_dataset_fp,\n",
        "    batch_size,\n",
        "    column_names=column_names,\n",
        "    label_name=label_name,\n",
        "    num_epochs=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gB_RSn62c-3G"
      },
      "source": [
        "`make_csv_dataset` fonksiyonu `(features, label)` ikilisinden olusan bir `tf.data.Dataset` dondurur. Burada `features` bir sozluktur: `{'feature_name': deger}`\n",
        "\n",
        "Eager modu aktive edildiginde bu 'Dataset' nesnesi yinelenebilir. Simdi ozelliklere goz atalim:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "iDuG94H-C122"
      },
      "outputs": [],
      "source": [
        "features, labels = next(iter(train_dataset))\n",
        "\n",
        "features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "E63mArnQaAGz"
      },
      "source": [
        "Benzer ozelliklerin bir araya getirildigine yani *batched* edildigine dikkat edelim. Her ornegin sutunlari eslestigi ozellik dizisine eklenir. `batch_size` degerini bu ozellik dizilerinde bulunan ornek sayisina esleyelim.\n",
        "\n",
        "Bu 'batch'ten birkac ozelligi grafik halinde gosterirseniz gruplasmayi gorebilirsiniz:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "me5Wn-9FcyyO"
      },
      "outputs": [],
      "source": [
        "plt.scatter(features['petal_length'].numpy(),\n",
        "            features['sepal_length'].numpy(),\n",
        "            c=labels.numpy(),\n",
        "            cmap='viridis')\n",
        "\n",
        "plt.xlabel(\"Petal length\")\n",
        "plt.ylabel(\"Sepal length\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YlxpSyHlhT6M"
      },
      "source": [
        "Model olustuma basamagini kolaylastirmak icin, ozellik sozlugunu `(batch_size, num_features)` sekli olan bir diziye cevirecek bir fonksiyon yazalim.\n",
        "\n",
        "Bu fonksiyon tensor dizisindeki degerleri alarak belirli boyuttaki birlestirilmis tensoru olusturan [tf.stack](https://www.tensorflow.org/api_docs/python/tf/stack) yontemini kullanir."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "jm932WINcaGU"
      },
      "outputs": [],
      "source": [
        "def pack_features_vector(features, labels):\n",
        "  \"\"\"Ozellikleri tek bir diziye paketleyelimPack the features into a single array.\"\"\"\n",
        "  features = tf.stack(list(features.values()), axis=1)\n",
        "  return features, labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "V1Vuph_eDl8x"
      },
      "source": [
        "Sonrasinda [tf.data.Dataset.map](https://www.tensorflow.org/api_docs/python/tf/data/dataset/map) yontemi ile her `(features,label)` ikisindeki `features`i egitim veri setine paketleyelim:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "ZbDkzGZIkpXf"
      },
      "outputs": [],
      "source": [
        "train_dataset = train_dataset.map(pack_features_vector)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NLy0Q1xCldVO"
      },
      "source": [
        "`Dataset` icindeki ozellik elemani simdi `(batch_size, num_features)` sekli olan dizilerdir. Ilk birkac ornege bakalim:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "kex9ibEek6Tr"
      },
      "outputs": [],
      "source": [
        "features, labels = next(iter(train_dataset))\n",
        "\n",
        "print(features[:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LsaVrtNM3Tx5"
      },
      "source": [
        "## Modelimizi secelim\n",
        "\n",
        "### Neden Model?\n",
        "\n",
        "*[Model](https://developers.google.com/machine-learning/crash-course/glossary#model)* ozelliklerle etiketler arasindaki etkilesimdir.  Zambak siniflandirmasi probleminde ise modelimiz tac yaprak ve canak yaprak olculeri ile tahmin edilen Zambak turleri arasindaki iliskiyi belirler. Bazi basit modeller birkac satir matematiksel islemle aciklanabilirken kompleks makine ogrenmesi modellerini aciklamak cok sayida degistirgenin bulunmasi sebebiyle cok zordur. \n",
        "\n",
        "Makine ogrenmesini kullanmadan Zambak turleri ve ozellikleri arasindaki iliskiyi kurabilir miydiniz?  Yani kosullu deyimler gibi geleneksel programlama tekniklerini kullanarak bir model olusturabilir miydiniz?  Eger verileri yeteri kadar inceleyip elimizdeki olculerle Zambak turleri arasindaki iliskiyi bulabilirseniz belki modeli olusturabilirsiniz. Bu karisik veri setlerinde neredeyse imkansiz hale gelir. Iyi bir makine ogrenmesi *modelinizi sizin yerinize olusturur*. Eger dogru makine ogrenmesi modeline dogru ornekleri verebilirseniz program sizin yerinize bu iliskiyi belirler.\n",
        "\n",
        "### Modelimizi secelim\n",
        "\n",
        "Simdi egitmek icin modelimizi secmeliyiz. Bircok model cesidi bulunur ve dogru modeli secmek deneyim gerektirir. Bu egitim sinir aglarini kullanarak Zambak siniflandirmasi problemini cozer. *[Sinir aglari](https://developers.google.com/machine-learning/glossary/#neural_network)* ozelliklerle etiketler arasindaki kompleks iliskiyi bulabilir. Bir ya da birden fazla *[sakli katmanlar (hidden layers)](https://developers.google.com/machine-learning/glossary/#hidden_layer)* seklinde organize olmus iyi yapilandirilmis bir grafiktir. Her sakli katman bir ya da birden fazla *[sinirden](https://developers.google.com/machine-learning/glossary/#neuron)* olusmustur. Bircok sinir agi kategorisi vardir ve bu program yogun (dense), ya da  *[tamamen birbirine bagli sinir agini (fully-connected neural network)](https://developers.google.com/machine-learning/glossary/#fully_connected_layer)* kullanir: bir katmandaki sinirler bir onceki katmandaki *butun* sinirlerden girdi baglantilarini alir. Asagidaki Sekil 2'de bir girdi katmani, iki sakli katman ve bir cikti katmanindan olusan yogun sinir aginin bir ornegini gorebilirsiniz:\n",
        "\n",
        "<table>\n",
        "  <tr><td>\n",
        "    <img src=\"https://www.tensorflow.org/images/custom_estimators/full_network.png\"\n",
        "         alt=\"A diagram of the network architecture: Inputs, 2 hidden layers, and outputs\">\n",
        "  </td></tr>\n",
        "  <tr><td align=\"center\">\n",
        "    <b>Sekil 2.</b> Ozellikleri, sakli katmanlari ve tahminleri olan bir sinir agi.<br/>&nbsp;\n",
        "  </td></tr>\n",
        "</table>\n",
        "\n",
        "Sekildeki modeli egitip etiketlenmemis bir ornek verdigimizde bize bu ornegin Zambak turlerinden birisi olup olmadigina yonelik bir tahmin yurutur. Bu tahmine *[cikarsama (inference)](https://developers.google.com/machine-learning/crash-course/glossary#inference)* adi verilir. Bu ornekteki ciktilarin degerlerinin toplami 1.0 idir. Sekildeki tahminler ise soyledir: *Iris setosa* icin `0.02`, *Iris versicolor* icin `0.95` ve *Iris virginica* icin `0.03`. Bu modelimizin yuzde 95 olasikla etiketsiz ornegi *Iris versicolor* olarak tahmin ettigi anlamina gelir."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "W23DIMVPQEBt"
      },
      "source": [
        "### Keras kullanarak modelimizi olusturalim \n",
        "\n",
        "TensorFlow [tf.keras](https://www.tensorflow.org/api_docs/python/tf/keras) API'si modelleri ve katmanlari olusturmak icin tavsiye edilen yontemdir. Keras her seyin birbirine baglanmasini hallederken sizin modeli olusturmaniz ve test etmeniz kolaylasir. \n",
        "\n",
        "[tf.keras.Sequential](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential) modeli dogrusal katman yiginidir. Yapicisi katman ornegi listesini alir. Ornegimizde bu liste her biri 10 dugumden olusan 2 [Yogun (Dense)](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense) katman ve etiket tahminlerini temsil eden 3 dugumden olusan bir cikti katmanini kapsar. Ilk katmanin gereken degistirgesi `input_shape`, veri setindeki ozelliklere denk gelir."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "2fZ6oL2ig3ZK"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(10, activation=tf.nn.relu, input_shape=(4,)),  # girdi sekli gereklidir \n",
        "  tf.keras.layers.Dense(10, activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dense(3)\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FHcbEzMpxbHL"
      },
      "source": [
        "*[Aktiflestirme fonksiyonu (activation function)](https://developers.google.com/machine-learning/crash-course/glossary#activation_function)* katamnada bulunan her dugumun cikti seklini belirler. Bu tur dogrusal olmayan iliskiler onemlidir cunku onlar olmadan modelimiz tek katmanli gibi davranirdi. Bircok [aktiflestirme turu](https://www.tensorflow.org/api_docs/python/tf/keras/activations) bulunur, fakat gizli tabakalar icin [ReLU](https://developers.google.com/machine-learning/crash-course/glossary#ReLU) yaygin olarak kullanilir.\n",
        "\n",
        "Sakli katmanlarin ve sinirlerin sayisi problemin turune ve veri setine gore degisir. Makine ogrenmesinin butun alanlarinda oldugu gibi bunu yapmak biraz deneyim, biraz bilgi ve biraz test etme gerektirir. Genel bir kural koymamiz gerekirse sakli katman ve sinir sayisi arttikca modelimiz genelde daha guclenir, fakat boyle bir modeli verimli sekilde egitmek icin daha cok veriye ihtiyacimiz vardir."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2wFKnhWCpDSS"
      },
      "source": [
        "### Modeli kullanalim\n",
        "\n",
        "Simdi modelimizin elimizdeki ozelliklere ne yaptigina hizlica goz atalim:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "xe6SQ5NrpB-I"
      },
      "outputs": [],
      "source": [
        "predictions = model(features)\n",
        "predictions[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wxyXOhwVr5S3"
      },
      "source": [
        "Buradaki her ornek her sinif icin bir [logit](https://developers.google.com/machine-learning/crash-course/glossary#logits) dondurur.\n",
        "\n",
        "Her sinif icin bu logitleri olasiliga donusturmek icin [softmax](https://developers.google.com/machine-learning/crash-course/glossary#softmax) fonksiyonunu kullanalim:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "_tRwHZmTNTX2"
      },
      "outputs": [],
      "source": [
        "tf.nn.softmax(predictions[:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uRZmchElo481"
      },
      "source": [
        "`tf.argmax`i siniflar arasindan gecirerek tahmin edilen sinifin dizinini bulabiliriz. Fakat, modelimiz daha egitilmedigi icin tahminler iyi degildir."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "-Jzm_GoErz8B"
      },
      "outputs": [],
      "source": [
        "print(\"Prediction: {}\".format(tf.argmax(predictions, axis=1)))\n",
        "print(\"    Labels: {}\".format(labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Vzq2E5J2QMtw"
      },
      "source": [
        "## Modeli egitelim\n",
        "\n",
        "*[Egitim](https://developers.google.com/machine-learning/crash-course/glossary#training)* makine ogrenmesi modelinin derece derece eniyilestirilmesi ya da modelin veri setini *ogrenmesi* asamasidir. Hedef egitim veri setinin yapisini iyice ogrenerek bilinmeyen veri hakkinda tahmin yapabilmektir. Eger egitim setini *cok iyi* ogrenirse tahminler sadece bu veri setinde calisacak ve genelestirilemez olacaktir. Bu probleme *[asiri uyum (overfitting)](https://developers.google.com/machine-learning/crash-course/glossary#overfitting)* adi verilir—bu tipki sorunun cozumunu anlamak yerine cevaplari ezberlemeye benzer.\n",
        "\n",
        "Zambak siniflandirmasi problemi *[gozetimli makine ogrenmesi](https://developers.google.com/machine-learning/glossary/#supervised_machine_learning)* ornegidir: model etiketleri olan orneklerle egitilir. *[Gozetimsiz makine ogrenmesinde](https://developers.google.com/machine-learning/glossary/#unsupervised_machine_learning)* ise, orneklerin etiketleri yoktur. Etiket yerine model ozellikler arasindaki deseni bulmaya calisir."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RaKp8aEjKX6B"
      },
      "source": [
        "### Kayip ve egim fonksiyonlarini tanimlayalim\n",
        "\n",
        "Egitim ve degerlendirme asamalari modelin *[kaybini](https://developers.google.com/machine-learning/crash-course/glossary#loss)* hesaplamalidir. Bu modelin tahminlerinin istenen etiketlerle farkini yani modelin ne kadar kotu calistigini hesaplar. Bu degeri kucultmeyi ve eniyilestirmeyi isteriz.\n",
        "\n",
        "Modelimiz [tf.keras.losses.categorical_crossentropy](https://www.tensorflow.org/api_docs/python/tf/losses/sparse_softmax_cross_entropy) fonksiyonu ile kaybi hesaplar. Bu fonksiyon modelin sinif tahminlerini ve istenen etiketleri alir ve butun orneklerin kayip degerlerinin ortalamasini dondurur."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "tMAT4DcMPwI-"
      },
      "outputs": [],
      "source": [
        "def loss(model, x, y):\n",
        "  y_ = model(x)\n",
        "  return tf.losses.sparse_softmax_cross_entropy(labels=y, logits=y_)\n",
        "\n",
        "\n",
        "l = loss(model, features, labels)\n",
        "print(\"Loss test: {}\".format(l))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3IcPqA24QM6B"
      },
      "source": [
        "[tf.GradientTape](https://www.tensorflow.org/api_docs/python/tf/GradientTape) kapsamini kullanarak modelimizi eniyilestirecek olan *[egimleri](https://developers.google.com/machine-learning/crash-course/glossary#gradient)* hesaplayabiliriz. Bu konuda daha cok ornek icin eager modu kitapcigina [buradan bakabilirsiniz](https://www.tensorflow.org/r1/guide/eager)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "x57HcKWhKkei"
      },
      "outputs": [],
      "source": [
        "def grad(model, inputs, targets):\n",
        "  with tf.GradientTape() as tape:\n",
        "    loss_value = loss(model, inputs, targets)\n",
        "  return loss_value, tape.gradient(loss_value, model.trainable_variables)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lOxFimtlKruu"
      },
      "source": [
        "### Eniyilestirici (optimizer) olusturalim\n",
        "\n",
        "*[Eniyilestirici](https://developers.google.com/machine-learning/crash-course/glossary#optimizer)* kayip fonkiyonunu en aza indirgemek icin hesaplanan egim degerlerini modelin degiskenlerine uygular. Kayip fonksiyonunu kivrimli bir yuzey olarak dusunebilirsini (Sekil 3) ve biz bu seklin en dusuk noktasini uzerinden gecerek bulmak istiyoruz. Egimler bizi en dik tirmanislara yonlendirir, bu yuzden biz ters yone dogru giderek tepeden asagiya hareket edecegiz. Her grup (batch) icin kayip ve egim degerlerini etkilesimli olarak hesaplayip egitim sirasinda modelimizi ayarlayacagiz. Modelimiz kaybi dusurmek icin yavas yavas agirliklar ve sapmalarin en iyi birlesimini bulacaktir. Kayip degeri ne kadar dusuk olursa modelimizin tahminleri o kadar iyi olur.\n",
        "\n",
        "<table>\n",
        "  <tr><td>\n",
        "    <img src=\"https://cs231n.github.io/assets/nn3/opt1.gif\" width=\"70%\"\n",
        "         alt=\"Optimization algorithms visualized over time in 3D space.\">\n",
        "  </td></tr>\n",
        "  <tr><td align=\"center\">\n",
        "    <b>Sekil 3.</b> Eniyilestirme algoritmalarinin zamanla 3D duzlemde goruntulenmesi.<br/>(Kaynak: <a href=\"http://cs231n.github.io/neural-networks-3/\">Stanford class CS231n</a>, MIT License, Goruntu: <a href=\"https://twitter.com/alecrad\">Alec Radford</a>)\n",
        "  </td></tr>\n",
        "</table>\n",
        "\n",
        "TensorFlow'un egitim icin bircok [eniyilestirme algoritmasi](https://www.tensorflow.org/api_guides/python/train) bulunmaktadir. Burada *[stochastic gradient descent](https://developers.google.com/machine-learning/crash-course/glossary#gradient_descent)* (SGD) algoritmasini gerceklestiren [tf.train.GradientDescentOptimizer](https://www.tensorflow.org/api_docs/python/tf/train/GradientDescentOptimizer) kullaniyoruz. `learning_rate` degeri her yinelemede basamak degerini asagi ceker. Bu daha iyi sonuc almak icin degistireceginiz bir *hyperparameter* idir."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XkUd6UiZa_dF"
      },
      "source": [
        "Eniyilestiriciyi (optimizer) ve `global_step` sayacini kuralim:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "8xxi2NNGKwG_"
      },
      "outputs": [],
      "source": [
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
        "\n",
        "global_step = tf.Variable(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pJVRZ0hP52ZB"
      },
      "source": [
        "Bunu bir eniyilestirme basamagini hesaplamak icin kullanacagiz:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "rxRNTFVe56RG"
      },
      "outputs": [],
      "source": [
        "loss_value, grads = grad(model, features, labels)\n",
        "\n",
        "print(\"Step: {}, Initial Loss: {}\".format(global_step.numpy(),\n",
        "                                          loss_value.numpy()))\n",
        "\n",
        "optimizer.apply_gradients(zip(grads, model.trainable_variables), global_step)\n",
        "\n",
        "print(\"Step: {},         Loss: {}\".format(global_step.numpy(),\n",
        "                                          loss(model, features, labels).numpy()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7Y2VSELvwAvW"
      },
      "source": [
        "### Egitim dongusu\n",
        "\n",
        "Butun parcalar yerine geldigine gore modelimizi egitebiliriz! Egitim dongusu veri setindeki ornekleri modelimize vererek daha iyi tahminde bulunmasini saglar. Asagida egitim basamaklarini gorebilirsiniz:\n",
        "\n",
        "1. Her *devri(epoch)* yineleyelim. Bir devir veri setinin ustunden bir kere gecmek anlamina gelir.\n",
        "2. Her devirde egitim veri setindeki (Dataset) ornekleri tek tek yineleyerek *ozelliklerini* (`x`) ve *etiketlerini* (`y`) yakalayalim.\n",
        "3. Ornegin ozelliklerini kullanarak bir tahminde bulunalim ve bunu etiket ile karsilastiralim. Tahminin hatasini hesaplayalim ve bu degeri modelin kaybini ve egimini bulmak icin kullanalim.\n",
        "4. Bir `eniyiseltirici (optimizer)` kullanarak modelin degiskenlerini guncelleyelim.\n",
        "5. Bazi istatiksel degerlerini daha sonra goruntulemek icin takip edelim.\n",
        "6. Her devir icin tekrarlayalim.\n",
        "\n",
        "`num_epochs` degiskeni veri setinin ustunden kac dongu gececegini belirler. Bu icgudulerimize ters gelse de modeli daha uzun egitmek daha iyi bir model elde edecegimiz anlamina gelmez. `num_epochs` ayarlacabileceginiz bir *[hyperparameter](https://developers.google.com/machine-learning/glossary/#hyperparameter)*'dir. Dogru devir sayisini secmek hem deneyim hem de test etmeyi gerektirir."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "AIgulGRUhpto"
      },
      "outputs": [],
      "source": [
        "## Not: Bu hucreyi tekrar calistirinca ayni model degiskenleri kullanilir \n",
        "\n",
        "from tensorflow import contrib\n",
        "tfe = contrib.eager\n",
        "\n",
        "# sonuclari ileride goruntulemek icin tutalim\n",
        "train_loss_results = []\n",
        "train_accuracy_results = []\n",
        "\n",
        "num_epochs = 201\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  epoch_loss_avg = tfe.metrics.Mean()\n",
        "  epoch_accuracy = tfe.metrics.Accuracy()\n",
        "\n",
        "  # Egitim dongusu - 32ser topluluk kullanarak \n",
        "  for x, y in train_dataset:\n",
        "    # Modeli eniyilestireliml\n",
        "    loss_value, grads = grad(model, x, y)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_variables),\n",
        "                              global_step)\n",
        "\n",
        "    # Ilerlemeyi takip edelim \n",
        "    epoch_loss_avg(loss_value)  # su anki topluluk kaybini ekleyelim\n",
        "    # tahmin edilen etiketle asil etiketi karsilastir\n",
        "    epoch_accuracy(tf.argmax(model(x), axis=1, output_type=tf.int32), y)\n",
        "\n",
        "  # devri bitirelim\n",
        "  train_loss_results.append(epoch_loss_avg.result())\n",
        "  train_accuracy_results.append(epoch_accuracy.result())\n",
        "\n",
        "  if epoch % 50 == 0:\n",
        "    print(\"Epoch {:03d}: Loss: {:.3f}, Accuracy: {:.3%}\".format(epoch,\n",
        "                                                                epoch_loss_avg.result(),\n",
        "                                                                epoch_accuracy.result()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2FQHVUnm_rjw"
      },
      "source": [
        "### Kayip fonksiyonunun zaman icinde degisimi goruntuleyelim "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "j3wdbmtLVTyr"
      },
      "source": [
        "Modelin egitim surecini yazdirmak yardimci olsa da bu sureci gorebilmek *daha* da faydalidir. [TensorBoard](https://www.tensorflow.org/r1/guide/summaries_and_tensorboard), TensorFlow ile gelen guzel bir goruntuleme aracidir, fakat basit cizimleri `matplotlib` birimi ile de yapabiliriz.\n",
        "\n",
        "Bu cizimleri yorumlamak biraz deneyim gerektirir, fakat asil gormek istedigimiz sey *kayip* degerinin dusmesi ve *dogruluk* degerinin yukselmesidir."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "agjvNd2iUGFn"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(2, sharex=True, figsize=(12, 8))\n",
        "fig.suptitle('Training Metrics')\n",
        "\n",
        "axes[0].set_ylabel(\"Loss\", fontsize=14)\n",
        "axes[0].plot(train_loss_results)\n",
        "\n",
        "axes[1].set_ylabel(\"Accuracy\", fontsize=14)\n",
        "axes[1].set_xlabel(\"Epoch\", fontsize=14)\n",
        "axes[1].plot(train_accuracy_results)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Zg8GoMZhLpGH"
      },
      "source": [
        "## Modelin ne kadar etkili oldugunu degerlendirelim\n",
        "\n",
        "Modelimizi egittigimize gore basarimi ustune istatistikleri alabiliriz.\n",
        "\n",
        "*Degerlendirme* modelin tahminlerini ne kadar etkili yaptiginin belirlenmesi anlamina gelir. Zambak siniflandirmasinda modelin etkililigini belirlemek icin birkac canak yaprak ve tac yaprak olculerini modelimize verelim ve modelimize bunlarin hangi ture ait oldugunu tahmin etmesini soralim. Sonra modelin tahmini ile asil etiketi karsilastiralim. Ornegin, girdinin yarisinda dogru tahminde bulunan bir modelin *[dogruluk degeri](https://developers.google.com/machine-learning/glossary/#accuracy)* `0.5` idir. Sekil 4'te 5 tahminden 4'unu tutturarak yuzde 80 dogruluk degerine sahip biraz daha etkili bir modeli gorebilirsiniz:\n",
        "\n",
        "<table cellpadding=\"8\" border=\"0\">\n",
        "  <colgroup>\n",
        "    <col span=\"4\" >\n",
        "    <col span=\"1\" bgcolor=\"lightblue\">\n",
        "    <col span=\"1\" bgcolor=\"lightgreen\">\n",
        "  </colgroup>\n",
        "  <tr bgcolor=\"lightgray\">\n",
        "    <th colspan=\"4\">Example features</th>\n",
        "    <th colspan=\"1\">Label</th>\n",
        "    <th colspan=\"1\" >Model prediction</th>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>5.9</td><td>3.0</td><td>4.3</td><td>1.5</td><td align=\"center\">1</td><td align=\"center\">1</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>6.9</td><td>3.1</td><td>5.4</td><td>2.1</td><td align=\"center\">2</td><td align=\"center\">2</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>5.1</td><td>3.3</td><td>1.7</td><td>0.5</td><td align=\"center\">0</td><td align=\"center\">0</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>6.0</td> <td>3.4</td> <td>4.5</td> <td>1.6</td> <td align=\"center\">1</td><td align=\"center\" bgcolor=\"red\">2</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>5.5</td><td>2.5</td><td>4.0</td><td>1.3</td><td align=\"center\">1</td><td align=\"center\">1</td>\n",
        "  </tr>\n",
        "  <tr><td align=\"center\" colspan=\"6\">\n",
        "    <b>Sekil 4.</b> Yuzde 80 dogruluk degeri olan bir Zambak siniflandiricisi.<br/>&nbsp;\n",
        "  </td></tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "z-EvK7hGL0d8"
      },
      "source": [
        "### Test veri setini olusturalim\n",
        "\n",
        "Modelin degerlendirilmesi modelin egitilmesine benzer. En buyuk fark orneklerin egitim setinden farkli bir *[test setinden](https://developers.google.com/machine-learning/crash-course/glossary#test_set)* gelmesidir. Modelin etkililigini adil sekilde degerlendirebilmek icin test orneklerinin egitim orneklerinden farkli olmasi gerekmektedir.\n",
        "\n",
        "Test `Dataset` ile egitim `Dataset`nin kurulumu birbirine benzer. CSV metin dosyasini indirelim ve degerleri ayristiralim, sonra da siralarini karistiralim:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Ps3_9dJ3Lodk"
      },
      "outputs": [],
      "source": [
        "test_url = \"https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\"\n",
        "\n",
        "test_fp = tf.keras.utils.get_file(fname=os.path.basename(test_url),\n",
        "                                  origin=test_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "SRMWCu30bnxH"
      },
      "outputs": [],
      "source": [
        "test_dataset = tf.contrib.data.make_csv_dataset(\n",
        "    test_fp,\n",
        "    batch_size,\n",
        "    column_names=column_names,\n",
        "    label_name='species',\n",
        "    num_epochs=1,\n",
        "    shuffle=False)\n",
        "\n",
        "test_dataset = test_dataset.map(pack_features_vector)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HFuOKXJdMAdm"
      },
      "source": [
        "### Modeli test veri setinde degerlendirelim\n",
        "\n",
        "Egitim asamasindan farkli olarak, model test verisinin sadece tek bir [devrini](https://developers.google.com/machine-learning/glossary/#epoch) degerlendirir. Asagidaki kod hucresinde test setindeki her ornegi yineleyerek modelin tahmini ile asil etiketi karsilastiriyoruz. Boylece modelin dogrulugunu butun test setinde olcmus olacagiz."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Tw03-MK1cYId"
      },
      "outputs": [],
      "source": [
        "test_accuracy = tfe.metrics.Accuracy()\n",
        "\n",
        "for (x, y) in test_dataset:\n",
        "  logits = model(x)\n",
        "  prediction = tf.argmax(logits, axis=1, output_type=tf.int32)\n",
        "  test_accuracy(prediction, y)\n",
        "\n",
        "print(\"Test set accuracy: {:.3%}\".format(test_accuracy.result()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HcKEZMtCOeK-"
      },
      "source": [
        "Ornegin son topluluktaki degere bakarak modelin genelde dogru oldugunu gorebiliriz:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "uNwt2eMeOane"
      },
      "outputs": [],
      "source": [
        "tf.stack([y,prediction],axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7Li2r1tYvW7S"
      },
      "source": [
        "## Egitilen modeli tahminde bulunmak icin kullanalim\n",
        "\n",
        "Bir modeli egittik ve Zambak turlerini siniflandirma da mukemmel olmasa da iyi oldugunu \"kanitladik\". Simdi bu modeli [etiketsiz ornekler](https://developers.google.com/machine-learning/glossary/#unlabeled_example), yani ozellikleri bulunan ama etiketleri olmayan ornekler, ustunde tahmin yurutmek icin kullanalim.\n",
        "\n",
        "Gercek hayatta, etiketsiz ornekler aplikasyonlar, CSV metinleri, ve veri besleyiciler gibi bircok farkli kaynaktan gelebilir. Simdilik biz tahmin yurutmek icin etiketsiz ornekleri kendimiz verecegiz. Hatirlarsaniz, etiket rakamlarini su sekilde isimlerle eslemistik:\n",
        "\n",
        "* `0`: Iris setosa\n",
        "* `1`: Iris versicolor\n",
        "* `2`: Iris virginica"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "kesTS5Lzv-M2"
      },
      "outputs": [],
      "source": [
        "predict_dataset = tf.convert_to_tensor([\n",
        "    [5.1, 3.3, 1.7, 0.5,],\n",
        "    [5.9, 3.0, 4.2, 1.5,],\n",
        "    [6.9, 3.1, 5.4, 2.1]\n",
        "])\n",
        "\n",
        "predictions = model(predict_dataset)\n",
        "\n",
        "for i, logits in enumerate(predictions):\n",
        "  class_idx = tf.argmax(logits).numpy()\n",
        "  p = tf.nn.softmax(logits)[class_idx]\n",
        "  name = class_names[class_idx]\n",
        "  print(\"Example {} prediction: {} ({:4.1f}%)\".format(i, name, 100*p))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "custom_training_walkthrough.ipynb",
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "version": "0.3.2"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
