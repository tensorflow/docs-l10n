{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copia de migration_guide.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wJcYs_ERTnnI"
      },
      "source": [
        "##### Copyright 2018 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "colab_type": "code",
        "id": "HMUDt0CiUJk9",
        "colab": {}
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "77z2OchJTk0l"
      },
      "source": [
        "# Convierta su código existente a TensorFlow 2.0\n",
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/guide/migration_guide\">\n",
        "    <img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />\n",
        "    Ver en TensorFlow.org</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/guide/migration_guide.ipynb\">\n",
        "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />\n",
        "    Correr en Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/guide/migration_guide.ipynb\">\n",
        "    <img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />\n",
        "    Ver codigo on GitHub</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/guide/migration_guide.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Descargar notebook</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BJo1CBvi0uc",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Note: Nuestra comunidad de Tensorflow ha traducido estos documentos. Como las traducciones de la comunidad son basados en el \"mejor esfuerzo\", no hay ninguna garantia que esta sea un reflejo preciso y actual de la Documentacion Oficial en Ingles. Si tienen sugerencias sobre como mejorar esta traduccion, por favor envian un \"Pull request\" al siguiente repositorio tensorflow/docs. Para ofrecerse como voluntario o hacer revision de las traducciones de la Comunidad por favor contacten al siguiente grupo docs@tensorflow.org list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "meUTrR4I6m1C"
      },
      "source": [
        "Importante: este documento es para usuarios de bajo nivel de la API de TensorFlow . Si esta utilizando la API de alto nivel (`tf.keras`) puede que haya poca o ninguna acción que deba tomar para que su código sea totalmente compatible con TensorFlow 2.0. Verifique su [tasa de aprendizaje predeterminada del optimizer](keras_optimizer_lr)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "C0V10enS1_WU"
      },
      "source": [
        "Es posible ejecutar código 1.X sin modificar ([excepto para contrib](https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md)), en TensorFlow 2.0 :\n",
        "\n",
        "```\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "```\n",
        "\n",
        "Sin embargo, esto no le permite aprovechar muchas de las mejoras realizadas en TensorFlow 2.0. Esta guia lo ayudara a actualizar su codigo, haciendolo mas simple, mas eficiente y mas facil de mantener."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GUp_x0bOgaac"
      },
      "source": [
        "## Script de conversion automatica\n",
        "\n",
        "El primer paso, antes de intentar implementar los cambios descritos en este documento, es intentar ejecutar el [script de actualización](./upgrade.md).\n",
        "\n",
        "Esto hara un paso inicial al actualizar su codigo a TensorFlow 2.0. Pero no puede hacer que su codigo sea idiomatico para 2.0. Su codigo aun puede utilizar los endpoints de `tf.compat.v1` para acceder a marcadores de posicion, sesiones, colecciones y otras funciones de estilo 1.x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0w5LiSYsy1mh"
      },
      "source": [
        "## Cambios de comportamiento de nivel superior\n",
        "\n",
        "Si su codigo funciona en TensorFlow 2.0 usando `tf.compat.v1.disable_v2_behavior()`, todavia hay cambios de comportamiento globales que puede necesitar modificar. Los principales cambios son:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1y-W0Mz_zB6Y"
      },
      "source": [
        "* *Eager execution, `v1.enable_eager_execution()`*: Cualquier codigo que implicitamente use un `tf.Graph` fallara. Asegurese de ajustar este codigo en un contexto `with tf.Graph(). as_default()`.\n",
        "    \n",
        "* *Variables de recursos, `v1.enable_resource_variables()`*: Algunos codigos pueden depender de comportamientos no deterministas habilitados por las variables de referencia TF.\n",
        "Las variables de recursos se bloquean durante la escritura y, por lo tanto, proporcionan garantias de coherencia mas intuitivas.\n",
        "\n",
        "  * Puede cambiar el comportamiento en casos extremos.\n",
        "  * Puede crear copias adicionales y puede tener un mayor uso de memoria.\n",
        "  * Se puede deshabilitar pasando `use_resource = False` al constructor` tf.Variable`.\n",
        "\n",
        "* *Tensor Shapes, `v1.enable_v2_tensorshape()`* : TF 2.0 simplifica el comportamiento de las Tensor Shapes. En lugar de `t.shape[0].value` puede usar ` t.shape[0]`. Estos cambios deben ser pequeños y tiene sentido solucionarlos de inmediato. Consulte [TensorShape](#tensorshape) para ver ejemplos.\n",
        "\n",
        "* *Control de Flujo, `v1.enable_control_flow_v2()`*: La implementacion del control de flujo TF 2.0 se ha simplificado y, por lo tanto, produce diferentes representaciones graficas. Por favor, [reporte bugs](https://github.com/tensorflow/tensorflow/issues) si se presenta cualquier problema."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_Ni9zLLvwcOR"
      },
      "source": [
        "## Hacer el codigo 2.0-nativo\n",
        "\n",
        "\n",
        "Esta guia le mostrara varios ejemplos de conversión de codigo TensorFlow 1.x a TensorFlow 2.0. Estos cambios permitiran que su codigo aproveche las optimizaciones de rendimiento y las llamadas API simplificadas.\n",
        "\n",
        "En cada caso, el patron es:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uP0O8Pc45LNs"
      },
      "source": [
        "### 1. Remplaza las llamadas `v1.Session.run`\n",
        "\n",
        "\n",
        "Cada llamada `v1.Session.run` debe ser reemplazada por una funcion Python.\n",
        "\n",
        "* Los `feed_dict` y` v1.placeholder`s se convierten en argumentos de funcion.\n",
        "* Los 'fetches' se convierten en el valor de retorno de la funcion.\n",
        "* Durante la conversion, la eager execution permite una depuracion facil con herramientas estandar de Python como `pdb`.\n",
        "\n",
        "Despues de eso, agrega un decorador `tf.function` para que funcione de manera eficiente en el grafico. Consulta la [Guía de autografos](autograph.ipynb) para obtener mas informacion sobre como funciona.\n",
        "\n",
        "Ten en cuenta que:\n",
        "\n",
        "* A diferencia de `v1.Session.run`, una` tf.function` tiene una firma de devolucion fija y siempre devuelve todas las salidas. Si esto causa problemas de rendimiento, crea dos funciones separadas.\n",
        "\n",
        "* No hay necesidad de un `tf.control_dependencies` u operaciones similares: una` tf.function` se comporta como si se ejecutara en el orden escrito. Las asignaciones `tf.Variable` y` tf.assert`s, por ejemplo, se ejecutan automaticamente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jlBOqROL5NmN"
      },
      "source": [
        "### 2. Utiliza objetos Python para rastrear variables y perdidas\n",
        "\n",
        "Todo el seguimiento de variables basado en nombres se desaconseja en TF 2.0. Utiliza objetos Python para rastrear variables.\n",
        "\n",
        "Utiliza `tf.Variable` en lugar de `v1.get_variable`.\n",
        "\n",
        "Cada `v1.variable_scope` debe convertirse en un objeto Python. Por lo general, este sera uno de la siguiente lista:\n",
        "\n",
        "* `tf.keras.layers.Layer`\n",
        "* `tf.keras.Model`\n",
        "* `tf.Module`\n",
        "\n",
        "Si necesitas agregar listas de variables (como `tf.Graph.get_collection(tf.GraphKeys.VARIABLES)`), usa los atributos `.variables` y`.trainable_variables` de los objetos `Layer` y` Model`.\n",
        "\n",
        "Las clases `Layer` y` Model` implementan varias propiedades que eliminan la necesidad de colecciones globales. Tu propiedad `.losses` puede ser un reemplazo para usar la coleccion `tf.GraphKeys.LOSSES`.\n",
        "\n",
        "Consulta las [guías de keras](keras.ipynb) para obtener mas detalles.\n",
        "\n",
        "Advertencia: Muchos simbolos `tf.compat.v1` usan las colecciones globales implicitamente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rGFhBzoF5FIq"
      },
      "source": [
        "### 3. Actualiza tus ciclos de entrenamiento\n",
        "\n",
        "Usa la API de nivel mas alto que funcione para tu caso. Prefiere `tf.keras.Model.fit` en lugar de construir tus propios ciclos de entrenamiento.\n",
        "\n",
        "Estas funciones de alto nivel manejan muchos de los detalles de bajo nivel que podrian ser faciles de perder si escribes tu propio ciclo de entrenamiento. Por ejemplo, recopilan automaticamente las perdidas de regularizacion y establecen el argumento `training = True` cuando llaman al modelo.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oaY37_6L4la5"
      },
      "source": [
        "### 4. Actualiza tus fuentes de entrada de datos\n",
        "\n",
        "Utiliza los datasets `tf.data`  para la entrada de datos. Estos objetos son eficientes, expresivos y se integran bien con tensorflow.\n",
        "\n",
        "Se pueden pasar directamente al metodo `tf.keras.Model.fit`.\n",
        "\n",
        "\n",
        "```\n",
        "model.fit(dataset, epochs=5)\n",
        "```\n",
        "\n",
        "Se pueden iterar directamente sobre Python estandar:\n",
        "\n",
        "```\n",
        "for example_batch, label_batch in dataset:\n",
        "    break\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_Mwsd0SK4oIs"
      },
      "source": [
        "#### 5. Migra los simbolos de `compat.v1` \n",
        "\n",
        "El modulo `tf.compat.v1` contiene la API completa de TensorFlow 1.x, con su semantica original.\n",
        "\n",
        "El [script de actualización TF2](upgrade.ipynb) convertira simbolos a sus equivalentes 2.0 si dicha conversion es segura, es decir, si puede determinar que el comportamiento de la versión 2.0 es exactamente equivalente (por ejemplo, cambiara el nombre de 'v1 .arg_max` a `tf.argmax`, ya que son la misma funcion).\n",
        "\n",
        "Después de que el script de actualizacion se ejecute en un fragmento de codigo, es probable que haya muchas menciones de `compat.v1`. Vale la pena revisar el codigo y convertirlos manualmente al equivalente 2.0 (deberia mencionarse en el registro si hay uno)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "X_ilfTGJ4Yml"
      },
      "source": [
        "## Convirtiendo modelos\n",
        "\n",
        "### Instalacion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bad2N-Z115W1",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "try:\n",
        "  # %tensorflow_version solo existe en Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "import tensorflow_datasets as tfds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FB99sqHX2Q5m"
      },
      "source": [
        "### Variables de bajo nivel y ejecucion del operador\n",
        "\n",
        "Ejemplos del uso de la API de bajo nivel incluyen:\n",
        "\n",
        "* Usando ambitos de variables para controlar la reutilizacion\n",
        "* Creando variables con `v1.get_variable`.\n",
        "* Accediendo a colecciones explicitamente\n",
        "* Accediendo a colecciones implicitamente con metodos como:\n",
        "\n",
        "   * `v1.global_variables`\n",
        "   * `v1.losses.get_regularization_loss`\n",
        "\n",
        "* Usando `v1.placeholder` para configurar entradas de graficos\n",
        "* Ejecutando de graficos con `Session.run`\n",
        "* Inicializando variables manualmente\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "e582IjyF2eje"
      },
      "source": [
        "#### Antes de convertir\n",
        "\n",
        "\n",
        "Asi es como estos patrones pueden verse en el codigo utilizando TensorFlow 1.x.\n",
        "\n",
        "\n",
        "```python\n",
        "in_a = tf.placeholder(dtype=tf.float32, shape=(2))\n",
        "in_b = tf.placeholder(dtype=tf.float32, shape=(2))\n",
        "\n",
        "def forward(x):\n",
        "  with tf.variable_scope(\"matmul\", reuse=tf.AUTO_REUSE):\n",
        "    W = tf.get_variable(\"W\", initializer=tf.ones(shape=(2,2)),\n",
        "                        regularizer=tf.contrib.layers.l2_regularizer(0.04))\n",
        "    b = tf.get_variable(\"b\", initializer=tf.zeros(shape=(2)))\n",
        "    return W * x + b\n",
        "\n",
        "out_a = forward(in_a)\n",
        "out_b = forward(in_b)\n",
        "\n",
        "reg_loss = tf.losses.get_regularization_loss(scope=\"matmul\")\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  outs = sess.run([out_a, out_b, reg_loss],\n",
        "      \t        feed_dict={in_a: [1, 0], in_b: [0, 1]})\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QARwz4Xd2lc2"
      },
      "source": [
        "#### Despues de convertir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "x0AVzBFRBPcU"
      },
      "source": [
        "En el codigo convertido:\n",
        "\n",
        "* Las variables son objetos locales de Python.\n",
        "* La funcion `forward` sigue definiendo el calculo.\n",
        "* La llamada  a `Session.run` se reemplaza con una llamada a la funcion `forward`\n",
        "* El decorador opcional `tf.function` se puede agregar para aumentar el rendimiento.\n",
        "* Las regularizaciones se calculan manualmente, sin hacer referencia a ninguna coleccion global.\n",
        "* **No hay sesiones ni placeholders**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lXEZoLMP2cWJ",
        "colab": {}
      },
      "source": [
        "W = tf.Variable(tf.ones(shape=(2,2)), name=\"W\")\n",
        "b = tf.Variable(tf.zeros(shape=(2)), name=\"b\")\n",
        "\n",
        "@tf.function\n",
        "def forward(x):\n",
        "  return W * x + b\n",
        "\n",
        "out_a = forward([1,0])\n",
        "print(out_a)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YmE96A_1jZTg",
        "colab": {}
      },
      "source": [
        "out_b = forward([0,1])\n",
        "\n",
        "regularizer = tf.keras.regularizers.l2(0.04)\n",
        "reg_loss = regularizer(W)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ycDxY9nL268-"
      },
      "source": [
        "### Modelos basados en `tf.layers`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "K-bIk7wL48U7"
      },
      "source": [
        "\n",
        "El modulo `v1.layers` se utiliza para contener funciones de capa que se basan en `v1.variable_scope` para definir y reutilizar variables."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8I_qKpT73KyM"
      },
      "source": [
        "#### Antes de convertir\n",
        "```python\n",
        "def model(x, training, scope='model'):\n",
        "  with tf.variable_scope(scope, reuse=tf.AUTO_REUSE):\n",
        "    x = tf.layers.conv2d(x, 32, 3, activation=tf.nn.relu,\n",
        "          kernel_regularizer=tf.contrib.layers.l2_regularizer(0.04))\n",
        "    x = tf.layers.max_pooling2d(x, (2, 2), 1)\n",
        "    x = tf.layers.flatten(x)\n",
        "    x = tf.layers.dropout(x, 0.1, training=training)\n",
        "    x = tf.layers.dense(x, 64, activation=tf.nn.relu)\n",
        "    x = tf.layers.batch_normalization(x, training=training)\n",
        "    x = tf.layers.dense(x, 10, activation=tf.nn.softmax)\n",
        "    return x\n",
        "\n",
        "train_out = model(train_data, training=True)\n",
        "test_out = model(test_data, training=False)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "b8_Ii7CQ3fK-"
      },
      "source": [
        "#### Despues de convertir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BsAseSMfB9XN"
      },
      "source": [
        "* La pila simple de capas encaja perfectamente en `tf.keras.Sequential`. (Para modelos más complejos, consulte [capas y modelos personalizados](keras/custom_layers_and_models.ipynb) y [la API funcional](keras/functional.ipynb)).\n",
        "* El modelo rastrea las variables y las perdidas de regularizacion.\n",
        "* La conversion fue uno a uno porque hay una asignacion directa de `v1.layers` a` tf.keras.layers`.\n",
        "\n",
        "La mayoria de los argumentos permanecieron igual. Pero note las diferencias:\n",
        "\n",
        "* El argumento `training` se pasa a cada capa por el modelo cuando se ejecuta.\n",
        "* El primer argumento de la funcion original `model` (la entrada` x`) desaparecio. Esto se debe a que las capas de objetos separan la construccion del modelo de la llamada del modelo.\n",
        "\n",
        "\n",
        "Tambien ten en cuenta que:\n",
        "\n",
        "* Si estabas utilizando regularizadores de inicializadores de `tf.contrib`, estos tienen mas cambios de argumento que otros.\n",
        "* El codigo ya no se escribe en las colecciones, por lo que funciones como `v1.losses.get_regularization_loss` ya no devolveran estos valores, lo que podria romper sus ciclos de entrenamiento."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DLAPORrN3lct",
        "colab": {}
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, 3, activation='relu',\n",
        "                           kernel_regularizer=tf.keras.regularizers.l2(0.04),\n",
        "                           input_shape=(28, 28, 1)),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dropout(0.1),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "train_data = tf.ones(shape=(1, 28, 28, 1))\n",
        "test_data = tf.ones(shape=(1, 28, 28, 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6nWh6IXvkMKv",
        "colab": {}
      },
      "source": [
        "train_out = model(train_data, training=True)\n",
        "print(train_out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YnAdIDLlj3go",
        "colab": {}
      },
      "source": [
        "test_out = model(test_data, training=False)\n",
        "print(test_out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sAgqwCJBMx_x",
        "colab": {}
      },
      "source": [
        "# Aqui estan todas las variables de entrenamiento.\n",
        "len(model.trainable_variables)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uX6knaYMNM8p",
        "colab": {}
      },
      "source": [
        "# Aqui esta la perdida de regularizacion\n",
        "model.losses"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9moqw5E_4Cwl"
      },
      "source": [
        "### Variables combinadas & `v1.layers`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "80DEsImmq6VX"
      },
      "source": [
        "El codigo existente a menudo mezcla variables y operaciones TF 1.x de nivel inferior con `v1.layers` de nivel superior."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oZe9L6RR4OcP"
      },
      "source": [
        "#### Antes de convetir\n",
        "```python\n",
        "def model(x, training, scope='model'):\n",
        "  with tf.variable_scope(scope, reuse=tf.AUTO_REUSE):\n",
        "    W = tf.get_variable(\n",
        "      \"W\", dtype=tf.float32,\n",
        "      initializer=tf.ones(shape=x.shape),\n",
        "      regularizer=tf.contrib.layers.l2_regularizer(0.04),\n",
        "      trainable=True)\n",
        "    if training:\n",
        "      x = x + W\n",
        "    else:\n",
        "      x = x + W * 0.5\n",
        "    x = tf.layers.conv2d(x, 32, 3, activation=tf.nn.relu)\n",
        "    x = tf.layers.max_pooling2d(x, (2, 2), 1)\n",
        "    x = tf.layers.flatten(x)\n",
        "    return x\n",
        "\n",
        "train_out = model(train_data, training=True)\n",
        "test_out = model(test_data, training=False)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "y6ORX7cD4TkD"
      },
      "source": [
        "#### Despues de convertir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2BaRwog5CBpz"
      },
      "source": [
        "Para convertir este codigo, sigue el patron de asignacion de capas a capas como en el ejemplo anterior.\n",
        "\n",
        "Un `v1.variable_scope` es efectivamente una capa propia. Asi que reescribalo como un `tf.keras.layers.Layer`. Ver [la guia](keras/custom_layers_and_models.ipynb) para mas detalles.\n",
        "\n",
        "El patron general es:\n",
        "\n",
        "* Recopila parametros de capa en `__init__`.\n",
        "* Construue las variables en `build`.\n",
        "* Ejecuta los calculos en `call` y devuelva el resultado.\n",
        "\n",
        "El `v1.variable_scope` es esencialmente una capa propia. Asi que reescribelo como un `tf.keras.layers.Layer`. Ver [la guia](keras/custom_layers_and_models.ipynb) para mas detalles."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YcCAjNuP4NVh",
        "colab": {}
      },
      "source": [
        "# Crea una capa personalizada para parte del modelo.\n",
        "class CustomLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self, *args, **kwargs):\n",
        "    super(CustomLayer, self).__init__(*args, **kwargs)\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    self.w = self.add_weight(\n",
        "        shape=input_shape[1:],\n",
        "        dtype=tf.float32,\n",
        "        initializer=tf.keras.initializers.ones(),\n",
        "        regularizer=tf.keras.regularizers.l2(0.02),\n",
        "        trainable=True)\n",
        "\n",
        "  # El metodo de llamada a veces se usara en modo grafico,\n",
        "  # el entrenamiento se convertira en un tensor\n",
        "  @tf.function\n",
        "  def call(self, inputs, training=None):\n",
        "    if training:\n",
        "      return inputs + self.w\n",
        "    else:\n",
        "      return inputs + self.w * 0.5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dR_QO6_wBgMm",
        "colab": {}
      },
      "source": [
        "custom_layer = CustomLayer()\n",
        "print(custom_layer([1]).numpy())\n",
        "print(custom_layer([1], training=True).numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VzqaIf4E42oY",
        "colab": {}
      },
      "source": [
        "train_data = tf.ones(shape=(1, 28, 28, 1))\n",
        "test_data = tf.ones(shape=(1, 28, 28, 1))\n",
        "\n",
        "\n",
        "# Construye el modelo incluyendo la capa personalizada\n",
        "model = tf.keras.Sequential([\n",
        "    CustomLayer(input_shape=(28, 28, 1)),\n",
        "    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    tf.keras.layers.Flatten(),\n",
        "])\n",
        "\n",
        "train_out = model(train_data, training=True)\n",
        "test_out = model(test_data, training=False)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dS5ed_jjOkvh"
      },
      "source": [
        "Algunas cosas a tener en cuenta:\n",
        "\n",
        "* Los modelos y capas de Keras subclasificados deben ejecutarse tanto en graficos v1 (sin dependencias de control automatico) como en modo eager \n",
        "   * Envuelva el `call()` en un `tf.function()` para obtener dependencias de autografos y control automatico\n",
        "\n",
        "* No olvides aceptar un argumento de 'training' para 'call'.\n",
        "     * A veces es un `tf.Tensor`\n",
        "     * A veces es un booleano Python.\n",
        "\n",
        "* Crea variables modelo en constructor o `Model.build` usando` self.add_weight () `.\n",
        "   * En `Model.build` tiene acceso a la forma de entrada, por lo que puede crear pesos con formas coincidentes.\n",
        "   * El uso de `tf.keras.layers.Layer.add_weight` le permite a Keras rastrear variables y perdidas de regularizacion.\n",
        "\n",
        "* No guardes `tf.Tensors` en tus objetos.\n",
        "   * Pueden crearse en una `tf.function` o en un eager context, y estos tensores se comportan de manera diferente.\n",
        "   * Usa `tf.Variable`s para el estado, siempre se pueden usar desde ambos contextos\n",
        "   * `tf.Tensors` son solo para valores intermedios."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ulaB1ymO4pw5"
      },
      "source": [
        "### Una nota sobre Slim y contrib.layers\n",
        "\n",
        "Una gran cantidad de codigo anterior de TensorFlow 1.x utiliza la biblioteca [Slim](https://ai.googleblog.com/2016/08/tf-slim-high-level-library-to-define.html), que era empaquetado con TensorFlow 1.x como `tf.contrib.layers`. Como modulo `contrib`, esto ya no esta disponible en TensorFlow 2.0, incluso en` tf.compat.v1`. La conversion de codigo usando Slim a TF 2.0 es mas complicada que la conversion de repositorios que usan `v1.layers`. De hecho, puede tener sentido convertir su codigo Slim a `v1.layers` primero, luego convertirlo a Keras.\n",
        "\n",
        "* Elimina `arg_scopes`, todos los argumentos deben ser explicitos\n",
        "* Si los usas, divide `normalizer_fn` y` Activation_fn` en sus propias capas\n",
        "* Las capas de conv separables se asignan a una o mas capas de Keras diferentes (capas de Keras separables en profundidad, pointwise y separables)\n",
        "* Slim y `v1.layers` tienen diferentes nombres arg y valores predeterminados\n",
        "* Algunos args tienen diferentes escalas\n",
        "* Si usas modelos pre-entrenados Slim, pruebe `tf.keras.applications` o [TFHub](https://tensorflow.orb/hub)\n",
        "\n",
        "Es posible que algunas capas `tf.contrib` no se hayan movido al nucleo de TensorFlow, sino que se hayan movido al [paquete de complementos TF](https://github.com/tensorflow/addons).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1w72KrXm4yZR"
      },
      "source": [
        "## Entrenamiento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "56PQxTgy2bpI"
      },
      "source": [
        "Hay muchas formas de alimentar datos a un modelo `tf.keras`. Aceptaran generadores Python y matrices Numpy como entrada.\n",
        "\n",
        "La forma recomendada de alimentar datos a un modelo es usar el paquete `tf.data`, que contiene una coleccion de clases de alto rendimiento para manipular datos.\n",
        "\n",
        "Si todavia utilizas `tf.queue`, ahora solo se admiten como estructuras de datos, no como canalizaciones de entrada."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "m6htasZ7iBB4"
      },
      "source": [
        "### Utilizando Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "loTPH2Pz4_Oj"
      },
      "source": [
        "El paquete [TensorFlow Datasets](https://tensorflow.org/datasets) (`tfds`) contiene utilidades para cargar conjuntos de datos predefinidos como objetos` tf.data.Dataset`.\n",
        "\n",
        "Para este ejemplo, carga el conjunto de datos MNIST, usando `tfds`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BMgxaLH74_s-",
        "colab": {}
      },
      "source": [
        "datasets, info = tfds.load(name='mnist', with_info=True, as_supervised=True)\n",
        "mnist_train, mnist_test = datasets['train'], datasets['test']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hPJhEuvj5VfR"
      },
      "source": [
        "Luego prepara los datos para el entrenamiento:\n",
        "\n",
        "   * Vuelva a escalar cada imagen.\n",
        "   * Barajea el orden de los ejemplos.\n",
        "   * Recoge lotes de imagenes y etiquetas.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "StBRHtJM2S7o",
        "colab": {}
      },
      "source": [
        "BUFFER_SIZE = 10 # Utiliza un valor mas grande para codigo real\n",
        "BATCH_SIZE = 64\n",
        "NUM_EPOCHS = 5\n",
        "\n",
        "\n",
        "def scale(image, label):\n",
        "  image = tf.cast(image, tf.float32)\n",
        "  image /= 255\n",
        "\n",
        "  return image, label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SKq14zKKFAdv"
      },
      "source": [
        "Para mantener el ejemplo corto, reduce el conjunto de datos para que solo devuelva 5 lotes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_J-o4YjG2mkM",
        "colab": {}
      },
      "source": [
        "train_data = mnist_train.map(scale).shuffle(BUFFER_SIZE).batch(BATCH_SIZE).take(5)\n",
        "test_data = mnist_test.map(scale).batch(BATCH_SIZE).take(5)\n",
        "\n",
        "STEPS_PER_EPOCH = 5\n",
        "\n",
        "train_data = train_data.take(STEPS_PER_EPOCH)\n",
        "test_data = test_data.take(STEPS_PER_EPOCH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XEqdkH54VM6c",
        "colab": {}
      },
      "source": [
        "image_batch, label_batch = next(iter(train_data))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mSev7vZC5GJB"
      },
      "source": [
        "### Usa los ciclos de entrenamiento de Keras\n",
        "\n",
        "Si no necesitas un control de bajo nivel de tu proceso de entrenamiento, se recomienda utilizar los metodos incorporados `fit`, `evaluate` y `predict` de Keras. Estos metodos proporcionan una interfaz uniforme para entrenar el modelo independientemente de la implementación (secuencial, funcional o subclasificada).\n",
        "\n",
        "Las ventajas de estos metodos incluyen:\n",
        "\n",
        "* Aceptan matrices Numpy, generadores Python y `tf.data.Datasets`\n",
        "* Aplican la regularizacion, y las perdidas de activacion automaticamente.\n",
        "* Admiten `tf.distribute` [para la capacitacion en multiples dispositivos](distribuir_estrategia.ipynb).\n",
        "* Admiten invocaciones arbitrarias como perdidas y metricas.\n",
        "* Admiten devoluciones de llamada como `tf.keras.callbacks.TensorBoard`, y devoluciones de llamada personalizadas.\n",
        "* Son efectivos, automaticamente usan graficos TensorFlow.\n",
        "\n",
        "Aqui hay un ejemplo de entrenamiento de un modelo usando un `Dataset`. (Para obtener detalles sobre como funciona, consulta [tutoriales](../tutoriales).)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uzHFCzd45Rae",
        "colab": {}
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, 3, activation='relu',\n",
        "                           kernel_regularizer=tf.keras.regularizers.l2(0.02),\n",
        "                           input_shape=(28, 28, 1)),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dropout(0.1),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "# model es el modelo completo sin capas personalizadas\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_data, epochs=NUM_EPOCHS)\n",
        "loss, acc = model.evaluate(test_data)\n",
        "\n",
        "print(\"Loss {}, Accuracy {}\".format(loss, acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "akpeOb09YBhq"
      },
      "source": [
        "### Escribe tu propio ciclo\n",
        "\n",
        "Si el paso de entrenamiento del modelo Keras funciona para usted, pero necesita mas control, considera usar el metodo `tf.keras.Model.train_on_batch`, en su propio ciclo de iteración de datos.\n",
        "\n",
        "Recuerda: se pueden implementar muchas cosas como un `tf.keras.callbacks.Callback`.\n",
        "\n",
        "Este metodo tiene muchas de las ventajas de los metodos mencionados en la seccion anterior, pero le da al usuario el control del ciclo externo.\n",
        "\n",
        "Tambien puede usar `tf.keras.Model.test_on_batch` o` tf.keras.Model.evaluate` para verificar el rendimiento durante el entrenamiento.\n",
        "\n",
        "Nota: `train_on_batch` y` test_on_batch`, por defecto devuelven la perdida y las metricas para el lote individual. Si pasa `reset_metrics = False`, devuelven las metricas acumuladas y debe recordar restablecer adecuadamente los acumuladores de metricas. Recuerda tambien que algunas metricas como `AUC` requieren que` reset_metrics = False` se calcule correctamente.\n",
        "\n",
        "Para continuar entrenando el modelo anterior:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eXr4CyJMtJJ6",
        "colab": {}
      },
      "source": [
        "\n",
        "# model es el modelo completo sin capas personalizadas\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "metrics_names = model.metrics_names\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  # Reinicia los acumuladores de metricas\n",
        "  model.reset_metrics()\n",
        "\n",
        "  for image_batch, label_batch in train_data:\n",
        "    result = model.train_on_batch(image_batch, label_batch)\n",
        "    print(\"train: \",\n",
        "          \"{}: {:.3f}\".format(metrics_names[0], result[0]),\n",
        "          \"{}: {:.3f}\".format(metrics_names[1], result[1]))\n",
        "  for image_batch, label_batch in test_data:\n",
        "    result = model.test_on_batch(image_batch, label_batch,\n",
        "                                 # Devuelve las metricas acumuladas\n",
        "                                 reset_metrics=False)\n",
        "  print(\"\\neval: \",\n",
        "        \"{}: {:.3f}\".format(metrics_names[0], result[0]),\n",
        "        \"{}: {:.3f}\".format(metrics_names[1], result[1]))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LQTaHTuK5S5A"
      },
      "source": [
        "<a name=\"custom_loop\"></a>\n",
        "\n",
        "### Personaliza el paso de entrenamiento\n",
        "\n",
        "Si necesitas mas flexibilidad y control, puedes conseguirlo implementando tu propio ciclo de entrenamiento. Hay tres pasos:\n",
        "\n",
        "1. Itera sobre un generador de Python o `tf.data.Dataset` para obtener lotes de ejemplos.\n",
        "2. Usa `tf.GradientTape` para recolectar gradientes.\n",
        "3. Utiliza uno de los `tf.keras.optimizers` para aplicar actualizaciones de peso a las variables del modelo.\n",
        "\n",
        "Recuerda:\n",
        "\n",
        "* Incluye siempre un argumento de `training` en el metodo` call` de capas y modelos subclasificados.\n",
        "* Asegurate de llamar al modelo con el argumento `training` configurado correctamente.\n",
        "* Segun el uso, las variables del modelo pueden no existir hasta que el modelo se ejecute en un lote de datos.\n",
        "* Necesitas manejar manualmente cosas como perdidas de regularizacion para el modelo.\n",
        "\n",
        "Ten en cuenta las simplificaciones relativas a v1:\n",
        "\n",
        "* No hay necesidad de ejecutar inicializadores variables. Las variables se inicializan en la creacion.\n",
        "* No es necesario agregar dependencias de control manual. Incluso en las operaciones `tf.function` actúan como en el modo eager."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gQooejfYlQeF",
        "colab": {}
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, 3, activation='relu',\n",
        "                           kernel_regularizer=tf.keras.regularizers.l2(0.02),\n",
        "                           input_shape=(28, 28, 1)),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dropout(0.1),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(0.001)\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "\n",
        "@tf.function\n",
        "def train_step(inputs, labels):\n",
        "  with tf.GradientTape() as tape:\n",
        "    predictions = model(inputs, training=True)\n",
        "    regularization_loss = tf.math.add_n(model.losses)\n",
        "    pred_loss = loss_fn(labels, predictions)\n",
        "    total_loss = pred_loss + regularization_loss\n",
        "\n",
        "  gradients = tape.gradient(total_loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  for inputs, labels in train_data:\n",
        "    train_step(inputs, labels)\n",
        "  print(\"Finished epoch\", epoch)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kS7WW5Z75ve3"
      },
      "source": [
        "### Nuevas metricas y perdidas de estilo\n",
        "\n",
        "En TensorFlow 2.0, las metricas y las perdidas son objetos. Estos funcionan tanto con eagerly como en `tf.function`s.\n",
        "\n",
        "Un objeto de perdida es invocable y espera el (y_pred, y_true) como argumentos:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "C5_TVrBlbBcy",
        "colab": {}
      },
      "source": [
        "cce = tf.losses.CategoricalCrossentropy(from_logits=True)\n",
        "cce([[1, 0]], [[-1.0,3.0]]).numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JFDc1v0XbAyB"
      },
      "source": [
        "Un objeto de metrica tiene los siguientes metodos:\n",
        "\n",
        "* `Metric.update_state()` - agrega nuevas observaciones\n",
        "* `Metric.result ()`: obtiene el resultado actual de la metrica, dados los valores observados\n",
        "* `Metric.reset_states()` - borra todas las observaciones.\n",
        "\n",
        "El objeto en si es invocable. La llamada actualiza el estado con nuevas observaciones, como con `update_state`, y devuelve el nuevo resultado de la metrica.\n",
        "\n",
        "No tienes que inicializar manualmente las variables de una metrica, y debido a que TensorFlow 2.0 tiene dependencias de control automatico, tampoco necesitas preocuparse por ellas.\n",
        "\n",
        "El siguiente codigo utiliza una metrica para realizar un seguimiento de la perdida media observada dentro de un ciclo de entrenamiento personalizado."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HAbA0fKW58CH",
        "colab": {}
      },
      "source": [
        "# Crea las metricas\n",
        "loss_metric = tf.keras.metrics.Mean(name='train_loss')\n",
        "accuracy_metric = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
        "\n",
        "@tf.function\n",
        "def train_step(inputs, labels):\n",
        "  with tf.GradientTape() as tape:\n",
        "    predictions = model(inputs, training=True)\n",
        "    regularization_loss = tf.math.add_n(model.losses)\n",
        "    pred_loss = loss_fn(labels, predictions)\n",
        "    total_loss = pred_loss + regularization_loss\n",
        "\n",
        "  gradients = tape.gradient(total_loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "  # Actualiza las metricas\n",
        "  loss_metric.update_state(total_loss)\n",
        "  accuracy_metric.update_state(labels, predictions)\n",
        "\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  # Reinicia las metricas\n",
        "  loss_metric.reset_states()\n",
        "  accuracy_metric.reset_states()\n",
        "\n",
        "  for inputs, labels in train_data:\n",
        "    train_step(inputs, labels)\n",
        "  # Obten las metricas resultantes\n",
        "  mean_loss = loss_metric.result()\n",
        "  mean_accuracy = accuracy_metric.result()\n",
        "\n",
        "  print('Epoch: ', epoch)\n",
        "  print('  loss:     {:.3f}'.format(mean_loss))\n",
        "  print('  accuracy: {:.3f}'.format(mean_accuracy))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Hf718XCgDAGJ"
      },
      "source": [
        "### Optimizadores Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "A6El-NxAQ8aF"
      },
      "source": [
        "Los optimizadores en `v1.train`, como `v1.train.AdamOptimizer` y `v1.train.GradientDescentOptimizer`, tienen equivalentes en` tf.keras.optimizers`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qgP89WdSDQx-"
      },
      "source": [
        "#### Conviertir `v1.train` a `keras.optimizers`\n",
        "\n",
        "Algunas cosas a tener en cuenta al convertir tus optimizadores\n",
        "\n",
        "* Actualiza tus optimizadores [puedes hacer que los checkpoints antiguos sean incompatibles](#checkpoints).\n",
        "* Todos los epsilons ahora estan predeterminados en `1e-7` en lugar de` 1e-8` (que es insignificante en la mayoria de los casos).\n",
        "* `v1.train.GradientDescentOptimizer` se puede reemplazar directamente por` tf.keras.optimizers.SGD`.\n",
        "* `v1.train.MomentumOptimizer` se puede reemplazar directamente por el optimizador` SGD` utilizando el argumento momentum: `tf.keras.optimizers.SGD (..., momentum = ...)`.\n",
        "* `v1.train.AdamOptimizer` se puede convertir para usar` tf.keras.optimizers.Adam`. Los argumentos `beta1` y` beta2` han cambiado de nombre a `beta_1` y` beta_2`.\n",
        "* `v1.train.RMSPropOptimizer` se puede convertir a` tf.keras.optimizers.RMSprop`. El argumento `decay` ha sido renombrado a` rho`.\n",
        "* `v1.train.AdadeltaOptimizer` se puede convertir directamente a` tf.keras.optimizers.Adadelta`.\n",
        "* `tf.train.AdagradOptimizer` se puede convertir directamente a` tf.keras.optimizers.Adagrad`.\n",
        "* `tf.train.FtrlOptimizer` se puede convertir directamente a` tf.keras.optimizers.Ftrl`. Se han eliminado los argumentos `acumular_nombre` y` lineal_nombre`.\n",
        "* El `tf.contrib.AdamaxOptimizer` y` tf.contrib.NadamOptimizer`, se pueden convertir directamente a `tf.keras.optimizers.Adamax` y` tf.keras.optimizers.Nadam`. Los argumentos `beta1` y` beta2` han cambiado de nombre a `beta_1` y` beta_2`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ef60-wJ2bR3l"
      },
      "source": [
        "\n",
        "#### Nuevos valores predeterminados para algunos `tf.keras.optimizers`\n",
        "<a id=\"keras_optimizer_lr\"></a>\n",
        "\n",
        "Advertencia: si ves un cambio en el comportamiento de convergencia de sus modelos, verifica las tasas de aprendizaje predeterminadas.\n",
        "\n",
        "No hay cambios para `optimizers.SGD`,` optimizers.Adam` u `optimizers.RMSprop`.\n",
        "\n",
        "Las siguientes tasas de aprendizaje predeterminadas han cambiado:\n",
        "\n",
        "* `optimizadores.Adagrad` de 0.01 a 0.001\n",
        "* `optimizadores.Adadelta` de 1.0 a 0.001\n",
        "* `optimizadores.Adamax` de 0.002 a 0.001\n",
        "* `optimizadores.Nadam` de 0.002 a 0.001"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5Cf1ks48Q3uc"
      },
      "source": [
        "### TensorBoard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0tx7FyM_RHwJ"
      },
      "source": [
        "TensorFlow 2.0 incluye cambios significativos en la API `tf.summary` utilizada para escribir datos de resumen para su visualización en TensorBoard. Para una introduccion general al nuevo tf.summary, hay [varios tutoriales disponibles](https://www.tensorflow.org/tensorboard/r2/get_started) que usan la API TF 2.0. Esto incluye una [Guia de migración de TensorBoard TF2.0](https://www.tensorflow.org/tensorboard/r2/migrate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JmMLBKs66DeA"
      },
      "source": [
        "## Guardando & Cargando\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5_QKn3Kl6TUu"
      },
      "source": [
        "<a id=\"checkpoints\"></a>\n",
        "### Compatibilidad de checkpoints\n",
        "\n",
        "TensorFlow 2.0 utiliza [checkpoints basados ​​en objetos](checkpoints.ipynb).\n",
        "\n",
        "Los checkpoints basados en nombres antiguos todavia se pueden cargar, si tienes cuidado.\n",
        "El proceso de conversion de codigo puede dar como resultado cambios de nombre variables, pero hay soluciones alternativas.\n",
        "\n",
        "El enfoque mas simple es alinear los nombres del nuevo modelo con los nombres en el punto de control:\n",
        "\n",
        "* Las variables todavia tienen un argumento `name` que puede establecer.\n",
        "* Los modelos Keras tambien toman un argumento `nombre` como el que establecen como prefijo para sus variables.\n",
        "* La función `v1.name_scope` se puede usar para establecer prefijos de nombre de variable. Esto es muy diferente de `tf.variable_scope`. Solo afecta a los nombres, y no rastrea variables y reutiliza.\n",
        "\n",
        "Si eso no funciona para su caso de uso, prueba la funcion `v1.train.init_from_checkpoint`. Se necesita un argumento `task_map`, que especifica la asignacion de los nombres antiguos a los nuevos.\n",
        "\n",
        "Nota: A diferencia de los checkpoints basados en objetos, que pueden [diferir la carga](checkpoints.ipynb # loading_mechanics), los checkpoints basados en nombres requieren que todas las variables se construyan cuando se llama a la funcion. Algunos modelos difieren las variables de construccion hasta que llame a `build` o ejecute el modelo en un lote de datos.\n",
        "\n",
        "El [repositorio de TensorFlow Estimator](https://github.com/tensorflow/estimator/blob/master/tensorflow_estimator/python/estimator/tools/checkpoint_converter.py) incluye una [herramienta de conversión](#checkpoint_converter) para actualizar los checkpoints para estimadores prefabricados de TensorFlow 1.X a 2.0. Puede servir como un ejemplo de como construir una herramienta en un caso de uso similar."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_ONjobDD6Uur"
      },
      "source": [
        "### Compatibilidad de modelos guardados\n",
        "\n",
        "No existen problemas de compatibilidad significativos para los modelos guardados.\n",
        "\n",
        "* TensorFlow 1.x saved_models funciona en TensorFlow 2.0.\n",
        "* TensorFlow 2.0 saved_models incluso carga el trabajo en TensorFlow 1.x si todas las operaciones son compatibles."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ewl9P3oZ6ZtR"
      },
      "source": [
        "## Estimadores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YprVP9g3l6eG"
      },
      "source": [
        "### Entrenamiento con estimadores\n",
        "\n",
        "Los estimadores son compatibles con TensorFlow 2.0.\n",
        "\n",
        "Cuando usa estimadores, puede usar `input_fn()`, `tf.estimator.TrainSpec` y` tf.estimator.EvalSpec` de TensorFlow 1.x.\n",
        "\n",
        "Aqui hay un ejemplo usando `input_fn` con train y evalua las especificaciones."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "N5kZeJsF8lS2"
      },
      "source": [
        "#### Creando las especificacviones input_fn y train/eval "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AOlXGO4J6jDh",
        "colab": {}
      },
      "source": [
        "\n",
        "# Define los estimadores de input_fn\n",
        "def input_fn():\n",
        "  datasets, info = tfds.load(name='mnist', with_info=True, as_supervised=True)\n",
        "  mnist_train, mnist_test = datasets['train'], datasets['test']\n",
        "\n",
        "  BUFFER_SIZE = 10000\n",
        "  BATCH_SIZE = 64\n",
        "\n",
        "  def scale(image, label):\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    image /= 255\n",
        "\n",
        "    return image, label[..., tf.newaxis]\n",
        "\n",
        "  train_data = mnist_train.map(scale).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "  return train_data.repeat()\n",
        "\n",
        "# Define las especificaciones de entrenamiento y de eval\n",
        "train_spec = tf.estimator.TrainSpec(input_fn=input_fn,\n",
        "                                    max_steps=STEPS_PER_EPOCH * NUM_EPOCHS)\n",
        "eval_spec = tf.estimator.EvalSpec(input_fn=input_fn,\n",
        "                                  steps=STEPS_PER_EPOCH)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_o6J48Nj9H5c"
      },
      "source": [
        "### Usando una definición de modelo Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IXCQdhGq9SbB"
      },
      "source": [
        "Hay algunas diferencias en como construir sus estimadores en TensorFlow 2.0.\n",
        "\n",
        "Recomendamos que definas tu modelo usando Keras, luego usa la utilidad `tf.keras.estimator.model_to_estimator` para convertir su modelo en un estimador. El siguiente codigo muestra como usar esta utilidad al crear y entrenar un estimador."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aelsClm3Cq4I",
        "colab": {}
      },
      "source": [
        "def make_model():\n",
        "  return tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, 3, activation='relu',\n",
        "                           kernel_regularizer=tf.keras.regularizers.l2(0.02),\n",
        "                           input_shape=(28, 28, 1)),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dropout(0.1),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "  ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HJb6f8dtl6rr",
        "colab": {}
      },
      "source": [
        "model = make_model()\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "estimator = tf.keras.estimator.model_to_estimator(\n",
        "  keras_model = model\n",
        ")\n",
        "\n",
        "tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-ptTxL1q6flL"
      },
      "source": [
        "### Usando un `model_fn` personalizado\n",
        "\n",
        "Si tienes un estimador personalizado `model_fn` existente que necesita mantener, puedes convertir su `model_fn` para usar un modelo Keras.\n",
        "\n",
        "Sin embargo, por razones de compatibilidad, un `model_fn` personalizado se ejecutara en modo grafico estilo 1.x. Esto significa que no hay una eager execution ni dependencias de control automatico."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Avgqf8IKfd51"
      },
      "source": [
        "<a name=\"minimal_changes\"></a>\n",
        "\n",
        "#### Model_fn personalizado con cambios minimos\n",
        "Para que tu `model_fn` personalizado funcione en TF 2.0, si prefieres cambios minimos en el codigo existente, se pueden usar simbolos` tf.compat.v1` como `optimizers` y` metrics`.\n",
        "\n",
        "Usar un modelo Keras en un `model_fn` personalizado es similar a usarlo en un ciclo de entrenamiento personalizado:\n",
        "\n",
        "* Establece la fase de \"training\" de manera apropiada, segun el argumento de \"mode\".\n",
        "* Pasa explicitamente las `variables_tranables` del modelo al optimizador.\n",
        "\n",
        "Pero hay diferencias importantes, en relacion con un [bucle personalizado] (# custom_loop):\n",
        "\n",
        "* En lugar de usar `Model.losses`, extrae las perdidas usando` Model.get_losses_for`.\n",
        "* Extrae las actualizaciones del modelo usando `Model.get_updates_for`.\n",
        "\n",
        "Nota: Las \"Updates\" son cambios que deben aplicarse a un modelo despues de cada lote. Por ejemplo, los promedios moviles de la media y la varianza en una capa `layers.BatchNormalization`.\n",
        "\n",
        "El siguiente codigo crea un estimador a partir de un `model_fn` personalizado, que ilustra todas estas preocupaciones."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iY16eZKW606-",
        "colab": {}
      },
      "source": [
        "def my_model_fn(features, labels, mode):\n",
        "  model = make_model()\n",
        "\n",
        "  optimizer = tf.compat.v1.train.AdamOptimizer()\n",
        "  loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "\n",
        "  training = (mode == tf.estimator.ModeKeys.TRAIN)\n",
        "  predictions = model(features, training=training)\n",
        "\n",
        "  if mode == tf.estimator.ModeKeys.PREDICT:\n",
        "    return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
        "\n",
        "  reg_losses = model.get_losses_for(None) + model.get_losses_for(features)\n",
        "  total_loss = loss_fn(labels, predictions) + tf.math.add_n(reg_losses)\n",
        "\n",
        "  accuracy = tf.compat.v1.metrics.accuracy(labels=labels,\n",
        "                                           predictions=tf.math.argmax(predictions, axis=1),\n",
        "                                           name='acc_op')\n",
        "\n",
        "  update_ops = model.get_updates_for(None) + model.get_updates_for(features)\n",
        "  minimize_op = optimizer.minimize(\n",
        "      total_loss,\n",
        "      var_list=model.trainable_variables,\n",
        "      global_step=tf.compat.v1.train.get_or_create_global_step())\n",
        "  train_op = tf.group(minimize_op, update_ops)\n",
        "\n",
        "  return tf.estimator.EstimatorSpec(\n",
        "    mode=mode,\n",
        "    predictions=predictions,\n",
        "    loss=total_loss,\n",
        "    train_op=train_op, eval_metric_ops={'accuracy': accuracy})\n",
        "\n",
        "# Creaa el estimador y el entrenador\n",
        "estimator = tf.estimator.Estimator(model_fn=my_model_fn)\n",
        "tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XVxHmU2ccfAG"
      },
      "source": [
        "#### `model_fn` personalizado con símbolos TF 2.0\n",
        "Si deseas deshacerse de todos los simbolos TF 1.x y actualizar tu `model_fn` personalizado a TF 2.0 nativo, debes actualizar el optimizador y las metricas a` tf.keras.optimizers` y `tf.keras.metrics`.\n",
        "\n",
        "En el `model_fn` personalizado, ademas de los [cambios](#minimal_changes) anteriores , se deben realizar más actualizaciones:\n",
        "\n",
        "* Utiliza [`tf.keras.optimizers`](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/optimizers) en lugar de `v1.train.Optimizer`.\n",
        "* Explicitamente pasa las `variables_tranables` del modelo a las` tf.keras.optimizers`.\n",
        "* Para calcular el `train_op / minimizar_op`,\n",
        "  * Usa `Optimizer.get_updates ()` si la perdida es perdida escalar `Tensor` (no es invocable). El primer elemento en la lista devuelta es el deseado `train_op / minimice_op`.\n",
        "  * Si la perdida es invocable (como una funcion), usa `Optimizer.minimize()` para obtener `train_op / minimice_op`.\n",
        "* Utiliza [`tf.keras.metrics`](https://www.tensorflow.org/api_docs/python/tf/keras/metrics) en lugar de` tf.compat.v1.metrics` para la evaluacion.\n",
        "\n",
        "Para el ejemplo anterior de `my_model_fn`, el codigo migrado con símbolos 2.0 se muestra como:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uf8J3nloeze2",
        "colab": {}
      },
      "source": [
        "def my_model_fn(features, labels, mode):\n",
        "  model = make_model()\n",
        "\n",
        "  training = (mode == tf.estimator.ModeKeys.TRAIN)\n",
        "  loss_obj = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "  predictions = model(features, training=training)\n",
        "\n",
        "  # Obten ambas perdidas incondicionales (la parte None)\n",
        "  # y las pérdidas condicionales de entrada (la parte de caracteristicas).\n",
        "  reg_losses = model.get_losses_for(None) + model.get_losses_for(features)\n",
        "  total_loss = loss_obj(labels, predictions) + tf.math.add_n(reg_losses)\n",
        "\n",
        "  # Actualiza a tf.keras.metrics.\n",
        "  accuracy_obj = tf.keras.metrics.Accuracy(name='acc_obj')\n",
        "  accuracy = accuracy_obj.update_state(\n",
        "      y_true=labels, y_pred=tf.math.argmax(predictions, axis=1))\n",
        "\n",
        "  train_op = None\n",
        "  if training:\n",
        "    # Actualiza a tf.keras.optimizers.\n",
        "    optimizer = tf.keras.optimizers.Adam()\n",
        "    # Asigna manualmente la variable tf.compat.v1.global_step a \n",
        "    # optimizer.iterations\n",
        "    # para hacer que tf.compat.v1.train.global_step aumente correctamente.\n",
        "    # Esta asignacion es imprescindible para cualquier `tf.train.SessionRunHook`\n",
        "    # especificado en estimador, ya que SessionRunHooks confía en el paso global.\n",
        "    optimizer.iterations = tf.compat.v1.train.get_or_create_global_step()\n",
        "    # Obten las actualizaciones incondicionales (la parte Ninguna)\n",
        "    # y las actualizaciones condicionales de entrada (la parte de caracterIsticas).\n",
        "    update_ops = model.get_updates_for(None) + model.get_updates_for(features)\n",
        "    # Computa minimize_op.\n",
        "    minimize_op = optimizer.get_updates(\n",
        "        total_loss,\n",
        "        model.trainable_variables)[0]\n",
        "    train_op = tf.group(minimize_op, *update_ops)\n",
        "\n",
        "  return tf.estimator.EstimatorSpec(\n",
        "    mode=mode,\n",
        "    predictions=predictions,\n",
        "    loss=total_loss,\n",
        "    train_op=train_op,\n",
        "    eval_metric_ops={'Accuracy': accuracy_obj})\n",
        "\n",
        "# Crea el Estimator y Train\n",
        "estimator = tf.estimator.Estimator(model_fn=my_model_fn)\n",
        "tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "g1l6VnOTodfA"
      },
      "source": [
        "### Estimadores prefabricados\n",
        "\n",
        "[Estimadores prefabricados](https://www.tensorflow.org/guide/premade_estimators) en la familia de `tf.estimator.DNN *`, `tf.estimator.Linear *` y `tf.estimator.DNNLinearCombined *` son todavia compatible con la API TensorFlow 2.0, sin embargo, algunos argumentos han cambiado:\n",
        "\n",
        "1. `input_layer_partitioner`: eliminado en 2.0.\n",
        "2. `loss_reduction`: actualizado a` tf.keras.losses.Reduction` en lugar de `tf.compat.v1.losses.Reduction`. Su valor predeterminado tambien se cambia a `tf.keras.losses.Reduction.SUM_OVER_BATCH_SIZE` de` tf.compat.v1.losses.Reduction.SUM`.\n",
        "3. `optimizer`,` dnn_optimizer` y `linear_optimizer`: este argumento se ha actualizado a` tf.keras.optimizers` en lugar del `tf.compat.v1.train.Optimizer`.\n",
        "\n",
        "Para migrar los cambios anteriores:\n",
        "1. No se necesitas migracion para `input_layer_partitioner` ya que [` Estrategia de distribución`](https://www.tensorflow.org/guide/distribute_strategy) lo manejara automaticamente en TF 2.0.\n",
        "2. Para `loss_reduction`, marca [` tf.keras.losses.Reduction`](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/losses/Reduction) para ver opciones admitidas\n",
        "3. Para los argumentos `optimizer`, si no pasa un argumento` optimizer`, `dnn_optimizer` o` linear_optimizer`, o si especifica el argumento `optimizer` como una` cadena` en su codigo, no necesitas cambiar nada. `tf.keras.optimizers` se usa por defecto. De lo contrario, debes actualizarlo desde `tf.compat.v1.train.Optimizer` a su correspondiente [` tf.keras.optimizers`](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/optimizadores)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "v0Kljg-AHyqv"
      },
      "source": [
        "#### Convertidor de checkpoints\n",
        "\n",
        "<a id=\"checkpoint_converter\"></a>\n",
        "\n",
        "La migración a `keras.optimizers` rompera los checkpoints guardados con TF 1.x, ya que`tf.keras.optimizers` genera un conjunto diferente de variables que se guardaran en los checkpoints. Para volver a utilizar el antiguo checkpoints despues de su migración a TF 2.0, prueba la [herramienta de conversión de punto de control](https://github.com/tensorflow/estimator/blob/master/tensorflow_estimator/python/estimator/tools/checkpoint_converter.py).\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "h9FiYN9mIPli",
        "colab": {}
      },
      "source": [
        "! curl -O https://raw.githubusercontent.com/tensorflow/estimator/master/tensorflow_estimator/python/estimator/tools/checkpoint_converter.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DMc6zDJaJwNw"
      },
      "source": [
        "La herramienta contiene ayuda integrada:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9JNZFX3rJLXv",
        "colab": {}
      },
      "source": [
        "! python checkpoint_converter.py -h"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dt8ct9XCFqls"
      },
      "source": [
        "<a id=\"tensorshape\"></a>\n",
        "\n",
        "## TensorShape\n",
        "\n",
        "Esta clase se simplifico para contener objetos `int`s, en lugar de objetos` tf.compat.v1.Dimension`. Por lo tanto, no es necesario llamar a `.value()` para obtener un `int`.\n",
        "\n",
        "Los objetos individuales `tf.compat.v1.Dimension` todavia son accesibles desde` tf.TensorShape.dims`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "x36cWcmM8Eu1"
      },
      "source": [
        "\n",
        "A continuación se muestran las diferencias entre TensorFlow 1.xy TensorFlow 2.0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PbpD-kHOZR4A",
        "colab": {}
      },
      "source": [
        "\n",
        "# Crea una forma y elige un indice\n",
        "i = 0\n",
        "shape = tf.TensorShape([16, None, 256])\n",
        "shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kDFck03neNy0"
      },
      "source": [
        "Si tienes esto en TF 1.x:\n",
        "\n",
        "```python\n",
        "value = shape[i].value\n",
        "```\n",
        "\n",
        "Haz esto en TF 2.0:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KuR73QGEeNdH",
        "colab": {}
      },
      "source": [
        "value = shape[i]\n",
        "value"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bPWPNKRiZmkd"
      },
      "source": [
        "Si tienes esto en TF 1.x:\n",
        "\n",
        "```python\n",
        "for dim in shape:\n",
        "    value = dim.value\n",
        "    print(value)\n",
        "```\n",
        "\n",
        "Haz esto en TF 2.0:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "y6s0vuuprJfc",
        "colab": {}
      },
      "source": [
        "for value in shape:\n",
        "  print(value)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YpRgngu3Zw-A"
      },
      "source": [
        "\n",
        "Si tienes esto en TF 1.x (o usas cualquier otro metodo de dimensión):\n",
        "\n",
        "```python\n",
        "dim = shape[i]\n",
        "dim.assert_is_compatible_with(other_dim)\n",
        "```\n",
        "\n",
        "Haz esto en TF 2.0:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LpViGEcUZDGX",
        "colab": {}
      },
      "source": [
        "other_dim = 16\n",
        "Dimension = tf.compat.v1.Dimension\n",
        "\n",
        "if shape.rank is None:\n",
        "  dim = Dimension(None)\n",
        "else:\n",
        "  dim = shape.dims[i]\n",
        "dim.is_compatible_with(other_dim) # o cualquier otro metodo de dimension"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GaiGe36dOdZ_",
        "colab": {}
      },
      "source": [
        "shape = tf.TensorShape(None)\n",
        "\n",
        "if shape:\n",
        "  dim = shape.dims[i]\n",
        "  dim.is_compatible_with(other_dim) # o cualquier otro metodo de dimension"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3kLLY0I3PI-l"
      },
      "source": [
        "\n",
        "El valor booleano de un `tf.TensorShape` es `True` si se conoce el rango, de otro modo es `False`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-Ow1ndKpOnJd",
        "colab": {}
      },
      "source": [
        "print(bool(tf.TensorShape([])))      # Escalar\n",
        "print(bool(tf.TensorShape([0])))     # Valor de longitud 0\n",
        "print(bool(tf.TensorShape([1])))     # Vector de longitud 1\n",
        "print(bool(tf.TensorShape([None])))  # Vector de longitud desconocida\n",
        "print(bool(tf.TensorShape([1, 10, 100])))       # Tensor 3D\n",
        "print(bool(tf.TensorShape([None, None, None]))) # Tensor 3D con dimenciones no conocidas\n",
        "print()\n",
        "print(bool(tf.TensorShape(None)))  # Un tensor con rango desconocido."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8u63n5S7Y9IX"
      },
      "source": [
        "## Otros cambios\n",
        "\n",
        "* Elimina `tf.colocate_with`: los algoritmos de colocacion de dispositivos de TensorFlow han mejorado significativamente. Esto ya no deberia ser necesario. Si eliminarlo provoca una degradación del rendimiento [reporta un bug](https://github.com/tensorflow/tensorflow/issues)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vKX6AdTAQhB-"
      },
      "source": [
        "## Conclusiones\n",
        "\n",
        "El proceso general es:\n",
        "\n",
        "1. Ejecuta el script de actualización.\n",
        "2. Elimina los símbolos contrib.\n",
        "3. Cambia sus modelos a un estilo orientado a objetos (Keras).\n",
        "4. Usa los bucles de entrenamiento y evaluacion `tf.keras` o` tf.estimator` donde puedas.\n",
        "5. De lo contrario, usa ciclos personalizados, pero asegurate de evitar sesiones y colecciones.\n",
        "\n",
        "\n",
        "Se necesita un poco de trabajo para convertir el codigo a TensorFlow 2.0 idiomatico, pero cada cambio resulta en:\n",
        "\n",
        "* Menos lineas de codigo.\n",
        "* Mayor claridad y simplicidad.\n",
        "* Depuracion mas facil.\n",
        "\n",
        "\n"
      ]
    }
  ]
}