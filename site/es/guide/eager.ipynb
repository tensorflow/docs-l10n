{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "eager.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CCQY7jpBfMur"
      },
      "source": [
        "##### Copyright 2018 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "colab_type": "code",
        "id": "z6X9omPnfO_h",
        "colab": {}
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2QQJJyDzqGRb"
      },
      "source": [
        "# Temas esenciales de la ejecución \"Eager\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXRrOAWMPdqC",
        "colab_type": "text"
      },
      "source": [
        "Nota: Nuestra comunidad de Tensorflow\n",
        "ha traducido estos documentos. Como las\n",
        "traducciones de la comunidad son\n",
        "basados en el \"mejor esfuerzo\", no hay\n",
        "ninguna garantia que esta sea un reflejo\n",
        "preciso y actual de la Documentacion\n",
        "Oficial en Ingles. Si tienen sugerencias\n",
        "sobre como mejorar esta traduccion, por\n",
        "favor envian un \"Pull request\" al siguiente\n",
        "repositorio tensorflow/docs. Para\n",
        "ofrecerse como voluntario o hacer\n",
        "revision de las traducciones de la\n",
        "Comunidad por favor contacten al\n",
        "siguiente grupo docs@tensorflow.org list."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "B1xdylywqUSX"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/guide/eager\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />Visualizar en TensorFlow.org</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/guide/eager.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Ejecutar en Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/guide/eager.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />Ver código fuente en GitHub</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/guide/eager.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Descargar notebook</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EGjDcGxIqEfX"
      },
      "source": [
        "\n",
        "\"Eager\" es un entorno de programación imperativo que\n",
        "evalúa las operaciones de inmediato, sin construir grafos: las operaciones regresan\n",
        "valores concretos en lugar de construir un grafo computacional para ejecutar más tarde. Esto\n",
        "facilita comenzar con los modelos TensorFlow,depuración, y\n",
        "reduce el  codigo repetitivo. Para seguir esta guía, ejecute el código.\n",
        "ejemplos a continuación en un intérprete interactivo de `python`.\n",
        "\n",
        "La ejecución \"eager\" es una plataforma flexible de aprendizaje automático para la investigación y\n",
        "experimentación, proporcionando:\n",
        "\n",
        "* * Una interfaz intuitiva *: estructura tu código de forma natural y usa datos de Python\n",
        "  estructuras Repita rápidamente en modelos pequeños y datos pequeños.\n",
        "* * Depuración más fácil *: llame a las operaciones directamente para inspeccionar los modelos en ejecución y probar\n",
        "  cambios Utilice las herramientas de depuración de Python estándar para la generación de informes de errores inmediatos.\n",
        "* * Flujo de control natural *: utilice el flujo de control de Python en lugar del control de gráfico\n",
        "  flujo, simplificando la especificación de modelos dinámicos.\n",
        "\n",
        "La ejecución rápida admite la mayoría de las operaciones de TensorFlow y la aceleración de GPU.\n",
        "\n",
        "Nota: Algunos modelos pueden experimentar una sobrecarga mayor con una ejecución \"eager\"\n",
        "habilitado Las mejoras de rendimiento están en curso, pero por favor\n",
        "[presentar un error] (https://github.com/tensorflow/tensorflow/issues) si encuentra un\n",
        "problema y comparte tu solución."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RBAeIwOMrYk8"
      },
      "source": [
        "## Preparación y uso básico"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ByNsp4VqqEfa",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x  #gpu\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "\n",
        "import cProfile"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "48P3-8q4qEfe"
      },
      "source": [
        "En Tensorflow 2.0, la ejecución eager está habilitada por defecto."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "attributes": {
          "classes": [
            "py"
          ],
          "id": ""
        },
        "colab_type": "code",
        "id": "7aFsD8csqEff",
        "colab": {}
      },
      "source": [
        "tf.executing_eagerly()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "x_G1zZT5qEfh"
      },
      "source": [
        "Ahora puedes ejecutar operaciones en TensorFlow y los resultados se ejecutarán inmediatamente:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "attributes": {
          "classes": [
            "py"
          ],
          "id": ""
        },
        "colab_type": "code",
        "id": "9gsI54pbqEfj",
        "colab": {}
      },
      "source": [
        "x = [[2.]]\n",
        "m = tf.matmul(x, x)\n",
        "print(\"hello, {}\".format(m))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ajFn6qsdqEfl"
      },
      "source": [
        "La habilitación de la ejecución \"eager\" cambia la forma en que se comportan las operaciones de TensorFlow; ahora evalúan de inmediato y devuelven sus valores a Python. los objetos hacen referencia a valores concretos en lugar de identificadores simbólicos a nodos en un grafo. Dado que no hay un grafo computacional para construir y ejecutar más tarde en una sesión, es fácil inspeccionar los resultados usando `print ()` o un depurador. Evaluar, imprimir y verificar los valores del tensor no interrumpe el flujo para calcular gradientes.\n",
        "\n",
        "La ejecución \"eager\" funciona bien con [NumPy](http://www.numpy.org/). Las operaciones de NumPy aceptan argumentos de `tf.Tensor`. Las [operaciones matemáticas](https://www.tensorflow.org/api_guides/python/math_ops) TensorFlow convierten los objetos Python y las matrices NumPy en objetos `tf.Tensor`. El método `tf.Tensor`. los métodos de numpy devuelven el valor del objeto como una matriz de datos (`ndarray`) NumPy.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sTO0_5TYqz1n",
        "colab": {}
      },
      "source": [
        "a = tf.constant([[1, 2],\n",
        "                 [3, 4]])\n",
        "print(a)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Dp14YT8Gq4r1",
        "colab": {}
      },
      "source": [
        "# Soporte de broadcasting\n",
        "b = tf.add(a, 1)\n",
        "print(b)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "69p3waMfq8cQ",
        "colab": {}
      },
      "source": [
        "# La sobrecarga de operadores es compatible\n",
        "print(a * b)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "attributes": {
          "classes": [
            "py"
          ],
          "id": ""
        },
        "colab_type": "code",
        "id": "Ui025t1qqEfm",
        "colab": {}
      },
      "source": [
        "# Usar funciones de NumPy\n",
        "import numpy as np\n",
        "\n",
        "c = np.multiply(a, b)\n",
        "print(c)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Tq_aFRzWrCua",
        "colab": {}
      },
      "source": [
        "# Obtener valores numpy de un tensor:\n",
        "print(a.numpy())\n",
        "# => [[1 2]\n",
        "#     [3 4]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "H08f9ss9qEft"
      },
      "source": [
        "## Flujo de control dinámico\n",
        "\n",
        "Una ventaja importante de la ejecución \"eager\" es que toda la funcionalidad del host el idioma está disponible mientras su modelo se está ejecutando. Así por ejemplo,\n",
        "es facil de escribir [fizzbuzz](https://en.wikipedia.org/wiki/Fizz_buzz):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "attributes": {
          "classes": [
            "py"
          ],
          "id": ""
        },
        "colab_type": "code",
        "id": "0fudRMeUqEfu",
        "colab": {}
      },
      "source": [
        "def fizzbuzz(max_num):\n",
        "  counter = tf.constant(0)\n",
        "  max_num = tf.convert_to_tensor(max_num)\n",
        "  for num in range(1, max_num.numpy()+1):\n",
        "    num = tf.constant(num)\n",
        "    if int(num % 3) == 0 and int(num % 5) == 0:\n",
        "      print('FizzBuzz')\n",
        "    elif int(num % 3) == 0:\n",
        "      print('Fizz')\n",
        "    elif int(num % 5) == 0:\n",
        "      print('Buzz')\n",
        "    else:\n",
        "      print(num.numpy())\n",
        "    counter += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "P2cKknQWrJLB",
        "colab": {}
      },
      "source": [
        "fizzbuzz(15)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7kA-aC3BqEfy"
      },
      "source": [
        "Esto tiene condicionales que dependen de los valores del tensor e imprime estos valores en tiempo de ejecución."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8huKpuuAwICq"
      },
      "source": [
        "## Ejercicios utilizando ejercución \"Eager\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mp2lCCZYrxHd"
      },
      "source": [
        "### Computación de gradientes\n",
        "\n",
        "[Automatic differentiation](https://en.wikipedia.org/wiki/Automatic_differentiation)\n",
        "es útil para implementar con algoritmos de aprendizaje automático como\n",
        "[backpropagation](https://en.wikipedia.org/wiki/Backpropagation) para entrenar redes neuronales. Durante la ejecución \"eager\", usa `tf.GradientTape` para rastrear operaciones y calcular gradientes más tarde.\n",
        "\n",
        "Puede usar `tf.GradientTape` para entrenar y / o calcular gradientes con \"eager\". Es especialmente útil para bucles complicados de entrenamiento.\n",
        "\n",
        "Dado que pueden ocurrir diferentes operaciones durante cada llamada, todos\n",
        "las operaciones de pase directo se graban en una \"cinta\". Para calcular el gradiente, juega la cinta al revés y luego descartar. Un `tf.GradientTape` particular solo puede\n",
        "calcular un gradiente; llamadas posteriores arrojan un error de tiempo de ejecución."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "attributes": {
          "classes": [
            "py"
          ],
          "id": ""
        },
        "colab_type": "code",
        "id": "7g1yWiSXqEf-",
        "colab": {}
      },
      "source": [
        "w = tf.Variable([[1.0]])\n",
        "with tf.GradientTape() as tape:\n",
        "  loss = w * w\n",
        "\n",
        "grad = tape.gradient(loss, w)\n",
        "print(grad)  # => tf.Tensor([[ 2.]], shape=(1, 1), dtype=float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vkHs32GqweYS"
      },
      "source": [
        "### Entrenar un modelo\n",
        "\n",
        "El siguiente ejemplo crea un modelo de varias capas que clasifica los dígitos manuscritos MNIST estándar. Demuestra el optimizador y las API de capa para crear grafos entrenables en un entorno de ejecución ansioso."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "38kymXZowhhz",
        "colab": {}
      },
      "source": [
        "# Obtener y dar forma a los datos mnist\n",
        "(mnist_images, mnist_labels), _ = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices(\n",
        "  (tf.cast(mnist_images[...,tf.newaxis]/255, tf.float32),\n",
        "   tf.cast(mnist_labels,tf.int64)))\n",
        "dataset = dataset.shuffle(1000).batch(32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rl1K8rOowmwT",
        "colab": {}
      },
      "source": [
        "# Construir el modelo\n",
        "mnist_model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Conv2D(16,[3,3], activation='relu',\n",
        "                         input_shape=(None, None, 1)),\n",
        "  tf.keras.layers.Conv2D(16,[3,3], activation='relu'),\n",
        "  tf.keras.layers.GlobalAveragePooling2D(),\n",
        "  tf.keras.layers.Dense(10)\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fvyk-HgGwxwl"
      },
      "source": [
        "\n",
        "Incluso sin capacitación, llame al modelo e inspeccione la salida en ejecución \"eager\":"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BsxystjBwxLS",
        "colab": {}
      },
      "source": [
        "for images,labels in dataset.take(1):\n",
        "  print(\"Logits: \", mnist_model(images[0:1]).numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Y3PGa8G7qEgB"
      },
      "source": [
        "Mientras que los modelos keras tienen un ciclo de entrenamiento incorporado (usando el método `fit`), a veces necesitas más personalización. Aquí hay un ejemplo de un ciclo de entrenamiento implementando \"eager\":"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bzRhM7JDnaEG",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "loss_history = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tXaupYXRI2YM"
      },
      "source": [
        "Nota: Use las funciones de aserción en `tf.debugging` para verificar si una condición se mantiene. Esto funciona en la ejecución \"eager\" y la ejecución del grafo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DDHrigtiCIA4",
        "colab": {}
      },
      "source": [
        "def train_step(images, labels):\n",
        "  with tf.GradientTape() as tape:\n",
        "    logits = mnist_model(images, training=True)\n",
        "    \n",
        "    # Agregar \"asserts\" para verificar la forma de la salida.\n",
        "    tf.debugging.assert_equal(logits.shape, (32, 10))\n",
        "    \n",
        "    loss_value = loss_object(labels, logits)\n",
        "\n",
        "  loss_history.append(loss_value.numpy().mean())\n",
        "  grads = tape.gradient(loss_value, mnist_model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(grads, mnist_model.trainable_variables))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "attributes": {
          "classes": [
            "py"
          ],
          "id": ""
        },
        "colab_type": "code",
        "id": "0m1xAXrmqEgJ",
        "colab": {}
      },
      "source": [
        "def train():\n",
        "  for epoch in range(3):\n",
        "    for (batch, (images, labels)) in enumerate(dataset):\n",
        "      train_step(images, labels)\n",
        "    print ('Epoch {} finished'.format(epoch))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "C5dGz0p_nf4W",
        "colab": {}
      },
      "source": [
        "train()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5vG5ql_2vYB5",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(loss_history)\n",
        "plt.xlabel('Batch #')\n",
        "plt.ylabel('Loss [entropy]')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kKpOlHPLqEgl"
      },
      "source": [
        "### Variables y optimizadores\n",
        "\n",
        "Los objetos `tf.Variable` almacenan valores mutables de` tf.Tensor` a los que se accede durante capacitación para facilitar la diferenciación automática. Los parámetros de un modelo pueden ser encapsulado en clases como variables.\n",
        "\n",
        "Es mejor encapsular los parámetros del modelo utilizando `tf.Variable` con\n",
        "`tf.GradientTape`. Por ejemplo, el ejemplo de diferenciación automática anterior\n",
        "puede reescribirse:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "attributes": {
          "classes": [
            "py"
          ],
          "id": ""
        },
        "colab_type": "code",
        "id": "nnQLBYmEqEgm",
        "colab": {}
      },
      "source": [
        "class Model(tf.keras.Model):\n",
        "  def __init__(self):\n",
        "    super(Model, self).__init__()\n",
        "    self.W = tf.Variable(5., name='weight')\n",
        "    self.B = tf.Variable(10., name='bias')\n",
        "  def call(self, inputs):\n",
        "    return inputs * self.W + self.B\n",
        "\n",
        "# Un conjunto de datos de puntos alrededor 3 * x + 2\n",
        "NUM_EXAMPLES = 2000\n",
        "training_inputs = tf.random.normal([NUM_EXAMPLES])\n",
        "noise = tf.random.normal([NUM_EXAMPLES])\n",
        "training_outputs = training_inputs * 3 + 2 + noise\n",
        "\n",
        "# La función de pérdida a optimizar\n",
        "def loss(model, inputs, targets):\n",
        "  error = model(inputs) - targets\n",
        "  return tf.reduce_mean(tf.square(error))\n",
        "\n",
        "def grad(model, inputs, targets):\n",
        "  with tf.GradientTape() as tape:\n",
        "    loss_value = loss(model, inputs, targets)\n",
        "  return tape.gradient(loss_value, [model.W, model.B])\n",
        "\n",
        "# Definir:\n",
        "# 1. Un modelo.\n",
        "# 2. Derivadas de una función de pérdida con respecto a los parámetros del modelo.\n",
        "# 3. Una estrategia para actualizar las variables basadas en los derivados.\n",
        "model = Model()\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
        "\n",
        "print(\"Initial loss: {:.3f}\".format(loss(model, training_inputs, training_outputs)))\n",
        "\n",
        "# Training loop\n",
        "for i in range(300):\n",
        "  grads = grad(model, training_inputs, training_outputs)\n",
        "  optimizer.apply_gradients(zip(grads, [model.W, model.B]))\n",
        "  if i % 20 == 0:\n",
        "    print(\"Loss at step {:03d}: {:.3f}\".format(i, loss(model, training_inputs, training_outputs)))\n",
        "\n",
        "print(\"Final loss: {:.3f}\".format(loss(model, training_inputs, training_outputs)))\n",
        "print(\"W = {}, B = {}\".format(model.W.numpy(), model.B.numpy()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rPjb8nRWqEgr"
      },
      "source": [
        "## Use objetos para el estado durante la ejecución \"eager\"\n",
        "\n",
        "Con la ejecución del grado TF 1.x, el estado del programa (como las variables) se almacena en colecciones globales y su vida útil es administrada por el objeto `tf.Session`. Por el contrario, durante la ejecución ansiosa, la vida útil de los objetos de estado está determinada por la vida útil de su objeto Python correspondiente.\n",
        "\n",
        "### Las variables son objetos\n",
        "\n",
        "Durante la ejecución \"eager\", las variables persisten hasta que se elimina la última referencia al objeto y luego se elimina."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "attributes": {
          "classes": [
            "py"
          ],
          "id": ""
        },
        "colab_type": "code",
        "id": "A2boS674qEgs",
        "colab": {}
      },
      "source": [
        "if tf.config.experimental.list_physical_devices(\"GPU\"):\n",
        "  with tf.device(\"gpu:0\"):\n",
        "    print(\"GPU enabled\")\n",
        "    v = tf.Variable(tf.random.normal([1000, 1000]))\n",
        "    v = None  # v no longer takes up GPU memory"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "scMjg6L6qEgv"
      },
      "source": [
        "### Guardado basado en objetos\n",
        "\n",
        "Esta sección es una versión abreviada de [guía de puntos de control de entrenamiento](./checkpoints.ipynb).\n",
        "\n",
        "`tf.train.Checkpoint` puede guardar y restaurar` tf.Variable` y crear \"checkpoints\":"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7z5xRfdHzZOQ",
        "colab": {}
      },
      "source": [
        "x = tf.Variable(10.)\n",
        "checkpoint = tf.train.Checkpoint(x=x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IffrUVG7zyVb",
        "colab": {}
      },
      "source": [
        "x.assign(2.)   # Asigne un nuevo valor a las variables y guarde.\n",
        "checkpoint_path = './ckpt/'\n",
        "checkpoint.save('./ckpt/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "attributes": {
          "classes": [
            "py"
          ],
          "id": ""
        },
        "colab_type": "code",
        "id": "eMT9koCoqEgw",
        "colab": {}
      },
      "source": [
        "x.assign(11.)  # Cambiar la variable después de guardar.\n",
        "\n",
        "# Restaurar valores desde el punto de control\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_path))\n",
        "\n",
        "print(x)  # => 2.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vbFnP-yLqEgx"
      },
      "source": [
        "Para guardar y cargar modelos, `tf.train.Checkpoint` almacena el estado interno de los objetos, sin requerir variables ocultas. Para registrar el estado de un `modelo`, un` optimizador` y un paso global, páselos a un `tf.train.Checkpoint`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "attributes": {
          "classes": [
            "py"
          ],
          "id": ""
        },
        "colab_type": "code",
        "id": "hWZHyAXMqEg0",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Conv2D(16,[3,3], activation='relu'),\n",
        "  tf.keras.layers.GlobalAveragePooling2D(),\n",
        "  tf.keras.layers.Dense(10)\n",
        "])\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "checkpoint_dir = 'path/to/model_dir'\n",
        "if not os.path.exists(checkpoint_dir):\n",
        "  os.makedirs(checkpoint_dir)\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "root = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                           model=model)\n",
        "\n",
        "root.save(checkpoint_prefix)\n",
        "root.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "R-ITwkBCF6GJ"
      },
      "source": [
        "Nota: En muchos bucles de entrenamiento, las variables se crean después de llamar a `tf.train.Checkpoint.restore`. Estas variables se restaurarán tan pronto como se creen, y las aserciones están disponibles para garantizar que se haya cargado completamente un punto de control. Ver el [guía de puntos de control de entrenamiento](./checkpoints.ipynb) para más detalles."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3yoD0VJ7qEg3"
      },
      "source": [
        "### Métricas orientadas a objetos\n",
        "\n",
        "`tf.keras.metrics` se almacenan como objetos. Actualizar una métrica pasando los nuevos datos al invocable y recupere el resultado utilizando el método `tf.keras.metrics.result`, por ejemplo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "attributes": {
          "classes": [
            "py"
          ],
          "id": ""
        },
        "colab_type": "code",
        "id": "9ccu0iAaqEg5",
        "colab": {}
      },
      "source": [
        "m = tf.keras.metrics.Mean(\"loss\")\n",
        "m(0)\n",
        "m(5)\n",
        "m.result()  # => 2.5\n",
        "m([8, 9])\n",
        "m.result()  # => 5.5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xEL4yJe5qEhD"
      },
      "source": [
        "## Temas avanzados de diferenciación automática\n",
        "\n",
        "### Modelos dinámicos\n",
        "\n",
        "`tf.GradientTape` también se puede utilizar en modelos dinámicos. Este ejemplo para un\n",
        "[backtracking line search](https://wikipedia.org/wiki/Backtracking_line_search)\n",
        "El algoritmo se parece al código NumPy, excepto que hay gradientes y es diferenciable, a pesar del flujo de control complejo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "attributes": {
          "classes": [
            "py"
          ],
          "id": ""
        },
        "colab_type": "code",
        "id": "L518n5dkqEhE",
        "colab": {}
      },
      "source": [
        "def line_search_step(fn, init_x, rate=1.0):\n",
        "  with tf.GradientTape() as tape:\n",
        "    # Las variables se registran automáticamente, pero observan manualmente un tensor\n",
        "    tape.watch(init_x)\n",
        "    value = fn(init_x)\n",
        "  grad = tape.gradient(value, init_x)\n",
        "  grad_norm = tf.reduce_sum(grad * grad)\n",
        "  init_value = value\n",
        "  while value > init_value - rate * grad_norm:\n",
        "    x = init_x - rate * grad\n",
        "    value = fn(x)\n",
        "    rate /= 2.0\n",
        "  return x, value"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gieGOf_DqEhK"
      },
      "source": [
        "### Gradientes personalizados\n",
        "\n",
        "Los gradientes personalizados son una manera fácil de sobreescribir los gradientes. Dentro de la función de avance, defina el gradiente con respecto a entradas, salidas o resultados intermedios. Por ejemplo, aquí hay una manera fácil de recortar La norma de los gradientes en el paso hacia atrás:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "attributes": {
          "classes": [
            "py"
          ],
          "id": ""
        },
        "colab_type": "code",
        "id": "-OwwsWUAqEhK",
        "colab": {}
      },
      "source": [
        "@tf.custom_gradient\n",
        "def clip_gradient_by_norm(x, norm):\n",
        "  y = tf.identity(x)\n",
        "  def grad_fn(dresult):\n",
        "    return [tf.clip_by_norm(dresult, norm), None]\n",
        "  return y, grad_fn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JPLDHkF_qEhN"
      },
      "source": [
        "Los gradientes personalizados se usan comúnmente para proporcionar un gradiente numéricamente estable para un secuencia de operaciones:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "attributes": {
          "classes": [
            "py"
          ],
          "id": ""
        },
        "colab_type": "code",
        "id": "24WiLROnqEhO",
        "colab": {}
      },
      "source": [
        "def log1pexp(x):\n",
        "  return tf.math.log(1 + tf.exp(x))\n",
        "\n",
        "def grad_log1pexp(x):\n",
        "  with tf.GradientTape() as tape:\n",
        "    tape.watch(x)\n",
        "    value = log1pexp(x)\n",
        "  return tape.gradient(value, x)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "n8fq69r9-B-c",
        "colab": {}
      },
      "source": [
        "# El cálculo de gradiente funciona bien en x = 0.\n",
        "grad_log1pexp(tf.constant(0.)).numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_VFSU0mG-FSp",
        "colab": {}
      },
      "source": [
        "# Sin embargo, x = 100 falla debido a la inestabilidad numérica.\n",
        "\n",
        "grad_log1pexp(tf.constant(100.)).numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-VcTR34rqEhQ"
      },
      "source": [
        "Aquí, la función `log1pexp` se puede simplificar analíticamente con un gradiente personalizado. La siguiente implementación reutiliza el valor de `tf.exp (x)` que se calcula durante el paso directo, lo que lo hace más eficiente al eliminar los cálculos redundantes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "attributes": {
          "classes": [
            "py"
          ],
          "id": ""
        },
        "colab_type": "code",
        "id": "Q7nvfx_-qEhS",
        "colab": {}
      },
      "source": [
        "@tf.custom_gradient\n",
        "def log1pexp(x):\n",
        "  e = tf.exp(x)\n",
        "  def grad(dy):\n",
        "    return dy * (1 - 1 / (1 + e))\n",
        "  return tf.math.log(1 + e), grad\n",
        "\n",
        "def grad_log1pexp(x):\n",
        "  with tf.GradientTape() as tape:\n",
        "    tape.watch(x)\n",
        "    value = log1pexp(x)\n",
        "  return tape.gradient(value, x)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5gHPKMfl-Kge",
        "colab": {}
      },
      "source": [
        "# Como antes, el cálculo del gradiente funciona bien en x = 0.\n",
        "grad_log1pexp(tf.constant(0.)).numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "u38MOfz3-MDE",
        "colab": {}
      },
      "source": [
        "# Y el cálculo de gradiente también funciona en x = 100.\n",
        "grad_log1pexp(tf.constant(100.)).numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rnZXjfQzqEhV"
      },
      "source": [
        "## Performance\n",
        "\n",
        "La computación se descarga automáticamente a las GPU durante la ejecución ansiosa. Si desea controlar dónde se ejecuta un cálculo, puede encerrarlo en un bloque `tf.device ('/ gpu: 0')` (o el equivalente de la CPU):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "attributes": {
          "classes": [
            "py"
          ],
          "id": ""
        },
        "colab_type": "code",
        "id": "Ac9Y64H-qEhX",
        "colab": {}
      },
      "source": [
        "import time\n",
        "\n",
        "def measure(x, steps):\n",
        "  # TensorFlow inicializa una GPU la primera vez que se usa, excluye el tiempo.\n",
        "  tf.matmul(x, x)\n",
        "  start = time.time()\n",
        "  for i in range(steps):\n",
        "    x = tf.matmul(x, x)\n",
        "  # tf.matmul puede regresar antes de completar la multiplicación de la matriz\n",
        "  # (p. ej., puede regresar después de aplicar la operación en una secuencia CUDA).\n",
        "  # La llamada x.numpy () a continuación asegurará que todas las operaciones en cola\n",
        "  # ha completado (y también copiará el resultado a la memoria del host,\n",
        "  # así que estamos incluyendo un poco más que solo la operación matmul\n",
        "  # hora).\n",
        "  _ = x.numpy()\n",
        "  end = time.time()\n",
        "  return end - start\n",
        "\n",
        "shape = (1000, 1000)\n",
        "steps = 200\n",
        "print(\"Time to multiply a {} matrix by itself {} times:\".format(shape, steps))\n",
        "\n",
        "# Se ejecuta en CPU:\n",
        "with tf.device(\"/cpu:0\"):\n",
        "  print(\"CPU: {} secs\".format(measure(tf.random.normal(shape), steps)))\n",
        "\n",
        "# Se ejecuta en GPU, si esta disponible:\n",
        "if tf.config.experimental.list_physical_devices(\"GPU\"):\n",
        "  with tf.device(\"/gpu:0\"):\n",
        "    print(\"GPU: {} secs\".format(measure(tf.random.normal(shape), steps)))\n",
        "else:\n",
        "  print(\"GPU: not found\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RLw3IS7UqEhe"
      },
      "source": [
        "A `tf.Tensor` object can be copied to a different device to execute its\n",
        "operations:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "attributes": {
          "classes": [
            "py"
          ],
          "id": ""
        },
        "colab_type": "code",
        "id": "ny6LX2BVqEhf",
        "colab": {}
      },
      "source": [
        "if tf.config.experimental.list_physical_devices(\"GPU\"):\n",
        "  x = tf.random.normal([10, 10])\n",
        "\n",
        "  x_gpu0 = x.gpu()\n",
        "  x_cpu = x.cpu()\n",
        "\n",
        "  _ = tf.matmul(x_cpu, x_cpu)    # Se ejecuta en CPU\n",
        "  _ = tf.matmul(x_gpu0, x_gpu0)  # Se ejecuta en GPU:0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oA_qaII3-p6c"
      },
      "source": [
        "### Benchmarks\n",
        "\n",
        "Para modelos pesados en cómputo, como\n",
        "[ResNet50](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/eager/python/examples/resnet50)\n",
        "entrenamiento en una GPU, el rendimiento de ejecución \"eager\" es comparable a la ejecución `tf.function`.\n",
        "Pero esta brecha crece para modelos con menos cómputo y hay trabajo para\n",
        "debe hacerse para optimizar rutas de código activo para modelos con muchas operaciones pequeñas.\n",
        "\n",
        "## Trabajar con funciones\n",
        "\n",
        "Si bien la ejecución \"eager\" hace que el desarrollo y la depuración sean más interactivos, La ejecución de grafos de estilo TensorFlow 1.x tiene ventajas para la capacitación distribuida, el rendimiento optimizaciones e implementación de producción. Para cerrar esta brecha, TensorFlow 2.0 introduce `function`s a través de la API` tf.function`. Para más información, vea la guía [Autograph](./autograph.ipynb)."
      ]
    }
  ]
}