{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8JSGdaDHc_f4"
      },
      "outputs": [],
      "source": [
        "# Copyright 2019 The TensorFlow Hub Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# =============================================================================="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2_BHI6XdJ30"
      },
      "source": [
        "# Text-to-Video retrieval with S3D MIL-NCE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rm0K9ZTgfISB"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td><a target=\"_blank\" href=\"https://www.tensorflow.org/hub/tutorials/text_to_video_retrieval_with_s3d_milnce\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\"> TensorFlow.orgで表示</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/ja/hub/tutorials/text_to_video_retrieval_with_s3d_milnce.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Run in Google Colab</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/ja/hub/tutorials/text_to_video_retrieval_with_s3d_milnce.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">GitHub でソースを表示</a></td>\n",
        "  <td>\n",
        "<a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/ja/hub/tutorials/text_to_video_retrieval_with_s3d_milnce.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">ノートブックをダウンロード</a><br>\n",
        "</td>\n",
        "  <td>     <a href=\"https://tfhub.dev/deepmind/mil-nce/s3d/1\"><img src=\"https://www.tensorflow.org/images/hub_logo_32px.png\">TF Hub モデルを参照</a> </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bC_xJPpQd-LO"
      },
      "outputs": [],
      "source": [
        "!pip install -q opencv-python\n",
        "\n",
        "import os\n",
        "\n",
        "import tensorflow.compat.v2 as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "from IPython import display\n",
        "import math"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxwaK-jf7qkW"
      },
      "source": [
        "## TF-Hub モデルをインポートする\n",
        "\n",
        "このチュートリアルでは、TensorFlow Hub の [S3D MIL-NCE モデル](https://tfhub.dev/deepmind/mil-nce/s3d/1)を使用して、特定のテキストクエリに最も該当する動画を検索する、**テキストから動画の取得**を行う方法を実演します。\n",
        "\n",
        "このモデルには、*動画埋め込み*を生成するためのシグネチャと*テキスト埋め込み*を生成するためのシグネチャがあります。これら 2 つの埋め込みを使用して、埋め込み空間内の最近傍を見つけ出します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nwv4ZQ4qmak5"
      },
      "outputs": [],
      "source": [
        "# Load the model once from TF-Hub.\n",
        "hub_handle = 'https://tfhub.dev/deepmind/mil-nce/s3d/1'\n",
        "hub_model = hub.load(hub_handle)\n",
        "\n",
        "def generate_embeddings(model, input_frames, input_words):\n",
        "  \"\"\"Generate embeddings from the model from video frames and input words.\"\"\"\n",
        "  # Input_frames must be normalized in [0, 1] and of the shape Batch x T x H x W x 3\n",
        "  vision_output = model.signatures['video'](tf.constant(tf.cast(input_frames, dtype=tf.float32)))\n",
        "  text_output = model.signatures['text'](tf.constant(input_words))\n",
        "  return vision_output['video_embedding'], text_output['text_embedding']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EOZzu9ddekEj"
      },
      "outputs": [],
      "source": [
        "# @title Define video loading and visualization functions  { display-mode: \"form\" }\n",
        "\n",
        "# Utilities to open video files using CV2\n",
        "def crop_center_square(frame):\n",
        "  y, x = frame.shape[0:2]\n",
        "  min_dim = min(y, x)\n",
        "  start_x = (x // 2) - (min_dim // 2)\n",
        "  start_y = (y // 2) - (min_dim // 2)\n",
        "  return frame[start_y:start_y+min_dim,start_x:start_x+min_dim]\n",
        "\n",
        "\n",
        "def load_video(video_url, max_frames=32, resize=(224, 224)):\n",
        "  path = tf.keras.utils.get_file(os.path.basename(video_url)[-128:], video_url)\n",
        "  cap = cv2.VideoCapture(path)\n",
        "  frames = []\n",
        "  try:\n",
        "    while True:\n",
        "      ret, frame = cap.read()\n",
        "      if not ret:\n",
        "        break\n",
        "      frame = crop_center_square(frame)\n",
        "      frame = cv2.resize(frame, resize)\n",
        "      frame = frame[:, :, [2, 1, 0]]\n",
        "      frames.append(frame)\n",
        "\n",
        "      if len(frames) == max_frames:\n",
        "        break\n",
        "  finally:\n",
        "    cap.release()\n",
        "  frames = np.array(frames)\n",
        "  if len(frames) < max_frames:\n",
        "    n_repeat = int(math.ceil(max_frames / float(len(frames))))\n",
        "    frames = frames.repeat(n_repeat, axis=0)\n",
        "  frames = frames[:max_frames]\n",
        "  return frames / 255.0\n",
        "\n",
        "def display_video(urls):\n",
        "    html = '<table>'\n",
        "    html += '<tr><th>Video 1</th><th>Video 2</th><th>Video 3</th></tr><tr>'\n",
        "    for url in urls:\n",
        "        html += '<td>'\n",
        "        html += '<img src=\"{}\" height=\"224\">'.format(url)\n",
        "        html += '</td>'\n",
        "    html += '</tr></table>'\n",
        "    return display.HTML(html)\n",
        "\n",
        "def display_query_and_results_video(query, urls, scores):\n",
        "  \"\"\"Display a text query and the top result videos and scores.\"\"\"\n",
        "  sorted_ix = np.argsort(-scores)\n",
        "  html = ''\n",
        "  html += '<h2>Input query: <i>{}</i> </h2><div>'.format(query)\n",
        "  html += 'Results: <div>'\n",
        "  html += '<table>'\n",
        "  html += '<tr><th>Rank #1, Score:{:.2f}</th>'.format(scores[sorted_ix[0]])\n",
        "  html += '<th>Rank #2, Score:{:.2f}</th>'.format(scores[sorted_ix[1]])\n",
        "  html += '<th>Rank #3, Score:{:.2f}</th></tr><tr>'.format(scores[sorted_ix[2]])\n",
        "  for i, idx in enumerate(sorted_ix):\n",
        "    url = urls[sorted_ix[i]];\n",
        "    html += '<td>'\n",
        "    html += '<img src=\"{}\" height=\"224\">'.format(url)\n",
        "    html += '</td>'\n",
        "  html += '</tr></table>'\n",
        "  return html\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ime5V4kDewh8"
      },
      "outputs": [],
      "source": [
        "# @title Load example videos and define text queries  { display-mode: \"form\" }\n",
        "\n",
        "video_1_url = 'https://upload.wikimedia.org/wikipedia/commons/b/b0/YosriAirTerjun.gif' # @param {type:\"string\"}\n",
        "video_2_url = 'https://upload.wikimedia.org/wikipedia/commons/e/e6/Guitar_solo_gif.gif' # @param {type:\"string\"}\n",
        "video_3_url = 'https://upload.wikimedia.org/wikipedia/commons/3/30/2009-08-16-autodrift-by-RalfR-gif-by-wau.gif' # @param {type:\"string\"}\n",
        "\n",
        "video_1 = load_video(video_1_url)\n",
        "video_2 = load_video(video_2_url)\n",
        "video_3 = load_video(video_3_url)\n",
        "all_videos = [video_1, video_2, video_3]\n",
        "\n",
        "query_1_video = 'waterfall' # @param {type:\"string\"}\n",
        "query_2_video = 'playing guitar' # @param {type:\"string\"}\n",
        "query_3_video = 'car drifting' # @param {type:\"string\"}\n",
        "all_queries_video = [query_1_video, query_2_video, query_3_video]\n",
        "all_videos_urls = [video_1_url, video_2_url, video_3_url]\n",
        "display_video(all_videos_urls)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCLKv_L_8Anc"
      },
      "source": [
        "## テキストから動画を取得する（実演）\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9oX8ItFUjybi"
      },
      "outputs": [],
      "source": [
        "# Prepare video inputs.\n",
        "videos_np = np.stack(all_videos, axis=0)\n",
        "\n",
        "# Prepare text input.\n",
        "words_np = np.array(all_queries_video)\n",
        "\n",
        "# Generate the video and text embeddings.\n",
        "video_embd, text_embd = generate_embeddings(hub_model, videos_np, words_np)\n",
        "\n",
        "# Scores between video and text is computed by dot products.\n",
        "all_scores = np.dot(text_embd, tf.transpose(video_embd))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d4AwYmODmE9Y"
      },
      "outputs": [],
      "source": [
        "# Display results.\n",
        "html = ''\n",
        "for i, words in enumerate(words_np):\n",
        "  html += display_query_and_results_video(words, all_videos_urls, all_scores[i, :])\n",
        "  html += '<br>'\n",
        "display.HTML(html)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "text_to_video_retrieval_with_s3d_milnce.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
