{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNLUPuRpkFv_"
      },
      "source": [
        "##### Copyright 2022 The TensorFlow Hub Authors.\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "DQcWZm0FkPk-"
      },
      "outputs": [],
      "source": [
        "#@title Copyright 2022 The TensorFlow Hub Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# =============================================================================="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Exbxve1rHlrF"
      },
      "source": [
        "# FILM モデルによるフレーム補間\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMWFVTlbrQ8m"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td><a target=\"_blank\" href=\"https://www.tensorflow.org/hub/tutorials/tf_hub_film_example\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">TensorFlow.org で表示</a></td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/ja/hub/tutorials/tf_hub_film_example.ipynb\">     <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">     Google Colab で実行</a>\n",
        "</td>\n",
        "  <td><a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/ja/hub/tutorials/tf_hub_film_example.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">GitHub でソースを表示</a></td>\n",
        "  <td><a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/ja/hub/tutorials/tf_hub_film_example.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">ノートブックをダウンロード</a></td>\n",
        "  <td><a href=\"https://tfhub.dev/google/film/1\"><img src=\"https://www.tensorflow.org/images/hub_logo_32px.png\">TF Hub モデルを参照</a></td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61H28S7ArUAZ"
      },
      "source": [
        "フレーム補間は、ある画像セットから多数の中間画像を合成するタスクです。この手法は通常、フレームレートのアップサンプリングやスローモーション動画効果の作成に使用されます。\n",
        "\n",
        "この Colab では、FILM モデルを使用してフレーム補間を行います。この Colab には、補間された中間画像から動画を作成するためのコードスニペットも用意されています。\n",
        "\n",
        "FILM の研究の詳細については、以下をお読みください。\n",
        "\n",
        "- Google AI ブログ: [Large Motion Frame Interpolation](https://ai.googleblog.com/2022/10/large-motion-frame-interpolation.html)（大規模なモーションのフレーム補間）\n",
        "- プロジェクトページ: FILM: [Frame Interpolation for Large Motion](https://film-net.github.io/)（大規模なモーションのフレーム補間）\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVX7s6zMulsu"
      },
      "source": [
        "## セットアップ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oi5t2OEJsGBW"
      },
      "outputs": [],
      "source": [
        "!pip install mediapy\n",
        "!sudo apt-get install -y ffmpeg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BA1tq39MjOiF"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "import requests\n",
        "import numpy as np\n",
        "\n",
        "from typing import Generator, Iterable, List, Optional\n",
        "import mediapy as media"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTgXmeYGnT7q"
      },
      "source": [
        "## TFHub からモデルを読み込む\n",
        "\n",
        "TensorFlow Hub からモデルを読み込むには、tfhub ライブラリと、ドキュメント URL のモデルハンドルが必要です。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GojhvyAtjUt0"
      },
      "outputs": [],
      "source": [
        "model = hub.load(\"https://tfhub.dev/google/film/1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOQJPsu2CwPk"
      },
      "source": [
        "## URL またはローカルから画像を読み込む Util 関数\n",
        "\n",
        "この関数は画像を読み込み、後でモデルで使用できるように準備します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BPnh5uhQvFln"
      },
      "outputs": [],
      "source": [
        "_UINT8_MAX_F = float(np.iinfo(np.uint8).max)\n",
        "\n",
        "def load_image(img_url: str):\n",
        "  \"\"\"Returns an image with shape [height, width, num_channels], with pixels in [0..1] range, and type np.float32.\"\"\"\n",
        "\n",
        "  if (img_url.startswith(\"https\")):\n",
        "    user_agent = {'User-agent': 'Colab Sample (https://tensorflow.org)'}\n",
        "    response = requests.get(img_url, headers=user_agent)\n",
        "    image_data = response.content\n",
        "  else:\n",
        "    image_data = tf.io.read_file(img_url)\n",
        "\n",
        "  image = tf.io.decode_image(image_data, channels=3)\n",
        "  image_numpy = tf.cast(image, dtype=tf.float32).numpy()\n",
        "  return image_numpy / _UINT8_MAX_F\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjDFns1zp5y6"
      },
      "source": [
        "FILM のモデル入力は、`time`、`x0`、`x1` をキーとするディクショナリです。\n",
        "\n",
        "- `time`: 補間されるフレームの位置。中間は `0.5` です。\n",
        "- `x0`: 開始フレームです。\n",
        "- `x1`: 最終フレームです。\n",
        "\n",
        "いずれのフレームも、ピクセルの範囲が `[0..1]` になるように正規化されている必要があります（上記の `load_image` で行われます）。\n",
        "\n",
        "`time` は `[0..1]` の値で、生成された画像の場所を示します。入力画像の中間は 0.5 です。\n",
        "\n",
        "3 つの値とも、バッチ次元が必要です。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VEQNQlHGsWSM"
      },
      "outputs": [],
      "source": [
        "# using images from the FILM repository (https://github.com/google-research/frame-interpolation/)\n",
        "\n",
        "image_1_url = \"https://github.com/google-research/frame-interpolation/blob/main/photos/one.png?raw=true\"\n",
        "image_2_url = \"https://github.com/google-research/frame-interpolation/blob/main/photos/two.png?raw=true\"\n",
        "\n",
        "time = np.array([0.5], dtype=np.float32)\n",
        "\n",
        "image1 = load_image(image_1_url)\n",
        "image2 = load_image(image_2_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r6_MQE9EuF_K"
      },
      "outputs": [],
      "source": [
        "input = {\n",
        "    'time': np.expand_dims(time, axis=0), # adding the batch dimension to the time\n",
        "     'x0': np.expand_dims(image1, axis=0), # adding the batch dimension to the image\n",
        "     'x1': np.expand_dims(image2, axis=0)  # adding the batch dimension to the image\n",
        "}\n",
        "mid_frame = model(input)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZkzYE2bptfD"
      },
      "source": [
        "モデルは 2 つの結果を出力しますが、ここで使用するのは `image` キーで、その値が補間されたフレームとなります。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eClVbNFhA5Py"
      },
      "outputs": [],
      "source": [
        "print(mid_frame.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rE2csH3u8ePe"
      },
      "outputs": [],
      "source": [
        "frames = [image1, mid_frame['image'][0].numpy(), image2]\n",
        "\n",
        "media.show_images(frames, titles=['input image one', 'generated image', 'input image two'], height=250)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fS1AT8kn-f_l"
      },
      "source": [
        "では、生成されたフレームから動画を作成しましょう。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oFc53B3p37SH"
      },
      "outputs": [],
      "source": [
        "media.show_video(frames, fps=3, title='FILM interpolated video')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5AOFNkj-lfO"
      },
      "source": [
        "## フレーム補間器ライブラリを定義する\n",
        "\n",
        "ご覧のとおり、トランジションがあまりスムーズではありません。\n",
        "\n",
        "これを改善するには、さらに多くの補間フレームが必要です。\n",
        "\n",
        "単に、中間画像でモデルを何度も実行し続けることもできますが、それよりも良いソリューションがあります。\n",
        "\n",
        "多数の補間画像を生成して動画をよりスムーズにするには、補間器ライブラリを作成します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tsoDv_9geoZn"
      },
      "outputs": [],
      "source": [
        "\"\"\"A wrapper class for running a frame interpolation based on the FILM model on TFHub\n",
        "\n",
        "Usage:\n",
        "  interpolator = Interpolator()\n",
        "  result_batch = interpolator(image_batch_0, image_batch_1, batch_dt)\n",
        "  Where image_batch_1 and image_batch_2 are numpy tensors with TF standard\n",
        "  (B,H,W,C) layout, batch_dt is the sub-frame time in range [0..1], (B,) layout.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def _pad_to_align(x, align):\n",
        "  \"\"\"Pads image batch x so width and height divide by align.\n",
        "\n",
        "  Args:\n",
        "    x: Image batch to align.\n",
        "    align: Number to align to.\n",
        "\n",
        "  Returns:\n",
        "    1) An image padded so width % align == 0 and height % align == 0.\n",
        "    2) A bounding box that can be fed readily to tf.image.crop_to_bounding_box\n",
        "      to undo the padding.\n",
        "  \"\"\"\n",
        "  # Input checking.\n",
        "  assert np.ndim(x) == 4\n",
        "  assert align > 0, 'align must be a positive number.'\n",
        "\n",
        "  height, width = x.shape[-3:-1]\n",
        "  height_to_pad = (align - height % align) if height % align != 0 else 0\n",
        "  width_to_pad = (align - width % align) if width % align != 0 else 0\n",
        "\n",
        "  bbox_to_pad = {\n",
        "      'offset_height': height_to_pad // 2,\n",
        "      'offset_width': width_to_pad // 2,\n",
        "      'target_height': height + height_to_pad,\n",
        "      'target_width': width + width_to_pad\n",
        "  }\n",
        "  padded_x = tf.image.pad_to_bounding_box(x, **bbox_to_pad)\n",
        "  bbox_to_crop = {\n",
        "      'offset_height': height_to_pad // 2,\n",
        "      'offset_width': width_to_pad // 2,\n",
        "      'target_height': height,\n",
        "      'target_width': width\n",
        "  }\n",
        "  return padded_x, bbox_to_crop\n",
        "\n",
        "\n",
        "class Interpolator:\n",
        "  \"\"\"A class for generating interpolated frames between two input frames.\n",
        "\n",
        "  Uses the Film model from TFHub\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, align: int = 64) -> None:\n",
        "    \"\"\"Loads a saved model.\n",
        "\n",
        "    Args:\n",
        "      align: 'If >1, pad the input size so it divides with this before\n",
        "        inference.'\n",
        "    \"\"\"\n",
        "    self._model = hub.load(\"https://tfhub.dev/google/film/1\")\n",
        "    self._align = align\n",
        "\n",
        "  def __call__(self, x0: np.ndarray, x1: np.ndarray,\n",
        "               dt: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"Generates an interpolated frame between given two batches of frames.\n",
        "\n",
        "    All inputs should be np.float32 datatype.\n",
        "\n",
        "    Args:\n",
        "      x0: First image batch. Dimensions: (batch_size, height, width, channels)\n",
        "      x1: Second image batch. Dimensions: (batch_size, height, width, channels)\n",
        "      dt: Sub-frame time. Range [0,1]. Dimensions: (batch_size,)\n",
        "\n",
        "    Returns:\n",
        "      The result with dimensions (batch_size, height, width, channels).\n",
        "    \"\"\"\n",
        "    if self._align is not None:\n",
        "      x0, bbox_to_crop = _pad_to_align(x0, self._align)\n",
        "      x1, _ = _pad_to_align(x1, self._align)\n",
        "\n",
        "    inputs = {'x0': x0, 'x1': x1, 'time': dt[..., np.newaxis]}\n",
        "    result = self._model(inputs, training=False)\n",
        "    image = result['image']\n",
        "\n",
        "    if self._align is not None:\n",
        "      image = tf.image.crop_to_bounding_box(image, **bbox_to_crop)\n",
        "    return image.numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeGYaNBd_7a5"
      },
      "source": [
        "## フレームと動画の生成ユーティリティ関数"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gOJxup6s_1DP"
      },
      "outputs": [],
      "source": [
        "def _recursive_generator(\n",
        "    frame1: np.ndarray, frame2: np.ndarray, num_recursions: int,\n",
        "    interpolator: Interpolator) -> Generator[np.ndarray, None, None]:\n",
        "  \"\"\"Splits halfway to repeatedly generate more frames.\n",
        "\n",
        "  Args:\n",
        "    frame1: Input image 1.\n",
        "    frame2: Input image 2.\n",
        "    num_recursions: How many times to interpolate the consecutive image pairs.\n",
        "    interpolator: The frame interpolator instance.\n",
        "\n",
        "  Yields:\n",
        "    The interpolated frames, including the first frame (frame1), but excluding\n",
        "    the final frame2.\n",
        "  \"\"\"\n",
        "  if num_recursions == 0:\n",
        "    yield frame1\n",
        "  else:\n",
        "    # Adds the batch dimension to all inputs before calling the interpolator,\n",
        "    # and remove it afterwards.\n",
        "    time = np.full(shape=(1,), fill_value=0.5, dtype=np.float32)\n",
        "    mid_frame = interpolator(\n",
        "        np.expand_dims(frame1, axis=0), np.expand_dims(frame2, axis=0), time)[0]\n",
        "    yield from _recursive_generator(frame1, mid_frame, num_recursions - 1,\n",
        "                                    interpolator)\n",
        "    yield from _recursive_generator(mid_frame, frame2, num_recursions - 1,\n",
        "                                    interpolator)\n",
        "\n",
        "\n",
        "def interpolate_recursively(\n",
        "    frames: List[np.ndarray], num_recursions: int,\n",
        "    interpolator: Interpolator) -> Iterable[np.ndarray]:\n",
        "  \"\"\"Generates interpolated frames by repeatedly interpolating the midpoint.\n",
        "\n",
        "  Args:\n",
        "    frames: List of input frames. Expected shape (H, W, 3). The colors should be\n",
        "      in the range[0, 1] and in gamma space.\n",
        "    num_recursions: Number of times to do recursive midpoint\n",
        "      interpolation.\n",
        "    interpolator: The frame interpolation model to use.\n",
        "\n",
        "  Yields:\n",
        "    The interpolated frames (including the inputs).\n",
        "  \"\"\"\n",
        "  n = len(frames)\n",
        "  for i in range(1, n):\n",
        "    yield from _recursive_generator(frames[i - 1], frames[i],\n",
        "                                    times_to_interpolate, interpolator)\n",
        "  # Separately yield the final frame.\n",
        "  yield frames[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X1R2KjhEAHu0"
      },
      "outputs": [],
      "source": [
        "times_to_interpolate = 6\n",
        "interpolator = Interpolator()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZUo8tg1AYvZ"
      },
      "source": [
        "## 補間器の実行"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QMMNjs7sAWTG"
      },
      "outputs": [],
      "source": [
        "input_frames = [image1, image2]\n",
        "frames = list(\n",
        "    interpolate_recursively(input_frames, times_to_interpolate,\n",
        "                                        interpolator))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s9mHHyCAAhrM"
      },
      "outputs": [],
      "source": [
        "print(f'video with {len(frames)} frames')\n",
        "media.show_video(frames, fps=30, title='FILM interpolated video')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0AZKeMVFwAc"
      },
      "source": [
        "詳細については、[FILM のモデルリポジトリ](https://github.com/google-research/frame-interpolation)にアクセスしてください。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8764ry3SGDks"
      },
      "source": [
        "## 引用\n",
        "\n",
        "このモデルとコードが作業に役立つと思われた方は、謝辞に以下の引用を使用してください。\n",
        "\n",
        "```\n",
        "@inproceedings{reda2022film,\n",
        " title = {FILM: Frame Interpolation for Large Motion},\n",
        " author = {Fitsum Reda and Janne Kontkanen and Eric Tabellion and Deqing Sun and Caroline Pantofaru and Brian Curless},\n",
        " booktitle = {The European Conference on Computer Vision (ECCV)},\n",
        " year = {2022}\n",
        "}\n",
        "```\n",
        "\n",
        "```\n",
        "@misc{film-tf,\n",
        "  title = {Tensorflow 2 Implementation of \"FILM: Frame Interpolation for Large Motion\"},\n",
        "  author = {Fitsum Reda and Janne Kontkanen and Eric Tabellion and Deqing Sun and Caroline Pantofaru and Brian Curless},\n",
        "  year = {2022},\n",
        "  publisher = {GitHub},\n",
        "  journal = {GitHub repository},\n",
        "  howpublished = {\\url{https://github.com/google-research/frame-interpolation}}\n",
        "}\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "tf_hub_film_example.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
