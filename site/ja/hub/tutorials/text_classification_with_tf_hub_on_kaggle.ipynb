{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6ZDpd9XzFeN"
      },
      "source": [
        "##### Copyright 2018 The TensorFlow Hub Authors.\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "KUu4vOt5zI9d"
      },
      "outputs": [],
      "source": [
        "# Copyright 2018 The TensorFlow Hub Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# =============================================================================="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ok9PfyoQ2rH_"
      },
      "source": [
        "# TF-Hub で Kaggle の問題を解く方法\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfBg1C5NB3X0"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td><a target=\"_blank\" href=\"https://www.tensorflow.org/hub/tutorials/text_classification_with_tf_hub_on_kaggle\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\"> TensorFlow.orgで表示</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/ja/hub/tutorials/text_classification_with_tf_hub_on_kaggle.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\"> Google Colab で実行</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/ja/hub/tutorials/text_classification_with_tf_hub_on_kaggle.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">GitHub でソースを表示</a></td>\n",
        "  <td><a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/ja/hub/tutorials/text_classification_with_tf_hub_on_kaggle.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">ノートブックをダウンロード/a0}</a></td>\n",
        "  <td><a href=\"https://tfhub.dev/google/nnlm-en-dim128/1\"><img src=\"https://www.tensorflow.org/images/hub_logo_32px.png\">TF Hub モデルを見る</a></td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "556YQZLUO4Ih"
      },
      "source": [
        "TF-Hub は、機械学習の知識を再利用可能なリソース、特にトレーニング済みの**モジュール**としてパッケージ化した知識を共有するためのプラットフォームです。このチュートリアルでは、TF-Hub テキスト埋め込みモジュールを使用して、合理的なベースラインの精度による単純なセンチメント分類器のトレーニングを行います。その後で、予測を Kaggle に送信します。\n",
        "\n",
        "TF-Hub によるテキスト分類と精度を改善するための追加手順に関する詳細なチュートリアルについては、[TF-Hub によるテキスト分類](https://colab.research.google.com/github/tensorflow/hub/blob/master/docs/tutorials/text_classification_with_tf_hub.ipynb)をご覧ください。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4DN769E2O_R"
      },
      "source": [
        "## セットアップ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9KyLct9rq0lo"
      },
      "outputs": [],
      "source": [
        "!pip install -q kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v7hy0bhngTUp"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import zipfile\n",
        "\n",
        "from sklearn import model_selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvgBdeMsuu_3"
      },
      "source": [
        "このチュートリアルでは Kaggle のデータセットを使用するため、Kaggle アカウントの [API トークンの作成](https://github.com/Kaggle/kaggle-api)と、Colab 環境へのトークンのアップロードが必要となります。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nI7C-Zc4urOH"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pathlib\n",
        "\n",
        "# Upload the API token.\n",
        "def get_kaggle():\n",
        "  try:\n",
        "    import kaggle\n",
        "    return kaggle\n",
        "  except OSError:\n",
        "    pass\n",
        "\n",
        "  token_file = pathlib.Path(\"~/.kaggle/kaggle.json\").expanduser()\n",
        "  token_file.parent.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "  try:\n",
        "    from google.colab import files\n",
        "  except ImportError:\n",
        "    raise ValueError(\"Could not find kaggle token.\")\n",
        "\n",
        "  uploaded = files.upload()\n",
        "  token_content = uploaded.get('kaggle.json', None)\n",
        "  if token_content:\n",
        "    token_file.write_bytes(token_content)\n",
        "    token_file.chmod(0o600)\n",
        "  else:\n",
        "    raise ValueError('Need a file named \"kaggle.json\"')\n",
        "  \n",
        "  import kaggle\n",
        "  return kaggle\n",
        "\n",
        "\n",
        "kaggle = get_kaggle()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OPyVxHuiTEE"
      },
      "source": [
        "# はじめに\n",
        "\n",
        "## データ\n",
        "\n",
        "Kaggle の [Sentiment Analysis on Movie Reviews](https://www.kaggle.com/c/sentiment-analysis-on-movie-reviews/data)（映画レビューのセンチメント分析）タスクを解いてみましょう。データセットには、Rotten Tomatoes という映画のレビューの構文サブフレーズが含まれます。これは、フレーズを 1 から 5 の段階で **negative**（否定的）または **positive**（肯定的）にラベル付けするタスクです。\n",
        "\n",
        "API を使用してデータをダウンロードする前に、[コンペのルールに同意](https://www.kaggle.com/c/sentiment-analysis-on-movie-reviews/data)する必要があります。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "both",
        "id": "rKzc-fOGV72G"
      },
      "outputs": [],
      "source": [
        "SENTIMENT_LABELS = [\n",
        "    \"negative\", \"somewhat negative\", \"neutral\", \"somewhat positive\", \"positive\"\n",
        "]\n",
        "\n",
        "# Add a column with readable values representing the sentiment.\n",
        "def add_readable_labels_column(df, sentiment_value_column):\n",
        "  df[\"SentimentLabel\"] = df[sentiment_value_column].replace(\n",
        "      range(5), SENTIMENT_LABELS)\n",
        "    \n",
        "# Download data from Kaggle and create a DataFrame.\n",
        "def load_data_from_zip(path):\n",
        "  with zipfile.ZipFile(path, \"r\") as zip_ref:\n",
        "    name = zip_ref.namelist()[0]\n",
        "    with zip_ref.open(name) as zf:\n",
        "      return pd.read_csv(zf, sep=\"\\t\", index_col=0)\n",
        "\n",
        "\n",
        "# The data does not come with a validation set so we'll create one from the\n",
        "# training set.\n",
        "def get_data(competition, train_file, test_file, validation_set_ratio=0.1):\n",
        "  data_path = pathlib.Path(\"data\")\n",
        "  kaggle.api.competition_download_files(competition, data_path)\n",
        "  competition_path = (data_path/competition)\n",
        "  competition_path.mkdir(exist_ok=True, parents=True)\n",
        "  competition_zip_path = competition_path.with_suffix(\".zip\")\n",
        "\n",
        "  with zipfile.ZipFile(competition_zip_path, \"r\") as zip_ref:\n",
        "    zip_ref.extractall(competition_path)\n",
        "  \n",
        "  train_df = load_data_from_zip(competition_path/train_file)\n",
        "  test_df = load_data_from_zip(competition_path/test_file)\n",
        "\n",
        "  # Add a human readable label.\n",
        "  add_readable_labels_column(train_df, \"Sentiment\")\n",
        "\n",
        "  # We split by sentence ids, because we don't want to have phrases belonging\n",
        "  # to the same sentence in both training and validation set.\n",
        "  train_indices, validation_indices = model_selection.train_test_split(\n",
        "      np.unique(train_df[\"SentenceId\"]),\n",
        "      test_size=validation_set_ratio,\n",
        "      random_state=0)\n",
        "\n",
        "  validation_df = train_df[train_df[\"SentenceId\"].isin(validation_indices)]\n",
        "  train_df = train_df[train_df[\"SentenceId\"].isin(train_indices)]\n",
        "  print(\"Split the training data into %d training and %d validation examples.\" %\n",
        "        (len(train_df), len(validation_df)))\n",
        "\n",
        "  return train_df, validation_df, test_df\n",
        "\n",
        "\n",
        "train_df, validation_df, test_df = get_data(\n",
        "    \"sentiment-analysis-on-movie-reviews\",\n",
        "    \"train.tsv.zip\", \"test.tsv.zip\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFq_EyS1BEyK"
      },
      "source": [
        "注意: このコンペのタスクは、すべてのレビューではなく、レビュー内の個別のフレーズを評価することで、難易度の非常に高いタスクと言えます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "42hgsiWNq5y9"
      },
      "outputs": [],
      "source": [
        "train_df.head(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPuHgx3BWBOg"
      },
      "source": [
        "## モデルをトレーニングする\n",
        "\n",
        "*注意: このタスクは回帰としてもモデル化することが可能です。[TF-Hub によるテキスト分類](https://colab.research.google.com/github/tensorflow/hub/blob/master/docs/tutorials/text_classification_with_tf_hub.ipynb)をご覧ください。*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23U30yEkVq4w"
      },
      "outputs": [],
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self, hub_url):\n",
        "    super().__init__()\n",
        "    self.hub_url = hub_url\n",
        "    self.embed = hub.load(self.hub_url).signatures['default']\n",
        "    self.sequential = tf.keras.Sequential([\n",
        "      tf.keras.layers.Dense(500),\n",
        "      tf.keras.layers.Dense(100),\n",
        "      tf.keras.layers.Dense(5),\n",
        "    ])\n",
        "\n",
        "  def call(self, inputs):\n",
        "    phrases = inputs['Phrase'][:,0]\n",
        "    embedding = 5*self.embed(phrases)['default']\n",
        "    return self.sequential(embedding)\n",
        "\n",
        "  def get_config(self):\n",
        "    return {\"hub_url\":self.hub_url}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JE--GDMM2tSp"
      },
      "outputs": [],
      "source": [
        "model = MyModel(\"https://tfhub.dev/google/nnlm-en-dim128/1\")\n",
        "model.compile(\n",
        "    loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    optimizer=tf.optimizers.Adam(), \n",
        "    metrics = [tf.keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\")])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SRr-lvhstiNw"
      },
      "outputs": [],
      "source": [
        "history = model.fit(x=dict(train_df), y=train_df['Sentiment'],\n",
        "          validation_data=(dict(validation_df), validation_df['Sentiment']),\n",
        "          epochs = 25)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8j7YTRSe7Pj"
      },
      "source": [
        "# 予測\n",
        "\n",
        "検証セットとトレーニングセットの予測を実行します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iGqVNSl87bgN"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zbLg5LzGwAfC"
      },
      "outputs": [],
      "source": [
        "train_eval_result = model.evaluate(dict(train_df), train_df['Sentiment'])\n",
        "validation_eval_result = model.evaluate(dict(validation_df), validation_df['Sentiment'])\n",
        "\n",
        "print(f\"Training set accuracy: {train_eval_result[1]}\")\n",
        "print(f\"Validation set accuracy: {validation_eval_result[1]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DR2IsTF5vuAX"
      },
      "source": [
        "## 混同行列\n",
        "\n",
        "特にマルチクラスの問題におけるもう 1 つの非常に興味深い統計に、[混同行列](https://en.wikipedia.org/wiki/Confusion_matrix)というのがあります。混同行列では、正確および不正確にラベル付けされたサンプルの比率を視覚化することができます。そのため、分類器がどの程度偏っているのか、ラベルの分布に意味があるかどうかを簡単に確認することができます。予測の最大部分が対角線に沿って分散されているのが理想です。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yKUnJFYY8bO_"
      },
      "outputs": [],
      "source": [
        "predictions = model.predict(dict(validation_df))\n",
        "predictions = tf.argmax(predictions, axis=-1)\n",
        "predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fjAs8W_Z9BvP"
      },
      "outputs": [],
      "source": [
        "cm = tf.math.confusion_matrix(validation_df['Sentiment'], predictions)\n",
        "cm = cm/cm.numpy().sum(axis=1)[:, tf.newaxis]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nT71CtArpsKz"
      },
      "outputs": [],
      "source": [
        "sns.heatmap(\n",
        "    cm, annot=True,\n",
        "    xticklabels=SENTIMENT_LABELS,\n",
        "    yticklabels=SENTIMENT_LABELS)\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pic7o2m04weY"
      },
      "source": [
        "次のコードをコードセルに貼り付けて実行することで、簡単に予測を Kaggle に送信することができます。\n",
        "\n",
        "```python\n",
        "test_predictions = model.predict(dict(test_df))\n",
        "test_predictions = np.argmax(test_predictions, axis=-1)\n",
        "\n",
        "result_df = test_df.copy()\n",
        "\n",
        "result_df[\"Predictions\"] = test_predictions\n",
        "\n",
        "result_df.to_csv(\n",
        "    \"predictions.csv\",\n",
        "    columns=[\"Predictions\"],\n",
        "    header=[\"Sentiment\"])\n",
        "kaggle.api.competition_submit(\"predictions.csv\", \"Submitted from Colab\",\n",
        "                              \"sentiment-analysis-on-movie-reviews\")\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50BLu-JX_dlm"
      },
      "source": [
        "送信後、[リーダーボードでその結果を確認](https://www.kaggle.com/c/sentiment-analysis-on-movie-reviews/leaderboard)することができます。"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "text_classification_with_tf_hub_on_kaggle.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
