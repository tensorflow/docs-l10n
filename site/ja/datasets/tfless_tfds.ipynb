{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_nWetWWd_ns"
      },
      "source": [
        "##### Copyright 2023 The TensorFlow Datasets Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "2pHVBk_seED1"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7vSdG6sAIQn"
      },
      "source": [
        "# Jax と PyTorch 用の TFDS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwc5GKHBASdc"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td><a target=\"_blank\" href=\"https://www.tensorflow.org/datasets/tfless_tfds\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">TensorFlow.org で表示</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/ja/datasets/tfless_tfds.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Google Colab で実行</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/ja/datasets/tfless_tfds.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">GitHub でソースを表示</a></td>\n",
        "  <td><a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/ja/datasets/tfless_tfds.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">ノートブックをダウンロード</a></td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ee074e4"
      },
      "source": [
        "TFDS は常に フレームワーク非依存型でした。たとえば、[NumPy 形式](https://www.tensorflow.org/datasets/api_docs/python/tfds/as_numpy)のデータセットを簡単に読み込んで、Jax と PyTorch で使用することができます。\n",
        "\n",
        "TensorFlow とそのデータ読み込みソリューション（[`tf.data`](https://www.tensorflow.org/guide/data)）は、設計上、API の第一級市民です。\n",
        "\n",
        "TensorFlow を使用せずに NumPy のみでデータを読み込めるように、TFDS を拡張しました。これは、Jax や PyTorch などの ML での使用に便利であり、実際に PyTorch ユーザーの場合、TensorFlow では以下のことが発生する可能性があります。\n",
        "\n",
        "- GPU/TPU メモリの予約\n",
        "- CI/CD でのビルド時間の長期化\n",
        "- ランタイム時のインポートの長期化\n",
        "\n",
        "TensorFlow は、データセットを読み取る際の依存関係ではなくなりました。\n",
        "\n",
        "ML パイプラインがサンプルを読み込んで解読し、モデルに提供するには、データローダーが必要です。データローダーは、「ソース/サンプラー/ローダー」パラダイムを使用します。\n",
        "\n",
        "```\n",
        " TFDS dataset       ┌────────────────┐\n",
        "   on disk          │                │\n",
        "        ┌──────────►│      Data      │\n",
        "|..|... │     |     │     source     ├─┐\n",
        "├──┼────┴─────┤     │                │ │\n",
        "│12│image12   │     └────────────────┘ │    ┌────────────────┐\n",
        "├──┼──────────┤                        │    │                │\n",
        "│13│image13   │                        ├───►│      Data      ├───► ML pipeline\n",
        "├──┼──────────┤                        │    │     loader     │\n",
        "│14│image14   │     ┌────────────────┐ │    │                │\n",
        "├──┼──────────┤     │                │ │    └────────────────┘\n",
        "|..|...       |     │     Index      ├─┘\n",
        "                    │    sampler     │\n",
        "                    │                │\n",
        "                    └────────────────┘\n",
        "```\n",
        "\n",
        "- データソースは、TFDS データセットからオンザフライ方式でサンプルにアクセスして解読します。\n",
        "- インデックスサンプラーは、レコードが処理される順序を決定します。これは、レコードを読み取る前にグローバル変換（グローバルシャッフル、シャーディング、複数のエポックの反復など）を実装するのに重要です。\n",
        "- データローダーは、データソースとインデックスサンプラーを利用して、読み込みをオーケストレーションします。パフォーマンスの最適化が可能です（プリフェッチ、マルチプロセッシング、またはマルチスレッドなど）。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UaWdLA3fQDK2"
      },
      "source": [
        "## 要約\n",
        "\n",
        "`tfds.data_source` は、データソースを作成する API で、以下を目的としています。\n",
        "\n",
        "1. 純粋な Python パイプラインでの高速プロトタイピング\n",
        "2. 大規模なデータ集約型 ML パイプラインの管理"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLho3l_Vd0a5"
      },
      "source": [
        "## セットアップ\n",
        "\n",
        "必要な依存関係をインストールしてインポートしましょう。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c4COEsqIdvYH"
      },
      "outputs": [],
      "source": [
        "!pip install array_record\n",
        "!pip install tfds-nightly\n",
        "\n",
        "import os\n",
        "os.environ.pop('TFDS_DATA_DIR', None)\n",
        "\n",
        "import tensorflow_datasets as tfds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjEJeF1Id_JM"
      },
      "source": [
        "## データソース\n",
        "\n",
        "データソースは基本的に Python シーケンスです。そのため、以下のプロトコルを実装する必要があります。\n",
        "\n",
        "```python\n",
        "class RandomAccessDataSource(Protocol):\n",
        "  \"\"\"Interface for datasources where storage supports efficient random access.\"\"\"\n",
        "\n",
        "  def __len__(self) -> int:\n",
        "    \"\"\"Number of records in the dataset.\"\"\"\n",
        "\n",
        "  def __getitem__(self, record_key: int) -> Sequence[Any]:\n",
        "    \"\"\"Retrieves records for the given record_keys.\"\"\"\n",
        "```\n",
        "\n",
        "**警告**: この API は現在も活発に開発されています。特に、現時点では、`__getitem__` は入力で `int` と `list[int]` をサポートする必要があります。将来的には、[標準](https://docs.python.org/3/reference/datamodel.html#object.__getitem__)に従って、おそらく `int` のみがサポートされます。\n",
        "\n",
        "基盤のファイル形式は有効なランダムアクセスをサポートする必要があります。現時点では、TFDS は [`array_record`](https://github.com/google/array_record) に依存しています。\n",
        "\n",
        "[`array_record`](https://github.com/google/array_record) は、[Riegeli](https://github.com/google/riegeli) から派生した新しいファイル形式です。IO 効率の新境地を達成しています。特に、ArrayRecord はレコードインデックスによる同時読み取り、書き込み、およびランダムアクセスをサポートしています。ArrayRecord は Riegeli を基盤としているため、同じ圧縮アルゴリズムをサポートしています。\n",
        "\n",
        "[`fashion_mnist`](https://www.tensorflow.org/datasets/catalog/fashion_mnist) はコンピュータビジョン用の共通データセットです。以下を使用するだけで、TFDS で ArrayRecord ベースのデータを取得することができます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Tslzx0_eEWx"
      },
      "outputs": [],
      "source": [
        "ds = tfds.data_source('fashion_mnist')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlaRrD_SeHLY"
      },
      "source": [
        "`tfds.data_source` は便利なラッパーで、以下に相当します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "duHDKzXReIKB"
      },
      "outputs": [],
      "source": [
        "builder = tfds.builder('fashion_mnist', file_format='array_record')\n",
        "builder.download_and_prepare()\n",
        "ds = builder.as_data_source()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlyIsd0ueKjQ"
      },
      "source": [
        "これは、データソースのディクショナリを出力します。\n",
        "\n",
        "```\n",
        "{\n",
        "  'train': DataSource(name=fashion_mnist, split='train', decoders=None),\n",
        "  'test': DataSource(name=fashion_mnist, split='test', decoders=None),\n",
        "}\n",
        "```\n",
        "\n",
        "`download_and_prepare` が実行し、レコードファイルを生成したら、TensorFlow は不要になります。すべては Python/NumPy で処理されます！\n",
        "\n",
        "TensorFlow をアンインストールして、別のサブプロセスでデータソースを読み込みなおして、このことを確認してみましょう。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mTfSzvaQkSd9"
      },
      "outputs": [],
      "source": [
        "!pip uninstall -y tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3sT5AN7neNT9"
      },
      "outputs": [],
      "source": [
        "%%writefile no_tensorflow.py\n",
        "import os\n",
        "os.environ.pop('TFDS_DATA_DIR', None)\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "try:\n",
        "  import tensorflow as tf\n",
        "except ImportError:\n",
        "  print('No TensorFlow found...')\n",
        "\n",
        "ds = tfds.data_source('fashion_mnist')\n",
        "print('...but the data source could still be loaded...')\n",
        "ds['train'][0]\n",
        "print('...and the records can be decoded.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FxohFdb3kSxh"
      },
      "outputs": [],
      "source": [
        "!python no_tensorflow.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1o8n-BhhePYY"
      },
      "source": [
        "今後のバージョンでは、データセットの準備も TensorFlow を使用せずに行えるようにする予定です。\n",
        "\n",
        "データソースには長さがあります。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qtfl17SQeQ7F"
      },
      "outputs": [],
      "source": [
        "len(ds['train'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-UFBu8leSMp"
      },
      "source": [
        "以下のようにして、データセットの最初の要素にアクセスすると..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFvT2Sx2eToh"
      },
      "outputs": [],
      "source": [
        "%%timeit\n",
        "ds['train'][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTgZskyZeU_D"
      },
      "source": [
        "他の要素へのアクセスと同じように安価に行えます。これが、[ランダムアクセス](https://en.wikipedia.org/wiki/Random_access)の定義です。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cPJFa6aIeWcY"
      },
      "outputs": [],
      "source": [
        "%%timeit\n",
        "ds['train'][1000]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fs3kafYheX6N"
      },
      "source": [
        "特徴量は NumPy DTypes（TensorFlow DTypes ではなく）を使用するようになりました。以下のようにして、特徴量を検査することができます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q7x5AEEaeZja"
      },
      "outputs": [],
      "source": [
        "features = tfds.builder('fashion_mnist').info.features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOnLqAZOeiBi"
      },
      "source": [
        "[特徴量の詳細は、ドキュメント](https://www.tensorflow.org/datasets/api_docs/python/tfds/features)で確認できます。ここでは、画像の形状とクラスの数を取得できます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xk8Vc-y0edlb"
      },
      "outputs": [],
      "source": [
        "shape = features['image'].shape\n",
        "num_classes = features['label'].num_classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFh8pytVemsu"
      },
      "source": [
        "## 純粋な Python で使用する\n",
        "\n",
        "Python でデータソースを反復することで、それを消費できます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ULjO-JDVefNf"
      },
      "outputs": [],
      "source": [
        "for example in ds['train']:\n",
        "  print(example)\n",
        "  break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZRHZNOkenPb"
      },
      "source": [
        "要素を検査すると、すべての特徴量がすでに NumPy を使って解読されているのがわかります。高速であるため、背後では、デフォルトで [OpenCV](https://opencv.org) を使用していますが、OpenCV がインストールされていない場合は、軽量で、画像を高速解読できる [Pillow](python-pillow.org) がデフォルトで使用されます。\n",
        "\n",
        "```\n",
        "{\n",
        "  'image': array([[[0], [0], ..., [0]],\n",
        "                  [[0], [0], ..., [0]]], dtype=uint8),\n",
        "  'label': 2,\n",
        "}\n",
        "```\n",
        "\n",
        "**注意**: 現在、この機能は、`Tensor`、`Image`、および `Scalar` の特徴量でしか使用できません。`Audio` と `Video` 特徴量は、間もなくサポートされる予定です。ご期待ください！"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8kLyK5j1enhc"
      },
      "source": [
        "## PyTorch で使用する\n",
        "\n",
        "PyTorch は、ソース/サンプラー/ローダー構成のパラダイムを使用します。Torch では、「データソース」のことを「データセット」と呼んでいます。[`torch.utils.data`](https://pytorch.org/docs/stable/data.html) には、有効な入力パイプラインを Torch でビルドするために必要なすべての情報が含まれます。\n",
        "\n",
        "通常の[マップスタイルのデータセット](https://pytorch.org/docs/stable/data.html#map-style-datasets)として、TFDS データソースを使用することができます。\n",
        "\n",
        "まず、Torch をインストールしてインポートします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3aKol1fDeyoK"
      },
      "outputs": [],
      "source": [
        "!pip install torch\n",
        "\n",
        "from tqdm import tqdm\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKdJvYywe0YC"
      },
      "source": [
        "トレーニング用のデータソースとテスト用のデータソースはすでに定義済みです（順に、`ds['train']` と `ds['test']`）。サンプラーとローダーを定義しましょう。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_4P2JIrie23f"
      },
      "outputs": [],
      "source": [
        "batch_size = 128\n",
        "train_sampler = torch.utils.data.RandomSampler(ds['train'], num_samples=5_000)\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    ds['train'],\n",
        "    sampler=train_sampler,\n",
        "    batch_size=batch_size,\n",
        ")\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    ds['test'],\n",
        "    sampler=None,\n",
        "    batch_size=batch_size,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVhofOm4e53O"
      },
      "source": [
        "PyTorch で、最初のサンプルを使って、単純なロジスティック回帰をトレーニングし、評価します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HcAmvMa-e42p"
      },
      "outputs": [],
      "source": [
        "class LinearClassifier(torch.nn.Module):\n",
        "  def __init__(self, shape, num_classes):\n",
        "    super(LinearClassifier, self).__init__()\n",
        "    height, width, channels = shape\n",
        "    self.classifier = torch.nn.Linear(height * width * channels, num_classes)\n",
        "\n",
        "  def forward(self, image):\n",
        "    image = image.view(image.size()[0], -1).to(torch.float32)\n",
        "    return self.classifier(image)\n",
        "\n",
        "\n",
        "model = LinearClassifier(shape, num_classes)\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "print('Training...')\n",
        "model.train()\n",
        "for example in tqdm(train_loader):\n",
        "  image, label = example['image'], example['label']\n",
        "  prediction = model(image)\n",
        "  loss = loss_function(prediction, label)\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "print('Testing...')\n",
        "model.eval()\n",
        "num_examples = 0\n",
        "true_positives = 0\n",
        "for example in tqdm(test_loader):\n",
        "  image, label = example['image'], example['label']\n",
        "  prediction = model(image)\n",
        "  num_examples += image.shape[0]\n",
        "  predicted_label = prediction.argmax(dim=1)\n",
        "  true_positives += (predicted_label == label).sum().item()\n",
        "print(f'\\nAccuracy: {true_positives/num_examples * 100:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewKJQpwZe6Ik"
      },
      "source": [
        "## 近日公開: JAX と使用する\n",
        "\n",
        "[Grain](https://github.com/google/grain) と緊密に作業を続けています。Grain はオープンソースの高速で決定論的な Python 用データローダーです。ご期待ください！"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvLEtCWRvvy8"
      },
      "source": [
        "## その他の資料\n",
        "\n",
        "詳細については、[`tfds.data_source`](https://www.tensorflow.org/datasets/api_docs/python/tfds/data_source) API ドキュメントをご覧ください。"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "tfless_tfds.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
