{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tce3stUlHN0L"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow Authors.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tuOe1ymfHZPu"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfBg1C5NB3X0"
      },
      "source": [
        "# TensorFlow Addons 損失 : TripletSemiHardLoss\n",
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>     <a target=\"_blank\" href=\"https://www.tensorflow.org/addons/tutorials/losses_triplet\">     <img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">     TensorFlow.org で表示</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/ja/addons/tutorials/losses_triplet.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Google Colab で実行</a>   </td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/ja/addons/tutorials/losses_triplet.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">GitHub でソースを表示</a>   </td>\n",
        "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/ja/addons/tutorials/losses_triplet.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">ノートブックをダウンロード</a>   </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHxb-dlhMIzW"
      },
      "source": [
        "## 概要\n",
        "\n",
        "このノートブックでは、TensorFlow Addons で TripletSemiHardLoss を使用する方法を紹介します。\n",
        "\n",
        "### リソース:\n",
        "\n",
        "- [FaceNet:  A Unified Embedding for Face Recognition and Clustering](https://arxiv.org/pdf/1503.03832.pdf)\n",
        "- [Oliver Moindrot のブログでは、アルゴリズムがとてもよく詳説されています](https://omoindrot.github.io/triplet-loss)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQwBbFVAyHJ_"
      },
      "source": [
        "## トリプレット損失\n",
        "\n",
        "FaceNet の論文で初めて紹介されたトリプレット損失 (TripletLoss) は、異なるクラスの埋め込み間の距離を最大化しながら、同じクラスの特徴を密接に埋め込むようにニューラルネットワークをトレーニングする損失関数です。 これを行うために、1 つのネガティブサンプルと 1 つのポジティブサンプルと共にアンカーが選択されます。![fig3](https://user-images.githubusercontent.com/18154355/61485418-1cbb1f00-a96f-11e9-8de8-3c46eef5a7dc.png)\n",
        "\n",
        "**損失関数はユークリッド距離関数として記述されます。**\n",
        "\n",
        "[Oliver Moindrot のブログでは、アルゴリズムがとてもよく詳説されています](https://omoindrot.github.io/triplet-loss)\n",
        "\n",
        "ここで、A はアンカー入力、P はポジティブサンプル入力、N はネガティブサンプル入力、およびアルファは、トリプレットが「簡単」になり過ぎて重みを調整する必要がなくなった時に指定するマージンです。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPJ5521HZHeL"
      },
      "source": [
        "## セミハードオンライン学習\n",
        "\n",
        "論文にあるように、最良の結果は「セミハード」として知られるトリプレットから得られます。これらはネガティブがポジティブよりアンカーから離れていても、ポジティブの損失を生成するトリプレットと定義されています。これらのトリプレットを効率的に見つけるために、オンライン学習を利用して、各バッチのセミハードの例のみからトレーニングします。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUXex9ctTuDB"
      },
      "source": [
        "## セットアップ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Vyo25M2ba1P"
      },
      "outputs": [],
      "source": [
        "!pip install -U tensorflow-addons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IqR2PQG4ZaZ0"
      },
      "outputs": [],
      "source": [
        "import io\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WH_7-ZYZYblV"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "import tensorflow_datasets as tfds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_D7CZqkv_Hj"
      },
      "source": [
        "## データを準備する"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iXvByj6wcT7d"
      },
      "outputs": [],
      "source": [
        "def _normalize_img(img, label):\n",
        "    img = tf.cast(img, tf.float32) / 255.\n",
        "    return (img, label)\n",
        "\n",
        "train_dataset, test_dataset = tfds.load(name=\"mnist\", split=['train', 'test'], as_supervised=True)\n",
        "\n",
        "# Build your input pipelines\n",
        "train_dataset = train_dataset.shuffle(1024).batch(32)\n",
        "train_dataset = train_dataset.map(_normalize_img)\n",
        "\n",
        "test_dataset = test_dataset.batch(32)\n",
        "test_dataset = test_dataset.map(_normalize_img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KR01t9v_fxbT"
      },
      "source": [
        "## モデルを構築する"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvOPPuIKhLJi"
      },
      "source": [
        "![fig2](https://user-images.githubusercontent.com/18154355/61485417-1cbb1f00-a96f-11e9-8d6a-94964ce8c4db.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "djpoAvfWNyL5"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(filters=64, kernel_size=2, padding='same', activation='relu', input_shape=(28,28,1)),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=2),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=2),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(256, activation=None), # No activation on final dense layer\n",
        "    tf.keras.layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=1)) # L2 normalize embeddings\n",
        "\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYE-BxhOzFQp"
      },
      "source": [
        "## トレーニングして評価する"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NxfYhtiSzHf-"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "    loss=tfa.losses.TripletSemiHardLoss())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TGBYNGxgVDrj"
      },
      "outputs": [],
      "source": [
        "# Train the network\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Y--0tK69SXf"
      },
      "outputs": [],
      "source": [
        "# Evaluate the network\n",
        "results = model.predict(test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dqSuLdVZGNrZ"
      },
      "outputs": [],
      "source": [
        "# Save test embeddings for visualization in projector\n",
        "np.savetxt(\"vecs.tsv\", results, delimiter='\\t')\n",
        "\n",
        "out_m = io.open('meta.tsv', 'w', encoding='utf-8')\n",
        "for img, labels in tfds.as_numpy(test_dataset):\n",
        "    [out_m.write(str(x) + \"\\n\") for x in labels]\n",
        "out_m.close()\n",
        "\n",
        "\n",
        "try:\n",
        "  from google.colab import files\n",
        "  files.download('vecs.tsv')\n",
        "  files.download('meta.tsv')\n",
        "except:\n",
        "  pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAtj_m6Z_Uwe"
      },
      "source": [
        "## プロジェクターを埋め込む"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4rjlG9rlbVA"
      },
      "source": [
        "ベクトルファイルとメタデータファイルは、次のリンクから読み込んで可視化することができます。https://projector.tensorflow.org/\n",
        "\n",
        "埋め込んだテストデータを UMAP で可視化すると、その結果を見ることができます。 ![embedding](https://user-images.githubusercontent.com/18154355/61600295-e6470380-abfd-11e9-8a00-2b25e7e6916f.png)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "losses_triplet.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
