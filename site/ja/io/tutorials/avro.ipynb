{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tce3stUlHN0L"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow IO Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tuOe1ymfHZPu"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFdPvlXBOdUN"
      },
      "source": [
        "# Avro Dataset API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfBg1C5NB3X0"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>     <a target=\"_blank\" href=\"https://www.tensorflow.org/io/tutorials/avro\">     <img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">     TensorFlow.org で表示</a> </td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/ja/io/tutorials/avro.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Google Colabで実行</a> </td>\n",
        "  <td><a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/ja/io/tutorials/avro.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">GitHubでソースを表示</a></td>\n",
        "      <td><a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/ja/io/tutorials/avro.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">ノートブックをダウンロード</a></td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHxb-dlhMIzW"
      },
      "source": [
        "## 概要\n",
        "\n",
        "Avro Dataset API は、Avro フォーマットデータを <a target=\"_blank\" href=\"https://www.tensorflow.org/api_docs/python/tf/data/Dataset\">TensorFlow Dataset</a> として TensorFlow にネイティブに読み込むことを目的としています。Avro は Protocol Buffers に類似するデータシリアル化システムです。永続データのシリアル化フォーマットと Hadoop ノード間の通信用ワイヤフォーマットの両方を提供できる Apache Hadoop で広く使用されています。Avro データは行指向の圧縮されたバイナリデータフォーマットです。個別の JSON ファイルとして保存されるスキーマに依存しています。Avro フォーマットとスキーマ宣言の仕様については、<a target=\"_blank\" href=\"https://avro.apache.org/docs/current/spec.html\">公式マニュアル</a>をご覧ください。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUXex9ctTuDB"
      },
      "source": [
        "## パッケージのセットアップ\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upgCc3gXybsA"
      },
      "source": [
        "### 必要な tensorflow-io パッケージをインストールする"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uUDYyMZRfkX4"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow-io"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjrZNJQRJP-U"
      },
      "source": [
        "### パッケージをインポートする"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m6KXZuTBWgRm"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_io as tfio\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCgO11GTJaTj"
      },
      "source": [
        "### インポートした TensorFlow と TensorFlow-IO を確認する"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dX74RKfZ_TdF"
      },
      "outputs": [],
      "source": [
        "print(\"tensorflow-io version: {}\".format(tfio.__version__))\n",
        "print(\"tensorflow version: {}\".format(tf.__version__))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0ZKhA6s0Pjp"
      },
      "source": [
        "## 使い方"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CfKVmCvwcL7"
      },
      "source": [
        "### データセットを探索する\n",
        "\n",
        "このチュートリアルの目的により、Avro サンプルデータセットをダウンロードしましょう。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGnbXuVnSo8T"
      },
      "source": [
        "Avro サンプルファイルをダウンロードします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tu01THzWcE-J"
      },
      "outputs": [],
      "source": [
        "!curl -OL https://github.com/tensorflow/io/raw/master/docs/tutorials/avro/train.avro\n",
        "!ls -l train.avro"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJzE6lMwhY7l"
      },
      "source": [
        "Avro サンプルファイルに対応するスキーマファイルをダウンロードします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cpxa6yhLhY7l"
      },
      "outputs": [],
      "source": [
        "!curl -OL https://github.com/tensorflow/io/raw/master/docs/tutorials/avro/train.avsc\n",
        "!ls -l train.avsc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9GCyPWNuOm7"
      },
      "source": [
        "上記の例では、テスト用の Avro データセットは MNIST データセットに基づいて作成されています。TFRecord の元の MNIST データセットは <a target=\"_blank\" href=\"https://www.tensorflow.org/datasets/api_docs/python/tfds/load\">TF 名前付きデータセット</a>から生成されていますが、MNIST データセットはデモデータセットとしては大きすぎるため、単純化するために、ほとんどをトリミングし、最初のいくつかのレコードだけが保持されています。また、元の MNIST データセットの `image` フィールドに追加のトリミングを行い、Avro の `features` フィールドにマッピングしています。そのため、avro ファイル `train.avro` には 4 つのレコードがあり、それぞれに 3 つのフィールドがあります。`features` フィールドは int の配列、`label` フィールドは int または null、`dataType` フィールドは enum です。デコードされた `train.avro` を表示するには以下のようにします（Avro は圧縮フォーマットであるため、<a target=\"_blank\" href=\"https://github.com/tensorflow/io/raw/master/docs/tutorials/avro/train.avro\">元の Avro データファイル</a>は人間が読み取ることはできません）。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upgCc3gXybsB"
      },
      "source": [
        "Avro ファイルを読み取るために必要なパッケージをインストールします。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nS3eTBvjt-O4"
      },
      "outputs": [],
      "source": [
        "!pip install avro\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7XR0agdhY7n"
      },
      "source": [
        "以下のようにして、Avro ファイルを読み取って、人間が読み取れるフォーマットで出力します。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nS3eTBvjt-O5"
      },
      "outputs": [],
      "source": [
        "from avro.io import DatumReader\n",
        "from avro.datafile import DataFileReader\n",
        "\n",
        "import json\n",
        "\n",
        "def print_avro(avro_file, max_record_num=None):\n",
        "    if max_record_num is not None and max_record_num <= 0:\n",
        "        return\n",
        "\n",
        "    with open(avro_file, 'rb') as avro_handler:\n",
        "        reader = DataFileReader(avro_handler, DatumReader())\n",
        "        record_count = 0\n",
        "        for record in reader:\n",
        "            record_count = record_count+1\n",
        "            print(record)\n",
        "            if max_record_num is not None and record_count == max_record_num:\n",
        "               break\n",
        "\n",
        "print_avro(avro_file='train.avro')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKgUPm6JhY7n"
      },
      "source": [
        "まは、`train.avsc` で表現される `train.avro` のスキーマは JSON 形式のファイルです。`train.avsc` を表示するには、以下のようにします。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D-95aom1hY7o"
      },
      "outputs": [],
      "source": [
        "def print_schema(avro_schema_file):\n",
        "    with open(avro_schema_file, 'r') as handle:\n",
        "        parsed = json.load(handle)\n",
        "    print(json.dumps(parsed, indent=4, sort_keys=True))\n",
        "\n",
        "print_schema('train.avsc')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21szKFY1hY7o"
      },
      "source": [
        "### データセットを準備する\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNeBO9m-hY7o"
      },
      "source": [
        "Avro Dataset API を使って、TensorFlow データセットとして `train.avro` を読み込みます。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v-nbLZHKhY7o"
      },
      "outputs": [],
      "source": [
        "features = {\n",
        "    'features[*]': tfio.experimental.columnar.VarLenFeatureWithRank(dtype=tf.int32),\n",
        "    'label': tf.io.FixedLenFeature(shape=[], dtype=tf.int32, default_value=-100),\n",
        "    'dataType': tf.io.FixedLenFeature(shape=[], dtype=tf.string)\n",
        "}\n",
        "\n",
        "schema = tf.io.gfile.GFile('train.avsc').read()\n",
        "\n",
        "dataset = tfio.experimental.columnar.make_avro_record_dataset(file_pattern=['train.avro'],\n",
        "                                                              reader_schema=schema,\n",
        "                                                              features=features,\n",
        "                                                              shuffle=False,\n",
        "                                                              batch_size=3,\n",
        "                                                              num_epochs=1)\n",
        "\n",
        "for record in dataset:\n",
        "    print(record['features[*]'])\n",
        "    print(record['label'])\n",
        "    print(record['dataType'])\n",
        "    print(\"--------------------\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IF_kYz_o2DH4"
      },
      "source": [
        "上記の例は、`train.avro` を TensorFlow Dataset に変換します。データセットの各要素は特徴量名をキーとするディクショナリで、値はスパースまたは密なテンソルに変換されます。たとえば `features`、`label`、および `dataType` フィールドはそれぞれ VarLenFeature(SparseTensor)、FixedLenFeature(DenseTensor)、および FixedLenFeature(DenseTensor) に変換されます。batch_size は 3 であるため、`train.avro` の 3 つのレコードが結果データセットの 1 つの要素に変換されます。ラベルが null の `train.avro` の最初のレコードについては、Avro リーダーによってしていされたデフォルト値（-100）に置換されます。この例では、`train.avro` に合計 4 件のレコードがあります。バッチサイズが 3 であるため、結果データセットには 3 つの要素が含まれ、その最後のバッチサイズは 1 となります。ただし、ユーザーは `drop_final_batch` を有効にすることで、サイズがバッチサイズよりも小さい場合は最後のバッチをドロップするように設定することもできます。以下に例を示します。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bc9vDHyghY7p"
      },
      "outputs": [],
      "source": [
        "dataset = tfio.experimental.columnar.make_avro_record_dataset(file_pattern=['train.avro'],\n",
        "                                                              reader_schema=schema,\n",
        "                                                              features=features,\n",
        "                                                              shuffle=False,\n",
        "                                                              batch_size=3,\n",
        "                                                              drop_final_batch=True,\n",
        "                                                              num_epochs=1)\n",
        "\n",
        "for record in dataset:\n",
        "    print(record)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x45KolnDhY7p"
      },
      "source": [
        "num_parallel_reads を増やして Avro の解析/読み取り並行性を高めることで、Avro データの処理を高速化することも可能です。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z2x-gPj_hY7p"
      },
      "outputs": [],
      "source": [
        "dataset = tfio.experimental.columnar.make_avro_record_dataset(file_pattern=['train.avro'],\n",
        "                                                              reader_schema=schema,\n",
        "                                                              features=features,\n",
        "                                                              shuffle=False,\n",
        "                                                              num_parallel_reads=16,\n",
        "                                                              batch_size=3,\n",
        "                                                              drop_final_batch=True,\n",
        "                                                              num_epochs=1)\n",
        "\n",
        "for record in dataset:\n",
        "    print(record)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6V-nwDJGhY7p"
      },
      "source": [
        "`make_avro_record_dataset` の詳細な使用方法については、<a target=\"_blank\" href=\"https://www.tensorflow.org/io/api_docs/python/tfio/experimental/columnar/make_avro_record_dataset\">API ドキュメント</a>をご覧ください。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIOijGlAhY7p"
      },
      "source": [
        "### Avro データセットで tf.keras モデルをトレーニングする\n",
        "\n",
        "では、MNIST データセットに基づく Avro データセットを使用して、tf.keras モデルトレーニングのエンドツーエンドの例を見てみましょう。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7K85D53hY7q"
      },
      "source": [
        "Avro Dataset API を使って、TensorFlow データセットとして `train.avro` を読み込みます。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VFoeLwIOhY7q"
      },
      "outputs": [],
      "source": [
        "features = {\n",
        "    'features[*]': tfio.experimental.columnar.VarLenFeatureWithRank(dtype=tf.int32),\n",
        "    'label': tf.io.FixedLenFeature(shape=[], dtype=tf.int32, default_value=-100),\n",
        "}\n",
        "\n",
        "\n",
        "schema = tf.io.gfile.GFile('train.avsc').read()\n",
        "\n",
        "dataset = tfio.experimental.columnar.make_avro_record_dataset(file_pattern=['train.avro'],\n",
        "                                                              reader_schema=schema,\n",
        "                                                              features=features,\n",
        "                                                              shuffle=False,\n",
        "                                                              batch_size=1,\n",
        "                                                              num_epochs=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hR2FnIIMhY7q"
      },
      "source": [
        "単純な Keras モデルを定義します。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hGV5rHfJhY7q"
      },
      "outputs": [],
      "source": [
        "def build_and_compile_cnn_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.compile(optimizer='sgd', loss='mse')\n",
        "    return model\n",
        "\n",
        "model = build_and_compile_cnn_model()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tuv9n6HshY7q"
      },
      "source": [
        "### Avro データセットで Keras モデルをトレーニングする\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lb44cUuWhY7r"
      },
      "outputs": [],
      "source": [
        "def extract_label(feature):\n",
        "  label = feature.pop('label')\n",
        "  return tf.sparse.to_dense(feature['features[*]']), label\n",
        "\n",
        "model.fit(x=dataset.map(extract_label), epochs=1, steps_per_epoch=1, verbose=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7K6qAv5rhY7r"
      },
      "source": [
        "Avro データセットは、Avro データを解析し、TensorFlow テンソルに変換することができます。これにはレコード、マップ、ブランチ、列挙のレコードも含まれます。解析情報は、マップとして Avro データセット実装に渡されます。このマップのキーはデータの解析方法をエンコードし、値は、データをどのように TensorFlow テンソルに変換する方法をエンコードし、プリミティブ型（ブール、int、ロング、浮動小数点、ダブル、文字列など）とテンソル型（スパースまたは密など）を決定します。以下に、TensorFlow のパーサータイプ（表 1）とプリミティブ型の変換（表 2）を示します。\n",
        "\n",
        "表 1. サポートされている TensorFlow パーサータイプ:\n",
        "\n",
        "TensorFlow パーサータイプ | TensorFlow テンソル | 説明\n",
        "--- | --- | ---\n",
        "tf.FixedLenFeature([], tf.int32) | 密なテンソル | 固定長の特徴量を解析します。つまり、すべての行の要素数は一定で、たとえば 1 つの要素または配列で、各行に同じ数の要素が必ず含まれます。\n",
        "tf.SparseFeature(index_key=['key_1st_index', 'key_2nd_index'], value_key='key_value', dtype=tf.int64, size=[20, 50]) | スパーステンソル | 各行にインデックスと値の可変長リストがある疎な特徴量を解析します。'index_key' はインデックスを、'value_key' は値を識別します。'dtype' はデータ型です。'size' は各インデックスエントリの期待される最大インデックス値です。\n",
        "tfio.experimental.columnar.VarLenFeatureWithRank([],tf.int64) | スパーステンソル | 可変長の特徴量を解析します。つまり、各データ行の要素数が異なる可能性があります。たとえば、最初の行には 5 つの要素があり、2 番目の行には 7 つの要素があります。\n",
        "\n",
        "表 2. サポートされている、Avro 型から TensorFlow の型への変換　<br>:\n",
        "\n",
        "Avro プリミティブ型 | TensorFlow プリミティブ型\n",
        "--- | ---\n",
        "boolean: バイナリ値 | tf.bool\n",
        "bytes: 8 ビット符号なしバイトのシーケンス | tf.string\n",
        "double: 倍精度 64 ビット IEEE 浮動小数点数 | tf.float64\n",
        "enum: 列挙型 | シンボル名を使った tf.string\n",
        "float: 単精度 32 ビット IEEE 浮動小数点数 | tf.float32\n",
        "int: 32 ビット符号付き整数 | tf.int32\n",
        "long: 64 ビット符号付整数 | tf.int64\n",
        "null: 値無し | デフォルト値を使用\n",
        "string: unicode 文字のシーケンス | tf.string\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PFQPuy5hY7r"
      },
      "source": [
        "Avro Dataset API の一連の包括的な例は、<a target=\"_blank\" href=\"https://github.com/tensorflow/io/blob/master/tests/test_parse_avro.py#L437\">tests</a> 内にあります。\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "Tce3stUlHN0L"
      ],
      "name": "avro.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
