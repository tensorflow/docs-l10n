{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2q27gKz1H20"
      },
      "source": [
        "##### Copyright 2019 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "TUfAcER1oUS6"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gb7qyhNL1yWt"
      },
      "source": [
        "# TensorFlow Lite Model Maker によるテキスト分類"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fw5Y7snSuG51"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td data-parent-segment-id=\"19267938\"><a target=\"_blank\" href=\"https://www.tensorflow.org/lite/tutorials/model_maker_text_classification\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">TensorFlow.org で表示</a></td>\n",
        "  <td data-parent-segment-id=\"19267939\">     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/ja/lite/tutorials/model_maker_text_classification.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Google Colab で実行</a>   </td>\n",
        "  <td data-parent-segment-id=\"19267940\">     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/ja/lite/tutorials/model_maker_text_classification.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">GitHub でソースを表示</a>   </td>\n",
        "  <td data-parent-segment-id=\"19267941\">     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/ja/lite/tutorials/model_maker_text_classification.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">ノートブックをダウンロード</a>   </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sr3q-gvm3cI8"
      },
      "source": [
        "TensorFlow Lite Model Maker ライブラリは、TensorFlow モデルを適合し、オンデバイス ML アプリケーションにこのモデルをデプロイする際に特定の入力データに変換するプロセスを単純化します。\n",
        "\n",
        "このノートブックでは、Model Maker ライブラリを使用して、モバイルデバイスで映画レビューを分類するために一般的に使用されるテキスト分類モデルの適応と変換を示す、エンドツーエンドの例を説明します。テキスト分類モデルは、テキストを既定のカテゴリに分類します。入力は前処理済みのテキストで、出力はカテゴリの確率です。このチュートリアルで使用されるデータセットは肯定的な映画レビューと否定的な映画レビューです。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcLF2PKkSbV3"
      },
      "source": [
        "## 前提条件\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vvAObmTqglq"
      },
      "source": [
        "### 必要なパッケージをインストールする\n",
        "\n",
        "この例を実行するには、[GitHub リポジトリ](https://github.com/tensorflow/examples/tree/master/tensorflow_examples/lite/model_maker) から、Model Maker パッケージを含む必要なパッケージをインストールする必要があります。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qhl8lqVamEty"
      },
      "outputs": [],
      "source": [
        "!pip install -q tflite-model-maker"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6lRhVK9Q_0U"
      },
      "source": [
        "必要なパッケージをインポートします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XtxiUeZEiXpt"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "\n",
        "from tflite_model_maker import model_spec\n",
        "from tflite_model_maker import text_classifier\n",
        "from tflite_model_maker.config import ExportFormat\n",
        "from tflite_model_maker.text_classifier import AverageWordVecSpec\n",
        "from tflite_model_maker.text_classifier import DataLoader\n",
        "\n",
        "import tensorflow as tf\n",
        "assert tf.__version__.startswith('2')\n",
        "tf.get_logger().setLevel('ERROR')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRd13bfetO7B"
      },
      "source": [
        "### サンプルデータをダウンロードする\n",
        "\n",
        "このチュートリアルでは、[SST-2](https://nlp.stanford.edu/sentiment/index.html)（Stanford Sentiment Treebank）を使用します。これは [GLUE](https://gluebenchmark.com/) ベンチマークのタスクの 1 つで、トレーニング用の 67,349 件の映画レビューとテスト用の 872 件の映画レビューが含まれています。データセットには肯定的なレビューと否定的なレビューの 2 つのクラスが含まれます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R2BSkxWg6Rhx"
      },
      "outputs": [],
      "source": [
        "data_dir = tf.keras.utils.get_file(\n",
        "      fname='SST-2.zip',\n",
        "      origin='https://dl.fbaipublicfiles.com/glue/data/SST-2.zip',\n",
        "      extract=True)\n",
        "data_dir = os.path.join(os.path.dirname(data_dir), 'SST-2')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPYTbGrizcTC"
      },
      "source": [
        "SST-2 データセットは TSV 形式で保存されています。TSV と CSV の唯一の違いは、TSV はタブ `\\t` 区切りであるのに対し、CSV はカンマ `,` 区切りであることです。\n",
        "\n",
        "次に、トレーニングデータセットの最初の 5 行を示します。label=0 は否定的、label=1 は肯定的です。\n",
        "\n",
        "文章 | ラベル |  |  |\n",
        "--- | --- | --- | --- | ---\n",
        "hide new secretions from the parental units | 0 |  |  |\n",
        "contains no wit , only labored gags | 0 |  |  |\n",
        "that loves its characters and communicates something rather beautiful about human nature | 1 |  |  |\n",
        "remains utterly satisfied to remain the same throughout | 0 |  |  |\n",
        "on the worst revenge-of-the-nerds clichés the filmmakers could dredge up | 0 |  |  |\n",
        "\n",
        "次に、そのデータセットを Pandas データフレームに読み込み、現在のラベル名（`0` と `1`）を人間が理解しやすいもの（`negative` と `positive`）に変更し、モデルのトレーニングにそれらを使用します。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iLNaOXnl3JQB"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def replace_label(original_file, new_file):\n",
        "  # Load the original file to pandas. We need to specify the separator as\n",
        "  # '\\t' as the training data is stored in TSV format\n",
        "  df = pd.read_csv(original_file, sep='\\t')\n",
        "\n",
        "  # Define how we want to change the label name\n",
        "  label_map = {0: 'negative', 1: 'positive'}\n",
        "\n",
        "  # Excute the label change\n",
        "  df.replace({'label': label_map}, inplace=True)\n",
        "\n",
        "  # Write the updated dataset to a new file\n",
        "  df.to_csv(new_file)\n",
        "\n",
        "# Replace the label name for both the training and test dataset. Then write the\n",
        "# updated CSV dataset to the current folder.\n",
        "replace_label(os.path.join(os.path.join(data_dir, 'train.tsv')), 'train.csv')\n",
        "replace_label(os.path.join(os.path.join(data_dir, 'dev.tsv')), 'dev.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xushUyZXqP59"
      },
      "source": [
        "## クイックスタート\n",
        "\n",
        "テキスト分類モデルのトレーニングには 5 つのステップがあります。\n",
        "\n",
        "**ステップ 1. テキスト分類モデルアーキテクチャを選択する。**\n",
        "\n",
        "ここでは、平均的な単語埋め込みモデルアーキテクチャを使用します。これで、適度な正確度のある小さな高速モデルが生成されます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CtdZ-JDwMimd"
      },
      "outputs": [],
      "source": [
        "spec = model_spec.get('average_word_vec')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yug6gR9qyHui"
      },
      "source": [
        "Model Maker では、[BERT](https://arxiv.org/abs/1810.04805) などのモデルもサポートしています。ほかのアーキテクチャについても興味がある場合は、以下の「[テキスト分類器のモデルアーキテクチャを選択する](#scrollTo=kJ_B8fMDOhMR)」セクションをご覧ください。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5U-A3tw6Y27"
      },
      "source": [
        "**ステップ 2. training と test データを読み込んで、特定の `model_spec` に従ってそれらを処理する。**\n",
        "\n",
        "Model Maker は CSV 形式の入力データを取ることができます。先ほど作成した、人が理解できるラベル名を使った training データセットと test データセットを読み込みます。\n",
        "\n",
        "それぞれのモデルアーキテクチャでは、入力データを特定の方法で処理する必要があります。`DataLoader` は `model_spec` から要件を読み取って、自動的に必要な処理を実行します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HD5BvzWe6YKa"
      },
      "outputs": [],
      "source": [
        "train_data = DataLoader.from_csv(\n",
        "      filename='train.csv',\n",
        "      text_column='sentence',\n",
        "      label_column='label',\n",
        "      model_spec=spec,\n",
        "      is_training=True)\n",
        "test_data = DataLoader.from_csv(\n",
        "      filename='dev.csv',\n",
        "      text_column='sentence',\n",
        "      label_column='label',\n",
        "      model_spec=spec,\n",
        "      is_training=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2uZkLR6N6gDR"
      },
      "source": [
        "**ステップ 3. training データを使用して TensorFlow モデルをトレーニングする。**\n",
        "\n",
        "平均的な単語埋め込みモデルではデフォルトで、`batch_size = 32` が使用されます。そのため、training データセットの 67,349 文を処理するのに 2104 ステップが掛かります。モデルを 10 エポックでトレーニングするため、トレーニングデータセットは 10 回処理されます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kwlYdTcg63xy"
      },
      "outputs": [],
      "source": [
        "model = text_classifier.create(train_data, model_spec=spec, epochs=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BzCHLWJ6h7q"
      },
      "source": [
        "**ステップ 4. test データでモデルを評価する。**\n",
        "\n",
        "training データセット内の文章を使用してテキスト分類モデルをトレーニングしたら、test データセットにある残りの 872 文を使用して、モデルがそれまでに見たことのない新しいデータに対してどのように実行するのかを評価します。\n",
        "\n",
        "デフォルトのバッチサイズは 32 であるため、test データセット内の 872 文の処理に 28 ステップが掛かります。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8xmnl6Yy7ARn"
      },
      "outputs": [],
      "source": [
        "loss, acc = model.evaluate(test_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CgCDMe0e6jlT"
      },
      "source": [
        "**ステップ 5. TensorFlow Lite モデルをエクスポートする。**\n",
        "\n",
        "撮れ人ぐ下テキスト分類を TensorFlow Lite 形式でエクスポートしましょう。モデルの手クスポート先のフォルダを指定します。デフォルトでは、TFLite モデルは平均的な単語埋め込みモデルアーキテクチャ向けにエクスポートされます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hm_UULdW7A9T"
      },
      "outputs": [],
      "source": [
        "model.export(export_dir='average_word_vec')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVxaf3x_7OfB"
      },
      "source": [
        "TensorFlow Lite モデルファイルは、Colab の左サイドバーを使ってダウンロードできます。上記の `export_dir` パラメーターに指定したとおり、`average_word_vec` フォルダに移動して、`model.tflite` ファイルを右クリックして `Download` を選択すると、ローカルコンピューターにダウンロードされます。\n",
        "\n",
        "このモデルは、[NLClassifier API](https://www.tensorflow.org/lite/inference_with_metadata/task_library/nl_classifier)（[TensorFlow Lite Task ライブラリ](https://www.tensorflow.org/lite/inference_with_metadata/task_library/overview)）を使って Android または iOS アプリに統合することができます。\n",
        "\n",
        "実動アプリでモデルがどのように使用されているかについては、「[TFLite テキスト分類のサンプルアプリ](https://github.com/tensorflow/examples/blob/master/lite/examples/text_classification/android/lib_task_api/src/main/java/org/tensorflow/lite/examples/textclassification/client/TextClassificationClient.java#L54)」をご覧ください。\n",
        "\n",
        "*注意 1: Android Studio Model Binding はテキスト分類をまだサポートしていないため、TensorFlow Lite Task ライブラリを使用してください。*\n",
        "\n",
        "*注意 2: TFLite モデルと同じフォルダに `model.json` ファイルがあります。このファイルには、TensorFlow Lite モデル内にバンドルされた[メタデータ](https://www.tensorflow.org/lite/convert/metadata)の JSON 表現が含まれています。モデルのメタデータは、TFLite Task ライブラリがモデルが何を行い、どのようにモデルのデータを事前処理/事後処理するのかを伝える上で役立ちます。`model.json` ファイルは情報提供の目的でのみ存在し、そのコンテンツは TFLite 内に存在するため、ダウンロードする必要はありません。*\n",
        "\n",
        "*注意 3: MobileBERT または BERT-Base アーキテクチャを使ってテキスト分類モデルをトレーニングする場合は、[BertNLClassifier API](https://www.tensorflow.org/lite/inference_with_metadata/task_library/bert_nl_classifier) を代わりに使って、トレーニング済みのモデルをモバイルアプリに組み込む必要があります。*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l65ctmtW7_FF"
      },
      "source": [
        "次のウォークスルーでは、例の詳細を手順を追って説明します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJ_B8fMDOhMR"
      },
      "source": [
        "## テキスト分類器のモデルアーキテクチャを選択する\n",
        "\n",
        "各 `model_spec` オブジェクトは、テキスト分類器の特定のモデルを表現します。TensorFlow Lite Model Maker は現在、[MobileBERT](https://arxiv.org/pdf/2004.02984.pdf)、平均的な単語埋め込み、および [BERT-Base](https://arxiv.org/pdf/1810.04805.pdf) モデルをサポートしています。\n",
        "\n",
        "サポートされているモデル | model_spec の名前 | モデルの説明 | モデルサイズ\n",
        "--- | --- | --- | ---\n",
        "MobileBERT | 'mobilebert_classifier' | BERT ベースより 4.3 倍小さく、5.5 倍高速ですが、オンデバイスアプリケーションに適した、優位性のある結果を達成します。 | 1MB 未満\n",
        "BERT ベース | 'bert_classifier' | NLP タスクで広く使用される標準的な BERT モデルです。 | 25MB、量子化あり <br> 100MB、量子化なし\n",
        "<a>BERT-Base</a> | 'average_word_vec' | RELU アクティベーションを使った平均テキスト単語埋め込みです。 | 300MB\n",
        "\n",
        "クイックスタートでは、兵器的な単語埋め込みモデルを使用しました。[MobileBERT](https://arxiv.org/pdf/2004.02984.pdf) に切り替えて、より高い正確度でモデルをトレーニングしてみましょう。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vEAWuZQ1PFiX"
      },
      "outputs": [],
      "source": [
        "mb_spec = model_spec.get('mobilebert_classifier')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygEncJxtl-nQ"
      },
      "source": [
        "## トレーニングデータを読み込む\n",
        "\n",
        "このチュートリアルでは独自のデータセットをアップロードして進めることができます。データセットをアップロードするには、Colab の左サイドバーを使ってください。\n",
        "\n",
        "<img src=\"https://storage.googleapis.com/download.tensorflow.org/models/tflite/screenshots/model_maker_text_classification.png\" width=\"800\" hspace=\"100\" alt=\"ファイルのアップロード\">\n",
        "\n",
        "データセットをクラウドにアップロードしない場合は、[ガイド](https://github.com/tensorflow/examples/tree/master/tensorflow_examples/lite/model_maker)に従ってローカルでライブラリを実行することもできます。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWAusqz-WD5i"
      },
      "source": [
        "説明をわかりやすくするために、先ほどダウンロードした SST-2 データセットを再利用することにします。`DataLoader.from_csv` メソッドを使って、データを読み込みましょう。\n",
        "\n",
        "モデルのアーキテクチャを変更したため、training データセットと test データセットを読み込み直して新しいプリプロセッシングロジックを適用する必要があります。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I_fOlZsklmlL"
      },
      "outputs": [],
      "source": [
        "train_data = DataLoader.from_csv(\n",
        "      filename='train.csv',\n",
        "      text_column='sentence',\n",
        "      label_column='label',\n",
        "      model_spec=mb_spec,\n",
        "      is_training=True)\n",
        "test_data = DataLoader.from_csv(\n",
        "      filename='dev.csv',\n",
        "      text_column='sentence',\n",
        "      label_column='label',\n",
        "      model_spec=mb_spec,\n",
        "      is_training=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlHvVvv2hw4H"
      },
      "source": [
        "Model Maker ライブラリは、データの読み込みに `from_folder()` メソッドをサポートしています。同じクラスのテキストデータは同じサブディレクトリに存在し、サブフォルダ名はクラス名として前提づけられています。各テキストファイルには、1 つの映画レビューサンプルがあります。`class_labels` パラメータはどのサブフォルダかを指定するために使用されます。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWuoensX4vDA"
      },
      "source": [
        "## TensorFlow モデルをトレーニングする\n",
        "\n",
        "training データを使用してテキスト分類モデルをトレーニングします。\n",
        "\n",
        "*注意: MobileBERT は複雑なモデルであるため、各エポックには Colab GPU で約 10 分掛かります。必ず GPU ランタイムを使用してください。*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TvYSUuJY3QxR"
      },
      "outputs": [],
      "source": [
        "model = text_classifier.create(train_data, model_spec=mb_spec, epochs=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JKI-pNc8idH"
      },
      "source": [
        "モデル構造を詳しく確認します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gd7Hs8TF8n3H"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LP5FPk_tOxoZ"
      },
      "source": [
        "## モデルを評価する\n",
        "\n",
        "test データ使用して、トレーニングしたばかりのモデルを評価し、損失と正確度の値を測定します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A8c2ZQ0J3Riy"
      },
      "outputs": [],
      "source": [
        "loss, acc = model.evaluate(test_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esBGwHE2QxE8"
      },
      "source": [
        "## TensorFlow Lite モデルとしてエクスポートする\n",
        "\n",
        "トレーニングされたモデルを[メタデータ](https://www.tensorflow.org/lite/convert/metadata)で TensorFlow Lite モデル形式に変換し、後でオンデバイス ML アプリケーションで使用できるようにします。ラベルファイルと語彙ファイルはメタデータに埋め込まれています。デフォルトの TFLite ファイル名は `model.tflite` です。\n",
        "\n",
        "多くのオンデバイス ML アプリケーションでは、モデルサイズが重要な要因です。そのため、モデルの量子化を適用して小さくし、実行速度を高められるようにすることをお勧めします。デフォルトのポストトレーニング量子化手法は、BERT および MobileBERT モデルの動的範囲量子化です。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Im6wA9lK3TQB"
      },
      "outputs": [],
      "source": [
        "model.export(export_dir='mobilebert/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w12kvDdHJIGH"
      },
      "source": [
        "TensorFlow Lite モデルファイルは、[BertNLClassifier API](https://www.tensorflow.org/lite/inference_with_metadata/task_library/bert_nl_classifier)（[TensorFlow Lite Task ライブラリ](https://www.tensorflow.org/lite/inference_with_metadata/task_library/overview)）を使ってモバイルアプリに組み込むことができます。これは、平均的な単語埋め込みモデルアーキテクチャでトレーニングしたテキスト分類を組み込むために使用した `NLClassifier` API とは**異なる**ことに注意してください。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVy0ormoMZwL"
      },
      "source": [
        "エクスポート形式は次のいずれかを使用できます。\n",
        "\n",
        "- `ExportFormat.TFLITE`\n",
        "- `ExportFormat.LABEL`\n",
        "- `ExportFormat.VOCAB`\n",
        "- `ExportFormat.SAVED_MODEL`\n",
        "\n",
        "デフォルトでは、モデルのメタデータを含む TensorFlow Lite モデルのみをエクスポートしますが、より詳しく調査するために、モデルに関連するほかのファイルをエクスポートすることを選択することもできます。たとえば、ラベルファイルと語彙ファイルのみをエクスポートする場合は、次のようにします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nbK7nzK_Mfx4"
      },
      "outputs": [],
      "source": [
        "model.export(export_dir='mobilebert/', export_format=[ExportFormat.LABEL, ExportFormat.VOCAB])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZKYthlVrTos"
      },
      "source": [
        "TFLite モデルを `evaluate_tflite` メソッドを使って評価し、その正確度を測定することができます。トレーニング済みの TensorFlow モデルを TFLite 形式に変換して量子化を適用すると、その正確度に影響が与えられるため、デプロイ前に TFLite モデルの正確度を評価することをお勧めします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ochbq95ZrVFX"
      },
      "outputs": [],
      "source": [
        "accuracy = model.evaluate_tflite('mobilebert/model.tflite', test_data)\n",
        "print('TFLite model accuracy: ', accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EoWiA_zX8rxE"
      },
      "source": [
        "## 高度な使用\n",
        "\n",
        "`create` 関数は、Model Maker ライブラリがモデルの作成に使用するドライバー関数です。`model_spec` パラメータによってモデルの仕様が定義されています。現在サポートされているクラスは、`AverageWordVecSpec` と `BertClassifierSpec` です。`create` 関数の構成は、次の手順で行います。\n",
        "\n",
        "1. `model_spec`　に基づいてテキスト分類器のモデルを作成します。\n",
        "2. 分類器モデルをトレーニングします。デフォルトのエポックとデフォルトのバッチサイズは、`default_training_epochs` と `default_batch_size` の変数に従って `model_spec` オブジェクトに設定されています。\n",
        "\n",
        "このセクションでは、モデルやトレーニングハイパーパラメータの調整など、いくつかの高度なトピックを説明します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8VxPiOLy4Gv"
      },
      "source": [
        "### MobileBERT モデルのハイパーパラメータをカスタマイズする\n",
        "\n",
        "調整できるモデルパラメータは次のとおりです。\n",
        "\n",
        "- `seq_len`: モデルにフィードするシーケンスの長さ。\n",
        "- `initializer_range`: すべての重み行列を初期化する truncated_normal_initializer の標準偏差。\n",
        "- `trainable`: トレーニング済みレイヤーがトレーニング可能かどうかを示すブール型。\n",
        "\n",
        "調整できるモデルパラメータは次のとおりです。\n",
        "\n",
        "- `model_dir`: モデルチェックポイントファイルの場所。設定されていない場合、一時ディレクトリが使用されます。\n",
        "- `dropout_rate`: ドロップアウト率。\n",
        "- `learning_rate`: Adam オプティマイザの初期学習率。\n",
        "- `tpu`: 接続先の TPU アドレス。\n",
        "\n",
        "調整できるトレーニングパイプラインは次のとおりです。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4tr9BLcjy4Sh"
      },
      "outputs": [],
      "source": [
        "new_model_spec = model_spec.get('mobilebert_classifier')\n",
        "new_model_spec.seq_len = 256"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwtiksguDfhl"
      },
      "source": [
        "### 平均的な単語埋め込みモデルのハイパーパラメータをカスタマイズする\n",
        "\n",
        "`AverageWordVecModelSpec` クラスの`wordvec_dim` や `seq_len` 変数などのモデルインフラストラクチャを調整できます。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cAOd5_bzH9AQ"
      },
      "source": [
        "たとえば、より大きな `wordvec_dim` の値を使ってモデルをトレーニングできます。モデルを変更する場合、新しい `model_spec` を構築する必要があります。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e9WBN0UTQoMN"
      },
      "outputs": [],
      "source": [
        "new_model_spec = AverageWordVecSpec(wordvec_dim=32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LSTdghTP0Cv"
      },
      "source": [
        "前処理されたデータを取得します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DVZurFBORG3J"
      },
      "outputs": [],
      "source": [
        "new_train_data = DataLoader.from_csv(\n",
        "      filename='train.csv',\n",
        "      text_column='sentence',\n",
        "      label_column='label',\n",
        "      model_spec=new_model_spec,\n",
        "      is_training=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tD7QVVHeRZoM"
      },
      "source": [
        "新しいモデルをトレーニングします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PzpV246_JGEu"
      },
      "outputs": [],
      "source": [
        "model = text_classifier.create(new_train_data, model_spec=new_model_spec)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvQuy7RSDir3"
      },
      "source": [
        "### トレーニングハイパーパラメータの調整\n",
        "\n",
        "モデルの精度に影響する `epochs` や `batch_size` などのトレーニングハイパーパラメータを調整できます。次にその例を示します。\n",
        "\n",
        "- `epochs`: エポックを増やすと、より優れた精度を達成できますが、過適合となる可能性があります。\n",
        "- `batch_size`: 1 つのトレーニングステップに使用するサンプル数。\n",
        "\n",
        "たとえば、エポック数を増やしてトレーニングすることができます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rnWFaYZBG6NW"
      },
      "outputs": [],
      "source": [
        "model = text_classifier.create(new_train_data, model_spec=new_model_spec, epochs=20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUaKQZBQHBQR"
      },
      "source": [
        "新たに再トレーニングされたモデルを 20 個のトレーニングエポックで評価します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BMPi1xflHDSY"
      },
      "outputs": [],
      "source": [
        "new_test_data = DataLoader.from_csv(\n",
        "      filename='dev.csv',\n",
        "      text_column='sentence',\n",
        "      label_column='label',\n",
        "      model_spec=new_model_spec,\n",
        "      is_training=False)\n",
        "\n",
        "loss, accuracy = model.evaluate(new_test_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eq6B9lKMfhS6"
      },
      "source": [
        "### モデルアーキテクチャを変更する\n",
        "\n",
        "`model_spec` を変更して、モデルを変更することができます。次に BERT ベースモデルに変更する例を示します。\n",
        "\n",
        "テキスト分類器の `model_spec` を BERT ベースモデルに変更します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QfFCWrwyggrT"
      },
      "outputs": [],
      "source": [
        "spec = model_spec.get('bert_classifier')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2d7yycrgu6L"
      },
      "source": [
        "残りのステップは同じです。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgiD_tkyQn7l"
      },
      "source": [
        "### TensorFlow Lite モデルでポストトレーニング量子化をカスタマイズする\n",
        "\n",
        "[ポストトレーニング量子化](https://www.tensorflow.org/lite/performance/post_training_quantization)は、モデルサイズと推論レイテンシを縮小できる変換テクニックです。このテクニックでは、モデル精度にほとんど影響することなく、CPU とハードウェアアクセラレータの推論速度も改善することができます。したがって、モデルを改善するために広く使われています。\n",
        "\n",
        "Model Maker ライブラリは、モデルをエクスポートする際に、デフォルトのポストトレーニング量子化手法を適用します。ポストトレーニング量子化をカスタマイズするのであれば、Model Maker は、[QuantizationConfig](https://www.tensorflow.org/lite/api_docs/python/tflite_model_maker/config/QuantizationConfig) を使った複数のポストトレーニング量子化オプションもサポートしています。例として、float16 量子化を見てみましょう。まず、量子化構成を定義します。\n",
        "\n",
        "```python\n",
        "config = QuantizationConfig.for_float16()\n",
        "```\n",
        "\n",
        "次に、その構成で TensorFlow Lite モデルをエクスポートします。\n",
        "\n",
        "```python\n",
        "model.export(export_dir='.', tflite_filename='model_fp16.tflite', quantization_config=config)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkJGvMEx6VD-"
      },
      "source": [
        "# その他の資料\n",
        "\n",
        "技術的な詳細については、[テキスト分類](https://www.tensorflow.org/lite/examples/text_classification/overview)の例をご覧ください。詳細については、以下をご覧ください。\n",
        "\n",
        "- TensorFlow Lite Model Maker の[ガイド](https://www.tensorflow.org/lite/guide/model_maker)と [API リファレンス](https://www.tensorflow.org/lite/api_docs/python/tflite_model_maker)\n",
        "- タスクライブラリ: デプロイ用の [NLClassifier](https://www.tensorflow.org/lite/inference_with_metadata/task_library/nl_classifier) および [BertNLClassifier](https://www.tensorflow.org/lite/inference_with_metadata/task_library/bert_nl_classifier)\n",
        "- エンドツーエンドリファレンスアプリ: [Android](https://github.com/tensorflow/examples/tree/master/lite/examples/text_classification/android) およおび [iOS](https://github.com/tensorflow/examples/tree/master/lite/examples/text_classification/ios)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "model_maker_text_classification.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
