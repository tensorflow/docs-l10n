{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vD3L4qeREvg"
      },
      "source": [
        "##### Copyright 2021 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "qLCxmWRyRMZE"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4k5PoHrgJQOU"
      },
      "source": [
        "# TFLite向けのJaxモデル変換\n",
        "\n",
        "## 概要\n",
        "\n",
        "注意: これは新しい API であり、pip install tf-nightly 経由でのみ使用できます。また、TensorFlow バージョン 2.7 で提供される予定です。この API は実験段階であり、変更される可能性があります。\n",
        "\n",
        "この CodeLab では、Jax を使用して MNIST 認識のモデルを構築する方法と、それを TensorFlow Lite に変換する方法について説明します。また、トレーニング後の量子化によって、Jaxに変換されたモデルを最適化する方法についても説明します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8cfOBcjSByO"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>     <a target=\"_blank\" href=\"https://www.tensorflow.org/lite/examples/jax_conversion/overview\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">TensorFlow.org で表示</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/ja/lite/examples/jax_conversion/overview.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Google Colab で実行</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/ja/lite/examples/jax_conversion/overview.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">GitHub でソースを表示</a>\n",
        "</td>\n",
        "  <td><a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/ja/lite/examples/jax_conversion/overview.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">ノートブックをダウンロード</a></td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lq-T8XZMJ-zv"
      },
      "source": [
        "## 前提条件\n",
        "\n",
        "最新の TensorFlow nightly pip ビルドでこの機能を試すことをお勧めします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EV04hKdrnE4f"
      },
      "outputs": [],
      "source": [
        "!pip install tf-nightly --upgrade\n",
        "!pip install jax --upgrade\n",
        "!pip install jaxlib --upgrade"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAeY43k9KM55"
      },
      "source": [
        "## データの準備\n",
        "\n",
        "MNIST データ、Keras データセット、プリプロセスをダウンロードします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qSOPSZJn1_Tj"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import functools\n",
        "\n",
        "import time\n",
        "import itertools\n",
        "\n",
        "import numpy.random as npr\n",
        "\n",
        "import jax.numpy as jnp\n",
        "from jax import jit, grad, random\n",
        "from jax.example_libraries import optimizers\n",
        "from jax.example_libraries import stax\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hdJIt3Da2Qn1"
      },
      "outputs": [],
      "source": [
        "def _one_hot(x, k, dtype=np.float32):\n",
        "  \"\"\"Create a one-hot encoding of x of size k.\"\"\"\n",
        "  return np.array(x[:, None] == np.arange(k), dtype)\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
        "train_images = train_images.astype(np.float32)\n",
        "test_images = test_images.astype(np.float32)\n",
        "\n",
        "train_labels = _one_hot(train_labels, 10)\n",
        "test_labels = _one_hot(test_labels, 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eFhx85YKlEY"
      },
      "source": [
        "## Jax で MNIST モデルを構築する"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mi3TKB9nnQdK"
      },
      "outputs": [],
      "source": [
        "def loss(params, batch):\n",
        "  inputs, targets = batch\n",
        "  preds = predict(params, inputs)\n",
        "  return -jnp.mean(jnp.sum(preds * targets, axis=1))\n",
        "\n",
        "def accuracy(params, batch):\n",
        "  inputs, targets = batch\n",
        "  target_class = jnp.argmax(targets, axis=1)\n",
        "  predicted_class = jnp.argmax(predict(params, inputs), axis=1)\n",
        "  return jnp.mean(predicted_class == target_class)\n",
        "\n",
        "init_random_params, predict = stax.serial(\n",
        "    stax.Flatten,\n",
        "    stax.Dense(1024), stax.Relu,\n",
        "    stax.Dense(1024), stax.Relu,\n",
        "    stax.Dense(10), stax.LogSoftmax)\n",
        "\n",
        "rng = random.PRNGKey(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRtnOBdJLd63"
      },
      "source": [
        "## モデルのトレーニングと評価"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SWbYRyj7LYZt"
      },
      "outputs": [],
      "source": [
        "step_size = 0.001\n",
        "num_epochs = 10\n",
        "batch_size = 128\n",
        "momentum_mass = 0.9\n",
        "\n",
        "\n",
        "num_train = train_images.shape[0]\n",
        "num_complete_batches, leftover = divmod(num_train, batch_size)\n",
        "num_batches = num_complete_batches + bool(leftover)\n",
        "\n",
        "def data_stream():\n",
        "  rng = npr.RandomState(0)\n",
        "  while True:\n",
        "    perm = rng.permutation(num_train)\n",
        "    for i in range(num_batches):\n",
        "      batch_idx = perm[i * batch_size:(i + 1) * batch_size]\n",
        "      yield train_images[batch_idx], train_labels[batch_idx]\n",
        "batches = data_stream()\n",
        "\n",
        "opt_init, opt_update, get_params = optimizers.momentum(step_size, mass=momentum_mass)\n",
        "\n",
        "@jit\n",
        "def update(i, opt_state, batch):\n",
        "  params = get_params(opt_state)\n",
        "  return opt_update(i, grad(loss)(params, batch), opt_state)\n",
        "\n",
        "_, init_params = init_random_params(rng, (-1, 28 * 28))\n",
        "opt_state = opt_init(init_params)\n",
        "itercount = itertools.count()\n",
        "\n",
        "print(\"\\nStarting training...\")\n",
        "for epoch in range(num_epochs):\n",
        "  start_time = time.time()\n",
        "  for _ in range(num_batches):\n",
        "    opt_state = update(next(itercount), opt_state, next(batches))\n",
        "  epoch_time = time.time() - start_time\n",
        "\n",
        "  params = get_params(opt_state)\n",
        "  train_acc = accuracy(params, (train_images, train_labels))\n",
        "  test_acc = accuracy(params, (test_images, test_labels))\n",
        "  print(\"Epoch {} in {:0.2f} sec\".format(epoch, epoch_time))\n",
        "  print(\"Training set accuracy {}\".format(train_acc))\n",
        "  print(\"Test set accuracy {}\".format(test_acc))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Y1OZBhfQhOj"
      },
      "source": [
        "## TFLite モデルに変換する\n",
        "\n",
        "次の手順を実行します。\n",
        "\n",
        "1. Jax `predict` 関数へのパラメーターを `functools.partial` でインライン化します。\n",
        "2. `jnp.zeros` を作成します。これは Jax でモデルを追跡するために使用される「プレースホルダー」テンソルです。\n",
        "3. `experimental_from_jax` を呼び出します。\n",
        "\n",
        "> - `serving_func` がリストでラップされます。\n",
        "> - 入力は特定の名前に関連付けられ、リストでラップされた配列として渡されます。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6pcqKZqdNTmn"
      },
      "outputs": [],
      "source": [
        "serving_func = functools.partial(predict, params)\n",
        "x_input = jnp.zeros((1, 28, 28))\n",
        "converter = tf.lite.TFLiteConverter.experimental_from_jax(\n",
        "    [serving_func], [[('input1', x_input)]])\n",
        "tflite_model = converter.convert()\n",
        "with open('jax_mnist.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqEhzaJPSPS1"
      },
      "source": [
        "## 変換された TFLite モデルを確認する\n",
        "\n",
        "変換されたモデルの結果を Jax モデルと比較します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "acj2AYzjSlaY"
      },
      "outputs": [],
      "source": [
        "expected = serving_func(train_images[0:1])\n",
        "\n",
        "# Run the model with TensorFlow Lite\n",
        "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
        "interpreter.allocate_tensors()\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "interpreter.set_tensor(input_details[0][\"index\"], train_images[0:1, :, :])\n",
        "interpreter.invoke()\n",
        "result = interpreter.get_tensor(output_details[0][\"index\"])\n",
        "\n",
        "# Assert if the result of TFLite model is consistent with the JAX model.\n",
        "np.testing.assert_almost_equal(expected, result, 1e-5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qy9Gp4H2SjBL"
      },
      "source": [
        "## モデルを最適化する\n",
        "\n",
        "モデルを最適化するために、`representative_dataset` を提供してトレーニング後の量子化を実行します。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KI0rLV-Meg-2"
      },
      "outputs": [],
      "source": [
        "def representative_dataset():\n",
        "  for i in range(1000):\n",
        "    x = train_images[i:i+1]\n",
        "    yield [x]\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.experimental_from_jax(\n",
        "    [serving_func], [[('x', x_input)]])\n",
        "tflite_model = converter.convert()\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.representative_dataset = representative_dataset\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "tflite_quant_model = converter.convert()\n",
        "with open('jax_mnist_quant.tflite', 'wb') as f:\n",
        "  f.write(tflite_quant_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15xQR3JZS8TV"
      },
      "source": [
        "## 最適化されたモデルを評価する"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X3oOm0OaevD6"
      },
      "outputs": [],
      "source": [
        "expected = serving_func(train_images[0:1])\n",
        "\n",
        "# Run the model with TensorFlow Lite\n",
        "interpreter = tf.lite.Interpreter(model_content=tflite_quant_model)\n",
        "interpreter.allocate_tensors()\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "interpreter.set_tensor(input_details[0][\"index\"], train_images[0:1, :, :])\n",
        "interpreter.invoke()\n",
        "result = interpreter.get_tensor(output_details[0][\"index\"])\n",
        "\n",
        "# Assert if the result of TFLite model is consistent with the Jax model.\n",
        "np.testing.assert_almost_equal(expected, result, 1e-5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqHXCNa3myor"
      },
      "source": [
        "## 量子化されたモデルサイズを比較する\n",
        "\n",
        "量子化されたモデルのサイズは元のモデルの 4 分の 1 のサイズになることがわかります。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imFPw007juVG"
      },
      "outputs": [],
      "source": [
        "!du -h jax_mnist.tflite\n",
        "!du -h jax_mnist_quant.tflite"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "overview.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
