{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FhGuhbZ6M5tl"
      },
      "source": [
        "##### Copyright 2022 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "AwOEIRJC6Une"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIdT9iu_Z4Rb"
      },
      "source": [
        "# Core API による行列近似"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBIlTPscrIT9"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td><a target=\"_blank\" href=\"https://www.tensorflow.org/guide/core/matrix_core\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">     TensorFlow.org で表示</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/ja/guide/core/matrix_core.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Google Colabで実行</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/ja/guide/core/matrix_core.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">GitHub でソースを表示</a></td>\n",
        "  <td><a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/ja/guide/core/matrix_core.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">ノートブックをダウンロード</a></td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGw8TF2vtzru"
      },
      "source": [
        "## はじめに\n",
        "\n",
        "このノートブックでは、[TensorFlow コアの低レベル API](https://www.tensorflow.org/guide/core) を使用して、TensorFlow の高性能科学計算プラットフォームとしての機能を紹介します。TensorFlow Core とその意図するユースケースの詳細については、[Core API の概要](https://www.tensorflow.org/guide/core)を参照してください。\n",
        "\n",
        "このチュートリアルでは、[特異値分解](https://developers.google.com/machine-learning/recommendation/collaborative/matrix)（SVD）の手法と、その低階数近似問題への応用について説明します。SVD は、実数または複素数の行列を因数分解するために使用され、画像圧縮などのデータ サイエンスのさまざまなユース ケースがあります。このチュートリアルの画像は、Google Brain の [Imagen](https://imagen.research.google/) プロジェクトからのものです。 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_FdwaovEkCC"
      },
      "source": [
        "> ![svd_intro](http://tensorflow.org/images/core/svd_intro.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nchsZfwEVtVs"
      },
      "source": [
        "## セットアップ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1rRo8oNqZ-Rj"
      },
      "outputs": [],
      "source": [
        "import matplotlib\n",
        "from matplotlib.image import imread\n",
        "from matplotlib import pyplot as plt\n",
        "import requests\n",
        "# Preset Matplotlib figure sizes.\n",
        "matplotlib.rcParams['figure.figsize'] = [16, 9]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9xQKvCJ85kCQ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "so_ewq3gAoEI"
      },
      "source": [
        "## SVD の基礎\n",
        "\n",
        "行列の特異値分解 ${\\mathrm{A}}$ は、次の因数分解によって決定されます。\n",
        "\n",
        "$${\\mathrm{A}} = {\\mathrm{U}} \\Sigma {\\mathrm{V}}^T$$\n",
        "\n",
        "ここでは、それぞれ以下を意味します。\n",
        "\n",
        "- $\\underset{m \\times n}{\\mathrm{A}}$: 入力行列、$m \\geq n$\n",
        "- $\\underset{m \\times n}{\\mathrm{U}}$: 直交行列、 ${\\mathrm{U}}^T{\\mathrm{U}} = {\\mathrm{I}}$ 各列で $u_i$、${\\mathrm{A}}$ の左特異ベクトルを表す\n",
        "- $\\underset{n \\times n}{\\Sigma}$: 各対角要素を持つ対角行列、$\\sigma_i$、${\\mathrm{A}}$ の特異値を表す\n",
        "- $\\underset{n \\times n}{{\\mathrm{V}}^T}$: 直交行列、${\\mathrm{V}}^T{\\mathrm{V}} = {\\mathrm{I}}$、各行 $v_i$ は、${\\mathrm{A}}$ の右特異ベクトルを表す\n",
        "\n",
        "$m < n$ の場合、${\\mathrm{U}}$ と $\\Sigma$ の次元はともに $(m \\times m)$ であり、${\\mathrm{V}}^T$ の次元は $(m \\times n)$ です。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enGGGXCQKNv8"
      },
      "source": [
        "> ![svd_full](http://tensorflow.org/images/core/svd_full.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NlP-cBdSKLtc"
      },
      "source": [
        "TensorFlow の線形代数パッケージには関数 `tf.linalg.svd` があり、1 つ以上の行列の特異値分解を計算するために使用できます。まず、単純な行列を定義し、その SVD 因数分解を計算します。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C3QAcgyoeIpv"
      },
      "outputs": [],
      "source": [
        "A = tf.random.uniform(shape=[40,30])\n",
        "# Compute the SVD factorization\n",
        "s, U, V = tf.linalg.svd(A)\n",
        "# Define Sigma and V Transpose\n",
        "S = tf.linalg.diag(s)\n",
        "V_T = tf.transpose(V)\n",
        "# Reconstruct the original matrix\n",
        "A_svd = U@S@V_T\n",
        "# Visualize \n",
        "plt.bar(range(len(s)), s);\n",
        "plt.xlabel(\"Singular value rank\")\n",
        "plt.ylabel(\"Singular value\")\n",
        "plt.title(\"Bar graph of singular values\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6H_C9WhFACm4"
      },
      "source": [
        "`tf.einsum` 関数を使用すると `tf.linalg.svd` の出力から行列再構成を直接計算できます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TPE6QeMtADUn"
      },
      "outputs": [],
      "source": [
        "A_svd = tf.einsum('s,us,vs -> uv',s,U,V)\n",
        "print('\\nReconstructed Matrix, A_svd', A_svd)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1m6JIsM9DLP"
      },
      "source": [
        "## SVD による低階数近似\n",
        "\n",
        "行列 ${\\mathrm{A}}$ の階数は、その列がまたがるベクトル空間の次元によって決まります。SVD は、より低い階数の行列を近似するために使用し、その結果として行列によって表される情報を格納するために必要なデータの次元を削減できます。\n",
        "\n",
        "SVD による ${\\mathrm{A}}$ の階数 r 近似は、次の式で定義されます。\n",
        "\n",
        "$${\\mathrm{A_r}} = {\\mathrm{U_r}} \\Sigma_r {\\mathrm{V_r}}^T$$\n",
        "\n",
        "ここでは、それぞれ以下を意味します。\n",
        "\n",
        "- $\\underset{m \\times r}{\\mathrm{U_r}}$: ${\\mathrm{U}}$ の最初の $r$ 列からなる行列\n",
        "- $\\underset{r \\times r}{\\Sigma_r}$: $\\Sigma$ の最初の $r$ 特異値からなる対角行列\n",
        "- $\\underset{r \\times n}{\\mathrm{V_r}}^T$: ${\\mathrm{V}}^T$ の最初の $r$ 行からなる行列"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJWMJu36QyUV"
      },
      "source": [
        "> ![svd_approx](http://tensorflow.org/images/core/svd_approx.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkiVUxeaQybq"
      },
      "source": [
        "まず、与えられた行列のランク r 近似を計算する関数を記述します。この低ランク近似手順は、画像圧縮に使用されます。したがって、各概算の物理データサイズを計算することにも役立ちます。単純化するために、ランク r 近似行列のデータサイズが、近似を計算するために必要な要素数の合計に等しいと仮定します。次に、元の行列 $\\mathrm{A}$  のランク r 近似 $\\mathrm{A}_r$ と誤差行列 $|\\mathrm{A} - \\mathrm{A}_r|$ を視覚化する関数を記述します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2oY3pMPagJrO"
      },
      "outputs": [],
      "source": [
        "def rank_r_approx(s, U, V, r, verbose=False):\n",
        "  # Compute the matrices necessary for a rank-r approximation\n",
        "  s_r, U_r, V_r = s[..., :r], U[..., :, :r], V[..., :, :r] # ... implies any number of extra batch axes\n",
        "  # Compute the low-rank approximation and its size\n",
        "  A_r = tf.einsum('...s,...us,...vs->...uv',s_r,U_r,V_r)\n",
        "  A_r_size = tf.size(U_r) + tf.size(s_r) + tf.size(V_r)\n",
        "  if verbose:\n",
        "    print(f\"Approximation Size: {A_r_size}\")\n",
        "  return A_r, A_r_size\n",
        "\n",
        "def viz_approx(A, A_r):\n",
        "  # Plot A, A_r, and A - A_r\n",
        "  vmin, vmax = 0, tf.reduce_max(A)\n",
        "  fig, ax = plt.subplots(1,3)\n",
        "  mats = [A, A_r, abs(A - A_r)]\n",
        "  titles = ['Original A', 'Approximated A_r', 'Error |A - A_r|']\n",
        "  for i, (mat, title) in enumerate(zip(mats, titles)):\n",
        "    ax[i].pcolormesh(mat, vmin=vmin, vmax=vmax)\n",
        "    ax[i].set_title(title)\n",
        "    ax[i].axis('off')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O3ZRkYCkX2FQ"
      },
      "outputs": [],
      "source": [
        "print(f\"Original Size of A: {tf.size(A)}\")\n",
        "s, U, V = tf.linalg.svd(A)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S1DR83VMX4cM"
      },
      "outputs": [],
      "source": [
        "# Rank-15 approximation\n",
        "A_15, A_15_size = rank_r_approx(s, U, V, 15, verbose = True)\n",
        "viz_approx(A, A_15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KgFT70XFX57E"
      },
      "outputs": [],
      "source": [
        "# Rank-3 approximation\n",
        "A_3, A_3_size = rank_r_approx(s, U, V, 3, verbose = True)\n",
        "viz_approx(A, A_3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DS4XoSlTJgX0"
      },
      "source": [
        "予想どおり、低い階数を使用すると、近似の精度が低下しますが、多くの場合、現実のシナリオでは低階数近似の品質は十分です。また、SVD を使用した低階数近似の主な目的は、データの次元を削減することで、データ自体のディスク領域を削減することではありませんが、入力行列が高次元になると、多く場合、低階数近似によりデータサイズを削減できます。この利点のため、このプロセスは画像圧縮の問題に適用できます。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IhsaiOnnZs6M"
      },
      "source": [
        "## 画像の読み込み\n",
        "\n",
        "次の画像は、[Imagen](https://imagen.research.google/) ホームページで入手できます。Imagen は、Google Research の Brain チームによって開発されたテキストから画像を生成する拡散モデルです。AI は、「タイムズスクエアで自転車に乗っているコーギー犬の写真。この犬はサングラスをかけてビーチハットをかぶっている。」というプロンプトに基づいて、この画像を作成しました。なんてクールなのでしょう！ また、以下の URL を任意の .jpg リンクに変更して、選択したカスタム画像を読み込むこともできます。\n",
        "\n",
        "画像を読み込んで視覚化することから始めます。 JPEG ファイルを読み取った後、Matplotlib は行列 ${\\mathrm{I}}$ を $(m \\times n \\times 3)$ の形状で出力します。これは、それぞれ赤、緑、青の 3 つのカラー チャネルを持つ 2 次元画像を表します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OVsZOQUAZ2C7"
      },
      "outputs": [],
      "source": [
        "img_link = \"https://imagen.research.google/main_gallery_images/a-photo-of-a-corgi-dog-riding-a-bike-in-times-square.jpg\"\n",
        "img_path = requests.get(img_link, stream=True).raw\n",
        "I = imread(img_path, 0)\n",
        "print(\"Input Image Shape:\", I.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qvs7uftcZ54x"
      },
      "outputs": [],
      "source": [
        "def show_img(I):\n",
        "  # Display the image in matplotlib\n",
        "  img = plt.imshow(I)\n",
        "  plt.axis('off')\n",
        "  return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZbesXO3HZ6Qs"
      },
      "outputs": [],
      "source": [
        "show_img(I)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdnUBVg_JoOa"
      },
      "source": [
        "## 画像圧縮アルゴリズム\n",
        "\n",
        "次に、SVD を使用して、サンプル画像の低階数近似を計算します。画像の形状は $(1024 \\times 1024 \\times 3)$ であり、SVD 理論は 2 次元行列にのみ適用されます。これは、サンプル画像を、3 つのカラー チャネルのそれぞれに対応する 3 つの等しいサイズの行列にバッチ処理する必要があることを意味します。そのためには、行列を $(3 \\times 1024 \\times 1024)$ の形状になるように転置します。近似誤差を明確に視覚化するために、画像の RGB 値を $[0,255]$ から $[0,1]$ に再スケーリングします。概算値を視覚化する前に、この間隔内に収まるようにクリップすることを忘れないでください。これには `tf.clip_by_value` 関数が役立ちます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i7DDp0h7oSIk"
      },
      "outputs": [],
      "source": [
        "def compress_image(I, r, verbose=False):\n",
        "  # Compress an image with the SVD given a rank \n",
        "  I_size = tf.size(I)\n",
        "  print(f\"Original size of image: {I_size}\")\n",
        "  # Compute SVD of image\n",
        "  I = tf.convert_to_tensor(I)/255\n",
        "  I_batched = tf.transpose(I, [2, 0, 1]) # einops.rearrange(I, 'h w c -> c h w')\n",
        "  s, U, V = tf.linalg.svd(I_batched)\n",
        "  # Compute low-rank approximation of image across each RGB channel\n",
        "  I_r, I_r_size = rank_r_approx(s, U, V, r)\n",
        "  I_r = tf.transpose(I_r, [1, 2, 0]) # einops.rearrange(I_r, 'c h w -> h w c')\n",
        "  I_r_prop = (I_r_size / I_size)\n",
        "  if verbose:\n",
        "    # Display compressed image and attributes\n",
        "    print(f\"Number of singular values used in compression: {r}\")\n",
        "    print(f\"Compressed image size: {I_r_size}\")\n",
        "    print(f\"Proportion of original size: {I_r_prop:.3f}\")\n",
        "    ax_1 = plt.subplot(1,2,1)\n",
        "    show_img(tf.clip_by_value(I_r,0.,1.))\n",
        "    ax_1.set_title(\"Approximated image\")\n",
        "    ax_2 = plt.subplot(1,2,2)\n",
        "    show_img(tf.clip_by_value(0.5+abs(I-I_r),0.,1.))\n",
        "    ax_2.set_title(\"Error\")\n",
        "  return I_r, I_r_prop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGQ_rTyKDX9F"
      },
      "source": [
        "次に、次の階数の階数 r 近似を計算します: 100、50、10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7GlKkVLGDjre"
      },
      "outputs": [],
      "source": [
        "I_100, I_100_prop = compress_image(I, 100, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XdvUkF5_E75D"
      },
      "outputs": [],
      "source": [
        "I_50, I_50_prop = compress_image(I, 50, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MsCNZ8416Sbk"
      },
      "outputs": [],
      "source": [
        "I_10, I_10_prop = compress_image(I, 10, verbose=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfYYBhcuNkvH"
      },
      "source": [
        "## 近似の評価\n",
        "\n",
        "様々な興味深い方法で有効性を測定し、行列近似をより詳細に制御できます。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2Lotde9Zg7v"
      },
      "source": [
        "### 圧縮係数と階数\n",
        "\n",
        "上記の各近似値について、階数によってデータサイズがどのように変化するかを観察します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O1ariNQe6Wbl"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(11,6))\n",
        "plt.plot([100, 50, 10], [I_100_prop, I_50_prop, I_10_prop])\n",
        "plt.xlabel(\"Rank\")\n",
        "plt.ylabel(\"Proportion of original image size\")\n",
        "plt.title(\"Compression factor vs rank\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvHcLRj2QoDg"
      },
      "source": [
        "このプロットに基づくと、近似画像の圧縮係数とその階数の間に線形関係があります。これをさらに詳しく調べるには、近似行列のデータサイズ ${\\mathrm{A}}_r$ が、その計算に必要な要素の総数として定義されていることを思い出してください。次の式を使用して、圧縮係数と階数の関係を見つけることができます。\n",
        "\n",
        "$$x = (m \\times r) + r + (r \\times n) = r \\times (m + n + 1)$$\n",
        "\n",
        "$$c = \\large \\frac{x}{y} = \\frac{r \\times (m + n + 1)}{m \\times n}$$\n",
        "\n",
        "ここでは、それぞれ以下を意味します。\n",
        "\n",
        "- $x$: ${\\mathrm{A_r}}$ のサイズ\n",
        "- $y$: ${\\mathrm{A}}$ のサイズ\n",
        "- $c = \\frac{x}{y}$: 圧縮係数\n",
        "- $r$: 近似の階数\n",
        "- $m$ と $n$: ${\\mathrm{A}}$ の行と列の次元\n",
        "\n",
        "画像を希望する係数 $c$ に圧縮するために必要な階数 $r$ を求めるには、上記の式を並べ替えて $r$ を求めます。\n",
        "\n",
        "$$r = ⌊{\\large\\frac{c \\times m \\times n}{m + n + 1}}⌋$$\n",
        "\n",
        "各 RGB 近似は互いに影響しないため、この式はカラーチャネルの次元とは無関係であることに注意してください。次に、希望する圧縮係数を指定して入力画像を圧縮する関数を作成します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "viVO-I60QynI"
      },
      "outputs": [],
      "source": [
        "def compress_image_with_factor(I, compression_factor, verbose=False):\n",
        "  # Returns a compressed image based on a desired compression factor\n",
        "  m,n,o = I.shape\n",
        "  r = int((compression_factor * m * n)/(m + n + 1))\n",
        "  I_r, I_r_prop = compress_image(I, r, verbose=verbose)\n",
        "  return I_r"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWSv58J6LSRQ"
      },
      "source": [
        "画像を元のサイズの 15% に圧縮します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HVeeloIwQ1b6"
      },
      "outputs": [],
      "source": [
        "compression_factor = 0.15\n",
        "I_r_img = compress_image_with_factor(I, compression_factor, verbose=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LkeRyms7jZMd"
      },
      "source": [
        "### 特異値の累積和\n",
        "\n",
        "特異値の累積和は、階数 r 近似によって取得されるエネルギー量の有用な指標になる場合があります。サンプル画像内の特異値の RGB 平均累積比率を可視化します。これには `tf.cumsum` 関数が役立ちます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CteJ6VbKlndu"
      },
      "outputs": [],
      "source": [
        "def viz_energy(I):\n",
        "  # Visualize the energy captured based on rank\n",
        "  # Computing SVD\n",
        "  I = tf.convert_to_tensor(I)/255\n",
        "  I_batched = tf.transpose(I, [2, 0, 1]) \n",
        "  s, U, V = tf.linalg.svd(I_batched)\n",
        "  # Plotting average proportion across RGB channels \n",
        "  props_rgb = tf.map_fn(lambda x: tf.cumsum(x)/tf.reduce_sum(x), s)\n",
        "  props_rgb_mean = tf.reduce_mean(props_rgb, axis=0)\n",
        "  plt.figure(figsize=(11,6))\n",
        "  plt.plot(range(len(I)), props_rgb_mean, color='k')\n",
        "  plt.xlabel(\"Rank / singular value number\")\n",
        "  plt.ylabel(\"Cumulative proportion of singular values\")\n",
        "  plt.title(\"RGB-averaged proportion of energy captured by the first 'r' singular values\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vl9PKow-GgCp"
      },
      "outputs": [],
      "source": [
        "viz_energy(I)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQtwimKuQP19"
      },
      "source": [
        "この画像のエネルギーの 90% 以上が、最初の 100 個の特異値にキャプチャされているようです。次に、希望するエネルギー保持率を指定して、入力画像を圧縮する関数を作成します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fum5Cvm7R5vH"
      },
      "outputs": [],
      "source": [
        "def compress_image_with_energy(I, energy_factor, verbose=False):\n",
        "  # Returns a compressed image based on a desired energy factor\n",
        "  # Computing SVD\n",
        "  I_rescaled = tf.convert_to_tensor(I)/255\n",
        "  I_batched = tf.transpose(I_rescaled, [2, 0, 1]) \n",
        "  s, U, V = tf.linalg.svd(I_batched)\n",
        "  # Extracting singular values\n",
        "  props_rgb = tf.map_fn(lambda x: tf.cumsum(x)/tf.reduce_sum(x), s)\n",
        "  props_rgb_mean = tf.reduce_mean(props_rgb, axis=0)\n",
        "  # Find closest r that corresponds to the energy factor\n",
        "  r = tf.argmin(tf.abs(props_rgb_mean - energy_factor)) + 1\n",
        "  actual_ef = props_rgb_mean[r]\n",
        "  I_r, I_r_prop = compress_image(I, r, verbose=verbose)\n",
        "  print(f\"Proportion of energy captured by the first {r} singular values: {actual_ef:.3f}\")\n",
        "  return I_r"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_rChG0OLby1"
      },
      "source": [
        "画像を圧縮して、そのエネルギーの 75% を保持します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xDXBaZQ4c5jF"
      },
      "outputs": [],
      "source": [
        "energy_factor = 0.75\n",
        "I_r_img = compress_image_with_energy(I, energy_factor, verbose=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tmqTW0CYX-v"
      },
      "source": [
        "### エラーと特異値\n",
        "\n",
        "近似誤差と特異値の間にも興味深い関係があります。近似のフロベニウスノルムの 2 乗は、除外された特異値の 2 乗の和に等しいことがわかります。\n",
        "\n",
        "$${||A - A_r||}^2 = \\sum_{i=r+1}^{R}σ_i^2$$\n",
        "\n",
        "このチュートリアルの最初にある行列例の階数 10 近似を使用して、この関係をテストしてください。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hctOvN8BckiS"
      },
      "outputs": [],
      "source": [
        "s, U, V = tf.linalg.svd(A)\n",
        "A_10, A_10_size = rank_r_approx(s, U, V, 10)\n",
        "squared_norm = tf.norm(A - A_10)**2\n",
        "s_squared_sum = tf.reduce_sum(s[10:]**2)\n",
        "print(f\"Squared Frobenius norm: {squared_norm:.3f}\")\n",
        "print(f\"Sum of squared singular values left out: {s_squared_sum:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgGQuV-yqYZH"
      },
      "source": [
        "## まとめ\n",
        "\n",
        "このノートブックでは、TensorFlow を使用して特異値分解を実装し、それを適用して画像圧縮アルゴリズムを作成するプロセスを紹介しました。以下に役立つヒントをいくつか紹介します。\n",
        "\n",
        "- [TensorFlow Core API](https://www.tensorflow.org/guide/core) は、高性能科学計算のさまざまなユースケースに利用できます。\n",
        "- TensorFlow の線形代数機能の詳細については、[linalg モジュール](https://www.tensorflow.org/api_docs/python/tf/linalg)のドキュメントを参照してください。\n",
        "- SVD は、[レコメンデーションシステム](https://developers.google.com/machine-learning/recommendation/labs/movie-rec-programming-exercise)の構築にも適用できます。\n",
        "\n",
        "TensorFlow Core API のその他の使用例については、[チュートリアル](https://www.tensorflow.org/guide/core)を参照してください。データの読み込みと準備についてさらに学習するには、[画像データの読み込み](https://www.tensorflow.org/tutorials/load_data/images)または [CSV データの読み込み](https://www.tensorflow.org/tutorials/load_data/csv)に関するチュートリアルを参照してください。"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "matrix_core.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
