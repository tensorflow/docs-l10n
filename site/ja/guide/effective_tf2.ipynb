{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tce3stUlHN0L"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tuOe1ymfHZPu"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFdPvlXBOdUN"
      },
      "source": [
        "# 効果的な TensorFlow 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfBg1C5NB3X0"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>     <a target=\"_blank\" href=\"https://www.tensorflow.org/guide/effective_tf2\">     <img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">     TensorFlow.org で表示</a>\n",
        "</td>\n",
        "  <td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/ja/guide/effective_tf2.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Google Colab で実行</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/ja/guide/effective_tf2.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">GitHub で表示</a></td>\n",
        "  <td><a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/ja/guide/effective_tf2.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">ノートブックをダウンロード</a></td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHxb-dlhMIzW"
      },
      "source": [
        "## 概要\n",
        "\n",
        "このガイドでは、TensorFlow 2（TF2）を使ってコードを記述する際のベストプラクティスを紹介しています。最近 TensorFlow 1（TF1）から切り替えたユーザーを対象としています。TF1 コードから TF2 への移行についての詳細は、[このガイドの移行セクション](https://tensorflow.org/guide/migrate)をご覧ください。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUXex9ctTuDB"
      },
      "source": [
        "## セットアップ\n",
        "\n",
        "このガイドの例に使用する TensorFlow とその他の依存関係をインポートします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IqR2PQG4ZaZ0"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ngds9zateIY8"
      },
      "source": [
        "## 慣用的な TensorFlow 2 の推奨事項"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3RdHaroMAi4"
      },
      "source": [
        "### コードを小さなモジュールにリファクタリングする\n",
        "\n",
        "コードを、必要に応じて呼び出せるより小さな関数にリファクタリングすることをお勧めします。最高のパフォーマンスを得るには、`tf.function` で行える最も大きな計算ブロックをデコレートするとよいでしょう（`tf.function` が呼び出すネストされた Python 関数には、`tf.function` に異なる `jit_compile` 設定を使用しない限り、別途独自のデコレーションは不要であることに注意してください）。ユースケースに応じて、複数のトレーニングステップであったり、トレーニングループ全体である場合があります。推論のユースケースについては、単一モデルのフォワードパスである場合があります。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rua1l8et3Evd"
      },
      "source": [
        "### 一部の `tf.keras.optimizer` のデフォルトの学習速度を調整する\n",
        "\n",
        "<a name=\"optimizer_defaults\"></a>\n",
        "\n",
        "TF2 では、一部の Keras オプティマイザの学習速度が異なります。モデルの収束の動作に変化がある場合は、デフォルトの学習速度を確認してください。\n",
        "\n",
        "`optimizers.SGD`、`optimizers.Adam`、または `optimizers.RMSprop` に変更はありません。\n",
        "\n",
        "デフォルトの学習率は次のように変更されました。\n",
        "\n",
        "- `optimizers.Adagrad` `0.01` から `0.001` へ\n",
        "- `optimizers.Adadelta` `1.0` から `0.001` へ\n",
        "- `optimizers.Adamax` `0.002` から `0.001` へ\n",
        "- `optimizers.Nadam` `0.002` から `0.001` へ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6LfkpsEldEV"
      },
      "source": [
        "### `tf.Module` と Keras レイヤーを使用して変数を管理する\n",
        "\n",
        "`tf.Module` と `tf.keras.layers.Layer` には、すべての従属変数を帰属的に収集する便利な `variables` と `trainable_variables` プロパティがあります。このため、変数が使用されている場所での変数の管理を簡単に行うことができます。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQ2U0rj1oBlc"
      },
      "source": [
        "Keras レイヤー/モデルは `tf.train.Checkpointable` から継承し、`@tf.function` と統合されています。このため、Keras オブジェクトに直接チェックポイントを設定したり、SavedModels をエクスポートしたりすることができます。この統合を利用するために、Keras の `Model.fit` API を必ずしも使用する必要はありません。\n",
        "\n",
        "Keras を使用して関連する変数のサブセットを収集する方法については、Keras ガイドの[転移学習とファインチューニング](https://www.tensorflow.org/guide/keras/transfer_learning#transfer_learning_fine-tuning_with_a_custom_training_loop)に関するセクションをご覧ください。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j34MsfxWodG6"
      },
      "source": [
        "### `tf.data.Dataset` と `tf.function` を組み合わせる\n",
        "\n",
        "[TensorFlow Datasets](https://tensorflow.org/datasets) パッケージ（`tfds`）には、事前定義済みのデータセットを `tf.data.Dataset` オブジェクトとして読み込むためのユーティリティが含まれます。この例では、`tfds` を使用して MNIST データセットを読み込めます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BMgxaLH74_s-"
      },
      "outputs": [],
      "source": [
        "datasets, info = tfds.load(name='mnist', with_info=True, as_supervised=True)\n",
        "mnist_train, mnist_test = datasets['train'], datasets['test']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPJhEuvj5VfR"
      },
      "source": [
        "次に、トレーニングのためのデータを準備します。\n",
        "\n",
        "- 各画像をリスケールする。\n",
        "- 例の順序をシャッフルする。\n",
        "- 画像とラベルのバッチを集める。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "StBRHtJM2S7o"
      },
      "outputs": [],
      "source": [
        "BUFFER_SIZE = 10 # Use a much larger value for real code\n",
        "BATCH_SIZE = 64\n",
        "NUM_EPOCHS = 5\n",
        "\n",
        "\n",
        "def scale(image, label):\n",
        "  image = tf.cast(image, tf.float32)\n",
        "  image /= 255\n",
        "\n",
        "  return image, label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKq14zKKFAdv"
      },
      "source": [
        "例を短く保つために、データセットを 5 バッチだけ返すようにトリミングします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_J-o4YjG2mkM"
      },
      "outputs": [],
      "source": [
        "train_data = mnist_train.map(scale).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "test_data = mnist_test.map(scale).batch(BATCH_SIZE)\n",
        "\n",
        "STEPS_PER_EPOCH = 5\n",
        "\n",
        "train_data = train_data.take(STEPS_PER_EPOCH)\n",
        "test_data = test_data.take(STEPS_PER_EPOCH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XEqdkH54VM6c"
      },
      "outputs": [],
      "source": [
        "image_batch, label_batch = next(iter(train_data))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loTPH2Pz4_Oj"
      },
      "source": [
        "メモリに収まるトレーニングデータは、通常の Python イテレーションでイテレートしますが、そうでない場合は `tf.data.Dataset` を使ってディスクからトレーニングをストリーミングするのが最適です。データセットは[イテラブル（イテレータではない）](https://docs.python.org/3/glossary.html#term-iterable)であり、Eager モードの Python インテラブルとまったく同様に機能します。コードを `tf.function` でラップすることで、データセットの非同期プリフェッチ/ストリーム機能をそのまま利用することができます。この方法は、Python イテレーションを、同等の、AutoGraph を使用したグラフ演算に置き換えます。\n",
        "\n",
        "```python\n",
        "@tf.function\n",
        "def train(model, dataset, optimizer):\n",
        "  for x, y in dataset:\n",
        "    with tf.GradientTape() as tape:\n",
        "      # training=True is only needed if there are layers with different\n",
        "      # behavior during training versus inference (e.g. Dropout).\n",
        "      prediction = model(x, training=True)\n",
        "      loss = loss_fn(prediction, y)\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "```\n",
        "\n",
        "Keras の `Model.fit` API を使用する場合、データセットのイテレーションを気にする必要はありません。\n",
        "\n",
        "```python\n",
        "model.compile(optimizer=optimizer, loss=loss_fn)\n",
        "model.fit(dataset)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSev7vZC5GJB"
      },
      "source": [
        "<a name=\"keras_training_loops\"></a>\n",
        "\n",
        "### Keras トレーニングループを使用する\n",
        "\n",
        "トレーニングプロセスの低レベル制御が不要な場合は、Keras 組み込みの `fit`、`evaluate`、および `predict` メソッドの使用が推奨されます。これらのメソッドは（シーケンシャル、関数型、またはサブクラス化）実装を問わず、モデルをトレーニングするための統一インターフェースを提供します。\n",
        "\n",
        "これらのメソッドには次のような優位点があります。\n",
        "\n",
        "- Numpy 配列、Python ジェネレータ、`tf.data.Datasets` を受け取ります。\n",
        "- これらは正則化と活性化損失を自動的に適用します。\n",
        "- [ハードウェア構成に関係なく](distributed_training.ipynb)トレーニングコードが変化しない `tf.distribute` をサポートします。\n",
        "- 任意の callable は損失とメトリクスとしてサポートします。\n",
        "- `tf.data.Datasets` のようなコールバックとカスタムコールバックをサポートします。\n",
        "- 自動的に TensorFlow グラフを使用し、高性能です。\n",
        "\n",
        "ここに `Dataset` を使用したモデルのトレーニング例を示します。この仕組みについての詳細は、[チュートリアル](https://tensorflow.org/tutorials)をご覧ください。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uzHFCzd45Rae"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, 3, activation='relu',\n",
        "                           kernel_regularizer=tf.keras.regularizers.l2(0.02),\n",
        "                           input_shape=(28, 28, 1)),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dropout(0.1),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dense(10)\n",
        "])\n",
        "\n",
        "# Model is the full model w/o custom layers\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_data, epochs=NUM_EPOCHS)\n",
        "loss, acc = model.evaluate(test_data)\n",
        "\n",
        "print(\"Loss {}, Accuracy {}\".format(loss, acc))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQTaHTuK5S5A"
      },
      "source": [
        "<a name=\"custom_loop\"></a>\n",
        "\n",
        "### トレーニングをカスタマイズして独自のループを記述する\n",
        "\n",
        "Keras モデルは機能しても、トレーニングステップまたは外側のトレーニングループに柔軟性と制御がさらに必要な場合は、独自のトレーニングステップやトレーニングループ全体を実装することができます。詳細については、Keras ガイドの[`fit` のカスタマイズ](https://www.tensorflow.org/guide/keras/customizing_what_happens_in_fit)をご覧ください。\n",
        "\n",
        "様々な機能を `tf.keras.callbacks.Callback` として実装することもできます。\n",
        "\n",
        "この方法には、[前述した](#keras_training_loops)多数のメリットがありますが、トレーニングステップだけでなく、外側のループを制御することができます。\n",
        "\n",
        "標準のトレーニングループには、以下の 3 つのステップがあります。\n",
        "\n",
        "1. Python ジェネレータか `tf.data.Datasets` をイテレーションして例のバッチを作成します。\n",
        "2. `tf.GradientTape` を使用して勾配を集めます。\n",
        "3. `tf.keras.optimizers` の 1 つを使用して、モデルの変数に重み更新を適用します。\n",
        "\n",
        "覚えておきましょう:\n",
        "\n",
        "- サブクラス化されたレイヤーとモデルの `call` メソッドには、常に `training` 引数を含めます。\n",
        "- `training` 引数を確実に正しくセットしてモデルを呼び出します。\n",
        "- 使用方法によっては、モデルがデータのバッチ上で実行されるまでモデル変数は存在しないかもしれません。\n",
        "- モデルの正則化損失などを手動で処理する必要があります。\n",
        "\n",
        "変数イニシャライザを実行したり、手動制御の依存関係を追加したりする必要はありません。自動制御依存関係と変数の初期化は、作成時に `tf.function` によって処理されます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gQooejfYlQeF"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, 3, activation='relu',\n",
        "                           kernel_regularizer=tf.keras.regularizers.l2(0.02),\n",
        "                           input_shape=(28, 28, 1)),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dropout(0.1),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dense(10)\n",
        "])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(0.001)\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "@tf.function\n",
        "def train_step(inputs, labels):\n",
        "  with tf.GradientTape() as tape:\n",
        "    predictions = model(inputs, training=True)\n",
        "    regularization_loss=tf.math.add_n(model.losses)\n",
        "    pred_loss=loss_fn(labels, predictions)\n",
        "    total_loss=pred_loss + regularization_loss\n",
        "\n",
        "  gradients = tape.gradient(total_loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  for inputs, labels in train_data:\n",
        "    train_step(inputs, labels)\n",
        "  print(\"Finished epoch\", epoch)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WikxMFGgo3oZ"
      },
      "source": [
        "### Python 制御フローで `tf.function` を利用する\n",
        "\n",
        "`tf.function` は、データに依存する制御フローを `tf.cond` や `tf.while_loop` といったグラフモード相当のフローに変換する方法を提供しています。\n",
        "\n",
        "データ依存の制御フローがよく見られる場所に、シーケンスモデルが挙げられます。`tf.keras.layers.RNN` は RNN セルをラップするため、静的または動的にリカレンスを展開することができます。例として、動的な展開を次のように実装しなおすことができます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n5UebfChRu4T"
      },
      "outputs": [],
      "source": [
        "class DynamicRNN(tf.keras.Model):\n",
        "\n",
        "  def __init__(self, rnn_cell):\n",
        "    super(DynamicRNN, self).__init__(self)\n",
        "    self.cell = rnn_cell\n",
        "\n",
        "  @tf.function(input_signature=[tf.TensorSpec(dtype=tf.float32, shape=[None, None, 3])])\n",
        "  def call(self, input_data):\n",
        "\n",
        "    # [batch, time, features] -> [time, batch, features]\n",
        "    input_data = tf.transpose(input_data, [1, 0, 2])\n",
        "    timesteps =  tf.shape(input_data)[0]\n",
        "    batch_size = tf.shape(input_data)[1]\n",
        "    outputs = tf.TensorArray(tf.float32, timesteps)\n",
        "    state = self.cell.get_initial_state(batch_size = batch_size, dtype=tf.float32)\n",
        "    for i in tf.range(timesteps):\n",
        "      output, state = self.cell(input_data[i], state)\n",
        "      outputs = outputs.write(i, output)\n",
        "    return tf.transpose(outputs.stack(), [1, 0, 2]), state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NhBI_SGKQVIB"
      },
      "outputs": [],
      "source": [
        "lstm_cell = tf.keras.layers.LSTMCell(units = 13)\n",
        "\n",
        "my_rnn = DynamicRNN(lstm_cell)\n",
        "outputs, state = my_rnn(tf.random.normal(shape=[10,20,3]))\n",
        "print(outputs.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "du7bn3NX7iIr"
      },
      "source": [
        "詳細は、[`tf.function` ガイド](https://www.tensorflow.org/guide/function)をご覧ください。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUAYhgL_NomT"
      },
      "source": [
        "### 新しいスタイルのメトリクスと損失\n",
        "\n",
        "メトリクスと損失は、Eager と `tf.function` で動作するオブジェクトです。\n",
        "\n",
        "損失オブジェクトは呼び出し可能で、(`y_true`, `y_pred`) を引数として期待します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pf5gcwMzNs8F"
      },
      "outputs": [],
      "source": [
        "cce = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "cce([[1, 0]], [[-1.0,3.0]]).numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a89m-wRfxyfV"
      },
      "source": [
        "#### メトリクスを使用してデータの収集と表示を行う\n",
        "\n",
        "`tf.metrics` を使ってデータを集計し、`tf.summary` を使ってサマリーをログに記録してから、コンテキストマネージャーを使ってライターにリダイレクトすることができます。サマリーはライターに直接送信されるため、コールサイトに`step` 値を提供する必要があります。\n",
        "\n",
        "```python\n",
        "summary_writer = tf.summary.create_file_writer('/tmp/summaries')\n",
        "with summary_writer.as_default():\n",
        "  tf.summary.scalar('loss', 0.1, step=42)\n",
        "```\n",
        "\n",
        "サマリーとしてデータをログに記録する前にデータを集計するには、`tf.metrics` を使用します。メトリクスはステートフルです。つまり、値を蓄積し、`result` メソッド（`Mean.result` など）が呼び出されたときに累積結果を返します。累積された値は、`Model.reset_states` を使用すると消去されます。\n",
        "\n",
        "```python\n",
        "def train(model, optimizer, dataset, log_freq=10):\n",
        "  avg_loss = tf.keras.metrics.Mean(name='loss', dtype=tf.float32)\n",
        "  for images, labels in dataset:\n",
        "    loss = train_step(model, optimizer, images, labels)\n",
        "    avg_loss.update_state(loss)\n",
        "    if tf.equal(optimizer.iterations % log_freq, 0):\n",
        "      tf.summary.scalar('loss', avg_loss.result(), step=optimizer.iterations)\n",
        "      avg_loss.reset_states()\n",
        "\n",
        "def test(model, test_x, test_y, step_num):\n",
        "  # training=False is only needed if there are layers with different\n",
        "  # behavior during training versus inference (e.g. Dropout).\n",
        "  loss = loss_fn(model(test_x, training=False), test_y)\n",
        "  tf.summary.scalar('loss', loss, step=step_num)\n",
        "\n",
        "train_summary_writer = tf.summary.create_file_writer('/tmp/summaries/train')\n",
        "test_summary_writer = tf.summary.create_file_writer('/tmp/summaries/test')\n",
        "\n",
        "with train_summary_writer.as_default():\n",
        "  train(model, optimizer, dataset)\n",
        "\n",
        "with test_summary_writer.as_default():\n",
        "  test(model, test_x, test_y, optimizer.iterations)\n",
        "```\n",
        "\n",
        "TensorBoard をサマリーログのディレクトリにポイントし、生成されたサマリーを可視化します。\n",
        "\n",
        "```shell\n",
        "tensorboard --logdir /tmp/summaries\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tx7FyM_RHwJ"
      },
      "source": [
        "`tf.summary` API を使用して、TensorBoard での可視化に使用するサマリーデータを記述します。詳細については、<a href=\"https://www.tensorflow.org/tensorboard/migrate#in_tf_2x\" data-md-type=\"link\">`tf.summary` ガイド</a>をご覧ください。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HAbA0fKW58CH"
      },
      "outputs": [],
      "source": [
        "# Create the metrics\n",
        "loss_metric = tf.keras.metrics.Mean(name='train_loss')\n",
        "accuracy_metric = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
        "\n",
        "@tf.function\n",
        "def train_step(inputs, labels):\n",
        "  with tf.GradientTape() as tape:\n",
        "    predictions = model(inputs, training=True)\n",
        "    regularization_loss=tf.math.add_n(model.losses)\n",
        "    pred_loss=loss_fn(labels, predictions)\n",
        "    total_loss=pred_loss + regularization_loss\n",
        "\n",
        "  gradients = tape.gradient(total_loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "  # Update the metrics\n",
        "  loss_metric.update_state(total_loss)\n",
        "  accuracy_metric.update_state(labels, predictions)\n",
        "\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  # Reset the metrics\n",
        "  loss_metric.reset_states()\n",
        "  accuracy_metric.reset_states()\n",
        "\n",
        "  for inputs, labels in train_data:\n",
        "    train_step(inputs, labels)\n",
        "  # Get the metric results\n",
        "  mean_loss=loss_metric.result()\n",
        "  mean_accuracy = accuracy_metric.result()\n",
        "\n",
        "  print('Epoch: ', epoch)\n",
        "  print('  loss:     {:.3f}'.format(mean_loss))\n",
        "  print('  accuracy: {:.3f}'.format(mean_accuracy))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bG9AaMzih3eh"
      },
      "source": [
        "#### Keras メトリクス名\n",
        "\n",
        "<a name=\"keras_metric_names\"></a>\n",
        "\n",
        "Keras モデルはメトリクス名の処理を一貫して行います。メトリクスリストで文字列を渡すと、*まさに*その文字列がメトリクスの `name` として使用されます。これらの名前は `model.fit` によって返される履歴オブジェクトと、`keras.callbacks` に渡されるログに表示されます。これはメトリクスリストで渡した文字列に設定されています。** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1iODIsGDgyYd"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    optimizer = tf.keras.optimizers.Adam(0.001),\n",
        "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics = ['acc', 'accuracy', tf.keras.metrics.SparseCategoricalAccuracy(name=\"my_accuracy\")])\n",
        "history = model.fit(train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8oGzs_TlisKJ"
      },
      "outputs": [],
      "source": [
        "history.history.keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaB2z2XIyhcr"
      },
      "source": [
        "### デバッグ\n",
        "\n",
        "Eager execution を使用してコードをステップごとに実行すると、形状、データ型、および値を検査することができます。`tf.function` や `tf.keras` などの特定の API は、パフォーマンスや移植性の目的で、Graph execution を使用するように設計されていますが、デバッグの際は、`tf.config.run_functions_eagerly(True)` を使って、このコード内で Eager execution を使用することができます。\n",
        "\n",
        "以下に例を示します。\n",
        "\n",
        "```python\n",
        "@tf.function\n",
        "def f(x):\n",
        "  if x > 0:\n",
        "    import pdb\n",
        "    pdb.set_trace()\n",
        "    x = x + 1\n",
        "  return x\n",
        "\n",
        "tf.config.run_functions_eagerly(True)\n",
        "f(tf.constant(1))\n",
        "```\n",
        "\n",
        "```\n",
        ">>> f()\n",
        "-> x = x + 1\n",
        "(Pdb) l\n",
        "  6     @tf.function\n",
        "  7     def f(x):\n",
        "  8       if x > 0:\n",
        "  9         import pdb\n",
        " 10         pdb.set_trace()\n",
        " 11  ->     x = x + 1\n",
        " 12       return x\n",
        " 13\n",
        " 14     tf.config.run_functions_eagerly(True)\n",
        " 15     f(tf.constant(1))\n",
        "[EOF]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdvGF2FvbBXZ"
      },
      "source": [
        "これは Keras モデルや、Eager execution をサポートするほかの API 内でも機能します。\n",
        "\n",
        "```python\n",
        "class CustomModel(tf.keras.models.Model):\n",
        "\n",
        "  @tf.function\n",
        "  def call(self, input_data):\n",
        "    if tf.reduce_mean(input_data) > 0:\n",
        "      return input_data\n",
        "    else:\n",
        "      import pdb\n",
        "      pdb.set_trace()\n",
        "      return input_data // 2\n",
        "\n",
        "\n",
        "tf.config.run_functions_eagerly(True)\n",
        "model = CustomModel()\n",
        "model(tf.constant([-2, -4]))\n",
        "```\n",
        "\n",
        "```\n",
        ">>> call()\n",
        "-> return input_data // 2\n",
        "(Pdb) l\n",
        " 10         if tf.reduce_mean(input_data) > 0:\n",
        " 11           return input_data\n",
        " 12         else:\n",
        " 13           import pdb\n",
        " 14           pdb.set_trace()\n",
        " 15  ->       return input_data // 2\n",
        " 16\n",
        " 17\n",
        " 18     tf.config.run_functions_eagerly(True)\n",
        " 19     model = CustomModel()\n",
        " 20     model(tf.constant([-2, -4]))\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0-F-bvJXKD8"
      },
      "source": [
        "注意:\n",
        "\n",
        "- `fit`、`evaluate`、`predict` などの `tf.keras.Model` は、内部では `tf.function` を使って[グラフ](https://www.tensorflow.org/guide/intro_to_graphs)として実行します。\n",
        "\n",
        "- `tf.keras.Model.compile` を使用する場合は、`run_eagerly = True` に設定して、`Model` ロジックが `tf.function` にラップされないようにします。\n",
        "\n",
        "- `tf.data.experimental.enable_debug_mode` を使用して、`tf.data` のデバッグモードを有効化します。詳細は、[API ドキュメント](https://www.tensorflow.org/api_docs/python/tf/data/experimental/enable_debug_mode)をご覧ください。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxa5yKK7bym0"
      },
      "source": [
        "### オブジェクトに `tf.Tensors` を保持しないこと\n",
        "\n",
        "これらのテンソルオブジェクトは、`tf.function` または Eager のコンテキストで作成される可能性があり、これらのテンソルは異なった振る舞いをします。`tf.Tensor` は必ず中間値のみに使用してください。\n",
        "\n",
        "状態を追跡するには、`tf.Variable` を使用してください。これらはいずれのコンテキストからも常に使用可能です。詳細については、<a href=\"https://www.tensorflow.org/guide/variable\" data-md-type=\"link\">`tf.Variable` ガイド</a>をご覧ください。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FdXLLYa2uAyx"
      },
      "source": [
        "## リソースとその他の文献\n",
        "\n",
        "- TF2 の使用方法についての詳細は、TF2 の[ガイド](https://tensorflow.org/guide)と[チュートリアル](https://tensorflow.org/tutorials)をご覧ください。\n",
        "\n",
        "- 前に TF1.x を使用していた場合は、コードを TF2 に移行することを強くお勧めします。詳細は、[移行ガイド](https://tensorflow.org/guide/migrate)をご覧ください。"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "effective_tf2.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
