{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7ITxKLUkX0v"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "yOYx6tzSnWQ3"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xgB0Oz5eGSQ"
      },
      "source": [
        "# グラフと `tf.function` の基礎"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4zzZVZtQb1w"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>     <a target=\"_blank\" href=\"https://www.tensorflow.org/guide/intro_to_graphs\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">View on TensorFlow.org</a>   </td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/guide/intro_to_graphs.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Run in Google Colab</a>   </td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/ja/guide/intro_to_graphs.ipynb\" class=\"\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">GitHub でソースを表示</a>   </td>\n",
        "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/ja/guide/intro_to_graphs.ipynb\" class=\"\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">ノートブックをダウンロード</a>   </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBKqnXI9GOax"
      },
      "source": [
        "## 概要\n",
        "\n",
        "This guide goes beneath the surface of TensorFlow and Keras to demonstrate how TensorFlow works. If you instead want to immediately get started with Keras, check out the [collection of Keras guides](https://www.tensorflow.org/guide/keras/).\n",
        "\n",
        "In this guide, you'll learn how TensorFlow allows you to make simple changes to your code to get graphs, how graphs are stored and represented, and how you can use them to accelerate your models.\n",
        "\n",
        "注意: TensorFlow 1.x のみの知識をお持ちの場合は、このガイドでは、非常に異なるグラフビューが紹介されています。\n",
        "\n",
        "**This is a big-picture overview that covers how `tf.function` allows you to switch from eager execution to graph execution.** For a more complete specification of `tf.function`, go to the <a href=\"./function.ipynb\" data-md-type=\"link\">Better performance with `tf.function`</a> guide.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0DdlfacAdTZ"
      },
      "source": [
        "### グラフとは？\n",
        "\n",
        "In the previous three guides, you ran TensorFlow **eagerly**. This means TensorFlow operations are executed by Python, operation by operation, and returning results back to Python.\n",
        "\n",
        "Eager execution には特有のメリットがいくつかありますが、Graph execution では Python 外への移植が可能になり、より優れたパフォーマンスを得られる傾向にあります。**Graph execution** では、テンソルの計算は *TensorFlow グラフ*（`tf.Graph` または単に「graph」とも呼ばれます）として実行されます。\n",
        "\n",
        "**グラフとは、計算のユニットを表す一連の `tf.Operation` オブジェクトと、演算間を流れるデータのユニットを表す `tf.Tensor` オブジェクトを含むデータ構造です。** `tf.Graph` コンテキストで定義されます。これらのグラフはデータ構造であるため、元の Python コードがなくても、保存、実行、および復元することができます。\n",
        "\n",
        "This is what a TensorFlow graph representing a two-layer neural network looks like when visualized in TensorBoard:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FvQ5aBuRGT1o"
      },
      "source": [
        "<img src=\"https://github.com/tensorflow/docs/blob/master/site/en/guide/images/intro_to_graphs/two-layer-network.png?raw=1\" alt=\"A simple TensorFlow graph\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHpY3avXGITP"
      },
      "source": [
        "### グラフのメリット\n",
        "\n",
        "With a graph, you have a great deal of flexibility.  You can use your TensorFlow graph in environments that don't have a Python interpreter, like mobile applications, embedded devices, and backend servers. TensorFlow uses graphs as the format for [saved models](./saved_model.ipynb) when it exports them from Python.\n",
        "\n",
        "また、グラフは最適化を簡単に行えるため、コンパイラは次のような変換を行えます。\n",
        "\n",
        "- 計算に定数ノードを畳み込むで、テンソルの値を統計的に推論します*（「定数畳み込み」）*。\n",
        "- 独立した計算のサブパートを分離し、スレッドまたはデバイスに分割します。\n",
        "- 共通部分式を取り除き、算術演算を単純化します。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1x1EOD9GjnB"
      },
      "source": [
        "これやほかの高速化を実行する [Grappler](./graph_optimization.ipynb) という総合的な最適化システムがあります。\n",
        "\n",
        "まとめると、グラフは非常に便利なもので、**複数のデバイス**で、TensorFlow の**高速化**、**並列化**、および効率化を期待することができます。\n",
        "\n",
        "However, you still want to define your machine learning models (or other computations) in Python for convenience, and then automatically construct graphs when you need them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-6Qi0thw2i9"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0d1689fa928f"
      },
      "source": [
        "Import some necessary libraries:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "goZwOXp_xyQj"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import timeit\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSZebVuWxDXu"
      },
      "source": [
        "## グラフを利用する\n",
        "\n",
        "TensorFlow では、`tf.function` を直接呼出しまたはデコレータとして使用し、グラフを作成して実行します。`tf.function` は通常の関数を入力として取り、`Function` を返します。<strong data-md-type=\"raw_html\">`Function` は、Python 関数から TensorFlow グラフを構築する Python コーラブルです。`Function` は 相当する Python 関数と同様に使用します。</strong>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HKbLeJ1y0Umi"
      },
      "outputs": [],
      "source": [
        "# Define a Python function.\n",
        "def a_regular_function(x, y, b):\n",
        "  x = tf.matmul(x, y)\n",
        "  x = x + b\n",
        "  return x\n",
        "\n",
        "# `a_function_that_uses_a_graph` is a TensorFlow `Function`.\n",
        "a_function_that_uses_a_graph = tf.function(a_regular_function)\n",
        "\n",
        "# Make some tensors.\n",
        "x1 = tf.constant([[1.0, 2.0]])\n",
        "y1 = tf.constant([[2.0], [3.0]])\n",
        "b1 = tf.constant(4.0)\n",
        "\n",
        "orig_value = a_regular_function(x1, y1, b1).numpy()\n",
        "# Call a `Function` like a Python function.\n",
        "tf_function_value = a_function_that_uses_a_graph(x1, y1, b1).numpy()\n",
        "assert(orig_value == tf_function_value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNvuAYpdrTOf"
      },
      "source": [
        "On the outside, a `Function` looks like a regular function you write using TensorFlow operations. [Underneath](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/eager/def_function.py), however, it is *very different*. A `Function` **encapsulates several `tf.Graph`s behind one API** (learn more in the *Polymorphism* section). That is how a `Function` is able to give you the benefits of graph execution, like speed and deployability (refer to *The benefits of graphs* above)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MT7U8ozok0gV"
      },
      "source": [
        "`tf.function` は関数と*それが呼び出すその他すべての関数に次のように適用します*。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rpz08iLplm9F"
      },
      "outputs": [],
      "source": [
        "def inner_function(x, y, b):\n",
        "  x = tf.matmul(x, y)\n",
        "  x = x + b\n",
        "  return x\n",
        "\n",
        "# Use the decorator to make `outer_function` a `Function`.\n",
        "@tf.function\n",
        "def outer_function(x):\n",
        "  y = tf.constant([[2.0], [3.0]])\n",
        "  b = tf.constant(4.0)\n",
        "\n",
        "  return inner_function(x, y, b)\n",
        "\n",
        "# Note that the callable will create a graph that\n",
        "# includes `inner_function` as well as `outer_function`.\n",
        "outer_function(tf.constant([[1.0, 2.0]])).numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P88fOr88qgCj"
      },
      "source": [
        "TensorFlow 1.x を使用したことがある場合は、`Placeholder` または `tf.Sesssion` をまったく定義する必要がないことに気づくでしょう。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfeKf0Nr1OEK"
      },
      "source": [
        "### Python 関数をグラフに変換する\n",
        "\n",
        "TensorFlow で記述するすべての関数には、組み込みの TF 演算と、`if-then` 句、ループ、`break`、`return`、`continue` などの Python ロジックが含まれます。TensorFlow 演算は `tf.Graph` で簡単にキャプチャされますが、Python 固有のロジックがグラフの一部となるには、さらにステップが必要となります。`tf.function` は、Python コードをグラフが生成するコードに変換するために、AutoGraph（`tf.autograph`）というライブラリを使用しています。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PFObpff1BMEb"
      },
      "outputs": [],
      "source": [
        "def simple_relu(x):\n",
        "  if tf.greater(x, 0):\n",
        "    return x\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "# `tf_simple_relu` is a TensorFlow `Function` that wraps `simple_relu`.\n",
        "tf_simple_relu = tf.function(simple_relu)\n",
        "\n",
        "print(\"First branch, with graph:\", tf_simple_relu(tf.constant(1)).numpy())\n",
        "print(\"Second branch, with graph:\", tf_simple_relu(tf.constant(-1)).numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hO4DBUNZBMwQ"
      },
      "source": [
        "Though it is unlikely that you will need to view graphs directly, you can inspect the outputs to check the exact results. These are not easy to read, so no need to look too carefully!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lAKaat3w0gnn"
      },
      "outputs": [],
      "source": [
        "# This is the graph-generating output of AutoGraph.\n",
        "print(tf.autograph.to_code(simple_relu))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8x6RAqza1UWf"
      },
      "outputs": [],
      "source": [
        "# This is the graph itself.\n",
        "print(tf_simple_relu.get_concrete_function(tf.constant(1)).graph.as_graph_def())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZ4Ieg6tBE6l"
      },
      "source": [
        "Most of the time, `tf.function` will work without  special considerations. However, there are some caveats, and the <a href=\"./function.ipynb\" data-md-type=\"link\">`tf.function` guide</a> can help here, as well as the [complete AutoGraph reference](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/g3doc/reference/index.md)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIpc_jfjEZEg"
      },
      "source": [
        "### ポリモーフィズム: 1 つの `Function` で複数のグラフを得る\n",
        "\n",
        "`tf.Graph` は特定の型の入力（特定の [`dtype`](https://www.tensorflow.org/api_docs/python/tf/dtypes/DType) のテンソルまたは同じ [`id()` のオブジェクト](https://docs.python.org/3/library/functions.html#id%5D)など）に特化しています。\n",
        "\n",
        "Each time you invoke a `Function` with a set of arguments that can't be handled by any of its existing graphs (such as arguments with new `dtypes` or incompatible shapes), `Function` creates a new `tf.Graph` specialized to those new arguments. The type specification of a `tf.Graph`'s inputs is known as its **input signature** or just a **signature**. For more information regarding when a new `tf.Graph` is generated and how that can be controlled, go to the *Rules of tracing* section of the [Better performance with `tf.function`](./function.ipynb) guide.\n",
        "\n",
        "`Function` はそのシグネチャに対応する `tf.Graph` を `ConcreteFunction` に格納します。<strong data-md-type=\"raw_html\">`ConcreteFunction` は `tf.Graph` を囲むラッパーです。</strong>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LOASwhbvIv_T"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def my_relu(x):\n",
        "  return tf.maximum(0., x)\n",
        "\n",
        "# `my_relu` creates new graphs as it observes more signatures.\n",
        "print(my_relu(tf.constant(5.5)))\n",
        "print(my_relu([1, -1]))\n",
        "print(my_relu(tf.constant([3., -3.])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qRtw7R4KL9X"
      },
      "source": [
        "`Function` がそのシグネチャですでに呼び出されている場合、`Function` は新しい `tf.Graph` を作成しません。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TjjbnL5OKNDP"
      },
      "outputs": [],
      "source": [
        "# These two calls do *not* create new graphs.\n",
        "print(my_relu(tf.constant(-2.5))) # Signature matches `tf.constant(5.5)`.\n",
        "print(my_relu(tf.constant([-1., 1.]))) # Signature matches `tf.constant([3., -3.])`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UohRmexhIpvQ"
      },
      "source": [
        "Because it's backed by multiple graphs, a `Function` is **polymorphic**. That enables it to support more input types than a single `tf.Graph` could represent, and to optimize each `tf.Graph` for better performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dxzqebDYFmLy"
      },
      "outputs": [],
      "source": [
        "# There are three `ConcreteFunction`s (one for each graph) in `my_relu`.\n",
        "# The `ConcreteFunction` also knows the return type and shape!\n",
        "print(my_relu.pretty_printed_concrete_signatures())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V11zkxU22XeD"
      },
      "source": [
        "## `tf.function` を使用する\n",
        "\n",
        "So far, you've learned how to convert a Python function into a graph simply by using `tf.function` as a decorator or wrapper. But in practice, getting `tf.function` to work correctly can be tricky! In the following sections, you'll learn how you can make your code work as expected with `tf.function`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yp_n0B5-P0RU"
      },
      "source": [
        "### Graph execution と Eager execution\n",
        "\n",
        "`Function` 内のコードは、Eager と Graph の両方で実行できますが、デフォルトでは、`Function` は Graph としてコードを実行するようになっています。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_R0BOvBFxqVZ"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def get_MSE(y_true, y_pred):\n",
        "  sq_diff = tf.pow(y_true - y_pred, 2)\n",
        "  return tf.reduce_mean(sq_diff)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zikMVPGhmDET"
      },
      "outputs": [],
      "source": [
        "y_true = tf.random.uniform([5], maxval=10, dtype=tf.int32)\n",
        "y_pred = tf.random.uniform([5], maxval=10, dtype=tf.int32)\n",
        "print(y_true)\n",
        "print(y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "07r08Dh158ft"
      },
      "outputs": [],
      "source": [
        "get_MSE(y_true, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyZNCRcQorGO"
      },
      "source": [
        "To verify that your `Function`'s graph is doing the same computation as its equivalent Python function, you can make it execute eagerly with `tf.config.run_functions_eagerly(True)`. This is a switch that <strong data-md-type=\"double_emphasis\">turns off `Function`'s ability to create and run graphs</strong>, instead of executing the code normally."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lKoF6NjPoI8w"
      },
      "outputs": [],
      "source": [
        "tf.config.run_functions_eagerly(True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ZLqTyn0oKeM"
      },
      "outputs": [],
      "source": [
        "get_MSE(y_true, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cV7daQW9odn-"
      },
      "outputs": [],
      "source": [
        "# Don't forget to set it back when you are done.\n",
        "tf.config.run_functions_eagerly(False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKT3YBsqy0x4"
      },
      "source": [
        "However, `Function` can behave differently under graph and eager execution. The Python [`print`](https://docs.python.org/3/library/functions.html#print) function is one example of how these two modes differ. Let's check out what happens when you insert a `print` statement to your function and call it repeatedly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BEJeVeBEoGjV"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def get_MSE(y_true, y_pred):\n",
        "  print(\"Calculating MSE!\")\n",
        "  sq_diff = tf.pow(y_true - y_pred, 2)\n",
        "  return tf.reduce_mean(sq_diff)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3sWTGwX3BzP1"
      },
      "source": [
        "何が出力されるか観察しましょう。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3rJIeBg72T9n"
      },
      "outputs": [],
      "source": [
        "error = get_MSE(y_true, y_pred)\n",
        "error = get_MSE(y_true, y_pred)\n",
        "error = get_MSE(y_true, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLMXk1uxKQ44"
      },
      "source": [
        "この出力に驚きましたか？**`get_MSE` は *3 回*呼び出されたにもかかわらず、出力されたのは 1 回だけでした。**\n",
        "\n",
        "To explain, the `print` statement is executed when `Function` runs the original code in order to create the graph in a process known as \"tracing\" (refer to the *Tracing* section of the [`tf.function` guide](./function.ipynb). <strong data-md-type=\"double_emphasis\">Tracing captures the TensorFlow operations into a graph, and `print` is not captured in the graph.</strong>  That graph is then executed for all three calls **without ever running the Python code again**.\n",
        "\n",
        "サニティーチェックとして、Graph execution をオフにして比較してみましょう。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oFSxRtcptYpe"
      },
      "outputs": [],
      "source": [
        "# Now, globally set everything to run eagerly to force eager execution.\n",
        "tf.config.run_functions_eagerly(True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qYxrAtvzNgHR"
      },
      "outputs": [],
      "source": [
        "# Observe what is printed below.\n",
        "error = get_MSE(y_true, y_pred)\n",
        "error = get_MSE(y_true, y_pred)\n",
        "error = get_MSE(y_true, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Df6ynXcAaup"
      },
      "outputs": [],
      "source": [
        "tf.config.run_functions_eagerly(False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUR7qC_bquCn"
      },
      "source": [
        "`print` is a *Python side effect*, and there are other differences that you should be aware of when converting a function into a `Function`. Learn more in the *Limitations* section of the [Better performance with `tf.function`](./function.ipynb) guide."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTZJfV_tccVp"
      },
      "source": [
        "注意: Eager execution と Graph execution の両方で値を出力する場合は、代わりに `tf.print` を使用してください。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMT_Xf5yKn9o"
      },
      "source": [
        "### Non-strict execution\n",
        "\n",
        "<a id=\"non-strict\"></a>\n",
        "\n",
        "Graph execution only executes the operations necessary to produce the observable effects, which includes:\n",
        "\n",
        "- The return value of the function\n",
        "- Documented well-known side-effects such as:\n",
        "  - Input/output operations, like `tf.print`\n",
        "  - Debugging operations, such as the assert functions in `tf.debugging`\n",
        "  - Mutations of `tf.Variable`\n",
        "\n",
        "This behavior is usually known as \"Non-strict execution\", and differs from eager execution, which steps through all of the program operations, needed or not.\n",
        "\n",
        "In particular, runtime error checking does not count as an observable effect. If an operation is skipped because it is unnecessary, it cannot raise any runtime errors.\n",
        "\n",
        "In the following example, the \"unnecessary\" operation `tf.gather` is skipped during graph execution, so the runtime error `InvalidArgumentError` is not raised as it would be in eager execution. Do not rely on an error being raised while executing a graph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OdN0nKlUwj7M"
      },
      "outputs": [],
      "source": [
        "def unused_return_eager(x):\n",
        "  # Get index 1 will fail when `len(x) == 1`\n",
        "  tf.gather(x, [1]) # unused \n",
        "  return x\n",
        "\n",
        "try:\n",
        "  print(unused_return_eager(tf.constant([0.0])))\n",
        "except tf.errors.InvalidArgumentError as e:\n",
        "  # All operations are run during eager execution so an error is raised.\n",
        "  print(f'{type(e).__name__}: {e}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d80Fob4MwhTs"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def unused_return_graph(x):\n",
        "  tf.gather(x, [1]) # unused\n",
        "  return x\n",
        "\n",
        "# Only needed operations are run during graph execution. The error is not raised.\n",
        "print(unused_return_graph(tf.constant([0.0])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "def6MupG9R0O"
      },
      "source": [
        "### `tf.function` best practices\n",
        "\n",
        "`Function` の動作に慣れるまで、しばらく時間がかかるかもしれませんが、その時間を短縮するには、トイ関数に `@tf.function` をデコレートしていろいろ試しながら、Eager から Graph execution に切り替える経験を積むと良いでしょう。\n",
        "\n",
        "*Designing for `tf.function`* may be your best bet for writing graph-compatible TensorFlow programs. Here are some tips:\n",
        "\n",
        "- 早い段階で Eager execution と Graph execution を切り替えながら、2 つのモードで異なる結果を得るかどうか、またはそのタイミングを知るために `tf.config.run_functions_eagerly` を頻繁に使用しましょう。\n",
        "- Create `tf.Variable`s outside the Python function and modify them on the inside. The same goes for objects that use `tf.Variable`, like `tf.keras.layers`, `tf.keras.Model`s and `tf.keras.optimizers`.\n",
        "- Avoid writing functions that depend on outer Python variables, excluding `tf.Variable`s and Keras objects. Learn more in *Depending on Python global and free variables* of the [`tf.function` guide](./function.ipynb).\n",
        "- Prefer to write functions which take tensors and other TensorFlow types as input. You can pass in other object types but be careful! Learn more in *Depending on Python objects* of the [`tf.function` guide](./function.ipynb).\n",
        "- パフォーマンスを最大限に得るには、`tf.function` の下にできるだけ多くの計算を含めるようにしましょう。たとえば、トレーニングステップ全体またはトレーニングループ全体をデコレートすることができます。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ViM3oBJVJrDx"
      },
      "source": [
        "## 高速化の確認"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6NHDp7vAKcJ"
      },
      "source": [
        "コードのパフォーマンスは通常、`tf.function` によって改善されますが、改善率は実行する計算によって異なります。 小さな計算であれば、グラフ呼び出しのオーバーヘッドに制約を受ける可能性があります。パフォーマンスの変化は、次のようにして確認することができます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jr7p1BBjauPK"
      },
      "outputs": [],
      "source": [
        "x = tf.random.uniform(shape=[10, 10], minval=-1, maxval=2, dtype=tf.dtypes.int32)\n",
        "\n",
        "def power(x, y):\n",
        "  result = tf.eye(10, dtype=tf.dtypes.int32)\n",
        "  for _ in range(y):\n",
        "    result = tf.matmul(x, result)\n",
        "  return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ms2yJyAnUYxK"
      },
      "outputs": [],
      "source": [
        "print(\"Eager execution:\", timeit.timeit(lambda: power(x, 100), number=1000))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gUB2mTyRYRAe"
      },
      "outputs": [],
      "source": [
        "power_as_graph = tf.function(power)\n",
        "print(\"Graph execution:\", timeit.timeit(lambda: power_as_graph(x, 100), number=1000), \"seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1Pfo5YwwILi"
      },
      "source": [
        "`tf.function` is commonly used to speed up training loops, and you can learn more about it in the <em data-md-type=\"emphasis\">Speeding-up your training step with `tf.function`</em> section of the [Writing a training loop from scratch](https://www.tensorflow.org/guide/keras/writing_a_training_loop_from_scratch) with Keras guide.\n",
        "\n",
        "Note: You can also try `tf.function(jit_compile=True)` for a more significant performance boost, especially if your code is heavy on TensorFlow control flow and uses many small tensors. Learn more in the <em data-md-type=\"emphasis\">Explicit compilation with `tf.function(jit_compile=True)`</em> section of the [XLA overview](https://www.tensorflow.org/xla)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sm0bNFp8PX53"
      },
      "source": [
        "### パフォーマンスとトレードオフ\n",
        "\n",
        "Graphs can speed up your code, but the process of creating them has some overhead. For some functions, the creation of the graph takes more time than the execution of the graph. **This investment is usually quickly paid back with the performance boost of subsequent executions, but it's important to be aware that the first few  steps of any large model training can be slower due to tracing.**\n",
        "\n",
        "No matter how large your model, you want to avoid tracing frequently. The [`tf.function` guide](./function.ipynb) discusses how to set input specifications and use tensor arguments to avoid retracing in the *Controlling retracing* section. If you find you are getting unusually poor performance, it's a good idea to check if you are retracing accidentally."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4InDaTjwmBA"
      },
      "source": [
        "## `Function` がトレーシングしているタイミングを確認するには\n",
        "\n",
        "`Function` がトレーシングしているタイミングを確認するには、コードに `print` ステートメントを追加すれば、`Function` がトレーシングを行うたびに `print` ステートメントが実行されるようになります。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hXtwlbpofLgW"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def a_function_with_python_side_effect(x):\n",
        "  print(\"Tracing!\") # An eager-only side effect.\n",
        "  return x * x + tf.constant(2)\n",
        "\n",
        "# This is traced the first time.\n",
        "print(a_function_with_python_side_effect(tf.constant(2)))\n",
        "# The second time through, you won't see the side effect.\n",
        "print(a_function_with_python_side_effect(tf.constant(3)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "inzSg8yzfNjl"
      },
      "outputs": [],
      "source": [
        "# This retraces each time the Python argument changes,\n",
        "# as a Python argument could be an epoch count or other\n",
        "# hyperparameter.\n",
        "print(a_function_with_python_side_effect(2))\n",
        "print(a_function_with_python_side_effect(3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtN8NW6AfKye"
      },
      "source": [
        "New Python arguments always trigger the creation of a new graph, hence the extra tracing.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1kbr5ocpS6R"
      },
      "source": [
        "## 次のステップ\n",
        "\n",
        "You can learn more about `tf.function` on the API reference page and by following the <a href=\"./function.ipynb\" data-md-type=\"link\">Better performance with `tf.function`</a> guide."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "intro_to_graphs.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
