{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-23gBrt4x2B"
      },
      "source": [
        "##### Copyright 2021 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "HMUDt0CiUJk9"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77z2OchJTk0l"
      },
      "source": [
        "# `tf.feature_column` を Keras 前処理レイヤーに移行する\n",
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td><a target=\"_blank\" href=\"https://www.tensorflow.org/guide/migrate/migrating_feature_columns\"> <img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\"> TensorFlow.org で表示</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/ja/guide/migrate/migrating_feature_columns.ipynb\"> <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\"> Google Colab で実行</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/ja/guide/migrate/migrating_feature_columns.ipynb\"> <img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\"> GitHub でソースを表示</a></td>\n",
        "  <td><a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/ja/guide/migrate/migrating_feature_columns.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">ノートブックをダウンロード</a></td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5jGPDA2PDPI"
      },
      "source": [
        "通常、モデルのトレーニングには、特に構造化データを扱う場合に、特徴量の前処理が必要となることがあります。TensorFlow 1 で `tf.estimator.Estimator` をトレーニングする場合、通常、`tf.feature_column` API を使用して特徴量の前処理を実行します。TensorFlow 2 では、Keras 前処理レイヤーで直接実行できます。\n",
        "\n",
        "この移行ガイドでは、特徴量カラムと前処理レイヤーの両方を使用した一般的な特徴量変換を紹介し、両方の API を使用して完全なモデルをトレーニングします。\n",
        "\n",
        "まず、必要なものをインポートします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iE0vSfMXumKI"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.compat.v1 as tf1\n",
        "import math"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVPYTQAWtDwH"
      },
      "source": [
        "次に、デモのために特徴量カラムを呼び出すためのユーティリティ関数を追加します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LAaifuuytJjM"
      },
      "outputs": [],
      "source": [
        "def call_feature_columns(feature_columns, inputs):\n",
        "  # This is a convenient way to call a `feature_column` outside of an estimator\n",
        "  # to display its output.\n",
        "  feature_layer = tf1.keras.layers.DenseFeatures(feature_columns)\n",
        "  return feature_layer(inputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJnw07hYDGYt"
      },
      "source": [
        "## 入力処理\n",
        "\n",
        "Estimator で特徴量カラムを使用するには、モデル入力は常にテンソルのディクショナリであることが期待されます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y0WUpQxsKEzf"
      },
      "outputs": [],
      "source": [
        "input_dict = {\n",
        "  'foo': tf.constant([1]),\n",
        "  'bar': tf.constant([0]),\n",
        "  'baz': tf.constant([-1])\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYsC6H_BJ8l3"
      },
      "source": [
        "各特徴量カラムは、ソースデータにインデックスを付けるためのキーを使用して作成する必要があります。すべての特徴量カラムの出力は連結され、Estimator モデルによって使用されます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3fvIe3V8Ffjt"
      },
      "outputs": [],
      "source": [
        "columns = [\n",
        "  tf1.feature_column.numeric_column('foo'),\n",
        "  tf1.feature_column.numeric_column('bar'),\n",
        "  tf1.feature_column.numeric_column('baz'),\n",
        "]\n",
        "call_feature_columns(columns, input_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvPfCK2XGTyl"
      },
      "source": [
        "Keras では、モデル入力はより柔軟です。`tf.keras.Model` は、単一のテンソル入力、テンソル特徴量のリスト、またはテンソル特徴量のディクショナリを処理できます。モデルの作成時に `tf.keras.Input` のディクショナリを渡すことで、ディクショナリの入力を処理できます。入力は自動的に連結されないため、より柔軟な方法で使用できます。これらは `tf.keras.layers.Concatenate` で連結できます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5sYWENkgLWJ2"
      },
      "outputs": [],
      "source": [
        "inputs = {\n",
        "  'foo': tf.keras.Input(shape=()),\n",
        "  'bar': tf.keras.Input(shape=()),\n",
        "  'baz': tf.keras.Input(shape=()),\n",
        "}\n",
        "# Inputs are typically transformed by preprocessing layers before concatenation.\n",
        "outputs = tf.keras.layers.Concatenate()(inputs.values())\n",
        "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "model(input_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXkmiuwXTS-B"
      },
      "source": [
        "## One-hot エンコーディングの整数 ID\n",
        "\n",
        "一般的に、既知の範囲の整数入力を One-hot エンコードすることにより特徴量を変換できます。特徴量カラムを使用した例を次に示します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XasXzOgatgRF"
      },
      "outputs": [],
      "source": [
        "categorical_col = tf1.feature_column.categorical_column_with_identity(\n",
        "    'type', num_buckets=3)\n",
        "indicator_col = tf1.feature_column.indicator_column(categorical_col)\n",
        "call_feature_columns(indicator_col, {'type': [0, 1, 2]})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSCkJEQ6U-ru"
      },
      "source": [
        "Keras 前処理レイヤーを使用すると、これらのカラムを `output_mode` を `'one_hot'` に設定した単一の `tf.keras.layers.CategoryEncoding` レイヤーに置き換えることができます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "799lbMNNuAVz"
      },
      "outputs": [],
      "source": [
        "one_hot_layer = tf.keras.layers.CategoryEncoding(\n",
        "    num_tokens=3, output_mode='one_hot')\n",
        "one_hot_layer([0, 1, 2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNzRtESU7tga"
      },
      "source": [
        "注意: 大規模な One-hot エンコーディングの場合、出力のスパース表現を使用する方がはるかに効率的です。`sparse=True` を `CategoryEncoding` レイヤーに渡すと、レイヤーの出力は `tf.sparse.SparseTensor` になり、効率的に `tf.keras.layers.Dense` レイヤーへの入力として処理されます。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zf7kjhTiAErK"
      },
      "source": [
        "## 数値的特徴量の正規化\n",
        "\n",
        "特徴量カラムを持つ連続浮動小数点特徴量を処理する場合、`tf.feature_column.numeric_column` を使用する必要があります。入力が既に正規化されている場合、これを Keras に変換するのは簡単です。上記のように、`tf.keras.Input` をモデルに直接使用するだけです。\n",
        "\n",
        "`numeric_column` を使用して入力を正規化することもできます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HbTMGB9XctGx"
      },
      "outputs": [],
      "source": [
        "def normalize(x):\n",
        "  mean, variance = (2.0, 1.0)\n",
        "  return (x - mean) / math.sqrt(variance)\n",
        "numeric_col = tf1.feature_column.numeric_column('col', normalizer_fn=normalize)\n",
        "call_feature_columns(numeric_col, {'col': tf.constant([[0.], [1.], [2.]])})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9cyhPR_drOz"
      },
      "source": [
        "対照的に、Keras では、この正規化は `tf.keras.layers.Normalization` で実行できます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8bcgG-yOdqUH"
      },
      "outputs": [],
      "source": [
        "normalization_layer = tf.keras.layers.Normalization(mean=2.0, variance=1.0)\n",
        "normalization_layer(tf.constant([[0.], [1.], [2.]]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1InD_4QLKU-"
      },
      "source": [
        "## 数値特徴量のバケット化と One-hot エンコーディング"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5e0b8iOLRzd"
      },
      "source": [
        "連続する浮動小数点の入力を変換するもう 1 つの一般的な方法は、固定範囲の整数にバケット化することです。\n",
        "\n",
        "特徴量カラムでは、`tf.feature_column.bucketized_column` を使用します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_rbx6qQ-LQx7"
      },
      "outputs": [],
      "source": [
        "numeric_col = tf1.feature_column.numeric_column('col')\n",
        "bucketized_col = tf1.feature_column.bucketized_column(numeric_col, [1, 4, 5])\n",
        "call_feature_columns(bucketized_col, {'col': tf.constant([1., 2., 3., 4., 5.])})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCYu-XtwXahx"
      },
      "source": [
        "Keras では、これを `tf.keras.layers.Discretization` に置き換えます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QK1WOG2uVVsL"
      },
      "outputs": [],
      "source": [
        "discretization_layer = tf.keras.layers.Discretization(bin_boundaries=[1, 4, 5])\n",
        "one_hot_layer = tf.keras.layers.CategoryEncoding(\n",
        "    num_tokens=4, output_mode='one_hot')\n",
        "one_hot_layer(discretization_layer([1., 2., 3., 4., 5.]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bm9tJZAgpt4"
      },
      "source": [
        "## 語彙を使用した文字列データの One-hot エンコーディング\n",
        "\n",
        "文字列の特徴量を処理するには、多くの場合、文字列をインデックスに変換するために語彙の検索が必要です。特徴量カラムを使用して文字列を検索し、インデックスを One-hot エンコードする例を次に示します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3fG_igjhukCO"
      },
      "outputs": [],
      "source": [
        "vocab_col = tf1.feature_column.categorical_column_with_vocabulary_list(\n",
        "    'sizes',\n",
        "    vocabulary_list=['small', 'medium', 'large'],\n",
        "    num_oov_buckets=0)\n",
        "indicator_col = tf1.feature_column.indicator_column(vocab_col)\n",
        "call_feature_columns(indicator_col, {'sizes': ['small', 'medium', 'large']})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rBgllRtY738"
      },
      "source": [
        "Keras 前処理レイヤーを使用して、`output_mode` を `'one_hot'` に設定して `tf.keras.layers.StringLookup` レイヤーを使用します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "arnPlSrWvDMe"
      },
      "outputs": [],
      "source": [
        "string_lookup_layer = tf.keras.layers.StringLookup(\n",
        "    vocabulary=['small', 'medium', 'large'],\n",
        "    num_oov_indices=0,\n",
        "    output_mode='one_hot')\n",
        "string_lookup_layer(['small', 'medium', 'large'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f76MVVYO8LB5"
      },
      "source": [
        "注意: 大規模な One-hot エンコーディングの場合、出力のスパース表現を使用する方がはるかに効率的です。`sparse=True` を `StringLookup` レイヤーに渡すと、レイヤーの出力は `tf.sparse.SparseTensor` になり、効率的に `tf.keras.layers.Dense` レイヤーへの入力として処理されます。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1CmfSXQZHE5"
      },
      "source": [
        "## 語彙を使用した文字列データの埋め込み\n",
        "\n",
        "より大きな語彙の場合、パフォーマンスを向上させるために埋め込みが必要になることがよくあります。特徴量カラムを使用して文字列特徴量を埋め込む例を次に示します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C3RK4HFazxlU"
      },
      "outputs": [],
      "source": [
        "vocab_col = tf1.feature_column.categorical_column_with_vocabulary_list(\n",
        "    'col',\n",
        "    vocabulary_list=['small', 'medium', 'large'],\n",
        "    num_oov_buckets=0)\n",
        "embedding_col = tf1.feature_column.embedding_column(vocab_col, 4)\n",
        "call_feature_columns(embedding_col, {'col': ['small', 'medium', 'large']})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3aTRVJ6qZZH0"
      },
      "source": [
        "これは、Keras 前処理レイヤーを使用して、`tf.keras.layers.StringLookup` レイヤーと `tf.keras.layers.Embedding` レイヤーを組み合わせることで実現できます。`StringLookup` のデフォルトの出力は、埋め込みに直接入力できる整数インデックスになります。\n",
        "\n",
        "注意: `Embedding` レイヤーには、トレーニング可能なパラメータが含まれています。`StringLookup` レイヤーはモデルの内部または外部のデータに適用できますが、正しくトレーニングするには、`Embedding` が常にトレーニング可能な Keras モデルの一部である必要があります。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8resGZPo0Fho"
      },
      "outputs": [],
      "source": [
        "string_lookup_layer = tf.keras.layers.StringLookup(\n",
        "    vocabulary=['small', 'medium', 'large'], num_oov_indices=0)\n",
        "embedding = tf.keras.layers.Embedding(3, 4)\n",
        "embedding(string_lookup_layer(['small', 'medium', 'large']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwqvADV6HRdC"
      },
      "source": [
        "## 重み付きカテゴリカルデータの和\n",
        "\n",
        "場合によっては、重みが関連付けられているカテゴリが出現するたびにカテゴリカルデータを処理する必要があります。特徴量カラムでは、これは `tf.feature_column.weighted_categorical_column` で処理されます。`indicator_column` と組み合わせると、カテゴリごとの重みの和を計算できます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "02HqjPLMRxWn"
      },
      "outputs": [],
      "source": [
        "ids = tf.constant([[5, 11, 5, 17, 17]])\n",
        "weights = tf.constant([[0.5, 1.5, 0.7, 1.8, 0.2]])\n",
        "\n",
        "categorical_col = tf1.feature_column.categorical_column_with_identity(\n",
        "    'ids', num_buckets=20)\n",
        "weighted_categorical_col = tf1.feature_column.weighted_categorical_column(\n",
        "    categorical_col, 'weights')\n",
        "indicator_col = tf1.feature_column.indicator_column(weighted_categorical_col)\n",
        "call_feature_columns(indicator_col, {'ids': ids, 'weights': weights})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98jaq7Q3S9aG"
      },
      "source": [
        "Keras では、これは `output_mode='count'` で `count_weights` 入力を `tf.keras.layers.CategoryEncoding` に渡すことで実行できます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JsoYUUgRS7hu"
      },
      "outputs": [],
      "source": [
        "ids = tf.constant([[5, 11, 5, 17, 17]])\n",
        "weights = tf.constant([[0.5, 1.5, 0.7, 1.8, 0.2]])\n",
        "\n",
        "# Using sparse output is more efficient when `num_tokens` is large.\n",
        "count_layer = tf.keras.layers.CategoryEncoding(\n",
        "    num_tokens=20, output_mode='count', sparse=True)\n",
        "tf.sparse.to_dense(count_layer(ids, count_weights=weights))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBJxb6y2GasI"
      },
      "source": [
        "## 重み付きカテゴリカルデータの埋め込み\n",
        "\n",
        "または、重み付きカテゴリカル入力を埋め込みたい場合もあります。特徴量カラムでは、`embedding_column` に `combiner` 引数が含まれています。サンプルにカテゴリの複数のエントリが含まれている場合、それらは引数の設定（デフォルトでは `'mean'`）に従って結合されます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AjOt1wgmT5mM"
      },
      "outputs": [],
      "source": [
        "ids = tf.constant([[5, 11, 5, 17, 17]])\n",
        "weights = tf.constant([[0.5, 1.5, 0.7, 1.8, 0.2]])\n",
        "\n",
        "categorical_col = tf1.feature_column.categorical_column_with_identity(\n",
        "    'ids', num_buckets=20)\n",
        "weighted_categorical_col = tf1.feature_column.weighted_categorical_column(\n",
        "    categorical_col, 'weights')\n",
        "embedding_col = tf1.feature_column.embedding_column(\n",
        "    weighted_categorical_col, 4, combiner='mean')\n",
        "call_feature_columns(embedding_col, {'ids': ids, 'weights': weights})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fd6eluARXndC"
      },
      "source": [
        "Keras では、`tf.keras.layers.Embedding` に対する `combiner` オプションはありませんが、`tf.keras.layers.Dense` で同じ効果を実現できます。上記の `embedding_column` は、カテゴリの重みに従って埋め込みベクトルを単純に線形結合しています。一見明らかではありませんが、カテゴリカル入力をサイズ `(num_tokens)` の疎な重みベクトルとして表し、形状 `(embedding_size, num_tokens)` の `Dense` カーネルを掛けるのとまったく同じです。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y-vZvPyiYilE"
      },
      "outputs": [],
      "source": [
        "ids = tf.constant([[5, 11, 5, 17, 17]])\n",
        "weights = tf.constant([[0.5, 1.5, 0.7, 1.8, 0.2]])\n",
        "\n",
        "# For `combiner='mean'`, normalize your weights to sum to 1. Removing this line\n",
        "# would be equivalent to an `embedding_column` with `combiner='sum'`.\n",
        "weights = weights / tf.reduce_sum(weights, axis=-1, keepdims=True)\n",
        "\n",
        "count_layer = tf.keras.layers.CategoryEncoding(\n",
        "    num_tokens=20, output_mode='count', sparse=True)\n",
        "embedding_layer = tf.keras.layers.Dense(4, use_bias=False)\n",
        "embedding_layer(count_layer(ids, count_weights=weights))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3I5loEx80MVm"
      },
      "source": [
        "## 完全なトレーニングサンプル\n",
        "\n",
        "完全なトレーニングワークフローでは、まず、異なる型の 3 つの特徴量を含むいくつかのデータを準備します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D_7nyBee0ZBV"
      },
      "outputs": [],
      "source": [
        "features = {\n",
        "    'type': [0, 1, 1],\n",
        "    'size': ['small', 'small', 'medium'],\n",
        "    'weight': [2.7, 1.8, 1.6],\n",
        "}\n",
        "labels = [1, 1, 0]\n",
        "predict_features = {'type': [0], 'size': ['foo'], 'weight': [-0.7]}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_4Xx2c37lqD"
      },
      "source": [
        "TensorFlow 1 と TensorFlow 2 の両方のワークフローに共通する定数をいくつか定義します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3cyfQZ7z8jZh"
      },
      "outputs": [],
      "source": [
        "vocab = ['small', 'medium', 'large']\n",
        "one_hot_dims = 3\n",
        "embedding_dims = 4\n",
        "weight_mean = 2.0\n",
        "weight_variance = 1.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywCgU7CMIfTH"
      },
      "source": [
        "### 特徴量カラムを使用する\n",
        "\n",
        "特徴量カラムは、作成時に Estimator にリストとして渡す必要があり、トレーニング中に暗黙的に呼び出されます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wsdhlm-uipr1"
      },
      "outputs": [],
      "source": [
        "categorical_col = tf1.feature_column.categorical_column_with_identity(\n",
        "    'type', num_buckets=one_hot_dims)\n",
        "# Convert index to one-hot; e.g. [2] -> [0,0,1].\n",
        "indicator_col = tf1.feature_column.indicator_column(categorical_col)\n",
        "\n",
        "# Convert strings to indices; e.g. ['small'] -> [1].\n",
        "vocab_col = tf1.feature_column.categorical_column_with_vocabulary_list(\n",
        "    'size', vocabulary_list=vocab, num_oov_buckets=1)\n",
        "# Embed the indices.\n",
        "embedding_col = tf1.feature_column.embedding_column(vocab_col, embedding_dims)\n",
        "\n",
        "normalizer_fn = lambda x: (x - weight_mean) / math.sqrt(weight_variance)\n",
        "# Normalize the numeric inputs; e.g. [2.0] -> [0.0].\n",
        "numeric_col = tf1.feature_column.numeric_column(\n",
        "    'weight', normalizer_fn=normalizer_fn)\n",
        "\n",
        "estimator = tf1.estimator.DNNClassifier(\n",
        "    feature_columns=[indicator_col, embedding_col, numeric_col],\n",
        "    hidden_units=[1])\n",
        "\n",
        "def _input_fn():\n",
        "  return tf1.data.Dataset.from_tensor_slices((features, labels)).batch(1)\n",
        "\n",
        "estimator.train(_input_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPIeG_YtfNV1"
      },
      "source": [
        "また、特徴量カラムは、モデルで推論を実行するときに入力データを変換するためにも使用されます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-AIIB8CfSqt"
      },
      "outputs": [],
      "source": [
        "def _predict_fn():\n",
        "  return tf1.data.Dataset.from_tensor_slices(predict_features).batch(1)\n",
        "\n",
        "next(estimator.predict(_predict_fn))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baMA01cBIivo"
      },
      "source": [
        "### Keras 前処理レイヤーを使用する\n",
        "\n",
        "Keras の前処理レイヤーは、より柔軟に呼び出せます。レイヤーはテンソルに直接適用したり、`tf.data` 入力パイプライン内で使用したり、トレーニング可能な Keras モデルに直接構築したりできます。\n",
        "\n",
        "この例では、`tf.data` 入力パイプライン内に前処理レイヤーを適用します。これを行うには、別の `tf.keras.Model` を定義して、入力する特徴量を前処理します。このモデルはトレーニング可能ではありませんが、前処理レイヤーをグループ化する便利な方法です。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NMz8RfMQdCZf"
      },
      "outputs": [],
      "source": [
        "inputs = {\n",
        "  'type': tf.keras.Input(shape=(), dtype='int64'),\n",
        "  'size': tf.keras.Input(shape=(), dtype='string'),\n",
        "  'weight': tf.keras.Input(shape=(), dtype='float32'),\n",
        "}\n",
        "# Convert index to one-hot; e.g. [2] -> [0,0,1].\n",
        "type_output = tf.keras.layers.CategoryEncoding(\n",
        "      one_hot_dims, output_mode='one_hot')(inputs['type'])\n",
        "# Convert size strings to indices; e.g. ['small'] -> [1].\n",
        "size_output = tf.keras.layers.StringLookup(vocabulary=vocab)(inputs['size'])\n",
        "# Normalize the numeric inputs; e.g. [2.0] -> [0.0].\n",
        "weight_output = tf.keras.layers.Normalization(\n",
        "      axis=None, mean=weight_mean, variance=weight_variance)(inputs['weight'])\n",
        "outputs = {\n",
        "  'type': type_output,\n",
        "  'size': size_output,\n",
        "  'weight': weight_output,\n",
        "}\n",
        "preprocessing_model = tf.keras.Model(inputs, outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRfISnj3NGlW"
      },
      "source": [
        "注意: レイヤー作成時に語彙と正規化統計を提供する代わりに、多くの前処理レイヤーは、入力データからレイヤーの状態を直接学習するための `adapt()` メソッドを提供します。詳細については、[前処理ガイド](https://www.tensorflow.org/guide/keras/preprocessing_layers#the_adapt_method)を参照してください。\n",
        "\n",
        "`tf.data.Dataset.map` への呼び出し内でこのモデルを適用できるようになりました。`map` に渡される関数は自動的に `tf.function` に変換され、`tf.function` コードを記述する際の通常の注意事項が適用されることに注意してください（副作用はありません）。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c_6xAUnbNREh"
      },
      "outputs": [],
      "source": [
        "# Apply the preprocessing in tf.data.Dataset.map.\n",
        "dataset = tf.data.Dataset.from_tensor_slices((features, labels)).batch(1)\n",
        "dataset = dataset.map(lambda x, y: (preprocessing_model(x), y),\n",
        "                      num_parallel_calls=tf.data.AUTOTUNE)\n",
        "# Display a preprocessed input sample.\n",
        "next(dataset.take(1).as_numpy_iterator())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_4u3J4NdJ8R"
      },
      "source": [
        "次に、トレーニング可能なレイヤーを含む別の `Model` を定義します。このモデルへの入力が、前処理された特徴量の型と形状をどのように反映しているかに注目してください。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kC9OZO5ldmP-"
      },
      "outputs": [],
      "source": [
        "inputs = {\n",
        "  'type': tf.keras.Input(shape=(one_hot_dims,), dtype='float32'),\n",
        "  'size': tf.keras.Input(shape=(), dtype='int64'),\n",
        "  'weight': tf.keras.Input(shape=(), dtype='float32'),\n",
        "}\n",
        "# Since the embedding is trainable, it needs to be part of the training model.\n",
        "embedding = tf.keras.layers.Embedding(len(vocab), embedding_dims)\n",
        "outputs = tf.keras.layers.Concatenate()([\n",
        "  inputs['type'],\n",
        "  embedding(inputs['size']),\n",
        "  tf.expand_dims(inputs['weight'], -1),\n",
        "])\n",
        "outputs = tf.keras.layers.Dense(1)(outputs)\n",
        "training_model = tf.keras.Model(inputs, outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ir-cn2H_d5R7"
      },
      "source": [
        "`training_model` を `tf.keras.Model.fit` でトレーニングできるようになりました。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6TS3YJ2vnvlW"
      },
      "outputs": [],
      "source": [
        "# Train on the preprocessed data.\n",
        "training_model.compile(\n",
        "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True))\n",
        "training_model.fit(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSaEbOE4ecsy"
      },
      "source": [
        "最後に、推論時に、これらの個別の段階を組み合わせて、生の特徴量入力を処理する単一のモデルにすると便利です。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QHjbIZYneboO"
      },
      "outputs": [],
      "source": [
        "inputs = preprocessing_model.input\n",
        "outputs = training_model(preprocessing_model(inputs))\n",
        "inference_model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "predict_dataset = tf.data.Dataset.from_tensor_slices(predict_features).batch(1)\n",
        "inference_model.predict(predict_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O01VQIxCWBxU"
      },
      "source": [
        "この合成モデルは、後で使用するために `.keras` ファイルとして保存できます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6tsyVZgh7Pve"
      },
      "outputs": [],
      "source": [
        "inference_model.save('model.keras')\n",
        "restored_model = tf.keras.models.load_model('model.keras')\n",
        "restored_model.predict(predict_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXMBwzggwUjI"
      },
      "source": [
        "注意: 前処理レイヤーはトレーニングできないため、`tf.data` を使用して*非同期*で適用できます。これには、前処理されたバッチをプリフェッチし、アクセラレータを解放してモデルの微分可能な部分に集中できるため、パフォーマンス上の利点があります（詳細については、<a data-md-type=\"raw_html\" href=\"../data_performance.ipynb\">`tf.data` API によるパフォーマンスの向上</a>ガイドの*プリフェッチ*セクションを参照してください）。このガイドが示すように、トレーニング中に前処理を分離し、推論中にそれを構成することは、これらのパフォーマンスの向上を活用する柔軟な方法です。ただし、モデルが小さい場合や前処理時間を無視できる場合は、最初から完全なモデルに前処理を組み込む方が簡単な場合があります。これを行うには、`tf.keras.Input` で始まる単一のモデルを構築し、その後に前処理レイヤー、その後にトレーニング可能なレイヤーを構築します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pjp7Z18gRCQ"
      },
      "source": [
        "## 特徴量カラムに対応する Keras レイヤー\n",
        "\n",
        "参考までに、特徴量カラムにほぼ対応する Keras 前処理レイヤーを次に示します。\n",
        "\n",
        "<table>\n",
        "<div>  <tr>\n",
        "    <th>特徴量カラム</th>\n",
        "    <th>Keras レイヤー</th>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>`tf.feature_column.bucketized_column`</td>\n",
        "    <td>`tf.keras.layers.Discretization`</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>`tf.feature_column.categorical_column_with_hash_bucket`</td>\n",
        "    <td>`tf.keras.layers.Hashing`</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>`tf.feature_column.categorical_column_with_identity`</td>\n",
        "    <td>`tf.keras.layers.CategoryEncoding`</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>`tf.feature_column.categorical_column_with_vocabulary_file`</td>\n",
        "    <td>`tf.keras.layers.StringLookup` または `tf.keras.layers.IntegerLookup`</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>`tf.feature_column.categorical_column_with_vocabulary_list`</td>\n",
        "    <td>`tf.keras.layers.StringLookup` または `tf.keras.layers.IntegerLookup`</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>`tf.feature_column.crossed_column`</td>\n",
        "    <td>`tf.keras.layers.experimental.preprocessing.HashedCrossing`</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>`tf.feature_column.embedding_column`</td>\n",
        "    <td>`tf.keras.layers.Embedding`</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>`tf.feature_column.indicator_column`</td>\n",
        "    <td>`output_mode='one_hot'` または `output_mode='multi_hot'`*</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>`tf.feature_column.numeric_column`</td>\n",
        "    <td>`tf.keras.layers.Normalization`</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>`tf.feature_column.sequence_categorical_column_with_hash_bucket`</td>\n",
        "    <td>`tf.keras.layers.Hashing`</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>`tf.feature_column.sequence_categorical_column_with_identity`</td>\n",
        "    <td>`tf.keras.layers.CategoryEncoding`</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>`tf.feature_column.sequence_categorical_column_with_vocabulary_file`</td>\n",
        "    <td>`tf.keras.layers.StringLookup`、`tf.keras.layers.IntegerLookup`、または `tf.keras.layer.TextVectorization`†</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>`tf.feature_column.sequence_categorical_column_with_vocabulary_list`</td>\n",
        "    <td>`tf.keras.layers.StringLookup`、`tf.keras.layers.IntegerLookup`、または `tf.keras.layer.TextVectorization`†</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>`tf.feature_column.sequence_numeric_column`</td>\n",
        "    <td>`tf.keras.layers.Normalization`</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>`tf.feature_column.weighted_categorical_column`</td>\n",
        "    <td>`tf.keras.layers.CategoryEncoding`</td>\n",
        "  </tr>\n",
        "</div>\n",
        "</table>\n",
        "\n",
        "† `tf.keras.layers.TextVectorization` は、自由形式のテキスト入力 （文全体または段落全体など）を直接処理できます。これは、TensorFlow 1 でのカテゴリカルシーケンス処理の 1 対 1 の置き換えではありませんが、アドホックテキスト前処理の便利な置き換えを提供します。\n",
        "\n",
        "† `tf.keras.layers.TextVectorization` は、自由形式のテキスト入力 （文全体または段落全体など）を直接処理できます。これは、TensorFlow 1 でのカテゴリカルシーケンス処理の 1 対 1 の置き換えではありませんが、アドホックテキスト前処理の便利な置き換えを提供します。\n",
        "\n",
        "注意: `tf.estimator.LinearClassifier` などの線形 Estimator は、`embedding_column` または `indicator_column` なしで直接のカテゴリカル入力（整数インデックス）を処理できます。ただし、整数インデックスを `tf.keras.layers.Dense` または `tf.keras.experimental.LinearModel` に直接渡すことはできません。これらの入力は、 `Dense` または `LinearModel` を呼び出す前に最初に `tf.layers.CategoryEncoding` で `output_mode='count'`（カテゴリサイズが大きい場合は `sparse=True`）でエンコードする必要があります）。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQCJ6lM3YDq_"
      },
      "source": [
        "## 次のステップ\n",
        "\n",
        "- Keras 前処理レイヤーの詳細については、[前処理レイヤーの操作](https://www.tensorflow.org/guide/keras/preprocessing_layers)ガイドを参照してください。\n",
        "- 前処理レイヤーを構造化データに適用する詳細な例については、[Keras 前処理レイヤーを使用して構造化データを分類する](../../tutorials/structured_data/preprocessing_layers.ipynb)チュートリアルを参照してください。"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "migrating_feature_columns.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
