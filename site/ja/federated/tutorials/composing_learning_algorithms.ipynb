{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkdnLiKk71g-"
      },
      "source": [
        "##### Copyright 2022 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "0asMuNro71hA"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXslvcRocA-0"
      },
      "source": [
        "# 学習アルゴリズムを作成する"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XBJJIqwcXKd"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td><a target=\"_blank\" href=\"https://www.tensorflow.org/federated/tutorials/composing_learning_algorithms\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">     TensorFlow.org で表示</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/ja/federated/tutorials/composing_learning_algorithms.ipynb\">     <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">     Google Colab で実行</a>\n",
        "  <td><a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/ja/federated/tutorials/composing_learning_algorithms.ipynb\">     <img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">     GitHubでソースを表示</a></td>\n",
        "  <td><a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/ja/federated/tutorials/composing_learning_algorithms.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">ノートブックをダウンロード</a></td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnUwFbCAKB2r"
      },
      "source": [
        "## 始める前に\n",
        "\n",
        "始める前に、環境が正しくセットアップされていることを確認するために、以下を実行してください。動作しない場合は、[インストール](../install.md)ガイドで手順を確認してください。 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZrGitA_KnRO0"
      },
      "outputs": [],
      "source": [
        "#@test {\"skip\": true}\n",
        "!pip install --quiet --upgrade tensorflow-federated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HGTM6tWOLo8M"
      },
      "outputs": [],
      "source": [
        "from collections.abc import Callable\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_federated as tff"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yr3ztf28fa1F"
      },
      "source": [
        "**注意**: この Colab は [最新リリースバージョン](https://github.com/tensorflow/federated#compatibility)の `tensorflow_federated` pip パッケージでの動作が確認されていますが、Tensorflow Federated プロジェクトは現在もプレリリース開発の段階にあるため、`main` では動作しない可能性があります。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFlTaHe0jV2S"
      },
      "source": [
        "# 学習アルゴリズムを作成する"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zQlyijofSzI"
      },
      "source": [
        "「[独自の連合学習アルゴリズムを構築する](https://github.com/tensorflow/federated/blob/v0.62.0/docs/tutorials/building_your_own_federated_learning_algorithm.ipynb)」では、TFF の連合コアを使用して直接 Federated Averaging（FedAvg）アルゴリズムのバージョンを実装しました。\n",
        "\n",
        "このチュートリアルでは、ゼロからすべてを再実装する必要のないように、TFF の API にある連合学習コンポーネントを使用してモジュール形式で連合学習アルゴリズムをを構築します。\n",
        "\n",
        "このチュートリアルの目的により、ローカルトレーニングで勾配クリッピングを使用するバリエーションの FedAvg を実装することにします。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHwcFnLAjqcG"
      },
      "source": [
        "## 学習アルゴリズムのビルディングブロック\n",
        "\n",
        "多数の学習アルゴリズムは、**ビルディングブロック**と呼ばれる以下の 4 つのコンポーネントに大きく分けることができます。\n",
        "\n",
        "1. ディストリビュータ（サーバーからクライアントへの通信）\n",
        "2. クライアントワーク（ローカルクライアントの計算）\n",
        "3. アグリゲータ（クライアントからサーバーへの通信）\n",
        "4. ファイナライザ（集約したクライアント出力を使用したサーバーの計算）"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwhOtjlvjboB"
      },
      "source": [
        "[「独自の連合学習アルゴリズムを構築する」チュートリアル](https://github.com/tensorflow/federated/blob/v0.62.0/docs/tutorials/building_your_own_federated_learning_algorithm.ipynb)では、これらすべてのビルディングブロックをゼロから実装しましたが、ほとんどの場合、そうする必要はありません。代わりに、似たようなアルゴリズムのビルディングブロックを再利用することができます。\n",
        "\n",
        "この場合、勾配クリッピングを伴う FedAvg を実装するには、**クライアントワーク**のビルディングブロックのみを変更するだけで済みます。残りのブロックは、「バニラ」FedAvg と同じものを使用することが可能です。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMnd0RvGlGjK"
      },
      "source": [
        "# クライアントワークを実装する\n",
        "\n",
        "まず、勾配クリッピングでローカルモデルトレーニングを行う TF ロジックを記述しましょう。単純さを考慮し、勾配は最大 1 でノルムを持つようにクリッピングされます。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lqZ-c4MphTU"
      },
      "source": [
        "## TF ロジック"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pIw7QQCqltdV"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def client_update(model: tff.learning.models.VariableModel,\n",
        "                  dataset: tf.data.Dataset,\n",
        "                  server_weights: tff.learning.models.ModelWeights,\n",
        "                  client_optimizer: tf.keras.optimizers.Optimizer):\n",
        "  \"\"\"Performs training (using the server model weights) on the client's dataset.\"\"\"\n",
        "  # Initialize the client model with the current server weights.\n",
        "  client_weights = tff.learning.models.ModelWeights.from_model(model)\n",
        "  tf.nest.map_structure(lambda x, y: x.assign(y),\n",
        "                        client_weights, server_weights)\n",
        "\n",
        "  # Use the client_optimizer to update the local model.\n",
        "  # Keep track of the number of examples as well.\n",
        "  num_examples = 0.0\n",
        "  for batch in dataset:\n",
        "    with tf.GradientTape() as tape:\n",
        "      # Compute a forward pass on the batch of data\n",
        "      outputs = model.forward_pass(batch)\n",
        "      num_examples += tf.cast(outputs.num_examples, tf.float32)\n",
        "\n",
        "    # Compute the corresponding gradient\n",
        "    grads = tape.gradient(outputs.loss, client_weights.trainable)\n",
        "\n",
        "    # Compute the gradient norm and clip\n",
        "    gradient_norm = tf.linalg.global_norm(grads)\n",
        "    if gradient_norm > 1:\n",
        "      grads = tf.nest.map_structure(lambda x: x/gradient_norm, grads)\n",
        "\n",
        "    grads_and_vars = zip(grads, client_weights.trainable)\n",
        "\n",
        "    # Apply the gradient using a client optimizer.\n",
        "    client_optimizer.apply_gradients(grads_and_vars)\n",
        "\n",
        "  # Compute the difference between the server weights and the client weights\n",
        "  client_update = tf.nest.map_structure(tf.subtract,\n",
        "                                        client_weights.trainable,\n",
        "                                        server_weights.trainable)\n",
        "\n",
        "  return tff.learning.templates.ClientResult(\n",
        "      update=client_update, update_weight=num_examples)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fe_emK8LpQe0"
      },
      "source": [
        "上記のコードについて重要なポイントがいくつかあります。1 つ目は、確認されるサンプル数を追跡することです。これは、クライアント更新の*重み*を構成します（クライアント間の平均を計算する場合）。\n",
        "\n",
        "2 つ目は、出力のパッケージ化に [`tff.learning.templates.ClientResult`](https://www.tensorflow.org/federated/api_docs/python/tff/learning/templates/ClientResult) を使用していることです。この戻り値の型は、`tff.learning` でクライアントワークのビルディングブロックを標準化するために使用されます。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5aKjB1Vpiv3"
      },
      "source": [
        "## ClientWorkProcess を作成する"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6IvXUJAzm8ab"
      },
      "source": [
        "上記の TF ロジックはクリッピングを伴うローカルトレーニングを実行しますが、必要なビルディングブロックを作成するには、TFF コードでラップされている必要があります。\n",
        "\n",
        "具体的には、4 つのビルディングブロックは [`tff.templates.MeasuredProcess`](https://www.tensorflow.org/federated/api_docs/python/tff/templates/MeasuredProcess) として表現されます。つまり、4 つすべてのブロックに、計算を初期化して実行するために使用される `initialize` と `next` 関数の両方が含まれるということです。\n",
        "\n",
        "これにより、各ビルディングブロックは演算を実行するために必要なそれぞれの**状態**（サーバーに保存）を追跡できます。このチュートリアルでは使用されませんが、イテレーションが何回行われたかを追跡したり、オプティマイザの状態を追跡したりすることができます。\n",
        "\n",
        "クライアントワーク TF ロジックは一般に [`tff.learning.templates.ClientWorkProcess`](https://www.tensorflow.org/federated/api_docs/python/tff/learning/templates/ClientWorkProcess) としてラップされます。これは、クライアントのローカルトレーニングで入出力する期待される型をコード化するものです。モデルとオプティマイザによって、以下のようにパラメータ化することができます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X-I-jPsZmmMy"
      },
      "outputs": [],
      "source": [
        "def build_gradient_clipping_client_work(\n",
        "    model_fn: Callable[[], tff.learning.models.VariableModel],\n",
        "    optimizer_fn: Callable[[], tf.keras.optimizers.Optimizer],\n",
        ") -> tff.learning.templates.ClientWorkProcess:\n",
        "  \"\"\"Creates a client work process that uses gradient clipping.\"\"\"\n",
        "\n",
        "  with tf.Graph().as_default():\n",
        "    # Wrap model construction in a graph to avoid polluting the global context\n",
        "    # with variables created for this model.\n",
        "    model = model_fn()\n",
        "  data_type = tff.SequenceType(model.input_spec)\n",
        "  model_weights_type = tff.learning.models.weights_type_from_model(model)\n",
        "\n",
        "  @tff.federated_computation\n",
        "  def initialize_fn():\n",
        "    return tff.federated_value((), tff.SERVER)\n",
        "\n",
        "  @tff.tf_computation(model_weights_type, data_type)\n",
        "  def client_update_computation(model_weights, dataset):\n",
        "    model = model_fn()\n",
        "    optimizer = optimizer_fn()\n",
        "    return client_update(model, dataset, model_weights, optimizer)\n",
        "\n",
        "  @tff.federated_computation(\n",
        "      initialize_fn.type_signature.result,\n",
        "      tff.type_at_clients(model_weights_type),\n",
        "      tff.type_at_clients(data_type)\n",
        "  )\n",
        "  def next_fn(state, model_weights, client_dataset):\n",
        "    client_result = tff.federated_map(\n",
        "        client_update_computation, (model_weights, client_dataset))\n",
        "    # Return empty measurements, though a more complete algorithm might\n",
        "    # measure something here.\n",
        "    measurements = tff.federated_value((), tff.SERVER)\n",
        "    return tff.templates.MeasuredProcessOutput(state, client_result,\n",
        "                                               measurements)\n",
        "  return tff.learning.templates.ClientWorkProcess(\n",
        "      initialize_fn, next_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMUX0d0Sx1Gq"
      },
      "source": [
        "# 学習アルゴリズムを作成する\n",
        "\n",
        "上記のクライアントワークを本格的なアルゴリズムへと展開していきましょう。まず、データとモデルをセットアップします。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQ_N9XbULo8P"
      },
      "source": [
        "## 入力データを準備する\n",
        "\n",
        "TFF に含まれる EMNIST データセットを読み込んで前処理します。詳細については、[画像分類](federated_learning_for_image_classification.ipynb)チュートリアルをご覧ください。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-WdnFluLLo8P"
      },
      "outputs": [],
      "source": [
        "emnist_train, emnist_test = tff.simulation.datasets.emnist.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kq8893GogB8E"
      },
      "source": [
        "データセットをモデルにフィードするには、データをフラット化してタプル形式 `(flattened_image_vector, label)` に変換します。\n",
        "\n",
        "次に、少数のクライアントを選択し、上記の前処理をデータセットに適用します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Blrh8zJgLo8R"
      },
      "outputs": [],
      "source": [
        "NUM_CLIENTS = 10\n",
        "BATCH_SIZE = 20\n",
        "\n",
        "def preprocess(dataset):\n",
        "\n",
        "  def batch_format_fn(element):\n",
        "    \"\"\"Flatten a batch of EMNIST data and return a (features, label) tuple.\"\"\"\n",
        "    return (tf.reshape(element['pixels'], [-1, 784]), \n",
        "            tf.reshape(element['label'], [-1, 1]))\n",
        "\n",
        "  return dataset.batch(BATCH_SIZE).map(batch_format_fn)\n",
        "\n",
        "client_ids = sorted(emnist_train.client_ids)[:NUM_CLIENTS]\n",
        "federated_train_data = [preprocess(emnist_train.create_tf_dataset_for_client(x))\n",
        "  for x in client_ids\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNO_Y9j_Lo8X"
      },
      "source": [
        "## モデルを準備する"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJ0I89ixz8yV"
      },
      "source": [
        "これは、[画像分類](federated_learning_for_image_classification.ipynb)チュートリアルと同じモデルを使用します。このモデル（`tf.keras` 経由で実装）には、非表示レイヤーと、その後にソフトマックスレイヤーが含まれています。このモデルを TFF で使用するために、Keras モデルは [`tff.learning.Model`](https://www.tensorflow.org/federated/api_docs/python/tff/learning/Model) としてラップします。こうすることで、TFF 内でモデルの[フォワードパス](https://www.tensorflow.org/federated/api_docs/python/tff/learning/Model#forward_pass)と[モデル出力の抽出](https://www.tensorflow.org/federated/api_docs/python/tff/learning/Model#report_local_unfinalized_metrics)を実行できるようになります。詳細については、[画像分類](federated_learning_for_image_classification.ipynb)チュートリアルをご覧ください。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yfld4oFNLo8Y"
      },
      "outputs": [],
      "source": [
        "def create_keras_model():\n",
        "  initializer = tf.keras.initializers.GlorotNormal(seed=0)\n",
        "  return tf.keras.models.Sequential([\n",
        "      tf.keras.layers.Input(shape=(784,)),\n",
        "      tf.keras.layers.Dense(10, kernel_initializer=initializer),\n",
        "      tf.keras.layers.Softmax(),\n",
        "  ])\n",
        "\n",
        "def model_fn():\n",
        "  keras_model = create_keras_model()\n",
        "  return tff.learning.models.from_keras_model(\n",
        "      keras_model,\n",
        "      input_spec=federated_train_data[0].element_spec,\n",
        "      loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7BPxQoGH0bEl"
      },
      "source": [
        "## オプティマイザを準備する"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRw9zwdh0dnL"
      },
      "source": [
        "[`tff.learning.algorithms.build_weighted_fed_avg`](https://www.tensorflow.org/federated/api_docs/python/tff/learning/algorithms/build_weighted_fed_avg) と同様に、ここでも、クライアントオプティマイザとサーバーオプティマイザの 2 つがあります。単純さを維持するため、オプティマイザは異なる学習率を伴う SGD とします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kOO1ObqJ0cmX"
      },
      "outputs": [],
      "source": [
        "client_optimizer_fn = lambda: tf.keras.optimizers.SGD(learning_rate=0.01)\n",
        "server_optimizer_fn = lambda: tf.keras.optimizers.SGD(learning_rate=1.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R64okB7k06sc"
      },
      "source": [
        "## ビルディングブロックを定義する\n",
        "\n",
        "クライアントワークのビルディングブロック、データ、モデル、およびオプティマイザのセットアップが完了したので、後は、ディストリビュータ、アグリゲータ、およびファイナライザのビルディングブロックを作成するのみです。これは、TFF で提供されている、FedAvg で使用されているデフォルトを借りれば完了です。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iwXOTPeIx2nx"
      },
      "outputs": [],
      "source": [
        "@tff.tf_computation()\n",
        "def initial_model_weights_fn():\n",
        "  return tff.learning.models.ModelWeights.from_model(model_fn())\n",
        "\n",
        "model_weights_type = initial_model_weights_fn.type_signature.result\n",
        "\n",
        "distributor = tff.learning.templates.build_broadcast_process(model_weights_type)\n",
        "client_work = build_gradient_clipping_client_work(model_fn, client_optimizer_fn)\n",
        "\n",
        "# TFF aggregators use a factory pattern, which create an aggregator\n",
        "# based on the output type of the client work. This also uses a float (the number\n",
        "# of examples) to govern the weight in the average being computed.)\n",
        "aggregator_factory = tff.aggregators.MeanFactory()\n",
        "aggregator = aggregator_factory.create(model_weights_type.trainable,\n",
        "                                       tff.TensorType(tf.float32))\n",
        "finalizer = tff.learning.templates.build_apply_optimizer_finalizer(\n",
        "    server_optimizer_fn, model_weights_type)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEYYNHqI1Jif"
      },
      "source": [
        "## ビルディングブロックを作成する\n",
        "\n",
        "最後に、TFF に組み込みの**コンポーザ**を使用して、ビルディングブロックを 1 つにまとめます。これは比較的単純なコンポーザで、上記の 4 つのビルディングブロックを提供してそれらの型を繋ぎ合わせます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z_86iNeM0IBm"
      },
      "outputs": [],
      "source": [
        "fed_avg_with_clipping = tff.learning.templates.compose_learning_process(\n",
        "    initial_model_weights_fn,\n",
        "    distributor,\n",
        "    client_work,\n",
        "    aggregator,\n",
        "    finalizer\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcK69pCG16-E"
      },
      "source": [
        "# アルゴリズムを実行する\n",
        "\n",
        "アルゴリズムが完成したので、実行してみましょう。まず、アルゴリズムを**初期化**します。このアルゴリズムの**状態**には、各ビルディングブロックのコンポーネントと*グローバルモデルの重み*のコンポーネントがあります。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jg22oFx11YKK"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "()"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "state = fed_avg_with_clipping.initialize()\n",
        "\n",
        "state.client_work"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmCiEdoq2doJ"
      },
      "source": [
        "期待したとおり、クライアントワークの状態は空です（上記のクライアントワークのコードを思い出しましょう！）。ただし、他のビルディングブロックの状態は空以外の場合があります。たとえば、ファイナライザはイテレーションが何回起きたかを追跡しているためです。`next` はまだ実行されていないため、状態は `0` となっています。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kEuB-8Z71-bd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0]"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "state.finalizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2N9XObhZ2zSQ"
      },
      "source": [
        "では、トレーニングラウンドを実行します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tKhPuBgW1-3c"
      },
      "outputs": [],
      "source": [
        "learning_process_output = fed_avg_with_clipping.next(state, federated_train_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7L0jKEe29bk"
      },
      "source": [
        "この（`tff.learning.templates.LearningProcessOutput`）出力には、`.state` と `.metrics` の出力があります。両方を確認しましょう。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AMsBmmQz28AZ"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[1]"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "learning_process_output.state.finalizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwcfhAbP3VkH"
      },
      "source": [
        "明らかに、ファイナライザの状態は、`.next` が実行されたため、1 ずつ増分しています。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0K91G_Ob3E05"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "OrderedDict([('distributor', ()),\n",
              "             ('client_work', ()),\n",
              "             ('aggregator',\n",
              "              OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "             ('finalizer', ())])"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "learning_process_output.metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sDyO9uz3Jaz"
      },
      "source": [
        "メトリックは空ですが、より複雑で実践的なアルゴリズムでは、一般に有用な情報が多数含まれます。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPpxe7Ie3gLJ"
      },
      "source": [
        "# まとめ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8uEZw-T3iBB"
      },
      "source": [
        "上記のビルディングブロック/コンポーザフレームワークを使用することで、すべてをゼロから作成せずとも、まったく新しい学習アルゴリズムを作成することができます。ただし、これは出発点に過ぎません。このフレームワークによって、アルゴリズムをはるかに簡単に単純な FedAvg の変更コードとして表現できるようになります。詳細については、[`tff.learning.algorithms`](https://www.tensorflow.org/federated/api_docs/python/tff/learning/algorithms) をご覧ください。これには、[FedProx](https://www.tensorflow.org/federated/api_docs/python/tff/learning/algorithms/build_weighted_fed_prox) や[クライアント学習率のスケジューリングを伴う FedAvg](https://www.tensorflow.org/federated/api_docs/python/tff/learning/algorithms/build_weighted_fed_avg_with_optimizer_schedule) などのアルゴリズムが含まれています。これらの API を使うと、[連合 k-平均クラスタリング](https://www.tensorflow.org/federated/api_docs/python/tff/learning/algorithms/build_fed_kmeans)など、まったく新しいアルゴリズムの実装の支援をさらに得られます。"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "composing_learning_algorithms.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
