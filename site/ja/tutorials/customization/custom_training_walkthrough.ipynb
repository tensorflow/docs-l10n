{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwxGnsA92emp"
      },
      "source": [
        "##### Copyright 2018 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "CPII1rGR2rF9"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JtEZ1pCPn--z"
      },
      "source": [
        "# カスタム訓練：ウォークスルー"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GV1F7tVTN3Dn"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>     <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/customization/custom_training_walkthrough\">     <img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">     TensorFlow.org で表示</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/ja/tutorials/customization/custom_training_walkthrough.ipynb\">     <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">     Google Colab で実行</a>\n",
        "</td>\n",
        "  <td><a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/ja/tutorials/customization/custom_training_walkthrough.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\"> GitHub でソースを表示</a></td>\n",
        "  <td><a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/ja/tutorials/customization/custom_training_walkthrough.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">ノートブックをダウンロード/a0}</a></td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDrzLFXE8T1l"
      },
      "source": [
        "このチュートリアルでは、カスタムトレーニングループを使って機械学習モデルをトレーニングし、ペンギンを種類別に*分類*する方法を説明します。このノートブックでは、TensorFlow を使用して、次の項目を達成します。\n",
        "\n",
        "1. データセットをインポートする\n",
        "2. 単純な線形モデルを構築する\n",
        "3. モデルをトレーニングする\n",
        "4. モデルの有効性を評価する\n",
        "5. トレーニングされたモデルを使用して予測を立てる\n",
        "\n",
        "## TensorFlow プログラミング\n",
        "\n",
        "このチュートリアルでは、次の TensorFlow プログラミングタスクを実演しています。\n",
        "\n",
        "- [TensorFlow Datasets API](https://www.tensorflow.org/datasets/overview#load_a_dataset) を使ってデータをインポートする\n",
        "- [Keras API](https://www.tensorflow.org/guide/keras/) を使ってモデルとレイヤーを構築する\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zx7wc0LuuxaJ"
      },
      "source": [
        "## ペンギンの分類の問題\n",
        "\n",
        "鳥類学者が、発見したペンギンを自動的に分類する方法を探していると仮定しましょう。機械学習では、ペンギンを静的に分類するためのアルゴリズムが多数用意されています。たとえば、高度な機械学習プログラムでは、写真を基にペンギンを分類できるものもあります。このチュートリアルで作成するモデルは、これよりも少しシンプルで、体重、フリッパーの長さ、くちばし、特に[ 嘴峰（しほう）](https://en.wikipedia.org/wiki/Beak#Culmen)の長さと幅に基づいてペンギンを分類します。\n",
        "\n",
        "ペンギンには 18 種ありますが、このチュートリアルでは次の 3 種のみを分類してみることにしましょう。\n",
        "\n",
        "- ヒゲペンギン\n",
        "- ジェンツーペンギン\n",
        "- アデリーペンギン\n",
        "\n",
        "<table>\n",
        "  <tr><td>     <img src=\"https://www.tensorflow.org/images/iris_three_species.jpg\" alt=\"Petal geometry compared for three iris species: Iris setosa, Iris virginica, and Iris versicolor\">   </td></tr>\n",
        "  <tr><td align=\"center\">\n",
        "<b>図 1.</b> <a href=\"https://en.wikipedia.org/wiki/Chinstrap_penguin\">ヒゲペンギン</a>、<a href=\"https://en.wikipedia.org/wiki/Gentoo_penguin\">ジェンツー</a>、および<a href=\"https://en.wikipedia.org/wiki/Ad%C3%A9lie_penguin\">アデリー</a>ペンギン（イラスト: @allison_horst, CC BY-SA 2.0）。<br>\n",
        "</td></tr>\n",
        "</table>\n",
        "\n",
        "幸いにも、体重、フリッパーの長さ、くちばしの測定値とその他のデータで含む[334 羽のペンギンのデータセット](https://allisonhorst.github.io/palmerpenguins/)が調査チームによって既に作成されて共有されています。このデータセットは、[penguins](https://www.tensorflow.org/datasets/catalog/penguins) TensorFlow Dataset としても提供されています。 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1J3AuPBT9gyR"
      },
      "source": [
        "## セットアップ\n",
        "\n",
        "penguis データセットに使用する `tfds-nightly` パッケージをインストールします。`tfds-nightly` パッケージは毎晩リリースされる TensorFlow Datasets（TFDS）のバージョンです。TFDS の詳細については、[TensorFlow Datasets の概要](https://www.tensorflow.org/datasets/overview)をご覧ください。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4XXWn1eDZmET"
      },
      "outputs": [],
      "source": [
        "!pip install -q tfds-nightly"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DtGeMicKRGzU"
      },
      "source": [
        "次に、Colab メニューから **Runtime &gt; Restart Runtime** を選択して、Colab ランタイムを再起動します。\n",
        "\n",
        "ランタイムを再起動せずに、チュートリアルを先に進めないでください。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9onjGZWZbA-"
      },
      "source": [
        "TensorFlow と他に必要な Python モジュールをインポートします。 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jElLULrDhQZR"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"TensorFlow version: {}\".format(tf.__version__))\n",
        "print(\"TensorFlow Datasets version: \",tfds.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Px6KAg0Jowz"
      },
      "source": [
        "## データセットをインポートする\n",
        "\n",
        "デフォルトの [penguins/processed](https://www.tensorflow.org/datasets/catalog/penguins) TensorFlow Dataset はすでにクリーニングされて正規化が済んでおり、モデルを構築できる準備が整っています。processed データをダウンロードする前に、簡易バージョンをプレビューして、元のペンギン調査データを理解しておきましょう。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnX1-aLors4S"
      },
      "source": [
        "### データをプレビューする\n",
        "\n",
        "TensorFlow Datasets [`tdfs.load`](https://www.tensorflow.org/datasets/api_docs/python/tfds/load) メソッドを使用して、penguins データセットの簡易バージョン（`penguins/simple`）をダウンロードします。このデータセットには 344 件のデータレコードが存在します。最初の 5 件のレコードを [`DataFrame`](https://www.tensorflow.org/datasets/api_docs/python/tfds/as_dataframe) オブジェクトに抽出し、このデータセットのサンプルの値を調べます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FQvb_JYdrpPm"
      },
      "outputs": [],
      "source": [
        "ds_preview, info = tfds.load('penguins/simple', split='train', with_info=True)\n",
        "df = tfds.as_dataframe(ds_preview.take(5), info)\n",
        "print(df)\n",
        "print(info.features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQhzD6P-uBoq"
      },
      "source": [
        "番号付きの行がデータレコードで、行ごとに 1 つの*[サンプル](https://developers.google.com/machine-learning/glossary/#example)*が含まれます。\n",
        "\n",
        "- 最初の 6 つのフィールドは、サンプルの特徴づける*[特徴量](https://developers.google.com/machine-learning/glossary/#feature)*です。ここでは、ペンギンの測定値を表す数字が含まれています。\n",
        "- 最後の列は*[ラベル](https://developers.google.com/machine-learning/glossary/#label)*です。予測しようとしている値がこれです。このデータセットでは、ペンギンの種名に対応する 0、1、または 2 の整数が示されます。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCtwLoJhhDNc"
      },
      "source": [
        "このデータセットでは、ペンギンの種のラベルを数値で表現することにより、構築するモデルで扱いやすくしています。これらの数値は、次のペンギンの種に対応しています。\n",
        "\n",
        "- `0`: アデリーペンギン\n",
        "- `1`: ヒゲペンギン\n",
        "- `2`: ジェンツーペンギン\n",
        "\n",
        "この順序で、ペンギンの種名を含むリストを作成します。このリストは、分類モデルの出力を解釈するために使用します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sVNlJlUOhkoX"
      },
      "outputs": [],
      "source": [
        "class_names = ['Adélie', 'Chinstrap', 'Gentoo']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iav9kEgxpY0s"
      },
      "source": [
        "特徴量とラベルについての詳細は、[機械学習クラッシュコースの ML 用語セクション](https://developers.google.com/machine-learning/crash-course/framing/ml-terminology)をご覧ください。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PD33PxSmCrtL"
      },
      "source": [
        "### 前処理済みのデータセットをダウンロードする\n",
        "\n",
        "次に、`tfds.load` メソッドを使用して、前処理済みの penguins データセット（`penguins/processed`）をダウンロードします。すると、`tf.data.Dataset` オブジェクトのリストが返されます。`penguins/processed` データセットには独自のテストセットは用意されていないため、80:20 分割で、トレーニングセットとテストセットに[データセットをスライス](https://www.tensorflow.org/datasets/splits)します。テストデータセットは、後でモデルを検証する際に使用します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EVV96zIYYAi8"
      },
      "outputs": [],
      "source": [
        "ds_split, info = tfds.load(\"penguins/processed\", split=['train[:20%]', 'train[20%:]'], as_supervised=True, with_info=True)\n",
        "\n",
        "ds_test = ds_split[0]\n",
        "ds_train = ds_split[1]\n",
        "assert isinstance(ds_test, tf.data.Dataset)\n",
        "\n",
        "print(info.features)\n",
        "df_test = tfds.as_dataframe(ds_test.take(5), info)\n",
        "print(\"Test dataset sample: \")\n",
        "print(df_test)\n",
        "\n",
        "df_train = tfds.as_dataframe(ds_train.take(5), info)\n",
        "print(\"Train dataset sample: \")\n",
        "print(df_train)\n",
        "\n",
        "ds_train_batch = ds_train.batch(32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xX2NfLyQOK1y"
      },
      "source": [
        "このバージョンのデータセットは処理済みであるため、データが 4 つの正規化された特徴量と種ラベルに縮小されていることに注意してください。このフォーマットでは、データを素早く使用してモデルをトレーニングできるようになっているため、移行の処理は必要ありません。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iDuG94H-C122"
      },
      "outputs": [],
      "source": [
        "features, labels = next(iter(ds_train_batch))\n",
        "\n",
        "print(features)\n",
        "print(labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E63mArnQaAGz"
      },
      "source": [
        "バッチのいくつかの特徴量をプロットして、クラスターを可視化できます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "me5Wn-9FcyyO"
      },
      "outputs": [],
      "source": [
        "plt.scatter(features[:,0],\n",
        "            features[:,2],\n",
        "            c=labels,\n",
        "            cmap='viridis')\n",
        "\n",
        "plt.xlabel(\"Body Mass\")\n",
        "plt.ylabel(\"Culmen Length\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LsaVrtNM3Tx5"
      },
      "source": [
        "## 単純な線形モデルを構築する\n",
        "\n",
        "### なぜモデルか？\n",
        "\n",
        "*[モデル](https://developers.google.com/machine-learning/crash-course/glossary#model)*は、特徴量とラベルの関係です。ペンギンの分類問題においては、このモデルは体重、フリッパー、および嘴峰の測定値、および予測されるペンギンの種の関係を定義しています。単純なモデルは、数行の代数で記述することは可能ですが、複雑な機械学習モデルにはパラメータの数も多く、要約が困難です。\n",
        "\n",
        "機械学習を*使用せずに*、4 つの特徴量とペンギンの種の関係を判定することはできるのでしょうか。つまり、従来のプログラミング手法（多数の条件ステートメントを使用するなど）を使って、モデルを作成できるのでしょうか。おそらく、体重と嘴峰の測定値の関係を特定できるだけの長い時間を費やしてデータセットを分析すれば、特定の種に絞ることは可能かもしれません。これでは、複雑なデータセットでは不可能でなくとも困難極まりないことでしょう。適した機械学習アプローチであれば、*ユーザーに代わってモデルを判定*することができます。代表的なサンプルを適確な機械学習モデルタイプに十分にフィードすれば、プログラムによって関係を見つけ出すことができます。\n",
        "\n",
        "### モデルの選択\n",
        "\n",
        "次に、トレーニングするモデルの種類を選択する必要があります。選択できる種類は多数あり、最適な種類を 1 つ選ぶにはそれなりの経験が必要となります。このチュートリアルでは、ニューラルネットワークを使用して、ペンギンの分類問題を解決することにします。[*ニューラルネットワーク*](https://developers.google.com/machine-learning/glossary/#neural_network)は、特徴量とラベルの複雑な関係を見つけ出すことができます。非常に構造化されたグラフで、1 つ以上の[*非表示レイヤー*](https://developers.google.com/machine-learning/glossary/#hidden_layer)で編成されており、各非表示レイヤーは 1 つ以上の[*ニューロン*](https://developers.google.com/machine-learning/glossary/#neuron)で構成されています。ニューラルネットワークにはいくつかのカテゴリがありますが、このプログラムでは、Dense または[*全結合のニューラルネットワーク*](https://developers.google.com/machine-learning/glossary/#fully_connected_layer)を使用します。このネットワークでは、1 つのレイヤーのニューロンが前のレイヤーの*すべての*ユーロんから入力接続を受け取ります。たとえば、図 2 では、1 つの入力レイヤー、2 つの非表示レイヤー、および 1 つの出力レイヤーで構成される Dense ニューラルネットワークが示されています。\n",
        "\n",
        "<table>\n",
        "  <tr><td>     <img src=\"https://www.tensorflow.org/images/custom_estimators/full_network.png\" alt=\"A diagram of the network architecture: Inputs, 2 hidden layers, and outputs\">   </td></tr>\n",
        "  <tr><td align=\"center\">     <b>図2.</b> 特徴量と隠れ層、予測をもつニューラルネットワーク<br>{nbsp}   </td></tr>\n",
        "</table>\n",
        "\n",
        "図 2 のモデルをトレーニングし、ラベルなしのサンプルをフィードすると、このペンギンが特定のペンギン種であるという尤度によって 3 つの予測が生成されます。この予測は[*推論*](https://developers.google.com/machine-learning/crash-course/glossary#inference)と呼ばれます。この例では、出力予測の和は 1.0 です。図 2 の場合、この予測は、*アデリー*は `0.02`、*ヒゲペンギン*は `0.95`、*ジェンツー*は `0.03` となります。つまり、モデルは、95% の確率で、ラベル無しのサンプルペンギンは*ヒゲペンギン*であると予測していることになります。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W23DIMVPQEBt"
      },
      "source": [
        "### Keras を使ったモデル構築\n",
        "\n",
        "TensorFlow の [tf.keras](https://www.tensorflow.org/api_docs/python/tf/keras) API は、モデルと層を作成するためのおすすめの方法です。Keras がすべてを結びつけるという複雑さを引き受けてくれるため、モデルや実験の構築がかんたんになります。\n",
        "\n",
        "`tf.keras.Sequential` モデルは、レイヤーの線形スタックです。コンストラクタはレイヤーインスタンスのリスト（この場合は 2 つの `tf.keras.layers.Dense` レイヤー、各レイヤーの 10 個のノード、ラベルの予測である 3 つのノードを持つ出力レイヤー）を取ります。最初のレイヤーの `input_shape` パラメータはデータセットの特徴量の数に対応しており、必須です。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2fZ6oL2ig3ZK"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(10, activation=tf.nn.relu, input_shape=(4,)),  # input shape required\n",
        "  tf.keras.layers.Dense(10, activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dense(3)\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHcbEzMpxbHL"
      },
      "source": [
        "[*活性化関数(activation function)*](https://developers.google.com/machine-learning/crash-course/glossary#activation_function)  は、そのレイヤーの各ノードの出力の形を決定します。この関数の非線形性は重要であり、それがなければモデルは 1層しかないものと等価になってしまいます。[利用可能な活性化関数](https://www.tensorflow.org/api_docs/python/tf/keras/activations) はたくさんありますが、隠れ層では [ReLU](https://developers.google.com/machine-learning/crash-course/glossary#ReLU) が一般的です。\n",
        "\n",
        "理想的な隠れ層の数やニューロンの数は問題やデータセットによって異なります。機械学習のさまざまな側面と同様に、ニューラルネットワークの最良の形を選択するには、知識と経験の両方が必要です。経験則から、一般的には隠れ層やニューロンの数を増やすとより強力なモデルを作ることができますが、効果的に訓練を行うためにより多くのデータを必要とします。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wFKnhWCpDSS"
      },
      "source": [
        "### モデルを使用する\n",
        "\n",
        "それでは、このモデルが特徴量のバッチに対して何を行うかを見てみましょう。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xe6SQ5NrpB-I"
      },
      "outputs": [],
      "source": [
        "predictions = model(features)\n",
        "predictions[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxyXOhwVr5S3"
      },
      "source": [
        "ご覧のように、サンプルのそれぞれは、各クラスの [ロジット(logit)](https://developers.google.com/machine-learning/crash-course/glossary#logits) 値を返します。\n",
        "\n",
        "これらのロジット値を各クラスの確率に変換するためには、 [softmax](https://developers.google.com/machine-learning/crash-course/glossary#softmax) 関数を使用します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_tRwHZmTNTX2"
      },
      "outputs": [],
      "source": [
        "tf.nn.softmax(predictions[:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRZmchElo481"
      },
      "source": [
        "クラスに渡って `tf.math.argmax` を取ると、クラスのインデックスの予測を得られますが、モデルはまだトレーニングされていないため、これは良い予測ではありません。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Jzm_GoErz8B"
      },
      "outputs": [],
      "source": [
        "print(\"Prediction: {}\".format(tf.argmax(predictions, axis=1)))\n",
        "print(\"    Labels: {}\".format(labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vzq2E5J2QMtw"
      },
      "source": [
        "## モデルの訓練\n",
        "\n",
        "[*訓練(Training)*](https://developers.google.com/machine-learning/crash-course/glossary#training) は、機械学習において、モデルが徐々に最適化されていく、あるいはモデルがデータセットを*学習する*段階です。目的は、見たことのないデータについて予測を行うため、訓練用データセットの構造を十分に学習することです。訓練用データセットを学習*しすぎる*と、予測は見たことのあるデータに対してしか有効ではなく、一般化できません。この問題は [*過学習(overfitting)*](https://developers.google.com/machine-learning/crash-course/glossary#overfitting) と呼ばれ、問題の解き方を理解するのではなく答えを丸暗記するようなものです。\n",
        "\n",
        "ペンギンの分類問題は、[*教師あり機械学習*](https://developers.google.com/machine-learning/glossary/#supervised_machine_learning)の例であり、モデルはラベルを含むサンプルからトレーニングされています。サンプルにラベルを含まない場合は、[*教師なし機械学習*](https://developers.google.com/machine-learning/glossary/#unsupervised_machine_learning)と呼ばれ、モデルは通常、特徴量からパターンを見つけ出します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RaKp8aEjKX6B"
      },
      "source": [
        "### 損失と勾配関数を定義する\n",
        "\n",
        "トレーニングと評価の段階では、モデルの[*損失*](https://developers.google.com/machine-learning/crash-course/glossary#loss)を計算する必要があります。これは、モデルの予測がどれくらい目標から外れているかを測定するものです。言い換えると、モデルのパフォーマンスがどれくらい劣っているかを示します。この値を最小化または最適化することが望まれます。\n",
        "\n",
        "モデルは、モデルのクラスの確率予測と目標のラベルを取り、サンプル間の平均的な損失を返す  `tf.keras.losses.SparseCategoricalCrossentropy` 関数を使用して損失を計算します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QOsi6b-1CXIn"
      },
      "outputs": [],
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tMAT4DcMPwI-"
      },
      "outputs": [],
      "source": [
        "def loss(model, x, y, training):\n",
        "  # training=training is needed only if there are layers with different\n",
        "  # behavior during training versus inference (e.g. Dropout).\n",
        "  y_ = model(x, training=training)\n",
        "\n",
        "  return loss_object(y_true=y, y_pred=y_)\n",
        "\n",
        "l = loss(model, features, labels, training=False)\n",
        "print(\"Loss test: {}\".format(l))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IcPqA24QM6B"
      },
      "source": [
        "[tf.GradientTape](https://www.tensorflow.org/api_docs/python/tf/GradientTape) コンテキストを使って、モデルを最適化する際に使われる [*勾配(gradients)*](https://developers.google.com/machine-learning/crash-course/glossary#gradient) を計算しましょう。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x57HcKWhKkei"
      },
      "outputs": [],
      "source": [
        "def grad(model, inputs, targets):\n",
        "  with tf.GradientTape() as tape:\n",
        "    loss_value = loss(model, inputs, targets, training=True)\n",
        "  return loss_value, tape.gradient(loss_value, model.trainable_variables)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOxFimtlKruu"
      },
      "source": [
        "### オプティマイザの作成\n",
        "\n",
        "[*オプティマイザ*](https://developers.google.com/machine-learning/crash-course/glossary#optimizer)は、`loss` 関数を最小化するために、計算された勾配をモデルのパラメータに適用します。損失関数は、曲面（図 3 を参照）として考えることができ、その周辺を探りながら最低ポイントを見つけることができます。勾配は最も急な上昇に向かってポイントするため、逆方向に進んで曲面を下方向に移動します。バッチごとに損失と勾配を対話的に計算することで、トレーニング中にモデルの調整を行うことができます。モデルは徐々に、重みとバイアスの最適な組み合わせを見つけて損失を最小化できるようになります。損失が低いほど、モデルの予測が最適化されます。\n",
        "\n",
        "<table>\n",
        "  <tr><td>     <img src=\"https://cs231n.github.io/assets/nn3/opt1.gif\" width=\"70%\" alt=\"Optimization algorithms visualized over time in 3D space.\">   </td></tr>\n",
        "  <tr><td align=\"center\">     <b>図3.</b> 3次元空間における最適化アルゴリズムの時系列可視化。<br>(Source: <a href=\"http://cs231n.github.io/neural-networks-3/\">Stanford class CS231n</a>, MIT License, Image credit: <a href=\"https://twitter.com/alecrad\">Alec Radford</a>)   </td></tr>\n",
        "</table>\n",
        "\n",
        "TensorFlow には、トレーニングに使用できる多数の最適化アルゴリズムが用意されています。このチュートリアルでは、[*確率的勾配降下法*](https://developers.google.com/machine-learning/crash-course/glossary#gradient_descent)（SGD）アルゴリズムを実装する `tf.keras.optimizers.SGD` を使用しています。`learning_rate` パラメータは、曲面を下降するイテレーションごとに取るステップサイズを設定します。このレートは、一般的により良い結果を達成できるように調整する[*ハイパーパラメータ*](https://developers.google.com/machine-learning/glossary/#hyperparameter)です。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkUd6UiZa_dF"
      },
      "source": [
        "オプティマイザを `0.01` の[*学習率*](https://developers.google.com/machine-learning/glossary#learning-rate)でインスタンス化します。これはトレーニングのイテレーションごとに、勾配が操作するスカラー値です。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8xxi2NNGKwG_"
      },
      "outputs": [],
      "source": [
        "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJVRZ0hP52ZB"
      },
      "source": [
        "次に、このオブジェクトを使用して、1 つの最適化ステップを計算します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rxRNTFVe56RG"
      },
      "outputs": [],
      "source": [
        "loss_value, grads = grad(model, features, labels)\n",
        "\n",
        "print(\"Step: {}, Initial Loss: {}\".format(optimizer.iterations.numpy(),\n",
        "                                          loss_value.numpy()))\n",
        "\n",
        "optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "print(\"Step: {},         Loss: {}\".format(optimizer.iterations.numpy(),\n",
        "                                          loss(model, features, labels, training=True).numpy()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Y2VSELvwAvW"
      },
      "source": [
        "### 訓練ループ\n",
        "\n",
        "すべての部品が揃ったので、モデルの訓練ができるようになりました。訓練ループは、モデルにデータセットのサンプルを供給し、モデルがよりよい予測を行えるようにします。下記のコードブロックは、この訓練のステップを構成します。\n",
        "\n",
        "1. *epoch（エポック）* をひとつずつ繰り返します。エポックとは、データセットをひととおり処理するということです。\n",
        "2. エポック内では、訓練用の `Dataset（データセット）` のサンプルひとつずつから、その *features（特徴量）* (`x`) と *label（ラベル）* (`y`) を取り出して繰り返し処理します。\n",
        "3. サンプルの特徴量を使って予測を行い、ラベルと比較します。予測の不正確度を測定し、それを使ってモデルの損失と勾配を計算します。\n",
        "4. `optimizer` を使って、モデルのパラメータを更新します。\n",
        "5. 可視化のためにいくつかの統計量を記録します。\n",
        "6. これをエポックごとに繰り返します。\n",
        "\n",
        "`num_epochs` 変数は、データセットコレクションをループする回数です。以下のコードでは、`num_epochs` は 201 に設定されているため、このトレーニングループは 201 回実行します。直感に反し、モデルをより長くトレーニングしても、モデルがさらに最適化されることは保証されません。`num_epochs` は、ユーザーが調整できる[*ハイパーパラメータ*](https://developers.google.com/machine-learning/glossary/#hyperparameter)です。通常、適切な数値を選択するには、経験と実験の両方が必要です。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AIgulGRUhpto"
      },
      "outputs": [],
      "source": [
        "## Note: Rerunning this cell uses the same model parameters\n",
        "\n",
        "# Keep results for plotting\n",
        "train_loss_results = []\n",
        "train_accuracy_results = []\n",
        "\n",
        "num_epochs = 201\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  epoch_loss_avg = tf.keras.metrics.Mean()\n",
        "  epoch_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "\n",
        "  # Training loop - using batches of 32\n",
        "  for x, y in ds_train_batch:\n",
        "    # Optimize the model\n",
        "    loss_value, grads = grad(model, x, y)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "    # Track progress\n",
        "    epoch_loss_avg.update_state(loss_value)  # Add current batch loss\n",
        "    # Compare predicted label to actual label\n",
        "    # training=True is needed only if there are layers with different\n",
        "    # behavior during training versus inference (e.g. Dropout).\n",
        "    epoch_accuracy.update_state(y, model(x, training=True))\n",
        "\n",
        "  # End epoch\n",
        "  train_loss_results.append(epoch_loss_avg.result())\n",
        "  train_accuracy_results.append(epoch_accuracy.result())\n",
        "\n",
        "  if epoch % 50 == 0:\n",
        "    print(\"Epoch {:03d}: Loss: {:.3f}, Accuracy: {:.3%}\".format(epoch,\n",
        "                                                                epoch_loss_avg.result(),\n",
        "                                                                epoch_accuracy.result()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Diep-ROEuKyl"
      },
      "source": [
        "または、組み込みの Keras [`Model.fit(ds_train_batch)`](https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit) メソッドを使用して、モデルをトレーニングすることもできます。 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FQHVUnm_rjw"
      },
      "source": [
        "### 時間の経過に対する損失関数の可視化"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3wdbmtLVTyr"
      },
      "source": [
        "モデルのトレーニングの進行状況を出力することは役立ちますが、TensorFlow に同梱された [TensorBoard](https://www.tensorflow.org/tensorboard) という可視化とメトリクスツールを使って進行状況を可視化することもできます。この単純な例では、`matplotlib` モジュールを使用して基本的なグラフを作成できます。\n",
        "\n",
        "これらのグラフを解釈するには経験が必要ですが、一般的に、*損失*の減少と*精度*の上昇に注目できます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "agjvNd2iUGFn"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(2, sharex=True, figsize=(12, 8))\n",
        "fig.suptitle('Training Metrics')\n",
        "\n",
        "axes[0].set_ylabel(\"Loss\", fontsize=14)\n",
        "axes[0].plot(train_loss_results)\n",
        "\n",
        "axes[1].set_ylabel(\"Accuracy\", fontsize=14)\n",
        "axes[1].set_xlabel(\"Epoch\", fontsize=14)\n",
        "axes[1].plot(train_accuracy_results)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zg8GoMZhLpGH"
      },
      "source": [
        "## モデルの有効性評価\n",
        "\n",
        "モデルがトレーニングが完了したため、パフォーマンスの統計を取得できるようになりました。\n",
        "\n",
        "*評価*とは、モデルがどれくらい効果的に予測を立てられるかを判定することです。ペンギンの分類においてモデルの有効性を判定するには、測定値をモデルに渡し、それが表すペンギンの種をモデルに問います。次に、モデルの予測を実際のラベルと比較します。たとえば、入力サンプルの半数で正しい種を選択したモデルであれば、その[*精度*](https://developers.google.com/machine-learning/glossary/#accuracy)は `0.5` となります。図 4 には、わずかに有効性の高いモデルが示されており、80% の精度で、5 回の予測の内 4 回が正解となっています。\n",
        "\n",
        "<table cellpadding=\"8\" border=\"0\">\n",
        "  <colgroup>\n",
        "    <col span=\"4\">\n",
        "    <col span=\"1\" bgcolor=\"lightblue\">\n",
        "    <col span=\"1\" bgcolor=\"lightgreen\">\n",
        "  </colgroup>\n",
        "  <tr bgcolor=\"lightgray\">\n",
        "    <th colspan=\"4\">サンプルの特徴量</th>\n",
        "    <th colspan=\"1\">ラベル</th>\n",
        "    <th colspan=\"1\">モデルの予測値</th>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>5.9</td>\n",
        "<td>3.0</td>\n",
        "<td>4.3</td>\n",
        "<td>1.5</td>\n",
        "<td align=\"center\">1</td>\n",
        "<td align=\"center\">1</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>6.9</td>\n",
        "<td>3.1</td>\n",
        "<td>5.4</td>\n",
        "<td>2.1</td>\n",
        "<td align=\"center\">2</td>\n",
        "<td align=\"center\">2</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>5.1</td>\n",
        "<td>3.3</td>\n",
        "<td>1.7</td>\n",
        "<td>0.5</td>\n",
        "<td align=\"center\">0</td>\n",
        "<td align=\"center\">0</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>6.0</td> <td>3.4</td> <td>4.5</td> <td>1.6</td> <td align=\"center\">1</td>\n",
        "<td align=\"center\" bgcolor=\"red\">2</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>5.5</td>\n",
        "<td>2.5</td>\n",
        "<td>4.0</td>\n",
        "<td>1.3</td>\n",
        "<td align=\"center\">1</td>\n",
        "<td align=\"center\">1</td>\n",
        "  </tr>\n",
        "  <tr><td align=\"center\" colspan=\"6\">     <b>図 4.</b> 80% 正確なペンギンの分類器<br>\n",
        "</td></tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-EvK7hGL0d8"
      },
      "source": [
        "### テストセットをセットアップする\n",
        "\n",
        "モデルの評価はモデルの訓練と同様です。もっとも大きな違いは、サンプルが訓練用データセットではなく[*テスト用データセット(test set)*](https://developers.google.com/machine-learning/crash-course/glossary#test_set) からのものであるという点です。モデルの有効性を正しく評価するには、モデルの評価に使うサンプルは訓練用データセットのものとは違うものでなければなりません。\n",
        "\n",
        "penguin データセットには、別途テストデータセットが用意されていないため、当然、前述のデータセットのダウンロードセクションのデータセットにもテストデータセットはありません。そこで、元のデータセットをテストデータセットとトレーニングデータセットに分割します。評価には、`ds_test_batch` データセットを使用してください。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFuOKXJdMAdm"
      },
      "source": [
        "### テスト用データセットでのモデルの評価\n",
        "\n",
        "トレーニングの段階とは異なり、このモデルはテストデータの 1 つの[エポック](https://developers.google.com/machine-learning/glossary/#epoch)しか評価しません。次のコードはテストセットの各サンプルを反復し、モデルの予測を実際のラベルに比較します。この比較は、テストセット全体におけるモデルの精度を測定するために使用されます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tw03-MK1cYId"
      },
      "outputs": [],
      "source": [
        "test_accuracy = tf.keras.metrics.Accuracy()\n",
        "ds_test_batch = ds_test.batch(10)\n",
        "\n",
        "for (x, y) in ds_test_batch:\n",
        "  # training=False is needed only if there are layers with different\n",
        "  # behavior during training versus inference (e.g. Dropout).\n",
        "  logits = model(x, training=False)\n",
        "  prediction = tf.argmax(logits, axis=1, output_type=tf.int64)\n",
        "  test_accuracy(prediction, y)\n",
        "\n",
        "print(\"Test set accuracy: {:.3%}\".format(test_accuracy.result()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fel8ql2qzGlK"
      },
      "source": [
        "また、`model.evaluate(ds_test, return_dict=True)` Keras 関数を使用して、テストデータセットの精度情報を取得することもできます。 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcKEZMtCOeK-"
      },
      "source": [
        "たとえば、最後のバッチを調べて、モデルの予測が通常正しい予測であることを観察することができます。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uNwt2eMeOane"
      },
      "outputs": [],
      "source": [
        "tf.stack([y,prediction],axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Li2r1tYvW7S"
      },
      "source": [
        "## 訓練済みモデルを使った予測\n",
        "\n",
        "モデルをトレーニングし、ペンギンの種を分類する上でモデルが良好であることを「証明」しました（ただし、完璧ではありません）。では、トレーニング済みのモデルを使用して、[*ラベルなしのサンプル*](https://developers.google.com/machine-learning/glossary/#unlabeled_example)、つまりラベルのない特徴量を含むサンプルで予測を立ててみましょう。\n",
        "\n",
        "実際には、ラベルなしのサンプルは、アプリ、CSV ファイル、データフィードといったさまざまなソースから取得される場合がありますが、このチュートリアルでは、ラベルなしのサンプルを手動で提供して、それぞれのラベルを予測することにします。ラベル番号は、次のように指定されていることを思い出してください。\n",
        "\n",
        "- `0`: アデリーペンギン\n",
        "- `1`: ヒゲペンギン\n",
        "- `2`: ジェンツーペンギン"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kesTS5Lzv-M2"
      },
      "outputs": [],
      "source": [
        "predict_dataset = tf.convert_to_tensor([\n",
        "    [0.3, 0.8, 0.4, 0.5,],\n",
        "    [0.4, 0.1, 0.8, 0.5,],\n",
        "    [0.7, 0.9, 0.8, 0.4]\n",
        "])\n",
        "\n",
        "# training=False is needed only if there are layers with different\n",
        "# behavior during training versus inference (e.g. Dropout).\n",
        "predictions = model(predict_dataset, training=False)\n",
        "\n",
        "for i, logits in enumerate(predictions):\n",
        "  class_idx = tf.argmax(logits).numpy()\n",
        "  p = tf.nn.softmax(logits)[class_idx]\n",
        "  name = class_names[class_idx]\n",
        "  print(\"Example {} prediction: {} ({:4.1f}%)\".format(i, name, 100*p))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "custom_training_walkthrough.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
