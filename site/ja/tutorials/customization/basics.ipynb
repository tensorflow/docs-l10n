{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPpI7RaYoZuE"
      },
      "source": [
        "##### Copyright 2018 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "hro2InpHobKk"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9i2Dsh-ziXr"
      },
      "source": [
        "# テンソルと演算"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hndw-YcxoOJK"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>     <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/customization/basics\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">View on TensorFlow.org</a>   </td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/ja/tutorials/customization/basics.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Run in Google Colab</a>   </td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/ja/tutorials/customization/basics.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">View source on GitHub</a>   </td>\n",
        "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/ja/tutorials/customization/basics.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Download notebook</a>   </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sILUVbHoSgH"
      },
      "source": [
        "これは、下記の手法を示す TensorFlow の入門チュートリアルです。\n",
        "\n",
        "- 必要なパッケージのインポート\n",
        "- テンソルの作成と使用\n",
        "- GPUによる高速化の使用\n",
        "- `tf.data.Dataset`のデモ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1JcS5iBXMRO"
      },
      "source": [
        "## TensorFlowのインポート\n",
        "\n",
        "始めるにはまず、`tensorflow` モジュールをインポートします。TensorFlow 2 の時点では、Eager execution はデフォルトでオンになっています。Eager execution では、TensorFlow のフロントエンドがよりインタラクティブになります。これについては、後で詳しく説明します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vjBPmYjLdFmk"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9UySOPLXdaw"
      },
      "source": [
        "## テンソル\n",
        "\n",
        "テンソルは多次元の配列です。NumPy `ndarray` オブジェクトと同様に、`tf.Tensor` オブジェクトにもデータ型と形状があります。また、`tf.Tensor` はアクセラレータのメモリに留まることが可能です（GPU 同様）。TensorFlow には、`tf.Tensor` を消費して生成する演算（[tf.add](https://www.tensorflow.org/api_docs/python/tf/add)、[tf.matmul](https://www.tensorflow.org/api_docs/python/tf/matmul)、[tf.linalg.inv](https://www.tensorflow.org/api_docs/python/tf/linalg/inv) など）が多数含まれたライブラリが用意されています。これらの演算によって、組み込みの Python 型が自動的に変換されます。以下に例を示します。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "code",
        "id": "ngUe237Wt48W"
      },
      "outputs": [],
      "source": [
        "print(tf.add(1, 2))\n",
        "print(tf.add([1, 2], [3, 4]))\n",
        "print(tf.square(5))\n",
        "print(tf.reduce_sum([1, 2, 3]))\n",
        "\n",
        "# Operator overloading is also supported\n",
        "print(tf.square(2) + tf.square(3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDY4WsYRhP81"
      },
      "source": [
        "それぞれの`tf.Tensor`には、形状とデータ型があります。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "srYWH1MdJNG7"
      },
      "outputs": [],
      "source": [
        "x = tf.matmul([[1]], [[2, 3]])\n",
        "print(x)\n",
        "print(x.shape)\n",
        "print(x.dtype)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBPw8e8vrsom"
      },
      "source": [
        "NumPy 配列と `tf.Tensor` の間のもっとも明確な違いは\n",
        "\n",
        "1. テンソルは（ GPU や TPU などの）アクセラレータメモリを使用できる\n",
        "2. テンソルは変更不可"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dwi1tdW3JBw6"
      },
      "source": [
        "### NumPy互換性\n",
        "\n",
        "TensorFlow の`tf.Tensor`と NumPy の `ndarray` 間の変換は簡単です。\n",
        "\n",
        "- TensorFlow の演算により NumPy の ndarray は自動的にテンソルに変換される\n",
        "- NumPy の演算によりテンソルは自動的に NuｍPy の ndarray に変換される\n",
        "\n",
        "テンソルは `.numpy()` メソッドを使って明示的に NumPy の ndarray に変換されます。NumPy のndarray と `tf.Tensor` はその下敷きとなるメモリ上の表現が、できるかぎり共通化されているので、通常この変換のコストは小さいです。しかし、NumPy 配列はホスト側のメモリに置かれる一方、`tf.Tensor` はGPU のメモリに置かれる可能性もあるため、下層の表現をいつも共通化できるとは限りません。また、変換にはGPU からホスト側メモリへのコピーも関わってきます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lCUWzso6mbqR"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "ndarray = np.ones([3, 3])\n",
        "\n",
        "print(\"TensorFlow operations convert numpy arrays to Tensors automatically\")\n",
        "tensor = tf.multiply(ndarray, 42)\n",
        "print(tensor)\n",
        "\n",
        "\n",
        "print(\"And NumPy operations convert Tensors to numpy arrays automatically\")\n",
        "print(np.add(tensor, 1))\n",
        "\n",
        "print(\"The .numpy() method explicitly converts a Tensor to a numpy array\")\n",
        "print(tensor.numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBNP8yTRfu_X"
      },
      "source": [
        "## GPU による高速化\n",
        "\n",
        "TensorFlow の演算の多くは、GPU を計算に使用することで高速化されます。TensorFlow は演算に注釈をつけなくとも、自動的に GPU と CPU のどちらかを選択し、必要であればテンソルを GPU メモリと CPU メモリの間でコピーして実行します。演算で生成されたテンソルは通常演算を実行したデバイスのメモリに置かれます。例を見てみましょう。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "code",
        "id": "3Twf_Rw-gQFM"
      },
      "outputs": [],
      "source": [
        "x = tf.random.uniform([3, 3])\n",
        "\n",
        "print(\"Is there a GPU available: \"),\n",
        "print(tf.config.list_physical_devices(\"GPU\"))\n",
        "\n",
        "print(\"Is the Tensor on GPU #0:  \"),\n",
        "print(x.device.endswith('GPU:0'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpgYzgVXW2Ud"
      },
      "source": [
        "### デバイス名\n",
        "\n",
        "`Tensor.device` プロパティにより、そのテンソルの内容を保持しているデバイスの完全な名前文字列を得ることができます。この名前には、プログラムを実行中のホストのネットワークアドレスや、ホスト上のデバイスについての詳細がエンコードされています。この情報は、TensorFlow プログラムの分散実行に必要なものです。テンソルがホスト上の `N` 番目のGPUにある場合、文字列の最後は `GPU:<N>` となります。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWZQCimzuqyP"
      },
      "source": [
        "### 明示的デバイス配置\n",
        "\n",
        "TensorFlowでいう**配置**は、個々の演算を実行するためにどのようにデバイスにアサイン（配置）されるかを指します。前述のとおり、明示的な示唆がなければ、TensorFlow は演算を実行するデバイスを自動的に決め、必要であればテンソルをそのデバイスにコピーします。しかし、`tf.device` コンテキストマネジャーを使うことで、TensorFlow の演算を特定のデバイスに配置することができます。例を見てみましょう。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RjkNZTuauy-Q"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "def time_matmul(x):\n",
        "  start = time.time()\n",
        "  for loop in range(10):\n",
        "    tf.matmul(x, x)\n",
        "\n",
        "  result = time.time()-start\n",
        "\n",
        "  print(\"10 loops: {:0.2f}ms\".format(1000*result))\n",
        "\n",
        "# Force execution on CPU\n",
        "print(\"On CPU:\")\n",
        "with tf.device(\"CPU:0\"):\n",
        "  x = tf.random.uniform([1000, 1000])\n",
        "  assert x.device.endswith(\"CPU:0\")\n",
        "  time_matmul(x)\n",
        "\n",
        "# Force execution on GPU #0 if available\n",
        "if tf.config.list_physical_devices(\"GPU\"):\n",
        "  print(\"On GPU:\")\n",
        "  with tf.device(\"GPU:0\"): # Or GPU:1 for the 2nd GPU, GPU:2 for the 3rd etc.\n",
        "    x = tf.random.uniform([1000, 1000])\n",
        "    assert x.device.endswith(\"GPU:0\")\n",
        "    time_matmul(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1K4dlhhHtQj"
      },
      "source": [
        "## データセット\n",
        "\n",
        "このセクションでは [`tf.data.Dataset` API](https://www.tensorflow.org/guide/datasets) を使って、モデルにデータを供給するためのパイプラインを構築します。`tf.data.Dataset` APIは、単純で再利用可能な部品をもとに、モデルの訓練あるいは評価ループにデータを供給する高性能で複雑な入力パイプラインを構築するために使われます。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zI0fmOynH-Ne"
      },
      "source": [
        "### ソース`Dataset`の作成\n",
        "\n",
        "[Dataset.from_tensors](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#from_tensors) や[Dataset.from_tensor_slices](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#from_tensor_slices) といったファクトリー関数または [TextLineDataset](https://www.tensorflow.org/api_docs/python/tf/data/TextLineDataset) あるいは[TFRecordDataset](https://www.tensorflow.org/api_docs/python/tf/data/TFRecordDataset) のようなファイルを読み込むオブジェクトを使って、 **元となる**データセットを作成しましょう。詳しくは、[TensorFlow Dataset guide](https://www.tensorflow.org/guide/datasets#reading_input_data) を参照してください。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F04fVOHQIBiG"
      },
      "outputs": [],
      "source": [
        "ds_tensors = tf.data.Dataset.from_tensor_slices([1, 2, 3, 4, 5, 6])\n",
        "\n",
        "# Create a CSV file\n",
        "import tempfile\n",
        "_, filename = tempfile.mkstemp()\n",
        "\n",
        "with open(filename, 'w') as f:\n",
        "  f.write(\"\"\"Line 1\n",
        "Line 2\n",
        "Line 3\n",
        "  \"\"\")\n",
        "\n",
        "ds_file = tf.data.TextLineDataset(filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbxIhC-5IPdf"
      },
      "source": [
        "### 変換の適用\n",
        "\n",
        "[map](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#map),  [batch](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#batch),  [shuffle](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#shuffle) などの変換関数を使って、データセットレコードに変換を適用します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uXSDZWE-ISsd"
      },
      "outputs": [],
      "source": [
        "ds_tensors = ds_tensors.map(tf.square).shuffle(2).batch(2)\n",
        "\n",
        "ds_file = ds_file.batch(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8X1GNfoIZKJ"
      },
      "source": [
        "### イテレート\n",
        "\n",
        "`tf.data.Dataset` オブジェクトは、中のレコードを繰り返し利用するためのイテレーションをサポートします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ws-WKRk5Ic6-"
      },
      "outputs": [],
      "source": [
        "print('Elements of ds_tensors:')\n",
        "for x in ds_tensors:\n",
        "  print(x)\n",
        "\n",
        "print('\\nElements in ds_file:')\n",
        "for x in ds_file:\n",
        "  print(x)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "basics.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
