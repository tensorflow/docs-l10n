{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tce3stUlHN0L"
      },
      "source": [
        "##### Copyright 2019 The TensorFlow Authors.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tuOe1ymfHZPu"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfBg1C5NB3X0"
      },
      "source": [
        "# DTensor による分散型トレーニング\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6P32iYYV27b"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>     <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/distribute/dtensor_ml_tutorial\">     <img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">     TensorFlow.org で表示</a> </td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/ja/tutorials/distribute/dtensor_ml_tutorial.ipynb\">     <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">     Google Colab で実行</a> </td>\n",
        "  <td><a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/ja/tutorials/distribute/dtensor_ml_tutorial.ipynb\">     <img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">     GitHubでソースを表示</a></td>\n",
        "  <td><a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/ja/tutorials/distribute/dtensor_ml_tutorial.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">ノートブックをダウンロード</a></td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kiF4jjX4O1mF"
      },
      "source": [
        "## 概要\n",
        "\n",
        "DTensor を使用すると、デバイス間でモデルのトレーニングを分散し、有効性、信頼性、およびスケーラビリティを改善することができます。DTensor の概念についての詳細は、[DTensor プログラミングガイド](https://www.tensorflow.org/guide/dtensor_overview)をご覧ください。\n",
        "\n",
        "このチュートリアルでは、DTensor を使って、センチメント分析モデルをトレーニングします。この例では、以下の 3 つの分散型トレーニングスキームについて紹介します。\n",
        "\n",
        "- データ並列トレーニング: トレーニングサンプルを複数のデバイスにシャーディング（分割）します。\n",
        "- モデル並列トレーニング: モデル変数を複数のデバイスにシャーディングします。\n",
        "- 空間並列トレーニング: 入力データの特徴量を複数のデバイスにシャーディングします（[空間分割](https://cloud.google.com/blog/products/ai-machine-learning/train-ml-models-on-large-images-and-3d-volumes-with-spatial-partitioning-on-cloud-tpus)としても知られています）。\n",
        "\n",
        "このチュートリアルのトレーニングの部分は、[センチメント分析に関する Kaggle ガイド](https://www.kaggle.com/code/anasofiauzsoy/yelp-review-sentiment-analysis-tensorflow-tfds/notebook)ノートブックを基盤としています。完全なトレーニングと評価のワークフロー（DTensor なし）について学習するには、そちらのノートブックをご覧ください。\n",
        "\n",
        "このチュートリアルでは、以下のステップを説明します。\n",
        "\n",
        "- まず、データクリーニングを行い、トークン化された文とその極性の `tf.data.Dataset` を取得します。\n",
        "\n",
        "- 次に、カスタム Dense レイヤーと BatchNorm レイヤーを使って MLP モデルを構築します。推論変数の追跡には、`tf.Module` を使用します。モデルコンストラクタは、追加の `Layout` 引数を取って、変数のシャーディングを制御します。\n",
        "\n",
        "- トレーニングには、はじめに `tf.experimental.dtensor` のチェックポイント機能を使ってデータ並列トレーニングを使用します。次に、モデル並列トレーニングと空間並列トレーニングを使用します。\n",
        "\n",
        "- 最後のセクションでは、TensorFlow 2.9 時点での `tf.saved_model` と `tf.experimental.dtensor` の対話を簡単に説明します。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YD80veeg7QtW"
      },
      "source": [
        "## MNIST モデルをビルドする\n",
        "\n",
        "DTensor は、TensorFlow 2.9.0 リリースに含まれています。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-RKXLJN-7Yyb"
      },
      "outputs": [],
      "source": [
        "!pip install --quiet --upgrade --pre tensorflow tensorflow-datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcxP4_Zu7ciQ"
      },
      "source": [
        "次に、`tensorflow` と `tensorflow.experimental.dtensor` をインポートし、8 個の仮想 CPU を使用するように TensorFlow を構成します。\n",
        "\n",
        "この例では CPU を使用しますが、DTensor は CPU、GPU、または TPU デバイスで同じように動作します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dXcB26oP7dUd"
      },
      "outputs": [],
      "source": [
        "import tempfile\n",
        "import numpy as np\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.experimental import dtensor\n",
        "print('TensorFlow version:', tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oHtO6MJLUXlz"
      },
      "outputs": [],
      "source": [
        "def configure_virtual_cpus(ncpu):\n",
        "  phy_devices = tf.config.list_physical_devices('CPU')\n",
        "  tf.config.set_logical_device_configuration(phy_devices[0], [\n",
        "        tf.config.LogicalDeviceConfiguration(),\n",
        "    ] * ncpu)\n",
        "\n",
        "configure_virtual_cpus(8)\n",
        "DEVICES = [f'CPU:{i}' for i in range(8)]\n",
        "\n",
        "tf.config.list_logical_devices('CPU')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omYd4jbF7j_I"
      },
      "source": [
        "## データセットをダウンロードする\n",
        "\n",
        "センチメント分析モデルをトレーニングするための IMDB レビューデータセットをダウンロードします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fW4w4QlFVHhx"
      },
      "outputs": [],
      "source": [
        "train_data = tfds.load('imdb_reviews', split='train', shuffle_files=True, batch_size=64)\n",
        "train_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ki3mpfi4aZH8"
      },
      "source": [
        "## データを準備する\n",
        "\n",
        "まず、テキストをトークン化します。ここでは、One-Hot エンコーディングの拡張機能である `'tf_idf'` モードの `tf.keras.layers.TextVectorization` を使用します。\n",
        "\n",
        "- 速度を得るために、トークン数は 1200 に制限します。\n",
        "- `tf.Module` を単純に維持するために、トレーニングの前のプリプロセッシングステップとして `TextVectorization` を実行します。\n",
        "\n",
        "データクリーニングセクションの最終結果は、トークン化したテキストを `x`、ラベルを `y` とした `Dataset` です。\n",
        "\n",
        "**注意**: プリプロセッシングステップとして `TextVectorization` を実行するのは、**通常の実践でも推奨される実践もありません**。こうすることで、トレーニングデータがクライアントメモリに収まることが想定されますが、常にそうであるとは限りません。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zNpxjku_57Lg"
      },
      "outputs": [],
      "source": [
        "text_vectorization = tf.keras.layers.TextVectorization(output_mode='tf_idf', max_tokens=1200, output_sequence_length=None)\n",
        "text_vectorization.adapt(data=train_data.map(lambda x: x['text']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q16bjngoVwQp"
      },
      "outputs": [],
      "source": [
        "def vectorize(features):\n",
        "  return text_vectorization(features['text']), features['label']\n",
        "\n",
        "train_data_vec = train_data.map(vectorize)\n",
        "train_data_vec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atTqL9kE5wz4"
      },
      "source": [
        "## DTensor を使ってニューラルネットワークを構築する\n",
        "\n",
        "では、DTensor を使って多層パーセプトロン（MLP）ネットワークを構築しましょう。このネットワークでは、全結合の Dense と BatchNorm レイヤーを使用します。\n",
        "\n",
        "`DTensor` は、入力 `Tensor` と変数の `dtensor.Layout` 属性に従って、通常の TensorFlow Ops の単一プログラムマルチデータ（SPMD）拡張を通じて TensorFlow を拡張します。\n",
        "\n",
        "`DTensor` を認識するレイヤーの変数は `dtensor.DVariable` で、`DTensor` を認識するレイヤーオブジェクトのコンストラクタは、通常のレイヤーパラメータの他に追加の `Layout` 入力を取ります。\n",
        "\n",
        "注意: TensorFlow 2.9 の時点では、`tf.keras.layer.Dense` や `tf.keras.layer.BatchNormalization` などの Keras レイヤーは、`dtensor.Layout` 引数を受け取ります。DTensor を使って Keras を使用する方法の詳細については、[DTensor と Keras の統合チュートリアル](/tutorials/distribute/dtensor_keras_tutorial)をご覧ください。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMCt-Gj3b3Jy"
      },
      "source": [
        "### Dense レイヤー\n",
        "\n",
        "以下のカスタム Dense レイヤーは、2 つのレイヤー変数を定義します。1 つは重みの変数 $W_{ij}$、もう 1 つはバイアスの変数 $b_i$ です。\n",
        "\n",
        "$$ y_j = \\sigma(\\sum_i x_i W_{ij} + b_j) $$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYlFUJWNjl4N"
      },
      "source": [
        "### Layout の推論\n",
        "\n",
        "この結果は、以下の観察結果から得られます。\n",
        "\n",
        "- 行列内積 $t_j = \\sum_i x_i W_{ij}$ のオペランドに推奨される DTensor シャーディングは、$i$ 軸に沿って $\\mathbf{W}$ と $\\mathbf{x}$ を同じ方法でシャーディングすることです。\n",
        "\n",
        "- 行列和 $t_j + b_j$ のオペランドに推奨される DTensor シャーディングは、$j$ 軸に沿って $\\mathbf{t}$ と $\\mathbf{b}$ を同じ方法でシャーディングすることです。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VpKblz7Yb16G"
      },
      "outputs": [],
      "source": [
        "class Dense(tf.Module):\n",
        "\n",
        "  def __init__(self, input_size, output_size,\n",
        "               init_seed, weight_layout, activation=None):\n",
        "    super().__init__()\n",
        "\n",
        "    random_normal_initializer = tf.function(tf.random.stateless_normal)\n",
        "\n",
        "    self.weight = dtensor.DVariable(\n",
        "        dtensor.call_with_layout(\n",
        "            random_normal_initializer, weight_layout,\n",
        "            shape=[input_size, output_size],\n",
        "            seed=init_seed\n",
        "            ))\n",
        "    if activation is None:\n",
        "      activation = lambda x:x\n",
        "    self.activation = activation\n",
        "    \n",
        "    # bias is sharded the same way as the last axis of weight.\n",
        "    bias_layout = weight_layout.delete([0])\n",
        "\n",
        "    self.bias = dtensor.DVariable(\n",
        "        dtensor.call_with_layout(tf.zeros, bias_layout, [output_size]))\n",
        "\n",
        "  def __call__(self, x):\n",
        "    y = tf.matmul(x, self.weight) + self.bias\n",
        "    y = self.activation(y)\n",
        "\n",
        "    return y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfVY_vAKbxM0"
      },
      "source": [
        "### BatchNorm\n",
        "\n",
        "バッチ正規化レイヤーでは、トレーニング中にモードが崩壊するのを回避できます。この場合は、バッチ正則化レイヤーを追加することで、モデルのトレーニングでゼロのみを生成するモデルが生成されないようにすることができます。\n",
        "\n",
        "以下のカスタム `BatchNorm` レイヤーのコンストラクタは、`Layout` 引数を取りません。これは、`BatchNorm` にレイヤー変数がないためです。ただし、レイヤーへの唯一の入力である 'x' がすでにグローバルバッチを表現する DTensor であるため、DTensor では機能します。\n",
        "\n",
        "注意: DTensor では、入力 Tensor 'x' は常にグローバルバッチを表現します。したがって、`tf.nn.batch_normalization` はグローバルバッチに適用されます。これは、Tensor 'x'  がバッチのレプリカ単位のシャード（ローカルバッチ）のみを表現する `tf.distribute.MirroredStrategy` を使ってトレーニングとは異なります。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "riBA9pfhlPFq"
      },
      "outputs": [],
      "source": [
        "class BatchNorm(tf.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "  def __call__(self, x, training=True):\n",
        "    if not training:\n",
        "      # This branch is not used in the Tutorial.\n",
        "      pass\n",
        "    mean, variance = tf.nn.moments(x, axes=[0])\n",
        "    return tf.nn.batch_normalization(x, mean, variance, 0.0, 1.0, 1e-5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4R4MPz5prh4"
      },
      "source": [
        "フル機能のバッチ正規化レイヤー（`tf.keras.layers.BatchNormalization` など）は、変数に Layout 引数が必要となります。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "unFcP99zprJj"
      },
      "outputs": [],
      "source": [
        "def make_keras_bn(bn_layout):\n",
        "  return tf.keras.layers.BatchNormalization(gamma_layout=bn_layout,\n",
        "                                            beta_layout=bn_layout,\n",
        "                                            moving_mean_layout=bn_layout,\n",
        "                                            moving_variance_layout=bn_layout,\n",
        "                                            fused=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8Dj7AJ_lPs0"
      },
      "source": [
        "### すべてのレイヤーをまとめる\n",
        "\n",
        "次に、上記のビルディングブロックを使って、多層パーセプトロン（MLP）ネットワークを構築しましょう。下の図では、DTensor シャーディングまたは複製を適用しない 2 つの `Dense` レイヤーの入力 `x` と重み行列を示します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udFGAO-NrZw6"
      },
      "source": [
        "<img src=\"https://www.tensorflow.org/images/dtensor/no_dtensor.png\" class=\"\" alt=\"非分散型モデルの入力と重み行列。\"> \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DCQ0aQ5rQtB"
      },
      "source": [
        "最初の `Dense` レイヤーの出力は、2 つ目の `Dense` レイヤーの入力に渡されます（`BatchNorm` の後）。したがって、最初の `Dense` レイヤー（$\\mathbf{W_1}$）の出力と 2 つ目の `Dense` レイヤー（$\\mathbf{W_2}$）の入力に推奨される DTensor シャーディングは、$\\mathbf{W_1}$ と $\\mathbf{W_2}$ を共通する軸 $\\hat{j}$ に沿って同じ方法でシャーディングすることです。\n",
        "\n",
        "$$ \\mathsf{Layout}[{W_{1,ij}}; i, j] = \\left[\\hat{i}, \\hat{j}\\right] \\ \\mathsf{Layout}[{W_{2,jk}}; j, k] = \\left[\\hat{j}, \\hat{k} \\right] $$\n",
        "\n",
        "レイアウトの推論では、2 つのレイアウトが独立していないことが示されていますが、モデルインターフェイスを単純化するために、`MLP` は Dense レイヤーごとに1つずつ、2 つの `Layout` 引数を取ります。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "junyS-965opl"
      },
      "outputs": [],
      "source": [
        "from typing import Tuple\n",
        "\n",
        "class MLP(tf.Module):\n",
        "\n",
        "  def __init__(self, dense_layouts: Tuple[dtensor.Layout, dtensor.Layout]):\n",
        "    super().__init__()\n",
        "\n",
        "    self.dense1 = Dense(\n",
        "        1200, 48, (1, 2), dense_layouts[0], activation=tf.nn.relu)\n",
        "    self.bn = BatchNorm()\n",
        "    self.dense2 = Dense(48, 2, (3, 4), dense_layouts[1])\n",
        "\n",
        "  def __call__(self, x):\n",
        "    y = x\n",
        "    y = self.dense1(y)\n",
        "    y = self.bn(y)\n",
        "    y = self.dense2(y)\n",
        "    return y\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dgLmebHhr7h"
      },
      "source": [
        "レイアウト推論の制約の正確さと API の単純さの間に発生するトレードオフは、DTensor を使用する API の一般的な設計ポイントです。別の API を使用して `Layout` 間の依存関係をキャプチャすることも可能です。たとえば、`MLPStricter` クラスはコンストラクタに `Layout` オブジェクトを作成します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wEZR7UlihsYX"
      },
      "outputs": [],
      "source": [
        "class MLPStricter(tf.Module):\n",
        "\n",
        "  def __init__(self, mesh, input_mesh_dim, inner_mesh_dim1, output_mesh_dim):\n",
        "    super().__init__()\n",
        "\n",
        "    self.dense1 = Dense(\n",
        "        1200, 48, (1, 2), dtensor.Layout([input_mesh_dim, inner_mesh_dim1], mesh),\n",
        "        activation=tf.nn.relu)\n",
        "    self.bn = BatchNorm()\n",
        "    self.dense2 = Dense(48, 2, (3, 4), dtensor.Layout([inner_mesh_dim1, output_mesh_dim], mesh))\n",
        "\n",
        "\n",
        "  def __call__(self, x):\n",
        "    y = x\n",
        "    y = self.dense1(y)\n",
        "    y = self.bn(y)\n",
        "    y = self.dense2(y)\n",
        "    return y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GcQi7D5mal2L"
      },
      "source": [
        "モデルが確実に実行するように、完全に複製されたレイアウトと完全に複製された `'x'` 入力のバッチを使用してモデルをプローブします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zOPuYeQwallh"
      },
      "outputs": [],
      "source": [
        "WORLD = dtensor.create_mesh([(\"world\", 8)], devices=DEVICES)\n",
        "\n",
        "model = MLP([dtensor.Layout.replicated(WORLD, rank=2),\n",
        "             dtensor.Layout.replicated(WORLD, rank=2)])\n",
        "\n",
        "sample_x, sample_y = train_data_vec.take(1).get_single_element()\n",
        "sample_x = dtensor.copy_to_mesh(sample_x, dtensor.Layout.replicated(WORLD, rank=2))\n",
        "print(model(sample_x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akrjDstEpDv9"
      },
      "source": [
        "## データをデバイスに移動する\n",
        "\n",
        "通常、`tf.data` イテレータ（およびその他のデータの取得手法）によって、ローカルホストのデバイスメモリにバックアップされるテンソルオブジェクトが生成されます。このデータは、DTensor のコンポーネントテンソルをバックアップするアクセラレータデバイスのメモリに転送する必要があります。\n",
        "\n",
        "このような状況においては、`dtensor.copy_to_mesh` は適していません。DTensor はグローバル観点であるため、すべてのデバイスに入力テンソルを複製してしまうためです。そのため、このチュートリアルでは、データの転送を容易にするヘルパー関数 `repack_local_tensor` を使用します。このヘルパー関数は、レプリカをバックアップするデバイスに、グローバルバッチのレプリカ用のシャードを送信する（送信するだけです）`dtensor.pack` を使用します。\n",
        "\n",
        "単純化されたこの関数は、シングルクライアントを想定しています。マルチクライアントアプリケーションでは、ローカルテンソルを分割する正しい方法と、Split とローカルデバイスのマッピングを特定するには、多大な労力が必要となる可能性があります。\n",
        "\n",
        "`tf.data` の統合を単純化する追加の DTensor API が計画されており、シングルクライアントとマルチクライアントの両方のアプリケーションがサポートされる予定です。ご期待ください。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3t5WvQR4Hvo4"
      },
      "outputs": [],
      "source": [
        "def repack_local_tensor(x, layout):\n",
        "  \"\"\"Repacks a local Tensor-like to a DTensor with layout.\n",
        "\n",
        "  This function assumes a single-client application.\n",
        "  \"\"\"\n",
        "  x = tf.convert_to_tensor(x)\n",
        "  sharded_dims = []\n",
        "\n",
        "  # For every sharded dimension, use tf.split to split the along the dimension.\n",
        "  # The result is a nested list of split-tensors in queue[0].\n",
        "  queue = [x]\n",
        "  for axis, dim in enumerate(layout.sharding_specs):\n",
        "    if dim == dtensor.UNSHARDED:\n",
        "      continue\n",
        "    num_splits = layout.shape[axis]\n",
        "    queue = tf.nest.map_structure(lambda x: tf.split(x, num_splits, axis=axis), queue)\n",
        "    sharded_dims.append(dim)\n",
        "\n",
        "  # Now we can build the list of component tensors by looking up the location in\n",
        "  # the nested list of split-tensors created in queue[0].\n",
        "  components = []\n",
        "  for locations in layout.mesh.local_device_locations():\n",
        "    t = queue[0]\n",
        "    for dim in sharded_dims:\n",
        "      split_index = locations[dim]  # Only valid on single-client mesh.\n",
        "      t = t[split_index]\n",
        "    components.append(t)\n",
        "\n",
        "  return dtensor.pack(components, layout)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KKCDcjG7zj2"
      },
      "source": [
        "## データ並列トレーニング\n",
        "\n",
        "このセクションでは、データ並列トレーニング使用して、MLP モデルをトレーニングします。その後のセクションでは、モデル並列トレーニングと空間並列トレーニングについて説明します。\n",
        "\n",
        "データ並列トレーニングは、分散型機械学習で一般的に使用されているスキームです。\n",
        "\n",
        "- モデル変数は、N 個のデバイスにそれぞれ複製されます。\n",
        "- グローバルバッチは、N 個のレプリカごとのバッチに分割されます。\n",
        "- それぞれのレプリカごとのバッチは、レプリカデバイスでトレーニングされます。\n",
        "- 勾配は、すべてのレプリカでデータの重み付けが集団的に実行される前に減らされます。\n",
        "\n",
        "データ並列トレーニングでは、デバイスの数に関してほぼ直線的なスピードアップが得られます。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMsLUyTGq3oL"
      },
      "source": [
        "### データ並列メッシュを作成する\n",
        "\n",
        "典型的なデータ並行トレーニングループは、単一の `batch` 次元で構成される DTensor `Mesh` を使用します。この場合、各デバイスは、グローバルバッチからシャードを受け取るモデルのレプリカとなります。\n",
        "\n",
        "\n",
        "<img src=\"https://www.tensorflow.org/images/dtensor/dtensor_data_para.png\" class=\"\" alt=\"データ並列メッシュ\">\n",
        "\n",
        "複製されたモデルはレプリカで実行するため、モデル変数が完全に複製されます（シャーディングされません）。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C0IyOlxmeu4I"
      },
      "outputs": [],
      "source": [
        "mesh = dtensor.create_mesh([(\"batch\", 8)], devices=DEVICES)\n",
        "\n",
        "model = MLP([dtensor.Layout([dtensor.UNSHARDED, dtensor.UNSHARDED], mesh),\n",
        "             dtensor.Layout([dtensor.UNSHARDED, dtensor.UNSHARDED], mesh),])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OREKwBybo1gZ"
      },
      "source": [
        "### トレーニングデータを DTensor にパッキングする\n",
        "\n",
        "トレーニングデータバッチは、DTensor がトレーニングデータを `'batch'` メッシュ次元に均等に分散するように、`'batch'`(first) 軸に沿ってシャーディングされて DTensor にパックされます。\n",
        "\n",
        "**注意**: DTensor では、`batch size` は常にグローバルバッチサイズを指します。バッチサイズは、`batch` メッシュ次元のサイズで均等に分割されるように選択します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8xMYkTpGocY8"
      },
      "outputs": [],
      "source": [
        "def repack_batch(x, y, mesh):\n",
        "  x = repack_local_tensor(x, layout=dtensor.Layout(['batch', dtensor.UNSHARDED], mesh))\n",
        "  y = repack_local_tensor(y, layout=dtensor.Layout(['batch'], mesh))\n",
        "  return x, y\n",
        "\n",
        "sample_x, sample_y = train_data_vec.take(1).get_single_element()\n",
        "sample_x, sample_y = repack_batch(sample_x, sample_y, mesh)\n",
        "\n",
        "print('x', sample_x[:, 0])\n",
        "print('y', sample_y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uONSiqOIkFL1"
      },
      "source": [
        "### トレーニングステップ\n",
        "\n",
        "この例では、カスタムトレーニングループ（CTL）で確率的勾配降下法オプティマイザを使用します。このトピックについての詳細は、[カスタムトレーニングループガイド](https://www.tensorflow.org/guide/keras/writing_a_training_loop_from_scratch)と[ウォークスルー](https://www.tensorflow.org/tutorials/customization/custom_training_walkthrough)をご覧ください。\n",
        "\n",
        "`train_step` は、この本体が TensorFlow Graph としてトレースされることを示すために、`tf.function` としてカプセル化されます。`train_step` の本体は、前方推論パス、後方勾配パス、および変数更新で構成されています。\n",
        "\n",
        "`train_step` の本体には特殊な DTensor アノテーションが含まれないことに注意してください。代わりに、`train_step` には、入力バッチとモデルのグローバルビューから入力 `x` と `y` を処理する高レベルの TensorFlow 演算子のみが含まれています。すべての DTensor アノテーション（`Mesh`, `Layout`）は、トレーニングステップから除外されます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BwUFzLGDtQT6"
      },
      "outputs": [],
      "source": [
        "# Refer to the CTL (custom training loop guide)\n",
        "@tf.function\n",
        "def train_step(model, x, y, learning_rate=tf.constant(1e-4)):\n",
        "  with tf.GradientTape() as tape:\n",
        "    logits = model(x)\n",
        "    # tf.reduce_sum sums the batch sharded per-example loss to a replicated\n",
        "    # global loss (scalar).\n",
        "    loss = tf.reduce_sum(\n",
        "        tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
        "            logits=logits, labels=y))\n",
        "  parameters = model.trainable_variables\n",
        "  gradients = tape.gradient(loss, parameters)\n",
        "  for parameter, parameter_gradient in zip(parameters, gradients):\n",
        "    parameter.assign_sub(learning_rate * parameter_gradient)\n",
        "\n",
        "  # Define some metrics\n",
        "  accuracy = 1.0 - tf.reduce_sum(tf.cast(tf.argmax(logits, axis=-1, output_type=tf.int64) != y, tf.float32)) / x.shape[0]\n",
        "  loss_per_sample = loss / len(x)\n",
        "  return {'loss': loss_per_sample, 'accuracy': accuracy}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OYTu4j0evWT"
      },
      "source": [
        "### チェックポイントを設定する\n",
        "\n",
        "DTensor モデルには、初期状態の `tf.train.Checkpoint` を使用してチェックポイントを設定できます。シャーディングされた DVariables の保存と復元は、有効な分割保存と復元を実行します。現在、`tf.train.Checkpoint.save` と `tf.train.Checkpoint.restore` を使用する場合、すべての DVariables は同じホストメッシュ状にある必要があり、DVariables と通常の変数を同時に保存することはできません。チェックポイントの設定についての詳細は、[こちらのガイド](../../guide/checkpoint.ipynb)をご覧ください。\n",
        "\n",
        "DTensor のチェックポイントが復元されると、変数の `Layout` がチェックポイントの保存時と異なる場合があります。つまり、DTensor モデルの保存は、レイアウトとメッシュに関係なく、分割保存の効率にのみ影響するということです。DTensor モデルを 1 つのメッシュとレイアウトで保存し、別のメッシュとレイアウトで復元することが可能です。このチュートリアルではこの機能を利用して、モデルの並列トレーニングと空間並列トレーニングのセクションでトレーニングを続けます。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rsInFFJg7x9t"
      },
      "outputs": [],
      "source": [
        "CHECKPOINT_DIR = tempfile.mkdtemp()\n",
        "\n",
        "def start_checkpoint_manager(model):\n",
        "  ckpt = tf.train.Checkpoint(root=model)\n",
        "  manager = tf.train.CheckpointManager(ckpt, CHECKPOINT_DIR, max_to_keep=3)\n",
        "\n",
        "  if manager.latest_checkpoint:\n",
        "    print(\"Restoring a checkpoint\")\n",
        "    ckpt.restore(manager.latest_checkpoint).assert_consumed()\n",
        "  else:\n",
        "    print(\"New training\")\n",
        "  return manager\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9r77ky5Jgp1j"
      },
      "source": [
        "### トレーニングループ\n",
        "\n",
        "データ並列トレーニングスキームの場合、トレーニングを数エポック行って、その進捗をレポートします。モデルのトレーニングには 3 エポックでは不十分です。精度 50% は、適当な推定と同等と言えます。\n",
        "\n",
        "後でトレーニングを再開できるように、チェックポイント設定を有効にします。以降のセクションにおいて、チェックポイントを読み込み、別の並列スキームでトレーニングを行います。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UaLn-vGZgqbS"
      },
      "outputs": [],
      "source": [
        "num_epochs = 2\n",
        "manager = start_checkpoint_manager(model)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  step = 0\n",
        "  pbar = tf.keras.utils.Progbar(target=int(train_data_vec.cardinality()), stateful_metrics=[])\n",
        "  metrics = {'epoch': epoch}\n",
        "  for x,y in train_data_vec:\n",
        "\n",
        "    x, y = repack_batch(x, y, mesh)\n",
        "\n",
        "    metrics.update(train_step(model, x, y, 1e-2))\n",
        "\n",
        "    pbar.update(step, values=metrics.items(), finalize=False)\n",
        "    step += 1\n",
        "  manager.save()\n",
        "  pbar.update(step, values=metrics.items(), finalize=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRFJEhum7EGD"
      },
      "source": [
        "## モデル並列トレーニング\n",
        "\n",
        "2 次元 `Mesh` に切り替えて、2 つ目のメッシュ次元に沿ってモデル変数をシャーディングすると、トレーニングがモデル並列になります。\n",
        "\n",
        "モデル並列トレーニングでは、モデルの各レプリカは複数のデバイス（この場合は 2 つ）にまたがっています。\n",
        "\n",
        "- 4 個のモデルレプリカがあり、トレーニングデータバッチは、その 4 個のレプリカに分散されます。\n",
        "- 単一のモデルレプリカ内の 2 つのデバイスは、複製されたトレーニングデータを受け取ります。\n",
        "\n",
        "\n",
        "<img src=\"https://www.tensorflow.org/images/dtensor/dtensor_model_para.png\" alt=\"Model parallel mesh\" class=\"\"> \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5gZE9IT5Dzwl"
      },
      "outputs": [],
      "source": [
        "mesh = dtensor.create_mesh([(\"batch\", 4), (\"model\", 2)], devices=DEVICES)\n",
        "model = MLP([dtensor.Layout([dtensor.UNSHARDED, \"model\"], mesh), \n",
        "             dtensor.Layout([\"model\", dtensor.UNSHARDED], mesh)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ihof3DkMFKnf"
      },
      "source": [
        "トレーニングデータは、バッチ次元に沿ってシャーディングされたままであるため、データ並列トレーニングの場合と同じ `repack_batch` 関数を再利用できます。DTensor は `\"model\"` メッシュ次元に沿って、レプリカごとのバッチをレプリカ内のすべてのデバイスに自動的に複製します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dZf56ynbE_p1"
      },
      "outputs": [],
      "source": [
        "def repack_batch(x, y, mesh):\n",
        "  x = repack_local_tensor(x, layout=dtensor.Layout(['batch', dtensor.UNSHARDED], mesh))\n",
        "  y = repack_local_tensor(y, layout=dtensor.Layout(['batch'], mesh))\n",
        "  return x, y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UW3OXdhNFfpv"
      },
      "source": [
        "次に、トレーニングループを実行します。トレーニングループは、データ並列トレーニングの例と同じチェックポイントマネージャーを再利用するため、コードは全く同じです。\n",
        "\n",
        "モデル並列トレーニングで、データ並列でトレーニングされたモデルのトレーニングを続けることができます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LLC0wgii7EgA"
      },
      "outputs": [],
      "source": [
        "num_epochs = 2\n",
        "manager = start_checkpoint_manager(model)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  step = 0\n",
        "  pbar = tf.keras.utils.Progbar(target=int(train_data_vec.cardinality()))\n",
        "  metrics = {'epoch': epoch}\n",
        "  for x,y in train_data_vec:\n",
        "    x, y = repack_batch(x, y, mesh)\n",
        "    metrics.update(train_step(model, x, y, 1e-2))\n",
        "    pbar.update(step, values=metrics.items(), finalize=False)\n",
        "    step += 1\n",
        "  manager.save()\n",
        "  pbar.update(step, values=metrics.items(), finalize=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZH-aMrVzi2L"
      },
      "source": [
        "## 空間並列トレーニング"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-bK6IZ9GCS9"
      },
      "source": [
        "非常に高次元のデータ（非常に大きな画像や動画など）をトレーニングする際は、特徴量次元に沿ってシャーディングすることが推奨される可能性があります。これは[空間分割](https://cloud.google.com/blog/products/ai-machine-learning/train-ml-models-on-large-images-and-3d-volumes-with-spatial-partitioning-on-cloud-tpus)と呼ばれる手法で、はじめは大きな 3D 入力サンプルでモデルをトレーニングするために TensorFlow に導入された手法です。\n",
        "\n",
        "\n",
        "<img src=\"https://www.tensorflow.org/images/dtensor/dtensor_spatial_para.png\" class=\"no-filter\" alt=\"空間並列メッシュ\">\n",
        "\n",
        "DTensor はこのようなケースもサポートしています。唯一変更が必要なのは、`feature` 次元を含めて対応する `Layout` を適用するメッシュを作成することです。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jpc9mqURGpmK"
      },
      "outputs": [],
      "source": [
        "mesh = dtensor.create_mesh([(\"batch\", 2), (\"feature\", 2), (\"model\", 2)], devices=DEVICES)\n",
        "model = MLP([dtensor.Layout([\"feature\", \"model\"], mesh), \n",
        "             dtensor.Layout([\"model\", dtensor.UNSHARDED], mesh)])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i07Wrv-jHBc1"
      },
      "source": [
        "入力テンソルを DTensor にパッキングする際に、`feature` 次元に沿って入力データをシャーディングします。この作業は、`repack_batch_for_spt` というわずかに異なる再パック関数を使って行います。ここで、`spt` は、空間並列トレーニング（Spatial Parallel Training）略です。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DWR8qF6BGtFL"
      },
      "outputs": [],
      "source": [
        "def repack_batch_for_spt(x, y, mesh):\n",
        "    # Shard data on feature dimension, too\n",
        "    x = repack_local_tensor(x, layout=dtensor.Layout([\"batch\", 'feature'], mesh))\n",
        "    y = repack_local_tensor(y, layout=dtensor.Layout([\"batch\"], mesh))\n",
        "    return x, y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ygl9dqMUHTVN"
      },
      "source": [
        "空間並列トレーニングも、他の並列トレーニングスキームで作成されたチェックポイントから続行することができます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p3NnpHSKo-hx"
      },
      "outputs": [],
      "source": [
        "num_epochs = 2\n",
        "\n",
        "manager = start_checkpoint_manager(model)\n",
        "for epoch in range(num_epochs):\n",
        "  step = 0\n",
        "  metrics = {'epoch': epoch}\n",
        "  pbar = tf.keras.utils.Progbar(target=int(train_data_vec.cardinality()))\n",
        "\n",
        "  for x, y in train_data_vec:\n",
        "    x, y = repack_batch_for_spt(x, y, mesh)\n",
        "    metrics.update(train_step(model, x, y, 1e-2))\n",
        "\n",
        "    pbar.update(step, values=metrics.items(), finalize=False)\n",
        "    step += 1\n",
        "  manager.save()\n",
        "  pbar.update(step, values=metrics.items(), finalize=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vp4L59CpJjYr"
      },
      "source": [
        "## SavedModel と DTensor\n",
        "\n",
        "DTensor と SavedModel の統合は、現在開発中です。\n",
        "\n",
        "TensorFlow `2.11` の時点では、`tf.saved_model` は分割されて複製された DTensor モデルを保存することが可能であるため、保存は、メッシュの様々なデバイスで有効な分割保存を実行しますが、モデルが保存されると、すべての DTensor アノテーションが失われ、保存したシグネチャは DTensor ではなく通常の Tensor とのみ使用できるようになってしまいます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "49HfIq_SJZoj"
      },
      "outputs": [],
      "source": [
        "mesh = dtensor.create_mesh([(\"world\", 1)], devices=DEVICES[:1])\n",
        "mlp = MLP([dtensor.Layout([dtensor.UNSHARDED, dtensor.UNSHARDED], mesh), \n",
        "           dtensor.Layout([dtensor.UNSHARDED, dtensor.UNSHARDED], mesh)])\n",
        "\n",
        "manager = start_checkpoint_manager(mlp)\n",
        "\n",
        "model_for_saving = tf.keras.Sequential([\n",
        "  text_vectorization,\n",
        "  mlp\n",
        "])\n",
        "\n",
        "@tf.function(input_signature=[tf.TensorSpec([None], tf.string)])\n",
        "def run(inputs):\n",
        "  return {'result': model_for_saving(inputs)}\n",
        "\n",
        "tf.saved_model.save(\n",
        "    model_for_saving, \"/tmp/saved_model\",\n",
        "    signatures=run)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6Csim_VMGxQ"
      },
      "source": [
        "TensorFlow 2.9.0 の時点では、読み込まれたシグネチャは通常の Tensor か完全に複製された DTensor（通常の Tensor に変換されます）を使ってのみ呼び出せます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HG_ASSzR4IWW"
      },
      "outputs": [],
      "source": [
        "sample_batch = train_data.take(1).get_single_element()\n",
        "sample_batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qW8yKPrhKQ5b"
      },
      "outputs": [],
      "source": [
        "loaded = tf.saved_model.load(\"/tmp/saved_model\")\n",
        "\n",
        "run_sig = loaded.signatures[\"serving_default\"]\n",
        "result = run_sig(sample_batch['text'])['result']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GahGbv0ZmkJb"
      },
      "outputs": [],
      "source": [
        "np.mean(tf.argmax(result, axis=-1) == sample_batch['label'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ks-Vs9qsH6jO"
      },
      "source": [
        "## 次のステップ\n",
        "\n",
        "このチュートリアルでは、DTensor を使って MLP センチメント分析モデルの構築とトレーニングを行う方法を説明しました。\n",
        "\n",
        "`Mesh` と `Layout` はプリミティブではありますが、DTensor は TensorFlow `tf.function` を、さまざまなトレーニングスキームに適した分散型プログラムに変換することができます。\n",
        "\n",
        "実際の機械学習アプリケーションでは、評価とクロス検証を適用して、過学習モデルが生成されないようにする必要があります。このチュートリアルで紹介された手法を適用して、評価に並列性を導入することも可能です。\n",
        "\n",
        "`tf.Module` を使ってモデルをゼロから構築するには多大な労力が必要であり、レイヤーやヘルパー関数と言った既存のビルディングブロックを再利用することで、モデル開発を大幅に高速化することができます。TensorFlow 2.9.0 の時点では、`tf.keras.layers` 以下のすべての Keras レイヤーは、その引数として DTensor レイアウトを受け入れ、DTensor モデルを構築するために使用することができます。また、モデルの実装を変更することなく、DTensor を使って直接 Keras モデルを再利用することも可能です。DTensor Keras の使用に関する詳細は、[DTensor と Keras の統合チュートリアル](https://www.tensorflow.org/tutorials/distribute/dtensor_keras_tutorial)をご覧ください。 "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "dtensor_ml_tutorial.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
