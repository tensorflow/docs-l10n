{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tce3stUlHN0L"
      },
      "source": [
        "##### Copyright 2019 The TensorFlow Authors.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tuOe1ymfHZPu"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfBg1C5NB3X0"
      },
      "source": [
        "# Keras を使ったマルチワーカートレーニング\n",
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td><a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/distribute/multi_worker_with_keras\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">TensorFlow.org で実行</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/distribute/multi_worker_with_keras.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Google Colab で実行</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/multi_worker_with_keras.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">GitHub でソースを表示</a></td>\n",
        "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/tutorials/distribute/multi_worker_with_keras.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">ノートブックをダウンロード</a>\n",
        "</td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHxb-dlhMIzW"
      },
      "source": [
        "## 概要\n",
        "\n",
        "このチュートリアルでは、`tf.distribute.Strategy` API、具体的には`tf.distribute.MultiWorkerMirroredStrategy` クラスを使用して、Keras モデルと `Model.fit` API によるマルチワーカー分散型トレーニングを実演します。このストラテジーの助けにより、シングルワーカーで実行するように設計された Keras モデルは、最小限のコード変更で複数のワーカーでシームレスに機能することができます。\n",
        "\n",
        "`tf.distribute.Strategy` API をさらに学習したい方は、[TensorFlow での分散トレーニング](../../guide/distributed_training.ipynb)ガイドで TensorFlow がサポートする分散ストラテジーの概要をご覧ください。\n",
        "\n",
        "Keras とカスタムループで `MultiWorkerMirroredStrategy` を使用する方法を学習する場合は、[Keras と MultiWorkerMirroredStrategy によるカスタムトレーニングループ](multi_worker_with_ctl.ipynb)をご覧ください。\n",
        "\n",
        "このチュートリアルの目的は、2 つのワーカーを使った最小限のマルチワーカーの例を紹介することです。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUXex9ctTuDB"
      },
      "source": [
        "## セットアップ\n",
        "\n",
        "まず、必要なものをインポートします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bnYxvfLD-LW-"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "import sys"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zz0EY91y3mxy"
      },
      "source": [
        "TensorFlow をインポートする前に、環境にいくつかの変更を加えます。\n",
        "\n",
        "1. すべての GPU を無効にします。 これにより、すべてのワーカーが同じ GPU を使用しようとすることによって発生するエラーが防止されます。 実際のアプリケーションでは、各ワーカーは異なるマシン上にあります。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "685pbYEY3jGC"
      },
      "outputs": [],
      "source": [
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7X1MS6385BWi"
      },
      "source": [
        "1. `TF_CONFIG` 環境変数をリセットします（これについては後で詳しく説明します）。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WEJLYa2_7OZF"
      },
      "outputs": [],
      "source": [
        "os.environ.pop('TF_CONFIG', None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rd4L9Ii77SS8"
      },
      "source": [
        "1. 現在のディレクトリが Python のパス上にあることを確認してください。これにより、ノートブックは `%%writefile` で書き込まれたファイルを後でインポートできるようになります。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hPBuZUNSZmrQ"
      },
      "outputs": [],
      "source": [
        "if '.' not in sys.path:\n",
        "  sys.path.insert(0, '.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDhHuMjb7bfU"
      },
      "source": [
        "次に TensorFlow をインポートします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vHNvttzV43sA"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0S2jpf6Sx50i"
      },
      "source": [
        "### データセットとモデルの定義"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLW6D2TzvC-4"
      },
      "source": [
        "次に、単純なモデルとデータセットの設定を使用して`mnist.py`ファイルを作成します。 この Python ファイルは、このチュートリアルのワーカープロセスによって使用されます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dma_wUAxZqo2"
      },
      "outputs": [],
      "source": [
        "%%writefile mnist_setup.py\n",
        "\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "def mnist_dataset(batch_size):\n",
        "  (x_train, y_train), _ = tf.keras.datasets.mnist.load_data()\n",
        "  # The `x` arrays are in uint8 and have values in the [0, 255] range.\n",
        "  # You need to convert them to float32 with values in the [0, 1] range.\n",
        "  x_train = x_train / np.float32(255)\n",
        "  y_train = y_train.astype(np.int64)\n",
        "  train_dataset = tf.data.Dataset.from_tensor_slices(\n",
        "      (x_train, y_train)).shuffle(60000).repeat().batch(batch_size)\n",
        "  return train_dataset\n",
        "\n",
        "def build_and_compile_cnn_model():\n",
        "  model = tf.keras.Sequential([\n",
        "      tf.keras.layers.InputLayer(input_shape=(28, 28)),\n",
        "      tf.keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
        "      tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
        "      tf.keras.layers.Flatten(),\n",
        "      tf.keras.layers.Dense(128, activation='relu'),\n",
        "      tf.keras.layers.Dense(10)\n",
        "  ])\n",
        "  model.compile(\n",
        "      loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "      optimizer=tf.keras.optimizers.SGD(learning_rate=0.001),\n",
        "      metrics=['accuracy'])\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UL3kisMO90X"
      },
      "source": [
        "### シングルワーカーでのモデルのトレーニング\n",
        "\n",
        "まず、少数のエポックでモデルをトレーニングし、シングルワーカーで結果を観察して、すべてが正しく機能していることを確認します。エポックが進むにつれ、損失が下降し、精度が 1.0 に近づくはずです。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Qe6iAf5O8iJ"
      },
      "outputs": [],
      "source": [
        "import mnist_setup\n",
        "\n",
        "batch_size = 64\n",
        "single_worker_dataset = mnist_setup.mnist_dataset(batch_size)\n",
        "single_worker_model = mnist_setup.build_and_compile_cnn_model()\n",
        "single_worker_model.fit(single_worker_dataset, epochs=3, steps_per_epoch=70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmgZwwymxqt5"
      },
      "source": [
        "## マルチワーカー構成\n",
        "\n",
        "では、マルチワーカートレーニングの世界を覗いてみましょう。\n",
        "\n",
        "### ジョブとタスクのクラスタ\n",
        "\n",
        "TensorFlow では、分散トレーニングには、いくつかのジョブが含まれる `'cluster'` があり、各ジョブには 1 つ以上の `'task'` が含まれることがあります。\n",
        "\n",
        "それぞれに異なる役割をもつ複数のマシンでトレーニングするには `TF_CONFIG` 環境変数が必要です。`TF_CONFIG` は JSON 文字列で、クラスタの一部である各ワーカーのクラスタ構成を指定するために使用されます。\n",
        "\n",
        "`TF_CONFIG` 変数には、`'cluster'` と `'task'` の 2 つのコンポーネントがあります。\n",
        "\n",
        "- `'cluster'` はすべてのワーカーに共通し、トレーニングクラスタに関する情報を、`'worker'` または `'chief'` などのさまざまなジョブの種類で構成される dict として提供します。\n",
        "\n",
        "    - `tf.distribute.MultiWorkerMirroredStrategy` によるマルチワーカートレーニングでは通常、`'worker'` が通常行うことのほかにチェックポイントの保存や TensorBoard 用のサマリーファイルの書き込みといった役割を果たす 1 つの `'worker'` があります。こういった `'worker'` はチーフワーカー（ジョブ名は `'chief'`）と呼ばれます。\n",
        "    - 通例、`'chief'` には `'index'` `0` が指定されます（実際、`tf.distribute.Strategy` はそのように実装されています）。\n",
        "\n",
        "- `'task'` は現在のタスクの情報を提供し、ワーカーごとに異なります。タスクはそのワーカーの `'type'` と `'index'` を指定します。\n",
        "\n",
        "以下に構成例を示します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XK1eTYvSZiX7"
      },
      "outputs": [],
      "source": [
        "tf_config = {\n",
        "    'cluster': {\n",
        "        'worker': ['localhost:12345', 'localhost:23456']\n",
        "    },\n",
        "    'task': {'type': 'worker', 'index': 0}\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjgwJbPKZkJL"
      },
      "source": [
        "これは、JSON 文字列としてシリアル化された同じ`TF_CONFIG`です。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yY-T0YDQZjbu"
      },
      "outputs": [],
      "source": [
        "json.dumps(tf_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f83FVYqDX3aX"
      },
      "source": [
        "`tf_config` は Python 単なるローカル変数です。トレーニング構成で使用するには、この dict を JSON としてシリアル化し、`TF_CONFIG` 環境変数に配置する必要があります。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YFpxrcsZ2xG"
      },
      "source": [
        "上記の構成例では、タスク `'type'` を `'worker'` に設定し、タスク `'index'` を `0` に設定しています。そのため、このマシンが*最初*のワーカーとなります。`'chief'` ワーカーとして指定されることになるため、ほかのワーカーよりも多くの作業を行います。\n",
        "\n",
        "注意: 他のマシンにも `TF_CONFIG` 環境変数を設定し、同じ `'cluster'` dict が必要となりますが、それらのマシンの役割に応じた異なるタスク `'type'` またはタスク `'index'` が必要となります。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aogb74kHxynz"
      },
      "source": [
        "説明の目的により、このチュートリアルではある `localhost` の 2 つのワーカーでどのように`TF_CONFIG` 変数をセットアップできるかを示しています。\n",
        "\n",
        "実際には、外部 IP aドレス/ポートに複数のワーカーを作成して、ワーカーごとに適宜 `TF_CONFIG` 変数を設定する必要があります。\n",
        "\n",
        "このチュートリアルでは、2 つのワーカーを使用します。\n",
        "\n",
        "- 最初の (`'chief'`) ワーカーの `TF_CONFIG` は上記に示す通りです。\n",
        "- 2 つ目のワーカーでは、`tf_config['task']['index']=1` を設定します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cIlkfWmjz1PG"
      },
      "source": [
        "### ノートブックの環境変数とサブプロセス"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcjAbuGY1ACJ"
      },
      "source": [
        "サブプロセスは、親プロセスの環境変数を継承します。\n",
        "\n",
        "たとえば、この Jupyter ノートブックのプロセスでは、環境変数を次のように設定できます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PH2gHn2_0_U8"
      },
      "outputs": [],
      "source": [
        "os.environ['GREETINGS'] = 'Hello TensorFlow!'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQkIX-cg18md"
      },
      "source": [
        "すると、サブプロセスからその環境変数にアクセスできます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pquKO6IA18G5"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "echo ${GREETINGS}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "af6BCA-Y2fpz"
      },
      "source": [
        "次のセクションでは、似たような方法で、`TF_CONFIG` をワーカーのサブプロセスに渡します。実際に行う場合はこのようにしてジョブを起動することはありませんが、この例では十分です。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhNtHfuxCGVy"
      },
      "source": [
        "## 適切なストラテジーを選択する\n",
        "\n",
        "TensorFlow では、以下の 2 つの分散型トレーニングがあります。\n",
        "\n",
        "- *同期トレーニング*: トレーニングのステップがワーカーとレプリカ間で同期されます。\n",
        "- *非同期トレーニング*: トレーニングステップが厳密に同期されません（[パラメータサーバートレーニング](parameter_server_training.ipynb)など）。\n",
        "\n",
        "このチュートリアルでは、`tf.distribute.MultiWorkerMirroredStrategy` のインスタンスを使用して、同期マルチワーカートレーニングを実行する方法を示します。\n",
        "\n",
        "`MultiWorkerMirroredStrategy`は、すべてのワーカーの各デバイスにあるモデルのレイヤーにすべての変数のコピーを作成します。集合通信に使用する TensorFlow 演算子`CollectiveOps`を使用して勾配を集め、変数の同期を維持します。このストラテジーの詳細は、[`tf.distribute.Strategy`ガイド](../../guide/distributed_training.ipynb)で説明されています。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1uFSHCJXMrQ-"
      },
      "outputs": [],
      "source": [
        "strategy = tf.distribute.MultiWorkerMirroredStrategy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0iv7SyyAohc"
      },
      "source": [
        "注意: `MultiWorkerMirroredStrategy`が呼び出されると、`TF_CONFIG`が解析され、TensorFlow の GRPC サーバーが開始します。そのため、`TF_CONFIG`環境変数は、`tf.distribute.Strategy`インスタンスが作成される前に設定しておく必要があります。`TF_CONFIG`はまだ設定されていないため、上記の戦略は実質的にシングルワーカーのトレーニングです。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMy2VM4Akzpr"
      },
      "source": [
        "`MultiWorkerMirroredStrategy` は、`tf.distribute.experimental.CommunicationOptions` パラメータを介して複数の実装を提供します。1) `RING` は gRPC をクロスホスト通信レイヤーとして使用して、リング状の集合体を実装します。2) `NCCL` は [NVIDIA Collective Communication Library](https://developer.nvidia.com/nccl) を使用して集合体を実装します。3) `AUTO` はその選択をランタイムに任せます。集合体の最適な実装は GPU の数と種類、およびクラスタ内のネットワーク相互接続によって異なります。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H47DDcOgfzm7"
      },
      "source": [
        "## モデルのトレーニング\n",
        "\n",
        "`tf.keras`に`tf.distribute.Strategy` API を統合したため、トレーニングをマルチワーカーに分散するには、モデルビルディングと`model.compile()`呼び出しを`strategy.scope()`内に収めるように変更することだけが必要となりました。この分散ストラテジーのスコープは、どこでどのように変数が作成されるかを指定し、`MultiWorkerMirroredStrategy`の場合、作成される変数は`MirroredVariable`で、各ワーカーに複製されます。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wo6b9wX65glL"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "  # Model building/compiling need to be within `strategy.scope()`.\n",
        "  multi_worker_model = mnist_setup.build_and_compile_cnn_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mhq3fzyR5hTw"
      },
      "source": [
        "注意: 現在のところ、`MultiWorkerMirroredStrategy` には、TensorFlow 演算子をストラテジーのインスタンスが作成された後に作成する必要があるという制限があります。`RuntimeError: Collective ops must be configured at program startup` が表示される場合は、プログラムのはじめに `MultiWorkerMirroredStrategy` のインスタンスを作成するようにし、演算子を作成するコードをストラテジーがインスタンス化される後に配置するようにしてください。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfYpmIxO6Jck"
      },
      "source": [
        "`MultiWorkerMirroredStrategy`で実際に実行するには、ワーカープロセスを実行し、`TF_CONFIG`をそれらに渡す必要があります。\n",
        "\n",
        "前に記述した`mnist_setup.py`ファイルと同様に、各ワーカーが実行する`main.py`は次のとおりです。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BcsuBYrpgnlS"
      },
      "outputs": [],
      "source": [
        "%%writefile main.py\n",
        "\n",
        "import os\n",
        "import json\n",
        "\n",
        "import tensorflow as tf\n",
        "import mnist_setup\n",
        "\n",
        "per_worker_batch_size = 64\n",
        "tf_config = json.loads(os.environ['TF_CONFIG'])\n",
        "num_workers = len(tf_config['cluster']['worker'])\n",
        "\n",
        "strategy = tf.distribute.MultiWorkerMirroredStrategy()\n",
        "\n",
        "global_batch_size = per_worker_batch_size * num_workers\n",
        "multi_worker_dataset = mnist_setup.mnist_dataset(global_batch_size)\n",
        "\n",
        "with strategy.scope():\n",
        "  # Model building/compiling need to be within `strategy.scope()`.\n",
        "  multi_worker_model = mnist_setup.build_and_compile_cnn_model()\n",
        "\n",
        "\n",
        "multi_worker_model.fit(multi_worker_dataset, epochs=3, steps_per_epoch=70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aom9xelvJQ_6"
      },
      "source": [
        "上記のコードスニペットでは、`Dataset.batch`に渡される`global_batch_size`が`per_worker_batch_size * num_workers`に設定されていることに注意してください。これにより、ワーカーの数に関係なく、各ワーカーが`per_worker_batch_size`の例のバッチを処理するようになります。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHLhOii67Saa"
      },
      "source": [
        "現在のディレクトリには、両方の Python ファイルが含まれています。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bi6x05Sr60O9"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "ls *.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmEEStPS6vR_"
      },
      "source": [
        "json は`TF_CONFIG`}をシリアル化し、環境変数に追加します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9uu3g7vV7Bbt"
      },
      "outputs": [],
      "source": [
        "os.environ['TF_CONFIG'] = json.dumps(tf_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MsY3dQLK7jdf"
      },
      "source": [
        "これで、`main.py`を実行し、`TF_CONFIG`を使用するワーカープロセスを起動できます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "txMXaq8d8N_S"
      },
      "outputs": [],
      "source": [
        "# first kill any previous runs\n",
        "%killbgscripts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qnSma_Ck7r-r"
      },
      "outputs": [],
      "source": [
        "%%bash --bg\n",
        "python main.py &> job_0.log"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZChyazqS7v0P"
      },
      "source": [
        "上記のコマンドについて注意すべき点がいくつかあります。\n",
        "\n",
        "1. [ノートブック 「マジック」 ](https://ipython.readthedocs.io/en/stable/interactive/magics.html)である`%%bash`を使用して、いくつかの bash コマンドを実行します。\n",
        "2. このワーカーは終了しないため、`--bg`フラグを使用して`bash`プロセスをバックグラウンドで実行します。 このワーカーは始める前にすべてのワーカーを待ちます。\n",
        "\n",
        "バックグラウンドのワーカープロセスはこのノートブックに出力を出力しないため、`&>` で出力をファイルにリダイレクトし、何が起こったかを検査できます。\n",
        "\n",
        "プロセスが開始するまで数秒待ちます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hm2yrULE9281"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "time.sleep(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFPoNxg_9_Mx"
      },
      "source": [
        "これまでにワーカーのログファイルに出力されたものを検査します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vZEOuVgQ9-hn"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "cat job_0.log"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqZhVF7L_KOy"
      },
      "source": [
        "ログファイルの最後の行は `Started server with target: grpc://localhost:12345`であるはずです。最初のワーカーは準備が整い、他のすべてのワーカーの準備が整うのを待っています。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pi8vPNNA_l4a"
      },
      "source": [
        "2番目のワーカーのプロセスを始めるように`tf_config`を更新します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lAiYkkPu_Jqd"
      },
      "outputs": [],
      "source": [
        "tf_config['task']['index'] = 1\n",
        "os.environ['TF_CONFIG'] = json.dumps(tf_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0AshGVO0_x0w"
      },
      "source": [
        "2番目のワーカーを起動します。すべてのワーカーがアクティブであるため、これによりトレーニングが開始されます（したがって、このプロセスをバックグラウンドで実行する必要はありません）。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ESVtyQ9_xjx"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "python main.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hX4FA2O2AuAn"
      },
      "source": [
        "最初のワーカーにより書き込まれたログを再確認すると、そのモデルのトレーニングに参加していることがわかります。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rc6hw3yTBKXX"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "cat job_0.log"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zL79ak5PMzEg"
      },
      "source": [
        "当然ながら、これはこのチュートリアルの最初に実行したテストよりも実行速度が*劣っています*。\n",
        "\n",
        "単一のマシンで複数のワーカーを実行しても、オーバーヘッドが追加されるだけです。\n",
        "\n",
        "ここではトレーニングの時間を改善することではなく、マルチワーカートレーニングの例を紹介することを目的としています。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sG5_1UgrgniF"
      },
      "outputs": [],
      "source": [
        "# Delete the `TF_CONFIG`, and kill any background tasks so they don't affect the next section.\n",
        "os.environ.pop('TF_CONFIG', None)\n",
        "%killbgscripts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9j2FJVHoUIrE"
      },
      "source": [
        "## マルチワーカートレーニングの詳細\n",
        "\n",
        "ここまで、基本的なマルチワーカーのセットアップの実行を見てきました。\n",
        "\n",
        "このチュートリアルの残りの部分では、実際のユースケースで役立つ重要な要素について詳しく説明します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rr14Vl9GR4zq"
      },
      "source": [
        "### データセットのシャーディング\n",
        "\n",
        "マルチワーカートレーニングでは、コンバージェンスとパフォーマンスを確保するために、データセットのシャーディングが必要です。\n",
        "\n",
        "前のセクションの例は、`tf.distribute.Strategy` API により提供されるデフォルトの自動シャーディングに依存しています。`tf.data.experimental.DistributeOptions` の `tf.data.experimental.AutoShardPolicy` を設定することで、シャーディングを制御できます。\n",
        "\n",
        "*自動シャーディング*の詳細については、[分散入力ガイド](https://www.tensorflow.org/tutorials/distribute/input#sharding)をご覧ください。\n",
        "\n",
        "自動シャーディングをオフにして、各レプリカがすべての例を処理する方法の簡単な例を次に示します（推奨されません）。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JxEtdh1vH-TF"
      },
      "outputs": [],
      "source": [
        "options = tf.data.Options()\n",
        "options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.OFF\n",
        "\n",
        "global_batch_size = 64\n",
        "multi_worker_dataset = mnist_setup.mnist_dataset(batch_size=64)\n",
        "dataset_no_auto_shard = multi_worker_dataset.with_options(options)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmqvlh5LhAoU"
      },
      "source": [
        "### 評価\n",
        "\n",
        "`validation_data` を `Model.fit` に渡すと、エポックごとにトレーニングと評価が交互に行われるようになります。`validation_data` を取る評価は同じセットのワーカー間で分散されているため、評価結果はすべてのワーカーが使用できるように集計されます。\n",
        "\n",
        "トレーニングと同様に、評価データセットもファイルレベルで自動的にシャーディングされます。評価データセットにグローバルバッチサイズを設定し、`validation_steps` を設定する必要があります。\n",
        "\n",
        "評価ではデータセットを繰り返すことも推奨されます。\n",
        "\n",
        "Alternatively, you can also create another task that periodically reads checkpoints and runs the evaluation. This is what Estimator does. But this is not a recommended way to perform evaluation and thus its details are omitted."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVk4ftYx6JAO"
      },
      "source": [
        "### 性能\n",
        "\n",
        "これで、`MultiWorkerMirroredStrategy` を使ってマルチワーカーで実行するようにセットアップされた Keras モデルの準備ができました。\n",
        "\n",
        "マルチワーカートレーニングのパフォーマンスを調整するには、次を行うことができます。\n",
        "\n",
        "- `tf.distribute.MultiWorkerMirroredStrategy` には複数の[集合体通信実装](https://www.tensorflow.org/api_docs/python/tf/distribute/experimental/CommunicationImplementation)が用意されています。\n",
        "\n",
        "    - `RING` は、クロスホスト通信レイヤーとして、gRPC を使用したリング状の集合体を実装します。\n",
        "    - `NCCL` は [NVIDIA Collective Communication Library](https://developer.nvidia.com/nccl) を使用して集合体を実装します。\n",
        "    - `AUTO` は、選択をランタイムに任せます。\n",
        "\n",
        "    集合体の最適な実装は、GPU の数、GPU の種類、およびクラスタ内のネットワーク相互接続によって異なります。自動選択をオーバーライドするには、`MultiWorkerMirroredStrategy` のコンストラクタの `communication_options` パラメータを以下のようにして指定します。\n",
        "\n",
        "    ```python\n",
        "    communication_options=tf.distribute.experimental.CommunicationOptions(implementation=tf.distribute.experimental.CollectiveCommunication.NCCL)\n",
        "    ```\n",
        "\n",
        "- 可能であれば、変数を `tf.float` にキャストします。\n",
        "\n",
        "    - 公式の ResNet モデルには、どのようにしてこれを行うかの[例](https://github.com/tensorflow/models/blob/8367cf6dabe11adf7628541706b660821f397dce/official/resnet/resnet_model.py#L466)が示されています。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97WhAu8uKw3j"
      },
      "source": [
        "### フォールトトレランス\n",
        "\n",
        "同期トレーニングでは、ワーカーが 1 つでも失敗し、障害復旧の仕組みが存在しない場合、クラスタは失敗します。\n",
        "\n",
        "Keras を`tf.distribute.Strategy`で使用する場合、ワーカーが停止した場合や不安定である際に、フォールトトラレンスが機能するというメリットがあります。この機能は、指定された分散ファイルシステムにトレーニングの状態を保存するため、失敗、または、中断されたインスタンスを再開する場合に、トレーニングの状態が復旧されます。\n",
        "\n",
        "When a worker becomes unavailable, other workers will fail (possibly after a timeout). In such cases, the unavailable worker needs to be restarted, as well as other workers that have failed.\n",
        "\n",
        "注意: 以前は、`ModelCheckpoint` コールバックには、マルチワーカートレーニングに失敗したジョブを再開したときに、トレーニングの状態を復元するメカニズムがありました。新たに導入される [`BackupAndRestore`](#scrollTo=kmH8uCUhfn4w) コールバックでは、一貫したエクスペリエンスを提供するために、シングルワーカートレーニングにもこのサポートが追加され、既存の `ModelCheckpoint` コールバックからフォールトトレランス機能が削除されました。今後、この動作に依存するアプリケーションは、新しい `BackupAndRestore` コールバックに移行する必要があります。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvHPjGlyyFt6"
      },
      "source": [
        "#### ModelCheckpoint コールバック\n",
        "\n",
        "`ModelCheckpoint`コールバックは、フォールトトレランス機能を提供しなくなりました。代わりに [`BackupAndRestore`](#scrollTo=kmH8uCUhfn4w)コールバックを使用してください。\n",
        "\n",
        "`ModelCheckpoint`コールバックを使用してチェックポイントを保存することは、依然として可能です。ただし、これを使用する場合、トレーニングが中断されるか、問題なく終了した場合、チェックポイントからトレーニングを続行するには、手動でモデルを読み込まなければなりません。\n",
        "\n",
        "オプションで、ユーザーは`ModelCheckpoint`コールバックの外部でモデル/重みを保存および復元することを選択できます。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUNV5Utc1d0s"
      },
      "source": [
        "### モデルの保存と読み込み\n",
        "\n",
        "`model.save` または `tf.saved_model.save` を使用してモデルを保存するには、ワーカーごとに異なる保存先が必要となります。\n",
        "\n",
        "- チーフワーカー以外のワーカーの場合、モデルを一時ディレクトリに保存する必要があります。\n",
        "- チーフワーカーの場合、指定されたモデルのディレクトリに保存する必要があります。\n",
        "\n",
        "ワーカーの一時ディレクトリは、複数のワーカーが同じ場所に書き込もうとしてエラーが発生しないように、一意のディレクトリである必要があります。\n",
        "\n",
        "すべてのディレクトリに保存されるモデルは同一のものであり、復元やサービングで参照されるのは一般的に、チーフワーカーが保存したモデルです。\n",
        "\n",
        "トレーニングが完了したらワーカーが作成した一時ディレクトリを削除するクリーンアップロジックを用意しておく必要があります。\n",
        "\n",
        "チーフとワーカーを同時に保存する必要があるのは、チェックポイント中に変数を集計する可能性があり、チーフとワーカーの両方が allreduce 通信プロトコルに参加する必要があるためです。しかしながら、チーフとワーカーを同じモデルディレクトリに保存すると競合が発生し、エラーとなります。\n",
        "\n",
        "`MultiWorkerMirroredStrategy` を使用すると、プログラムはワーカーごとに実行され、現在のワーカーがチーフであるかを知る際には、`task_type` と `task_id` の属性があるクラスタレゾルバオブジェクトが利用されます。\n",
        "\n",
        "- `task_type` から、現在のジョブが何であるか（`'worker'` など）を知ることができます。\n",
        "- `task_id` から、ワーカーの ID を得られます。\n",
        "- `task_id == 0` のワーカーはチーフワーカーです。\n",
        "\n",
        "以下のコードスニペットの `write_filepath` 関数は、書き込みのファイルパスを指定します。このパスはワーカーの `task_id` によって異なります。\n",
        "\n",
        "- チーフワーカー（`task_id == 0`）の場合は、元のファイルパスに書き込みます。\n",
        "- それ以外のワーカーの場合は、書き込むディレクトリパスに `task_id` を指定して、一時ディレクトリ（`temp_dir`）を作成します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XQfGkmg-pfCY"
      },
      "outputs": [],
      "source": [
        "model_path = '/tmp/keras-model'\n",
        "\n",
        "def _is_chief(task_type, task_id):\n",
        "  # Note: there are two possible `TF_CONFIG` configuration.\n",
        "  #   1) In addition to `worker` tasks, a `chief` task type is use;\n",
        "  #      in this case, this function should be modified to\n",
        "  #      `return task_type == 'chief'`.\n",
        "  #   2) Only `worker` task type is used; in this case, worker 0 is\n",
        "  #      regarded as the chief. The implementation demonstrated here\n",
        "  #      is for this case.\n",
        "  # For the purpose of this Colab section, the `task_type is None` case\n",
        "  # is added because it is effectively run with only a single worker.\n",
        "  return (task_type == 'worker' and task_id == 0) or task_type is None\n",
        "\n",
        "def _get_temp_dir(dirpath, task_id):\n",
        "  base_dirpath = 'workertemp_' + str(task_id)\n",
        "  temp_dir = os.path.join(dirpath, base_dirpath)\n",
        "  tf.io.gfile.makedirs(temp_dir)\n",
        "  return temp_dir\n",
        "\n",
        "def write_filepath(filepath, task_type, task_id):\n",
        "  dirpath = os.path.dirname(filepath)\n",
        "  base = os.path.basename(filepath)\n",
        "  if not _is_chief(task_type, task_id):\n",
        "    dirpath = _get_temp_dir(dirpath, task_id)\n",
        "  return os.path.join(dirpath, base)\n",
        "\n",
        "task_type, task_id = (strategy.cluster_resolver.task_type,\n",
        "                      strategy.cluster_resolver.task_id)\n",
        "write_model_path = write_filepath(model_path, task_type, task_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hs0_agYR_qKm"
      },
      "source": [
        "これで、保存の準備ができました。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J-yA3BYG_vTs"
      },
      "outputs": [],
      "source": [
        "multi_worker_model.save(write_model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LXUVVl9_v5x"
      },
      "source": [
        "前述したように、後でモデルを読み込む場合、チーフが保存した場所にあるモデルのみを使用するべきなので、非チーフワーカーが保存した一時的なモデルは削除します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aJTyu-97ABpY"
      },
      "outputs": [],
      "source": [
        "if not _is_chief(task_type, task_id):\n",
        "  tf.io.gfile.rmtree(os.path.dirname(write_model_path))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nr-2PKlHAPBT"
      },
      "source": [
        "読み込む際に便利な `tf.keras.models.load_model` API を使用して、以降の作業に続けることにします。\n",
        "\n",
        "ここでは、単一ワーカーのみを使用してトレーニングを読み込んで続けると仮定します。この場合、別の `strategy.scope()` 内で `tf.keras.models.load_model` を呼び出しません（前に定義したように、`strategy = tf.distribute.MultiWorkerMirroredStrategy()` です）。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iUZna-JKAOrX"
      },
      "outputs": [],
      "source": [
        "loaded_model = tf.keras.models.load_model(model_path)\n",
        "\n",
        "# Now that the model is restored, and can continue with the training.\n",
        "loaded_model.fit(single_worker_dataset, epochs=2, steps_per_epoch=20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJ1fmxmTpocS"
      },
      "source": [
        "### チェックポイントの保存と復元\n",
        "\n",
        "一方、チェックポイントを作成すれば、モデルの重みを保存し、モデル全体を保存せずともそれらを復元することが可能です。\n",
        "\n",
        "ここでは、モデルをトラッキングする `tf.train.Checkpoint` を 1 つ作成します。これは `tf.train.CheckpointManager` によって管理されるため、最新のチェックポイントのみが保存されます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_1-RYaB5xnNH"
      },
      "outputs": [],
      "source": [
        "checkpoint_dir = '/tmp/ckpt'\n",
        "\n",
        "checkpoint = tf.train.Checkpoint(model=multi_worker_model)\n",
        "write_checkpoint_dir = write_filepath(checkpoint_dir, task_type, task_id)\n",
        "checkpoint_manager = tf.train.CheckpointManager(\n",
        "    checkpoint, directory=write_checkpoint_dir, max_to_keep=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oBpPCRsW1MF"
      },
      "source": [
        "`CheckpointManager` の準備ができたら、チェックポイントを保存し、チーフ以外のワーカーが保存したチェックポイントを削除します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l1ZXG_GbWzLp"
      },
      "outputs": [],
      "source": [
        "checkpoint_manager.save()\n",
        "if not _is_chief(task_type, task_id):\n",
        "  tf.io.gfile.rmtree(write_checkpoint_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RO7cbN40XD5v"
      },
      "source": [
        "これで、復元する必要があれば、便利な`tf.train.latest_checkpoint`関数を使用して、保存された最新のチェックポイントを見つけることができるようになりました。チェックポイントが復元されると、トレーニングを続行することができます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NJW7vtknXFEH"
      },
      "outputs": [],
      "source": [
        "latest_checkpoint = tf.train.latest_checkpoint(checkpoint_dir)\n",
        "checkpoint.restore(latest_checkpoint)\n",
        "multi_worker_model.fit(multi_worker_dataset, epochs=2, steps_per_epoch=20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmH8uCUhfn4w"
      },
      "source": [
        "#### BackupAndRestore コールバック\n",
        "\n",
        "`tf.keras.callbacks.BackupAndRestore` コールバックはフォールトトレランス機能を提供します。この機能はモデルと現在のエポック番号を一時チェックポイントファイルを`backup_dir`引数でバックアップし、`BackupAndRestore`でコールバックします。これは、各エポックの終了時に実行されます。\n",
        "\n",
        "ジョブが中断されて再開されると、コールバックは最新のチェックポイントを復元するため、中断されたエポックの始めからトレーニングを続行することができます。未完了のエポックで中断前に実行された部分のトレーニングは破棄されるため、モデルの最終状態に影響することはありません。\n",
        "\n",
        "これを使用するには、`Model.fit` 呼び出し時に、 `Model.fit` のインスタンスを指定します。\n",
        "\n",
        "MultiWorkerMirroredStrategy では、ワーカーが中断されると、そのワーカーが再開するまでクラスタ全体が一時停止されます。そのワーカーが再開するとほかのワーカーも再開します。中断したワーカーがクラスタに参加し直すと、各ワーカーは以前に保存されたチェックポイントファイルを読み取って以前の状態を復元するため、クラスタの同期状態が戻ります。そして、トレーニングが続行されます。\n",
        "\n",
        "`BackupAndRestore` コールバックは、`CheckpointManager` を使用して、トレーニングの状態を保存・復元します。これには、既存のチェックポイントを最新のものと併せて追跡するチェックポイントと呼ばれるファイルが生成されます。このため、ほかのチェックポイントの保存に  `backup_dir` を再利用しないようにし、名前の競合を回避する必要があります。\n",
        "\n",
        "現在、`BackupAndRestore` コールバックは、ストラテジーなしのシングルワーカートレーニング（`MirroredStrategy`）と `MultiWorkerMirroredStrategy` によるマルチワーカートレーニングをサポートしています。\n",
        "\n",
        "以下に、マルチワーカートレーニングとシングルワーカートレーニングの 2 つの例を示します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CYdzZi4Qs1jz"
      },
      "outputs": [],
      "source": [
        "# Multi-worker training with `MultiWorkerMirroredStrategy`\n",
        "# and the `BackupAndRestore` callback.\n",
        "\n",
        "callbacks = [tf.keras.callbacks.BackupAndRestore(backup_dir='/tmp/backup')]\n",
        "with strategy.scope():\n",
        "  multi_worker_model = mnist_setup.build_and_compile_cnn_model()\n",
        "multi_worker_model.fit(multi_worker_dataset,\n",
        "                       epochs=3,\n",
        "                       steps_per_epoch=70,\n",
        "                       callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIV5_3ebzXmB"
      },
      "source": [
        "`BackupAndRestore` に指定した `backup_dir` のディレクトリを検査すると、一時的に生成されたチェックポイントファイルがいくつかあることに気づくでしょう。これらのファイルは、以前に失われたインスタンスの復元に必要なもので、トレーニングが正常に終了した時点で、`Model.fit` の最後にライブラリによって削除されます。\n",
        "\n",
        "注意: 現在のところ、`BackupAndRestore` コールバックは Eager モードのみをサポートしています。Graph モードでは、前述した[保存/復元モデル](#model_saving_and_loading)を使用し、`Model.fit` に `initial_epoch` を指定することで実施することを検討してください。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ega2hdOQEmy_"
      },
      "source": [
        "## 追加リソース\n",
        "\n",
        "1. [TensorFlow での分散型トレーニング](https://www.tensorflow.org/guide/distributed_training)ガイドでは、利用可能な分散ストラテジーの概要が説明されています。\n",
        "2. [Keras によるカスタムトレーニングループと MultiWorkerMirroredStrategy](multi_worker_with_ctl.ipynb) のチュートリアルでは、Keras とカスタムトレーニングループで`MultiWorkerMirroredStrategy` を使用する方法が説明されています。\n",
        "3. [公式モデル](https://github.com/tensorflow/models/tree/master/official)をご覧ください。この多くは、複数の分散ストラテジーを実行するように構成できます。\n",
        "4. [tf.function を使ったパフォーマンスの改善](../../guide/function.ipynb)ガイドでは、その他のストラテジーや、TensorFlow モデルのパフォーマンスを最適化するために使用できる [TensorFlow Profiler](../../guide/profiler.md) といったツールに関する情報が提供されています。"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "multi_worker_with_keras.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
