{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tce3stUlHN0L"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tuOe1ymfHZPu"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFdPvlXBOdUN"
      },
      "source": [
        "# ML Metadata による ML エンジニアリングの改善\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfBg1C5NB3X0"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td><a target=\"_blank\" href=\"https://www.tensorflow.org/tfx/tutorials/mlmd/mlmd_tutorial\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">TensorFlow.org で表示</a></td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/ja/tfx/tutorials/mlmd/mlmd_tutorial.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Google Colab で実行</a>\n",
        "</td>\n",
        "  <td><a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/ja/tfx/tutorials/mlmd/mlmd_tutorial.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">GitHubでソースを表示</a></td>\n",
        "<td><a target=\"_blank\" href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/ja/tfx/tutorials/mlmd/mlmd_tutorial.ipynb\"><img width=\"32px\" src=\"https://www.tensorflow.org/images/download_logo_32px.png\">ノートブックをダウンロード</a></td>\n",
        "  \n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHxb-dlhMIzW"
      },
      "source": [
        "ペンギンを分類する本番 ML パイプラインをセットアップしたと仮定します。トレーニングデータを取り込んでモデルのトレーニングと評価を行い、本番にプッシュするパイプラインです。\n",
        "\n",
        "ところが後で、様々な種類のペンギンを含むより大きなデータセットでこのモデルを使用してみると、モデルが期待したように動作せず、種を誤って分類し始めてしまいました。\n",
        "\n",
        "この時点で、以下について知ろうとするでしょう。\n",
        "\n",
        "- 唯一利用できるアーティファクトが本番のモデルである場合、そのモデルを最も効率的にデバッグする方法は？\n",
        "- モデルのトレーニングには使用されたデータセットは？\n",
        "- 不具合のあるモデルを生じたトレーニングランは？\n",
        "- モデルの評価結果の場所は？\n",
        "- デバッグを始める場所は？\n",
        "\n",
        "[ML Metadata（MLMD）](https://github.com/google/ml-metadata)は、ML モデルに関連付けられたメタデータを使用して、上記やそれ以外の疑問に対する答えを見つけられるようにするライブラリです。分かりやすく例えると、このメタデータは、ソフトウェア開発におけるロギングに相当すると考えられるでしょう。MLMD では、ML パイプラインの様々なコンポーネントに関連付けられたアーティファクトとリネージを確実に追跡することができます。\n",
        "\n",
        "このチュートリアルでは、TFX パイプラインをセットアップして、ペンギンを、体重、嘴峰（しほう）長、嘴峰高、フリッパーの長さに基づいて 3 つの種に分類するモデルを作成します。次に、MLMD を使用して、パイプラインコンポーネントのリネージを追跡します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rGF8hLibz6p"
      },
      "source": [
        "## Colab における TFX パイプライン\n",
        "\n",
        "Colab は、本番環境とは大きく異なる軽量の開発環境です。本番では、データ取り込み、変換、モデルトレーニング、ラン履歴など、複数の分散システムをまたぐ様々なパイプラインコンポーネントが伴うことがあります。このチュートリアルでは、オーケストレーションとメタデータストレージに大きな違いがあり、すべて Colab 内でローカルに処理されることに注意しておく必要があります。Colab での TFX についての詳細は、[こちら](https://www.tensorflow.org/tfx/tutorials/tfx/components_keras#background)をご覧ください。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUXex9ctTuDB"
      },
      "source": [
        "## MNIST モデルをビルドする\n",
        "\n",
        "まず、必要なパッケージをインストールしてインポートし、パスを設定して、データをダウンロードします。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lko0xn8JxI6F"
      },
      "source": [
        "### Pip のアップグレード\n",
        "\n",
        "ローカルで実行する場合にシステム Pip をアップグレードしないようにするには、Colab で実行していることを確認してください。もちろん、ローカルシステムは個別にアップグレードできます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7pXW--mlxQhY"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  import colab\n",
        "  !pip install --upgrade pip\n",
        "except:\n",
        "  pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQV-Cget1S8t"
      },
      "source": [
        "### TFX をインストールしてインポートする"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "82jOhrcA36YA"
      },
      "outputs": [],
      "source": [
        " !pip install -q tfx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5p3LRwkZRbj"
      },
      "source": [
        "### パッケージをインポートする"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1oayJjlQZxS"
      },
      "source": [
        "#### ランタイムを再起動しましたか？\n",
        "\n",
        "Google Colab を使用している場合は、上記のセルを初めて実行した後に、「ランタイムを再起動」ボタンをクリックするか、「ランタイム」&gt;「ランタイムの再起動...」メニューを使って、ランタイムを再起動する必要があります。これは、Colab がパッケージを読み込むために必要な作業です。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zknUh9LrZZf2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tempfile\n",
        "import urllib\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow_model_analysis as tfma\n",
        "from tfx.orchestration.experimental.interactive.interactive_context import InteractiveContext"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OD2cRhwM3ez2"
      },
      "source": [
        "TFX と MLMD のバージョンを確認します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z1ut9Wy_Qf1Q"
      },
      "outputs": [],
      "source": [
        "from tfx import v1 as tfx\n",
        "print('TFX version: {}'.format(tfx.__version__))\n",
        "import ml_metadata as mlmd\n",
        "print('MLMD version: {}'.format(mlmd.__version__))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhNtHfuxCGVy"
      },
      "source": [
        "## データセットをダウンロードする\n",
        "\n",
        "この Colab では、[Github](https://github.com/allisonhorst/palmerpenguins) にある [Palmer Penguins データセット](https://allisonhorst.github.io/palmerpenguins/articles/intro.html)を使用します。このデータセットは、不完全なレコードを除外し、`island` と `sex` 列を削除し、ラベルを `int32` に変換して処理されています。データセットには、ペンギンの体重、嘴峰長、嘴峰高、フリッパーの長さの 334 件のレコードが含まれています。このデータを使用して、ペンギンを 3 つの種のいずれかに分類します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B_NibNnjzGHu"
      },
      "outputs": [],
      "source": [
        "DATA_PATH = 'https://raw.githubusercontent.com/tensorflow/tfx/master/tfx/examples/penguin/data/labelled/penguins_processed.csv'\n",
        "_data_root = tempfile.mkdtemp(prefix='tfx-data')\n",
        "_data_filepath = os.path.join(_data_root, \"penguins_processed.csv\")\n",
        "urllib.request.urlretrieve(DATA_PATH, _data_filepath)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NXg2bGA19HJ"
      },
      "source": [
        "## InteractiveContext を作成する\n",
        "\n",
        "TFX コンポーネントをこのノートブックで対話的に実行するには、`InteractiveContext` を作成します。`InteractiveContext` は、エフェメラル MLMD データベースインスタンスのある一時ディレクトリを使用します。`InteractiveContext` への呼び出しは、Colab 環境外では no-ops であることに注意してください。\n",
        "\n",
        "一般に、類似するパイプラインランを 1 つの `Context` にグループ化することが推奨されています。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bytrDFKh40mi"
      },
      "outputs": [],
      "source": [
        "interactive_context = InteractiveContext()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-58fa9S6Nao"
      },
      "source": [
        "## TFX パイプラインを構築する\n",
        "\n",
        "TFX パイプラインは、ML ワークフローの様々な側面を実行する複数のコンポーネントで構成されます。このノートブックでは、 `ExampleGen`、`StatisticsGen`、`SchemaGen`、および `Trainer` コンポーネントを作成して実行し、`Evaluator` と `Pusher` コンポーネントによって、トレーニングされたモデルの評価とプッシュを行います。\n",
        "\n",
        "TFX パイプラインのコンポーネントについての詳細は、[コンポーネントのチュートリアル](https://www.tensorflow.org/tfx/tutorials/tfx/components_keras)をご覧ください。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urh3FTb81yyM"
      },
      "source": [
        "注意: 個別のコンポーネントをセットアップして TFX パイプラインを構築するには、大量のボイラープレートコードが伴います。このチュートリアルの目的においては、パイプラインセットアップのすべてのコードを完全に理解しなくても構いません。 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnnq7Gf8CHZJ"
      },
      "source": [
        "### ExampleGen コンポーネントをインスタンス化して実行する"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H9zaBZh3C_9x"
      },
      "outputs": [],
      "source": [
        "example_gen = tfx.components.CsvExampleGen(input_base=_data_root)\n",
        "interactive_context.run(example_gen)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqxye_p1DLmf"
      },
      "source": [
        "### StatisticsGen コンポーネントをインスタンス化して実行する"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s67sHU_vDRds"
      },
      "outputs": [],
      "source": [
        "statistics_gen = tfx.components.StatisticsGen(\n",
        "    examples=example_gen.outputs['examples'])\n",
        "interactive_context.run(statistics_gen)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xib9oRb_ExjJ"
      },
      "source": [
        "### SchemaGen コンポーネントをインスタンス化して実行する"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "csmD4CSUE3JT"
      },
      "outputs": [],
      "source": [
        "infer_schema = tfx.components.SchemaGen(\n",
        "    statistics=statistics_gen.outputs['statistics'], infer_feature_shape=True)\n",
        "interactive_context.run(infer_schema)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pYNlw7BHUjP"
      },
      "source": [
        "### Trainer コンポーネントをインスタンス化して実行する\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MTxf8xs_kKfG"
      },
      "outputs": [],
      "source": [
        "# Define the module file for the Trainer component\n",
        "trainer_module_file = 'penguin_trainer.py'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f3nLHEmUkRUw"
      },
      "outputs": [],
      "source": [
        "%%writefile {trainer_module_file}\n",
        "\n",
        "# Define the training algorithm for the Trainer module file\n",
        "import os\n",
        "from typing import List, Text\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from tfx import v1 as tfx\n",
        "from tfx_bsl.public import tfxio\n",
        "\n",
        "from tensorflow_metadata.proto.v0 import schema_pb2\n",
        "\n",
        "# Features used for classification - culmen length and depth, flipper length,\n",
        "# body mass, and species.\n",
        "\n",
        "_LABEL_KEY = 'species'\n",
        "\n",
        "_FEATURE_KEYS = [\n",
        "    'culmen_length_mm', 'culmen_depth_mm', 'flipper_length_mm', 'body_mass_g'\n",
        "]\n",
        "\n",
        "\n",
        "def _input_fn(file_pattern: List[Text],\n",
        "              data_accessor: tfx.components.DataAccessor,\n",
        "              schema: schema_pb2.Schema, batch_size: int) -> tf.data.Dataset:\n",
        "  return data_accessor.tf_dataset_factory(\n",
        "      file_pattern,\n",
        "      tfxio.TensorFlowDatasetOptions(\n",
        "          batch_size=batch_size, label_key=_LABEL_KEY), schema).repeat()\n",
        "\n",
        "\n",
        "def _build_keras_model():\n",
        "  inputs = [keras.layers.Input(shape=(1,), name=f) for f in _FEATURE_KEYS]\n",
        "  d = keras.layers.concatenate(inputs)\n",
        "  d = keras.layers.Dense(8, activation='relu')(d)\n",
        "  d = keras.layers.Dense(8, activation='relu')(d)\n",
        "  outputs = keras.layers.Dense(3)(d)\n",
        "  model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "  model.compile(\n",
        "      optimizer=keras.optimizers.Adam(1e-2),\n",
        "      loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "      metrics=[keras.metrics.SparseCategoricalAccuracy()])\n",
        "  return model\n",
        "\n",
        "\n",
        "def run_fn(fn_args: tfx.components.FnArgs):\n",
        "  schema = schema_pb2.Schema()\n",
        "  tfx.utils.parse_pbtxt_file(fn_args.schema_path, schema)\n",
        "  train_dataset = _input_fn(\n",
        "      fn_args.train_files, fn_args.data_accessor, schema, batch_size=10)\n",
        "  eval_dataset = _input_fn(\n",
        "      fn_args.eval_files, fn_args.data_accessor, schema, batch_size=10)\n",
        "  model = _build_keras_model()\n",
        "  model.fit(\n",
        "      train_dataset,\n",
        "      epochs=int(fn_args.train_steps / 20),\n",
        "      steps_per_epoch=20,\n",
        "      validation_data=eval_dataset,\n",
        "      validation_steps=fn_args.eval_steps)\n",
        "  model.save(fn_args.serving_model_dir, save_format='tf')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qcmSNiqq5QaV"
      },
      "source": [
        "`Trainer` コンポーネントを実行します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4AzsMk7oflMg"
      },
      "outputs": [],
      "source": [
        "trainer = tfx.components.Trainer(\n",
        "    module_file=os.path.abspath(trainer_module_file),\n",
        "    examples=example_gen.outputs['examples'],\n",
        "    schema=infer_schema.outputs['schema'],\n",
        "    train_args=tfx.proto.TrainArgs(num_steps=100),\n",
        "    eval_args=tfx.proto.EvalArgs(num_steps=50))\n",
        "interactive_context.run(trainer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdCq5c0f5MyA"
      },
      "source": [
        "### モデルを評価してプッシュする\n",
        "\n",
        "`Evaluator` コンポーネントを使用してモデルの評価と「ブレッシング」を行い、`Pusher` コンポーネントを使用してモデルをサービングディレクトリにプッシュします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NDx-fTUb6RUU"
      },
      "outputs": [],
      "source": [
        "_serving_model_dir = os.path.join(tempfile.mkdtemp(),\n",
        "                                  'serving_model/penguins_classification')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PpS4-wCf6eLR"
      },
      "outputs": [],
      "source": [
        "eval_config = tfma.EvalConfig(\n",
        "    model_specs=[\n",
        "        tfma.ModelSpec(label_key='species', signature_name='serving_default')\n",
        "    ],\n",
        "    metrics_specs=[\n",
        "        tfma.MetricsSpec(metrics=[\n",
        "            tfma.MetricConfig(\n",
        "                class_name='SparseCategoricalAccuracy',\n",
        "                threshold=tfma.MetricThreshold(\n",
        "                    value_threshold=tfma.GenericValueThreshold(\n",
        "                        lower_bound={'value': 0.6})))\n",
        "        ])\n",
        "    ],\n",
        "    slicing_specs=[tfma.SlicingSpec()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kFuH1YTh8vSf"
      },
      "outputs": [],
      "source": [
        "evaluator = tfx.components.Evaluator(\n",
        "    examples=example_gen.outputs['examples'],\n",
        "    model=trainer.outputs['model'],\n",
        "    schema=infer_schema.outputs['schema'],\n",
        "    eval_config=eval_config)\n",
        "interactive_context.run(evaluator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NCV9gcCQ966W"
      },
      "outputs": [],
      "source": [
        "pusher = tfx.components.Pusher(\n",
        "    model=trainer.outputs['model'],\n",
        "    model_blessing=evaluator.outputs['blessing'],\n",
        "    push_destination=tfx.proto.PushDestination(\n",
        "        filesystem=tfx.proto.PushDestination.Filesystem(\n",
        "            base_directory=_serving_model_dir)))\n",
        "interactive_context.run(pusher)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9K7RzdBzkru7"
      },
      "source": [
        "TFX パイプラインを実行すると、MLMD データベースにデータが入力されます。次のセクションでは、MLMD API によってこのデータベースをクエリし、メタデータ情報を取得します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GRCGQu7RguC"
      },
      "source": [
        "## MLMD データベースをクエリする\n",
        "\n",
        "MLMD データベースは、3 種類のメタデータを格納します。\n",
        "\n",
        "- パイプラインコンポーネントに関連付けられたパイプラインとリネージの情報に関するメタデータ\n",
        "- パイプラインランで生成されたアーティファクトに関するメタデータ\n",
        "- パイプラインの実行に関するメタデータ\n",
        "\n",
        "典型的な本番環境パイプラインは、新しいデータが届くたびに複数のモデルを配信します。配信されたモデルにエラーのある結果が含まれる場合、MLMD データベースをクエリし、不具合のあるモデルを分離することができます。その上で、それらのモデルに対応するパイプラインコンポーネントのリネージを追跡し、モデルをデバッグすることができます。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0xVYqAkJybK"
      },
      "source": [
        "前に定義した `InteractiveContext` を使用して、MLMD データベースをクエリするメタデータ（MD）ストアをセットアップします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P1p38etAv0kC"
      },
      "outputs": [],
      "source": [
        "connection_config = interactive_context.metadata_connection_config\n",
        "store = mlmd.MetadataStore(connection_config)\n",
        "\n",
        "# All TFX artifacts are stored in the base directory\n",
        "base_dir = connection_config.sqlite.filename_uri.split('metadata.sqlite')[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uq-1ep4suvuZ"
      },
      "source": [
        "MD ストアからデータを表示するためのヘルパー関数を作成します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q1ib8yStu6CW"
      },
      "outputs": [],
      "source": [
        "def display_types(types):\n",
        "  # Helper function to render dataframes for the artifact and execution types\n",
        "  table = {'id': [], 'name': []}\n",
        "  for a_type in types:\n",
        "    table['id'].append(a_type.id)\n",
        "    table['name'].append(a_type.name)\n",
        "  return pd.DataFrame(data=table)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HmqzYZcV3UG5"
      },
      "outputs": [],
      "source": [
        "def display_artifacts(store, artifacts):\n",
        "  # Helper function to render dataframes for the input artifacts\n",
        "  table = {'artifact id': [], 'type': [], 'uri': []}\n",
        "  for a in artifacts:\n",
        "    table['artifact id'].append(a.id)\n",
        "    artifact_type = store.get_artifact_types_by_id([a.type_id])[0]\n",
        "    table['type'].append(artifact_type.name)\n",
        "    table['uri'].append(a.uri.replace(base_dir, './'))\n",
        "  return pd.DataFrame(data=table)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iBdGCZ0CMJDO"
      },
      "outputs": [],
      "source": [
        "def display_properties(store, node):\n",
        "  # Helper function to render dataframes for artifact and execution properties\n",
        "  table = {'property': [], 'value': []}\n",
        "  for k, v in node.properties.items():\n",
        "    table['property'].append(k)\n",
        "    table['value'].append(\n",
        "        v.string_value if v.HasField('string_value') else v.int_value)\n",
        "  for k, v in node.custom_properties.items():\n",
        "    table['property'].append(k)\n",
        "    table['value'].append(\n",
        "        v.string_value if v.HasField('string_value') else v.int_value)\n",
        "  return pd.DataFrame(data=table)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1B-jRNH0M0k4"
      },
      "source": [
        "まず、MD ストアに対し、格納されたすべての `ArtifactTypes` のリストをクエリします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6zXSQL8s5dyL"
      },
      "outputs": [],
      "source": [
        "display_types(store.get_artifact_types())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "quOsBgtM3r7S"
      },
      "source": [
        "次に、すべての `PushedModel` アーティファクトをクエリします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bUv_EI-bEMMu"
      },
      "outputs": [],
      "source": [
        "pushed_models = store.get_artifacts_by_type(\"PushedModel\")\n",
        "display_artifacts(store, pushed_models)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UecjkVOqJCBE"
      },
      "source": [
        "MD ストアに対し、最後にプッシュされたモデルをクエリします。このチュートリアルには、プッシュされたモデルが 1 つしかありません。 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N8tPvRtcPTrU"
      },
      "outputs": [],
      "source": [
        "pushed_model = pushed_models[-1]\n",
        "display_properties(store, pushed_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5Mz4vfP6wHO"
      },
      "source": [
        "プッシュされたモデルをデバッグする際の最初のステップは、どのモデルがプッシュされており、そのモデルをトレーニングする上でどのトレーニングデータが使用されたかを確認することです。\n",
        "\n",
        "MLMD には、来歴グラフを走査するトラバーサル API があるため、それを使用して、モデルの来歴を分析することができます。 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BLfydQVxOwf3"
      },
      "outputs": [],
      "source": [
        "def get_one_hop_parent_artifacts(store, artifacts):\n",
        "  # Get a list of artifacts within a 1-hop of the artifacts of interest\n",
        "  artifact_ids = [artifact.id for artifact in artifacts]\n",
        "  executions_ids = set(\n",
        "      event.execution_id\n",
        "      for event in store.get_events_by_artifact_ids(artifact_ids)\n",
        "      if event.type == mlmd.proto.Event.OUTPUT)\n",
        "  artifacts_ids = set(\n",
        "      event.artifact_id\n",
        "      for event in store.get_events_by_execution_ids(executions_ids)\n",
        "      if event.type == mlmd.proto.Event.INPUT)\n",
        "  return [artifact for artifact in store.get_artifacts_by_id(artifacts_ids)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3G0e0WIE9e9w"
      },
      "source": [
        "親アーティファクトに対し、プッシュされたモデルをクエリします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pOEFxucJQ1i6"
      },
      "outputs": [],
      "source": [
        "parent_artifacts = get_one_hop_parent_artifacts(store, [pushed_model])\n",
        "display_artifacts(store, parent_artifacts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJror5mf-W0M"
      },
      "source": [
        "プロパティに対し、モデルをクエリします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OSCb0bg6Qmj4"
      },
      "outputs": [],
      "source": [
        "exported_model = parent_artifacts[0]\n",
        "display_properties(store, exported_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phz1hfzc_UcK"
      },
      "source": [
        "上流アーティファクトに対し、モデルをクエリします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nx_-IVhjRGA4"
      },
      "outputs": [],
      "source": [
        "model_parents = get_one_hop_parent_artifacts(store, [exported_model])\n",
        "display_artifacts(store, model_parents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00jqfk6o_niu"
      },
      "source": [
        "モデルのトレーニングに使用されたトレーニングデータを取得します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2nMECsKvROEX"
      },
      "outputs": [],
      "source": [
        "used_data = model_parents[0]\n",
        "display_properties(store, used_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgTMTaew_3Fe"
      },
      "source": [
        "モデルのトレーニングに使用されたトレーニングデータを取得したので、もう一度データベースをクエリし、トレーニングステップ（実行）を見つけます。MD ストアに対し、登録された実行タイプのリストをクエリします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8cBKQsScaD9a"
      },
      "outputs": [],
      "source": [
        "display_types(store.get_execution_types())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxcue6SggQ_b"
      },
      "source": [
        "トレーニングステップは `tfx.components.trainer.component.Trainer` という `ExecutionType` です。MD ストアを走査して、プッシュされたモデルに対応する trainer ランを取得します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ned8BxHzaunk"
      },
      "outputs": [],
      "source": [
        "def find_producer_execution(store, artifact):\n",
        "  executions_ids = set(\n",
        "      event.execution_id\n",
        "      for event in store.get_events_by_artifact_ids([artifact.id])\n",
        "      if event.type == mlmd.proto.Event.OUTPUT)\n",
        "  return store.get_executions_by_id(executions_ids)[0]\n",
        "\n",
        "trainer = find_producer_execution(store, exported_model)\n",
        "display_properties(store, trainer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYzlTckHClxC"
      },
      "source": [
        "## 目次\n",
        "\n",
        "このチュートリアルでは、MLMD を使用して、TFX パイプラインコンポーネントのリネージを追跡し、問題を解決する方法について学習しました。\n",
        "\n",
        "MLMD の使用方法についての詳細は、以下の追加リソースをご覧ください。\n",
        "\n",
        "- [MLMD API ドキュメント](https://www.tensorflow.org/tfx/ml_metadata/api_docs/python/mlmd)\n",
        "- [MLMD ガイド](https://www.tensorflow.org/tfx/guide/mlmd)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Tce3stUlHN0L"
      ],
      "name": "mlmd_tutorial.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
