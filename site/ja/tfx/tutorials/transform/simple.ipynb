{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tghWegsjhpkt"
      },
      "source": [
        "##### Copyright 2021 The TensorFlow Authors.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "rSGJWC5biBiG"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-Iyf5gv5oBq"
      },
      "source": [
        "# TensorFlow Transform を使用したデータの前処理\n",
        "\n",
        "***TensorFlow Extended (TFX) の特徴エンジニアリングコンポーネント***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5ST8dI25wbA"
      },
      "source": [
        "Note: We recommend running this tutorial in a Colab notebook, with no setup required!  Just click \"Run in Google Colab\".\n",
        "\n",
        "<div class=\"devsite-table-wrapper\"><table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "<td><a target=\"_blank\" href=\"https://www.tensorflow.org/tfx/tutorials/transform/simple\">\n",
        "<img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a></td>\n",
        "<td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/tfx/blob/master/docs/tutorials/transform/simple.ipynb\">\n",
        "<img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Run in Google Colab</a></td>\n",
        "<td><a target=\"_blank\" href=\"https://github.com/tensorflow/tfx/blob/master/docs/tutorials/transform/simple.ipynb\">\n",
        "<img width=32px src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">View source on GitHub</a></td>\n",
        "<td><a target=\"_blank\" href=\"https://storage.googleapis.com/tensorflow_docs/tfx/docs/tutorials/transform/simple.ipynb\">\n",
        "<img width=32px src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Download notebook</a></td>\n",
        "</table></div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPt5BHTwy_0F"
      },
      "source": [
        "This example colab notebook provides a very simple example of how <a target=\"_blank\" href=\"https://www.tensorflow.org/tfx/transform/get_started/\">TensorFlow Transform (<code>tf.Transform</code>)</a> can be used to preprocess data using exactly the same code for both training a model and serving inferences in production.\n",
        "\n",
        "TensorFlow Transform は、トレーニングデータセットのフルパスを必要とする特徴の作成など、TensorFlow の入力データを前処理するためのライブラリです。たとえば、TensorFlow Transform を使用すると、次のことができます。\n",
        "\n",
        "- 平均と標準偏差を使用して入力値を正規化する\n",
        "- すべての入力値に対して語彙を生成することにより、文字列を整数に変換する\n",
        "- 観測されたデータ分布に基づいて、浮動小数点数をバケットに割り当てることにより、浮動小数点数を整数に変換する\n",
        "\n",
        "TensorFlow には、単一のサンプルまたはサンプルのバッチに対する操作のサポートが組み込まれています。`tf.Transform`は、これらの機能を拡張して、トレーニングデータセット全体のフルパスをサポートします。\n",
        "\n",
        "The output of `tf.Transform` is exported as a TensorFlow graph which you can use for both training and serving. Using the same graph for both training and serving can prevent skew, since the same transformations are applied in both stages."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6c8lD3uQm8m5"
      },
      "source": [
        "### Upgrade Pip\n",
        "\n",
        "To avoid upgrading Pip in a system when running locally, check to make sure that we're running in Colab.  Local systems can of course be upgraded separately."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EmiQXNLZm8z-"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  import colab\n",
        "  !pip install --upgrade pip\n",
        "except:\n",
        "  pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiBxgnc-m8-X"
      },
      "source": [
        "### TensorFlow Transform のインストール"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j2CTKbMNm9I4"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U tensorflow_transform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R0mXLOJR_-dv"
      },
      "outputs": [],
      "source": [
        "# This cell is only necessary because packages were installed while python was\n",
        "# running. It avoids the need to restart the runtime when running in Colab.\n",
        "import pkg_resources\n",
        "import importlib\n",
        "\n",
        "importlib.reload(pkg_resources)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RptgLn2RYuK3"
      },
      "source": [
        "## インポート"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K4QXVIM7iglN"
      },
      "outputs": [],
      "source": [
        "import pathlib\n",
        "import pprint\n",
        "import tempfile\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_transform as tft\n",
        "\n",
        "import tensorflow_transform.beam as tft_beam\n",
        "from tensorflow_transform.tf_metadata import dataset_metadata\n",
        "from tensorflow_transform.tf_metadata import schema_utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxOxaaOYRfl7"
      },
      "source": [
        "## データ: ダミーデータを作成する\n",
        "\n",
        "簡単な例として、いくつかの簡単なダミーデータを作成します。\n",
        "\n",
        "- `raw_data` は前処理する最初の生データです\n",
        "- `raw_data_metadata` には`raw_data` の各列の型を示すスキーマが含まれています。この例では非常に簡単です。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-R236Tkf_ON3"
      },
      "outputs": [],
      "source": [
        "raw_data = [\n",
        "      {'x': 1, 'y': 1, 's': 'hello'},\n",
        "      {'x': 2, 'y': 2, 's': 'world'},\n",
        "      {'x': 3, 'y': 3, 's': 'hello'}\n",
        "  ]\n",
        "\n",
        "raw_data_metadata = dataset_metadata.DatasetMetadata(\n",
        "    schema_utils.schema_from_feature_spec({\n",
        "        'y': tf.io.FixedLenFeature([], tf.float32),\n",
        "        'x': tf.io.FixedLenFeature([], tf.float32),\n",
        "        's': tf.io.FixedLenFeature([], tf.string),\n",
        "    }))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xexbWmQEBUBZ"
      },
      "source": [
        "## 変換：前処理関数を作成する\n",
        "\n",
        "<em>前処理関数</em>は、tf.Transform の最も重要な概念です。前処理関数では、データセットの変換が実際に行われます。テンソルのディクショナリーを受け入れて返します。ここで、テンソルは <a><code>Tensor</code></a> または <a><code>SparseTensor</code></a> を意味します。通常、前処理関数の中心となる API 呼び出しには 2 つの主要なグループがあります。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zadh6MXLS3eD"
      },
      "source": [
        "1. **TensorFlow 演算子:** テンソルを受け入れて返す関数。通常は TensorFlow 演算子を意味します。これらは、生データを一度に 1 つの特徴ベクトルで変換されたデータに変換するグラフに TensorFlow 演算子を追加します。これらは、トレーニングとサービングの両方で、すべてのサンプルで実行されます。\n",
        "2. **Tensorflow Transform Analyzers/Mappers:** Any of the analyzers/mappers provided by tf.Transform. These also accept and return tensors, and typically contain a combination of Tensorflow ops and Beam computation, but unlike TensorFlow ops they only run in the Beam pipeline during analysis requiring a full pass over the entire training dataset. The Beam computation runs only once, (prior to training, during analysis), and typically make a full pass over the entire training dataset. They create `tf.constant` tensors, which are added to your graph. For example, `tft.min` computes the minimum of a tensor over the training dataset.\n",
        "\n",
        "注意: 前処理関数をサービング推論に適用する場合、トレーニング中にアナライザーにより作成された定数は変更されません。データに傾向または季節性の要素がある場合は、それに応じて計画します。\n",
        "\n",
        "Note: The `preprocessing_fn` is not directly callable. This means that calling `preprocessing_fn(raw_data)` will not work. Instead, it must be passed to the Transform Beam API as shown in the following cells."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H2wANNF_2dCR"
      },
      "outputs": [],
      "source": [
        "def preprocessing_fn(inputs):\n",
        "    \"\"\"Preprocess input columns into transformed columns.\"\"\"\n",
        "    x = inputs['x']\n",
        "    y = inputs['y']\n",
        "    s = inputs['s']\n",
        "    x_centered = x - tft.mean(x)\n",
        "    y_normalized = tft.scale_to_0_1(y)\n",
        "    s_integerized = tft.compute_and_apply_vocabulary(s)\n",
        "    x_centered_times_y_normalized = (x_centered * y_normalized)\n",
        "    return {\n",
        "        'x_centered': x_centered,\n",
        "        'y_normalized': y_normalized,\n",
        "        's_integerized': s_integerized,\n",
        "        'x_centered_times_y_normalized': x_centered_times_y_normalized,\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSl9qyTCbBKR"
      },
      "source": [
        "## Syntax\n",
        "\n",
        "You're almost ready to put everything together and use <a target=\"_blank\" href=\"https://beam.apache.org/\">Apache Beam</a> to run it.\n",
        "\n",
        "Apache Beam uses a <a target=\"_blank\" href=\"https://beam.apache.org/documentation/programming-guide/#applying-transforms\">special syntax to define and invoke transforms</a>.  For example, in this line:\n",
        "\n",
        "```\n",
        "result = pass_this | 'name this step' >> to_this_call\n",
        "```\n",
        "\n",
        "メソッド <code>to_this_call</code> が呼び出され、<code>pass_this</code> というオブジェクトが渡されます。<a target=\"_blank\" href=\"https://stackoverflow.com/questions/50519662/what-does-the-redirection-mean-in-apache-beam-python\">この演算は、スタックトレースで <code>name this step</code> と呼ばれます</a>。<code>to_this_call</code> の呼び出しの結果は、<code>result</code> に返されます。 頻繁にパイプラインのステージは次のようにチェーンされます。\n",
        "\n",
        "```\n",
        "result = apache_beam.Pipeline() | 'first step' >> do_this_first() | 'second step' >> do_this_last()\n",
        "```\n",
        "\n",
        "そして、新しいパイプラインで始まったので、以下のように続行します。\n",
        "\n",
        "```\n",
        "next_result = result | 'doing more stuff' >> another_function()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kLDSxOQ8xgg"
      },
      "source": [
        "## すべてを提供する\n",
        "\n",
        "Now we're ready to transform our data. We'll use Apache Beam with a direct runner, and supply three inputs:\n",
        "\n",
        "1. `raw_data` - 上で作成した生の入力データ\n",
        "2. `raw_data_metadata` - 生データのスキーマ\n",
        "3. `preprocessing_fn` - 変換を行うために作成した関数"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mAF9w7RTZU7c"
      },
      "outputs": [],
      "source": [
        "def main(output_dir):\n",
        "  # Ignore the warnings\n",
        "  with tft_beam.Context(temp_dir=tempfile.mkdtemp()):\n",
        "    transformed_dataset, transform_fn = (  # pylint: disable=unused-variable\n",
        "        (raw_data, raw_data_metadata) | tft_beam.AnalyzeAndTransformDataset(\n",
        "            preprocessing_fn))\n",
        "\n",
        "  transformed_data, transformed_metadata = transformed_dataset  # pylint: disable=unused-variable\n",
        "\n",
        "  # Save the transform_fn to the output_dir\n",
        "  _ = (\n",
        "      transform_fn\n",
        "      | 'WriteTransformFn' >> tft_beam.WriteTransformFn(output_dir))\n",
        "\n",
        "  return transformed_data, transformed_metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zZPQl0X19ni2"
      },
      "outputs": [],
      "source": [
        "output_dir = pathlib.Path(tempfile.mkdtemp())\n",
        "\n",
        "transformed_data, transformed_metadata = main(str(output_dir))\n",
        "\n",
        "print('\\nRaw data:\\n{}\\n'.format(pprint.pformat(raw_data)))\n",
        "print('Transformed data:\\n{}'.format(pprint.pformat(transformed_data)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NO6LyTneNndy"
      },
      "source": [
        "## 答えは正しいでしょうか？\n",
        "\n",
        "以前は、これを行うために `tf.Transform` を使用しました。\n",
        "\n",
        "```\n",
        "x_centered = x - tft.mean(x)\n",
        "y_normalized = tft.scale_to_0_1(y)\n",
        "s_integerized = tft.compute_and_apply_vocabulary(s)\n",
        "x_centered_times_y_normalized = (x_centered * y_normalized)\n",
        "```\n",
        "\n",
        "- **x_centered** - With input of `[1, 2, 3]` the mean of x is 2, and we subtract it from x to center our x values at 0.  So our result of `[-1.0, 0.0, 1.0]` is correct.\n",
        "- **y_normalized** - We wanted to scale our y values between 0 and 1.  Our input was `[1, 2, 3]` so our result of `[0.0, 0.5, 1.0]` is correct.\n",
        "- **s_integerized** - We wanted to map our strings to indexes in a vocabulary, and there were only 2 words in our vocabulary (\"hello\" and \"world\").  So with input of `[\"hello\", \"world\", \"hello\"]` our result of `[0, 1, 0]` is correct. Since \"hello\" occurs most frequently in this data, it will be the first entry in the vocabulary.\n",
        "- **x_centered_times_y_normalized** - We wanted to create a new feature by crossing `x_centered` and `y_normalized` using multiplication.  Note that this multiplies the results, not the original values, and our new result of `[-0.0, 0.0, 1.0]` is correct."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXw790Sr8Jws"
      },
      "source": [
        "## Use the resulting `transform_fn`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "We4Mafrq8id6"
      },
      "outputs": [],
      "source": [
        "!ls -l {output_dir}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SoaaAXxk_vWP"
      },
      "source": [
        "The `transform_fn/` directory contains a `tf.saved_model` implementing with all the constants tensorflow-transform analysis results built into the graph. \n",
        "\n",
        "It is possible to load this directly with `tf.saved_model.load`, but this not easy to use:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cz8dqFW6ANJQ"
      },
      "outputs": [],
      "source": [
        "loaded = tf.saved_model.load(str(output_dir/'transform_fn'))\n",
        "loaded.signatures['serving_default']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCugaxMiBosA"
      },
      "source": [
        "A better approach is to load it using `tft.TFTransformOutput`. The `TFTransformOutput.transform_features_layer` method returns a `tft.TransformFeaturesLayer` object that can be used to apply the transformation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HNd4r2gJ75nx"
      },
      "outputs": [],
      "source": [
        "tf_transform_output = tft.TFTransformOutput(output_dir)\n",
        "\n",
        "tft_layer = tf_transform_output.transform_features_layer()\n",
        "tft_layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "se-M1zx49kTY"
      },
      "source": [
        "This `tft.TransformFeaturesLayer` expects a dictionary of batched features. So create a `Dict[str, tf.Tensor]` from the `List[Dict[str, Any]]` in `raw_data`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2nyE1fVj82Gp"
      },
      "outputs": [],
      "source": [
        "raw_data_batch = {\n",
        "    's': tf.constant([ex['s'] for ex in raw_data]),\n",
        "    'x': tf.constant([ex['x'] for ex in raw_data], dtype=tf.float32),\n",
        "    'y': tf.constant([ex['y'] for ex in raw_data], dtype=tf.float32),\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "016sJ_cD_gVC"
      },
      "source": [
        "You can use the `tft.TransformFeaturesLayer` on it's own:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fIXJYE0Z9Mrs"
      },
      "outputs": [],
      "source": [
        "transformed_batch = tft_layer(raw_data_batch)\n",
        "\n",
        "{key: value.numpy() for key, value in transformed_batch.items()}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBfO5cp-8pqb"
      },
      "source": [
        "## Export"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3SN7D-FzrZ3"
      },
      "source": [
        "A more typical use case would use `tf.Transform` to apply the transformation to the training and evaluation datasets (see the [next tutorial](census.ipynb) for an example). Then, after training, before exporting the model attach the `tft.TransformFeaturesLayer` as the first layer so that you can export it as part of your `tf.saved_model`. For a concrete example, keep reading."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYV_oy5s9Dn9"
      },
      "source": [
        "### An example training model\n",
        "\n",
        "Below is a model that:\n",
        "\n",
        "1. takes the transformed batch,\n",
        "2. stacks them all together into a simple `(batch, features)` matrix,\n",
        "3. runs them through a few dense layers, and\n",
        "4. produces 10 linear outputs.\n",
        "\n",
        "In a real use case you would apply a one-hot to the `s_integerized` feature.\n",
        "\n",
        "You could train this model on a dataset transformed by `tf.Transform`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xWiEo1ZUzp4x"
      },
      "outputs": [],
      "source": [
        "class StackDict(tf.keras.layers.Layer):\n",
        "  def call(self, inputs):\n",
        "    values = [\n",
        "        tf.cast(v, tf.float32)\n",
        "        for k,v in sorted(inputs.items(), key=lambda kv: kv[0])]\n",
        "    return tf.stack(values, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A0QJpoWT1aUD"
      },
      "outputs": [],
      "source": [
        "class TrainedModel(tf.keras.Model):\n",
        "  def __init__(self):\n",
        "    super().__init__(self)\n",
        "    self.concat = StackDict()\n",
        "    self.body = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.Dense(10),\n",
        "    ])\n",
        "\n",
        "  def call(self, inputs, training=None):\n",
        "    x = self.concat(inputs)\n",
        "    return self.body(x, training)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DkMwREIx2fkD"
      },
      "outputs": [],
      "source": [
        "trained_model = TrainedModel()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBwnbh1Q-TBK"
      },
      "source": [
        "Imagine we trained the model.\n",
        "\n",
        "```\n",
        "trained_model.compile(loss=..., optimizer='adam')\n",
        "trained_model.fit(...)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "notFxUC0AFs6"
      },
      "source": [
        "This model runs on the transformed inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d2KJ8nGt228O"
      },
      "outputs": [],
      "source": [
        "trained_model_output = trained_model(transformed_batch)\n",
        "trained_model_output.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzWs35Ki6M5c"
      },
      "source": [
        "### An example export wrapper\n",
        "\n",
        "Imagine you've trained the above model and want to export it.\n",
        "\n",
        "You'll want to include the transform function in the exported model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pe-nbN123qUt"
      },
      "outputs": [],
      "source": [
        "class ExportModel(tf.Module):\n",
        "  def __init__(self, trained_model, input_transform):\n",
        "    self.trained_model = trained_model\n",
        "    self.input_transform = input_transform\n",
        "\n",
        "  @tf.function\n",
        "  def __call__(self, inputs, training=None):\n",
        "    x = self.input_transform(inputs)\n",
        "    return self.trained_model(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iLUIO-Y87AC0"
      },
      "outputs": [],
      "source": [
        "export_model = ExportModel(trained_model=trained_model,\n",
        "                           input_transform=tft_layer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFDYQDgU7ozE"
      },
      "source": [
        "This combined model works on the raw data, and produces exactly the same results as calling the trained model directly:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AqwHTex27ILk"
      },
      "outputs": [],
      "source": [
        "export_model_output = export_model(raw_data_batch)\n",
        "export_model_output.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AZQ6_Dfd7xws"
      },
      "outputs": [],
      "source": [
        "tf.reduce_max(abs(export_model_output - trained_model_output)).numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5r-lH_nh8PM-"
      },
      "source": [
        "This `export_model` includes the `tft.TransformFeaturesLayer` and is entierly self-contained. You can save it and restore it in another environment and still get exactly the same result:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VK17CShl8F7s"
      },
      "outputs": [],
      "source": [
        "import tempfile\n",
        "model_dir = tempfile.mkdtemp(suffix='tft')\n",
        "\n",
        "tf.saved_model.save(export_model, model_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RTF-yRnA9yrL"
      },
      "outputs": [],
      "source": [
        "reloaded = tf.saved_model.load(model_dir)\n",
        "\n",
        "reloaded_model_output = reloaded(raw_data_batch)\n",
        "reloaded_model_output.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFx1I6FQ9_mj"
      },
      "outputs": [],
      "source": [
        "tf.reduce_max(abs(export_model_output - reloaded_model_output)).numpy()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "tghWegsjhpkt",
        "cSl9qyTCbBKR",
        "NO6LyTneNndy"
      ],
      "name": "simple.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
