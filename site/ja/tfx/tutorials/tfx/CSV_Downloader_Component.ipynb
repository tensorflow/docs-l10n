{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nl4XCJN9g8Bc"
      },
      "source": [
        "Copyright 2023 The TensorFlow Authors.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dIUc9Zh3hM6H"
      },
      "outputs": [],
      "source": [
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wU-hMBZVmyCo"
      },
      "source": [
        "# CNN Daily データセットを使った大規模言語モデルの TFX Pipeline チュートリアル\n",
        "\n",
        "この codelab では、KerasNLP を使用して、GPT-2 モデルという事前トレーニング済みの大規模言語モデル（LLM）を読み込み、データセットに合わせてファインチューニングを行います。このデモで使用されるデータセットは、CNN daily データセットです。ここでは、エンドツーエンドのプロセスを実演する目的のみで GPT-2 が使用されています。この codelab で紹介されるテクニックとツールは、Google T5 などの他のジェネレーティブ言語モデルに移植できる可能性があります。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJAp-HxKiKsE"
      },
      "source": [
        "<div class=\"devsite-table-wrapper\"><table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "<td><a target=\"_blank\" href=\"https://www.tensorflow.org/ja/tfx/tutorials/tfx/CSV_Downloader_Component\"> <img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">TensorFlow.org で表示</a></td>\n",
        "<td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/ja/tfx/tutorials/tfx/CSV_Downloader_Component.ipynb\"> <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Google Colab で実行</a></td>\n",
        "<td><a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/ja/tfx/tutorials/tfx/CSV_Downloader_Component.ipynb\"> <img width=\"32px\" src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">GitHub でソースを表示</a></td>\n",
        "<td><a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/ja/tfx/tutorials/tfx/CSV_Downloader_Component.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">ノートブックをダウンロード</a></td>\n",
        "</table></div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MK3ryPikKtj"
      },
      "source": [
        "# 始める前に\n",
        "\n",
        "Colab には様々な種類のランタイムが用意されています。**ランタイム-&gt; ランタイムのタイプの変更** にアクセスし、必ず GPU ハードウェアアクセラレータのランタイムを選択してください。GPT-2 モデルのファインチューニングを行うため、12G 以上のシステム RAM と約 15G の GPU RAM が必要です。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMmMNdV1jZAS"
      },
      "source": [
        "# セットアップ\n",
        "\n",
        "まず、TFX Python パッケージをインストールします。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C23ItymvmVth"
      },
      "source": [
        "## Pip をアップグレードする\n",
        "\n",
        "ローカルで実行する場合にシステムの Pip をアップグレードしないように、Colab で実行していることを確認してください。もちろん、ローカルシステムは個別にアップグレードできます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cfSG5IFamUq7"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  import colab\n",
        "  !pip install --upgrade pip\n",
        "except:\n",
        "  pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "te56mTWomdLq"
      },
      "source": [
        "## TFX をインストールする\n",
        "\n",
        "TFX では現在、Colab の Python 3.10 との問題が発生しています。したがって、以下のコマンド\n",
        "\n",
        "```\n",
        "!pip install -U tfx\n",
        "```\n",
        "\n",
        "を実行して tfx をインストールすると**失敗します**。そのため、以下のコードに従ってください。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TGlfiX4PmcjZ"
      },
      "outputs": [],
      "source": [
        "%%shell\n",
        "update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.8 3\n",
        "curl -O https://bootstrap.pypa.io/get-pip.py\n",
        "python get-pip.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nYHRZQjQEcS7"
      },
      "outputs": [],
      "source": [
        "# 1) TFX relies on an old version of google-api-core so we let google-auth float\n",
        "# for the install. We grep it out below:\n",
        "!grep -v google-auth /etc/requirements.core.in > requirements.txt\n",
        "\n",
        "# 2) httplib2 should be included in /etc/requirements.core.in but it's not for\n",
        "# reasons. We ensure it's included:\n",
        "!grep httplib2 /etc/requirements.user.in >> requirements.txt\n",
        "\n",
        "# 3) google.colab package is not available as a wheel. We symlink that in so\n",
        "# it's on the sys.path of Python 3.8:\n",
        "!mkdir /usr/local/lib/python3.8/dist-packages/google\n",
        "!ln -s /usr/local/lib/python3.10/dist-packages/google/colab /usr/local/lib/python3.8/dist-packages/google/colab\n",
        "\n",
        "# Now with those pre-requisites out of the way:\n",
        "!pip install tfx==1.13.0 -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5MiV2iFkiqbL"
      },
      "outputs": [],
      "source": [
        "!pip install keras_nlp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZo6NOYQEcS7"
      },
      "source": [
        "# インポート\n",
        "\n",
        "まず、インポートを片付けてしまいましょう。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VDhX6vgUEcS7"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tfx.types import Channel\n",
        "from tfx.orchestration.experimental.interactive.interactive_context import InteractiveContext"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVMFdYDtmgPX"
      },
      "source": [
        "## shapely をアンインストールする\n",
        "\n",
        "TODO(b/263441833) これは、ImportError を回避するための一時的な策です。最終的には、追加の依存関係をアンインストールする代わりに Bigquery の最近のバージョンをサポートすることで処理される必要があります。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K4AKpWUiEcS7"
      },
      "outputs": [],
      "source": [
        "!pip uninstall shapely -y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJaN_u_8tEwi"
      },
      "source": [
        "## ランタイムを再起動しましたか？\n",
        "\n",
        "Google Colab を使用している場合は、上記のセルを初めて実行した後に、「ランタイムを再起動」ボタンをクリックするか、「ランタイム」&gt;「ランタイムの再起動...」メニューを使って、ランタイムを再起動する必要があります。これは、Colab がパッケージを読み込むために必要な作業です。\n",
        "\n",
        "TensorFlow と TFX のバージョンを確認します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fac1XkwrnXW6"
      },
      "source": [
        "ライブラリのバージョンを確認します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VNwD6G4TXrlq"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "print('TensorFlow version: {}'.format(tf.__version__))\n",
        "from tfx import v1 as tfx\n",
        "print('TFX version: {}'.format(tfx.__version__))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LnvgEYNwtMhJ"
      },
      "source": [
        "## 変数をセットアップする\n",
        "\n",
        "パイプラインを定義するために使用する変数がいくつかあります。これらの変数は、必要に応じてカスタマイズすることが可能です。デフォルトでは、パイプラインからのすべての出力は、現在のディレクトリに生成されます。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVFcsQhWkbkw"
      },
      "source": [
        "# CSV Downloader\n",
        "\n",
        "パイプラインの効率を高め、自動化の可能性を得るために、ダウンロードされる CSV ファイルへのダウンロードリンクを取得するコンポーネントを使用すると便利です。さらに、TFX 本番 ML パイプラインには、パイプラインコンポーネント、実行、および生成されるアーティファクトの情報を含むメタデータを収集するという重要な目標があります。言い換えると、メタデータの目的は、パイプラインコンポーネントの系統を解析して問題をデバッグすることであるため、CSV Downloader コンポーネントを使うことで、データのソースと、データがパイプラインに進入するまえに行われた前処理ステップについての情報をログ記録し、追跡することができます。このセクションでは、CSVdoc という新しいアーティファクトを宣言し、データセットの情報を保管して CSVdoc アーティファクトの URI にある CSV Fairuwo ダウンロードする CSV Downloader というカスタムコンポーネントを作成します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jc1JTbjjo0bd"
      },
      "outputs": [],
      "source": [
        "from tfx.types import artifact\n",
        "from tfx import types\n",
        "\n",
        "Property = artifact.Property\n",
        "PropertyType = artifact.PropertyType\n",
        "\n",
        "URL_PROPERTY = Property(type=PropertyType.STRING)\n",
        "PATH_PROPERTY = Property(type=PropertyType.STRING)\n",
        "\n",
        "class CsvDoc(types.Artifact):\n",
        "  \"\"\" Artifact that contains the CSV dataset.\n",
        "\n",
        "     - 'url' : saves the source of the original data.\n",
        "     - 'path': saves the path to the CSV file.\n",
        "  \"\"\"\n",
        "\n",
        "  TYPE_NAME = 'CsvDoc'\n",
        "  PROPERTIES = {\n",
        "      'url' : URL_PROPERTY,\n",
        "      'path': PATH_PROPERTY,\n",
        "  }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Qks2al5X1Us"
      },
      "outputs": [],
      "source": [
        "from absl import logging\n",
        "import requests\n",
        "import os\n",
        "import tfx.v1 as tfx\n",
        "from tfx.dsl.component.experimental.decorators import component\n",
        "\n",
        "@tfx.dsl.components.component\n",
        "def CsvDownloaderComponent(\n",
        "    url: tfx.dsl.components.Parameter[str],\n",
        "    file_name: tfx.dsl.components.Parameter[str],\n",
        "    saved_file: tfx.dsl.components.OutputArtifact[CsvDoc],\n",
        ") -> None:\n",
        "  response = requests.get(url)\n",
        "  saved_file.url = url\n",
        "  if response.status_code == 200:\n",
        "    file_path = os.path.join(saved_file.uri, file_name)\n",
        "    saved_file.path = file_path\n",
        "    url_content = response.content\n",
        "    with open(file_path, 'wb') as csv_file:\n",
        "      csv_file.write(url_content)\n",
        "    logging.info(f\"CSV file saved successfully at {file_path}\")\n",
        "  else:\n",
        "    raise Exception(\"CSV file failed to be saved.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3D3O4L6hYBBt"
      },
      "outputs": [],
      "source": [
        "downloader = CsvDownloaderComponent(\n",
        "  url = 'https://drive.google.com/uc?id=1YdZsJlRafqxiNSl0nHQkwR7rzrNlN9LI&export=download', file_name ='testing_doc.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fGm5cG6cYE10"
      },
      "outputs": [],
      "source": [
        "from tfx.orchestration.experimental.interactive.interactive_context import InteractiveContext\n",
        "context = InteractiveContext()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SHpBtrduYG7U"
      },
      "outputs": [],
      "source": [
        "context.run(downloader, enable_cache = False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "CSV_Downloader_Component.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
