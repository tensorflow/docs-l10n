{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjUA6S30k52h"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "SpNWyqewk8fE"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TyrY7lV0oke"
      },
      "source": [
        "# Penguin テンプレートで独自データ用の TFX パイプラインを作成する\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQmvgl9nsqPW"
      },
      "source": [
        "注意: このチュートリアルは、Google Cloud [Vertex AI Workbench](https://cloud.google.com/vertex-ai-workbench) で実行することをお勧めします。[Vertex AI Workbench に移動](https://console.cloud.google.com/vertex-ai/workbench)してください。\n",
        "\n",
        "<div class=\"devsite-table-wrapper\"><table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "<td><a target=\"_blank\" href=\"https://www.tensorflow.org/tfx/tutorials/tfx/penguin_template\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">TensorFlow.org で表示</a></td>\n",
        "<td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/ja/tfx/tutorials/tfx/penguin_template.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Google Colab で実行</a>\n",
        "</td>\n",
        "<td><a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/ja/tfx/tutorials/tfx/penguin_template.ipynb\"><img width=\"32px\" src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">GitHubでソースを表示</a></td>\n",
        "<td><a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/ja/tfx/tutorials/tfx/penguin_template.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">ノートブックをダウンロード</a></td>\n",
        "</table></div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLYriYe10okf"
      },
      "source": [
        "## 重み値のみを保存。（通常、モデルのトレーニング時に使用）。\n",
        "\n",
        "このドキュメントでは、TFX Python パッケージに含まれる *penguin template* を使用して、独自のデータセットの TensorFlow Extended（TFX）パイプラインを作成する方法を説明します。作成されるパイプラインでは最初に [Palmer Penguins](https://allisonhorst.github.io/palmerpenguins/articles/intro.html) データセットが使用されますが、独自のデータセットに合わせてこのパイプラインを変換します。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0HDv9FAbUy9"
      },
      "source": [
        "### 前提条件\n",
        "\n",
        "- Linux / MacOS\n",
        "- Python 3.6-3.8\n",
        "- Jupyter notebook\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaXSIXh9czAX"
      },
      "source": [
        "## ステップ 1. 事前定義さあれたテンプレートをプロジェクトディレクトリにコピーする\n",
        "\n",
        "このステップでは、作業パイプラインプロジェクトディレクトリを作成し、TFX の *penguin テンプレート*からファイルをコピーします。これは、独自の TFX パイプラインプロジェクトの足場として捉えるとよいでしょう。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WoUaCyNF_YlF"
      },
      "source": [
        "### Pip を更新する\n",
        "\n",
        "Colab で実行している場合は、最新バージョンの Pip を使用していることを確認してください。ローカルシステムは、もちろん個別に更新できます。\n",
        "\n",
        "注意: Vertex AI Workbench で実行している場合でも、おそらく更新することが推奨されます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iQIUEpFp_ZA2"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "if 'google.colab' in sys.modules:\n",
        "  !pip install --upgrade pip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmVR97AgacoP"
      },
      "source": [
        "### 必要なパッケージをインストールする\n",
        "\n",
        "まず、TFX と TensorFlow Model Analysis（TFMA）をインストールします。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XNiqq_kN0okj"
      },
      "outputs": [],
      "source": [
        "!pip install -U tfx tensorflow-model-analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hX1rqpbQ0okp"
      },
      "source": [
        "TFX のバージョンを確認します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XAIoKMNG0okq"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_model_analysis as tfma\n",
        "import tfx\n",
        "\n",
        "print('TF version: {}'.format(tf.__version__))\n",
        "print('TFMA version: {}'.format(tfma.__version__))\n",
        "print('TFX version: {}'.format(tfx.__version__))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOsQbkky0ok7"
      },
      "source": [
        "以上でパイプラインを作成する準備ができました。\n",
        "\n",
        "`PROJECT_DIR` を自分の環境の適切な場所に設定します。デフォルト値は `~/imported/${PIPELINE_NAME}` で、[Google Cloud AI Platform Notebook](https://console.cloud.google.com/ai-platform/notebooks/) 環境の場合に最適です。\n",
        "\n",
        "以下の `PIPELINE_NAME` を変更することで、パイプラインに別の名前を付けることができます。また、これはファイルが配置されるプロジェクトディレクトリ名にもなります。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cIPlt-700ok-"
      },
      "outputs": [],
      "source": [
        "PIPELINE_NAME=\"my_pipeline\"\n",
        "import os\n",
        "# Set this project directory to your new tfx pipeline project.\n",
        "PROJECT_DIR=os.path.join(os.path.expanduser(\"~\"), \"imported\", PIPELINE_NAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozHIomcd0olB"
      },
      "source": [
        "### テンプレートファイルをコピーする\n",
        "\n",
        "TFX には、TFX Python パッケージとともに `penguin` テンプレートが含まれます。`penguin` テンプレートには、データセットをパイプラインに取り込む指示が多数含まれています。このチュートリアルでは、それを目的としています。\n",
        "\n",
        "`tfx template copy` CLI コマンドは、事前定義されたテンプレートファイルをプロジェクトディレクトリにコピーします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VLXpTTjU0olD"
      },
      "outputs": [],
      "source": [
        "# Set `PATH` to include user python binary directory and a directory containing `skaffold`.\n",
        "PATH=%env PATH\n",
        "%env PATH={PATH}:/home/jupyter/.local/bin\n",
        "\n",
        "!tfx template copy \\\n",
        "  --pipeline-name={PIPELINE_NAME} \\\n",
        "  --destination-path={PROJECT_DIR} \\\n",
        "  --model=penguin"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxOT19QS0olH"
      },
      "source": [
        "このノートブックの作業ディレクトリコンテキストをプロジェクトディレクトリに変更します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6P-HljcU0olI"
      },
      "outputs": [],
      "source": [
        "%cd {PROJECT_DIR}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1tEYUQxH0olO"
      },
      "source": [
        "> 注意: JupyterLab または Google Cloud AI Platform Notebook を使用している場合は、作成されたプロジェクトディレクトリをクリックして、左側の `File Browser` のディレクトリを忘れずに変更してください。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzT2PFrN0olQ"
      },
      "source": [
        "### コピーしたソースファイルを閲覧する\n",
        "\n",
        "TFX テンプレートは、Python ソースコードやサンプルデータなど、パイプラインを構築するための基本的なスキャフォールドファイルを提供しています。`penguin` テンプレートは、[ペンギンの例](https://github.com/tensorflow/tfx/tree/master/tfx/examples/penguin)と同じ *Palmer Penguins* データセットを使用しています。\n",
        "\n",
        "ここでは、各 Python ファイルを簡単に紹介します。\n",
        "\n",
        "- `pipeline`- このディレクトリには、パイプラインの定義が含まれています。\n",
        "    - `configs.py` — パイプライン ランナーの共通定数を定義します。\n",
        "    - `pipeline.py` — TFX コンポーネントとパイプラインを定義します。\n",
        "- `models` - このディレクトリには ML モデルの定義が含まれています。\n",
        "    - `features.py`、`features_test.py` — モデルの特徴を定義します。\n",
        "    - `preprocessing.py`、`preprocessing_test.py` — データの前処理ルーチンを定義します。\n",
        "    - `constants.py` — モデルの定数を定義します。\n",
        "    - `model.py`、`model_test.py` — TensorFlow などの ML フレームワークを使って ML モデルを定義します。\n",
        "- `local_runner.py` — ローカルオーケストレーションエンジンを使用するローカル環境のランナーを定義します。\n",
        "- `kubeflow_runner.py` — Kubeflow Pipelines オーケストレーションエンジン用のランナーを定義します。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "saF1CpVefaf1"
      },
      "source": [
        "デフォルトでは、テンプレートには標準の TFX コンポーネントしか含まれていません。アクションをカスタマイズする必要がある場合は、パイプライン用のカスタムコンポーネントを作成できます。詳細については、[TFX カスタムコンポーネントガイド](https://www.tensorflow.org/tfx/guide/understanding_custom_components)をご覧ください。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROwHAsDK0olT"
      },
      "source": [
        "#### Unit-test ファイル\n",
        "\n",
        "名前に `_test.py` が含まれているファイルがあることに気が付きましたか。これらはパイプラインの単体テストであり、独自のパイプラインを実装するときに単体テストを追加することをお勧めします。テストファイルのモジュール名に `-m` フラグを指定すると、単体テストを実行できます。通常、モジュール名を取得するには、`.py` 拡張子を削除し、`/` を `.` に置き換えます。以下に例を示します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M0cMdE2Z0olU"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "!{sys.executable} -m models.features_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tO9Jhplo0olX"
      },
      "source": [
        "### ローカル環境に TFX パイプラインを作成する\n",
        "\n",
        "TFX は、パイプラインを実行するオーケストレーションエンジンを複数サポートしています。ここでは、ローカルオーケストレーションエンジンを使用します。ローカルオーケストレーションエンジンは、その他の依存関係を使用せずに実行し、リモート計算クラスタではなくローカル環境で実行するため、開発やデバッグに適しています。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZO6yR8lOo5GZ"
      },
      "source": [
        "`local_runner.py` を使用して、ローカルオーケストレータでパイプラインを実行します。実行する前に、パイプラインを作成する必要があります。パイプラインは、`pipeline create` コマンドで作成できます。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_9unbcHlo7Yi"
      },
      "outputs": [],
      "source": [
        "!tfx pipeline create --engine=local --pipeline_path=local_runner.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrRL6R06o99S"
      },
      "source": [
        "`pipeline create` コマンドは、実際に実行せずに`local_runner.py` に定義されたパイプラインを登録します。\n",
        "\n",
        "次の手順では、作成したパイプラインを `run create` コマンドで実行します。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7p73589GbTFi"
      },
      "source": [
        "## ステップ 2. 独自のデータをパイプラインに取り込む\n",
        "\n",
        "最初のパイプラインでは、テンプレートに含まれるペンギンのデータセットを取り込みます。データをパイプラインに取り込む必要があり、ほとんどの TFX パイプラインは ExampleGen コンポーネントから始まります。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEVwa28qtjwi"
      },
      "source": [
        "### ExampleGen を選択する\n",
        "\n",
        "データは、ローカルまたは分散ファイルシステム、またはクエリ可能なシステムなど、パイプラインがアクセスする場所であれば、どこにでも格納できます。TFX には、データを TFX パイプラインに取り込むための [`ExampleGen` コンポーネント](https://www.tensorflow.org/tfx/guide/examplegen)が複数用意されています。以下のサンプル生成コンポーネントのいずれかを選択できます。\n",
        "\n",
        "- CsvExampleGen: ディレクトリの CSV ファイルを読み取ります。[ペンギンの例](https://github.com/tensorflow/tfx/tree/master/tfx/examples/penguin)と[シカゴタクシーの例](https://github.com/tensorflow/tfx/tree/master/tfx/examples/chicago_taxi_pipeline)で使用されています。\n",
        "- ImportExampleGen: TFRecord ファイルを TF Example データフォーマットで取ります。[MNIST の例](https://github.com/tensorflow/tfx/tree/master/tfx/examples/mnist)で使用されています。\n",
        "- FileBasedExampleGen: [Avro](https://github.com/tensorflow/tfx/blob/master/tfx/components/example_gen/custom_executors/avro_executor.py) または [Parquet](https://github.com/tensorflow/tfx/blob/master/tfx/components/example_gen/custom_executors/parquet_executor.py) フォーマット用。\n",
        "- [BigQueryExampleGen](https://www.tensorflow.org/tfx/api_docs/python/tfx/extensions/google_cloud_big_query/example_gen/component/BigQueryExampleGen): Google Cloud BigQuery にデータを直接読み取ります。[シカゴタクシーの例](https://github.com/tensorflow/tfx/tree/master/tfx/examples/chicago_taxi_pipeline)で使用されています。\n",
        "\n",
        "また、独自の ExampleGen を作成することも可能です。たとえば、tfx にはデータソースとして [Presto を使用するカスタム ExecampleGen](https://github.com/tensorflow/tfx/tree/master/tfx/examples/custom_components/presto_example_gen) が含まれています。カスタム Executor の使用と開発方法についての詳細は、[ガイド](https://www.tensorflow.org/tfx/guide/examplegen#custom_examplegen)をご覧ください。\n",
        "\n",
        "使用する ExampleGen を決定したら、データを使用するためのパイプライン定義を変更する必要があります。\n",
        "\n",
        "1. `local_runner.py` の `DATA_PATH` を変更して、ファイルの場所に設定します。\n",
        "\n",
        "- ローカル環境にファイルがある場合は、そのパスを指定します。パイプラインの開発またはデバッグには、このオプションが最適です。\n",
        "- GCS にファイルがある場合は、`gs://{bucket_name}/...` からのパスを使用できます。[`gsutil`](https://cloud.google.com/storage/docs/gsutil) などを使って、ターミナルから GCS にアクセスできることを確認してください。必要であれば、[Google Cloud の認証ガイド](https://cloud.google.com/sdk/docs/authorizing)をご覧ください。\n",
        "- BigQueryExampleGen などのクエリベースの ExampleGen を使用する場合は、データソースからデータを選択するためのクエリ文が必要です。Google Cloud BigQuery をデータソースとして使用する場合には、このほかにもいくつか設定が必要です。\n",
        "    - `pipeline/configs.py`:\n",
        "        - `GOOGLE_CLOUD_PROJECT` と `GCS_BUCKET_NAME` を自分の GCP プロジェクトとバケット名に変更します。このバケットは、パイプラインを実行する前に存在する必要があります。\n",
        "        - `BIG_QUERY_WITH_DIRECT_RUNNER_BEAM_PIPELINE_ARGS` 変数をコメント解除します。\n",
        "        - `BIG_QUERY_QUERY` 変数をコメント解除し、**自分のクエリ文**に設定します。\n",
        "    - `local_runner.py`:\n",
        "        - `pipeline.create_pipeline()` の `data_path` 引数をコメントアウトし、代わりに `query` 引数をコメント解除します。\n",
        "    - `pipeline/pipeline.py`:\n",
        "        - `create_pipeline()` の `data_path` 引数をコメントアウトし、`query` 引数をコメント解除します。\n",
        "        - CsvExampleGen の代わりに [BigQueryExampleGen](https://www.tensorflow.org/tfx/api_docs/python/tfx/extensions/google_cloud_big_query/example_gen/component/BigQueryExampleGen) を使用します。\n",
        "\n",
        "1. `pipeline/pipeline.py` で、既存の CsvExampleGen を自分の ExampleGen クラスに置き換えます。それぞれの ExampleGen クラスのシグネチャは異なります。詳細については、[ExampleGen コンポーネントガイド](https://www.tensorflow.org/tfx/guide/examplegen)をご覧ください。`pipeline/pipeline.py` に `import` 文を使って、必要なモジュールを忘れずにインポートしてください。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xiAG6acjbl5U"
      },
      "source": [
        "最初のパイプラインは、`ExampleGen`、`StatisticsGen`、`SchemaGen`、`ExampleValidator` の 4 つのコンポーネントで構成されています。`StatisticsGen`、`SchemaGen`、および `ExampleValidator` については、何の変更も必要ありません。このパイプラインを初めて実行してみましょう。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tKOI48WumF7h"
      },
      "outputs": [],
      "source": [
        "# Update and run the pipeline.\n",
        "!tfx pipeline update --engine=local --pipeline_path=local_runner.py \\\n",
        " && tfx run create --engine=local --pipeline_name={PIPELINE_NAME}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFbYFNVbbzna"
      },
      "source": [
        "パイプラインが正常に完了すると、「Component ExampleValidator is finished.」が表示されます。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uuD5FRPAcOn8"
      },
      "source": [
        "### パイプラインの出力を調べる"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tL1wWoDh5wkj"
      },
      "source": [
        "TFX パイプラインは、アーティファクトと、アーティファクトとパイプラインの実行のメタデータを含む [metadata DB(MLMD)](https://www.tensorflow.org/tfx/guide/mlmd) の 2 種類の出力を生成します。出力の場所は、`local_runner.py` で定義されいます。デフォルトでは、アーティファクトは `tfx_pipeline_output` ディレクトリに、メタデータは sqlite データベースとして `tfx_metadata` ディレクトリに保存されています。\n",
        "\n",
        "これらの出力は、MLMD API を使って調べられます。まず、生成されたばかりの出力アーティファクトを検索するユーティリティ関数を定義しましょう。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K0i_jTvOI8mv"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tfx\n",
        "from ml_metadata import errors\n",
        "from ml_metadata.proto import metadata_store_pb2\n",
        "from tfx.types import artifact_utils\n",
        "\n",
        "# TODO(b/171447278): Move these functions into TFX library.\n",
        "\n",
        "def get_latest_executions(store, pipeline_name, component_id = None):\n",
        "  \"\"\"Fetch all pipeline runs.\"\"\"\n",
        "  if component_id is None:  # Find entire pipeline runs.\n",
        "    run_contexts = [\n",
        "        c for c in store.get_contexts_by_type('run')\n",
        "        if c.properties['pipeline_name'].string_value == pipeline_name\n",
        "    ]\n",
        "  else:  # Find specific component runs.\n",
        "    run_contexts = [\n",
        "        c for c in store.get_contexts_by_type('component_run')\n",
        "        if c.properties['pipeline_name'].string_value == pipeline_name and\n",
        "           c.properties['component_id'].string_value == component_id\n",
        "    ]\n",
        "  if not run_contexts:\n",
        "    return []\n",
        "  # Pick the latest run context.\n",
        "  latest_context = max(run_contexts,\n",
        "                       key=lambda c: c.last_update_time_since_epoch)\n",
        "  return store.get_executions_by_context(latest_context.id)\n",
        "\n",
        "def get_latest_artifacts(store, pipeline_name, component_id = None):\n",
        "  \"\"\"Fetch all artifacts from latest pipeline execution.\"\"\"\n",
        "  executions = get_latest_executions(store, pipeline_name, component_id)\n",
        "\n",
        "  # Fetch all artifacts produced from the given executions.\n",
        "  execution_ids = [e.id for e in executions]\n",
        "  events = store.get_events_by_execution_ids(execution_ids)\n",
        "  artifact_ids = [\n",
        "      event.artifact_id for event in events\n",
        "      if event.type == metadata_store_pb2.Event.OUTPUT\n",
        "  ]\n",
        "  return store.get_artifacts_by_id(artifact_ids)\n",
        "\n",
        "def find_latest_artifacts_by_type(store, artifacts, artifact_type):\n",
        "  \"\"\"Get the latest artifacts of a specified type.\"\"\"\n",
        "  # Get type information from MLMD\n",
        "  try:\n",
        "    artifact_type = store.get_artifact_type(artifact_type)\n",
        "  except errors.NotFoundError:\n",
        "    return []\n",
        "  # Filter artifacts with type.\n",
        "  filtered_artifacts = [aritfact for aritfact in artifacts\n",
        "                        if aritfact.type_id == artifact_type.id]\n",
        "  # Convert MLMD artifact data into TFX Artifact instances.\n",
        "  return [artifact_utils.deserialize_artifact(artifact_type, artifact)\n",
        "      for artifact in filtered_artifacts]\n",
        "\n",
        "\n",
        "from tfx.orchestration.experimental.interactive import visualizations\n",
        "\n",
        "def visualize_artifacts(artifacts):\n",
        "  \"\"\"Visualizes artifacts using standard visualization modules.\"\"\"\n",
        "  for artifact in artifacts:\n",
        "    visualization = visualizations.get_registry().get_visualization(\n",
        "        artifact.type_name)\n",
        "    if visualization:\n",
        "      visualization.display(artifact)\n",
        "\n",
        "from tfx.orchestration.experimental.interactive import standard_visualizations\n",
        "standard_visualizations.register_standard_visualizations()\n",
        "\n",
        "import pprint\n",
        "\n",
        "from tfx.orchestration import metadata\n",
        "from tfx.types import artifact_utils\n",
        "from tfx.types import standard_artifacts\n",
        "\n",
        "def preview_examples(artifacts):\n",
        "  \"\"\"Preview a few records from Examples artifacts.\"\"\"\n",
        "  pp = pprint.PrettyPrinter()\n",
        "  for artifact in artifacts:\n",
        "    print(\"==== Examples artifact:{}({})\".format(artifact.name, artifact.uri))\n",
        "    for split in artifact_utils.decode_split_names(artifact.split_names):\n",
        "      print(\"==== Reading from split:{}\".format(split))\n",
        "      split_uri = artifact_utils.get_split_uri([artifact], split)\n",
        "\n",
        "      # Get the list of files in this directory (all compressed TFRecord files)\n",
        "      tfrecord_filenames = [os.path.join(split_uri, name)\n",
        "                            for name in os.listdir(split_uri)]\n",
        "      # Create a `TFRecordDataset` to read these files\n",
        "      dataset = tf.data.TFRecordDataset(tfrecord_filenames,\n",
        "                                        compression_type=\"GZIP\")\n",
        "      # Iterate over the first 2 records and decode them.\n",
        "      for tfrecord in dataset.take(2):\n",
        "        serialized_example = tfrecord.numpy()\n",
        "        example = tf.train.Example()\n",
        "        example.ParseFromString(serialized_example)\n",
        "        pp.pprint(example)\n",
        "\n",
        "import local_runner\n",
        "\n",
        "metadata_connection_config = metadata.sqlite_metadata_connection_config(\n",
        "              local_runner.METADATA_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmwor9nVcmxy"
      },
      "source": [
        "次に、MLMD から出力アーティファクトのメタデータを読み取ります。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TtsrZEUB1-J4"
      },
      "outputs": [],
      "source": [
        "with metadata.Metadata(metadata_connection_config) as metadata_handler:\n",
        "    # Search all aritfacts from the previous pipeline run.\n",
        "    artifacts = get_latest_artifacts(metadata_handler.store, PIPELINE_NAME)\n",
        "    # Find artifacts of Examples type.\n",
        "    examples_artifacts = find_latest_artifacts_by_type(\n",
        "        metadata_handler.store, artifacts,\n",
        "        standard_artifacts.Examples.TYPE_NAME)\n",
        "    # Find artifacts generated from StatisticsGen.\n",
        "    stats_artifacts = find_latest_artifacts_by_type(\n",
        "        metadata_handler.store, artifacts,\n",
        "        standard_artifacts.ExampleStatistics.TYPE_NAME)\n",
        "    # Find artifacts generated from SchemaGen.\n",
        "    schema_artifacts = find_latest_artifacts_by_type(\n",
        "        metadata_handler.store, artifacts,\n",
        "        standard_artifacts.Schema.TYPE_NAME)\n",
        "    # Find artifacts generated from ExampleValidator.\n",
        "    anomalies_artifacts = find_latest_artifacts_by_type(\n",
        "        metadata_handler.store, artifacts,\n",
        "        standard_artifacts.ExampleAnomalies.TYPE_NAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3U5MNAUIdBtN"
      },
      "source": [
        "これで、各コンポーネントの出力を調べられるようになりました。[Tensorflow Data Validation(TFDV)](https://www.tensorflow.org/tfx/data_validation/get_started) が `StatisticsGen`、`SchemaGen`、および `ExampleValidator` に使用されており、TFDV を使って、これらのコンポーネントの出力を可視化することができます。\n",
        "\n",
        "このチュートリアルでは、TFDV を内部的に使用して可視化を表示する可視化ヘルパーメソッドを TFX に使用します。各コンポーネントの詳細については、[TFX コンポーネントのチュートリアル](https://www.tensorflow.org/tfx/tutorials/tfx/components_keras)をご覧ください。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxS6FsgU2IoZ"
      },
      "source": [
        "#### ExampleGen の出力を調べる\n",
        "\n",
        "ExampleGen の出力を調べてみましょう。Split ごとに最初の 2 つの Example を見てみます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3NWzXEcE13tW"
      },
      "outputs": [],
      "source": [
        "preview_examples(examples_artifacts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0uiuPhkGEBz"
      },
      "source": [
        "デフォルトでは、TFX ExampleGen は Example を *train* と *eval* の 2 つの Split に分割しますが、[Split 構成を調整する](https://www.tensorflow.org/tfx/guide/examplegen#span_version_and_split)ことが可能です。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVh13wJu-IRv"
      },
      "source": [
        "#### StatisticsGen の出力を調べる\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9LipxUp7-IRw"
      },
      "outputs": [],
      "source": [
        "visualize_artifacts(stats_artifacts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8aebEY4c0Ju7"
      },
      "source": [
        "これらの統計は、データのスキーマを自動的に作成するために SchemaGen に提供されます。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExEKbdw8-IRx"
      },
      "source": [
        "#### SchemaGen の出力を調べる\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M2IURBSp-IRy"
      },
      "outputs": [],
      "source": [
        "visualize_artifacts(schema_artifacts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTvj8yeBHDdU"
      },
      "source": [
        "このスキーマは、StatisticsGen の出力から自動的に推論されます。このチュートリアルでは生成されたスキーマを使用しますが、[スキーマを変更してカスタマイズする](https://www.tensorflow.org/tfx/guide/statsgen#creating_a_curated_schema)ことも可能です。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rl1PEUgo-IRz"
      },
      "source": [
        "#### ExampleValidator の出力を調べる\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F-4oAjGR-IR0"
      },
      "outputs": [],
      "source": [
        "visualize_artifacts(anomalies_artifacts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t026ZzbU0961"
      },
      "source": [
        "異常が見つかった場合は、すべての Example が自分の想定に従っているかについて、データを調べることができます。StatistcsGen などの他のコンポーネントの出力が役立つ場合があります。見つかった異常によってパイプラインの実行がブロックされることはありません。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFMmqy1W-IR1"
      },
      "source": [
        "`SchemaGen` の出力から、利用可能な特徴量を見ることができます。特徴量が直接 `Trainer` で ML モデルを構築するために使用できる場合は、次のステップを省略してステップ 4 にお進みください。使用できない場合は、次のステップで特徴量エンジニアリングを実行できます。平均を計算するなどのフル pass 演算が必要な場合や、スケーリングが必要jな場合は特に、`Transform` コンポーネントが必要となります。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYH8Y2KB0olm"
      },
      "source": [
        "## ステップ 3.（オプション）Transform コンポーネントを使った特徴量エンジニアリング\n",
        "\n",
        "このステップでは、パイプラインで `Transform` コンポーネントが使用するいくつかの特徴量エンジニアリングジョブを定義します。詳細については、[Transform コンポーネントガイド](https://www.tensorflow.org/tfx/guide/transform)をご覧ください。\n",
        "\n",
        "このステップは、トレーニングコードで、ExampleGen の出力に提供されていない追加の特徴量が必要な場合にのみ必要です。そうでない場合は、Trainer の使用に関する次のステップにお進みください。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qm_JjQUydbbb"
      },
      "source": [
        "### モデルの特徴量を定義する\n",
        "\n",
        "`models/features.py` には、特徴量名、語彙のサイズなど、モデルの特徴量を定義する定数が含まれます。`penguin` モデルは、教師あり学習モデルを使って分類の問題を解決し、すべての特徴量は連続した数値特徴量であるため、`penguin` テンプレートにはデフォルトで `FEATURE_KEYS` と `LABEL_KEY` の 2 つの定数があります。別の例については、[シカゴタクシーの例の特徴量定義](https://github.com/tensorflow/tfx/blob/master/tfx/experimental/templates/taxi/models/features.py)をご覧ください。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATUeHXvJdcBn"
      },
      "source": [
        "### preprocessing_fn() でトレーニング/サービング用の前処理を実装する\n",
        "\n",
        "実際の特徴量エンジニアリングは、`models/preprocessing.py` の`preprocessing_fn()` 関数で行われます。\n",
        "\n",
        "`preprocessing_fn` では、テンソルの入力ディクショナリを操作する一連の関数を定義して、テンソルの出力ディクショナリを生成することができます。TensorFlow Transform API には `scale_to_0_1` や `compute_and_apply_vocabulary` といったヘルパー関数も用意されています。または通常の TensorFlow 関数を使用することも可能です。`penguin` テンプレートにはデフォルトで、特徴量値を正規化するための [tft.scale_to_z_score](https://www.tensorflow.org/tfx/transform/api_docs/python/tft/scale_to_z_score) 関数の使用例が含まれています。\n",
        "\n",
        "`preprocessing_fn` のオーサリングについての詳細は、[Tensflow Transform ガイド](https://www.tensorflow.org/tfx/transform/get_started)をご覧ください。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUg_Lc43dbTp"
      },
      "source": [
        "### パイプラインに Transform コンポーネントを追加する\n",
        "\n",
        "preprocessing_fn の準備ができたら、パイプラインに `Transform` コンポーネントを追加します。\n",
        "\n",
        "1. `pipeline/pipeline.py` ファイルで、`# components.append(transform)` をコメント解除し、そのコンポーネントをパイプラインに追加します。\n",
        "\n",
        "パイプラインを更新して、もう一度実行できます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VE-Pqvto0olm"
      },
      "outputs": [],
      "source": [
        "!tfx pipeline update --engine=local --pipeline_path=local_runner.py \\\n",
        " && tfx run create --engine=local --pipeline_name={PIPELINE_NAME}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8q1ZYEHX0olo"
      },
      "source": [
        "パイプラインが正常に実行したら、ログの*どこか*に「Component Transform is finished.」が表示されます。`Transform` コンポーネントと `ExampleValidator` コンポーネントは互いに依存していないため、実行順は不定です。とは言え、`Transform` と `ExampleValidator` のいずれかがパイプライン実行の最後のコンポーネントとなる可能性があります。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrPEnZt0E_0m"
      },
      "source": [
        "### Transform の出力を調べる\n",
        "\n",
        "Transform コンポーネントは、Tensorflow グラフと変換済みの Example の 2 種類の出力を作成します。変換された Example は、ExampleGen からも生成される Examples アーティファクトタイプですが、これには、代わりに変換済みの特徴量値が含まれます。\n",
        "\n",
        "これらは前のステップと同じ方法で調べることが可能です。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FvC5S66ZU5g6"
      },
      "outputs": [],
      "source": [
        "with metadata.Metadata(metadata_connection_config) as metadata_handler:\n",
        "    # Search all aritfacts from the previous run of Transform component.\n",
        "    artifacts = get_latest_artifacts(metadata_handler.store,\n",
        "                                     PIPELINE_NAME, \"Transform\")\n",
        "    # Find artifacts of Examples type.\n",
        "    transformed_examples_artifacts = find_latest_artifacts_by_type(\n",
        "        metadata_handler.store, artifacts,\n",
        "        standard_artifacts.Examples.TYPE_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CAFiEPKuC6Ib"
      },
      "outputs": [],
      "source": [
        "preview_examples(transformed_examples_artifacts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWMBXU510olp"
      },
      "source": [
        "## ステップ 4. Trainer コンポーネントでモデルをトレーニングする\n",
        "\n",
        "`Trainer` コンポーネントを使って ML モデルを構築します。詳細については、[Trainer コンポーネントガイド](https://www.tensorflow.org/tfx/guide/trainer)をご覧ください。Trainer コンポーネントにモデルコードを提供する必要があります。\n",
        "\n",
        "### モデルを定義する\n",
        "\n",
        "penguin テンプレートでは、`Trainer` コンポーネントの `run_fn` 引数として `models.model.run_fn` が使用されています。これは、`models/model.py` の `run_fn()` 関数が、`Trainer` コンポーネントが実行する際に呼び出されるということです。特定のコードで `keras` API を使用すると、単純な DNN モデルを構築するコードを確認できます。TFX での Keras API の使用についての詳細は、[TFX における TensorFlow 2.x](https://www.tensorflow.org/tfx/guide/keras)ガイドをご覧ください。\n",
        "\n",
        "この `run_fn` では、コンポーネントによって指定される `fn_args.serving_model_dir` がポイントするディレクトリにモデルを構築して保存する必要があります。`run_fn` に渡される `fn_args` に他の引数を使用することが可能です。`fn_args` の引数の全リストについては. [関連するコード](https://github.com/tensorflow/tfx/blob/b01482442891a49a1487c67047e85ab971717b75/tfx/components/trainer/executor.py#L141)をご覧ください。\n",
        "\n",
        "必要に応じて、`models/features.py` に特徴量を定義して使用します。ステップ 3 で特徴量を変換している場合は、モデルへの入力として変換した特徴量が確認できます。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFiLIaCm-IR4"
      },
      "source": [
        "### パイプラインに Trainer コンポーネントを追加する\n",
        "\n",
        "run_fn の準備ができたら、パイプラインに  `Trainer` コンポーネントを追加します。\n",
        "\n",
        "1. `pipeline/pipeline.py` ファイルで、`# components.append(trainer)` をコメント解除し、そのコンポーネントをパイプラインに追加します。\n",
        "\n",
        "trainer コンポーネントの引数は、Transform コンポーネントを使用しているかどうかによって異なる場合があります。\n",
        "\n",
        "- `Transform` コンポーネントを**使用していない**場合は、引数を変更する必要はありません。\n",
        "\n",
        "- `Transform` コンポーネントを使用している場合は、`Trainer` コンポーネントのインスタンスを作成する際に、引数を変更する必要があります。\n",
        "\n",
        "    - `examples` 引数を`examples=transform.outputs['transformed_examples'],` に変更します。トレーニングには変換済みの Example を使用する必要があります。\n",
        "    - `transform_graph=transform.outputs['transform_graph'],` のように、`transform_graph` を追加します。このグラフには、変換演算の TensorFlow グラフが含まれます。\n",
        "    - 上記の変更を行ったら、Trainer コンポーネント作成のコードは以下のようになります。\n",
        "\n",
        "    ```python\n",
        "    # If you use a Transform component.\n",
        "    trainer = Trainer(\n",
        "        run_fn=run_fn,\n",
        "        examples=transform.outputs['transformed_examples'],\n",
        "        transform_graph=transform.outputs['transform_graph'],\n",
        "        schema=schema_gen.outputs['schema'],\n",
        "        ...\n",
        "    ```\n",
        "\n",
        "パイプラインを更新して、もう一度実行できます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VQDNitkH0olq"
      },
      "outputs": [],
      "source": [
        "!tfx pipeline update --engine=local --pipeline_path=local_runner.py \\\n",
        " && tfx run create --engine=local --pipeline_name={PIPELINE_NAME}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksWfVQUnMYCX"
      },
      "source": [
        "この実行が正常に行われると、自分のモデルに使用する初めての TFX パイプラインの作成が完了です。お疲れ様でした！\n",
        "\n",
        "新しいモデルは、出力ディレクトリ配下のどこかにありますが、中間結果が多数含まれる TFX パイプライン外部の一定した場所かサービスにモデルを維持するのがよいでしょう。構築したしたモデルを継続的に評価するとさらによいでしょう。ML 本番システムにおいては非常に重要なことです。次のステップでは、継続的評価とデプロイの仕組みを確認しましょう。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DRTFdTy0ol3"
      },
      "source": [
        "## ステップ 5.（オプション）Evaluator でモデルを評価し、Pusher で公開する\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DID2nzH-IR7"
      },
      "source": [
        "[`Evaluator`](https://www.tensorflow.org/tfx/guide/evaluator) コンポーネントは、`Trainer` から構築された各モデルを継続的に評価し、[`Pusher`](https://www.tensorflow.org/tfx/guide/pusher) はそのモデルをファイルシステムの事前定義の場所や [Google Cloud AI Platform Models](https://console.cloud.google.com/ai-platform/models) にコピーします。\n",
        "\n",
        "### パイプラインに Evaluator コンポーネントを追加する\n",
        "\n",
        "`pipeline/pipeline.py` ファイル:\n",
        "\n",
        "1. `# components.append(model_resolver)` をコメント解除し、最新のモデルレゾルバ―をパイプラインに追加します。Evaluator は、最後のパイプラインランで Evaluator に渡された古い基準モデルに対し、モデルを比較するために使用することができます。Evaluator に渡された最後のモデルは、`LatestBlessedModelResolver` が見つけます。\n",
        "2. モデルに適切な `tfma.MetricsSpec` を設定します。評価は、ML モデルごとに異なる場合があります。penguin テンプレートでは、複数のカテゴリの分類問題を解決しているため、`SparseCategoricalAccuracy` が使用されていました。特定のスライスについてモデルを分析するには、`tfma.SliceSpec` を指定する必要もあります。詳細については、[Evaluator コンポーネントガイド](https://www.tensorflow.org/tfx/guide/evaluator)をご覧ください。\n",
        "3. `# components.append(evaluator)` をコメント解除し、そのコンポーネントをパイプラインに追加します。\n",
        "\n",
        "パイプラインを更新して、もう一度実行できます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i5_ojoZZmaDQ"
      },
      "outputs": [],
      "source": [
        "# Update and run the pipeline.\n",
        "!tfx pipeline update --engine=local --pipeline_path=local_runner.py \\\n",
        " && tfx run create --engine=local --pipeline_name={PIPELINE_NAME}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apZX74qJ-IR7"
      },
      "source": [
        "### Evaluator の出力を調べる\n",
        "\n",
        "このステップでは、TensorFlow Model Analysis（TFMA）Jupyter Notebook 拡張機能が必要です。TEMA Notebook 拡張機能のバージョンは、TFMA Python パッケージと同じである必要があります。\n",
        "\n",
        "以下のコマンドは NPM レジストリから TFMA Notebook 拡張機能をインストールします。完了までに数分かかる場合があります。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VoL46D5Pw5FX"
      },
      "outputs": [],
      "source": [
        "# Install TFMA notebook extension.\n",
        "!jupyter labextension install tensorflow_model_analysis@{tfma.__version__}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKMo4j8ww5PB"
      },
      "source": [
        "インストールが完了したら、**ブラウザを再読み込み**して、拡張機能を有効にしてください。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ztotdqS-IR8"
      },
      "outputs": [],
      "source": [
        "with metadata.Metadata(metadata_connection_config) as metadata_handler:\n",
        "  # Search all aritfacts from the previous pipeline run.\n",
        "  artifacts = get_latest_artifacts(metadata_handler.store, PIPELINE_NAME)\n",
        "  model_evaluation_artifacts = find_latest_artifacts_by_type(\n",
        "      metadata_handler.store, artifacts,\n",
        "      standard_artifacts.ModelEvaluation.TYPE_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tVojwMCuDJuk"
      },
      "outputs": [],
      "source": [
        "if model_evaluation_artifacts:\n",
        "  tfma_result = tfma.load_eval_result(model_evaluation_artifacts[0].uri)\n",
        "  tfma.view.render_slicing_metrics(tfma_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18tqjyHN-IR9"
      },
      "source": [
        "### パイプラインに Pusher コンポーネントを追加する\n",
        "\n",
        "モデルが有望だと思える場合は、モデルを公開する必要があります。[Pusher コンポーネント](https://www.tensorflow.org/tfx/guide/pusher)は、ファイルシステムの場所または[カスタム Executor](https://github.com/tensorflow/tfx/blob/master/tfx/extensions/google_cloud_ai_platform/pusher/executor.py) の使用により GCP AI Platform Models にモデルを公開できます。\n",
        "\n",
        "`Evaluator` コンポーネントは、`Trainer` から構築された各モデルを継続的に評価し、[`Pusher`](https://www.tensorflow.org/tfx/guide/pusher) はそのモデルをファイルシステムの事前定義の場所や [Google Cloud AI Platform Models](https://console.cloud.google.com/ai-platform/models) にコピーします。\n",
        "\n",
        "1. `local_runner.py` で、`SERVING_MODEL_DIR` を、公開するディレクトリに設定します。\n",
        "2. `pipeline/pipeline.py` ファイルで、`# components.append(pusher)` をコメント解除し、Pusher をパイプラインに追加します。\n",
        "\n",
        "パイプラインを更新して、もう一度実行できます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QH81d9FsrSXS"
      },
      "outputs": [],
      "source": [
        "# Update and run the pipeline.\n",
        "!tfx pipeline update --engine=local --pipeline_path=local_runner.py \\\n",
        " && tfx run create --engine=local --pipeline_name={PIPELINE_NAME}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_K6Z18tC-IR-"
      },
      "source": [
        "`SERVING_MODEL_DIR` に新しいモデルを見つけられます。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20KRGsPX0ol3"
      },
      "source": [
        "## ステップ 6.（オプション）GCP の Kubeflow Pipelines にパイプラインをデプロイする\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0X6vfy7s-IR-"
      },
      "source": [
        "前述のとおり、`local_runner.py` はデバッグや開発の目的に適していますが、本番のワークロードにおいては最適なソリューションとは言えません。このステップでは、Google Cloud の Kubeflow Pipelines にパイプラインをデプロイします。\n",
        "\n",
        "### 準備\n",
        "\n",
        "パイプラインを Kubeflow Pipelines クラスタにデプロイするには、`kfp` python パッケージと `skaffold` プログラムが必要です。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ge1bMUtU-IR_"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade -q kfp\n",
        "\n",
        "# Download skaffold and set it executable.\n",
        "!curl -Lo skaffold https://storage.googleapis.com/skaffold/releases/latest/skaffold-linux-amd64 && chmod +x skaffold"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZsbnGq52-ISB"
      },
      "source": [
        "`skaffold` バイナリを、シェルが見つけられる場所に移動する必要があります。または、`tfx` バイナリを `--skaffold-cmd` フラグで実行する際には skaffold へのパスを指定することができます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4amQ0Elz-ISC"
      },
      "outputs": [],
      "source": [
        "# Move skaffold binary into your path\n",
        "!mv skaffold /home/jupyter/.local/bin/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rmyns-o-ISD"
      },
      "source": [
        "パイプラインを実行するための Kubeflow Pipelines クラスタも必要です。[Cloud AI Platform Pipelines での TFX のチュートリアル](https://www.tensorflow.org/tfx/tutorials/tfx/cloud-ai-platform-pipelines)に記載されているステップ 1 と 2 を実行してください。\n",
        "\n",
        "クラスタの準備ができたら、[Google cloud console の `Pipelines` ページ](http://console.cloud.google.com/ai-platform/pipelines)で、*Open Pipelines Dashboard（パイプラインダッシュボードを開く）*をクリックし、パイプラインダッシュボードを開きます。このページの URL は、パイプラインランをリクエストする `ENDPOINT` です。エンドポイント値は、https:// の後から googleusercontent.com までです。以下のコードブロックに自分のエンドポイントを入力してください。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hGyj-Qa3-ISD"
      },
      "outputs": [],
      "source": [
        "ENDPOINT='' # Enter your ENDPOINT here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igTo05YI-ISF"
      },
      "source": [
        "Kubeflow Pipelines クラスタでコードを実行するには、コードをコンテナイメージにパックする必要があります。このイメージjは、パイプラインをデプロイするときに自動的に構築されるため、イメージの名前とコンテナレジストリを設定することだけが必要となります。この例では、[Google Container Registry](https://cloud.google.com/container-registry) を使用して、`tfx-pipeline` と名付けます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5J3LrI0K-ISF"
      },
      "outputs": [],
      "source": [
        "# Read GCP project id from env.\n",
        "shell_output=!gcloud config list --format 'value(core.project)' 2>/dev/null\n",
        "GOOGLE_CLOUD_PROJECT=shell_output[0]\n",
        "\n",
        "# Docker image name for the pipeline image.\n",
        "CUSTOM_TFX_IMAGE='gcr.io/' + GOOGLE_CLOUD_PROJECT + '/tfx-pipeline'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gg11pLmU-ISH"
      },
      "source": [
        "### データの場所を設定する\n",
        "\n",
        "データは Kubeflow Pipelines クラスタからアクセスできる必要があります。ローカル環境のデータを使用した場合は、Google Cloud Storage などのリモートストレージにアップロードする必要があるかもしれません。たとえば、ペンギンのデータを、Kubeflow Pipelines クラスタがデプロイされたときに自動的に作成されるデフォルトのバケットにアップロードできます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y8MmRIHi-ISH"
      },
      "outputs": [],
      "source": [
        "!gsutil cp data/data.csv gs://{GOOGLE_CLOUD_PROJECT}-kubeflowpipelines-default/tfx-template/data/penguin/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASc1tDMm-ISJ"
      },
      "source": [
        "`kubeflow_runner.py` の `DATA_PATH` に保存されたデータ場所を更新します。\n",
        "\n",
        "BigQueryExampleGen を使用している場合は、データファイルをアップロードする必要はありませんが、`kubeflow_runner.py` が `pipeline.create_pipeline()` 関数と同じ `query` と `beam_pipeline_args` 引数を使用することを確認してください。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q42gn3XS-ISK"
      },
      "source": [
        "### パイプラインをデプロイする\n",
        "\n",
        "すべての準備が整ったら、`tfx pipeline create` コマンドを使ってパイプラインを作成できます。\n",
        "\n",
        "> 注意: Kubeflow Pipelines のパイプラインを作成するときは、パイプラインの実行に使用されるコンテナイメージが必要です。そして、`skaffold` がイメージを構築します。`skaffold` は Docker ハブからベースイメージをプルするため、最初にイメージをビルドするときは 5〜10 分かかりますが、2 回目以降のビルドにはそれほど時間がかかりません。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ytZ0liBn-ISK"
      },
      "outputs": [],
      "source": [
        "!tfx pipeline create  \\\n",
        "--engine=kubeflow \\\n",
        "--pipeline-path=kubeflow_runner.py \\\n",
        "--endpoint={ENDPOINT} \\\n",
        "--build-target-image={CUSTOM_TFX_IMAGE}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFqUQxQG-ISM"
      },
      "source": [
        "次に、`tfx run create` コマンドを使用して、新しく作成されたパイプラインで実行を開始します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ps-4RHz-ISM"
      },
      "outputs": [],
      "source": [
        "!tfx run create --engine=kubeflow --pipeline-name={PIPELINE_NAME} --endpoint={ENDPOINT}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fx3LtAL0-ISN"
      },
      "source": [
        "または、Kubeflow Pipelines ダッシュボードでパイプラインを実行することもできます。新しいランは、Kubeflow Pipelines ダッシュボードの `Experiments` の下に一覧表示されます。実験をクリックすると、進行状況を監視し、実行中に作成されたアーティファクトを可視化できます。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mP8W6zjD-ISO"
      },
      "source": [
        "Kubeflow Pipelines でパイプラインを実行することに興味がある場合は、詳細な指示について、[Cloud AI Platform Pipelines での TFX のチュートリアル](https://www.tensorflow.org/tfx/tutorials/tfx/cloud-ai-platform-pipelines)をご覧ください。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTsgD_Kz-ISO"
      },
      "source": [
        "### クリーンアップ\n",
        "\n",
        "このステップで使用されているすべての Google Cloud リソースをクリーンアップするには、チュートリアルで使用した [Google Cloud プロジェクトを削除](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects)できます。\n",
        "\n",
        "または、各コンソールにアクセスして、個々のリソースをクリーンアップすることもできます。\n",
        "\n",
        "- [Google Cloud Storage](https://console.cloud.google.com/storage)\n",
        "- [Google Container Registry](https://console.cloud.google.com/gcr)\n",
        "- [Google Kubernetes Engine](https://console.cloud.google.com/kubernetes)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "DjUA6S30k52h"
      ],
      "name": "penguin_template.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
