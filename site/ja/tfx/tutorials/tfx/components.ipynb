{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdeKOEkv1Fe8"
      },
      "source": [
        "##### Copyright 2021 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "c2jyGuiG1gHr"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23R0Z9RojXYW"
      },
      "source": [
        "# TFX Estimator コンポーネントのチュートリアル\n",
        "\n",
        "***TensorFlow Extended (TFX) の各コンポーネントの紹介***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LidV2qsXm4XC"
      },
      "source": [
        "注：この例は、Jupyter スタイルのノートブックで今すぐ実行できます。セットアップは必要ありません。「Google Colab で実行」をクリックするだけです\n",
        "\n",
        "<div class=\"devsite-table-wrapper\"><table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "<td><a target=\"_blank\" href=\"https://www.tensorflow.org/tfx/tutorials/tfx/components\"> <img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">TensorFlow.org で表示</a></td>\n",
        "<td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/ja/tfx/tutorials/tfx/components.ipynb\"> <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Google Colab で実行</a></td>\n",
        "<td><a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/ja/tfx/tutorials/tfx/components.ipynb\"> <img width=\"32px\" src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">GitHub でソースを表示</a></td>\n",
        "<td><a target=\"_blank\" href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/ja/tfx/tutorials/tfx/components.ipynb\"><img width=\"32px\" src=\"https://www.tensorflow.org/images/download_logo_32px.png\">ノートブックをダウンロード</a></td>\n",
        "</table></div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBbTLeWmWs8q"
      },
      "source": [
        "> 警告: 新しいコードには Estimators は推奨されません。Estimators は `v1.Session` スタイルのコードを実行しますが、これは正しく記述するのはより難しく、特に TF 2 コードと組み合わせると予期しない動作をする可能性があります。Estimators は、[互換性保証](https://tensorflow.org/guide/versions)の対象となりますが、セキュリティの脆弱性以外の修正は行われません。詳細については、[移行ガイド](https://tensorflow.org/guide/migrate)を参照してください。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAD1tLoTm_QS"
      },
      "source": [
        "この Colab ベースのチュートリアルでは、TensorFlow Extended (TFX) のそれぞれの組み込みコンポーネントをインタラクティブに説明します。\n",
        "\n",
        "ここではデータの取り込みからモデルのプッシュ、サービングまで、エンド ツー エンドの機械学習パイプラインのすべてのステップを見ていきます。\n",
        "\n",
        "完了したら、このノートブックのコンテンツを TFX パイプライン ソース コードとして自動的にエクスポートできます。これは、Apache Airflow および Apache Beam とオーケストレーションできます。\n",
        "\n",
        "注: このノートブックとそれに関連する API は**試験的**なものであり、現在開発中です。機能、動作、およびプレゼンテーションの大幅な変更が予想されます。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfSQ-kX-MLEr"
      },
      "source": [
        "## 背景情報\n",
        "\n",
        "このノートブックでは、Jupyter/Colab 環境で TFX を使用する方法を紹介します。ここでは、インタラクティブなノートブックでシカゴのタクシーの例を見ていきます。\n",
        "\n",
        "TFX パイプラインの構造に慣れるのには、インタラクティブなノートブックで作業するのが便利です。独自のパイプラインを軽量の開発環境として開発する場合にも役立ちますが、インタラクティブ ノートブックのオーケストレーションとメタデータ アーティファクトへのアクセス方法には違いがあるので注意してください。\n",
        "\n",
        "### オーケストレーション\n",
        "\n",
        "TFX の実稼働デプロイメントでは、Apache Airflow、Kubeflow Pipelines、Apache Beam などのオーケストレーターを使用して、TFX コンポーネントの事前定義済みパイプライン グラフをオーケストレーションします。インタラクティブなノートブックでは、ノートブック自体がオーケストレーターであり、ノートブック セルを実行するときにそれぞれの TFX コンポーネントを実行します。\n",
        "\n",
        "### メタデータ\n",
        "\n",
        "TFX の実稼働デプロイメントでは、ML Metadata（MLMD）API を介してメタデータにアクセスします。MLMD は、メタデータ プロパティを MySQL や SQLite などのデータベースに格納し、メタデータ ペイロードをファイル システムなどの永続ストアに保存します。インタラクティブなノートブックでは、プロパティとペイロードの両方が、Jupyter ノートブックまたは Colab サーバーの`/tmp`ディレクトリにあるエフェメラル SQLite データベースに保存されます。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GivNBNYjb3b"
      },
      "source": [
        "## Setup\n",
        "\n",
        "まず、必要なパッケージをインストールしてインポートし、パスを設定して、データをダウンロードします。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDl_6DkqJ-pG"
      },
      "source": [
        "### Pip のアップグレード\n",
        "\n",
        "ローカルで実行する場合にシステム Pip をアップグレードしないようにするには、Colab で実行していることを確認してください。もちろん、ローカルシステムは個別にアップグレードできます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFhBChv4J_PD"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  import colab\n",
        "  !pip install --upgrade pip\n",
        "except:\n",
        "  pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZOYTt1RW4TK"
      },
      "source": [
        "### TFX をインストールする\n",
        "\n",
        "**注：Google Colab では、パッケージが更新されるため、このセルを初めて実行するときに、ランタイムを再起動する必要があります（[ランタイム]&gt; [ランタイムの再起動...]）。**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S4SQA7Q5nej3"
      },
      "outputs": [],
      "source": [
        "!pip install -U tfx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szPQ2MDYPZ5j"
      },
      "source": [
        "## ランタイムを再起動しましたか？\n",
        "\n",
        "Google Colab を使用している場合は、上記のセルを初めて実行するときにランタイムを再起動する必要があります（[ランタイム]&gt; [ランタイムの再起動...]）。これは、Colab がパッケージを読み込むために必要です。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-ePgV0Lj68Q"
      },
      "source": [
        "### パッケージをインポートする\n",
        "\n",
        "標準の TFX コンポーネント クラスを含む必要なパッケージをインポートします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YIqpWK9efviJ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pprint\n",
        "import tempfile\n",
        "import urllib\n",
        "\n",
        "import absl\n",
        "import tensorflow as tf\n",
        "import tensorflow_model_analysis as tfma\n",
        "tf.get_logger().propagate = False\n",
        "pp = pprint.PrettyPrinter()\n",
        "\n",
        "from tfx import v1 as tfx\n",
        "from tfx.orchestration.experimental.interactive.interactive_context import InteractiveContext\n",
        "\n",
        "%load_ext tfx.orchestration.experimental.interactive.notebook_extensions.skip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCZTHRy0N1D6"
      },
      "source": [
        "ライブラリのバージョンを確認します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eZ4K18_DN2D8"
      },
      "outputs": [],
      "source": [
        "print('TensorFlow version: {}'.format(tf.__version__))\n",
        "print('TFX version: {}'.format(tfx.__version__))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufJKQ6OvkJlY"
      },
      "source": [
        "### パイプライン パスを設定"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ad5JLpKbf6sN"
      },
      "outputs": [],
      "source": [
        "# This is the root directory for your TFX pip package installation.\n",
        "_tfx_root = tfx.__path__[0]\n",
        "\n",
        "# This is the directory containing the TFX Chicago Taxi Pipeline example.\n",
        "_taxi_root = os.path.join(_tfx_root, 'examples/chicago_taxi_pipeline')\n",
        "\n",
        "# This is the path where your model will be pushed for serving.\n",
        "_serving_model_dir = os.path.join(\n",
        "    tempfile.mkdtemp(), 'serving_model/taxi_simple')\n",
        "\n",
        "# Set up logging.\n",
        "absl.logging.set_verbosity(absl.logging.INFO)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2cMMAbSkGfX"
      },
      "source": [
        "### サンプルデータのダウンロード\n",
        "\n",
        "TFX パイプラインで使用するサンプル データセットをダウンロードします。\n",
        "\n",
        "使用しているデータセットは、シカゴ市がリリースした [タクシー乗車データセット](https://data.cityofchicago.org/Transportation/Taxi-Trips/wrvz-psew)です。このデータセットの列は次のとおりです。\n",
        "\n",
        "<table>\n",
        "<tr>\n",
        "<td>pickup_community_area</td>\n",
        "<td>fare</td>\n",
        "<td>trip_start_month</td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>trip_start_hour</td>\n",
        "<td>trip_start_day</td>\n",
        "<td>trip_start_timestamp</td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>pickup_latitude</td>\n",
        "<td>pickup_longitude</td>\n",
        "<td>dropoff_latitude</td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>dropoff_longitude</td>\n",
        "<td>trip_miles</td>\n",
        "<td>pickup_census_tract</td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>dropoff_census_tract</td>\n",
        "<td>payment_type</td>\n",
        "<td>company</td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>trip_seconds</td>\n",
        "<td>dropoff_community_area</td>\n",
        "<td>tips</td>\n",
        "</tr>\n",
        "</table>\n",
        "\n",
        "このデータセットを使用して、タクシー乗車の`tips`を予測するモデルを構築します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BywX6OUEhAqn"
      },
      "outputs": [],
      "source": [
        "_data_root = tempfile.mkdtemp(prefix='tfx-data')\n",
        "DATA_PATH = 'https://raw.githubusercontent.com/tensorflow/tfx/master/tfx/examples/chicago_taxi_pipeline/data/simple/data.csv'\n",
        "_data_filepath = os.path.join(_data_root, \"data.csv\")\n",
        "urllib.request.urlretrieve(DATA_PATH, _data_filepath)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blZC1sIQOWfH"
      },
      "source": [
        "CSV ファイルを見てみましょう。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c5YPeLPFOXaD"
      },
      "outputs": [],
      "source": [
        "!head {_data_filepath}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QioyhunCImwE"
      },
      "source": [
        "*注：この Web サイトは、シカゴ市の公式 Web サイト www.cityofchicago.org で公開されたデータを変更して使用するアプリケーションを提供します。シカゴ市は、この Web サイトで提供されるデータの内容、正確性、適時性、または完全性について一切の表明を行いません。この Web サイトで提供されるデータは、随時変更される可能性があり、提供されるデータはユーザーの自己責任で利用されるものとします。*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ONIE_hdkPS4"
      },
      "source": [
        "### InteractiveContext を作成する\n",
        "\n",
        "最後に、このノートブックで TFX コンポーネントをインタラクティブに実行できるようにする InteractiveContext を作成します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Rh6K5sUf9dd"
      },
      "outputs": [],
      "source": [
        "# Here, we create an InteractiveContext using default parameters. This will\n",
        "# use a temporary directory with an ephemeral ML Metadata database instance.\n",
        "# To use your own pipeline root or database, the optional properties\n",
        "# `pipeline_root` and `metadata_connection_config` may be passed to\n",
        "# InteractiveContext. Calls to InteractiveContext are no-ops outside of the\n",
        "# notebook.\n",
        "context = InteractiveContext()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdQWxfsVkzdJ"
      },
      "source": [
        "## TFX コンポーネントをインタラクティブに実行する\n",
        "\n",
        "次のセルでは、TFX コンポーネントを 1 つずつ作成し、それぞれを実行して、出力アーティファクトを視覚化します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9fwt9gQk3BR"
      },
      "source": [
        "### ExampleGen\n",
        "\n",
        "`ExampleGen`コンポーネントは通常、TFX パイプラインの先頭にあり、以下を実行します。\n",
        "\n",
        "1. データをトレーニング セットと評価セットに分割します (デフォルトでは、2/3 トレーニング + 1/3 評価)。\n",
        "2. データを `tf.Example` 形式に変換します。 (詳細は[こちら](https://www.tensorflow.org/tutorials/load_data/tfrecord))\n",
        "3. 他のコンポーネントがアクセスできるように、データを `_tfx_root`ディレクトリにコピーします。\n",
        "\n",
        "`ExampleGen`は、データソースへのパスを入力として受け取ります。ここでは、これはダウンロードした CSV を含む`_data_root`パスです。\n",
        "\n",
        "注意: このノートブックでは、コンポーネントを 1 つずつインスタンス化し、`InteractiveContext.run()`で実行しますが、実稼働環境では、すべてのコンポーネントを事前に`Pipeline`で指定して、オーケストレーターに渡します（[TFX パイプライン ガイドの構築](https://www.tensorflow.org/tfx/guide/build_tfx_pipeline)を参照してください）。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PyXjuMt8f-9u"
      },
      "outputs": [],
      "source": [
        "example_gen = tfx.components.CsvExampleGen(input_base=_data_root)\n",
        "context.run(example_gen)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OqCoZh7KPUm9"
      },
      "source": [
        "`ExampleGen`の出力アーティファクトを調べてみましょう。このコンポーネントは、トレーニングサンプルと評価サンプルの 2 つのアーティファクトを生成します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "880KkTAkPeUg"
      },
      "outputs": [],
      "source": [
        "artifact = example_gen.outputs['examples'].get()[0]\n",
        "print(artifact.split_names, artifact.uri)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6vcbW_wPqvl"
      },
      "source": [
        "また、最初の 3 つのトレーニングサンプルも見てみます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H4XIXjiCPwzQ"
      },
      "outputs": [],
      "source": [
        "# Get the URI of the output artifact representing the training examples, which is a directory\n",
        "train_uri = os.path.join(example_gen.outputs['examples'].get()[0].uri, 'Split-train')\n",
        "\n",
        "# Get the list of files in this directory (all compressed TFRecord files)\n",
        "tfrecord_filenames = [os.path.join(train_uri, name)\n",
        "                      for name in os.listdir(train_uri)]\n",
        "\n",
        "# Create a `TFRecordDataset` to read these files\n",
        "dataset = tf.data.TFRecordDataset(tfrecord_filenames, compression_type=\"GZIP\")\n",
        "\n",
        "# Iterate over the first 3 records and decode them.\n",
        "for tfrecord in dataset.take(3):\n",
        "  serialized_example = tfrecord.numpy()\n",
        "  example = tf.train.Example()\n",
        "  example.ParseFromString(serialized_example)\n",
        "  pp.pprint(example)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2gluYjccf-IP"
      },
      "source": [
        "`ExampleGen`がデータの取り込みを完了したので、次のステップ、データ分析に進みます。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csM6BFhtk5Aa"
      },
      "source": [
        "### StatisticsGen\n",
        "\n",
        "`StatisticsGen`コンポーネントは、データ分析用のデータセットの統計を計算し、ダウンストリームのコンポーネントで使用します。これは、[TensorFlow Data Validation](https://www.tensorflow.org/tfx/data_validation/get_started) ライブラリを使用します。\n",
        "\n",
        "`StatisticsGen`コンポーネントは、データ分析用のデータセットの統計を計算し、ダウンストリーム コンポーネントで使用します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MAscCCYWgA-9"
      },
      "outputs": [],
      "source": [
        "statistics_gen = tfx.components.StatisticsGen(examples=example_gen.outputs['examples'])\n",
        "context.run(statistics_gen)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLI6cb_5WugZ"
      },
      "source": [
        "`StatisticsGen`の実行が完了すると、出力された統計を視覚化できます。色々なプロットを試してみてください！"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tLjXy7K6Tp_G"
      },
      "outputs": [],
      "source": [
        "context.show(statistics_gen.outputs['statistics'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLKLTO9Nk60p"
      },
      "source": [
        "### SchemaGen\n",
        "\n",
        "`SchemaGen`コンポーネントは、データ統計に基づいてスキーマを生成します。（スキーマは、データセット内の特徴の予想される境界、タイプ、プロパティを定義します。）また、[TensorFlow データ検証](https://www.tensorflow.org/tfx/data_validation/get_started)ライブラリも使用します。\n",
        "\n",
        "`SchemaGen`は、`StatisticsGen`で生成した統計を入力として受け取り、デフォルトでトレーニング分割を参照します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ygQvZ6hsiQ_J"
      },
      "outputs": [],
      "source": [
        "schema_gen = tfx.components.SchemaGen(\n",
        "    statistics=statistics_gen.outputs['statistics'],\n",
        "    infer_feature_shape=False)\n",
        "context.run(schema_gen)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zi6TxTUKXM6b"
      },
      "source": [
        "`SchemaGen`の実行が完了すると、生成されたスキーマを表として視覚化できます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ec9vqDXpXeMb"
      },
      "outputs": [],
      "source": [
        "context.show(schema_gen.outputs['schema'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZWWdbA-m7zp"
      },
      "source": [
        "データセットのそれぞれの特徴量は、スキーマ表のプロパティの横に行として表示されます。スキーマは、ドメインとして示される、カテゴリカル特徴量が取るすべての値もキャプチャします。\n",
        "\n",
        "スキーマの詳細については、[SchemaGen のドキュメント](https://www.tensorflow.org/tfx/guide/schemagen)をご覧ください。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1qcUuO9k9f8"
      },
      "source": [
        "### ExampleValidator\n",
        "\n",
        "`ExampleValidator`コンポーネントは、スキーマで定義された期待に基づいて、データの異常を検出します。また、[TensorFlow Data Validation](https://www.tensorflow.org/tfx/data_validation/get_started) ライブラリも使用します。\n",
        "\n",
        "`ExampleValidator`は、`StatisticsGen`からの統計と`SchemaGen`からのスキーマを入力として受け取ります。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XRlRUuGgiXks"
      },
      "outputs": [],
      "source": [
        "example_validator = tfx.components.ExampleValidator(\n",
        "    statistics=statistics_gen.outputs['statistics'],\n",
        "    schema=schema_gen.outputs['schema'])\n",
        "context.run(example_validator)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "855mrHgJcoer"
      },
      "source": [
        "`ExampleValidator`の実行が完了すると、異常を表として視覚化できます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TDyAAozQcrk3"
      },
      "outputs": [],
      "source": [
        "context.show(example_validator.outputs['anomalies'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znMoJj60ybZx"
      },
      "source": [
        "異常の表では、異常がないことがわかります。これは、分析した最初のデータセットで、スキーマはこれに合わせて調整されているため、異常がないことが予想されます。このスキーマは確認する必要があります。予期されないものがある場合は、データに異常があることを意味します。確認されたスキーマを使用することにより将来のデータを保護できます。ここで生成された異常は、モデルのパフォーマンスをデバッグし、データが時間の経過とともにどのように変化するかを理解し、データ エラーを特定するために使用できます。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPViEz5RlA36"
      },
      "source": [
        "### 変換\n",
        "\n",
        "`Transform`コンポーネントは、トレーニングとサービングの両方で特徴量エンジニアリングを実行します。これは、[TensorFlow Transform](https://www.tensorflow.org/tfx/transform/get_started) ライブラリを使用します。\n",
        "\n",
        "`Transform`は、`ExampleGen`からのデータ、`SchemaGen`からのスキーマ、ユーザー定義の Transform コードを含むモジュールを入力として受け取ります。\n",
        "\n",
        "以下のユーザー定義の Transform コードの例を見てみましょう（TensorFlow Transform API の概要については、[チュートリアルを参照してください](https://www.tensorflow.org/tfx/tutorials/transform/simple)）。まず、特徴量エンジニアリングのいくつかの定数を定義します。\n",
        "\n",
        "注意: `%%writefile`セル マジックは、セルの内容をディスク上の`.py`ファイルとして保存します。これにより、`Transform`コンポーネントはコードをモジュールとして読み込むことができます。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PuNSiUKb4YJf"
      },
      "outputs": [],
      "source": [
        "_taxi_constants_module_file = 'taxi_constants.py'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HPjhXuIF4YJh"
      },
      "outputs": [],
      "source": [
        "%%writefile {_taxi_constants_module_file}\n",
        "\n",
        "# Categorical features are assumed to each have a maximum value in the dataset.\n",
        "MAX_CATEGORICAL_FEATURE_VALUES = [24, 31, 12]\n",
        "\n",
        "CATEGORICAL_FEATURE_KEYS = [\n",
        "    'trip_start_hour', 'trip_start_day', 'trip_start_month',\n",
        "    'pickup_census_tract', 'dropoff_census_tract', 'pickup_community_area',\n",
        "    'dropoff_community_area'\n",
        "]\n",
        "\n",
        "DENSE_FLOAT_FEATURE_KEYS = ['trip_miles', 'fare', 'trip_seconds']\n",
        "\n",
        "# Number of buckets used by tf.transform for encoding each feature.\n",
        "FEATURE_BUCKET_COUNT = 10\n",
        "\n",
        "BUCKET_FEATURE_KEYS = [\n",
        "    'pickup_latitude', 'pickup_longitude', 'dropoff_latitude',\n",
        "    'dropoff_longitude'\n",
        "]\n",
        "\n",
        "# Number of vocabulary terms used for encoding VOCAB_FEATURES by tf.transform\n",
        "VOCAB_SIZE = 1000\n",
        "\n",
        "# Count of out-of-vocab buckets in which unrecognized VOCAB_FEATURES are hashed.\n",
        "OOV_SIZE = 10\n",
        "\n",
        "VOCAB_FEATURE_KEYS = [\n",
        "    'payment_type',\n",
        "    'company',\n",
        "]\n",
        "\n",
        "# Keys\n",
        "LABEL_KEY = 'tips'\n",
        "FARE_KEY = 'fare'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Duj2Ax5z4YJl"
      },
      "source": [
        "次に、生データを入力として受け取り、モデルのトレーニングに使用できる変換された特徴量を返す`preprocessing_fn`を記述します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4AJ9hBs94YJm"
      },
      "outputs": [],
      "source": [
        "_taxi_transform_module_file = 'taxi_transform.py'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MYmxxx9A4YJn"
      },
      "outputs": [],
      "source": [
        "%%writefile {_taxi_transform_module_file}\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_transform as tft\n",
        "\n",
        "import taxi_constants\n",
        "\n",
        "_DENSE_FLOAT_FEATURE_KEYS = taxi_constants.DENSE_FLOAT_FEATURE_KEYS\n",
        "_VOCAB_FEATURE_KEYS = taxi_constants.VOCAB_FEATURE_KEYS\n",
        "_VOCAB_SIZE = taxi_constants.VOCAB_SIZE\n",
        "_OOV_SIZE = taxi_constants.OOV_SIZE\n",
        "_FEATURE_BUCKET_COUNT = taxi_constants.FEATURE_BUCKET_COUNT\n",
        "_BUCKET_FEATURE_KEYS = taxi_constants.BUCKET_FEATURE_KEYS\n",
        "_CATEGORICAL_FEATURE_KEYS = taxi_constants.CATEGORICAL_FEATURE_KEYS\n",
        "_FARE_KEY = taxi_constants.FARE_KEY\n",
        "_LABEL_KEY = taxi_constants.LABEL_KEY\n",
        "\n",
        "\n",
        "def preprocessing_fn(inputs):\n",
        "  \"\"\"tf.transform's callback function for preprocessing inputs.\n",
        "  Args:\n",
        "    inputs: map from feature keys to raw not-yet-transformed features.\n",
        "  Returns:\n",
        "    Map from string feature key to transformed feature operations.\n",
        "  \"\"\"\n",
        "  outputs = {}\n",
        "  for key in _DENSE_FLOAT_FEATURE_KEYS:\n",
        "    # If sparse make it dense, setting nan's to 0 or '', and apply zscore.\n",
        "    outputs[key] = tft.scale_to_z_score(\n",
        "        _fill_in_missing(inputs[key]))\n",
        "\n",
        "  for key in _VOCAB_FEATURE_KEYS:\n",
        "    # Build a vocabulary for this feature.\n",
        "    outputs[key] = tft.compute_and_apply_vocabulary(\n",
        "        _fill_in_missing(inputs[key]),\n",
        "        top_k=_VOCAB_SIZE,\n",
        "        num_oov_buckets=_OOV_SIZE)\n",
        "\n",
        "  for key in _BUCKET_FEATURE_KEYS:\n",
        "    outputs[key] = tft.bucketize(\n",
        "        _fill_in_missing(inputs[key]), _FEATURE_BUCKET_COUNT)\n",
        "\n",
        "  for key in _CATEGORICAL_FEATURE_KEYS:\n",
        "    outputs[key] = _fill_in_missing(inputs[key])\n",
        "\n",
        "  # Was this passenger a big tipper?\n",
        "  taxi_fare = _fill_in_missing(inputs[_FARE_KEY])\n",
        "  tips = _fill_in_missing(inputs[_LABEL_KEY])\n",
        "  outputs[_LABEL_KEY] = tf.where(\n",
        "      tf.math.is_nan(taxi_fare),\n",
        "      tf.cast(tf.zeros_like(taxi_fare), tf.int64),\n",
        "      # Test if the tip was > 20% of the fare.\n",
        "      tf.cast(\n",
        "          tf.greater(tips, tf.multiply(taxi_fare, tf.constant(0.2))), tf.int64))\n",
        "\n",
        "  return outputs\n",
        "\n",
        "\n",
        "def _fill_in_missing(x):\n",
        "  \"\"\"Replace missing values in a SparseTensor.\n",
        "  Fills in missing values of `x` with '' or 0, and converts to a dense tensor.\n",
        "  Args:\n",
        "    x: A `SparseTensor` of rank 2.  Its dense shape should have size at most 1\n",
        "      in the second dimension.\n",
        "  Returns:\n",
        "    A rank 1 tensor where missing values of `x` have been filled in.\n",
        "  \"\"\"\n",
        "  if not isinstance(x, tf.sparse.SparseTensor):\n",
        "    return x\n",
        "\n",
        "  default_value = '' if x.dtype == tf.string else 0\n",
        "  return tf.squeeze(\n",
        "      tf.sparse.to_dense(\n",
        "          tf.SparseTensor(x.indices, x.values, [x.dense_shape[0], 1]),\n",
        "          default_value),\n",
        "      axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgbmZr3sgbWW"
      },
      "source": [
        "次に、この特徴量エンジニアリング コードを `Transform`コンポーネントに渡し、実行してデータを変換します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jHfhth_GiZI9"
      },
      "outputs": [],
      "source": [
        "transform = tfx.components.Transform(\n",
        "    examples=example_gen.outputs['examples'],\n",
        "    schema=schema_gen.outputs['schema'],\n",
        "    module_file=os.path.abspath(_taxi_transform_module_file))\n",
        "context.run(transform)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwAwb4rARRQ2"
      },
      "source": [
        "`Transform`の出力アーティファクトを調べてみましょう。このコンポーネントは、2 種類の出力を生成します。\n",
        "\n",
        "- `transform_graph`は、前処理演算を実行できるグラフです (このグラフは、サービングモデルと評価モデルに含まれます)。\n",
        "- `transformed_examples`は前処理されたトレーニングおよび評価データを表します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SClrAaEGR1O5"
      },
      "outputs": [],
      "source": [
        "transform.outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyFkBd9AR1sy"
      },
      "source": [
        "`transform_graph`アーティファクトを見てみましょう。これは、3 つのサブディレクトリを含むディレクトリを指しています。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5tRw4DneR3i7"
      },
      "outputs": [],
      "source": [
        "train_uri = transform.outputs['transform_graph'].get()[0].uri\n",
        "os.listdir(train_uri)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fqV54CIR6Pu"
      },
      "source": [
        "`transformed_metadata`サブディレクトリには、前処理されたデータのスキーマが含まれています。`transform_fn`サブディレクトリには、実際の前処理グラフが含まれています。`metadata`サブディレクトリには、元のデータのスキーマが含まれています。\n",
        "\n",
        "また、最初の 3 つの変換された例も見てみます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pwbW2zPKR_S4"
      },
      "outputs": [],
      "source": [
        "# Get the URI of the output artifact representing the transformed examples, which is a directory\n",
        "train_uri = os.path.join(transform.outputs['transformed_examples'].get()[0].uri, 'Split-train')\n",
        "\n",
        "# Get the list of files in this directory (all compressed TFRecord files)\n",
        "tfrecord_filenames = [os.path.join(train_uri, name)\n",
        "                      for name in os.listdir(train_uri)]\n",
        "\n",
        "# Create a `TFRecordDataset` to read these files\n",
        "dataset = tf.data.TFRecordDataset(tfrecord_filenames, compression_type=\"GZIP\")\n",
        "\n",
        "# Iterate over the first 3 records and decode them.\n",
        "for tfrecord in dataset.take(3):\n",
        "  serialized_example = tfrecord.numpy()\n",
        "  example = tf.train.Example()\n",
        "  example.ParseFromString(serialized_example)\n",
        "  pp.pprint(example)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_b_V6eN4f69"
      },
      "source": [
        "`Transform`コンポーネントがデータを特徴量に変換したら、次にモデルをトレーニングします。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBJFtnl6lCg9"
      },
      "source": [
        "### Trainer\n",
        "\n",
        "`Trainer`コンポーネントは、TensorFlow で定義したモデルをトレーニングします (Estimator API または Keras API を [ `model_to_estimator` ](https://www.tensorflow.org/api_docs/python/tf/keras/estimator/model_to_estimator) とともに使用します)。\n",
        "\n",
        "`Trainer`は、`SchemaGen`からのスキーマ、`Transform`からの変換されたデータとグラフ、トレーニング パラメータ、およびユーザー定義されたモデル コードを含むモジュールを入力として受け取ります。\n",
        "\n",
        "以下のユーザー定義モデル コードの例を見てみましょう（TensorFlow Estimator API の概要については、[チュートリアルを参照してください](https://www.tensorflow.org/tutorials/estimator/premade)）。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N1376oq04YJt"
      },
      "outputs": [],
      "source": [
        "_taxi_trainer_module_file = 'taxi_trainer.py'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nf9UuNng4YJu"
      },
      "outputs": [],
      "source": [
        "%%writefile {_taxi_trainer_module_file}\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_model_analysis as tfma\n",
        "import tensorflow_transform as tft\n",
        "from tensorflow_transform.tf_metadata import schema_utils\n",
        "from tfx_bsl.tfxio import dataset_options\n",
        "\n",
        "import taxi_constants\n",
        "\n",
        "_DENSE_FLOAT_FEATURE_KEYS = taxi_constants.DENSE_FLOAT_FEATURE_KEYS\n",
        "_VOCAB_FEATURE_KEYS = taxi_constants.VOCAB_FEATURE_KEYS\n",
        "_VOCAB_SIZE = taxi_constants.VOCAB_SIZE\n",
        "_OOV_SIZE = taxi_constants.OOV_SIZE\n",
        "_FEATURE_BUCKET_COUNT = taxi_constants.FEATURE_BUCKET_COUNT\n",
        "_BUCKET_FEATURE_KEYS = taxi_constants.BUCKET_FEATURE_KEYS\n",
        "_CATEGORICAL_FEATURE_KEYS = taxi_constants.CATEGORICAL_FEATURE_KEYS\n",
        "_MAX_CATEGORICAL_FEATURE_VALUES = taxi_constants.MAX_CATEGORICAL_FEATURE_VALUES\n",
        "_LABEL_KEY = taxi_constants.LABEL_KEY\n",
        "\n",
        "\n",
        "# Tf.Transform considers these features as \"raw\"\n",
        "def _get_raw_feature_spec(schema):\n",
        "  return schema_utils.schema_as_feature_spec(schema).feature_spec\n",
        "\n",
        "\n",
        "def _build_estimator(config, hidden_units=None, warm_start_from=None):\n",
        "  \"\"\"Build an estimator for predicting the tipping behavior of taxi riders.\n",
        "  Args:\n",
        "    config: tf.estimator.RunConfig defining the runtime environment for the\n",
        "      estimator (including model_dir).\n",
        "    hidden_units: [int], the layer sizes of the DNN (input layer first)\n",
        "    warm_start_from: Optional directory to warm start from.\n",
        "  Returns:\n",
        "    A dict of the following:\n",
        "      - estimator: The estimator that will be used for training and eval.\n",
        "      - train_spec: Spec for training.\n",
        "      - eval_spec: Spec for eval.\n",
        "      - eval_input_receiver_fn: Input function for eval.\n",
        "  \"\"\"\n",
        "  real_valued_columns = [\n",
        "      tf.feature_column.numeric_column(key, shape=())\n",
        "      for key in _DENSE_FLOAT_FEATURE_KEYS\n",
        "  ]\n",
        "  categorical_columns = [\n",
        "      tf.feature_column.categorical_column_with_identity(\n",
        "          key, num_buckets=_VOCAB_SIZE + _OOV_SIZE, default_value=0)\n",
        "      for key in _VOCAB_FEATURE_KEYS\n",
        "  ]\n",
        "  categorical_columns += [\n",
        "      tf.feature_column.categorical_column_with_identity(\n",
        "          key, num_buckets=_FEATURE_BUCKET_COUNT, default_value=0)\n",
        "      for key in _BUCKET_FEATURE_KEYS\n",
        "  ]\n",
        "  categorical_columns += [\n",
        "      tf.feature_column.categorical_column_with_identity(  # pylint: disable=g-complex-comprehension\n",
        "          key,\n",
        "          num_buckets=num_buckets,\n",
        "          default_value=0) for key, num_buckets in zip(\n",
        "              _CATEGORICAL_FEATURE_KEYS,\n",
        "              _MAX_CATEGORICAL_FEATURE_VALUES)\n",
        "  ]\n",
        "  return tf.estimator.DNNLinearCombinedClassifier(\n",
        "      config=config,\n",
        "      linear_feature_columns=categorical_columns,\n",
        "      dnn_feature_columns=real_valued_columns,\n",
        "      dnn_hidden_units=hidden_units or [100, 70, 50, 25],\n",
        "      warm_start_from=warm_start_from)\n",
        "\n",
        "\n",
        "def _example_serving_receiver_fn(tf_transform_graph, schema):\n",
        "  \"\"\"Build the serving in inputs.\n",
        "  Args:\n",
        "    tf_transform_graph: A TFTransformOutput.\n",
        "    schema: the schema of the input data.\n",
        "  Returns:\n",
        "    Tensorflow graph which parses examples, applying tf-transform to them.\n",
        "  \"\"\"\n",
        "  raw_feature_spec = _get_raw_feature_spec(schema)\n",
        "  raw_feature_spec.pop(_LABEL_KEY)\n",
        "\n",
        "  raw_input_fn = tf.estimator.export.build_parsing_serving_input_receiver_fn(\n",
        "      raw_feature_spec, default_batch_size=None)\n",
        "  serving_input_receiver = raw_input_fn()\n",
        "\n",
        "  transformed_features = tf_transform_graph.transform_raw_features(\n",
        "      serving_input_receiver.features)\n",
        "\n",
        "  return tf.estimator.export.ServingInputReceiver(\n",
        "      transformed_features, serving_input_receiver.receiver_tensors)\n",
        "\n",
        "\n",
        "def _eval_input_receiver_fn(tf_transform_graph, schema):\n",
        "  \"\"\"Build everything needed for the tf-model-analysis to run the model.\n",
        "  Args:\n",
        "    tf_transform_graph: A TFTransformOutput.\n",
        "    schema: the schema of the input data.\n",
        "  Returns:\n",
        "    EvalInputReceiver function, which contains:\n",
        "      - Tensorflow graph which parses raw untransformed features, applies the\n",
        "        tf-transform preprocessing operators.\n",
        "      - Set of raw, untransformed features.\n",
        "      - Label against which predictions will be compared.\n",
        "  \"\"\"\n",
        "  # Notice that the inputs are raw features, not transformed features here.\n",
        "  raw_feature_spec = _get_raw_feature_spec(schema)\n",
        "\n",
        "  serialized_tf_example = tf.compat.v1.placeholder(\n",
        "      dtype=tf.string, shape=[None], name='input_example_tensor')\n",
        "\n",
        "  # Add a parse_example operator to the tensorflow graph, which will parse\n",
        "  # raw, untransformed, tf examples.\n",
        "  features = tf.io.parse_example(serialized_tf_example, raw_feature_spec)\n",
        "\n",
        "  # Now that we have our raw examples, process them through the tf-transform\n",
        "  # function computed during the preprocessing step.\n",
        "  transformed_features = tf_transform_graph.transform_raw_features(\n",
        "      features)\n",
        "\n",
        "  # The key name MUST be 'examples'.\n",
        "  receiver_tensors = {'examples': serialized_tf_example}\n",
        "\n",
        "  # NOTE: Model is driven by transformed features (since training works on the\n",
        "  # materialized output of TFT, but slicing will happen on raw features.\n",
        "  features.update(transformed_features)\n",
        "\n",
        "  return tfma.export.EvalInputReceiver(\n",
        "      features=features,\n",
        "      receiver_tensors=receiver_tensors,\n",
        "      labels=transformed_features[_LABEL_KEY])\n",
        "\n",
        "\n",
        "def _input_fn(file_pattern, data_accessor, tf_transform_output, batch_size=200):\n",
        "  \"\"\"Generates features and label for tuning/training.\n",
        "\n",
        "  Args:\n",
        "    file_pattern: List of paths or patterns of input tfrecord files.\n",
        "    data_accessor: DataAccessor for converting input to RecordBatch.\n",
        "    tf_transform_output: A TFTransformOutput.\n",
        "    batch_size: representing the number of consecutive elements of returned\n",
        "      dataset to combine in a single batch\n",
        "\n",
        "  Returns:\n",
        "    A dataset that contains (features, indices) tuple where features is a\n",
        "      dictionary of Tensors, and indices is a single Tensor of label indices.\n",
        "  \"\"\"\n",
        "  return data_accessor.tf_dataset_factory(\n",
        "      file_pattern,\n",
        "      dataset_options.TensorFlowDatasetOptions(\n",
        "          batch_size=batch_size, label_key=_LABEL_KEY),\n",
        "      tf_transform_output.transformed_metadata.schema)\n",
        "\n",
        "\n",
        "# TFX will call this function\n",
        "def trainer_fn(trainer_fn_args, schema):\n",
        "  \"\"\"Build the estimator using the high level API.\n",
        "  Args:\n",
        "    trainer_fn_args: Holds args used to train the model as name/value pairs.\n",
        "    schema: Holds the schema of the training examples.\n",
        "  Returns:\n",
        "    A dict of the following:\n",
        "      - estimator: The estimator that will be used for training and eval.\n",
        "      - train_spec: Spec for training.\n",
        "      - eval_spec: Spec for eval.\n",
        "      - eval_input_receiver_fn: Input function for eval.\n",
        "  \"\"\"\n",
        "  # Number of nodes in the first layer of the DNN\n",
        "  first_dnn_layer_size = 100\n",
        "  num_dnn_layers = 4\n",
        "  dnn_decay_factor = 0.7\n",
        "\n",
        "  train_batch_size = 40\n",
        "  eval_batch_size = 40\n",
        "\n",
        "  tf_transform_graph = tft.TFTransformOutput(trainer_fn_args.transform_output)\n",
        "\n",
        "  train_input_fn = lambda: _input_fn(  # pylint: disable=g-long-lambda\n",
        "      trainer_fn_args.train_files,\n",
        "      trainer_fn_args.data_accessor,\n",
        "      tf_transform_graph,\n",
        "      batch_size=train_batch_size)\n",
        "\n",
        "  eval_input_fn = lambda: _input_fn(  # pylint: disable=g-long-lambda\n",
        "      trainer_fn_args.eval_files,\n",
        "      trainer_fn_args.data_accessor,\n",
        "      tf_transform_graph,\n",
        "      batch_size=eval_batch_size)\n",
        "\n",
        "  train_spec = tf.estimator.TrainSpec(  # pylint: disable=g-long-lambda\n",
        "      train_input_fn,\n",
        "      max_steps=trainer_fn_args.train_steps)\n",
        "\n",
        "  serving_receiver_fn = lambda: _example_serving_receiver_fn(  # pylint: disable=g-long-lambda\n",
        "      tf_transform_graph, schema)\n",
        "\n",
        "  exporter = tf.estimator.FinalExporter('chicago-taxi', serving_receiver_fn)\n",
        "  eval_spec = tf.estimator.EvalSpec(\n",
        "      eval_input_fn,\n",
        "      steps=trainer_fn_args.eval_steps,\n",
        "      exporters=[exporter],\n",
        "      name='chicago-taxi-eval')\n",
        "\n",
        "  run_config = tf.estimator.RunConfig(\n",
        "      save_checkpoints_steps=999, keep_checkpoint_max=1)\n",
        "\n",
        "  run_config = run_config.replace(model_dir=trainer_fn_args.serving_model_dir)\n",
        "\n",
        "  estimator = _build_estimator(\n",
        "      # Construct layers sizes with exponetial decay\n",
        "      hidden_units=[\n",
        "          max(2, int(first_dnn_layer_size * dnn_decay_factor**i))\n",
        "          for i in range(num_dnn_layers)\n",
        "      ],\n",
        "      config=run_config,\n",
        "      warm_start_from=trainer_fn_args.base_model)\n",
        "\n",
        "  # Create an input receiver for TFMA processing\n",
        "  receiver_fn = lambda: _eval_input_receiver_fn(  # pylint: disable=g-long-lambda\n",
        "      tf_transform_graph, schema)\n",
        "\n",
        "  return {\n",
        "      'estimator': estimator,\n",
        "      'train_spec': train_spec,\n",
        "      'eval_spec': eval_spec,\n",
        "      'eval_input_receiver_fn': receiver_fn\n",
        "  }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GY4yTRaX4YJx"
      },
      "source": [
        "次に、このモデル コードを`Trainer`コンポーネントに渡し、それを実行してモデルをトレーニングします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "429-vvCWibO0"
      },
      "outputs": [],
      "source": [
        "from tfx.components.trainer.executor import Executor\n",
        "from tfx.dsl.components.base import executor_spec\n",
        "\n",
        "trainer = tfx.components.Trainer(\n",
        "    module_file=os.path.abspath(_taxi_trainer_module_file),\n",
        "    custom_executor_spec=executor_spec.ExecutorClassSpec(Executor),\n",
        "    examples=transform.outputs['transformed_examples'],\n",
        "    schema=schema_gen.outputs['schema'],\n",
        "    transform_graph=transform.outputs['transform_graph'],\n",
        "    train_args=tfx.proto.TrainArgs(num_steps=10000),\n",
        "    eval_args=tfx.proto.EvalArgs(num_steps=5000))\n",
        "context.run(trainer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Cql1G35StJp"
      },
      "source": [
        "#### TensorBoard でトレーニングを分析する\n",
        "\n",
        "オプションで、TensorBoard を Trainer に接続して、モデルの学習曲線を分析できます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bXe62WE0S0Ek"
      },
      "outputs": [],
      "source": [
        "# Get the URI of the output artifact representing the training logs, which is a directory\n",
        "model_run_dir = trainer.outputs['model_run'].get()[0].uri\n",
        "\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir {model_run_dir}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmPftrv0lEQy"
      },
      "source": [
        "### Evaluator\n",
        "\n",
        "`Evaluator`コンポーネントは、評価セットに対してモデル パフォーマンス指標を計算します。これには、[TensorFlow Model Analysis](https://www.tensorflow.org/tfx/model_analysis/get_started) ライブラリが使用されます`Evaluator`は、オプションで、新しくトレーニングされたモデルが以前のモデルよりも優れていることを検証できます。これは、モデルを毎日自動的にトレーニングおよび検証する実稼働環境のパイプライン設定で役立ちます。このノートブックでは 1 つのモデルのみをトレーニングするため、`Evaluator`はモデルに自動的に「good」というラベルを付けます。\n",
        "\n",
        "`Evaluator`は、`ExampleGen`からのデータ、`Trainer`からのトレーニング済みモデル、およびスライス構成を入力として受け取ります。スライス構成により、特徴値に関する指標をスライスすることができます (たとえば、午前 8 時から午後 8 時までのタクシー乗車でモデルがどのように動作するかなど)。この構成の例は、以下を参照してください。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fVhfzzh9PDEx"
      },
      "outputs": [],
      "source": [
        "eval_config = tfma.EvalConfig(\n",
        "    model_specs=[\n",
        "        # Using signature 'eval' implies the use of an EvalSavedModel. To use\n",
        "        # a serving model remove the signature to defaults to 'serving_default'\n",
        "        # and add a label_key.\n",
        "        tfma.ModelSpec(signature_name='eval')\n",
        "    ],\n",
        "    metrics_specs=[\n",
        "        tfma.MetricsSpec(\n",
        "            # The metrics added here are in addition to those saved with the\n",
        "            # model (assuming either a keras model or EvalSavedModel is used).\n",
        "            # Any metrics added into the saved model (for example using\n",
        "            # model.compile(..., metrics=[...]), etc) will be computed\n",
        "            # automatically.\n",
        "            metrics=[\n",
        "                tfma.MetricConfig(class_name='ExampleCount')\n",
        "            ],\n",
        "            # To add validation thresholds for metrics saved with the model,\n",
        "            # add them keyed by metric name to the thresholds map.\n",
        "            thresholds = {\n",
        "                'accuracy': tfma.MetricThreshold(\n",
        "                    value_threshold=tfma.GenericValueThreshold(\n",
        "                        lower_bound={'value': 0.5}),\n",
        "                    # Change threshold will be ignored if there is no\n",
        "                    # baseline model resolved from MLMD (first run).\n",
        "                    change_threshold=tfma.GenericChangeThreshold(\n",
        "                       direction=tfma.MetricDirection.HIGHER_IS_BETTER,\n",
        "                       absolute={'value': -1e-10}))\n",
        "            }\n",
        "        )\n",
        "    ],\n",
        "    slicing_specs=[\n",
        "        # An empty slice spec means the overall slice, i.e. the whole dataset.\n",
        "        tfma.SlicingSpec(),\n",
        "        # Data can be sliced along a feature column. In this case, data is\n",
        "        # sliced along feature column trip_start_hour.\n",
        "        tfma.SlicingSpec(feature_keys=['trip_start_hour'])\n",
        "    ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mBdKH1F8JuT"
      },
      "source": [
        "次に、この構成を`Evaluator`に渡して実行します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zjcx8g6mihSt"
      },
      "outputs": [],
      "source": [
        "# Use TFMA to compute a evaluation statistics over features of a model and\n",
        "# validate them against a baseline.\n",
        "\n",
        "# The model resolver is only required if performing model validation in addition\n",
        "# to evaluation. In this case we validate against the latest blessed model. If\n",
        "# no model has been blessed before (as in this case) the evaluator will make our\n",
        "# candidate the first blessed model.\n",
        "model_resolver = tfx.dsl.Resolver(\n",
        "      strategy_class=tfx.dsl.experimental.LatestBlessedModelStrategy,\n",
        "      model=tfx.dsl.Channel(type=tfx.types.standard_artifacts.Model),\n",
        "      model_blessing=tfx.dsl.Channel(\n",
        "          type=tfx.types.standard_artifacts.ModelBlessing)).with_id(\n",
        "              'latest_blessed_model_resolver')\n",
        "context.run(model_resolver)\n",
        "\n",
        "evaluator = tfx.components.Evaluator(\n",
        "    examples=example_gen.outputs['examples'],\n",
        "    model=trainer.outputs['model'],\n",
        "    eval_config=eval_config)\n",
        "context.run(evaluator)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AeCVkBusS_8g"
      },
      "source": [
        "`Evaluator`の出力アーティファクトを調べてみましょう。 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k4GghePOTJxL"
      },
      "outputs": [],
      "source": [
        "evaluator.outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5TMskWe9LL0"
      },
      "source": [
        "`evaluation`出力を使用すると、評価セット全体のグローバル指標のデフォルトの視覚化を表示できます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U729j5X5QQUQ"
      },
      "outputs": [],
      "source": [
        "context.show(evaluator.outputs['evaluation'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-tI4p6m-OAn"
      },
      "source": [
        "スライスされた評価メトリクスの視覚化を表示するには、TensorFlow Model Analysis ライブラリを直接呼び出します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pyis6iy0HLdi"
      },
      "outputs": [],
      "source": [
        "import tensorflow_model_analysis as tfma\n",
        "\n",
        "# Get the TFMA output result path and load the result.\n",
        "PATH_TO_RESULT = evaluator.outputs['evaluation'].get()[0].uri\n",
        "tfma_result = tfma.load_eval_result(PATH_TO_RESULT)\n",
        "\n",
        "# Show data sliced along feature column trip_start_hour.\n",
        "tfma.view.render_slicing_metrics(\n",
        "    tfma_result, slicing_column='trip_start_hour')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uvYrUf2-r_6"
      },
      "source": [
        "この視覚化は同じ指標を示していますが、評価セット全体ではなく、`trip_start_hour`のすべての特徴値で計算されています。\n",
        "\n",
        "TensorFlow モデル分析は、公平性インジケーターやモデル パフォーマンスの時系列のプロットなど、他の多くの視覚化をサポートしています。詳細については、[チュートリアル](https://www.tensorflow.org/tfx/tutorials/model_analysis/tfma_basic)を参照してください。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEotnkxEswUb"
      },
      "source": [
        "構成にしきい値を追加したため、検証出力も利用できます。`blessing`アーティファクトの存在は、モデルが検証に合格したことを示しています。これは実行される最初の検証であるため、候補は自動的に bless されます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FZmiRtg6TKtR"
      },
      "outputs": [],
      "source": [
        "blessing_uri = evaluator.outputs['blessing'].get()[0].uri\n",
        "!ls -l {blessing_uri}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hM1tFkOVSBa0"
      },
      "source": [
        "検証結果レコードを読み込み、成功を確認することもできます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lxa5G08bSJ8a"
      },
      "outputs": [],
      "source": [
        "PATH_TO_RESULT = evaluator.outputs['evaluation'].get()[0].uri\n",
        "print(tfma.load_validation_result(PATH_TO_RESULT))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8DYekCZlHfj"
      },
      "source": [
        "### Pusher\n",
        "\n",
        "`Pusher`コンポーネントは通常、TFX パイプラインの最後にあります。このコンポーネントはモデルが検証に合格したかどうかをチェックし、合格した場合はモデルを `_serving_model_dir`にエクスポートします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r45nQ69eikc9"
      },
      "outputs": [],
      "source": [
        "pusher = tfx.components.Pusher(\n",
        "    model=trainer.outputs['model'],\n",
        "    model_blessing=evaluator.outputs['blessing'],\n",
        "    push_destination=tfx.proto.PushDestination(\n",
        "        filesystem=tfx.proto.PushDestination.Filesystem(\n",
        "            base_directory=_serving_model_dir)))\n",
        "context.run(pusher)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctUErBYoTO9I"
      },
      "source": [
        "次に`Pusher`の出力アーティファクトを調べてみましょう。 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pRkWo-MzTSss"
      },
      "outputs": [],
      "source": [
        "pusher.outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peH2PPS3VgkL"
      },
      "source": [
        "特に、Pusher はモデルを次のような SavedModel 形式でエクスポートします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4zyIqWl9TSdG"
      },
      "outputs": [],
      "source": [
        "push_uri = pusher.outputs['pushed_model'].get()[0].uri\n",
        "model = tf.saved_model.load(push_uri)\n",
        "\n",
        "for item in model.signatures.items():\n",
        "  pp.pprint(item)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-YPNUuHANtj"
      },
      "source": [
        "組み込みの TFX コンポーネントの紹介は以上です。"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "wdeKOEkv1Fe8"
      ],
      "name": "components.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
