{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjUA6S30k52h"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "SpNWyqewk8fE"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqZC7Cv942w0"
      },
      "source": [
        "# Create a TFX pipeline using templates with Local orchestrator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdSXv1DrxdLL"
      },
      "source": [
        "<div class=\"devsite-table-wrapper\"><table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "<td><a target=\"_blank\" href=\"https://www.tensorflow.org/tfx/tutorials/tfx/template_local\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">TensorFlow.org で実行</a></td>\n",
        "<td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/tfx/blob/master/docs/tutorials/tfx/template_local.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Google Colabで実行</a>\n",
        "</td>\n",
        "<td><a target=\"_blank\" href=\"https://github.com/tensorflow/tfx/tree/master/docs/tutorials/tfx/template_local.ipynb\">     <img width=\"32px\" src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">     GitHubでソースを表示</a></td>\n",
        "<td><a href=\"https://storage.googleapis.com/tensorflow_docs/tfx/docs/tutorials/tfx/template_local.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">ノートブックをダウンロード</a></td>\n",
        "</table></div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRBoc5la42w0"
      },
      "source": [
        "## 重み値のみを保存。（通常、モデルのトレーニング時に使用）。\n",
        "\n",
        "This document will provide instructions to create a TensorFlow Extended (TFX) pipeline using *templates* which are provided with TFX Python package. Most of instructions are Linux shell commands, and corresponding Jupyter Notebook code cells which invoke those commands using `!` are provided.\n",
        "\n",
        "You will build a pipeline using [Taxi Trips dataset](https://data.cityofchicago.org/Transportation/Taxi-Trips/wrvz-psew) released by the City of Chicago. We strongly encourage you to try to build your own pipeline using your dataset by utilizing this pipeline as a baseline.\n",
        "\n",
        "We will build a pipeline which runs on local environment. If you are interested in using Kubeflow orchestrator on Google Cloud, please see [TFX on Cloud AI Platform Pipelines tutorial](https://www.tensorflow.org/tfx/tutorials/tfx/cloud-ai-platform-pipelines).\n",
        "\n",
        "## 前提条件\n",
        "\n",
        "- Linux / MacOS\n",
        "- Python &gt;= 3.5.3\n",
        "\n",
        "You can get all prerequisites easily by [running this notebook on Google Colab](https://colab.sandbox.google.com/github/tensorflow/tfx/blob/master/docs/tutorials/tfx/template_local.ipynb).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRW5apUw42w1"
      },
      "source": [
        "## ステップ 1.  環境をセットアップする\n",
        "\n",
        "**Throughout this document, we will present commands twice. Once as a copy-and-paste-ready shell command, once as a jupyter notebook cell. If you are using Colab, just skip shell script block and execute notebook cells.**\n",
        "\n",
        "You should prepare a development environment to build a pipeline.\n",
        "\n",
        "Install `tfx` python package. We recommend use of `virtualenv` in the local environment. You can use following shell script snippet to set up your environment.\n",
        "\n",
        "```sh\n",
        "# Create a virtualenv for tfx.\n",
        "virtualenv -p python3 venv\n",
        "source venv/bin/activate\n",
        "# Install python packages.\n",
        "python -m pip install --upgrade \"tfx<2\"\n",
        "```\n",
        "\n",
        "If you are using colab:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "llKzIjr442w1"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "!{sys.executable} -m pip install --upgrade \"tfx<2\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NA86S2v42w1"
      },
      "source": [
        "NOTE: There might be some errors during package installation. For example,\n",
        "\n",
        ">ERROR: some-package 0.some_version.1 has requirement other-package!=2.0.,&lt;3,&gt;=1.15, but you'll have other-package 2.0.0 which is incompatible.\n",
        "\n",
        "Please ignore these errors at this moment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m6-DrWm042w4"
      },
      "outputs": [],
      "source": [
        "# Set `PATH` to include user python binary directory.\n",
        "HOME=%env HOME\n",
        "PATH=%env PATH\n",
        "%env PATH={PATH}:{HOME}/.local/bin"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YszwBVuS42w6"
      },
      "source": [
        "Let's check the version of TFX.\n",
        "```bash\n",
        "python -c \"from tfx import version ; print('TFX version: {}'.format(version.__version__))\"\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sBLyQWYF42w6"
      },
      "outputs": [],
      "source": [
        "!python3 -c \"from tfx import version ; print('TFX version: {}'.format(version.__version__))\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycspntQk42xF"
      },
      "source": [
        "以上でパイプラインを作成する準備ができました。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BoSOcmEB42xF"
      },
      "source": [
        "## Step 2. Copy predefined template to your project directory.\n",
        "\n",
        "このステップでは、事前定義されたテンプレートから追加のファイルをコピーして、作業パイプラインプロジェクトディレクトリとファイルを作成します。\n",
        "\n",
        "以下の `PIPELINE_NAME` を変更することで、パイプラインに別の名前を付けることができます。また、これはファイルが配置されるプロジェクトディレクトリ名にもなります。\n",
        "\n",
        "```bash\n",
        "export PIPELINE_NAME=\"my_pipeline\"\n",
        "export PROJECT_DIR=~/tfx/${PIPELINE_NAME}\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IYGyT4ib42xG"
      },
      "outputs": [],
      "source": [
        "PIPELINE_NAME=\"my_pipeline\"\n",
        "import os\n",
        "# Create a project directory under Colab content directory.\n",
        "PROJECT_DIR=os.path.join(os.sep,\"content\",PIPELINE_NAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GjXe_3oY42xI"
      },
      "source": [
        "TFX には、TFX python パッケージと `taxi` テンプレートが含まれています。分類や回帰など、ポイントワイズの予測問題を解決するには、このテンプレートを利用してスタートできます。\n",
        "\n",
        "`tfx template copy` CLI コマンドは、事前定義されたテンプレートファイルをプロジェクトディレクトリにコピーします。\n",
        "\n",
        "```sh\n",
        "tfx template copy \\\n",
        "   --pipeline_name=\"${PIPELINE_NAME}\" \\\n",
        "   --destination_path=\"${PROJECT_DIR}\" \\\n",
        "   --model=taxi\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3PmXatBD42xI"
      },
      "outputs": [],
      "source": [
        "!tfx template copy \\\n",
        "  --pipeline_name={PIPELINE_NAME} \\\n",
        "  --destination_path={PROJECT_DIR} \\\n",
        "  --model=taxi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fyhkhhxY42xK"
      },
      "source": [
        "このノートブックの作業ディレクトリコンテキストをプロジェクトディレクトリに変更します。\n",
        "\n",
        "```bash\n",
        "cd ${PROJECT_DIR}\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y9e_g5rc42xL"
      },
      "outputs": [],
      "source": [
        "%cd {PROJECT_DIR}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rKBRbE342xN"
      },
      "source": [
        "## Step 3. Browse your copied source files."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdiHik_w42xN"
      },
      "source": [
        "TFX テンプレートは、Python ソースコード、サンプルデータ、パイプラインの出力を分析する Jupyter Notebook など、パイプラインを構築するための基本的なスキャフォールドファイルを提供します。`taxi` テンプレートは、<a>Airflow Tutorial </a>と同じ<em>シカゴタクシー</em>データセットと ML モデルを使用します。\n",
        "\n",
        "In Google Colab, you can browse files by clicking a folder icon on the left. Files should be copied under the project directoy, whose name is `my_pipeline` in this case. You can click directory names to see the content of the directory, and double-click file names to open them.\n",
        "\n",
        "ここでは、各 Python ファイルを簡単に紹介します。\n",
        "\n",
        "- pipeline - このディレクトリには、パイプラインの定義が含まれています。\n",
        "    - configs.py — パイプライン ランナーの共通定数を定義します。\n",
        "    - pipeline.py — TFX コンポーネントとパイプラインを定義します。\n",
        "- models - このディレクトリには、機械学習モデルの定義が含まれています。\n",
        "    - `features.py`、`features_test.py` — モデルの特徴を定義します。\n",
        "    - `preprocessing.py`、`preprocessing_test.py` — `tf::Transform`を使用して前処理ジョブを定義します。\n",
        "    - estimator - このディレクトリには、Estimator ベースのモデルが含まれています。\n",
        "        - constants.py — モデルの定数を定義します。\n",
        "        - `model.py`、`model_test.py` — TF estimator を使用して DNN モデルを定義します\n",
        "    - keras - このディレクトリには、Keras ベースのモデルが含まれています。\n",
        "        - constants.py — モデルの定数を定義します。\n",
        "        - `model.py`、`model_test.py` — Keras を使用して DNN モデルを定義します。\n",
        "- `beam_runner.py`、`kubeflow_runner.py` — オーケストレーション エンジンごとにランナーを定義します。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmWtR_Eq42xQ"
      },
      "source": [
        "名前に `_test.py` が含まれているファイルがあることに気が付きましたか。これらはパイプラインの単体テストであり、独自のパイプラインを実装するときに単体テストを追加することをお勧めします。テストファイルのモジュール名に `-m` フラグを指定すると、単体テストを実行できます。通常、モジュール名を取得するには、`.py` 拡張子を削除し、`/` を `.` に置き換えます。以下に例を示します。\n",
        "\n",
        "```bash\n",
        "python -m models.features_test\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H0DzGg-642xQ"
      },
      "outputs": [],
      "source": [
        "!{sys.executable} -m models.features_test\n",
        "!{sys.executable} -m models.keras.model_test\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fK_C6C6g42xS"
      },
      "source": [
        "## ステップ 4. 最初の TFX パイプラインを実行する\n",
        "\n",
        "You can create a pipeline using `pipeline create` command.\n",
        "\n",
        "```bash\n",
        "tfx pipeline create --engine=local --pipeline_path=local_runner.py\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D5YikNik42xX"
      },
      "outputs": [],
      "source": [
        "!tfx pipeline create --engine=local --pipeline_path=local_runner.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kvZIn8142xZ"
      },
      "source": [
        "Then, you can run the created pipeline using `run create` command.\n",
        "```sh\n",
        "tfx run create --engine=local --pipeline_name=\"${PIPELINE_NAME}\"\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SnTC_Rql42xZ"
      },
      "outputs": [],
      "source": [
        "!tfx run create --engine=local --pipeline_name={PIPELINE_NAME}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GM1G1Efw42xb"
      },
      "source": [
        "If successful, you'll see `Component CsvExampleGen is finished.` When you copy the template, only one component, CsvExampleGen, is included in the pipeline."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pfQcePs42xc"
      },
      "source": [
        "## ステップ 5. データ検証用のコンポーネントを追加する\n",
        "\n",
        "このステップでは、`StatisticsGen`、`SchemaGen`、および、`ExampleValidator` などのデータ検証用のコンポーネントを追加します。データ検証については、[Tensorflow データ検証の基礎](https://www.tensorflow.org/tfx/data_validation/get_started)を参照してください。\n",
        "\n",
        "We will modify copied pipeline definition in `pipeline/pipeline.py`. If you are working on your local environment, use your favorite editor to edit the file. If you are working on Google Colab,\n",
        "\n",
        "> **Click folder icon on the left to open `Files` view**.\n",
        "\n",
        "> **Click `my_pipeline` to open the directory and click `pipeline` directory to open and double-click `pipeline.py` to open the file**.\n",
        "\n",
        "> Find and uncomment the 3 lines which add `StatisticsGen`, `SchemaGen`, and `ExampleValidator` to the pipeline. (Tip: find comments containing `TODO(step 5):`).\n",
        "\n",
        "> Your change will be saved automatically in a few seconds. Make sure that the `*` mark in front of the `pipeline.py` disappeared in the tab title. **There is no save button or shortcut for the file editor in Colab. Python files in file editor can be saved to the runtime environment even in `playground` mode.**\n",
        "\n",
        "次に、パイプライン定義を変更して既存のパイプラインを更新します。`tfx pipeline update` コマンドを使用してパイプラインを更新し、続いて `tfx run create` コマンドを使用して更新されたパイプラインの新しい実行を作成します。\n",
        "\n",
        "```sh\n",
        "# Update the pipeline\n",
        "tfx pipeline update --engine=local --pipeline_path=local_runner.py\n",
        "# You can run the pipeline the same way.\n",
        "tfx run create --engine local --pipeline_name \"${PIPELINE_NAME}\"\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wMsT-5EX42xc"
      },
      "outputs": [],
      "source": [
        "# Update the pipeline\n",
        "!tfx pipeline update --engine=local --pipeline_path=local_runner.py\n",
        "# You can run the pipeline the same way.\n",
        "!tfx run create --engine local --pipeline_name {PIPELINE_NAME}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUU5_3yR42xe"
      },
      "source": [
        "You should be able to see the output log from the added components. Our pipeline creates output artifacts in `tfx_pipeline_output/my_pipeline` directory."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7p7CLDvD42xe"
      },
      "source": [
        "## ステップ 6. トレーニング用のコンポーネントを追加する\n",
        "\n",
        "このステップでは、`Transform`、`Trainer`、`Resolver`、`Evaluator`、および、`Pusher` などのトレーニングとモデル検証用のコンポーネントを追加します。\n",
        "\n",
        "> **Open `pipeline/pipeline.py`**. Find and uncomment 5 lines which add `Transform`, `Trainer`, `Resolver`, `Evaluator` and `Pusher` to the pipeline. (Tip: find `TODO(step 6):`)\n",
        "\n",
        "以前と同様に、変更されたパイプライン定義で既存のパイプラインを更新する必要があります。手順はステップ 5 と同じです。`tfx pipeline update` を使用してパイプラインを更新し、`tfx run create` を使用して実行を作成します。\n",
        "\n",
        "```sh\n",
        "tfx pipeline update --engine=local --pipeline_path=local_runner.py\n",
        "tfx run create --engine local --pipeline_name \"${PIPELINE_NAME}\"\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ik8JbnRq42xf"
      },
      "outputs": [],
      "source": [
        "!tfx pipeline update --engine=local --pipeline_path=local_runner.py\n",
        "!tfx run create --engine local --pipeline_name {PIPELINE_NAME}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3L3NEPanUGY"
      },
      "source": [
        "When this execution run finishes successfully, you have now created and run your first TFX pipeline using Local orchestrator!\n",
        "\n",
        "**注意：**パイプライン実行を作成するたびに、入力とパラメーターが変更されていなくても、すべてのコンポーネントが何度も実行されることに気付いたかもしれません。これは時間とリソースの無駄なので、パイプラインキャッシングを使用してこれらの実行をスキップできます。`pipeline.py` の `Pipeline` オブジェクトに `enable_cache=True` を指定することで、キャッシュを有効にできます。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjcMwjov42xh"
      },
      "source": [
        "## Step 7. (*Optional*) Try BigQueryExampleGen.\n",
        "\n",
        "BigQuery は、サーバーレスでスケーラビリティと費用対効果の高いクラウド データ ウェアハウスです。BigQuery は、TFX のトレーニング サンプルのソースとして使用できます。このステップでは、パイプラインにBigQueryExampleGenを追加します。\n",
        "\n",
        "You need a [Google Cloud Platform](https://cloud.google.com/gcp/getting-started) account to use BigQuery. Please prepare a GCP project.\n",
        "\n",
        "Login to your project using colab auth library or `gcloud` utility.\n",
        "\n",
        "```sh\n",
        "# You need `gcloud` tool to login in local shell environment.\n",
        "gcloud auth login\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2K7nuHZ4uNXc"
      },
      "outputs": [],
      "source": [
        "if 'google.colab' in sys.modules:\n",
        "  from google.colab import auth\n",
        "  auth.authenticate_user()\n",
        "  print('Authenticated')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Win212lr03zP"
      },
      "source": [
        "You should specify your GCP project name to access BigQuery resources using TFX. Set `GOOGLE_CLOUD_PROJECT` environment variable to your project name.\n",
        "\n",
        "```sh\n",
        "export GOOGLE_CLOUD_PROJECT=YOUR_PROJECT_NAME_HERE\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vvpw_lGByxSx"
      },
      "outputs": [],
      "source": [
        "# Set your project name below.\n",
        "# WARNING! ENTER your project name before running this cell.\n",
        "%env GOOGLE_CLOUD_PROJECT=YOUR_PROJECT_NAME_HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhClPWEuuOaP"
      },
      "source": [
        "> **Open `pipeline/pipeline.py`**. Comment out `CsvExampleGen` and uncomment the line which create an instance of `BigQueryExampleGen`. You also need to uncomment `query` argument of the `create_pipeline` function.\n",
        "\n",
        "We need to specify which GCP project to use for BigQuery again, and this is done by setting `--project` in `beam_pipeline_args` when creating a pipeline.\n",
        "\n",
        "> **Open `pipeline/configs.py`**. Uncomment the definition of `BIG_QUERY__WITH_DIRECT_RUNNER_BEAM_PIPELINE_ARGS` and `BIG_QUERY_QUERY`. You should replace the project id and the region value in this file with the correct values for your GCP project.\n",
        "\n",
        "> **Open `local_runner.py`**. Uncomment two arguments, `query` and `beam_pipeline_args`, for create_pipeline() method.\n",
        "\n",
        "Now the pipeline is ready to use BigQuery as an example source. Update the pipeline and create a run as we did in step 5 and 6."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w8rOdC3r42xi"
      },
      "outputs": [],
      "source": [
        "!tfx pipeline update --engine=local --pipeline_path=local_runner.py\n",
        "!tfx run create --engine local --pipeline_name {PIPELINE_NAME}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxYxNHLN42xo"
      },
      "source": [
        "## What's next: Ingest YOUR data to the pipeline.\n",
        "\n",
        "シカゴタクシーデータセットを使用してモデルのパイプラインを作成しました。次に、データをパイプラインに入れます。\n",
        "\n",
        "データは、GCS や BigQuery など、パイプラインがアクセスできる場所であればどこにでも保存できます。データにアクセスするには、パイプライン定義を変更する必要があります。\n",
        "\n",
        "1. データがファイルに保存されている場合は、`kubeflow_runner.py` または `local_runner.py` の `DATA_PATH` を変更し、ファイルの場所に設定します。データが BigQuery に保存されている場合は、`pipeline/configs.py` の `BIG_QUERY_QUERY` を変更して、データを正しくクエリします。\n",
        "2. models/features.pyに特徴量を追加します。\n",
        "3. models/preprocessing.pyを変更して、トレーニング用の入力データを変換します。\n",
        "4. models/keras/model.pyとmodels/keras/constants.pyを変更して、機械学習モデルを記述します。\n",
        "    - Estimator ベースのモデルを使用することもできます。 `pipeline/configs.py` の `RUN_FN` 定数を `models.estimator.model.run_fn` に変更します。\n",
        "\n",
        "詳細については、[トレーナーコンポーネントガイド](https://www.tensorflow.org/tfx/guide/trainer)を参照してください。"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "template_beam.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
