{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjUA6S30k52h"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "SpNWyqewk8fE"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqZC7Cv942w0"
      },
      "source": [
        "# ローカルオーケストレーターでテンプレートを使用して TFX パイプラインを作成する"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdSXv1DrxdLL"
      },
      "source": [
        "<div class=\"devsite-table-wrapper\"><table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "<td><a target=\"_blank\" href=\"https://www.tensorflow.org/tfx/tutorials/tfx/template_local\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">TensorFlow.org で実行</a></td>\n",
        "<td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/ja/tfx/tutorials/tfx/template_beam.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Google Colabで実行</a> </td>\n",
        "<td><a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/ja/tfx/tutorials/tfx/template_beam.ipynb\">     <img width=\"32px\" src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">     GitHubでソースを表示</a></td>\n",
        "<td><a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/ja/tfx/tutorials/tfx/template_beam.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">ノートブックをダウンロード</a></td>\n",
        "</table></div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRBoc5la42w0"
      },
      "source": [
        "## 重み値のみを保存。（通常、モデルのトレーニング時に使用）。\n",
        "\n",
        "このドキュメントでは、TFX Python パッケージで提供される*テンプレート*を使用して TensorFlow Extended（TFX）パイプラインを作成する手順について説明します。命令の多くは Linux シェルコマンドであり、`!` を使用してそれらのコマンドを呼び出す、対応する Jupyter Notebook コードセルが提供されています。\n",
        "\n",
        "シカゴ市が公開した[タクシー乗降データセット](https://data.cityofchicago.org/Transportation/Taxi-Trips/wrvz-psew)を使用してパイプラインを構築します。このパイプラインをベースラインとして利用し、データセットを使用して独自のパイプラインを構築してみることを強くお勧めします。\n",
        "\n",
        "ローカル環境で実行されるパイプラインを構築します。Google Cloud で Kubeflow オーケストレーターを使用することに興味がある場合は、[クラウド AI プラットフォームパイプラインでの TFX チュートリアル](https://www.tensorflow.org/tfx/tutorials/tfx/cloud-ai-platform-pipelines)を参照してください。\n",
        "\n",
        "## 前提条件\n",
        "\n",
        "- Linux / MacOS\n",
        "- Python &gt;= 3.5.3\n",
        "\n",
        "[このノートブックを Google Colab で実行](https://colab.sandbox.google.com/github/tensorflow/tfx/blob/master/docs/tutorials/tfx/template_local.ipynb)すると、すべての前提条件を簡単に満たすことができます。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRW5apUw42w1"
      },
      "source": [
        "## ステップ 1.  環境をセットアップする\n",
        "\n",
        "**このドキュメント全体を通して、コマンドを 2 回示します。コピーアンドペースト対応のシェルコマンドとして 1 回、Jupyter ノートブックセルとして 1 回です。Colab を使用している場合は、シェルスクリプトブロックをスキップしてノートブックセルを実行するだけです。**\n",
        "\n",
        "パイプラインを構築するための開発環境を準備する必要があります。\n",
        "\n",
        "`tfx` パッケージをインストールします。ローカル環境で `virtualenv` を使用することをお勧めします。次のシェルスクリプトスニペットを使用して、環境を設定できます。\n",
        "\n",
        "```sh\n",
        "# Create a virtualenv for tfx.\n",
        "virtualenv -p python3 venv\n",
        "source venv/bin/activate\n",
        "# Install python packages.\n",
        "python -m pip install --upgrade \"tfx<2\"\n",
        "```\n",
        "\n",
        "colab を使用している場合\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "llKzIjr442w1"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "!{sys.executable} -m pip install --upgrade \"tfx<2\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NA86S2v42w1"
      },
      "source": [
        "注意: パッケージのインストール中にエラーが発生する可能性があります。例えば、\n",
        "\n",
        "> ERROR: some-package 0.some_version.1 has requirement other-package!=2.0.,&lt;3,&gt;=1.15, but you'll have other-package 2.0.0 which is incompatible.\n",
        "\n",
        "現時点では、これらのエラーは無視してください。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m6-DrWm042w4"
      },
      "outputs": [],
      "source": [
        "# Set `PATH` to include user python binary directory.\n",
        "HOME=%env HOME\n",
        "PATH=%env PATH\n",
        "%env PATH={PATH}:{HOME}/.local/bin"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YszwBVuS42w6"
      },
      "source": [
        "TFX のバージョンを確認しましょう。\n",
        "\n",
        "```bash\n",
        "python -c \"from tfx import version ; print('TFX version: {}'.format(version.__version__))\"\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sBLyQWYF42w6"
      },
      "outputs": [],
      "source": [
        "!python3 -c \"from tfx import version ; print('TFX version: {}'.format(version.__version__))\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycspntQk42xF"
      },
      "source": [
        "以上でパイプラインを作成する準備ができました。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BoSOcmEB42xF"
      },
      "source": [
        "## ステップ 2. 事前定義されたテンプレートをプロジェクトディレクトリにコピーする\n",
        "\n",
        "このステップでは、事前定義されたテンプレートから追加のファイルをコピーして、作業パイプラインプロジェクトディレクトリとファイルを作成します。\n",
        "\n",
        "以下の `PIPELINE_NAME` を変更することで、パイプラインに別の名前を付けることができます。また、これはファイルが配置されるプロジェクトディレクトリ名にもなります。\n",
        "\n",
        "```bash\n",
        "export PIPELINE_NAME=\"my_pipeline\"\n",
        "export PROJECT_DIR=~/tfx/${PIPELINE_NAME}\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IYGyT4ib42xG"
      },
      "outputs": [],
      "source": [
        "PIPELINE_NAME=\"my_pipeline\"\n",
        "import os\n",
        "# Create a project directory under Colab content directory.\n",
        "PROJECT_DIR=os.path.join(os.sep,\"content\",PIPELINE_NAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GjXe_3oY42xI"
      },
      "source": [
        "TFX には、TFX python パッケージと `taxi` テンプレートが含まれています。分類や回帰など、ポイントワイズの予測問題を解決するには、このテンプレートを利用してスタートできます。\n",
        "\n",
        "`tfx template copy` CLI コマンドは、事前定義されたテンプレートファイルをプロジェクトディレクトリにコピーします。\n",
        "\n",
        "```sh\n",
        "tfx template copy \\\n",
        "   --pipeline_name=\"${PIPELINE_NAME}\" \\\n",
        "   --destination_path=\"${PROJECT_DIR}\" \\\n",
        "   --model=taxi\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3PmXatBD42xI"
      },
      "outputs": [],
      "source": [
        "!tfx template copy \\\n",
        "  --pipeline_name={PIPELINE_NAME} \\\n",
        "  --destination_path={PROJECT_DIR} \\\n",
        "  --model=taxi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fyhkhhxY42xK"
      },
      "source": [
        "このノートブックの作業ディレクトリコンテキストをプロジェクトディレクトリに変更します。\n",
        "\n",
        "```bash\n",
        "cd ${PROJECT_DIR}\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y9e_g5rc42xL"
      },
      "outputs": [],
      "source": [
        "%cd {PROJECT_DIR}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rKBRbE342xN"
      },
      "source": [
        "## ステップ 3. コピーしたソースファイルを閲覧する"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdiHik_w42xN"
      },
      "source": [
        "TFX テンプレートは、Python ソースコード、サンプルデータ、パイプラインの出力を分析する Jupyter Notebook など、パイプラインを構築するための基本的なスキャフォールドファイルを提供します。`taxi` テンプレートは、<a>Airflow Tutorial </a>と同じ<em>シカゴタクシー</em>データセットと ML モデルを使用します。\n",
        "\n",
        "Google Colab では、左側のフォルダアイコンをクリックしてファイルを参照できます。この場合、ファイルは `my_pipeline` という名前のプロジェクトディレクトリの下にコピーする必要があります。ディレクトリ名をクリックするとディレクトリの内容が表示され、ファイル名をダブルクリックして開くことができます。\n",
        "\n",
        "ここでは、各 Python ファイルを簡単に紹介します。\n",
        "\n",
        "- pipeline - このディレクトリには、パイプラインの定義が含まれています。\n",
        "    - configs.py — パイプライン ランナーの共通定数を定義します。\n",
        "    - pipeline.py — TFX コンポーネントとパイプラインを定義します。\n",
        "- models - このディレクトリには、機械学習モデルの定義が含まれています。\n",
        "    - `features.py`、`features_test.py` — モデルの特徴を定義します。\n",
        "    - `preprocessing.py`、`preprocessing_test.py` — `tf::Transform`を使用して前処理ジョブを定義します。\n",
        "    - estimator - このディレクトリには、Estimator ベースのモデルが含まれています。\n",
        "        - constants.py — モデルの定数を定義します。\n",
        "        - `model.py`、`model_test.py` — TF estimator を使用して DNN モデルを定義します\n",
        "    - keras - このディレクトリには、Keras ベースのモデルが含まれています。\n",
        "        - constants.py — モデルの定数を定義します。\n",
        "        - `model.py`、`model_test.py` — Keras を使用して DNN モデルを定義します。\n",
        "- `beam_runner.py`、`kubeflow_runner.py` — オーケストレーション エンジンごとにランナーを定義します。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmWtR_Eq42xQ"
      },
      "source": [
        "名前に `_test.py` が含まれているファイルがあることに気が付きましたか。これらはパイプラインの単体テストであり、独自のパイプラインを実装するときに単体テストを追加することをお勧めします。テストファイルのモジュール名に `-m` フラグを指定すると、単体テストを実行できます。通常、モジュール名を取得するには、`.py` 拡張子を削除し、`/` を `.` に置き換えます。以下に例を示します。\n",
        "\n",
        "```bash\n",
        "python -m models.features_test\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H0DzGg-642xQ"
      },
      "outputs": [],
      "source": [
        "!{sys.executable} -m models.features_test\n",
        "!{sys.executable} -m models.keras.model_test\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fK_C6C6g42xS"
      },
      "source": [
        "## ステップ 4. 最初の TFX パイプラインを実行する\n",
        "\n",
        "`pipeline create` コマンドを使用してパイプラインを作成できます。\n",
        "\n",
        "```bash\n",
        "tfx pipeline create --engine=local --pipeline_path=local_runner.py\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D5YikNik42xX"
      },
      "outputs": [],
      "source": [
        "!tfx pipeline create --engine=local --pipeline_path=local_runner.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kvZIn8142xZ"
      },
      "source": [
        "次に、`run create` コマンドを使用して作成されたパイプラインを実行できます。\n",
        "\n",
        "```sh\n",
        "tfx run create --engine=local --pipeline_name=\"${PIPELINE_NAME}\"\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SnTC_Rql42xZ"
      },
      "outputs": [],
      "source": [
        "!tfx run create --engine=local --pipeline_name={PIPELINE_NAME}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GM1G1Efw42xb"
      },
      "source": [
        "成功すると、`Component CsvExampleGen is finished` と表示されます。テンプレートをコピーする場合、パイプラインに含まれるコンポーネントは CsvExampleGen の 1 つだけです。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pfQcePs42xc"
      },
      "source": [
        "## ステップ 5. データ検証用のコンポーネントを追加する\n",
        "\n",
        "このステップでは、`StatisticsGen`、`SchemaGen`、および、`ExampleValidator` などのデータ検証用のコンポーネントを追加します。データ検証については、[Tensorflow データ検証の基礎](https://www.tensorflow.org/tfx/data_validation/get_started)を参照してください。\n",
        "\n",
        "コピーされたパイプライン定義を `pipeline/pipeline.py` で変更します。ローカル環境で作業している場合は、お気に入りのエディタを使用してファイルを編集します。Google Colab で作業している場合は、次を実行します。\n",
        "\n",
        "> **左側のフォルダアイコンをクリックして、 `Files` ビューを開きます**。\n",
        "\n",
        "> **`my_pipeline` をクリックしてディレクトリを開き、`pipeline` ディレクトリをクリックして開き、`pipeline.py` をダブルクリックしてファイルを開きます**。\n",
        "\n",
        "> `StatisticsGen`、`SchemaGen`、および `ExampleValidator` をパイプラインに追加する 3 行を見つけてコメントを外します。（ヒント: `TODO(step 5):` が含まれているコメントを見つけます。\n",
        "\n",
        "> 変更は数秒で自動的に保存されます。 `pipeline.py` の前にある `*` マークがタブタイトルに表示されていないことを確認してください。**Colab にはファイルエディタの保存ボタンやショートカットはありません。ファイルエディタの Python ファイルは、`playground` モードでもランタイム環境に保存できます。**\n",
        "\n",
        "次に、パイプライン定義を変更して既存のパイプラインを更新します。`tfx pipeline update` コマンドを使用してパイプラインを更新し、続いて `tfx run create` コマンドを使用して更新されたパイプラインの新しい実行を作成します。\n",
        "\n",
        "```sh\n",
        "# Update the pipeline\n",
        "tfx pipeline update --engine=local --pipeline_path=local_runner.py\n",
        "# You can run the pipeline the same way.\n",
        "tfx run create --engine local --pipeline_name \"${PIPELINE_NAME}\"\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wMsT-5EX42xc"
      },
      "outputs": [],
      "source": [
        "# Update the pipeline\n",
        "!tfx pipeline update --engine=local --pipeline_path=local_runner.py\n",
        "# You can run the pipeline the same way.\n",
        "!tfx run create --engine local --pipeline_name {PIPELINE_NAME}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUU5_3yR42xe"
      },
      "source": [
        "追加されたコンポーネントからの出力ログを確認できるはずです。パイプラインは、`tfx_pipeline_output/my_pipeline` ディレクトリに出力アーティファクトを作成します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7p7CLDvD42xe"
      },
      "source": [
        "## ステップ 6. トレーニング用のコンポーネントを追加する\n",
        "\n",
        "このステップでは、`Transform`、`Trainer`、`Resolver`、`Evaluator`、および、`Pusher` などのトレーニングとモデル検証用のコンポーネントを追加します。\n",
        "\n",
        "> **`pipeline/pipeline.py`を開きます**。パイプラインに`Transform`、`Trainer`、`Resolver`、`Evaluator`、`Pusher` を追加する 5 行を見つけてコメントを外します（ヒント: `TODO(step 6):` を見つけます）。\n",
        "\n",
        "以前と同様に、変更されたパイプライン定義で既存のパイプラインを更新する必要があります。手順はステップ 5 と同じです。`tfx pipeline update` を使用してパイプラインを更新し、`tfx run create` を使用して実行を作成します。\n",
        "\n",
        "```sh\n",
        "tfx pipeline update --engine=local --pipeline_path=local_runner.py\n",
        "tfx run create --engine local --pipeline_name \"${PIPELINE_NAME}\"\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ik8JbnRq42xf"
      },
      "outputs": [],
      "source": [
        "!tfx pipeline update --engine=local --pipeline_path=local_runner.py\n",
        "!tfx run create --engine local --pipeline_name {PIPELINE_NAME}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3L3NEPanUGY"
      },
      "source": [
        "この実行が正常に終了すると、ローカルオーケストレーターを使用して最初の TFX パイプラインを作成して実行できます。\n",
        "\n",
        "**注意：**パイプライン実行を作成するたびに、入力とパラメーターが変更されていなくても、すべてのコンポーネントが何度も実行されることに気付いたかもしれません。これは時間とリソースの無駄なので、パイプラインキャッシングを使用してこれらの実行をスキップできます。`pipeline.py` の `Pipeline` オブジェクトに `enable_cache=True` を指定することで、キャッシュを有効にできます。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjcMwjov42xh"
      },
      "source": [
        "## ステップ 7.（*オプション*）BigQueryExampleGen を試してみる\n",
        "\n",
        "BigQuery は、サーバーレスでスケーラビリティと費用対効果の高いクラウド データ ウェアハウスです。BigQuery は、TFX のトレーニング サンプルのソースとして使用できます。このステップでは、パイプラインにBigQueryExampleGenを追加します。\n",
        "\n",
        "BigQuery を使用するには、[Google Cloud Platform](https://cloud.google.com/gcp/getting-started) アカウントが必要です。GCP プロジェクトを準備してください。\n",
        "\n",
        "colab 認証ライブラリまたは `gcloud` ユーティリティを使用してプロジェクトにログインします。\n",
        "\n",
        "```sh\n",
        "# You need `gcloud` tool to login in local shell environment.\n",
        "gcloud auth login\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2K7nuHZ4uNXc"
      },
      "outputs": [],
      "source": [
        "if 'google.colab' in sys.modules:\n",
        "  from google.colab import auth\n",
        "  auth.authenticate_user()\n",
        "  print('Authenticated')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Win212lr03zP"
      },
      "source": [
        "TFX を使用して BigQuery リソースにアクセスするには、GCP プロジェクト名を指定する必要があります。`GOOGLE_CLOUD_PROJECT` 環境変数をプロジェクト名に設定します。\n",
        "\n",
        "```sh\n",
        "export GOOGLE_CLOUD_PROJECT=YOUR_PROJECT_NAME_HERE\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vvpw_lGByxSx"
      },
      "outputs": [],
      "source": [
        "# Set your project name below.\n",
        "# WARNING! ENTER your project name before running this cell.\n",
        "%env GOOGLE_CLOUD_PROJECT=YOUR_PROJECT_NAME_HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhClPWEuuOaP"
      },
      "source": [
        "> **`pipeline/pipeline.py` を開きます**。`CsvExampleGen` をコメントアウトし、`BigQueryExampleGen` のインスタンスを作成する行のコメントを外します。また、`create_pipeline` 関数の `query` 引数のコメントも外す必要があります。\n",
        "\n",
        "BigQuery に使用する GCP プロジェクトを再度指定する必要があります。そのためには、パイプラインの作成時に `beam_pipeline_args` に `--project` を設定します。\n",
        "\n",
        "> **`pipeline/configs.py` を開きます**。`BIG_QUERY__WITH_DIRECT_RUNNER_BEAM_PIPELINE_ARGS` と `BIG_QUERY_QUERY` の定義のコメントを外します。このファイルのプロジェクト ID とリージョンの値を GCP プロジェクトの正しい値に置き換える必要があります。\n",
        "\n",
        "> **`local_runner.py` を開きます**。create_pipeline() メソッドの 2 つの引数、`query` と `beam_pipeline_args` のコメントを外します。\n",
        "\n",
        "これで、パイプラインでサンプルソースとして BigQuery を使用する準備が整いました。ステップ 5 と 6 で行ったように、パイプラインを更新して実行を作成します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w8rOdC3r42xi"
      },
      "outputs": [],
      "source": [
        "!tfx pipeline update --engine=local --pipeline_path=local_runner.py\n",
        "!tfx run create --engine local --pipeline_name {PIPELINE_NAME}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxYxNHLN42xo"
      },
      "source": [
        "## 次のステップ: データをパイプラインに取り込む\n",
        "\n",
        "シカゴタクシーデータセットを使用してモデルのパイプラインを作成しました。次に、データをパイプラインに入れます。\n",
        "\n",
        "データは、GCS や BigQuery など、パイプラインがアクセスできる場所であればどこにでも保存できます。データにアクセスするには、パイプライン定義を変更する必要があります。\n",
        "\n",
        "1. データがファイルに保存されている場合は、`kubeflow_runner.py` または `local_runner.py` の `DATA_PATH` を変更し、ファイルの場所に設定します。データが BigQuery に保存されている場合は、`pipeline/configs.py` の `BIG_QUERY_QUERY` を変更して、データを正しくクエリします。\n",
        "2. models/features.pyに特徴量を追加します。\n",
        "3. models/preprocessing.pyを変更して、トレーニング用の入力データを変換します。\n",
        "4. models/keras/model.pyとmodels/keras/constants.pyを変更して、機械学習モデルを記述します。\n",
        "    - Estimator ベースのモデルを使用することもできます。 `pipeline/configs.py` の `RUN_FN` 定数を `models.estimator.model.run_fn` に変更します。\n",
        "\n",
        "詳細については、[トレーナーコンポーネントガイド](https://www.tensorflow.org/tfx/guide/trainer)を参照してください。"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "template_beam.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
