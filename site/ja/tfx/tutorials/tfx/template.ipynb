{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjUA6S30k52h"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "SpNWyqewk8fE"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TyrY7lV0oke"
      },
      "source": [
        "# テンプレートを使用して TFX パイプラインを作成する"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wD2KOXlZuAOj"
      },
      "source": [
        "注意: このチュートリアルは、Google Cloud Vertex AI Workbench で実行することをお勧めします。[このノートブックを Vertex AI Workbenchで起動](https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?q=download_url%3Dhttps%253A%252F%252Fraw.githubusercontent.com%252Ftensorflow%252Ftfx%252Fmaster%252Fdocs%252Ftutorials%252Ftfx%252Ftemplate.ipynb)してください。\n",
        "\n",
        "<div class=\"devsite-table-wrapper\"><table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "<td><a target=\"_blank\" href=\"https://www.tensorflow.org/tfx/tutorials/tfx/template\"> <img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">TensorFlow.org で表示</a></td>\n",
        "<td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/ja/tfx/tutorials/tfx/template.ipynb\"> <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Google Colab で実行</a></td>\n",
        "<td><a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/ja/tfx/tutorials/tfx/template.ipynb\"> <img width=\"32px\" src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">GitHub でソースを表示</a></td>\n",
        "<td><a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/ja/tfx/tutorials/tfx/template.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">ノートブックをダウンロード</a></td>\n",
        "</table></div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLYriYe10okf"
      },
      "source": [
        "## はじめに\n",
        "\n",
        "このドキュメントでは、TFX Python パッケージで提供される*テンプレート*を使用し、TensorFlow Extended (TFX) パイプラインを作成する手順について説明します。命令の多くは Linux シェルコマンドであり、AI Platform Notebooks インスタンスで実行されます。ここでは `!` を使用してこれらのコマンドの呼び出しに対応する Jupyter Notebook コードセルが提供されています。\n",
        "\n",
        "シカゴ市が公開した[タクシー乗降データセット](https://data.cityofchicago.org/Transportation/Taxi-Trips/wrvz-psew)を使用してパイプラインを構築します。このパイプラインをベースラインとして利用して、データセットを使用して独自のパイプラインを構築してみることを強くお勧めします。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxPMeugQ0okg"
      },
      "source": [
        "## ステップ 1. 環境をセットアップする\n",
        "\n",
        "AI Platform Pipeline は、パイプラインを構築するための開発環境と、新しく構築されたパイプラインを実行するための Kubeflow Pipeline クラスターを準備します。\n",
        "\n",
        "**注意：**特定の TensorFlow バージョン、または GPU インスタンスを選択するには、AI Platform Notebook に TensorFlow にプリインストールされたインスタンスを作成します。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-am1yWXt0okh"
      },
      "source": [
        "`kfp` の追加要件を使用して `tfx` python パッケージをインストールします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XNiqq_kN0okj"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "# Use the latest version of pip.\n",
        "!pip install --upgrade pip\n",
        "# Install tfx and kfp Python packages.\n",
        "!pip install --upgrade \"tfx[kfp]<2\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hX1rqpbQ0okp"
      },
      "source": [
        "TFX のバージョンを確認します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XAIoKMNG0okq"
      },
      "outputs": [],
      "source": [
        "!python3 -c \"from tfx import version ; print('TFX version: {}'.format(version.__version__))\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7JLpaXT0okv"
      },
      "source": [
        "AI Platform Pipeline では、TFX は [Kubeflow Pipelines](https://www.kubeflow.org/docs/pipelines/overview/pipelines-overview/) を使用してホストされた Kubernetes 環境で実行されます。\n",
        "\n",
        "Kubeflow パイプラインを使用するためにいくつかの環境変数を設定しましょう。\n",
        "\n",
        "まず、GCP プロジェクト ID を取得します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hw3nsooU0okv"
      },
      "outputs": [],
      "source": [
        "# Read GCP project id from env.\n",
        "shell_output=!gcloud config list --format 'value(core.project)' 2>/dev/null\n",
        "GOOGLE_CLOUD_PROJECT=shell_output[0]\n",
        "%env GOOGLE_CLOUD_PROJECT={GOOGLE_CLOUD_PROJECT}\n",
        "print(\"GCP project ID:\" + GOOGLE_CLOUD_PROJECT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_6r4uzE0oky"
      },
      "source": [
        "また、KFP クラスターにアクセスする必要があります。Google Cloud Console の [AI Platform]&gt; [Pipeline] メニューからアクセスできます。KFP クラスターの「エンドポイント」は、パイプラインダッシュボードの URL から見つけることができます。または、このノートブックを起動した [はじめに] ページの URL から取得することもできます。`ENDPOINT` 環境変数を作成し、それを KFP クラスターエンドポイントに設定します。**ENDPOINT には、URL のホスト名部分のみを含める必要があります。**たとえば、KFP ダッシュボードの URL が `https://1e9deb537390ca22-dot-asia-east1.pipelines.googleusercontent.com/#/start` の場合、ENDPOINT 値は `1e9deb537390ca22-dot-asia-east1.pipelines.googleusercontent.com` になります。\n",
        "\n",
        "> **注意：以下の ENDPOINT 値を設定する必要があります。**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AzqEQORV0oky"
      },
      "outputs": [],
      "source": [
        "# This refers to the KFP cluster endpoint\n",
        "ENDPOINT='' # Enter your ENDPOINT here.\n",
        "if not ENDPOINT:\n",
        "    from absl import logging\n",
        "    logging.error('Set your ENDPOINT in this cell.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6T-KXeA0ok3"
      },
      "source": [
        "現在の GCP プロジェクトで、イメージ名を `tfx-pipeline` と設定します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ztxXOVD0ok4"
      },
      "outputs": [],
      "source": [
        "# Docker image name for the pipeline image.\n",
        "CUSTOM_TFX_IMAGE='gcr.io/' + GOOGLE_CLOUD_PROJECT + '/tfx-pipeline'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOsQbkky0ok7"
      },
      "source": [
        "以上でパイプラインを作成する準備ができました。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cxlbi1QM0ok8"
      },
      "source": [
        "## ステップ 2. 事前定義されたテンプレートをプロジェクトディレクトリにコピーする\n",
        "\n",
        "このステップでは、事前定義されたテンプレートから追加のファイルをコピーして、作業パイプラインプロジェクトディレクトリとファイルを作成します。\n",
        "\n",
        "以下の `PIPELINE_NAME` を変更することで、パイプラインに別の名前を付けることができます。また、これはファイルが配置されるプロジェクトディレクトリ名にもなります。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cIPlt-700ok-"
      },
      "outputs": [],
      "source": [
        "PIPELINE_NAME=\"my_pipeline\"\n",
        "import os\n",
        "PROJECT_DIR=os.path.join(os.path.expanduser(\"~\"),\"imported\",PIPELINE_NAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozHIomcd0olB"
      },
      "source": [
        "TFX には、TFX python パッケージと `taxi` テンプレートが含まれています。分類や回帰など、ポイントワイズの予測問題を解決するには、このテンプレートを利用してスタートできます。\n",
        "\n",
        "`tfx template copy` CLI コマンドは、事前定義されたテンプレートファイルをプロジェクトディレクトリにコピーします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VLXpTTjU0olD"
      },
      "outputs": [],
      "source": [
        "!tfx template copy \\\n",
        "  --pipeline-name={PIPELINE_NAME} \\\n",
        "  --destination-path={PROJECT_DIR} \\\n",
        "  --model=taxi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxOT19QS0olH"
      },
      "source": [
        "このノートブックの作業ディレクトリコンテキストをプロジェクトディレクトリに変更します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6P-HljcU0olI"
      },
      "outputs": [],
      "source": [
        "%cd {PROJECT_DIR}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1tEYUQxH0olO"
      },
      "source": [
        "> 注意: 作成されたプロジェクトディレクトリをクリックして、左側の `File Browser` のディレクトリを変更することを忘れないでください。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzT2PFrN0olQ"
      },
      "source": [
        "## ステップ 3. コピーしたソースファイルを閲覧する\n",
        "\n",
        "TFX テンプレートは、Python ソースコード、サンプルデータ、パイプラインの出力を分析する Jupyter Notebook など、パイプラインを構築するための基本的なスキャフォールドファイルを提供します。`taxi` テンプレートは、[Airflow Tutorial ](https://www.tensorflow.org/tfx/tutorials/tfx/airflow_workshop)と同じ*シカゴタクシー*データセットと ML モデルを使用します。\n",
        "\n",
        "ここでは、各 Python ファイルを簡単に紹介します。\n",
        "\n",
        "- `pipeline` - このディレクトリには、パイプラインの定義が含まれています。\n",
        "    - `configs.py` — パイプライン ランナーの共通定数を定義します。\n",
        "    - `pipeline.py` — TFX コンポーネントとパイプラインを定義します。\n",
        "- `models` - このディレクトリには、機械学習モデルの定義が含まれています。\n",
        "    - `features.py`、`features_test.py` — モデルの特徴を定義します。\n",
        "    - `preprocessing.py`、`preprocessing_test.py` — `tf::Transform`を使用して前処理ジョブを定義します。\n",
        "    - `estimator` - このディレクトリには、Estimator ベースのモデルが含まれています。\n",
        "        - `constants.py` — モデルの定数を定義します。\n",
        "        - `model.py`、`model_test.py` — TF estimator を使用して DNN モデルを定義します\n",
        "    - `keras` - このディレクトリには、Keras ベースのモデルが含まれています。\n",
        "        - `constants.py` — モデルの定数を定義します。\n",
        "        - `model.py`、`model_test.py` — Keras を使用して DNN モデルを定義します。\n",
        "- `beam_runner.py`、`kubeflow_runner.py` — オーケストレーション エンジンごとにランナーを定義します。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROwHAsDK0olT"
      },
      "source": [
        "名前に `_test.py` が含まれているファイルがあることに気が付きましたか。これらはパイプラインの単体テストであり、独自のパイプラインを実装するときに単体テストを追加することをお勧めします。テストファイルのモジュール名に `-m` フラグを指定すると、単体テストを実行できます。通常、モジュール名を取得するには、`.py` 拡張子を削除し、`/` を `.` に置き換えます。以下に例を示します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M0cMdE2Z0olU"
      },
      "outputs": [],
      "source": [
        "!{sys.executable} -m models.features_test\n",
        "!{sys.executable} -m models.keras.model_test\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tO9Jhplo0olX"
      },
      "source": [
        "## ステップ 4. 最初の TFX パイプラインを実行する\n",
        "\n",
        "TFX パイプラインのコンポーネントは、実行ごとに出力を [ML メタデータアーティファクト](https://www.tensorflow.org/tfx/guide/mlmd)として生成するため、それらをどこかに保存する必要があります。KFP クラスターがアクセスできる任意のストレージを使用できます。この例では、Google Cloud Storage (GCS) を使用します。デフォルトの GCS バケットが自動的に作成されているはずです。その名前は `<your-project-id>-kubeflowpipelines-default` になります。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zr-RjyPWTHdH"
      },
      "source": [
        "サンプルデータを GCS バケットにアップロードして、後でパイプラインで使用できるようにします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gW-dSHW-TSdc"
      },
      "outputs": [],
      "source": [
        "!gsutil cp data/data.csv gs://{GOOGLE_CLOUD_PROJECT}-kubeflowpipelines-default/tfx-template/data/taxi/data.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wc54hDZu0ole"
      },
      "source": [
        "`tfx pipeline create` コマンドを使用して TFX パイプラインを作成します。\n",
        "\n",
        "> 注意: KFP のパイプラインを作成するときは、パイプラインの実行に使用されるコンテナイメージが必要です。そして、`skaffold` がイメージを構築します。skaffold は Docker ハブからベースイメージをプルするため、最初にイメージをビルドするときは 5〜10 分かかりますが、2 回目以降のビルドにはそれほど時間がかかりません。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kOU7zQof0olf"
      },
      "outputs": [],
      "source": [
        "!tfx pipeline create  --pipeline-path=kubeflow_runner.py --endpoint={ENDPOINT} \\\n",
        "--build-image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmA6___Y0olh"
      },
      "source": [
        "パイプラインの作成中に、Docker イメージをビルドするための `Dockerfile` が生成されます。これらのファイルを他のソースファイルと一緒にソース管理システム (git など) に追加することを忘れないでください。\n",
        "\n",
        "注意: `airflow` がインストールされておらず、`--engine` が指定されていない場合、`kubeflow` がオーケストレーションエンジンとして自動的に選択されます。\n",
        "\n",
        "次に、`tfx run create` コマンドを使用して、新しく作成されたパイプラインで実行を開始します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cKSjVVsa0oli"
      },
      "outputs": [],
      "source": [
        "!tfx run create --pipeline-name={PIPELINE_NAME} --endpoint={ENDPOINT}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pg0VxvUC0olk"
      },
      "source": [
        "または、KFP ダッシュボードでパイプラインを実行することもできます。新しい実行は、KFP ダッシュボードの[試験]の下に一覧表示されます。試験をクリックすると、進行状況を監視し、実行中に作成されたアーティファクトを視覚化できます。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLN4ges90oll"
      },
      "source": [
        "ただし、KFP ダッシュボードにアクセスすることをお勧めします。KFP ダッシュボードには、Google Cloud Console の Cloud AI Platform Pipelines メニューからアクセスできます。ダッシュボードにアクセスすると、パイプラインを見つけて、パイプラインに関する豊富な情報にアクセスできます。たとえば、*試験*メニューで実行を見つけることができ、試験で実行を開くと、*アーティファクト*メニューでパイプラインからすべてのアーティファクトを表示できます。\n",
        "\n",
        "> 注意: パイプラインの実行に失敗した場合は、KFP ダッシュボードの[試験]タブで各 TFX コンポーネントの詳細なログを確認できます。\n",
        "\n",
        "失敗の主な原因の 1 つは、許可関連の問題です。KFP クラスタに Google Cloud API へのアクセス権限があることを確認してください。これは、[GCP で KFP クラスタを作成するときに](https://cloud.google.com/ai-platform/pipelines/docs/setting-up)構成します。[GCP でのトラブルシューティング ドキュメント](https://cloud.google.com/ai-platform/pipelines/docs/troubleshooting)を参照してください。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYH8Y2KB0olm"
      },
      "source": [
        "## ステップ 5. データ検証用のコンポーネントを追加する\n",
        "\n",
        "このステップでは、`StatisticsGen`、`SchemaGen`、および、`ExampleValidator` などのデータ検証用のコンポーネントを追加します。データ検証については、[Tensorflow データ検証の基礎](https://www.tensorflow.org/tfx/data_validation/get_started)を参照してください。\n",
        "\n",
        "> **ダブルクリックしてディレクトリを `pipeline` に変更し、もう一度ダブルクリックして  `pipeline.py`を開きます**。`StatisticsGen`、`SchemaGen` および `ExampleValidator` をパイプラインに追加する 3 行を見つけてコメントを外します。（ヒント：`TODO(step 5):` を含むコメントを検索します）。編集後は、必ず `pipeline.py` を保存してください。\n",
        "\n",
        "次に、パイプライン定義を変更して既存のパイプラインを更新します。`tfx pipeline update` コマンドを使用してパイプラインを更新し、続いて `tfx run create` コマンドを使用して更新されたパイプラインの新しい実行を作成します。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VE-Pqvto0olm"
      },
      "outputs": [],
      "source": [
        "# Update the pipeline\n",
        "!tfx pipeline update \\\n",
        "--pipeline-path=kubeflow_runner.py \\\n",
        "--endpoint={ENDPOINT}\n",
        "# You can run the pipeline the same way.\n",
        "!tfx run create --pipeline-name {PIPELINE_NAME} --endpoint={ENDPOINT}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8q1ZYEHX0olo"
      },
      "source": [
        "### パイプライン出力を確認する\n",
        "\n",
        "KFP ダッシュボードにアクセスし、パイプライン実行のページでパイプライン出力を見つけます。左側の*{nbsp}[試験] *タブをクリックし、[試験] ページの*{nbsp}[すべての実行] *をクリックします。パイプラインの名前の実行が表示されるはずです。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWMBXU510olp"
      },
      "source": [
        "## ステップ 6. トレーニング用のコンポーネントを追加する\n",
        "\n",
        "このステップでは、`Transform`、`Trainer`、`Resolver`、`Evaluator`、および、`Pusher` などのトレーニングとモデル検証用のコンポーネントを追加します。\n",
        "\n",
        "> **ダブルクリックして `pipeline.py` を開きます**。`Transform`、`Trainer`、`Resolver`、`Evaluator` および `Pusher` をパイプラインに追加する 5 行を見つけてコメントを外します (ヒント: `TODO(step 6):` を見つけます。)\n",
        "\n",
        "以前と同様に、変更されたパイプライン定義で既存のパイプラインを更新する必要があります。手順はステップ 5 と同じです。`tfx pipeline update` を使用してパイプラインを更新し、`tfx run create` を使用して実行を作成します。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VQDNitkH0olq"
      },
      "outputs": [],
      "source": [
        "!tfx pipeline update \\\n",
        "--pipeline-path=kubeflow_runner.py \\\n",
        "--endpoint={ENDPOINT}\n",
        "!tfx run create --pipeline-name {PIPELINE_NAME} --endpoint={ENDPOINT}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksWfVQUnMYCX"
      },
      "source": [
        "この実行が正常に終了すると、AI プラットフォームパイプラインで最初の TFX パイプラインが作成され、実行されます。\n",
        "\n",
        "**注意：**モデルコードを変更した場合は、コンテナイメージも再構築する必要があります。`pipeline update` コマンドの `--build-image` フラグを使用して再構築をトリガーできます。\n",
        "\n",
        "**注意：**パイプライン実行を作成するたびに、入力とパラメーターが変更されていなくても、すべてのコンポーネントが何度も実行されることに気付いたかもしれません。これは時間とリソースの無駄なので、パイプラインキャッシングを使用してこれらの実行をスキップできます。`pipeline.py` の `Pipeline` オブジェクトに `enable_cache=True` を指定することで、キャッシュを有効にできます。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkF7klWi0ols"
      },
      "source": [
        "## ステップ 7. (*オプション*) BigQueryExampleGen を試してみる\n",
        "\n",
        "[BigQuery](https://cloud.google.com/bigquery) は、サーバーレスでスケーラビリティと費用対効果の高いクラウド データ ウェアハウスです。BigQuery は、TFX のトレーニング サンプルのソースとして使用できます。このステップでは、パイプラインに `BigQueryExampleGen` を追加します。\n",
        "\n",
        "> **`pipeline.py` をダブルクリックして開きます**。`CsvExampleGen` をコメントアウトし、`BigQuery Example Gen` のインスタンスを作成する行のコメントを外します。また、`create_pipeline` 関数の`query` 引数のコメントも外す必要があります。\n",
        "\n",
        "BigQuery に使用する GCP プロジェクトを指定する必要があります。そのためには、パイプラインの作成時に `beam_pipeline_args` に `--project` を設定します。\n",
        "\n",
        "> **`configs.py`** をダブルクリックして開きます。`BIG_QUERY_WITH_DIRECT_RUNNER_BEAM_PIPELINE_ARGS` と `BIG_QUERY_QUERY` の定義のコメントを外します。このファイルのリージョンの値を、GCP プロジェクトの正しい値に置き換えます。\n",
        "\n",
        "> **注意: 続行する前に、GCP リージョンを `configs.py` ファイルに設定する必要があります。**\n",
        "\n",
        "> **ディレクトリを 1 レベル上に変更します。**ファイル リストの上にあるディレクトリの名前をクリックします。ディレクトリ名はパイプライン名で、パイプライン名を変更しなかった場合は `my_pipeline` です。\n",
        "\n",
        "> **ダブルクリックして `kubeflow_runner.py`** を開きます。`create_pipeline` 関数の 2 つの引数  `query` と `beam_pipeline_args` のコメントを外します。\n",
        "\n",
        "パイプラインで BigQuery をサンプル ソースとして使用する準備ができました。前と同じようにパイプラインを更新し、ステップ 5 と 6 で行ったように新しい実行を作成します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1sD3NxB60olt"
      },
      "outputs": [],
      "source": [
        "!tfx pipeline update \\\n",
        "--pipeline-path=kubeflow_runner.py \\\n",
        "--endpoint={ENDPOINT}\n",
        "!tfx run create --pipeline-name {PIPELINE_NAME} --endpoint={ENDPOINT}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LpA2R6Lu0olv"
      },
      "source": [
        "## ステップ 8. (*オプション*) KFP で Dataflow を試してみる\n",
        "\n",
        "いくつかの [TFX コンポーネントは Apache Beam を使用](https://www.tensorflow.org/tfx/guide/beam)してデータ並列パイプラインを実装します。そのため、[Google Cloud Dataflow](https://cloud.google.com/dataflow/) を使用してデータ処理ワークロードを分散できます。このステップでは、Apache Beam のデータ処理バックエンドとして Dataflow を使用するように Kubeflow オーケストレーターを設定します。\n",
        "\n",
        "> **`pipeline` をダブルクリックしてディレクトリを変更し、`configs.py`** をダブルクリックして開きます。`GOOGLE_CLOUD_REGION` と `DATAFLOW_BEAM_PIPELINE_ARGS` の定義のコメントを外します。\n",
        "\n",
        "> **ディレクトリを 1 レベル上に変更します。**ファイル リストの上にあるディレクトリの名前をクリックします。ディレクトリ名はパイプライン名で、変更しなかった場合は `my_pipeline` です。\n",
        "\n",
        "> **`kubeflow_runner.py`** をダブルクリックして開きます。`beam_pipeline_args` のコメントを外します。（ステップ 7 で追加した最新の`beam_pipeline_args` も必ずコメントアウトしてください）。\n",
        "\n",
        "以上で、パイプラインで Dataflow を使用する準備が整いました。ステップ 5 と 6 で行ったように、パイプラインを更新し、実行を作成します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H3HVPcKi0olw"
      },
      "outputs": [],
      "source": [
        "!tfx pipeline update \\\n",
        "--pipeline-path=kubeflow_runner.py \\\n",
        "--endpoint={ENDPOINT}\n",
        "!tfx run create --pipeline-name {PIPELINE_NAME} --endpoint={ENDPOINT}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uxDY13N0oly"
      },
      "source": [
        "Cloud Console の Dataflow で Dataflow のジョブを見つけることができます。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJOmh1RY0olz"
      },
      "source": [
        "## ステップ 9. (*オプション*) TKFP で Cloud AI Platform のトレーニングと予測を試してみる\n",
        "\n",
        "TFX は、[トレーニングと予測のための Cloud AI Platform](https://cloud.google.com/ai-platform/) など、いくつかのマネージド GCP サービスと相互運用します。機械学習モデルをトレーニングするためのマネージド サービスである Cloud AI Platform Training を使用するように `Trainer` コンポーネントを設定できます。さらに、モデルが構築され、サービングする準備ができたら、サービングするためにモデルを Cloud AI Platform Prediction に *push* できます。このステップでは、Cloud AI Platform サービスを使用するように `Trainer`  コンポーネントと`Pusher` コンポーネントを設定します。\n",
        "\n",
        "> ファイルを編集する前に、最初に *AI Platform Training と Prediction API* を有効にする必要がある場合があります。\n",
        "\n",
        "> **`pipeline` をダブルクリックしてディレクトリを変更し、ダブルクリックして `configs.py`** を開きます。`GOOGLE_CLOUD_REGION`、`GCP_AI_PLATFORM_TRAINING_ARGS`、`GCP_AI_PLATFORM_SERVING_ARGS` の定義のコメントを外します。カスタム ビルドのコンテナ イメージを使用して Cloud AI Platform Training でモデルをトレーニングするため、`GCP_AI_PLATFORM_TRAINING_ARGS` の `masterConfig.imageUri` を上記の `CUSTOM_TFX_IMAGE` と同じ値に設定する必要があります。\n",
        "\n",
        "> **ディレクトリを 1 レベル上に変更し、ダブルクリックして `kubeflow_runner.py`** を開きます。`ai_platform_training_args` と `ai_platform_serving_args` のコメントを外します。\n",
        "\n",
        "ステップ  5 と 6 で行ったように、パイプラインを更新し、実行を作成します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yxOjhBmG0ol0"
      },
      "outputs": [],
      "source": [
        "!tfx pipeline update \\\n",
        "--pipeline-path=kubeflow_runner.py \\\n",
        "--endpoint={ENDPOINT}\n",
        "!tfx run create --pipeline-name {PIPELINE_NAME} --endpoint={ENDPOINT}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkoIMUfj0ol2"
      },
      "source": [
        "トレーニング ジョブは [Cloud AI Platform ジョブ](https://console.cloud.google.com/ai-platform/jobs)で見つけることができます。パイプラインが正常に完了した場合、[Cloud AI Platform モデル](https://console.cloud.google.com/ai-platform/models)でモデルを見つけることができます。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DRTFdTy0ol3"
      },
      "source": [
        "## ステップ 10. データをパイプラインに取り込む\n",
        "\n",
        "シカゴタクシーデータセットを使用してモデルのパイプラインを作成しました。次に、データをパイプラインに入れます。\n",
        "\n",
        "データは、GCS や BigQuery など、パイプラインがアクセスできる場所であればどこにでも保存できます。データにアクセスするには、パイプライン定義を変更する必要があります。\n",
        "\n",
        "1. データがファイルに保存されている場合は、`kubeflow_runner.py` または `local_runner.py` の `DATA_PATH` を変更し、ファイルの場所に設定します。データが BigQuery に保存されている場合は、`pipeline/configs.py` の `BIG_QUERY_QUERY` を変更して、データを正しくクエリします。\n",
        "2. `models`/<code>features.py</code> に特徴量を追加します。\n",
        "3. `models`/<code>preprocessing.py</code> を変更して、<a>トレーニング用の入力データを変換</a>します。\n",
        "4. `models/keras/model.py` と`models/keras/constants.py` を変更して、[機械学習モデルを記述](https://www.tensorflow.org/tfx/guide/trainer)します。\n",
        "    - Estimator ベースのモデルを使用することもできます。 `pipeline/configs.py` の `RUN_FN` 定数を `models.estimator.model.run_fn` に変更します。\n",
        "\n",
        "詳細については、[トレーナーコンポーネントガイド](https://www.tensorflow.org/tfx/guide/trainer)を参照してください。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20KRGsPX0ol3"
      },
      "source": [
        "## クリーンアップ\n",
        "\n",
        "このプロジェクトで使用されているすべての Google Cloud リソースをクリーンアップするには、チュートリアルで使用した [Google Cloud プロジェクトを削除](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects)します。\n",
        "\n",
        "または、各コンソールにアクセスして、個々のリソースをクリーンアップすることもできます。\n",
        "\n",
        "- [Google Cloud Storage](https://console.cloud.google.com/storage)\n",
        "- [Google Container Registry](https://console.cloud.google.com/gcr)\n",
        "- [Google Kubernetes Engine](https://console.cloud.google.com/kubernetes)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "template.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
