{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tghWegsjhpkt"
      },
      "source": [
        "##### Copyright &copy; 2020 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "rSGJWC5biBiG"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YuSYVbwEYNHw"
      },
      "source": [
        "# TensorFlow データ検証\n",
        "\n",
        "***TensorFlow Extended の主要コンポーネントの例***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLsMb4vqY244"
      },
      "source": [
        "注意：この例は、Jupyter スタイルのノートブックで今すぐ実行できます。セットアップは必要ありません。「Google Colab で実行」をクリックするだけです。\n",
        "\n",
        "<div class=\"devsite-table-wrapper\"><table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "<td><a target=\"_blank\" href=\"https://www.tensorflow.org/tfx/tutorials/data_validation/tfdv_basic\"> <img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">TensorFlow.org で表示</a></td>\n",
        "<td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/ja/tfx/tutorials/data_validation/tfdv_basic.ipynb\"> <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Google Colab で実行</a></td>\n",
        "<td><a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/ja/tfx/tutorials/data_validation/tfdv_basic.ipynb\"> <img width=\"32px\" src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">GitHub でソースを表示</a></td>\n",
        "</table></div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPt5BHTwy_0F"
      },
      "source": [
        "このサンプルの colab ノートブックは、TensorFlow Data Validation (TFDV) を使用してデータセットを調査および視覚化する方法を示しています。これには、記述統計の確認、スキーマの推測、異常のチェックと修正、データセットのドリフトとスキューのチェックが含まれています。実稼働環境のパイプラインでデータセットが時間の経過とともにどのように変化するかなど、データセットの特性を理解することが重要です。また、データの異常を探し、トレーニング、評価、およびサービングデータセットを比較して、それらが一貫していることを確認することも重要です。\n",
        "\n",
        "シカゴ市からリリースされた[タクシー乗車データセット](https://data.cityofchicago.org/Transportation/Taxi-Trips/wrvz-psew)のデータを使用します。\n",
        "\n",
        "注意：このWeb サイトは、シカゴ市の公式 Web サイト www.cityofchicago.org で公開されたデータを変更して使用するアプリケーションを提供します。シカゴ市は、この Web サイトで提供されるデータの内容、正確性、適時性、または完全性について一切の表明を行いません。この Web サイトで提供されるデータは、随時変更される可能性があります。かかる Web サイトで提供されるデータはユーザーの自己責任で利用されるものとします。\n",
        "\n",
        "データセットの詳細については、[Google BigQuery](https://cloud.google.com/bigquery/) を[参照](https://cloud.google.com/bigquery/public-data/chicago-taxi)してください。[BigQuery UI](https://bigquery.cloud.google.com/dataset/bigquery-public-data:chicago_taxi_trips) でデータセット全体をご確認ください。\n",
        "\n",
        "キーポイント：モデラーおよび開発者の皆さんは、このデータがどのように使用されるか、モデルの予測が引き起こす可能性のある潜在的メリット・デメリットについて考えてください。このようなモデルは、社会的バイアスと格差を拡大する可能性があります。特徴は解決しようとする問題に関連していますか、それともバイアスを導入しますか？ 詳細については、[機械学習における公平性](https://developers.google.com/machine-learning/fairness-overview/)についてご一読ください。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fnm6Mj3vTGLm"
      },
      "source": [
        "データセットの列は次のとおりです。\n",
        "\n",
        "<table>\n",
        "<tr>\n",
        "<td>pickup_community_area</td>\n",
        "<td>fare</td>\n",
        "<td>trip_start_month</td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>trip_start_hour</td>\n",
        "<td>trip_start_day</td>\n",
        "<td>trip_start_timestamp</td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>pickup_latitude</td>\n",
        "<td>pickup_longitude</td>\n",
        "<td>dropoff_latitude</td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>dropoff_longitude</td>\n",
        "<td>trip_miles</td>\n",
        "<td>pickup_census_tract</td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>dropoff_census_tract</td>\n",
        "<td>payment_type</td>\n",
        "<td>company</td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>trip_seconds</td>\n",
        "<td>dropoff_community_area</td>\n",
        "<td>tips</td>\n",
        "</tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsYC3O-DnYro"
      },
      "source": [
        "### Pip のアップグレード\n",
        "\n",
        "ローカルで実行する場合にシステム Pip をアップグレードしないようにするには、Colab で実行していることを確認してください。もちろん、ローカルシステムは個別にアップグレードできます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b0ISmRq3nY3-"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  import colab\n",
        "  !pip install --upgrade pip\n",
        "except:\n",
        "  pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRvh2GMUnZC-"
      },
      "source": [
        "### TensorFlow のインストール\n",
        "\n",
        "**注意：Google Colab では、パッケージが更新されるため、このセルを初めて実行するときに、ランタイムを再起動（[ランタイム] &gt; [ランタイムの再起動...]）する必要があります。**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zDDaJgzQnZNe"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow==2.2.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RptgLn2RYuK3"
      },
      "source": [
        "## Python バージョンのチェック"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RwDCQCtkdI9e"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "# Confirm that we're using Python 3\n",
        "assert sys.version_info.major is 3, 'Oops, not running Python 3. Use Runtime > Change runtime type'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qBFH1ARcSNk"
      },
      "source": [
        "## TFDV のインストール\n",
        "\n",
        "これにより、すべての依存関係が取得されます。これには1分かかります。互換性のない依存関係バージョンに関する警告またはエラーは無視します。\n",
        "\n",
        "**注意：Google Colab では、パッケージが更新されるため、このセルを初めて実行するときに、ランタイムを再起動（[ランタイム] &gt; [ランタイムの再起動...]）する必要があります。**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hPJsE5Gkdp8m"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "print('Installing TensorFlow Data Validation')\n",
        "!pip install -q tensorflow_data_validation[visualization]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_NXX5GaSiZx"
      },
      "source": [
        "## ランタイムを再起動しましたか？\n",
        "\n",
        "Google Colab を使用している場合は、上記のセルを初めて実行するときにランタイムを再起動（[ランタイム]　&gt; [ランタイムの再起動...]）する必要があります。これは、Colab がパッケージを読み込むために必要です。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5MizoHg1DRlK"
      },
      "source": [
        "## ファイルを読み込む\n",
        "\n",
        "Google Cloud Storage からデータセットをダウンロードします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x5gfFiTeDa6Y"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tempfile, urllib, zipfile\n",
        "\n",
        "# Set up some globals for our file paths\n",
        "BASE_DIR = tempfile.mkdtemp()\n",
        "DATA_DIR = os.path.join(BASE_DIR, 'data')\n",
        "OUTPUT_DIR = os.path.join(BASE_DIR, 'chicago_taxi_output')\n",
        "TRAIN_DATA = os.path.join(DATA_DIR, 'train', 'data.csv')\n",
        "EVAL_DATA = os.path.join(DATA_DIR, 'eval', 'data.csv')\n",
        "SERVING_DATA = os.path.join(DATA_DIR, 'serving', 'data.csv')\n",
        "\n",
        "# Download the zip file from GCP and unzip it\n",
        "zip, headers = urllib.request.urlretrieve('https://storage.googleapis.com/artifacts.tfx-oss-public.appspot.com/datasets/chicago_data.zip')\n",
        "zipfile.ZipFile(zip).extractall(BASE_DIR)\n",
        "zipfile.ZipFile(zip).close()\n",
        "\n",
        "print(\"Here's what we downloaded:\")\n",
        "!ls -R {os.path.join(BASE_DIR, 'data')}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFXK2AdpSpv0"
      },
      "source": [
        "### バージョンのチェック"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F5rPatTDSCHB"
      },
      "outputs": [],
      "source": [
        "import tensorflow_data_validation as tfdv\n",
        "print('TFDV version: {}'.format(tfdv.version.__version__))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0sFmiTbT8-x"
      },
      "source": [
        "## 統計を計算し、視覚化する\n",
        "\n",
        "まず、[`tfdv.generate_statistics_from_csv`](https://www.tensorflow.org/tfx/data_validation/api_docs/python/tfdv/generate_statistics_from_csv)を使用して、トレーニングデータの統計を計算します。（警告は無視します）\n",
        "\n",
        "TFDV は、[記述統計](https://github.com/tensorflow/metadata/blob/v0.6.0/tensorflow_metadata/proto/v0/statistics.proto)を計算し、存在する特徴やそれらの値分布の形などを含むデータの概要を迅速に提供します。\n",
        "\n",
        "内部的には、TFDV は[Apache Beam](https://beam.apache.org/)のデータ並列処理フレームワークを使用して、大規模なデータセットの統計計算をスケーリングします。アプリケーションを TFDV とより深く統合させるには（データ生成パイプラインの最後に統計生成をアタッチする場合など）、API は統計生成用の Beam PTransform も公開します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EE481oMbT-H0"
      },
      "outputs": [],
      "source": [
        "train_stats = tfdv.generate_statistics_from_csv(data_location=TRAIN_DATA)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhXQSxJ2dB_6"
      },
      "source": [
        "次に、[`tfdv.visualize_statistics`](https://www.tensorflow.org/tfx/data_validation/api_docs/python/tfdv/visualize_statistics)を使用します。これは、[ファセット](https://pair-code.github.io/facets/)を使用して、トレーニングデータの簡潔な視覚化を作成します。\n",
        "\n",
        "- 数値の特徴とカテゴリの特徴が別々に視覚化され、各特徴の分布を示すグラフが表示されます。\n",
        "- 値が欠落しているかゼロの特徴は、それらの特徴の例に問題がある可能性があることを視覚的に示すために、パーセンテージが赤で表示されることに注意してください。パーセンテージは、その特徴の値が欠落しているかゼロである例のパーセンテージです。\n",
        "- `pickup_census_tract`の値を持つ例がないことに注意してください。これは次元削減の機会です。\n",
        "- グラフの上にある[展開]をクリックして、表示を変更してみてください\n",
        "- グラフのバーにカーソルを合わせて、バケットの範囲とカウントを表示してみてください\n",
        "- 対数目盛と線形目盛を切り替えてみてください。対数目盛が`payment_type`カテゴリカル特徴の詳細をどのように示しているかに注目してください。\n",
        "- [表示するグラフ]メニューから[分位数]を選択し、マーカーにカーソルを合わせて分位数のパーセンテージを表示してみてください"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U3tUKgh7Up3x"
      },
      "outputs": [],
      "source": [
        "tfdv.visualize_statistics(train_stats)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVR02-y4V0uM"
      },
      "source": [
        "## スキーマを推測する\n",
        "\n",
        "次に、[`tfdv.infer_schema`](https://www.tensorflow.org/tfx/data_validation/api_docs/python/tfdv/infer_schema)を使用してデータのスキーマを作成しましょう。<br>スキーマは、機械学習に関連するデータの制約を定義します。制約の例には、各特徴のデータ型（数値、または、カテゴリ）、またはデータ内に存在する頻度が含まれます。カテゴリカル特徴の場合、スキーマはドメイン（許容値のリスト）も定義します。スキーマの作成は、特に多くの特徴を備えたデータセットの場合、手間のかかる作業になる可能性があるため、TFDV は、記述統計に基づいてスキーマの初期バージョンを生成する方法を提供します。\n",
        "\n",
        "実稼働環境のパイプラインの残りの部分は、TFDV が生成するスキーマが正しいことに依存するため、スキーマを正しく作成することが重要です。スキーマはデータのドキュメントも提供するため、異なる開発者が同じデータで作業する場合に役立ちます。[`tfdv.display_schema`](https://www.tensorflow.org/tfx/data_validation/api_docs/python/tfdv/display_schema)を使用して、推測されたスキーマを表示し、確認します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6LLkRJThVr9m"
      },
      "outputs": [],
      "source": [
        "schema = tfdv.infer_schema(statistics=train_stats)\n",
        "tfdv.display_schema(schema=schema)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVa3EXE8WEDE"
      },
      "source": [
        "## 評価データにエラーがないか確認します\n",
        "\n",
        "これまでは、トレーニングデータのみを見てきましたが、評価データがトレーニングデータと一致していること（同じスキーマを使用していることなど）を確認することが重要です。また、評価データに、トレーニングデータとほぼ同じ数値の範囲の特徴の例が含まれていることも重要です。カテゴリカル特徴でも同じです。そうでない場合、損失面の一部を評価しなかったため、評価中に特定されないトレーニングの問題が発生する可能性があります。\n",
        "\n",
        "- 各特徴には、トレーニングデータセットと評価データセットの両方の統計が含まれていることに注意してください。\n",
        "- チャートにトレーニングデータセットと評価データセットの両方がオーバーレイされ、それらを簡単に比較できるようになっています。\n",
        "- チャートにはパーセンテージビューが含まれています。これは、ログまたはデフォルトの線形スケールと組み合わせることができます。\n",
        "- `trip_miles`の平均と中央値は、トレーニングデータセットと評価データセットで異なることに注意してください。これは問題を引き起こすでしょうか？\n",
        "- 最大`tips`は、トレーニングデータセットと評価データセットで大きく異なります。これは問題を引き起こすでしょうか？\n",
        "- 数値特徴チャートの展開をクリックし、対数スケールを選択します。`trip_seconds`特徴を確認し、最大値の違いに注目してください。評価は損失面の一部を見逃すでしょうか？"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j_P0RLYlV6XG"
      },
      "outputs": [],
      "source": [
        "# Compute stats for evaluation data\n",
        "eval_stats = tfdv.generate_statistics_from_csv(data_location=EVAL_DATA)\n",
        "\n",
        "# Compare evaluation data with training data\n",
        "tfdv.visualize_statistics(lhs_statistics=eval_stats, rhs_statistics=train_stats,\n",
        "                          lhs_name='EVAL_DATASET', rhs_name='TRAIN_DATASET')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycRRa4leHp84"
      },
      "source": [
        "## 評価の異常をチェックします\n",
        "\n",
        "評価データセットは、トレーニングデータセットのスキーマと一致していますか？これは、許容値の範囲を特定するカテゴリカル特徴にとって特に重要です。\n",
        "\n",
        "キーポイント：トレーニングデータセットにないカテゴリカル特徴値を持つデータを使用して評価しようとするとどうなるでしょうか？トレーニングデータセットの範囲外の数値特徴はどうなるでしょうか？"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T7uGVeL2WOam"
      },
      "outputs": [],
      "source": [
        "# Check eval data for errors by validating the eval data stats using the previously inferred schema.\n",
        "anomalies = tfdv.validate_statistics(statistics=eval_stats, schema=schema)\n",
        "tfdv.display_anomalies(anomalies)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzxx1gBpJIBa"
      },
      "source": [
        "## スキーマの評価の異常を修正する\n",
        "\n",
        "評価データには`company`の新しい値がいくつかありますが、トレーニングデータにはありません。また、`payment_type`の新しい値もあります。これらは異常と見なす必要がありますが、それらに対して何をするかは、データに関するドメイン知識によって異なります。異常が本当にデータエラーを示している場合は、基になるデータを修正する必要があります。それ以外の場合は、スキーマを更新して、評価データセットに値を含めることができます。\n",
        "\n",
        "キーポイント：これらの問題を修正しなかった場合、評価結果にどのような影響があるでしょうか？\n",
        "\n",
        "評価データセットを変更しない限り、すべてを修正することはできませんが、受け入れやすいスキーマ内のものを修正することはできます。例えば、特定の特徴の異常とは何かという見方を見直したり、カテゴリカル特徴の欠落値を含めるようにスキーマを更新したりできます。TFDV を利用することにより、修正が必要なものを見つけることができます。\n",
        "\n",
        "これらの修正を行ってから、もう一度確認します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "legN2nXLWZAc"
      },
      "outputs": [],
      "source": [
        "# Relax the minimum fraction of values that must come from the domain for feature company.\n",
        "company = tfdv.get_feature(schema, 'company')\n",
        "company.distribution_constraints.min_domain_mass = 0.9\n",
        "\n",
        "# Add new value to the domain of feature payment_type.\n",
        "payment_type_domain = tfdv.get_domain(schema, 'payment_type')\n",
        "payment_type_domain.value.append('Prcard')\n",
        "\n",
        "# Validate eval stats after updating the schema \n",
        "updated_anomalies = tfdv.validate_statistics(eval_stats, schema)\n",
        "tfdv.display_anomalies(updated_anomalies)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNo72YP9LN98"
      },
      "source": [
        "TFDV を使用してトレーニング データと評価データが一致することを確認しました。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZ1P4ucHJj5o"
      },
      "source": [
        "## スキーマの環境変数"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qb179jczJppA"
      },
      "source": [
        "また、この例では「サービング」データセットを分割しているので、それも確認する必要があります。デフォルトでは、パイプライン内のすべてのデータセットは同じスキーマを使用する必要がありますが、多くの場合、例外があります。たとえば、教師あり学習では、データセットにラベルを含める必要がありますが、推論用のモデルを提供する場合、ラベルは含まれません。場合によっては、スキーマをわずかに変更する必要があります。\n",
        "\n",
        "**環境**を使用して、このような要件を表すことができます。特に、スキーマの特徴は、`default_environment`、`in_environment`、および、`not_in_environment`を使用して一連の環境に関連付けることができます。\n",
        "\n",
        "たとえば、このデータセットでは、特徴`Tips`がトレーニングのラベルとして含まれていますが、サービングデータにありません。環境を指定しないと、異常として表示されます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wSZfbnifJuTA"
      },
      "outputs": [],
      "source": [
        "serving_stats = tfdv.generate_statistics_from_csv(SERVING_DATA)\n",
        "serving_anomalies = tfdv.validate_statistics(serving_stats, schema)\n",
        "\n",
        "tfdv.display_anomalies(serving_anomalies)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDYHvZ09LfkT"
      },
      "source": [
        "以下では特徴`tips`について説明します。また、スキーマは乗車期間（秒）として浮動小数点数型の値を期待していましたが整数型の値があります。TFDV は、その違いを見つけ、生成されるトレーニングテータとサービングデータの不整合を明らかにします。モデルのパフォーマンスが（時には破壊的に）低下するまで、このような問題に気付かないことがよくあります。これが重大な問題であってもなくても、調査する必要があります。\n",
        "\n",
        "この場合、整数値を浮上小数点に安全に変換できます。以下のとおり、スキーマを使用して型を推測するように TFDV に指示します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OhtYF8aAczpd"
      },
      "outputs": [],
      "source": [
        "options = tfdv.StatsOptions(schema=schema, infer_type_from_schema=True)\n",
        "serving_stats = tfdv.generate_statistics_from_csv(SERVING_DATA, stats_options=options)\n",
        "serving_anomalies = tfdv.validate_statistics(serving_stats, schema)\n",
        "\n",
        "tfdv.display_anomalies(serving_anomalies)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJjh5rigc5xy"
      },
      "source": [
        "これで、特徴`tips`（ラベル）が異常として表示されます（「列がドロップされました」）。サービングデータにラベルが含まれることは想定されていないため、TFDV にそれを無視するように指示します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bnbnw8H6Lp2M"
      },
      "outputs": [],
      "source": [
        "# All features are by default in both TRAINING and SERVING environments.\n",
        "schema.default_environment.append('TRAINING')\n",
        "schema.default_environment.append('SERVING')\n",
        "\n",
        "# Specify that 'tips' feature is not in SERVING environment.\n",
        "tfdv.get_feature(schema, 'tips').not_in_environment.append('SERVING')\n",
        "\n",
        "serving_anomalies_with_env = tfdv.validate_statistics(\n",
        "    serving_stats, schema, environment='SERVING')\n",
        "\n",
        "tfdv.display_anomalies(serving_anomalies_with_env)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yteMr3AGMYEp"
      },
      "source": [
        "## ドリフトとスキューのチェック"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Ftd5k6AMkPV"
      },
      "source": [
        "TFDV は、データセットがスキーマで設定された期待値に準拠しているかどうかを確認する他、リフトとスキューを検出する機能も提供します。TFDV は、スキーマで指定されたドリフト/スキューコンパレータに基づいてさまざまなデータセットの統計を比較することにより、このチェックを実行します。\n",
        "\n",
        "### ドリフト\n",
        "\n",
        "ドリフト検知は、カテゴリカルな特徴量で、連続したスパン (言い換えるとスパン N とスパン N+1 ) のデータ、例えば異なる日付の訓練データについてサポートしています。ここで、ドリフトは[L-無限大 距離](https://en.wikipedia.org/wiki/Chebyshev_distance)に基いて表されます。また、ドリフトが許容可能でないほど高い値をとった場合に警告を受け取るように、距離のしきい値を設定できます。正しく距離を設定することは、典型的にはドメイン知識や試行錯誤が必要な反復的なプロセスになります。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBFuLpXb6qSp"
      },
      "source": [
        "### 歪度\n",
        "\n",
        "TFDV は、データ内の3種類の歪度（スキーマ歪度、特徴歪度、および分布歪度）を検出します。\n",
        "\n",
        "#### スキーマ歪度\n",
        "\n",
        "スキーマ歪度は、トレーニングデータとサービングデータが同じスキーマに準拠していない場合に発生します。トレーニングデータとサービングデータの両方が同じスキーマに準拠することが期待されます。 これらの間に予想される偏差（ラベル機能はトレーニングデータにのみ存在し、サービングには存在しないなど）は、スキーマの環境フィールドで指定する必要があります。\n",
        "\n",
        "#### 特徴量の歪度\n",
        "\n",
        "特徴量の歪度は、モデルがトレーニングする特徴値が、サービング時に表示される特徴値と異なる場合に発生します。たとえば、これは次の場合に発生する可能性があります。\n",
        "\n",
        "- 特徴量を生成するデータソースがトレーニング時から実稼働環境に移行する間に修正される場合\n",
        "- トレーニング時と実稼働環境とで特徴量を生成するロジックが一貫していない場合。例えば、何らかの変換処理をどちらか一方のコードにしか追加していない場合。\n",
        "\n",
        "#### 分布歪度\n",
        "\n",
        "分布の偏りは特徴量の分布が実稼働環境のデータの分布と著しく異なるときに生じます。分布の偏りが生じる主要な原因の1つは、トレーニングデータセットを生成するために異なるコードまたは異なるデータソースを使用することです。もう1つの理由は、サンプリングメカニズムの欠陥で、代表的でないサービングデータのサブサンプルがトレーニングされる場合です。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wEUsZm_rOd1Q"
      },
      "outputs": [],
      "source": [
        "# Add skew comparator for 'payment_type' feature.\n",
        "payment_type = tfdv.get_feature(schema, 'payment_type')\n",
        "payment_type.skew_comparator.infinity_norm.threshold = 0.01\n",
        "\n",
        "# Add drift comparator for 'company' feature.\n",
        "company=tfdv.get_feature(schema, 'company')\n",
        "company.drift_comparator.infinity_norm.threshold = 0.001\n",
        "\n",
        "skew_anomalies = tfdv.validate_statistics(train_stats, schema,\n",
        "                                          previous_statistics=eval_stats,\n",
        "                                          serving_statistics=serving_stats)\n",
        "\n",
        "tfdv.display_anomalies(skew_anomalies)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GzbbsPgf0Bg"
      },
      "source": [
        "この例では、多少のドリフトが見られますが、設定したしきい値をはるかに下回っています。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJ5saC9eWvHx"
      },
      "source": [
        "## スキーマの凍結\n",
        "\n",
        "スキーマがレビューおよびキュレートされたので、「凍結」状態を反映するようにスキーマをファイルに保存します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ydkL4DkIWn18"
      },
      "outputs": [],
      "source": [
        "from tensorflow.python.lib.io import file_io\n",
        "from google.protobuf import text_format\n",
        "\n",
        "file_io.recursive_create_dir(OUTPUT_DIR)\n",
        "schema_file = os.path.join(OUTPUT_DIR, 'schema.pbtxt')\n",
        "tfdv.write_schema_text(schema, schema_file)\n",
        "\n",
        "!cat {schema_file}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8eC59yISdGB"
      },
      "source": [
        "## TFDV を使用する場合\n",
        "\n",
        "ここでは、TFDV はトレーニングパイプラインの開始にのみ適用されましたが、実際には多くの用途があります。例を以下に示します。\n",
        "\n",
        "- 推論のための新しいデータを検証して、急に不良な特徴を受け取り始めていないことを確認します。\n",
        "- 推論のために新しいデータを検証して、モデルが決定面のその部分でトレーニングされていることを確認します。\n",
        "- データを変換して特徴量エンジニアリング（おそらく[TensorFlow Transform](https://www.tensorflow.org/tfx/transform/) を使用）を行った後にデータを検証して、問題がないことを確認します。"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "tghWegsjhpkt"
      ],
      "name": "tfdv_basic.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
