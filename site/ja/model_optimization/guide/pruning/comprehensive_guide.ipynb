{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tce3stUlHN0L"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "IcfrhafzkZbH"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFdPvlXBOdUN"
      },
      "source": [
        "# プルーニングの総合ガイド"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfBg1C5NB3X0"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/model_optimization/guide/pruning/comprehensive_guide\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/model-optimization/blob/master/tensorflow_model_optimization/g3doc/guide/pruning/comprehensive_guide.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/model-optimization/blob/master/tensorflow_model_optimization/g3doc/guide/pruning/comprehensive_guide.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://storage.googleapis.com/tensorflow_docs/model-optimization/tensorflow_model_optimization/g3doc/guide/pruning/comprehensive_guide.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbORZA_bQx1G"
      },
      "source": [
        "Keras 重みプルーニングの総合ガイドへようこそ。\n",
        "\n",
        "このページでは、さまざまなユースケースを示し、それぞれで API を使用する方法を説明します。どの API が必要であるかを特定したら、[API ドキュメント](https://www.tensorflow.org/model_optimization/api_docs/python/tfmot/sparsity)でパラメータと詳細を確認してください。\n",
        "\n",
        "- プルーニングのメリットとサポート対象を確認する場合は、[概要](https://www.tensorflow.org/model_optimization/guide/pruning)をご覧ください。\n",
        "- 単一のエンドツーエンドの例については、[プルーニングの例](https://www.tensorflow.org/model_optimization/guide/pruning/pruning_with_keras)をご覧ください。\n",
        "\n",
        "次のユースケースについて説明しています。\n",
        "\n",
        "- プルーニングされたモデルの定義とトレーニング\n",
        "    - Sequential と Functional\n",
        "    - Keras model.fit とカスタムトレーニングループ\n",
        "- プルーニングされたモデルのチェックポイントと逆シリアル化\n",
        "- プルーニングされたモデルのデプロイと圧縮のメリットの確認\n",
        "\n",
        "プルーニングアルゴリズムの構成については、`tfmot.sparsity.keras.prune_low_magnitude` API ドキュメントをご覧ください。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nuABqZnXVDvO"
      },
      "source": [
        "## セットアップ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9mRDekZEfnR"
      },
      "source": [
        "必要な API の特定と目的の理解については、次を実行できますが、このセクションを読まずに進むことができます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "both",
        "id": "lvpH1Hg7ULFz"
      },
      "outputs": [],
      "source": [
        "! pip install -q tensorflow-model-optimization\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import tensorflow_model_optimization as tfmot\n",
        "\n",
        "%load_ext tensorboard\n",
        "\n",
        "import tempfile\n",
        "\n",
        "input_shape = [20]\n",
        "x_train = np.random.randn(1, 20).astype(np.float32)\n",
        "y_train = tf.keras.utils.to_categorical(np.random.randn(1), num_classes=20)\n",
        "\n",
        "def setup_model():\n",
        "  model = tf.keras.Sequential([\n",
        "      tf.keras.layers.Dense(20, input_shape=input_shape),\n",
        "      tf.keras.layers.Flatten()\n",
        "  ])\n",
        "  return model\n",
        "\n",
        "def setup_pretrained_weights():\n",
        "  model = setup_model()\n",
        "\n",
        "  model.compile(\n",
        "      loss=tf.keras.losses.categorical_crossentropy,\n",
        "      optimizer='adam',\n",
        "      metrics=['accuracy']\n",
        "  )\n",
        "\n",
        "  model.fit(x_train, y_train)\n",
        "\n",
        "  _, pretrained_weights = tempfile.mkstemp('.tf')\n",
        "\n",
        "  model.save_weights(pretrained_weights)\n",
        "\n",
        "  return pretrained_weights\n",
        "\n",
        "def get_gzipped_model_size(model):\n",
        "  # Returns size of gzipped model, in bytes.\n",
        "  import os\n",
        "  import zipfile\n",
        "\n",
        "  _, keras_file = tempfile.mkstemp('.h5')\n",
        "  model.save(keras_file, include_optimizer=False)\n",
        "\n",
        "  _, zipped_file = tempfile.mkstemp('.zip')\n",
        "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
        "    f.write(keras_file)\n",
        "\n",
        "  return os.path.getsize(zipped_file)\n",
        "\n",
        "setup_model()\n",
        "pretrained_weights = setup_pretrained_weights()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZyLYFTER4aP"
      },
      "source": [
        "## モデルを定義する"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ybigft1fTn4T"
      },
      "source": [
        "### すべてのモデルをプルーニングする（Sequential と Functional）"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "puZvqnp1xsn-"
      },
      "source": [
        "**モデルの精度を高めるためのヒント:**\n",
        "\n",
        "- 「一部のレイヤーをプルーニングする」を試して、最も精度を低下させるレイヤーのプルーニングを省略します。\n",
        "- 一般的に、始めからトレーニングするよりも、プルーニングで微調整する方が優れています。\n",
        "\n",
        "プルーニングでモデル全体をトレーニングするには、モデルに `tfmot.sparsity.keras.prune_low_magnitude` を適用します。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aIn-hFO_T_PU"
      },
      "outputs": [],
      "source": [
        "base_model = setup_model()\n",
        "base_model.load_weights(pretrained_weights) # optional but recommended.\n",
        "\n",
        "model_for_pruning = tfmot.sparsity.keras.prune_low_magnitude(base_model)\n",
        "\n",
        "model_for_pruning.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTbTLn3dZM7h"
      },
      "source": [
        "### 一部のレイヤーをプルーニングする（Sequential と Functional）"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbM8o832xTxV"
      },
      "source": [
        "モデルのプルーニングによって制度に悪影響が及ぶことがあります。そのため、選択的にモデルのレイヤーをプルーニングすることで、精度、速度、およびモデルサイズ間のトレードオフを探ることができます。\n",
        "\n",
        "**モデルの精度を高めるためのヒント:**\n",
        "\n",
        "- 一般的に、始めからトレーニングするよりも、プルーニングで微調整する方が優れています。\n",
        "- 初期のレイヤーの代わりに後のレイヤーのプルーニングを試します。\n",
        "- クリティカルレイヤー（注意メカニズムなど）のプルーニングを回避します。\n",
        "\n",
        "**その他**:\n",
        "\n",
        "- `tfmot.sparsity.keras.prune_low_magnitude` API ドキュメントには、レイヤーごとにプルーニング構成を変える方法が示されています。\n",
        "\n",
        "次の例では、`Dense` レイヤーのみをプルーニングしています。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HN0B_QB-ZhE2"
      },
      "outputs": [],
      "source": [
        "# Create a base model\n",
        "base_model = setup_model()\n",
        "base_model.load_weights(pretrained_weights) # optional but recommended for model accuracy\n",
        "\n",
        "# Helper function uses `prune_low_magnitude` to make only the \n",
        "# Dense layers train with pruning.\n",
        "def apply_pruning_to_dense(layer):\n",
        "  if isinstance(layer, tf.keras.layers.Dense):\n",
        "    return tfmot.sparsity.keras.prune_low_magnitude(layer)\n",
        "  return layer\n",
        "\n",
        "# Use `tf.keras.models.clone_model` to apply `apply_pruning_to_dense` \n",
        "# to the layers of the model.\n",
        "model_for_pruning = tf.keras.models.clone_model(\n",
        "    base_model,\n",
        "    clone_function=apply_pruning_to_dense,\n",
        ")\n",
        "\n",
        "model_for_pruning.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HiA28PrrW11H"
      },
      "source": [
        "この例ではプルーニングするものを決定するためにレイヤーの種類が使用されていますが、特定のレイヤーをプルーニングする上で最も簡単な方法は、`name` プロパティを設定し、`clone_function` でその名前を探す方法です。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CjY_JyB808Da"
      },
      "outputs": [],
      "source": [
        "print(base_model.layers[0].name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpb_BydRaSoF"
      },
      "source": [
        "#### 可読性が高くても、モデルの精度を潜在的に低下させる"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vqXeYffzSHp"
      },
      "source": [
        "これは、プルーニングによる微調整とは使用できません。そのため、微調整をサポートする上記の例よりも制度に劣る可能性があります。\n",
        "\n",
        "初期のモデルを定義する際に `prune_low_magnitude` を適用することも可能ですが、後で重みを読み込む場合、以下の例が機能しません。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5p5jvH5KznJ"
      },
      "source": [
        "**Functional の例**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Wow55hg5oiM"
      },
      "outputs": [],
      "source": [
        "# Use `prune_low_magnitude` to make the `Dense` layer train with pruning.\n",
        "i = tf.keras.Input(shape=(20,))\n",
        "x = tfmot.sparsity.keras.prune_low_magnitude(tf.keras.layers.Dense(10))(i)\n",
        "o = tf.keras.layers.Flatten()(x)\n",
        "model_for_pruning = tf.keras.Model(inputs=i, outputs=o)\n",
        "\n",
        "model_for_pruning.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIGj-r2of2ls"
      },
      "source": [
        "**Sequential の例**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mQOiDUGgfi4y"
      },
      "outputs": [],
      "source": [
        "# Use `prune_low_magnitude` to make the `Dense` layer train with pruning.\n",
        "model_for_pruning = tf.keras.Sequential([\n",
        "  tfmot.sparsity.keras.prune_low_magnitude(tf.keras.layers.Dense(20, input_shape=input_shape)),\n",
        "  tf.keras.layers.Flatten()\n",
        "])\n",
        "\n",
        "model_for_pruning.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnMguvVSnUqD"
      },
      "source": [
        "### カスタム Keras レイヤーのプルーニングまたはプルーニングするレイヤーの部分の変更"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLgH1aFMjTK4"
      },
      "source": [
        "**一般的な過ち:** バイアスをプルーニングすると通常、モデルの精度を著しく悪化させてしまう。\n",
        "\n",
        "`tfmot.sparsity.keras.PrunableLayer` は、2 つのユースケースに役立ちます。\n",
        "\n",
        "1. カスタム Keras レイヤーのプルーニング\n",
        "2. プルーニングする組み込み Keras レイヤーの部分の変更\n",
        "\n",
        "たとえば、API はデフォルトで `Dense` レイヤーのカーネルのプルーニングのみを行います。以下の例ではバイアスもプルーニングします。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "77jgBjccnTh6"
      },
      "outputs": [],
      "source": [
        "class MyDenseLayer(tf.keras.layers.Dense, tfmot.sparsity.keras.PrunableLayer):\n",
        "\n",
        "  def get_prunable_weights(self):\n",
        "    # Prune bias also, though that usually harms model accuracy too much.\n",
        "    return [self.kernel, self.bias]\n",
        "\n",
        "# Use `prune_low_magnitude` to make the `MyDenseLayer` layer train with pruning.\n",
        "model_for_pruning = tf.keras.Sequential([\n",
        "  tfmot.sparsity.keras.prune_low_magnitude(MyDenseLayer(20, input_shape=input_shape)),\n",
        "  tf.keras.layers.Flatten()\n",
        "])\n",
        "\n",
        "model_for_pruning.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itAyTyzvRroH"
      },
      "source": [
        "## モデルのトレーニング"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4hnWH2NY5MO"
      },
      "source": [
        "### Model.fit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LYCDIunTE9B"
      },
      "source": [
        "Call the `tfmot.sparsity.keras.UpdatePruningStep` callback during training. \n",
        "\n",
        "To help debug training, use the `tfmot.sparsity.keras.PruningSummaries` callback."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fKZ2PxcpY_WV"
      },
      "outputs": [],
      "source": [
        "# Define the model.\n",
        "base_model = setup_model()\n",
        "base_model.load_weights(pretrained_weights) # optional but recommended for model accuracy\n",
        "model_for_pruning = tfmot.sparsity.keras.prune_low_magnitude(base_model)\n",
        "\n",
        "log_dir = tempfile.mkdtemp()\n",
        "callbacks = [\n",
        "    tfmot.sparsity.keras.UpdatePruningStep(),\n",
        "    # Log sparsity and other metrics in Tensorboard.\n",
        "    tfmot.sparsity.keras.PruningSummaries(log_dir=log_dir)\n",
        "]\n",
        "\n",
        "model_for_pruning.compile(\n",
        "      loss=tf.keras.losses.categorical_crossentropy,\n",
        "      optimizer='adam',\n",
        "      metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model_for_pruning.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    callbacks=callbacks,\n",
        "    epochs=2,\n",
        ")\n",
        "\n",
        "#docs_infra: no_execute\n",
        "%tensorboard --logdir={log_dir}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kcuGmf5MSnJ"
      },
      "source": [
        "For non-Colab users, you can see [the results of a previous run](https://tensorboard.dev/experiment/XiNXEBjHQ3Oabc6jRLKiXQ/#scalars&_smoothingWeight=0) of this code block on [TensorBoard.dev](https://tensorboard.dev/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDcSvbNdZA-1"
      },
      "source": [
        "### カスタムトレーニングループ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQA8GaD6T3-o"
      },
      "source": [
        "トレーニング中に `tfmot.sparsity.keras.UpdatePruningStep` コールバックを呼び出します。\n",
        "\n",
        "トレーニングをデバッグできるようにするには、`tfmot.sparsity.keras.PruningSummaries` コールバックを使用します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hPQUrkodbIF2"
      },
      "outputs": [],
      "source": [
        "# Define the model.\n",
        "base_model = setup_model()\n",
        "base_model.load_weights(pretrained_weights) # optional but recommended for model accuracy\n",
        "model_for_pruning = tfmot.sparsity.keras.prune_low_magnitude(base_model)\n",
        "\n",
        "# Boilerplate\n",
        "loss = tf.keras.losses.categorical_crossentropy\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "log_dir = tempfile.mkdtemp()\n",
        "unused_arg = -1\n",
        "epochs = 2\n",
        "batches = 1 # example is hardcoded so that the number of batches cannot change.\n",
        "\n",
        "# Non-boilerplate.\n",
        "model_for_pruning.optimizer = optimizer\n",
        "step_callback = tfmot.sparsity.keras.UpdatePruningStep()\n",
        "step_callback.set_model(model_for_pruning)\n",
        "log_callback = tfmot.sparsity.keras.PruningSummaries(log_dir=log_dir) # Log sparsity and other metrics in Tensorboard.\n",
        "log_callback.set_model(model_for_pruning)\n",
        "\n",
        "step_callback.on_train_begin() # run pruning callback\n",
        "for _ in range(epochs):\n",
        "  log_callback.on_epoch_begin(epoch=unused_arg) # run pruning callback\n",
        "  for _ in range(batches):\n",
        "    step_callback.on_train_batch_begin(batch=unused_arg) # run pruning callback\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "      logits = model_for_pruning(x_train, training=True)\n",
        "      loss_value = loss(y_train, logits)\n",
        "      grads = tape.gradient(loss_value, model_for_pruning.trainable_variables)\n",
        "      optimizer.apply_gradients(zip(grads, model_for_pruning.trainable_variables))\n",
        "\n",
        "  step_callback.on_epoch_end(batch=unused_arg) # run pruning callback\n",
        "\n",
        "#docs_infra: no_execute\n",
        "%tensorboard --logdir={log_dir}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vh4lJt4zMh1v"
      },
      "source": [
        "Colab を使用していないユーザーは、[TensorBoard.dev](https://tensorboard.dev/experiment/jDeGzF3xQeSyb7Qir1ZcBQ/#scalars&_smoothingWeight=0) で、このノートブックの[前回の実行結果](https://tensorboard.dev/)を閲覧できます。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8H-8lQ-cPa-"
      },
      "source": [
        "### プルーニングされたモデルの精度を改善する\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2t4fYXvAV1V"
      },
      "source": [
        "まず、`tfmot.sparsity.keras.prune_low_magnitude` API ドキュメントを確認し、プルーニングスケジュールが何か、また各種プルーニングスケジュールの計算について理解してください。\n",
        "\n",
        "**ヒント**:\n",
        "\n",
        "- モデルがプルーニングする際に、高すぎず低すぎない学習率を使用します。[プルーニングスケジュール](https://www.tensorflow.org/model_optimization/api_docs/python/tfmot/sparsity/keras/PruningSchedule)をハイパーパラメータとすることを検討してください。\n",
        "\n",
        "- 簡易テストとして、トレーニング始めに最終的なスパース性までモデルを実験的にプルーニングします。`tfmot.sparsity.keras.ConstantSparsity` スケジュールで `begin_step` を 0 に設定します。良い結果が得る可能性があります。\n",
        "\n",
        "- モデルに回復する時間を与えられうように、あまり頻繁にプルーニングしないようにします。[プルーニングスケジュール](https://www.tensorflow.org/model_optimization/api_docs/python/tfmot/sparsity/keras/PruningSchedule)には十分なデフォルトの頻度が指定されています。\n",
        "\n",
        "- モデルの精度を改善するための一般的なアイデアについては、「モデルを定義する」に記載のケース別のヒントをご覧ください。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpvX5IqahV1r"
      },
      "source": [
        "## チェックポイントと逆シリアル化"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GuZ5wlij1dcJ"
      },
      "source": [
        "チェックポイント作成時には、オプティマイザのステップを保持する必要があります。つまり、チェックポイント作成に Keras HDF5 モデルを使用することはできますが、Keras HDF5 の重みは使用できません。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6khQg-q7imfH"
      },
      "outputs": [],
      "source": [
        "# Define the model.\n",
        "base_model = setup_model()\n",
        "base_model.load_weights(pretrained_weights) # optional but recommended for model accuracy\n",
        "model_for_pruning = tfmot.sparsity.keras.prune_low_magnitude(base_model)\n",
        "\n",
        "_, keras_model_file = tempfile.mkstemp('.h5')\n",
        "\n",
        "# Checkpoint: saving the optimizer is necessary (include_optimizer=True is the default).\n",
        "model_for_pruning.save(keras_model_file, include_optimizer=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-CLxooLYnRN"
      },
      "source": [
        "上記は一般的に適用されます。次のコードは、HDF5 モデル形式のみで必要です（HDF5 重みまたはその他の形式では不要です）。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2nGC1hZnYlzb"
      },
      "outputs": [],
      "source": [
        "# Deserialize model.\n",
        "with tfmot.sparsity.keras.prune_scope():\n",
        "  loaded_model = tf.keras.models.load_model(keras_model_file)\n",
        "\n",
        "loaded_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jew8M217SgQw"
      },
      "source": [
        "## プルーニングされたモデルをデプロイする"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2uj4SfF1cnTR"
      },
      "source": [
        "### サイズ圧縮によるモデルのエクスポート"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57uNm47L4Yro"
      },
      "source": [
        "**一般的な過ち**: `strip_pruning` と標準圧縮アルゴリズム（gzip など）の適用は、プルーニングの圧縮のメリットを確認する上で必要です。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EZ3TD8cYkxZM"
      },
      "outputs": [],
      "source": [
        "# Define the model.\n",
        "base_model = setup_model()\n",
        "base_model.load_weights(pretrained_weights) # optional but recommended for model accuracy\n",
        "model_for_pruning = tfmot.sparsity.keras.prune_low_magnitude(base_model)\n",
        "\n",
        "# Typically you train the model here.\n",
        "\n",
        "model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
        "\n",
        "print(\"final model\")\n",
        "model_for_export.summary()\n",
        "\n",
        "print(\"\\n\")\n",
        "print(\"Size of gzipped pruned model without stripping: %.2f bytes\" % (get_gzipped_model_size(model_for_pruning)))\n",
        "print(\"Size of gzipped pruned model with stripping: %.2f bytes\" % (get_gzipped_model_size(model_for_export)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPXvYIHOctem"
      },
      "source": [
        "### ハードウェア固有の最適化"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqk0jI49c1mw"
      },
      "source": [
        "異なるバックエンドで[プルーニングによるレイテンシの改善]((https://github.com/tensorflow/model-optimization/issues/173))が可能になったら、ブロックのスパース性を使用することで、特定のハードウェアのレイテンシを改善することができます。\n",
        "\n",
        "ブロックサイズを大きくすると、ターゲットモデルの精度を得るために達成可能なピークスパース性が低下します。これにも関わらず、レイテンシは改善されることがあります。\n",
        "\n",
        "ブロックスパース性のサポート状況に関する詳細は、`tfmot.sparsity.keras.prune_low_magnitude` API ドキュメントをご覧ください。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xedaVDeFc0bw"
      },
      "outputs": [],
      "source": [
        "base_model = setup_model()\n",
        "\n",
        "# For using intrinsics on a CPU with 128-bit registers, together with 8-bit\n",
        "# quantized weights, a 1x16 block size is nice because the block perfectly\n",
        "# fits into the register.\n",
        "pruning_params = {'block_size': [1, 16]}\n",
        "model_for_pruning = tfmot.sparsity.keras.prune_low_magnitude(base_model, **pruning_params)\n",
        "\n",
        "model_for_pruning.summary()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Tce3stUlHN0L"
      ],
      "name": "comprehensive_guide.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
