{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8b6f4aa6b1b5"
      },
      "source": [
        "**Copyright 2021 The TensorFlow Authors.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "mEE8NFIMSGO-"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfBg1C5NB3X0"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td><a target=\"_blank\" href=\"https://www.tensorflow.org/model_optimization/guide/combine/pqat_example\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">TensorFlow.org で表示</a></td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/ja/model_optimization/guide/combine/pqat_example.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Google Colab で実行</a>   </td>\n",
        "  <td><a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/ja/model_optimization/guide/combine/pqat_example.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">GitHub でソースを表示</a></td>\n",
        "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/ja/model_optimization/guide/combine/pqat_example.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">ノートブックをダウンロード</a>   </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyiSRgdtSGPC"
      },
      "source": [
        "# Keras でのプルーニングを保持する量子化認識トレーニング（PQAT）の例"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKnJyAaASGPD"
      },
      "source": [
        "## 概要\n",
        "\n",
        "このチュートリアルでは、TensorFlow モデル最適化ツールキットの協調最適化パイプラインの一部である**プルーニングを保持する量子化認識トレーニング (PQAT)** API の使用法を実演します。\n",
        "\n",
        "### その他のページ\n",
        "\n",
        "パイプラインの概要とその他の利用可能な手法については、[協調最適化の概要ページ](https://www.tensorflow.org/model_optimization/guide/combine/collaborative_optimization)を参照してください。\n",
        "\n",
        "### 内容\n",
        "\n",
        "チュートリアルでは、次について説明しています。\n",
        "\n",
        "1. MNIST データセットの `tf.keras` モデルを最初からトレーニングする。\n",
        "2. スパース性 API を適用してモデルをプルーニングで微調整し、精度を確認する。\n",
        "3. QAT を適用し、スパース性の損失を観察します。\n",
        "4. PQAT を適用し、前に適用されたスパース性が保持されていることを確認する。\n",
        "5. TFLite モデルを生成し、それに PQAT を適用した場合の影響を観察する。\n",
        "6. 達成した PQAT モデルの精度を、ポストトレーニング量子化を使用して量子化されたモデルと比較する。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgcQznnZSGPE"
      },
      "source": [
        "## セットアップ\n",
        "\n",
        "この Jupyter ノートブックは、ローカルの [virtualenv](https://www.tensorflow.org/install/pip?lang=python3#2.-create-a-virtual-environment-recommended) または [Colab](https://colab.sandbox.google.com/) で実行できます。依存関係のセットアップに関する詳細は、[インストールガイド](https://www.tensorflow.org/model_optimization/guide/install)をご覧ください。 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3asgXMqnSGPE"
      },
      "outputs": [],
      "source": [
        "! pip install -q tensorflow-model-optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gL6JiLXkSGPI"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "import tempfile\n",
        "import zipfile\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKzOfl5FSGPL"
      },
      "source": [
        "## プルーニングを使用せずに、MNIST の tf.keras モデルをトレーニングする"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w7Fd6jZ7SGPL"
      },
      "outputs": [],
      "source": [
        "# Load MNIST dataset\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# Normalize the input image so that each pixel value is between 0 to 1.\n",
        "train_images = train_images / 255.0\n",
        "test_images  = test_images / 255.0\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.InputLayer(input_shape=(28, 28)),\n",
        "  tf.keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
        "  tf.keras.layers.Conv2D(filters=12, kernel_size=(3, 3),\n",
        "                         activation=tf.nn.relu),\n",
        "  tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(10)\n",
        "])\n",
        "\n",
        "# Train the digit classification model\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(\n",
        "    train_images,\n",
        "    train_labels,\n",
        "    validation_split=0.1,\n",
        "    epochs=10\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBOQ8MeESGPO"
      },
      "source": [
        "### ベースラインモデルを評価して後で使用できるように保存する"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HYulekocSGPP"
      },
      "outputs": [],
      "source": [
        "_, baseline_model_accuracy = model.evaluate(\n",
        "    test_images, test_labels, verbose=0)\n",
        "\n",
        "print('Baseline test accuracy:', baseline_model_accuracy)\n",
        "\n",
        "_, keras_file = tempfile.mkstemp('.h5')\n",
        "print('Saving model to: ', keras_file)\n",
        "tf.keras.models.save_model(model, keras_file, include_optimizer=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWPgcnjKSGPR"
      },
      "source": [
        "## モデルをプルーニングし、50％ のスパース性に微調整する"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2wKK7w9SGPS"
      },
      "source": [
        "`prune_low_magnitude()` API を適用して、事前にトレーニングされたモデル全体をプルーニングします。zip を適用し、モデルサイズを縮小する際に精度が効果的に維持されることを観察してください。API を使用して、モデルの精度を維持しながら最高の圧縮率を達成するための最適な方法については、[プルーニング総合ガイド](https://www.tensorflow.org/model_optimization/guide/pruning/comprehensive_guide)を参照してください。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ea40z522SGPT"
      },
      "source": [
        "### モデルを定義してスパース性 API を適用する"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7aOB5vjOZMTS"
      },
      "source": [
        "スパース性 API を使用する前に、モデルを事前にトレーニングする必要があります。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OzqKKt0mSGPT"
      },
      "outputs": [],
      "source": [
        "import tensorflow_model_optimization as tfmot\n",
        "\n",
        "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
        "\n",
        "pruning_params = {\n",
        "      'pruning_schedule': tfmot.sparsity.keras.ConstantSparsity(0.5, begin_step=0, frequency=100)\n",
        "  }\n",
        "\n",
        "callbacks = [\n",
        "  tfmot.sparsity.keras.UpdatePruningStep()\n",
        "]\n",
        "\n",
        "pruned_model = prune_low_magnitude(model, **pruning_params)\n",
        "\n",
        "# Use smaller learning rate for fine-tuning\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
        "\n",
        "pruned_model.compile(\n",
        "  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "  optimizer=opt,\n",
        "  metrics=['accuracy'])\n",
        "\n",
        "pruned_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ev4MyClmSGPW"
      },
      "source": [
        "### モデルを微調整し、ベースラインに対する精度を評価する"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQoy9CcASGPX"
      },
      "source": [
        "3 エポックのプルーニングでモデルを微調整します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jn29-coXSGPX"
      },
      "outputs": [],
      "source": [
        "# Fine-tune model\n",
        "pruned_model.fit(\n",
        "  train_images,\n",
        "  train_labels,\n",
        "  epochs=3,\n",
        "  validation_split=0.1,\n",
        "  callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "198b9e9ce00b"
      },
      "source": [
        "モデルのスパース性を計算して出力するヘルパー関数を定義します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "69468934028c"
      },
      "outputs": [],
      "source": [
        "def print_model_weights_sparsity(model):\n",
        "\n",
        "    for layer in model.layers:\n",
        "        if isinstance(layer, tf.keras.layers.Wrapper):\n",
        "            weights = layer.trainable_weights\n",
        "        else:\n",
        "            weights = layer.weights\n",
        "        for weight in weights:\n",
        "            # ignore auxiliary quantization weights\n",
        "            if \"quantize_layer\" in weight.name:\n",
        "                continue\n",
        "            weight_size = weight.numpy().size\n",
        "            zero_num = np.count_nonzero(weight == 0)\n",
        "            print(\n",
        "                f\"{weight.name}: {zero_num/weight_size:.2%} sparsity \",\n",
        "                f\"({zero_num}/{weight_size})\",\n",
        "            )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abc304948a53"
      },
      "source": [
        "モデルが正しくプルーニングされていることを確認します。最初にプルーニングラッパーを削除する必要があります。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a3fada83ffd7"
      },
      "outputs": [],
      "source": [
        "stripped_pruned_model = tfmot.sparsity.keras.strip_pruning(pruned_model)\n",
        "\n",
        "print_model_weights_sparsity(stripped_pruned_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvaZKoxtTORx"
      },
      "source": [
        "この例では、ベースラインと比較し、プルーニング後のテスト精度に最小限の損失があります。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bE7MxpWLTaQ1"
      },
      "outputs": [],
      "source": [
        "_, pruned_model_accuracy = pruned_model.evaluate(\n",
        "  test_images, test_labels, verbose=0)\n",
        "\n",
        "print('Baseline test accuracy:', baseline_model_accuracy)\n",
        "print('Pruned test accuracy:', pruned_model_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXfPMa6ISGPd"
      },
      "source": [
        "## QAT と PQAT を適用し、モデルクラスタへの影響を確認する"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zr_QIhcUeuC"
      },
      "source": [
        "次に、プルーニングされたモデルに QAT とプルーニングを保持する QAT（PQAT）の両方を適用し、PQAT がプルーニングされたモデルのスパース性を保持することを確認します。PQAT API を適用する前に、`tfmot.sparsity.keras.strip_pruning` を使用してモデルからプルーニングのラッパーを削除したことに注意してください。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4h6tSvMzSGPd"
      },
      "outputs": [],
      "source": [
        "# QAT\n",
        "qat_model = tfmot.quantization.keras.quantize_model(stripped_pruned_model)\n",
        "\n",
        "qat_model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "print('Train qat model:')\n",
        "qat_model.fit(train_images, train_labels, batch_size=128, epochs=1, validation_split=0.1)\n",
        "\n",
        "# PQAT\n",
        "quant_aware_annotate_model = tfmot.quantization.keras.quantize_annotate_model(\n",
        "              stripped_pruned_model)\n",
        "pqat_model = tfmot.quantization.keras.quantize_apply(\n",
        "              quant_aware_annotate_model,\n",
        "              tfmot.experimental.combine.Default8BitPrunePreserveQuantizeScheme())\n",
        "\n",
        "pqat_model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "print('Train pqat model:')\n",
        "pqat_model.fit(train_images, train_labels, batch_size=128, epochs=1, validation_split=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8e90c14cce8d"
      },
      "outputs": [],
      "source": [
        "print(\"QAT Model sparsity:\")\n",
        "print_model_weights_sparsity(qat_model)\n",
        "print(\"PQAT Model sparsity:\")\n",
        "print_model_weights_sparsity(pqat_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2877629dd054"
      },
      "source": [
        "## PQAT モデルの圧縮のメリットを確認する\n",
        "\n",
        "zip 形式のモデルファイルを取得するためのヘルパー関数を定義します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b72869768986"
      },
      "outputs": [],
      "source": [
        "def get_gzipped_model_size(file):\n",
        "  # It returns the size of the gzipped model in kilobytes.\n",
        "\n",
        "  _, zipped_file = tempfile.mkstemp('.zip')\n",
        "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
        "    f.write(file)\n",
        "\n",
        "  return os.path.getsize(zipped_file)/1000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1ef78df5740"
      },
      "source": [
        "これは小規模なモデルなので、2 つのモデルの違いはあまり目立ちません。より大きな本番モデルにプルーニングと PQAT を適用すると、より大きな圧縮が得られます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "057965bfae3d"
      },
      "outputs": [],
      "source": [
        "# QAT model\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(qat_model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "qat_tflite_model = converter.convert()\n",
        "qat_model_file = 'qat_model.tflite'\n",
        "# Save the model.\n",
        "with open(qat_model_file, 'wb') as f:\n",
        "    f.write(qat_tflite_model)\n",
        "    \n",
        "# PQAT model\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(pqat_model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "pqat_tflite_model = converter.convert()\n",
        "pqat_model_file = 'pqat_model.tflite'\n",
        "# Save the model.\n",
        "with open(pqat_model_file, 'wb') as f:\n",
        "    f.write(pqat_tflite_model)\n",
        "    \n",
        "print(\"QAT model size: \", get_gzipped_model_size(qat_model_file), ' KB')\n",
        "print(\"PQAT model size: \", get_gzipped_model_size(pqat_model_file), ' KB')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "286cd588785a"
      },
      "source": [
        "## TF から TFLite への精度の永続性を確認する\n",
        "\n",
        "テストデータセットで TFLite モデルを評価するヘルパー関数を定義します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8808bb8628bd"
      },
      "outputs": [],
      "source": [
        "def eval_model(interpreter):\n",
        "  input_index = interpreter.get_input_details()[0][\"index\"]\n",
        "  output_index = interpreter.get_output_details()[0][\"index\"]\n",
        "\n",
        "  # Run predictions on every image in the \"test\" dataset.\n",
        "  prediction_digits = []\n",
        "  for i, test_image in enumerate(test_images):\n",
        "    if i % 1000 == 0:\n",
        "      print(f\"Evaluated on {i} results so far.\")\n",
        "    # Pre-processing: add batch dimension and convert to float32 to match with\n",
        "    # the model's input data format.\n",
        "    test_image = np.expand_dims(test_image, axis=0).astype(np.float32)\n",
        "    interpreter.set_tensor(input_index, test_image)\n",
        "\n",
        "    # Run inference.\n",
        "    interpreter.invoke()\n",
        "\n",
        "    # Post-processing: remove batch dimension and find the digit with highest\n",
        "    # probability.\n",
        "    output = interpreter.tensor(output_index)\n",
        "    digit = np.argmax(output()[0])\n",
        "    prediction_digits.append(digit)\n",
        "\n",
        "  print('\\n')\n",
        "  # Compare prediction results with ground truth labels to calculate accuracy.\n",
        "  prediction_digits = np.array(prediction_digits)\n",
        "  accuracy = (prediction_digits == test_labels).mean()\n",
        "  return accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dd9e954bd826"
      },
      "source": [
        "プルーニングおよび量子化されたモデルを評価し、TensorFlow の精度が TFLite バックエンドに持続することを確認します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4eaf0160ea09"
      },
      "outputs": [],
      "source": [
        "interpreter = tf.lite.Interpreter(pqat_model_file)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "pqat_test_accuracy = eval_model(interpreter)\n",
        "\n",
        "print('Pruned and quantized TFLite test_accuracy:', pqat_test_accuracy)\n",
        "print('Pruned TF test accuracy:', pruned_model_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26dec6d57704"
      },
      "source": [
        "## ポストトレーニング量子化を適用し、PQAT モデルと比較する\n",
        "\n",
        "次に、プルーニングされたモデルで通常のポストトレーニング量子化（微調整なし）を使用し、PQAT モデルと比較した精度を確認します。量子化モデルの精度を向上させるために PQAT を使用する必要がある理由がお分かりになると思います。\n",
        "\n",
        "まず、最初の 1000 個のトレーニング画像からキャリブレーションデータセットのジェネレータを定義します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e92771026b96"
      },
      "outputs": [],
      "source": [
        "def mnist_representative_data_gen():\n",
        "  for image in train_images[:1000]:  \n",
        "    image = np.expand_dims(image, axis=0).astype(np.float32)\n",
        "    yield [image]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "085aa0dbc8a8"
      },
      "source": [
        "モデルを量子化し、以前に取得した CPAT モデルと精度を比較します。微調整で量子化されたモデルは、より高い精度を実現することに注目してください。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0c913c4d4f9b"
      },
      "outputs": [],
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(stripped_pruned_model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.representative_dataset = mnist_representative_data_gen\n",
        "post_training_tflite_model = converter.convert()\n",
        "post_training_model_file = 'post_training_model.tflite'\n",
        "# Save the model.\n",
        "with open(post_training_model_file, 'wb') as f:\n",
        "    f.write(post_training_tflite_model)\n",
        "    \n",
        "# Compare accuracy\n",
        "interpreter = tf.lite.Interpreter(post_training_model_file)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "post_training_test_accuracy = eval_model(interpreter)\n",
        "\n",
        "print('PQAT TFLite test_accuracy:', pqat_test_accuracy)\n",
        "print('Post-training (no fine-tuning) TF test accuracy:', post_training_test_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "422b323172c5"
      },
      "source": [
        "## 結論"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7JhbpowqSGP1"
      },
      "source": [
        "このチュートリアルでは、モデルを作成し、スパース性 API を使用してプルーニングし、スパース性を保持する量子化認識トレーニング（PQAT）を適用して、QAT を使用する際にスパース性を保持する方法を学習しました。最終的な PQAT モデルを QAT モデルと比較し、スパース性が前者で保持され、後者で失われることを示しました。続いて、モデルを TFLite に変換して、連鎖クラスタリングと PQAT モデル最適化手法の圧縮の利点を示し、TFLite モデルを評価して、TFLite バックエンドで精度が維持されることを確認しました。最後に、PQAT モデルを、ポストトレーニング量子化 API を使用したプルーニングされた量子化モデルと比較し、PQAT を使用すると通常の量子化よりも精度の低下を抑えられることを示しました。"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "pqat_example.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
