{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FhGuhbZ6M5tl"
      },
      "source": [
        "##### Copyright 2018 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "AwOEIRJC6Une"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "KyPEtTqk6VdG"
      },
      "outputs": [],
      "source": [
        "#@title MIT License\n",
        "#\n",
        "# Copyright (c) 2017 François Chollet\n",
        "#\n",
        "# Permission is hereby granted, free of charge, to any person obtaining a\n",
        "# copy of this software and associated documentation files (the \"Software\"),\n",
        "# to deal in the Software without restriction, including without limitation\n",
        "# the rights to use, copy, modify, merge, publish, distribute, sublicense,\n",
        "# and/or sell copies of the Software, and to permit persons to whom the\n",
        "# Software is furnished to do so, subject to the following conditions:\n",
        "#\n",
        "# The above copyright notice and this permission notice shall be included in\n",
        "# all copies or substantial portions of the Software.\n",
        "#\n",
        "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n",
        "# THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n",
        "# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n",
        "# DEALINGS IN THE SOFTWARE."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIdT9iu_Z4Rb"
      },
      "source": [
        "# Regressione base: Prevedere il consumo di carburante"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBIlTPscrIT9"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/keras/regression\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />Visualizza su TensorFlow.org</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/it/tutorials/keras/regression.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Esegui in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/it/tutorials/keras/regression.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />Visualizza il sorgente su GitHub</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/it/tutorials/keras/regression.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Scarica il notebook</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHp3M9ZmrIxj"
      },
      "source": [
        "In un problema di *regressione*, abbiamo l'obiettivo di prevedere l'andamento di un valore continuo, come un prezzo o una probabilità. Al contrario di un problema di *classificazione*, ove abbiamo l'obiettivo di scegliere una classe tra una lista di classi (per esempio, quando un'immagine contenga una mela o un'arancia, riconoscere quale frutto è nell'immagine).\n",
        "\n",
        "Questo notebook usa il classico Dataset [Auto MPG](https://archive.ics.uci.edu/ml/datasets/auto+mpg) e costruisce un modello per prevedere il consumo di carburante delle auto della fine degli anni '70 e dell'inizio degli anni '80. Per farlo, forniremo al modello una descrizione di mote automobili di quel periodo. Questa descrizione include attributi come: cilindri, cilindrata, cavalli di potenza, e peso.\n",
        "\n",
        "Questo esempio usa le API `tf.keras`, per i dettagli vedere [questa guida](https://www.tensorflow.org/guide/keras)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "moB4tpEHxKB3"
      },
      "outputs": [],
      "source": [
        "# Use seaborn for pairplot\n",
        "!pip install seaborn\n",
        "\n",
        "# Use some functions from tensorflow_docs\n",
        "!pip install git+https://github.com/tensorflow/docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1rRo8oNqZ-Rj"
      },
      "outputs": [],
      "source": [
        "import pathlib\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9xQKvCJ85kCQ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qz4HfsgRQUiV"
      },
      "outputs": [],
      "source": [
        "import tensorflow_docs as tfdocs\n",
        "import tensorflow_docs.plots\n",
        "import tensorflow_docs.modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_72b0LCNbjx"
      },
      "source": [
        "## Il dataset Auto MPG\n",
        "\n",
        "Il dataset è disponibile su [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFh9ne3FZ-On"
      },
      "source": [
        "### Otteniamo i dati\n",
        "Per prima cosa, scarichiamo il dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p9kxxgzvzlyz"
      },
      "outputs": [],
      "source": [
        "dataset_path = keras.utils.get_file(\"auto-mpg.data\", \"http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data\")\n",
        "dataset_path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nslsRLh7Zss4"
      },
      "source": [
        "Importiamolo usando pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CiX2FI4gZtTt"
      },
      "outputs": [],
      "source": [
        "column_names = ['MPG','Cylinders','Displacement','Horsepower','Weight',\n",
        "                'Acceleration', 'Model Year', 'Origin']\n",
        "raw_dataset = pd.read_csv(dataset_path, names=column_names,\n",
        "                      na_values = \"?\", comment='\\t',\n",
        "                      sep=\" \", skipinitialspace=True)\n",
        "\n",
        "dataset = raw_dataset.copy()\n",
        "dataset.tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MWuJTKEDM-f"
      },
      "source": [
        "### Ripuliamo i dati\n",
        "\n",
        "Il dataset contiene alcuni valori sconosciuti."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JEJHhN65a2VV"
      },
      "outputs": [],
      "source": [
        "dataset.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UPN0KBHa_WI"
      },
      "source": [
        "Per mantenere semplice questo tutorial iniziale, eliminiamo queste righe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ZUDosChC1UN"
      },
      "outputs": [],
      "source": [
        "dataset = dataset.dropna()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XKitwaH4v8h"
      },
      "source": [
        "La colonna `\"Origine\"`, in verità, è una categoria, non un numero. Così la convertiamo in un indicatore:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gWNTD2QjBWFJ"
      },
      "outputs": [],
      "source": [
        "dataset['Origin'] = dataset['Origin'].map(lambda x: {1: 'USA', 2: 'Europe', 3: 'Japan'}.get(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ulXz4J7PAUzk"
      },
      "outputs": [],
      "source": [
        "dataset = pd.get_dummies(dataset, prefix='', prefix_sep='')\n",
        "dataset.tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cuym4yvk76vU"
      },
      "source": [
        "### Partizioniamo i dati in addestramento e verifica\n",
        "\n",
        "Ora dividiamo in due il dataset in un insieme di addestramento ed uno di verifica.\n",
        "\n",
        "Useremo l'insieme di verifica nella valutazione finale del nostro modello."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qn-IGhUE7_1H"
      },
      "outputs": [],
      "source": [
        "train_dataset = dataset.sample(frac=0.8,random_state=0)\n",
        "test_dataset = dataset.drop(train_dataset.index)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4ubs136WLNp"
      },
      "source": [
        "### Osserviamo i dati\n",
        "\n",
        "Diamo un'occhiata alla distribuzione congiunta di alcune coppie di colonne dall'insieme di addestramento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oRKO_x8gWKv-"
      },
      "outputs": [],
      "source": [
        "sns.pairplot(train_dataset[[\"MPG\", \"Cylinders\", \"Displacement\", \"Weight\"]], diag_kind=\"kde\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gavKO_6DWRMP"
      },
      "source": [
        "Ed anche alle statistiche generali:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yi2FzC3T21jR"
      },
      "outputs": [],
      "source": [
        "train_stats = train_dataset.describe()\n",
        "train_stats.pop(\"MPG\")\n",
        "train_stats = train_stats.transpose()\n",
        "train_stats"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Db7Auq1yXUvh"
      },
      "source": [
        "### Separiamo le caratteristiche dalle etichette\n",
        "\n",
        "Separiamo i valori obiettivo, o \"etichette\", dalle caratteristiche. Questa etichetta è il valore che il modello sarà addestrato a predire."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t2sluJdCW7jN"
      },
      "outputs": [],
      "source": [
        "train_labels = train_dataset.pop('MPG')\n",
        "test_labels = test_dataset.pop('MPG')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRklxK5s388r"
      },
      "source": [
        "### normalizziamo i dati\n",
        "\n",
        "Osserviamo di nuovo il blocco `train_stats` sopra, e notiamo come siano diversi gli intervalli di ciascuna caratteristica."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ywmerQ6dSox"
      },
      "source": [
        "E' buona pratica normalizzare le caratteristiche che usano diversi intervalli e scale. Sebbene il modello *possa* convergere senza normalizzare le caratteristiche, ciò rende l'addestramento più difficile, e rende il modello risultante dipendente dalla scelta delle unità usate nell'input.\n",
        "\n",
        "Nota: Sebbene, intenzionalmente, generiamo queste statistiche dal solo dataset di addestramento, esse potranno essere usate anche per normalizzare il dataset di validazione. Ciò è necessario per proiettare il dataset di validazione con la stessa distribuzione con cui è stato addestrato il modello."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JlC5ooJrgjQF"
      },
      "outputs": [],
      "source": [
        "def norm(x):\n",
        "  return (x - train_stats['mean']) / train_stats['std']\n",
        "normed_train_data = norm(train_dataset)\n",
        "normed_test_data = norm(test_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BuiClDk45eS4"
      },
      "source": [
        "Questi dati normalizzati saranno quelli che useremo per addestrare il modello.\n",
        "\n",
        "Attenzione: Le statistiche utilizzate per normalizzare gli input (la media e la deviazione standard) devono essere applicate ad ogni altro valore con cui sia alimentato il modello, assieme alla codifica degli indicatori che abbiamo fatto prima. Inclusi: l'insieme di validazione ed i dati vivi, quando il modello verrà usato in produzione."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmjdzxKzEu1-"
      },
      "source": [
        "## Il modello"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SWtkIjhrZwa"
      },
      "source": [
        "### Costruiamo il modello\n",
        "\n",
        "Andiamo a realizzare il nostro modello. Useremo un modello `Sequenziale` con due livelli nascosti, densamente connessi, ed un livello di uscita che restituisce un valore singolo, continuo. I passi di costruzione del modello sono raccolti in una funzione, `build_model`, perché, in seguito, creeremo un secondo modello."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c26juK7ZG8j-"
      },
      "outputs": [],
      "source": [
        "def build_model():\n",
        "  model = keras.Sequential([\n",
        "    layers.Dense(64, activation='relu', input_shape=[len(train_dataset.keys())]),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(1)\n",
        "  ])\n",
        "\n",
        "  optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
        "\n",
        "  model.compile(loss='mse',\n",
        "                optimizer=optimizer,\n",
        "                metrics=['mae', 'mse'])\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cGbPb-PHGbhs"
      },
      "outputs": [],
      "source": [
        "model = build_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sj49Og4YGULr"
      },
      "source": [
        "### Osserviamo il modello\n",
        "\n",
        "Usiamo il metodo `.summary` per visualizzare una semplice descrizione del modello"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ReAD0n6MsFK-"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vt6W50qGsJAL"
      },
      "source": [
        "Ora proviamo il modello. Prendiamo un blocco di `10` esempi dai dati di addestramento e, su di essi, chiamiamo `model.predict`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-d-gBaVtGTSC"
      },
      "outputs": [],
      "source": [
        "example_batch = normed_train_data[:10]\n",
        "example_result = model.predict(example_batch)\n",
        "example_result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlM8KrSOsaYo"
      },
      "source": [
        "Sembra essere funzionante, e produce un risultato nel formato e del tipo attesi."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-qWCsh6DlyH"
      },
      "source": [
        "### Addestriamo il modello\n",
        "\n",
        "Addestriamo il modello per 1000 epoche, e registriamo l'accuratezza dell'addestramento e della validazione nell'oggetto `history`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sD7qHCmNIOY0"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 1000\n",
        "\n",
        "history = model.fit(\n",
        "  normed_train_data, train_labels,\n",
        "  epochs=EPOCHS, validation_split = 0.2, verbose=0,\n",
        "  callbacks=[tfdocs.modeling.EpochDots()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQm3pc0FYPQB"
      },
      "source": [
        "Visualizziamo il progresso del modello durante l'addestramento usando le statistiche immagazzinate nell'oggetto `history`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Xj91b-dymEy"
      },
      "outputs": [],
      "source": [
        "hist = pd.DataFrame(history.history)\n",
        "hist['epoch'] = history.epoch\n",
        "hist.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "czYtZS9A6D-X"
      },
      "outputs": [],
      "source": [
        "plotter = tfdocs.plots.HistoryPlotter(smoothing_std=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nMCWKskbUTvG"
      },
      "outputs": [],
      "source": [
        "plotter.plot({'Basic': history}, metric = \"mae\")\n",
        "plt.ylim([0, 10])\n",
        "plt.ylabel('MAE [MPG]')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N9u74b1tXMd9"
      },
      "outputs": [],
      "source": [
        "plotter.plot({'Basic': history}, metric = \"mse\")\n",
        "plt.ylim([0, 20])\n",
        "plt.ylabel('MSE [MPG^2]')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AqsuANc11FYv"
      },
      "source": [
        "Questo grafico mostra miglioramenti modesti, o anche peggioramenti nell'errore di validazione dopo circa 100 epoche. Andiamo a modificare la chiamata alla `model.fit` per fermare automaticamente l'addestramento quando il risultato della validazione non migliora. Useremo la *EarlyStopping callback* che controlla la condizione di addestramento ad ogni epoca. Se un dato numero di epoche passano senza mostrare miglioramenti, allora l'addestramento viene interrotto automaticamente.\n",
        "\n",
        "[Qui](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping) potete imparare di più a proposito di questa callback."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fdMZuhUgzMZ4"
      },
      "outputs": [],
      "source": [
        "model = build_model()\n",
        "\n",
        "# The patience parameter is the amount of epochs to check for improvement\n",
        "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
        "\n",
        "early_history = model.fit(normed_train_data, train_labels, \n",
        "                    epochs=EPOCHS, validation_split = 0.2, verbose=0, \n",
        "                    callbacks=[early_stop, tfdocs.modeling.EpochDots()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LcopvQh3X-kX"
      },
      "outputs": [],
      "source": [
        "plotter.plot({'Early Stopping': early_history}, metric = \"mae\")\n",
        "plt.ylim([0, 10])\n",
        "plt.ylabel('MAE [MPG]')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3St8-DmrX8P4"
      },
      "source": [
        "Il grafico mostra che l'errore medio sull'insieme di validazione è solitamente attorno a +/- 2 MPG. Va bene? Lasciamo a voi la decisione.\n",
        "\n",
        "Andiamo a vedere quanto il modello generalizzi bene con l'insieme di **test**, che non abbiamo usato nell'addestramento del modello.  Questo ci dice come ci possiamo aspettare che il modello possa comportarsi, quando lo usiamo nel mondo reale."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jl_yNr5n1kms"
      },
      "outputs": [],
      "source": [
        "loss, mae, mse = model.evaluate(normed_test_data, test_labels, verbose=2)\n",
        "\n",
        "print(\"Testing set Mean Abs Error: {:5.2f} MPG\".format(mae))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ft603OzXuEZC"
      },
      "source": [
        "### Facciamo previsioni\n",
        "\n",
        "Finalmente, facciamo previsioni sui valori di MPG usando i dati nel l'insieme di test:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xe7RXH3N3CWU"
      },
      "outputs": [],
      "source": [
        "test_predictions = model.predict(normed_test_data).flatten()\n",
        "\n",
        "a = plt.axes(aspect='equal')\n",
        "plt.scatter(test_labels, test_predictions)\n",
        "plt.xlabel('True Values [MPG]')\n",
        "plt.ylabel('Predictions [MPG]')\n",
        "lims = [0, 50]\n",
        "plt.xlim(lims)\n",
        "plt.ylim(lims)\n",
        "_ = plt.plot(lims, lims)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19wyogbOSU5t"
      },
      "source": [
        "Sembra che il nostro modello preveda ragionevolmente bene. Diamo un'occhiata alla distribuzione dell'errore."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f-OHX4DiXd8x"
      },
      "outputs": [],
      "source": [
        "error = test_predictions - test_labels\n",
        "plt.hist(error, bins = 25)\n",
        "plt.xlabel(\"Prediction Error [MPG]\")\n",
        "_ = plt.ylabel(\"Count\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0CB5tBjSU5w"
      },
      "source": [
        "Non è una gaussiana, ma potevamo aspettarcelo, perché il numero di campioni è molto piccolo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgGQuV-yqYZH"
      },
      "source": [
        "## Conclusioni\n",
        "\n",
        "Questo notebook ha introdotto alcune tecniche per gestire un problema di regressione.\n",
        "\n",
        "* L'Errore Quadratico Medio (MSE) è una funzione perdita comunemente usata nei problemi di regressione (per i problemi di classificazione si usano altre funzioni perdita).\n",
        "* Analogamente, le metriche di valutazione usate per la regressione sono diverse da quelle della classificazione. Una metrica di comune per la regressione è l'Errore Assoluto Medio (MAE).\n",
        "* Quando caratteristiche numeriche di input hanno valori su intervalli diversi, ogni caratteristica deve essere scalata indipendentemente sullo stesso intervallo.\n",
        "* Se non ci sono abbastanza dati di addestramento, una soluzione è preferire una rete piccola con pochi livelli per evitare il sovra-allenamento.\n",
        "* L'interruzione precoce è una tecnica utile per prevenire il sovra-allenamento."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "regression.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
