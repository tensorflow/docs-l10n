{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDnwEv8FtJm7"
      },
      "source": [
        "##### Copyright 2018 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "JlknJBWQtKkI"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60RdWsg1tETW"
      },
      "source": [
        "# Custom layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcJg7Enms86w"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/customization/custom_layers\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />Visualizza su TensorFlow.org</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/it/tutorials/customization/custom_layers.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Esegui in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/it/tutorials/customization/custom_layers.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />Visualizza il sorgente su GitHub</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/it/tutorials/customization/custom_layers.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Scarica il notebook</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEu3q4jmpKVT"
      },
      "source": [
        "Raccomandiamo di usare `tf.keras` come API di alto livello per la costruzione di reti neurali. Detto ciò, molte delle API di TensorFLow sono utilizzabili tramite esecuzione eager."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Py0m-N6VgQFJ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TluWFcB_2nP5"
      },
      "outputs": [],
      "source": [
        "print(tf.test.is_gpu_available())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSFfVVjkrrsI"
      },
      "source": [
        "## Layers: sets comuni di operazioni utili\n",
        "\n",
        "Spesso scrivendo codice per modelli di machine learning vuoi operare a un livello di astrazione più alto delle singole operazioni e della manipolazione di singole variabili.\n",
        "\n",
        "Molti modelli di machine learning sono esprimibili tramite composizione e impilamento di layer relativamente semplici e TensorFlow fornishe sia un set composto di molti layer comuni sia modalità semplici per te per scrivere layer specifici per la tua apllicazione da zero o come composizione di layer esistenti.\n",
        "\n",
        "TensorFlow include l'API completa di [Keras](https://keras.io) nel package tf.keras e i layer di Keras sono molto utili quando si creano i propri modelli.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8PyXlPl-4TzQ"
      },
      "outputs": [],
      "source": [
        "# Nel package tf.keras.layers, i layers sono oggetti. Per costruire un layer,\n",
        "# costruisci semplicemente l'oggetto. La maggior parte dei layer prendono come\n",
        "# primo argomento il numero delle dimensioni / canali in output.\n",
        "layer = tf.keras.layers.Dense(100)\n",
        "# Il numero di dimensioni in input è spesso non necessario, dal momento che\n",
        "# può essere inferita la prima volta che il layer è usato, ma può essere fornito\n",
        "# se vuoi spcificarlo manualmente, il che è utile in alcuni modelli complessi.\n",
        "layer = tf.keras.layers.Dense(10, input_shape=(None, 5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fn69xxPO5Psr"
      },
      "source": [
        "La lista completa di layer preesistenti può essere vista nella [documentazione](https://www.tensorflow.org/api_docs/python/tf/keras/layers). Questa include Dense (un layer completamente connesso),\n",
        "Conv2D, LSTM, BatchNormalization, Dropout e molti altri."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E3XKNknP5Mhb"
      },
      "outputs": [],
      "source": [
        "# Per usare un layer, è sufficente chiamarlo.\n",
        "layer(tf.zeros([10, 5]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wt_Nsv-L5t2s"
      },
      "outputs": [],
      "source": [
        "# I layers hanno molti metodi utili. Per esempio, puoi ispezionare tutte le\n",
        "# variabili in un layer usando `layer.variables` e variabili allenabili usando\n",
        "# `layer.trainable_variables`. In questo caso un layer completamente connesso\n",
        "# avrà variabili per pesi e bias.\n",
        "layer.variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ilvKjz8_4MQ"
      },
      "outputs": [],
      "source": [
        "# Le variabili sono  anche accessibili tramite accessori.\n",
        "layer.kernel, layer.bias"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0kDbE54-5VS"
      },
      "source": [
        "## Implementare layer custom\n",
        "\n",
        "Il modo migliore per implementare il tuo proprio layer è estendere la classe tf.keras.Layer e implementare:\n",
        "\n",
        "1. `__init__` , dove puoi fare tutte le inizializzazioni indipendenti dall'input\n",
        "2. `build`, dove sai la forma dei tensori di input e puoi fare il resto dell'inizializzazione\n",
        "3. `call`, dove puoi fare il calcolo forward\n",
        "\n",
        "Nota che non devi aspettare fino a che `build` sia chiamata per creare le tue variabili, puoi anche crearle in `__init__`. Tuttavia, il vantaggio di creare in `build` sta nella possibilità di creare le variabili dopo, basandosi sulla forma dell'input su cui il layer opererà. Dall'altro lato, creare le variabili in `__init__` significherebbe che la forma richiesta per creare le variabili dovra' esspere esplicitamente specificata."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Byl3n1k5kIy"
      },
      "outputs": [],
      "source": [
        "class MyDenseLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self, num_outputs):\n",
        "    super(MyDenseLayer, self).__init__()\n",
        "    self.num_outputs = num_outputs\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    self.kernel = self.add_weight(\"kernel\",\n",
        "                                  shape=[int(input_shape[-1]),\n",
        "                                         self.num_outputs])\n",
        "\n",
        "  def call(self, input):\n",
        "    return tf.matmul(input, self.kernel)\n",
        "\n",
        "layer = MyDenseLayer(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vrmBsYGOnuGO"
      },
      "outputs": [],
      "source": [
        "_ = layer(tf.zeros([10, 5])) # Calling the layer `.builds` it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1bsLjiPfnvat"
      },
      "outputs": [],
      "source": [
        "print([var.name for var in layer.trainable_variables])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tk8E2vY0-z4Z"
      },
      "source": [
        "Il codice in generale è più facile da leggere e mantenere se usa layer standard ogniqualvolta possibile, dal momento che i lettori saranno più familari col comportamento di layer standard. Se vuoi utilizzare un layer che non è present in `tf.keras.layers`, considera di creare una [issue github](http://github.com/tensorflow/tensorflow/issues/new) o, ancora meglio, di mandarci una pull request!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qhg4KlbKrs3G"
      },
      "source": [
        "## Modelli: Comporre layers\n",
        "\n",
        "Molte cose interessanti sullo stile dei layer nei modelli di machine learning sono implementate componendo layer esistenti. Per esempio, ogni blocco residuale in una resnet è la composizione di convoluzioni, normalizzazioni di batch e una scorciatoia. I layers possono essere innestati dentro altri layer.\n",
        "\n",
        "Tipicamente erediti da `keras.Model` quando necessiti di metodi per i modelli tra i quali: `Model.fit`,`Model.evaluate` e `Model.save` (vedi [Layer Custom Keras e modelli](../../guide/keras/custom_layers_and_models.ipynb) per dettagli).\n",
        "\n",
        "Un altra feature fornita da `keras.Model` (invece di `keras.layers.Layer`) è che in aggiunta al tenere traccia delle variabii, un `keras.Model` tiene traccia anche dei suoi layer interni, rendendoli più semplici per l'ispezione,\n",
        "\n",
        "Per esempio ecco qui un blocco ResNet:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N30DTXiRASlb"
      },
      "outputs": [],
      "source": [
        "class ResnetIdentityBlock(tf.keras.Model):\n",
        "  def __init__(self, kernel_size, filters):\n",
        "    super(ResnetIdentityBlock, self).__init__(name='')\n",
        "    filters1, filters2, filters3 = filters\n",
        "\n",
        "    self.conv2a = tf.keras.layers.Conv2D(filters1, (1, 1))\n",
        "    self.bn2a = tf.keras.layers.BatchNormalization()\n",
        "\n",
        "    self.conv2b = tf.keras.layers.Conv2D(filters2, kernel_size, padding='same')\n",
        "    self.bn2b = tf.keras.layers.BatchNormalization()\n",
        "\n",
        "    self.conv2c = tf.keras.layers.Conv2D(filters3, (1, 1))\n",
        "    self.bn2c = tf.keras.layers.BatchNormalization()\n",
        "\n",
        "  def call(self, input_tensor, training=False):\n",
        "    x = self.conv2a(input_tensor)\n",
        "    x = self.bn2a(x, training=training)\n",
        "    x = tf.nn.relu(x)\n",
        "\n",
        "    x = self.conv2b(x)\n",
        "    x = self.bn2b(x, training=training)\n",
        "    x = tf.nn.relu(x)\n",
        "\n",
        "    x = self.conv2c(x)\n",
        "    x = self.bn2c(x, training=training)\n",
        "\n",
        "    x += input_tensor\n",
        "    return tf.nn.relu(x)\n",
        "\n",
        "\n",
        "block = ResnetIdentityBlock(1, [1, 2, 3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7D8ZR5mqtokj"
      },
      "outputs": [],
      "source": [
        "_ = block(tf.zeros([1, 2, 3, 3])) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MJ8rzFpdoE_m"
      },
      "outputs": [],
      "source": [
        "block.layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dewldLuDvQRM"
      },
      "outputs": [],
      "source": [
        "len(block.variables)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FrqIXeSetaYi"
      },
      "outputs": [],
      "source": [
        "block.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYfucVw65PMj"
      },
      "source": [
        "La maggior parte delle volte, tuttavia, i modelli che compongono molti layer sono semplicemente chiamati un layer alla volta. Questo può essere fatto con poco codice usando `tf.keras.Sequential`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L9frk7Ur4uvJ"
      },
      "outputs": [],
      "source": [
        "my_seq = tf.keras.Sequential([tf.keras.layers.Conv2D(1, (1, 1),\n",
        "                                                    input_shape=(\n",
        "                                                        None, None, 3)),\n",
        "                             tf.keras.layers.BatchNormalization(),\n",
        "                             tf.keras.layers.Conv2D(2, 1,\n",
        "                                                    padding='same'),\n",
        "                             tf.keras.layers.BatchNormalization(),\n",
        "                             tf.keras.layers.Conv2D(3, (1, 1)),\n",
        "                             tf.keras.layers.BatchNormalization()])\n",
        "my_seq(tf.zeros([1, 2, 3, 3]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tVAsbFITuScB"
      },
      "outputs": [],
      "source": [
        "my_seq.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5YwYcnuK-wc"
      },
      "source": [
        "# Passi successivi\n",
        "\n",
        "Ora puoi tornare indietro al notebook precedente e addattare l'esempio della regressione lineare per usare layer e modelli affiché sia meglio strutturato."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "custom_layers.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
